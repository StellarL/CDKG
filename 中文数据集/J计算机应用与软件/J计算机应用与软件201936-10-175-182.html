<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135556551252500%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJYRJ201910032%26RESULT%3d1%26SIGN%3dy5DvaZ%252bA5YvZa3YPegLFvnvmFUE%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201910032&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201910032&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201910032&amp;v=MjA4NDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEaFZyL0FMelRaWkxHNEg5ak5yNDlHWm9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#57" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#64" data-title="&lt;b&gt;1 深度前馈网络理论&lt;/b&gt; "><b>1 深度前馈网络理论</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#66" data-title="&lt;b&gt;1.1 参数初始化&lt;/b&gt;"><b>1.1 参数初始化</b></a></li>
                                                <li><a href="#69" data-title="&lt;b&gt;1.2 非线性激活函数&lt;/b&gt;"><b>1.2 非线性激活函数</b></a></li>
                                                <li><a href="#74" data-title="&lt;b&gt;1.3 交叉熵损失函数&lt;/b&gt;"><b>1.3 交叉熵损失函数</b></a></li>
                                                <li><a href="#82" data-title="&lt;b&gt;1.4 输出单元&lt;/b&gt;"><b>1.4 输出单元</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;1.5 结构设计&lt;/b&gt;"><b>1.5 结构设计</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#87" data-title="&lt;b&gt;2 深度前馈网络优化设计&lt;/b&gt; "><b>2 深度前馈网络优化设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#88" data-title="&lt;b&gt;2.1 梯度优化算法&lt;/b&gt;"><b>2.1 梯度优化算法</b></a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;2.2 正则化&lt;/b&gt;"><b>2.2 正则化</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#102" data-title="&lt;b&gt;3 实 验&lt;/b&gt; "><b>3 实 验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#104" data-title="&lt;b&gt;3.1 实验数据及预处理&lt;/b&gt;"><b>3.1 实验数据及预处理</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;3.2 参数设置&lt;/b&gt;"><b>3.2 参数设置</b></a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;3.3 结果分析&lt;/b&gt;"><b>3.3 结果分析</b></a></li>
                                                <li><a href="#127" data-title="&lt;b&gt;3.4 与其他方法的比较分析&lt;/b&gt;"><b>3.4 与其他方法的比较分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#132" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#72" data-title="图1 ReLU激活函数曲线">图1 ReLU激活函数曲线</a></li>
                                                <li><a href="#90" data-title="图2 TensorFlow中各种优化算法关系图">图2 TensorFlow中各种优化算法关系图</a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;表1 Adam算法&lt;/b&gt;"><b>表1 Adam算法</b></a></li>
                                                <li><a href="#98" data-title="图3 Dropout示意图">图3 Dropout示意图</a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;表2 轴承故障规格&lt;/b&gt;"><b>表2 轴承故障规格</b></a></li>
                                                <li><a href="#108" data-title="图4 10种不同工况下振动原始信号图">图4 10种不同工况下振动原始信号图</a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;表3 TensorFlow中核心参数的设置&lt;/b&gt;"><b>表3 TensorFlow中核心参数的设置</b></a></li>
                                                <li><a href="#115" data-title="图5 网络结构对故障诊断准确率的影响">图5 网络结构对故障诊断准确率的影响</a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;表4 不同网络结构下的网络模型故障诊断评估&lt;/b&gt;"><b>表4 不同网络结构下的网络模型故障诊断评估</b></a></li>
                                                <li><a href="#121" data-title="图6 TensorFlow中Deep feedforward network的
故障诊断模型">图6 TensorFlow中Deep feedforward network的
故障诊断模型</a></li>
                                                <li><a href="#122" data-title="图7 准确率和训练次数的关系曲线图">图7 准确率和训练次数的关系曲线图</a></li>
                                                <li><a href="#123" data-title="图8 损失和训练次数的关系曲线图">图8 损失和训练次数的关系曲线图</a></li>
                                                <li><a href="#124" data-title="图9 混淆矩阵">图9 混淆矩阵</a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;表5 故障诊断报告&lt;/b&gt;"><b>表5 故障诊断报告</b></a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;表6 不同方法的诊断结果比较&lt;/b&gt;"><b>表6 不同方法的诊断结果比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 吕维宗,王海瑞,舒捷.量子粒子群算法优化相关向量机的轴承故障诊断[J].计算机应用与软件,2019,36(1):6-11,16." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201901003&amp;v=MDkwMTNvOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURoVnIvQUx6VFpaTEc0SDlqTXI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         吕维宗,王海瑞,舒捷.量子粒子群算法优化相关向量机的轴承故障诊断[J].计算机应用与软件,2019,36(1):6-11,16.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Lei Y.Intelligent fault diagnosis and remaining useful life prediction of rotating machinery[M].Xi’an Jiaotong university press,2017:146." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Intelligent fault diagnosis and remaining useful life prediction of rotating machinery">
                                        <b>[2]</b>
                                         Lei Y.Intelligent fault diagnosis and remaining useful life prediction of rotating machinery[M].Xi’an Jiaotong university press,2017:146.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Wongsuphasawat K,Smilkov D,Wexler J,et al.Visualizing dataflow graphs of deep learning models in TensorFlow[J].IEEE Transactions on Visualization and Computer Graphics,2018,24(1):1-12." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visualizing dataflow graphs of deep learning models in TensorFlow">
                                        <b>[3]</b>
                                         Wongsuphasawat K,Smilkov D,Wexler J,et al.Visualizing dataflow graphs of deep learning models in TensorFlow[J].IEEE Transactions on Visualization and Computer Graphics,2018,24(1):1-12.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 靳涛,张永爱.TensorFlow平台下基于深度学习的数字识别[J].信息技术与网络安全,2018,37(4):74-78." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201804017&amp;v=MDc2Mjk5bk1xNDlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEaFZyL0FNalhCZDdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         靳涛,张永爱.TensorFlow平台下基于深度学习的数字识别[J].信息技术与网络安全,2018,37(4):74-78.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 侯艳路,丁世飞,孙统风.混合深度学习模型C-RF及其在手写数字识别中的应用[J].数据采集与处理,2018,33(2):343-350." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJCJ201802017&amp;v=MTk2NDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEaFZyL0FOaWZJWkxHNEg5bk1yWTlFWTRRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         侯艳路,丁世飞,孙统风.混合深度学习模型C-RF及其在手写数字识别中的应用[J].数据采集与处理,2018,33(2):343-350.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 韩山杰,谈世哲.基于TensorFlow进行股票预测的深度学习模型的设计与实现[J].计算机应用与软件,2018,35(6):267-271,291." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201806050&amp;v=MjI2NTR6cXFCdEdGckNVUjdxZlp1WnRGaURoVnIvQUx6VFpaTEc0SDluTXFZOUFaSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         韩山杰,谈世哲.基于TensorFlow进行股票预测的深度学习模型的设计与实现[J].计算机应用与软件,2018,35(6):267-271,291.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 王丽华,谢阳阳,周子贤,等.基于卷积神经网络的异步电机故障诊断[J].振动测试与诊断,2017,37(6):1208-1215,1283." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDCS201706023&amp;v=MTk4MzE0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURoVnIvQVB5bklmYkc0SDliTXFZOUhaNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         王丽华,谢阳阳,周子贤,等.基于卷积神经网络的异步电机故障诊断[J].振动测试与诊断,2017,37(6):1208-1215,1283.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 王丽华,谢阳阳,张永宏,等.采用深度学习的异步电机故障诊断方法[J].西安交通大学学报,2017,51(10):128-134." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAJT201710021&amp;v=MTYzNzgvQVBTekJlckc0SDliTnI0OUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURoVnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         王丽华,谢阳阳,张永宏,等.采用深度学习的异步电机故障诊断方法[J].西安交通大学学报,2017,51(10):128-134.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 孙文珺,邵思羽,严如强.基于稀疏自动编码深度神经网络的感应电动机故障诊断[J].机械工程学报,2016,52(9):65-71." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXXB201609009&amp;v=MjYwMDlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZpRGhWci9BTHpYVGJMRzRIOWZNcG85RmJZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         孙文珺,邵思羽,严如强.基于稀疏自动编码深度神经网络的感应电动机故障诊断[J].机械工程学报,2016,52(9):65-71.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Wen L,Li X,Gao L,et al.A new convolutional neural network based data-driven fault diagnosis method[J].IEEE Transactions on Industrial Electronics,2018,65(7):5990-5998." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A new convolutional neural network-based data-driven fault diagnosis method">
                                        <b>[10]</b>
                                         Wen L,Li X,Gao L,et al.A new convolutional neural network based data-driven fault diagnosis method[J].IEEE Transactions on Industrial Electronics,2018,65(7):5990-5998.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 仝卫国,李敏霞,张一可.深度学习优化算法研究[J].计算机科学,2018,45(S2):155-159." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2018S2030&amp;v=MjY4NzJGaURoVnIvQUx6N0JiN0c0SDltdnJZOUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         仝卫国,李敏霞,张一可.深度学习优化算法研究[J].计算机科学,2018,45(S2):155-159.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Nair V,Hinton G E.Rectified linear units improve restricted boltzmann machines[C]//Proceedings of the 27th International Conference on International Conference on Machine Learning.Omnipress,2010:807-814." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rectified linear units improve restricted boltzmann machines">
                                        <b>[12]</b>
                                         Nair V,Hinton G E.Rectified linear units improve restricted boltzmann machines[C]//Proceedings of the 27th International Conference on International Conference on Machine Learning.Omnipress,2010:807-814.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Glorot X,Bengio Y.Understanding the difficulty of training deep feedforward neural networks[J].Journal of Machine Learning Research,2010,9:249-256." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Understanding the difficulty of training deep feedforward neural networks">
                                        <b>[13]</b>
                                         Glorot X,Bengio Y.Understanding the difficulty of training deep feedforward neural networks[J].Journal of Machine Learning Research,2010,9:249-256.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Jarrett K,Kavukcuoglu K,Ranzato M,et al.What is the best multi-stage architecture for object recognition?[C]//2009 IEEE 12th International Conference on Computer Vision,2009:2146-2153." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=What is the Best Multi-Stage Architecture for Object Recognition?">
                                        <b>[14]</b>
                                         Jarrett K,Kavukcuoglu K,Ranzato M,et al.What is the best multi-stage architecture for object recognition?[C]//2009 IEEE 12th International Conference on Computer Vision,2009:2146-2153.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Dahl G E,Sainath T N,Hinton G E.Improving deep neural networks for LVCSR using rectified linear units and dropout[C]//2013 IEEE International Conference on Acoustics,Speech and Signal Processing,2013:8609-8613." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving deep neural netw orks for LVCSR using rectified linear units and dropout">
                                        <b>[15]</b>
                                         Dahl G E,Sainath T N,Hinton G E.Improving deep neural networks for LVCSR using rectified linear units and dropout[C]//2013 IEEE International Conference on Acoustics,Speech and Signal Processing,2013:8609-8613.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     Glorot X,Bordes A,Bengio Y.Deep sparse rectifier neural networks[C]//Proceedings of the 14th International Conference on Artificial Intelligence and Statistics(AISTATS).2010.</a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     郑泽宇,梁博文,顾思宇.Tensorflow实战google深度学习框架[M].电子工业出版社,2018:75.</a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Ian G,Yoshua B,Aaron C.Deep learning[M].Posts &amp;amp; Telecom Press,2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep learning">
                                        <b>[18]</b>
                                         Ian G,Yoshua B,Aaron C.Deep learning[M].Posts &amp;amp; Telecom Press,2017.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" 何宇健.Python与机器学习实战:决策树、集成学习、支持向量机与神经网络算法详解及编程实现[M].电子工业出版社,2017:203-204." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787121317200000&amp;v=MzI1MzlTbURkOVNIN24zeEU5ZmJ2bktyaWZaZVp2RnlubVVyZk1KVjRjWEZxekdiSzZIOUxOcUkxRlpPc1BEQk04enhV&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         何宇健.Python与机器学习实战:决策树、集成学习、支持向量机与神经网络算法详解及编程实现[M].电子工业出版社,2017:203-204.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" Hornik K,Stinchcombe M,White H.Multilayer feedforward networks are universal approximators[J].Neural Networks,1989,2(5):359-366." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multilayer feedforward networks are universal approximators">
                                        <b>[20]</b>
                                         Hornik K,Stinchcombe M,White H.Multilayer feedforward networks are universal approximators[J].Neural Networks,1989,2(5):359-366.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" Sutskever I,Martens J,Dahl G,et al.On the importance of initialization and momentum in deep learning[C]//Proceedings of the 30th International Conference on International Conference on Machine Learning—Volume 28.2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the importance of initialization and momentum in deep learning">
                                        <b>[21]</b>
                                         Sutskever I,Martens J,Dahl G,et al.On the importance of initialization and momentum in deep learning[C]//Proceedings of the 30th International Conference on International Conference on Machine Learning—Volume 28.2013.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" >
                                        <b>[22]</b>
                                     Duchi J,Hazan E,Singer Y.Adaptive subgradient methods for online learning and stochastic optimization[J].Journal of Machine Learning Research,2011,12(7):257-269.</a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" Tieleman T,Hinton G.RMSProp:Divide the gradient by a running average of its recent magnitude[R].COURSERA:Neural Networks for Machine Learning.2012." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Lecture 6.5-rmsprop:Divide the gradient by a running average of its recent magnitude">
                                        <b>[23]</b>
                                         Tieleman T,Hinton G.RMSProp:Divide the gradient by a running average of its recent magnitude[R].COURSERA:Neural Networks for Machine Learning.2012.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" Kingma D P,Ba J.Adam:A method for stochastic optimization[EB].arXiv:1412.6980.2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adam:A method for stochastic optimization[EB]">
                                        <b>[24]</b>
                                         Kingma D P,Ba J.Adam:A method for stochastic optimization[EB].arXiv:1412.6980.2014.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" Le Q V,Ngiam J,Coates A,et al.On optimization methods for deep learning[C]//Proceedings of the 28th International Conference on Machine Learning,ICML 2011,Bellevue,Washington,USA,June 28—July 2,2011.DBLP,2011." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On optimization methods for deep learning">
                                        <b>[25]</b>
                                         Le Q V,Ngiam J,Coates A,et al.On optimization methods for deep learning[C]//Proceedings of the 28th International Conference on Machine Learning,ICML 2011,Bellevue,Washington,USA,June 28—July 2,2011.DBLP,2011.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_26" title=" 周安众,罗可.一种卷积神经网络的稀疏性Dropout正则化方法[J].小型微型计算机系统,2018,39(8):1674-1679." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201808008&amp;v=MDk1MDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEaFZyL0FQVFhjZHJHNEg5bk1wNDlGYklRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                         周安众,罗可.一种卷积神经网络的稀疏性Dropout正则化方法[J].小型微型计算机系统,2018,39(8):1674-1679.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_27" title=" Srivastava N,Hinton G,Krizhevsky A,et al.Dropout:A simple way to prevent neural networks from overfitting[J].Journal of Machine Learning Research,2014,15(1):1929-1958." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dropout:A simple way to prevent neural networks from overfitting">
                                        <b>[27]</b>
                                         Srivastava N,Hinton G,Krizhevsky A,et al.Dropout:A simple way to prevent neural networks from overfitting[J].Journal of Machine Learning Research,2014,15(1):1929-1958.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(10),175-182 DOI:10.3969/j.issn.1000-386x.2019.10.031            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>TensorFlow中深度前馈网络优化研究及其轴承故障诊断应用</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%A2%81%E6%98%B1&amp;code=40746261&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">梁昱</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%BD%AC%E5%BD%AC&amp;code=24951709&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李彬彬</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E5%BF%97%E9%AB%98&amp;code=42269807&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈志高</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%84%A6%E6%96%8C&amp;code=08558565&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">焦斌</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E7%94%B5%E6%9C%BA%E5%AD%A6%E9%99%A2%E7%94%B5%E6%B0%94%E5%AD%A6%E9%99%A2&amp;code=0140466&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海电机学院电气学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E6%A0%B8%E6%A3%80%E4%BF%AE%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8%E6%B5%B7%E7%9B%90%E5%88%86%E5%85%AC%E5%8F%B8&amp;code=1738436&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中核检修有限公司海盐分公司</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>目前在复杂系统的故障诊断中,故障特征与故障类型之间存在较强的非线性关系,且数据量较大,信号处理复杂,诊断效率不高,而深度学习在特征提取与模式识别方面显示出巨大潜力。针对此问题提出基于深度前馈网络的故障诊断模型,将其应用于复杂的轴承故障诊断。该方法直接将原始信号作为模型的输入特征量,然后利用谷歌开源深度学习框架TensorFlow建模,通过相关参数设置、梯度算法优化、正则化处理对网络进行优化设计。构建上万的9种轴承故障类型样本,确保样本多样性,提高网络鲁棒性,最终优化后的模型诊断准确率为98.96%。将该方法与多种传统的机器学习诊断方法进行比较,结果表明该方法能更有效地进行轴承故障诊断,验证了模型的合理性和优越性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度前馈网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%82%E6%95%B0%E9%80%89%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">参数选取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">优化算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=TensorFlow&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">TensorFlow;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BD%B4%E6%89%BF%E6%95%85%E9%9A%9C%E8%AF%8A%E6%96%AD&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">轴承故障诊断;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    梁昱，硕士生，主研领域:电机故障诊断。;
                                </span>
                                <span>
                                    李彬彬，讲师。;
                                </span>
                                <span>
                                    陈志高，工程师。;
                                </span>
                                <span>
                                    焦斌，教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-08</p>

            </div>
                    <h1><b>OPTIMIZATION OF DEEP FEEDFORWARD NETWORK IN TENSORFLOW AND ITS APPLICATION OF BEARING FAULT DIAGNOSIS</b></h1>
                    <h2>
                    <span>Liang Yu</span>
                    <span>Li Binbin</span>
                    <span>Chen Zhigao</span>
                    <span>Jiao Bin</span>
            </h2>
                    <h2>
                    <span>School of Electrical Engineering, Shanghai Dianji University</span>
                    <span>China Nuclear Industry Maintenance Co., Ltd.Haiyan Branch</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>At present, in the fault diagnosis of complex systems, there is a strong nonlinear relationship between the fault characteristics and the fault type. Due to the big amount of data and the complex signal processing, the efficiency of diagnosis is not high, while the deep learning has shown great potential in feature extraction and pattern recognition. We proposed a fault diagnosis model based on deep feedforward network for this problem, which was applied to complex bearing fault diagnosis. We directly regarded the original signal as the input feature of the model, and then used the Google open source deep learning framework TensorFlow to model and optimize the network through relevant parameters setting, gradient optimization algorithm and regularization processing. Nine kinds of bearing fault samples beyond 10 000, were built to ensure sample diversity, improve network robustness. The final optimized model diagnosis accuracy is 98.96%. This method is compared with many traditional machine learning methods, and the results show that it can diagnose bearing fault more effectively and verify the rationality and superiority of the model.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deep%20feedforward%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deep feedforward network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Parameter%20selection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Parameter selection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Optimization%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Optimization algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=TensorFlow&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">TensorFlow;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Bearing%20fault%20diagnosis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Bearing fault diagnosis;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-08</p>
                            </div>


        <!--brief start-->
                        <h3 id="57" name="57" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="58">在工业生产中,大型旋转机械设备安全可靠地正常运行极其重要,其中轴承作为其关键部件,一旦发生故障,将对公司生产效益和人身安全产生很大的影响,所以滚动轴承的运维和故障诊断技术极为重要<citation id="138" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="59">深度学习是指一类机器学习技术,其深层体系结构中的多层信息非线性处理机制被用于模式分类以及其他学习任务<citation id="139" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>,它强调多层和非线性。实际上,深度学习起源于Artificial Neural Network的概念,所以深度学习基本上就是指深层神经网络。</p>
                </div>
                <div class="p1">
                    <p id="60">谷歌公司的深度学习框架TensorFlow是一个灵活便利、功能强大的机器学习库,许多深度学习算法封装于其中,用户只要将TensorFlow导入到Python中调用就可以搭建各种网络模型,极大方便了深度学习的研究<citation id="140" type="reference"><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="61">基于深度前馈网络,近年来,深度学习在机器学习领域备受关注,在分类、预测、故障诊断等多领域取得突破的成果。文献<citation id="141" type="reference">[<a class="sup">5</a>]</citation>中提出了C-RF模型,把卷积神经网络(CNN)提取到的特征输入随机森林(RF)中进行分类,实验结果表明该模型的分类效果和泛化能力比单独使用RF有了很大的提高。文献<citation id="142" type="reference">[<a class="sup">6</a>]</citation>中提出构建多层感知器(MLP)神经网络模型用于股票预测,并将TensorFlow与传统BP神经网络进行性能对比,实验结果说明TensorFlow具有更好的预测准确度和更快的收敛速度。文献<citation id="144" type="reference">[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</citation>分别提出了基于短时傅里叶变换(STFT)、CNN、SDAE的电机故障诊断方法,并与传统的故障诊断方法进行比较,实验结果表明,所提出方法能更好地实现感应电机故障诊断。文献<citation id="143" type="reference">[<a class="sup">10</a>]</citation>提出了一种新的基于LeNet-5卷积网络的数据驱动故障诊断方法,1-D信号转换成2-D图像信号,提高了模型的特征提取能力,并应用于电机轴承、水泵、液压泵的故障诊断中,模型预测准确率都在99%以上。</p>
                </div>
                <div class="p1">
                    <p id="62">深度学习取得重大成果的原因一方面在于计算机运算能力的提高和大数据的支持,另一方面是网络本身结构和参数的合理设置与选择。合适的训练优化算法、合理的参数设置和模型结构直接影响网络模型的泛化能力和准确性,有助于加快收敛速度防止过拟合。因此,参数设置、优化算法和网络结构一直是深度学习研究中的重点和难点<citation id="145" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="63">本文基于现代深度前馈神经网络的基本理论,对深层神经网络中的参数设置、优化算法、结构选择进行深入研究,在TensorFlow中建立最优深度前馈神经网络模型。本文提出直接将原始振动信号作为模型的输入,无需进行复杂的信号处理和故障特征提取。最后结合美国西储大学滚动轴承方面的实验数据,将优化的模型在电机轴承故障诊断领域中进行了验证,完成9种不同工况下轴承的故障诊断,并和其他常用的机器学习算法比较。</p>
                </div>
                <h3 id="64" name="64" class="anchor-tag"><b>1 深度前馈网络理论</b></h3>
                <div class="p1">
                    <p id="65">深度前馈网络应用在故障诊断方面,可以将其看作是分类器,定义了一个映射集<i>y</i>=<i>f</i>(<i>x</i>,<i>θ</i>),输入<i>x</i>通过相关参数<i>θ</i>映射到一个输出类别<i>y</i>。</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66"><b>1.1 参数初始化</b></h4>
                <div class="p1">
                    <p id="67">深度前馈网络模型中参数<i>θ</i>的学习算法是迭代的,所以初始值(即迭代起点)对于迭代过程是否达到局部最小、是否能够收敛到一个代价高或低的点以及训练时间的大小关系密切,不合适的参数初始化方法会降低梯度的学习优化效率和网络泛化能力<citation id="146" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。通常来说,需要初始化每个单元使其具有不同的初始参数,防止学习算法以相同的方式更新某两个单元,因此促使了参数的随机初始化。</p>
                </div>
                <div class="p1">
                    <p id="68">通常情况下,可以为每个神经元除权值以外的参数(如偏置值等)设置启发式挑选的常数,设置为0或0附近小的常数。而所有的权值则初始化为小的随机数,可以在高斯分布中随机抽取。一般而言总是希望神经元的输出值接近于零,尽可能保证参数<i>θ</i>都能够在其激活函数偏导数最大之处进行调整。因此在TensorFlow中权值初始化可以从截断正态分布中随机抽取,生成的值<i>w</i>～<i>N</i>(<i>μ</i>,<i>σ</i><sup>2</sup>),其中,<i>μ</i>=0,<i>σ</i><sup>2</sup>=1,如果<i>w</i>的取值在区间(<i>μ</i>-2<i>σ</i>,<i>μ</i>+2<i>σ</i>)之外则重新进行选择。由正态分布的“3<i>σ</i>”原则可知,区间(<i>μ</i>-2<i>σ</i>,<i>μ</i>+2<i>σ</i>)内的面积为95.45%,这样保证权值<i>w</i>都在均值0附近。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69"><b>1.2 非线性激活函数</b></h4>
                <div class="p1">
                    <p id="70">非激活函数通常用于隐含层,完成信号的前向传播。传统Sigmoid和Tanh函数<citation id="147" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>大部分定义域内都饱和,仅接近0时它们才对输入强烈敏感,这种广泛饱和性会造成梯度消失,并且不具有稀疏性。只有当合适的代价函数来抵消饱和性时,它们作为输出单元可以与基于梯度的学习相兼容。</p>
                </div>
                <div class="p1">
                    <p id="71">神经学家发现生物神经元的激活方式具有单侧抑制、兴奋边界宽阔以及输出具有稀疏性的特性。ReLU函数<i>f</i>(<i>x</i>)=max(<i>x</i>,0),曲线如图1所示。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910032_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 ReLU激活函数曲线" src="Detail/GetImg?filename=images/JYRJ201910032_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 ReLU激活函数曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910032_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="73">可以看出,ReLU函数几乎是线性的,这使得只要是处于激活状态,其导数都能保持较大,小于0则没有输出,因此它保留了许多使得线性模型易于使用基于梯度的方法进行优化的属性,同时也符合生物神经元单侧抑制和兴奋边界宽阔的特性,并且ReLU函数还具有稀疏表达能力。因此,目前深度前馈网络、CNN、RNN、LSTM等主流深度学习模型的激活函数大多采用ReLU函数<citation id="149" type="reference"><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>。文献<citation id="148" type="reference">[<a class="sup">16</a>]</citation>表明ReLU函数在训练正确率和网络收敛速度上均优于其他激活函数。</p>
                </div>
                <h4 class="anchor-tag" id="74" name="74"><b>1.3 交叉熵损失函数</b></h4>
                <div class="p1">
                    <p id="75">深度前馈网络模型效果及优化的目标是通过损失函数来定义的,损失函数是模型对数据拟合程度的反映,拟合得越好,则值越小。常用的损失函数为:均方差损失函数和交叉熵损失函数。均方差损失函数(MSE)直观意义是模型预测值和真值的欧氏距离,而交叉熵损失函数(Cross entropy)如下:</p>
                </div>
                <div class="p1">
                    <p id="76"><mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo stretchy="false">(</mo><mi>p</mi><mo>,</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>x</mi></munder><mi>p</mi></mstyle><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mrow><mi>log</mi></mrow><mi>q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="77">给定两个概率分布<i>p</i>和<i>q</i>,交叉熵刻画了两个概率分布之间的距离,值越小则说明两者越接近。在决策分类问题中使用比较广泛<citation id="150" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。在故障诊断中概率分布<i>p</i><sub><i>i</i></sub>是真正的标签,给定分布<i>q</i><sub><i>i</i></sub>是预测值。</p>
                </div>
                <div class="p1">
                    <p id="78">基于统计学理论,现代深度前馈网络大多数都使用最大似然原理来优化学习,即损失函数就是负的对数似然,它与交叉熵等价。损失函数表示为:</p>
                </div>
                <div class="p1">
                    <p id="79"><mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mo>-</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>,</mo><mi>y</mi><mo>∼</mo><mover accent="true"><mi>p</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mtext>d</mtext><mtext>a</mtext><mtext>t</mtext><mtext>a</mtext></mrow></msub></mrow></msub><mrow><mi>log</mi></mrow><mspace width="0.25em" /><mi>p</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>o</mtext><mtext>d</mtext><mtext>e</mtext><mtext>l</mtext></mrow></msub><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="80">式中:<mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>p</mi><mo>^</mo></mover></math></mathml><sub>data</sub>为数据生成分布,在统计学理论中,可以把训练集和测试集样本看成是相互独立的,二者数据集是同分布的;<i>E</i>是期望。损失函数的具体形式取决于log <i>p</i><sub>model</sub>。</p>
                </div>
                <div class="p1">
                    <p id="81">使用最大似然来导出损失函数的方法,一方面减轻了每个模型设计损失函数的负担,这样不用预测<i>y</i>的完整概率分布,而是仅仅预测在<i>x</i>条件下<i>y</i>的某种统计量,例如参数的点估计、偏差、方差,对于刻画泛化、过拟合等非常有帮助;另一方面负的对数似然在很多模型中避免了激活函数梯度饱和(梯度消失)的问题,损失函数取对数后可以消除某些输出单元中的指数效果。这也是交叉熵损失函数比均方差损失函数更受欢迎的原因之一<citation id="151" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="82" name="82"><b>1.4 输出单元</b></h4>
                <div class="p1">
                    <p id="83">神经网络的输出不一定是一个概率分布,但是在电机故障诊断中可以把“一个样例属于某一个类别”看成一个概率事件,那么训练数据的正确答案就符合一个概率分布,将输出结果变成概率分布常用的方法是用于Multinoulli输出分布的Softmax单元。假设原始的神经网络输出为<i>y</i>,那么经过Softmax回归处理之后的输出为<citation id="152" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="84">Softmax<mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mtext>e</mtext><msup><mrow></mrow><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msup></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mtext>e</mtext></mstyle><msup><mrow></mrow><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msup></mrow></mfrac></mrow></math></mathml>      (3)</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>1.5 结构设计</b></h4>
                <div class="p1">
                    <p id="86">深度前馈网络的整体结构主要包括网络的深度和宽度。神经网络的万能近似定理表明<citation id="153" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>,即使网络只有一个隐含层,但只要节点数足够多(网络足够宽)也能够在训练集上近似任何函数,而更深的网络则意味着每一层会使用较少的节点数,但缺点是网络过于复杂难以优化,大大增加了参数训练的时间,所以模型性能提高优先考虑增加隐含层中的神经元数,其训练效果会比增加层数更容易观察和调整。结构设计可采用如下方法:先设较少的节点数,然后逐渐增加节点数,每次对网络进行训练并记录在验证集上表现的误差,直到满足要求即可。因此最优的深度前馈网络结构必须通过大量实验来找到。</p>
                </div>
                <h3 id="87" name="87" class="anchor-tag"><b>2 深度前馈网络优化设计</b></h3>
                <h4 class="anchor-tag" id="88" name="88"><b>2.1 梯度优化算法</b></h4>
                <div class="p1">
                    <p id="89">在参数的更新过程中,某些优化算法能根据模型的参数和损失来优化模型。梯度下降法是最普遍的优化算法,它会沿逆梯度方向让超参数不断更新,使总损失不断下降。优化损失函数<i>L</i>(<i>θ</i>)过程可以抽象为寻找一个参数<i>θ</i>,使得<i>L</i>(<i>θ</i>)最小,通过迭代的方法来不断逼近最优解。一般来说,参数更新包含两种思路:更新的方向和调整学习率。TensorFlow中常用的优化方法有<citation id="154" type="reference"><link href="43" rel="bibliography" /><link href="45" rel="bibliography" /><link href="47" rel="bibliography" /><link href="49" rel="bibliography" /><sup>[<a class="sup">21</a>,<a class="sup">22</a>,<a class="sup">23</a>,<a class="sup">24</a>]</sup></citation>:更新方向算法,包括梯度下降法(GD)和动量法(Momentum);自适应学习率调整(Adaptive learning rate)算法,包括AdaGrad算法、RMSProp算法、Adam算法。优化算法之间联系如图2所示。</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910032_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 TensorFlow中各种优化算法关系图" src="Detail/GetImg?filename=images/JYRJ201910032_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 TensorFlow中各种优化算法关系图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910032_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="91">由图2可以看出,梯度下降对于神经网络而言,几乎所有深度模型的迭代总是基于梯度来使得损失函数下降,梯度下降可谓是训练的全部,最多也只是不断地研究出各式各样的梯度下降法的变体而已。</p>
                </div>
                <div class="p1">
                    <p id="92">梯度下降法的缺点<citation id="155" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>:不能保证被优化的函数达到全局最优解,容易陷入局部极小值;计算时间长、收敛速度慢,学习率无法自适应调整,在海量数据下,要计算所有训练数据的损失函数是非常消耗时间的。而Adam<citation id="156" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>算法是利用梯度一阶矩估计和二阶矩估计动态调整每个参数的学习率,算法描述如表1所示。</p>
                </div>
                <div class="area_img" id="93">
                    <p class="img_tit"><b>表1 Adam算法</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="93" border="1"><tr><td><br />Require</td><td>全局学习率<i>η</i>,默认0.001,初始参数<i>θ</i>,用于数值稳定的小常数<i>δ</i>,矩估计的指数衰减率<i>ρ</i><sub>1</sub>和<i>ρ</i><sub>2</sub>,默认分别为0.9和0.999,初始化一阶和二阶变量以及时间<i>s</i>=<i>G</i>=<i>t</i>=0</td></tr><tr><td><br />计算梯度</td><td><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><mo>←</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mo>∇</mo><msub><mrow></mrow><mi>θ</mi></msub><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>L</mi></mstyle><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup></mrow></math>;<i>θ</i>),<i>y</i><sup>(<i>i</i>)</sup>)</td></tr><tr><td><br />更新有偏一阶矩估计</td><td><i>s</i>←<i>ρ</i><sub>1</sub><i>s</i>+(1-<i>ρ</i><sub>1</sub>)<i>g</i></td></tr><tr><td><br />更新有偏二阶矩估计</td><td><i>G</i>←<i>ρ</i><sub>2</sub><i>G</i>+(1-<i>ρ</i><sub>2</sub>)<i>g</i>⊙<i>g</i></td></tr><tr><td><br />修正一阶估计偏差</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>s</mi><mo>^</mo></mover><mo>←</mo><mfrac><mi>s</mi><mrow><mn>1</mn><mo>-</mo><mi>ρ</mi><msubsup><mrow></mrow><mn>1</mn><mi>t</mi></msubsup></mrow></mfrac></mrow></math></td></tr><tr><td><br />修正二阶估计偏差</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>G</mi><mo>^</mo></mover><mo>←</mo><mfrac><mi>G</mi><mrow><mn>1</mn><mo>-</mo><mi>ρ</mi><msubsup><mrow></mrow><mn>2</mn><mi>t</mi></msubsup></mrow></mfrac></mrow></math></td></tr><tr><td><br />计算参数更新</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Δ</mtext><mi>θ</mi><mo>=</mo><mi>η</mi><mfrac><mi>G</mi><mrow><mi>δ</mi><mo>+</mo><msqrt><mover accent="true"><mi>G</mi><mo>^</mo></mover></msqrt></mrow></mfrac></mrow></math></td></tr><tr><td><br />应用更新</td><td><i>θ</i>←<i>θ</i>-Δ<i>θ</i></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="94">可以看出,Adam优化算法在于计算历史梯度衰减方式上,使用了类似动量的衰减方法,实质上就是带有动量项的RMSProp。Adam将动量应用于缩放后的梯度,同时结合了AdaGrad善于处理稀疏梯度和RMSProp善于处理非平稳目标的优点,在自适应学习率方面表现较好,适用于大多非凸优化,也适用于海量数据和高维空间。因此Adam算法是应用最广泛的、效果最好的算法,它高效、稳定,适用于绝大多数的应用场景。</p>
                </div>
                <h4 class="anchor-tag" id="95" name="95"><b>2.2 正则化</b></h4>
                <div class="p1">
                    <p id="96">深度学习中数学模型的设计要求不仅在训练集上表现好,而且能在新输入上泛化良好,许多策略被显示地设计来减少测试误差,这些策略被统称为正则化。在机器学习中,过拟合现象被称为过度训练,本质是过于复杂的模型在学习中不知不觉中提取了一些残余变化(即随机干扰噪声),产生与特定数据集过于紧密或完全对应的分析,从而忽视了通用的趋势和整体的规律,无法拟合其他数据或可靠地预测未来的观测结果。而正则化是降低泛化误差,减小过拟合的一个有效手段,包括L1、L2正则化以及最常用的Dropout。</p>
                </div>
                <div class="p1">
                    <p id="97">Dropout的优点是计算方便,训练过程中会产生<i>n</i>个随机二进制数与某些神经元相乘,从而依概率去掉对应层的某些神经元,使得每次迭代中训练的都是一个小的神经网络,如图3所示<citation id="157" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910032_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 Dropout示意图" src="Detail/GetImg?filename=images/JYRJ201910032_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 Dropout示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910032_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="99">文献<citation id="158" type="reference">[<a class="sup">27</a>]</citation>中显示,Dropout比其他标准的计算开销小的正则化方法(如L1,L2正则化)更有效,经过交叉验证,keep prob率等于0.5的时候效果最好,因为此时dropout随机生成的网络结构最多。</p>
                </div>
                <div class="p1">
                    <p id="100">Dropout的另一个显著优点是降低了模型的计算复杂度,它一般不限制适用的模型或训练过程,基本在所有使用分布式表示且用SGD法训练的模型上都表现良好,包括RBM、CNN、RNN等网络模型。</p>
                </div>
                <div class="p1">
                    <p id="101">另一方面Dropout减少了模型的有效容量,为了弥补这种影响,必须扩大模型规模,所以当只有极少的训练样本时,Dropout不会很有效。文献<citation id="159" type="reference">[<a class="sup">27</a>]</citation>中还提到在少于5 000的测试样本的Alternative Splicing Data上,Bayes神经网络比Dropout表现得更好。所以至少要在上万数据集上使用Dropout会比L1和L2的正则化方法更有效,最佳验证集的泛化误差会比较小。</p>
                </div>
                <h3 id="102" name="102" class="anchor-tag"><b>3 实 验</b></h3>
                <div class="p1">
                    <p id="103">深度前馈网络是在Python3.6开发环境Spyder中通过编程并调用开源的TensorFlow库建立的。计算机处理器:Intel(R) Core(TM) i5-7400 CPU @ 3.00 GHz,内存(RAM)为8 GB,操作系统64位Windows。</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104"><b>3.1 实验数据及预处理</b></h4>
                <div class="p1">
                    <p id="105">本实验所运用的数据来自美国Case Western Reserve大学正常和故障滚动承故障测试数据。使用电火花加工(EDM)对电机轴承的滚球、内滚道和外滚道引入不同直径的点蚀故障。故障规格如表2所示。</p>
                </div>
                <div class="area_img" id="106">
                    <p class="img_tit"><b>表2 轴承故障规格</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="106" border="1"><tr><td><br />故障位置</td><td>故障直径/inch</td><td>相关说明</td></tr><tr><td>Ball</td><td>0.007</td><td>电机转速1 750 r/min,载荷2 hp,采样率12 kHz,驱动端轴承型号6205-2RS JEM SFK</td></tr><tr><td><br /></td><td>0.014</td><td></td></tr><tr><td><br /></td><td>0.021</td><td></td></tr><tr><td><br />Inner Raceway</td><td>0.007</td><td></td></tr><tr><td><br /></td><td>0.014</td><td></td></tr><tr><td><br /></td><td>0.021</td><td></td></tr><tr><td><br />Outer Raceway</td><td>0.007</td><td></td></tr><tr><td><br /></td><td>0.014</td><td></td></tr><tr><td><br /></td><td>0.021</td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="107">将Normal信号和表2中的9种振动故障信号导入Python中,得到10种对应的振动原始信号图如图4所示。</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910032_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 10种不同工况下振动原始信号图" src="Detail/GetImg?filename=images/JYRJ201910032_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 10种不同工况下振动原始信号图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910032_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="109">电机转速为1 750 r/min,采样频率为12 kHz,则一个周期一转采集到约412(60×12 000÷1 750)个振动点,因此网络的输入样本为412维的原始数据。为了获得足够的训练样本和测试样本,并保证不重复抽样,采用连续抽样的截取方法来获取样本,并设定一定的抽样步长。本实验设置抽样步长为412,标签0～9分别代表正常信号和9种故障信号,从每种信号中随机抽样获得5 000个样本,加上标签最终得到50 000×(412+1)的矩阵作为网络的输入,将此矩阵保存至.csv文件,以便于导入到深度前馈网络中进行故障诊断,在模型训练时再按7∶3比例随机分为35 000个样本训练集和15 000个样本测试集。</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110"><b>3.2 参数设置</b></h4>
                <div class="p1">
                    <p id="111">表3为在故障诊断中,深度前馈神经网络模型在TensorFlow中的关键参数设置。</p>
                </div>
                <div class="area_img" id="112">
                    <p class="img_tit"><b>表3 TensorFlow中核心参数的设置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="112" border="1"><tr><td><br />功能</td><td>TensorFlow程序</td></tr><tr><td><br />激活函数</td><td>tf.nn.relu(tf.matmul(x,w)+b)</td></tr><tr><td><br />权值初始化</td><td>tf.Variable(tf.truncated_normal())</td></tr><tr><td><br />偏置值初始化</td><td>tf.Variable(tf.zeros([])+0.1)</td></tr><tr><td><br />Dropout</td><td>tf.nn.dropout()</td></tr><tr><td><br />输出层激活函数</td><td>tf.nn.softmax()</td></tr><tr><td><br />交叉熵损失函数</td><td>tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels,logits))</td></tr><tr><td><br />Adam优化</td><td>tf.train.AdamOptimizer().minimize(loss)</td></tr><tr><td><br />模型预测求准<br />确率</td><td>tf.reduce_mean(tf.cast(tf.equal(tf.argmax(),tf.argmax()),tf.float32))</td></tr><tr><td><br />运行模型</td><td>tf.Session().run(feed_dict={x, y})</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="113" name="113"><b>3.3 结果分析</b></h4>
                <div class="p1">
                    <p id="114">图5为不同网络结构在训练1 000次后对诊断准确率的影响,横轴表示学习参数的数量。</p>
                </div>
                <div class="area_img" id="115">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910032_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 网络结构对故障诊断准确率的影响" src="Detail/GetImg?filename=images/JYRJ201910032_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 网络结构对故障诊断准确率的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910032_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="116">从图5中可以看出,随着参数不断增加,准确率渐渐提高,当增加到100万以上时,由于模型复杂参数过多出现过拟合现象,准确率有所下降,而四层和五层网络的泛化能力较强,在30～100万的参数区间内有较高准确率。三层、四层、五层、六层网络结构准确率普遍都在98%以上,且四层、五层整体效果要优于三层、六层,说明对应本实验轴承故障数据集,适当调整网络的宽度或深度都可以达到较好的泛化能力。</p>
                </div>
                <div class="p1">
                    <p id="117">进一步比较分析,表4为不同网络结构下的深度前馈网络模型故障诊断评估表,选取四层和五层网络为比较对象,选取30～100万的学习参数区间,测试集样本数是15 000,训练次数为1 000次。评估指标中,上升时间指准确率从10%上升到90%所需时间。</p>
                </div>
                <div class="area_img" id="118">
                    <p class="img_tit"><b>表4 不同网络结构下的网络模型故障诊断评估</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="118" border="1"><tr><td>网络结构</td><td>参数数量</td><td>准确率</td><td>训练<br />时长</td><td>上升<br />时间</td><td>误诊<br />样本</td></tr><tr><td><br />412-400-<br />400-10</td><td>328 800</td><td>0.989 3</td><td>1 058 s</td><td>74s</td><td>160</td></tr><tr><td><br />412-500-<br />400-10</td><td>410 000</td><td>0.989 1</td><td>1 201 s</td><td>85 s</td><td>163</td></tr><tr><td><br />412-600-<br />500-10</td><td>552 200</td><td>0.989 6</td><td>1 495 s</td><td>78 s</td><td>156</td></tr><tr><td><br />412-700-<br />600-10</td><td>714 400</td><td>0.988 8</td><td>1 780 s</td><td>102 s</td><td>165</td></tr><tr><td><br />412-800-<br />750-10</td><td>937 100</td><td>0.989 1</td><td>2 192 s</td><td>113 s</td><td>163</td></tr><tr><td><br />412-300-300-<br />300-10</td><td>306 600</td><td>0.989 3</td><td>1 056 s</td><td>88 s</td><td>159</td></tr><tr><td><br />412-400-400-<br />400-10</td><td>488 800</td><td>0.989 2</td><td>1 540 s</td><td>155 s</td><td>160</td></tr><tr><td><br />412-500-500-<br />500-10</td><td>711 000</td><td>0.989 0</td><td>1 924 s</td><td>118 s</td><td>164</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="119">从表4中可以看出,所有网络准确率达到了98.9%左右,结构为412-600-500-10的四层网络模型效果最优,准确率达到最高98.96%,误诊数也是最低的,且优化速度较快,只用78 s模型诊断准确率就从10%上升到90%。尽管其训练时间较长,但是训练网络是线下进行,为了更好地诊断轴承故障,花时间训练一个最优网络是值得的。</p>
                </div>
                <div class="p1">
                    <p id="120">综上所述,选取412-600-500-10四层网络结构为最优的深度前馈网络模型,对应的详细模型如图6所示,图7、图8为其诊断准确率、损失与训练次数的学习曲线图,图9为测试集对应的混淆矩阵,表5为其对应的故障诊断报告。</p>
                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910032_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 TensorFlow中Deep feedforward network的
故障诊断模型" src="Detail/GetImg?filename=images/JYRJ201910032_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 TensorFlow中Deep feedforward network的
故障诊断模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910032_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910032_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 准确率和训练次数的关系曲线图" src="Detail/GetImg?filename=images/JYRJ201910032_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 准确率和训练次数的关系曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910032_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910032_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 损失和训练次数的关系曲线图" src="Detail/GetImg?filename=images/JYRJ201910032_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 损失和训练次数的关系曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910032_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="124">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910032_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 混淆矩阵" src="Detail/GetImg?filename=images/JYRJ201910032_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 混淆矩阵  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910032_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="125">
                    <p class="img_tit"><b>表5 故障诊断报告</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="125" border="1"><tr><td>故障类别</td><td>Precision</td><td>Recall</td><td>F1-score</td><td>Support</td></tr><tr><td><br />Normal</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1 498</td></tr><tr><td><br />Ball fault-007</td><td>0.99</td><td>1.00</td><td>1.00</td><td>1 519</td></tr><tr><td><br />Ball fault-014</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1 508</td></tr><tr><td><br />Ball fault-021</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1 512</td></tr><tr><td><br />Inner race-007</td><td>0.92</td><td>1.00</td><td>0.96</td><td>1 521</td></tr><tr><td><br />Inner race-014</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1 464</td></tr><tr><td><br />Inner race-021</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1 510</td></tr><tr><td><br />Outer race-007</td><td>1.00</td><td>0.90</td><td>0.95</td><td>1 485</td></tr><tr><td><br />Outer race-014</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1 456</td></tr><tr><td><br />Outer race-021</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1 527</td></tr><tr><td><br />Avg/total</td><td>0.99</td><td>0.99</td><td>0.99</td><td>15 000</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="126">从图7和图8中可以看出,对于轴承故障数据诊断准确率为98.96%,损失仅为1.472;从图9和表5中可以看出针对每个故障类别的预测准确性,除了Outer race-007类故障诊断出现了0.1的误诊率,即1 485个样本中有大约150个误诊成Inner race-007故障,其他情况基本诊断正确,而且,每种故障的查准率(Precision)、召回率(Recall)、F1分数(F1-score)平均值都为0.99,结果充分说明最优深度前馈网络模型能够较好地实现轴承故障诊断。</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127"><b>3.4 与其他方法的比较分析</b></h4>
                <div class="p1">
                    <p id="128">模式识别是轴承故障诊断中的重要一步,实质是分类算法,传统常用于分类的机器学习算法有k-近邻算法、支持向量机(SVM)、逻辑回归算法(Logistic Regression)、决策树(Decision Tree)、随机森林算法(Random Forest)、朴素贝叶斯(Naive Bayers)等。</p>
                </div>
                <div class="p1">
                    <p id="129">为了和机器学习算法作比较,利用和3.1节同样的50 000组数据作为输入数据,15 000组为测试集。不同方法的诊断结果如表6所示。</p>
                </div>
                <div class="area_img" id="130">
                    <p class="img_tit"><b>表6 不同方法的诊断结果比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="130" border="1"><tr><td>识别<br />模型</td><td>相关核心参数<br />设置</td><td>训练分<br />/%</td><td>测试分<br />/%</td><td>误诊数</td><td>时间/s</td></tr><tr><td><br />普通<br />k-近邻</td><td>K=2</td><td>97.06</td><td>88.71</td><td>1 694</td><td>1 416</td></tr><tr><td><br />带权<br />k-近邻</td><td>K=2,weight</td><td>100</td><td>91.26</td><td>1 311</td><td>1 417</td></tr><tr><td><br />逻辑回归</td><td>penalty=L2<br />solver= lbfgs</td><td>45.26</td><td>39.38</td><td>9 084</td><td>21</td></tr><tr><td><br />决策树</td><td>criterion=entropy<br />splitter=best<br />max_depth=50<br />min_impurity<br />_decrease=1e-6</td><td>99.89</td><td>53.86</td><td>6921</td><td>78</td></tr><tr><td><br />随机森林</td><td>n_estimators=100<br />max_features=20</td><td>100</td><td>93.21</td><td>1018</td><td>103</td></tr><tr><td><br />支持<br />向量机</td><td>C=1<br /><i>γ</i> =0.1</td><td>99.52</td><td>93.55</td><td>967</td><td>1 545</td></tr><tr><td><br />朴素<br />贝叶斯</td><td>GaussianNB</td><td>61.96</td><td>60.70</td><td>5 894</td><td>4.32</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="131">由表6可得,逻辑回归和朴素贝叶斯方法效果较差,说明模型无法很好地拟合训练集和预测测试集;决策树模型虽然对样本拟合情况极佳,但是模型测试分只有53.86%,对新数据诊断误差很大,说明改模型容易造成过拟合;相比而言k-近邻、随机森林和支持向量机的训练集分数几乎达到100%,对训练样本的拟合情况较好,对测试样本的预测诊断率也在90%以上,训练速度也比较快,说明模型的准确性和泛化能力良好。但还是远低于本文实验的结果98.96%,可见机器学习和深度前馈网络相比,虽然训练速度上有优势,但是算法的鲁棒性模型诊断结果相对较差。经过大量数据测试经验发现,上述传统的机器学习算法一般在数据集较小的情况下,往往分类效果比会比深度前馈神经网络要好,在上万数据的情况下效果普遍低于深度前馈网络。</p>
                </div>
                <h3 id="132" name="132" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="133">本文提出基于现代深度前馈神经网络的轴承故障诊断模型,并通过梯度优化算法、正则化方式以及不同网络结构的研究,旨在向最优模型的建立不断靠近。实验在Python语言开发环境中编写程序并调用开源的TensorFlow库函数完成。利用深度前馈网络强大的非线性学习能力,无需人工处理数据提取复杂的特征即可实现高精度的滚动轴承故障诊断,实验结果最终达到了98.96%的诊断准确率。通过和传统机器学习方法比较说明该方法存在的优势,从而表明了深度前馈神经网络模型有更强的分类决策能力。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201901003&amp;v=MjQxMTgvQUx6VFpaTEc0SDlqTXJvOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURoVnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 吕维宗,王海瑞,舒捷.量子粒子群算法优化相关向量机的轴承故障诊断[J].计算机应用与软件,2019,36(1):6-11,16.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Intelligent fault diagnosis and remaining useful life prediction of rotating machinery">

                                <b>[2]</b> Lei Y.Intelligent fault diagnosis and remaining useful life prediction of rotating machinery[M].Xi’an Jiaotong university press,2017:146.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visualizing dataflow graphs of deep learning models in TensorFlow">

                                <b>[3]</b> Wongsuphasawat K,Smilkov D,Wexler J,et al.Visualizing dataflow graphs of deep learning models in TensorFlow[J].IEEE Transactions on Visualization and Computer Graphics,2018,24(1):1-12.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201804017&amp;v=MTc0NjBNalhCZDdHNEg5bk1xNDlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEaFZyL0E=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 靳涛,张永爱.TensorFlow平台下基于深度学习的数字识别[J].信息技术与网络安全,2018,37(4):74-78.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJCJ201802017&amp;v=MjYyMTVoVnIvQU5pZklaTEc0SDluTXJZOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaUQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 侯艳路,丁世飞,孙统风.混合深度学习模型C-RF及其在手写数字识别中的应用[J].数据采集与处理,2018,33(2):343-350.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201806050&amp;v=MTExMjg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURoVnIvQUx6VFpaTEc0SDluTXFZOUFaSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 韩山杰,谈世哲.基于TensorFlow进行股票预测的深度学习模型的设计与实现[J].计算机应用与软件,2018,35(6):267-271,291.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDCS201706023&amp;v=MDgzNzJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZpRGhWci9BUHluSWZiRzRIOWJNcVk5SFo0UUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 王丽华,谢阳阳,周子贤,等.基于卷积神经网络的异步电机故障诊断[J].振动测试与诊断,2017,37(6):1208-1215,1283.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAJT201710021&amp;v=MjM5MDlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZpRGhWci9BUFN6QmVyRzRIOWJOcjQ5SFpZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 王丽华,谢阳阳,张永宏,等.采用深度学习的异步电机故障诊断方法[J].西安交通大学学报,2017,51(10):128-134.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXXB201609009&amp;v=MjE3ODF6WFRiTEc0SDlmTXBvOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURoVnIvQUw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 孙文珺,邵思羽,严如强.基于稀疏自动编码深度神经网络的感应电动机故障诊断[J].机械工程学报,2016,52(9):65-71.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A new convolutional neural network-based data-driven fault diagnosis method">

                                <b>[10]</b> Wen L,Li X,Gao L,et al.A new convolutional neural network based data-driven fault diagnosis method[J].IEEE Transactions on Industrial Electronics,2018,65(7):5990-5998.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2018S2030&amp;v=MDcxNDc0SDltdnJZOUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGaURoVnIvQUx6N0JiN0c=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 仝卫国,李敏霞,张一可.深度学习优化算法研究[J].计算机科学,2018,45(S2):155-159.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rectified linear units improve restricted boltzmann machines">

                                <b>[12]</b> Nair V,Hinton G E.Rectified linear units improve restricted boltzmann machines[C]//Proceedings of the 27th International Conference on International Conference on Machine Learning.Omnipress,2010:807-814.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Understanding the difficulty of training deep feedforward neural networks">

                                <b>[13]</b> Glorot X,Bengio Y.Understanding the difficulty of training deep feedforward neural networks[J].Journal of Machine Learning Research,2010,9:249-256.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=What is the Best Multi-Stage Architecture for Object Recognition?">

                                <b>[14]</b> Jarrett K,Kavukcuoglu K,Ranzato M,et al.What is the best multi-stage architecture for object recognition?[C]//2009 IEEE 12th International Conference on Computer Vision,2009:2146-2153.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving deep neural netw orks for LVCSR using rectified linear units and dropout">

                                <b>[15]</b> Dahl G E,Sainath T N,Hinton G E.Improving deep neural networks for LVCSR using rectified linear units and dropout[C]//2013 IEEE International Conference on Acoustics,Speech and Signal Processing,2013:8609-8613.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 Glorot X,Bordes A,Bengio Y.Deep sparse rectifier neural networks[C]//Proceedings of the 14th International Conference on Artificial Intelligence and Statistics(AISTATS).2010.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 郑泽宇,梁博文,顾思宇.Tensorflow实战google深度学习框架[M].电子工业出版社,2018:75.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep learning">

                                <b>[18]</b> Ian G,Yoshua B,Aaron C.Deep learning[M].Posts &amp; Telecom Press,2017.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787121317200000&amp;v=MjI1NzJLcmlmWmVadkZ5bm1VcmZNSlY0Y1hGcXpHYks2SDlMTnFJMUZaT3NQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZu&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> 何宇健.Python与机器学习实战:决策树、集成学习、支持向量机与神经网络算法详解及编程实现[M].电子工业出版社,2017:203-204.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multilayer feedforward networks are universal approximators">

                                <b>[20]</b> Hornik K,Stinchcombe M,White H.Multilayer feedforward networks are universal approximators[J].Neural Networks,1989,2(5):359-366.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the importance of initialization and momentum in deep learning">

                                <b>[21]</b> Sutskever I,Martens J,Dahl G,et al.On the importance of initialization and momentum in deep learning[C]//Proceedings of the 30th International Conference on International Conference on Machine Learning—Volume 28.2013.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" >
                                    <b>[22]</b>
                                 Duchi J,Hazan E,Singer Y.Adaptive subgradient methods for online learning and stochastic optimization[J].Journal of Machine Learning Research,2011,12(7):257-269.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Lecture 6.5-rmsprop:Divide the gradient by a running average of its recent magnitude">

                                <b>[23]</b> Tieleman T,Hinton G.RMSProp:Divide the gradient by a running average of its recent magnitude[R].COURSERA:Neural Networks for Machine Learning.2012.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adam:A method for stochastic optimization[EB]">

                                <b>[24]</b> Kingma D P,Ba J.Adam:A method for stochastic optimization[EB].arXiv:1412.6980.2014.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On optimization methods for deep learning">

                                <b>[25]</b> Le Q V,Ngiam J,Coates A,et al.On optimization methods for deep learning[C]//Proceedings of the 28th International Conference on Machine Learning,ICML 2011,Bellevue,Washington,USA,June 28—July 2,2011.DBLP,2011.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201808008&amp;v=MjUwMzdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZpRGhWci9BUFRYY2RyRzRIOW5NcDQ5RmI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b> 周安众,罗可.一种卷积神经网络的稀疏性Dropout正则化方法[J].小型微型计算机系统,2018,39(8):1674-1679.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dropout:A simple way to prevent neural networks from overfitting">

                                <b>[27]</b> Srivastava N,Hinton G,Krizhevsky A,et al.Dropout:A simple way to prevent neural networks from overfitting[J].Journal of Machine Learning Research,2014,15(1):1929-1958.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201910032" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201910032&amp;v=MjA4NDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RmlEaFZyL0FMelRaWkxHNEg5ak5yNDlHWm9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
