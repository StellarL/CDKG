<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135626507502500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201907039%26RESULT%3d1%26SIGN%3di6PI78lZRGr9EADMCplWOnD79wo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907039&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907039&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907039&amp;v=MjY1MDBGckNVUjdxZlp1WnRGeWpoVXJ2SUx6VFpaTEc0SDlqTXFJOUdiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#51" data-title="&lt;b&gt;1 基于混合算法的人体异常行为检测和识别方法&lt;/b&gt; "><b>1 基于混合算法的人体异常行为检测和识别方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="&lt;b&gt;1.1 CAMS跟踪算法&lt;/b&gt;"><b>1.1 CAMS跟踪算法</b></a></li>
                                                <li><a href="#69" data-title="&lt;b&gt;1.2 校正背景权重直方图 (CBWH) 技术&lt;/b&gt;"><b>1.2 校正背景权重直方图 (CBWH) 技术</b></a></li>
                                                <li><a href="#87" data-title="&lt;b&gt;1.3 无味粒子滤波 (UPF) 技术&lt;/b&gt;"><b>1.3 无味粒子滤波 (UPF) 技术</b></a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;1.4 图像稀疏表达&lt;/b&gt;"><b>1.4 图像稀疏表达</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#125" data-title="&lt;b&gt;2 实验与分析&lt;/b&gt; "><b>2 实验与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#126" data-title="&lt;b&gt;2.1 实验基础&lt;/b&gt;"><b>2.1 实验基础</b></a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;2.2 无遮挡场景下的跟踪性能对比&lt;/b&gt;"><b>2.2 无遮挡场景下的跟踪性能对比</b></a></li>
                                                <li><a href="#137" data-title="&lt;b&gt;2.3 存在障碍物遮挡时的跟踪性能对比&lt;/b&gt;"><b>2.3 存在障碍物遮挡时的跟踪性能对比</b></a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;2.4 在公开数据集UMN上的实验验证&lt;/b&gt;"><b>2.4 在公开数据集UMN上的实验验证</b></a></li>
                                                <li><a href="#149" data-title="&lt;b&gt;2.5 存在背景影响的跟踪性能对比&lt;/b&gt;"><b>2.5 存在背景影响的跟踪性能对比</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#160" data-title="&lt;b&gt;3 结 语&lt;/b&gt; "><b>3 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="图1 多技术人体异常行为检测与识别系统框架">图1 多技术人体异常行为检测与识别系统框架</a></li>
                                                <li><a href="#115" data-title="图2 图像稀疏表达">图2 图像稀疏表达</a></li>
                                                <li><a href="#131" data-title="图3 分别在50, 150, 250和350帧进行人体运动跟踪">图3 分别在50, 150, 250和350帧进行人体运动跟踪</a></li>
                                                <li><a href="#134" data-title="图4 无障碍路径估计结果">图4 无障碍路径估计结果</a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;表1 所提方法和无障碍CAMS的跟踪结果对比&lt;/b&gt;"><b>表1 所提方法和无障碍CAMS的跟踪结果对比</b></a></li>
                                                <li><a href="#140" data-title="图5 目标对象被遮挡时路径估计结果">图5 目标对象被遮挡时路径估计结果</a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;表2 所提出方法与CAMS算法在有遮挡情况下的跟踪结果&lt;/b&gt;"><b>表2 所提出方法与CAMS算法在有遮挡情况下的跟踪结果</b></a></li>
                                                <li><a href="#146" data-title="图6 公开数据集UMN中正常帧 (a-c) 和异常帧 (d-f) ">图6 公开数据集UMN中正常帧 (a-c) 和异常帧 (d-f) </a></li>
                                                <li><a href="#147" data-title="图7 不同方法在公开数据集UMN中的异常探测ROC曲线">图7 不同方法在公开数据集UMN中的异常探测ROC曲线</a></li>
                                                <li><a href="#151" data-title="图8 传统CAMS算法和所提出算法在50帧、100帧和150帧处当背景中存在其他类似物体时对异常行为的检测情况">图8 传统CAMS算法和所提出算法在50帧、100帧和150帧处当背景中存在其他类似物体时对异常行为......</a></li>
                                                <li><a href="#154" data-title="图9 当目标对象背景中有相似颜色的其他物体时的路径估计结果">图9 当目标对象背景中有相似颜色的其他物体时的路径估计结果</a></li>
                                                <li><a href="#155" data-title="&lt;b&gt;表3 当目标对象具有相似颜色属性的背景对象时, 跟踪所提出方法和CAMS的结果&lt;/b&gt;"><b>表3 当目标对象具有相似颜色属性的背景对象时, 跟踪所提出方法和CAMS的结果</b></a></li>
                                                <li><a href="#158" data-title="图10 同时估计目标物体路径时处理粒子所花费的时间对比">图10 同时估计目标物体路径时处理粒子所花费的时间对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 邵振峰, 蔡家骏, 王中元, 等.面向智能监控摄像头的监控视频大数据分析处理[J].电子与信息学报, 2017, 39 (5) :1116-1122." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201705015&amp;v=MTkxNjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVcnZJSVRmU2RyRzRIOWJNcW85RVlZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         邵振峰, 蔡家骏, 王中元, 等.面向智能监控摄像头的监控视频大数据分析处理[J].电子与信息学报, 2017, 39 (5) :1116-1122.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 邓磊, 陈宝华, 赖伟良, 等.三维监控系统中基于三维重构的交互式标定[J].电子学报, 2017, 45 (3) :527-533." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201703003&amp;v=MTU3MjRlN0c0SDliTXJJOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVXJ2SUlUZlQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         邓磊, 陈宝华, 赖伟良, 等.三维监控系统中基于三维重构的交互式标定[J].电子学报, 2017, 45 (3) :527-533.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 潘志安, 朱三元.移动摄像视频的多运动目标实时跟踪算法[J].控制工程, 2017, 24 (4) :836-843." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZDF201704023&amp;v=MTE0NzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVydklMemZQYUxHNEg5Yk1xNDlIWjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         潘志安, 朱三元.移动摄像视频的多运动目标实时跟踪算法[J].控制工程, 2017, 24 (4) :836-843.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 沈铮, 吴薇.基于图像处理的公交车内人群异常情况检测[J].计算机工程与设计, 2018, 39 (1) :165-171." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201801029&amp;v=MjkzNThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVydklOaWZZWkxHNEg5bk1ybzlIYlk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         沈铮, 吴薇.基于图像处理的公交车内人群异常情况检测[J].计算机工程与设计, 2018, 39 (1) :165-171.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 罗建华.基于改进提升模型的视频目标跟踪算法[J].计算机应用与软件, 2018, 35 (1) :261-263." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201801046&amp;v=MjY5NjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVXJ2SUx6VFpaTEc0SDluTXJvOUJZb1FLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         罗建华.基于改进提升模型的视频目标跟踪算法[J].计算机应用与软件, 2018, 35 (1) :261-263.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 侯晴宇, 卞春江, 逯力红, 等.红外图像中快速小目标的均值移位跟踪[J].哈尔滨工业大学学报, 2013, 45 (4) :79-83." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBX201304014&amp;v=MjQ0NjRSN3FmWnVadEZ5amhVcnZJTFNqSmRyRzRIOUxNcTQ5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         侯晴宇, 卞春江, 逯力红, 等.红外图像中快速小目标的均值移位跟踪[J].哈尔滨工业大学学报, 2013, 45 (4) :79-83.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Sabokrou M, Fayyaz M, Fathy M, et al.Deep-Cascade:Cascading 3D Deep Neural Networks for Fast Anomaly Detection and Localization in Crowded Scenes[J].IEEE Transactions on Image Processing, 2017, 26 (4) :1992-2004." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep-cascade cascading 3d deep neural networks for fast anomaly detection and localization in crowded scenes">
                                        <b>[7]</b>
                                         Sabokrou M, Fayyaz M, Fathy M, et al.Deep-Cascade:Cascading 3D Deep Neural Networks for Fast Anomaly Detection and Localization in Crowded Scenes[J].IEEE Transactions on Image Processing, 2017, 26 (4) :1992-2004.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Chaker R, Aghbari Z A, Junejo I N.Social Network Model for Crowd Anomaly Detection and Localization[J].Pattern Recognition, 2017, 61:266-281." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Social network model for crowd anomaly detection and localization">
                                        <b>[8]</b>
                                         Chaker R, Aghbari Z A, Junejo I N.Social Network Model for Crowd Anomaly Detection and Localization[J].Pattern Recognition, 2017, 61:266-281.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Xiu C, Ba F.Target tracking based on the improved Camshift method[C]// 2016 Chinese Control and Decision Conference (CCDC) .IEEE, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Target tracking based on the improved Camshift method">
                                        <b>[9]</b>
                                         Xiu C, Ba F.Target tracking based on the improved Camshift method[C]// 2016 Chinese Control and Decision Conference (CCDC) .IEEE, 2016.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 陈文会, 张晶, 樊养余, 等.一种基于背景减法和帧差的运动目标检测算法[J].电子设计工程, 2013, 21 (3) :24-26." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201303008&amp;v=MDU3MDVMRzRIOUxNckk5RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVcnZJSWpyUGQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         陈文会, 张晶, 樊养余, 等.一种基于背景减法和帧差的运动目标检测算法[J].电子设计工程, 2013, 21 (3) :24-26.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Hsia C H, Liou Y J, Chiang J S.Directional Prediction CamShift algorithm based on Adaptive Search Pattern for moving object tracking[J].Journal of Real-Time Image Processing, 2016, 12 (1) :183-195." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Directional prediction Cam Shift algorithm based on adaptive search pattern for moving object tracking">
                                        <b>[11]</b>
                                         Hsia C H, Liou Y J, Chiang J S.Directional Prediction CamShift algorithm based on Adaptive Search Pattern for moving object tracking[J].Journal of Real-Time Image Processing, 2016, 12 (1) :183-195.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Feng X, Jiang J, Lin P, et al.Radar target detection method based on particle filter theory under correlated non-Gaussian clutter backgrounds[C]// IET International Radar Conference 2015.IET, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Radar target detection method based on particle filter theory under correlated non-Gaussian clutter backgrounds">
                                        <b>[12]</b>
                                         Feng X, Jiang J, Lin P, et al.Radar target detection method based on particle filter theory under correlated non-Gaussian clutter backgrounds[C]// IET International Radar Conference 2015.IET, 2016.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" 张赛钰, 朱小玲, 汪衍广, 等.基于帧差法与Mean-shift算法相结合的运动熔滴识别与跟踪方法[J].上海交通大学学报, 2016, 50 (10) :1605-1608." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SHJT201610020&amp;v=MjgxNDVyRzRIOWZOcjQ5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVcnZJTmlYQmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         张赛钰, 朱小玲, 汪衍广, 等.基于帧差法与Mean-shift算法相结合的运动熔滴识别与跟踪方法[J].上海交通大学学报, 2016, 50 (10) :1605-1608.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" 王宇霞, 赵清杰, 蔡艺明, 等.基于自重构粒子滤波算法的目标跟踪[J].计算机学报, 2016, 39 (7) :1294-1306." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201607002&amp;v=MjMyODF6N0Jkckc0SDlmTXFJOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVXJ2SUw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         王宇霞, 赵清杰, 蔡艺明, 等.基于自重构粒子滤波算法的目标跟踪[J].计算机学报, 2016, 39 (7) :1294-1306.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 杨超, 蔡晓东, 王丽娟, 等.一种改进的CAMShift跟踪算法及人脸检测框架[J].计算机工程与科学, 2016, 38 (9) :1863-1869." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201609019&amp;v=MTY4MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVydklMejdCWmJHNEg5Zk1wbzlFYllRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         杨超, 蔡晓东, 王丽娟, 等.一种改进的CAMShift跟踪算法及人脸检测框架[J].计算机工程与科学, 2016, 38 (9) :1863-1869.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Ning J, Zhang L, Zhang D, et al.Robust mean-shift tracking with corrected background-weighted histogram[J].Iet Computer Vision, 2012, 6 (1) :62-69." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust mean-shift tracking with corrected background-weighted histogram">
                                        <b>[16]</b>
                                         Ning J, Zhang L, Zhang D, et al.Robust mean-shift tracking with corrected background-weighted histogram[J].Iet Computer Vision, 2012, 6 (1) :62-69.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" 基于三维直方图修正和灰度熵分解的图像分割[J].计算机工程, 2014, 40 (5) :234-237." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201405049&amp;v=MDk5NjF6N0JiYkc0SDlYTXFvOUJiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVXJ2SUw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         基于三维直方图修正和灰度熵分解的图像分割[J].计算机工程, 2014, 40 (5) :234-237.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" 崔汪莉, 卫军胡, 纪鹏, 等.基于加权局部梯度直方图的头部三维姿态估计[J].西安交通大学学报, 2015, 49 (11) :71-76." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAJT201511012&amp;v=MDA0OTFOcm85RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVcnZJUFN6QmVyRzRIOVQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         崔汪莉, 卫军胡, 纪鹏, 等.基于加权局部梯度直方图的头部三维姿态估计[J].西安交通大学学报, 2015, 49 (11) :71-76.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" Yang Y, Jia Y X, Rong C Z, et al.Object Tracking Based on Corrected Background-Weighted Histogram Mean Shift and Kalman Filter[J].Advanced Materials Research, 2013, 765-767:720-725." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJTT&amp;filename=SJTT13121200151870&amp;v=MDI5OTVmZXJLN0g5UE5yWTlGWmU0T0JIczVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRm9WYmhJPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         Yang Y, Jia Y X, Rong C Z, et al.Object Tracking Based on Corrected Background-Weighted Histogram Mean Shift and Kalman Filter[J].Advanced Materials Research, 2013, 765-767:720-725.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" Zhao F, Ge S S, Jie Z, et al.Celestial navigation in deep space exploration using spherical simplex unscented particle filter[J].Iet Signal Processing, 2018, 12 (4) :463-470." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Celestial navigation in deep space exploration using spherical simplex unscented particle filter">
                                        <b>[20]</b>
                                         Zhao F, Ge S S, Jie Z, et al.Celestial navigation in deep space exploration using spherical simplex unscented particle filter[J].Iet Signal Processing, 2018, 12 (4) :463-470.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(07),224-230+241 DOI:10.3969/j.issn.1000-386x.2019.07.038            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>室内视频监控下基于混合算法的人体异常行为检测和识别方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%91%E6%B5%A9&amp;code=22288716&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郑浩</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%BB%BA%E8%8A%B3&amp;code=24003064&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘建芳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BB%96%E6%A2%A6%E6%80%A1&amp;code=40521410&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">廖梦怡</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%B3%E9%A1%B6%E5%B1%B1%E5%AD%A6%E9%99%A2%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0252100&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">平顶山学院计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%AD%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E5%9B%BD%E5%AE%B6%E6%95%B0%E5%AD%97%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83&amp;code=0200298&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华中师范大学国家数字化学习工程技术研究中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对目前室内人体异常行为检测和识别中照明变化、遮挡、相机移动和背景等因素对检测准确性的影响, 提出一种多技术混合跟踪方法。该方法基于连续自适应均值漂移 (CAMS) , 引入校正背景权重直方图 (CBWH) 和无味粒子滤波 (UPF) 技术处理遮挡和相似颜色对象的干扰。采用基于稀疏表达的检测方式从多种场景对目标对象的异常行为进行检测和识别, 并利用均方误差统计量评估所提方法的性能。同时在公开数据集UMN上进行仿真验证。实验结果表明, 该方法在不同场景中有障碍物遮挡或是具有相似颜色的其他对象情况下都能准确检测和识别目标对象。此外, 该技术还可能进一步改善复杂场景下多摄像机中目标对象的跟踪性能。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A3%80%E6%B5%8B%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">检测识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%9E%E7%BB%AD%E8%87%AA%E9%80%82%E5%BA%94%E5%9D%87%E5%80%BC%E6%BC%82%E7%A7%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">连续自适应均值漂移;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A0%A1%E6%AD%A3%E8%83%8C%E6%99%AF%E6%9D%83%E9%87%8D%E7%9B%B4%E6%96%B9%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">校正背景权重直方图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%A0%E5%91%B3%E7%B2%92%E5%AD%90%E6%BB%A4%E6%B3%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">无味粒子滤波;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A8%80%E7%96%8F%E8%A1%A8%E8%BE%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">稀疏表达;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AE%A4%E5%86%85%E8%A7%86%E9%A2%91%E7%9B%91%E6%8E%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">室内视频监控;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    郑浩, 讲师, 主研领域:图形图像处理, 软件工程。;
                                </span>
                                <span>
                                    刘建芳, 讲师。;
                                </span>
                                <span>
                                    廖梦怡, 讲师。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>河南省科技厅科技发展计划科技攻关项目 (182102310040);</span>
                                <span>平顶山学院青年科研基金项目 (PXYQNJJ2017002);</span>
                    </p>
            </div>
                    <h1><b>HUMAN ABNORMAL BEHAVIOR DETECTION AND RECOGNITION BASED ON HYBRID ALGORITHM IN INDOOR VIDEO SURVEILLANCE</b></h1>
                    <h2>
                    <span>Zheng Hao</span>
                    <span>Liu Jianfang</span>
                    <span>Liao Mengyi</span>
            </h2>
                    <h2>
                    <span>School of Computer, Pingdingshan University</span>
                    <span>National Digital Learning Engineering Technology Research Center, Huazhong Normal University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the influence of illumination variations, occlusions, camera movements, and background clutters on monitoring accuracy in the detection and recognition of human abnormal behavior, a hybrid multi-technique tracking method was proposed. Based on continuous adaptive mean shift (CAMS) , we introduced corrected background weight histogram (CBWH) and unscented particle filter (UPF) to deal with the interference of shading and similar color objects. The sparse expression detection method was utilized to identify the abnormal behavior of the target object in various scenarios. The performance of the proposed method was evaluated by using the mean square error (MSE) , and the simulation was carried out on the open data set UMN. The experimental results show that the method can accurately detect and recognize the target object under the condition of obstacle occlusion or similar color object in different scenes. In addition, this technique may further improve the tracking performance of target objects in multiple cameras and complex scenes.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Tracking%20and%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Tracking and recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Continuous%20adaptive%20mean%20shift%20(CAMS)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Continuous adaptive mean shift (CAMS) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Corrected%20background%20weight%20histogram%20(CBWH)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Corrected background weight histogram (CBWH) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Unscented%20particle%20filter%20(UPF)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Unscented particle filter (UPF) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Sparse%20expression&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Sparse expression;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Indoor%20video%20monitoring&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Indoor video monitoring;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-25</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="44">近年来, 监控摄像已广泛应用于银行、超市、监狱、机场、停车场、加油站、救援、医学检测等场景, 以保证人民生命及财产安全和社会稳定<citation id="169" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。同时针对室内老年人异常行为检测与识别方面也有较广泛的应用, 但由于室内照明变化、遮挡和相似背景其他对象等因素的干扰, 对于异常行为的检测和识别具有一定的挑战性, 学者针对现有监控识别系统在人体异常行为检测和识别性能的提升开展了大量研究工作<citation id="163" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。其中常见的状态检测和识别方法包括<citation id="170" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>:检测和跟踪、跟踪前检测和基于概率假设密度滤波器等多目标跟踪技术。虽然学者们已经提出了许多以互斥方式处理照明变化、运动状态变化等因素的干扰和局限, 但当有障碍物遮挡和存在其他相似对象时对人体异常行为的检测和识别问题仍未得到完全解决。其中, 平均移位跟踪算法<citation id="164" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>建立在密度外观模型上, 用于跟踪静止或移动物体, 由于其结构简单和计算量小等优点, 已被广泛应用于物体的实时检测与识别。但其主要问题是当目标物体靠近或远离相机的焦点时会导致跟踪失败。因此, 文献<citation id="165" type="reference">[<a class="sup">7</a>]</citation>提出了一种用于拥挤场景中快速异常检测和定位的级联式三维深层神经网络, 并对比了其余传统光流法和社会力模型等方法的异常行为检测效果, 但该方法主要针对室外拥挤场景, 且更侧重于异常行为的检测与定位。文献<citation id="166" type="reference">[<a class="sup">8</a>]</citation>则针对该问题提出了一种社会网络模型的检测方法, 利用局部社交网络对全球社交网络显示场景中的动态对象进行检测, 并对所划分的每个长方体中的人体行为践行建模, 最终实现异常行为的检测与定位。文献<citation id="167" type="reference">[<a class="sup">9</a>]</citation>提出了在跟踪过程中自适应地调整跟踪窗口的大小和目标对象的分布模式的改进连续自适应均值漂移 (CAMS) , 但CAMS跟踪方法在目标对象所在背景中有相似颜色的其他对象或是所要跟踪的对象突然被障碍物遮挡时, 其检测和识别性能往往差强人意。文献<citation id="168" type="reference">[<a class="sup">10</a>]</citation>提出了一种整合跟踪和识别技术的背景减法算法, 以检测室内环境中的人体存在, 并消除背景中相似颜色其他对象对人体异常行为检测和识别的干扰, 但当有障碍物遮挡时的跟踪效果却有待提升。</p>
                </div>
                <div class="p1">
                    <p id="45">此外, 在CAMS和Kalman的组合滤波器中, Kalman滤波器主要用于预测目标物体的可能位置, 同时借助CAMS在预测区域中搜索和匹配目标物体, 以实现目标对象的检测、识别和跟踪。如文献<citation id="171" type="reference">[<a class="sup">11</a>]</citation>在CAMS无法正确估计目标物体的路径时, 引入卡尔曼滤波技术来跟踪目标对象, 以实现对目标对象的检测和识别, 然而却受限于高斯假设, 导致跟踪效果欠佳。粒子滤波器因其所具有的非高斯、非线性等假设属性而被应用于视觉对象跟踪<citation id="172" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。研究表明, 粒子滤波器和CAMS的组合可以提高在线跟踪的性能, 但粒子滤波器使用转换优先级作为提议分布, 并且不考虑当前观察到的数据, 从而导致低概率区域中许多粒子的浪费<citation id="173" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="46">因此, 提出了在CAMS基础上, 引入无味粒子滤波器 (UPF) 和校正背景权重直方图 (CBWH) , 整合稀疏表达的多技术混合跟踪方法来提升室内人体异常行为检测与识别系统的综合性能。本文创新点总结如下:</p>
                </div>
                <div class="p1">
                    <p id="47"> (1) UPF技术可以有效解决CAMS跟踪过程中目标对象被遮挡的问题, 对目标进行有效跟踪;</p>
                </div>
                <div class="p1">
                    <p id="48"> (2) CBWH技术可以在被跟踪目标对象背景中具有与其颜色相近的其他对象时提高算法对目标对象路径估计的准确性。</p>
                </div>
                <div class="p1">
                    <p id="49"> (3) 稀疏表达的引入可以针对人体异常行为进行有效检测和识别, 实现系统预期功能。</p>
                </div>
                <div class="p1">
                    <p id="50">此外所提集成技术, 对于检测和跟踪视频序列中的对象具有良好的快速性和鲁棒性。</p>
                </div>
                <h3 id="51" name="51" class="anchor-tag"><b>1 基于混合算法的人体异常行为检测和识别方法</b></h3>
                <div class="p1">
                    <p id="52">所提出的混合算法人体异常行为检测与识别系统框架如图1所示。首先, 将一系列视频帧传递到颜色转换模块以分解帧中目标对象的颜色。若目标对象背景中具有与其相近颜色的其他对象时, 则通过CBWH模块从其背景干扰中恢复对目标对象的筛选, 并确定可能的颜色分布, 再调用CAMS模块;否则直接调用CAMS模块。此外, 当目标对象的路径被障碍物遮挡时, CAMS模块将输出到UPF模块, 进行目标对象路径的正确估计, 再通过基于稀疏表达的异常行为识别模块最终以视频形式显示。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907039_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 多技术人体异常行为检测与识别系统框架" src="Detail/GetImg?filename=images/JYRJ201907039_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 多技术人体异常行为检测与识别系统框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907039_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="54" name="54"><b>1.1 CAMS跟踪算法</b></h4>
                <div class="p1">
                    <p id="55">CAMS是一种目标跟踪算法, 它通过改变窗口的大小将循环中的Mean-Shift算法结合起来直到收敛<citation id="174" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。初始化搜索窗口的位置和大小须包含视频序列中目标对象的所在区域, 通过对搜索窗口内每个像素的色调进行采样, 生成概率密度函数并存储为直方图目标对象的模型<citation id="175" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。在跟踪的下一阶段, 通过扫描所捕获场景的每个像素来进行概率分布估计, 最后计算该像素属于目标对象的概率。若隐藏搜索窗口基于 (<i>x</i>, <i>y</i>) 坐标的初始位置, 则搜索窗口第零, 第一和第二阶图像矩阵可表示如下:</p>
                </div>
                <div class="p1">
                    <p id="56"><b><i>M</i></b><sub>00</sub>=<mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>x</mi></munder><mrow></mrow></mstyle><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mrow></mrow></mstyle></mrow></math></mathml><i>p</i> (<i>x</i>, <i>y</i>)      (1) <b><i>M</i></b><sub>10</sub>=<mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>x</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mi>x</mi></mstyle></mrow></mstyle><mi>p</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mtext> </mtext><mi mathvariant="bold-italic">Μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>1</mn></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>x</mi></munder><mrow></mrow></mstyle><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mrow></mrow></mstyle></mrow></math></mathml><i>yp</i> (<i>x</i>, <i>y</i>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="59"><b><i>M</i></b><sub>20</sub>=<mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>x</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mi>x</mi></mstyle></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mi>p</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mtext> </mtext><mi mathvariant="bold-italic">Μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>2</mn></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>x</mi></munder><mrow></mrow></mstyle><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mrow></mrow></mstyle></mrow></math></mathml><i>y</i><sup>2</sup><i>p</i> (<i>x</i>, <i>y</i>)      (3) </p>
                </div>
                <div class="p1">
                    <p id="61">式中:<i>p</i> (<i>x</i>, <i>y</i>) 表示图像中位置 (<i>x</i>, <i>y</i>) 处的概率值, <i>x</i>和<i>y</i>分别表示矩形搜索窗口的坐标。在下一步中, 搜索窗口中的中心位置 (<i>Cl</i>) 可利用下式计算:</p>
                </div>
                <div class="p1">
                    <p id="62"><mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>l</mi><msub><mrow></mrow><mi>x</mi></msub><mo>=</mo><mfrac><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>0</mn></mrow></msub></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>0</mn></mrow></msub></mrow></mfrac><mtext> </mtext><mi>C</mi><mi>l</mi><msub><mrow></mrow><mi>y</mi></msub><mo>=</mo><mfrac><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>1</mn></mrow></msub></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>0</mn></mrow></msub></mrow></mfrac></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="64">同时, 通过使用目标对象的纵横比 (<i>Ar</i>) 来更新搜索窗口位置:</p>
                </div>
                <div class="p1">
                    <p id="65"><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>r</mi><mo>=</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>2</mn><mspace width="0.25em" /></mrow></msub></mrow><mrow><mi>y</mi><msubsup><mrow></mrow><mrow><mi>c</mi><mi>l</mi><mspace width="0.25em" /></mrow><mo>, </mo></msubsup></mrow></mfrac></mrow><mo>) </mo></mrow><mo>/</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>0</mn><mspace width="0.25em" /></mrow></msub></mrow><mrow><mi>x</mi><msubsup><mrow></mrow><mrow><mi>c</mi><mi>l</mi><mspace width="0.25em" /></mrow><mo>, </mo></msubsup></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="67"><i>Width</i>=2<i>M</i><sub>00</sub>×<i>Ar Height</i>=2<i>M</i><sub>00</sub>/<i>Ar</i>      (6) </p>
                </div>
                <div class="p1">
                    <p id="68">CAMS跟踪算法用于检测和跟踪视频序列中的目标对象时, 重复上述式 (1) -式 (6) 直到达到所需的收敛状态。但当目标对象具有与其背景中其他对象颜色相似时, 算法跟踪性能通常会变差。其次就是在视频序列中所要跟踪的对象出现遇到被遮挡的情况时, CAMS跟踪算法就会失去对物体路径的估计能力, 从而导致跟踪效果不佳。这两个突出的问题在当前大多数跟踪算法都较为突出。因此, 引入CBWH和UPF方法来加以优化。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69"><b>1.2 校正背景权重直方图 (CBWH) 技术</b></h4>
                <div class="p1">
                    <p id="70">在对目标对象进行跟踪时, 检测区域中通常会包括对象的背景信息, 当目标和背景或背景中其他对象具有较高相关性高的情况下, 对象的定位精度将降低, 从而影响跟踪准确性<citation id="178" type="reference"><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>。为最小化背景特征的对定位精度的影响, 引入了CBWH技术来刻画目标对象与背景之间的特征差异<citation id="176" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>, 以提高对目标物体的跟踪精度, CBWH的数学模型可表示如下<citation id="177" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="71"><mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mover accent="true"><mi>α</mi><mo>^</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mi>u</mi></msub><mo>=</mo><msup><mi>C</mi><mo>′</mo></msup><mi>v</mi><msub><mrow></mrow><mi>u</mi></msub></mrow></math></mathml><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml><i>k</i> (‖<i>x</i><mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup></mrow></math></mathml>‖<sup>2</sup>) <i>δ</i>[<i>b</i> (<i>x</i><mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup></mrow></math></mathml>) -<i>u</i>]      (7) </p>
                </div>
                <div class="p1">
                    <p id="76"><mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mover accent="true"><mi>β</mi><mo>^</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>C</mi><msubsup><mrow></mrow><mi>h</mi><mi>i</mi></msubsup><mi>v</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>h</mi></msub></mrow></munderover><mi>k</mi></mstyle><mrow><mo> (</mo><mrow><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mfrac><mrow><mi>y</mi><mo>-</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mi>h</mi></mfrac><mo stretchy="false">|</mo><mo stretchy="false">|</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>) </mo></mrow><mi>δ</mi><mo stretchy="false">[</mo><mi>b</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>u</mi><mo stretchy="false">]</mo></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="78"><mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">{</mo><mi>ξ</mi><msub><mrow></mrow><mi>u</mi></msub><mo>=</mo><mrow><mi>min</mi></mrow><mrow><mo> (</mo><mrow><mover accent="true"><mi>z</mi><mo>^</mo></mover><msup><mrow></mrow><mo>*</mo></msup><mo>/</mo><mover accent="true"><mi>z</mi><mo>^</mo></mover><msub><mrow></mrow><mi>u</mi></msub><mo>, </mo><mn>1</mn></mrow><mo>) </mo></mrow><mo stretchy="false">}</mo><msub><mrow></mrow><mrow><mi>u</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>m</mi></mrow></msub></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="80"><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">{</mo><mover accent="true"><mi>z</mi><mo>^</mo></mover><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">}</mo><msub><mrow></mrow><mrow><mi>u</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>m</mi></mrow></msub><mrow><mo> (</mo><mrow><mtext>w</mtext><mtext>i</mtext><mtext>t</mtext><mtext>h</mtext><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mover accent="true"><mi>z</mi><mo>^</mo></mover></mstyle><msub><mrow></mrow><mi>u</mi></msub><mo>=</mo><mn>1</mn></mrow><mo>) </mo></mrow></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="82">式中:<mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mover accent="true"><mi>α</mi><mo>^</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mi>u</mi></msub></mrow></math></mathml>表示新的目标模型, <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mover accent="true"><mi>β</mi><mo>^</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mrow></math></mathml>表示新的目标候选模型, <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>z</mi><mo>^</mo></mover><msup><mrow></mrow><mo>*</mo></msup></mrow></math></mathml>是最小非零<mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">{</mo><msup><mover accent="true"><mi>z</mi><mo>^</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">}</mo><msub><mrow></mrow><mrow><mi>u</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>m</mi></mrow></msub></mrow></math></mathml>中的值。背景模型可用式 (9) 和式 (10) 表示, 其大小为目标对象的三倍。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87"><b>1.3 无味粒子滤波 (UPF) 技术</b></h4>
                <div class="p1">
                    <p id="88">滤波技术被广泛用于建立模型, 其主要目的是估计后续帧中目标对象的状态。比较常见的滤波方案是采用序贯蒙特卡洛法, 即粒子滤波器 (Particle Filters, PF) 对后续统计值进行估计和计算, 其中包括平均值、模式、峰度和方差等。然而, PF对抽样的合理性要求较高, 若不能使用最新的可用信息来估计新的状态值, 则只有少数粒子可以存活。因此, 采用UPF方法作为提议分布, 将粒子尽可能多地移向高可能性区域, 以便恰当地估计目标对象在被遮挡情况下的路径。UPF算法第一阶段涉及到的目标对象初始化状态可表示如下:</p>
                </div>
                <div class="p1">
                    <p id="89"><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>x</mi><mo stretchy="true">¯</mo></mover><msubsup><mrow></mrow><mn>0</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo><mi>R</mi><mo stretchy="false">[</mo><mi>x</mi><msubsup><mrow></mrow><mn>0</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">]</mo></mrow></math></mathml>      (12) </p>
                </div>
                <div class="p1">
                    <p id="91"><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msubsup><mrow></mrow><mn>0</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo><mi>R</mi><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mi>x</mi><msubsup><mrow></mrow><mn>0</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>-</mo><mover accent="true"><mi>x</mi><mo stretchy="true">¯</mo></mover><msubsup><mrow></mrow><mn>0</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>x</mi><msubsup><mrow></mrow><mn>0</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>-</mo><mover accent="true"><mi>x</mi><mo stretchy="true">¯</mo></mover><msubsup><mrow></mrow><mn>0</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>Τ</mi></msup><mo stretchy="false">]</mo></mrow></math></mathml>      (13) </p>
                </div>
                <div class="p1">
                    <p id="93">式中:<i>x</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>0</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>表示物体相对于先前的粒子数<i>P</i> (<i>x</i><sub>0</sub>) 。基于式 (13) 确定一系列的sigma点, 并利用式 (14) 更新粒子, 将跟新结果传递到下一步进行如式 (15) -式 (17) 处理, 并利用式 (18) 执行测量更新:</p>
                </div>
                <div class="p1">
                    <p id="95"><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mi>a</mi></mrow></msubsup><mo>=</mo><mo stretchy="false">[</mo><mover accent="true"><mi>x</mi><mo stretchy="true">¯</mo></mover><msubsup><mrow></mrow><mn>0</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mi>a</mi></mrow></msubsup><mover accent="true"><mi>x</mi><mo stretchy="true">¯</mo></mover><msubsup><mrow></mrow><mn>0</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mi>a</mi></mrow></msubsup><mo>±</mo><msqrt><mrow><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mi>a</mi></msub><mo>+</mo><mi>γ</mi><mo stretchy="false">) </mo><mi>Ρ</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mi>a</mi></mrow></msubsup></mrow></msqrt><mo stretchy="false">]</mo></mrow></math></mathml>      (14) </p>
                </div>
                <div class="p1">
                    <p id="97"><i>X</i><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mi>a</mi></mrow></msubsup></mrow></math></mathml>=<i>f</i> (<i>X</i><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mi>x</mi></mrow></msubsup></mrow></math></mathml>, <i>X</i><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mi>v</mi></mrow></msubsup></mrow></math></mathml>)      (15) </p>
                </div>
                <div class="p1">
                    <p id="101"><i>P</i><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>=<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>i</mi><mrow><mn>2</mn><mi>n</mi><msub><mrow></mrow><mi>a</mi></msub></mrow></munderover><mrow></mrow></mstyle></mrow></math></mathml><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false"> (</mo><mi>c</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">[</mo><mi>X</mi><msubsup><mrow></mrow><mi>t</mi><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mi>x</mi></mrow></msubsup><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn><mo>-</mo><mover accent="true"><mi>x</mi><mo stretchy="true">¯</mo></mover><msubsup><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>X</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mi>x</mi></mrow></msubsup><mo>-</mo><mover accent="true"><mi>x</mi><mo stretchy="true">¯</mo></mover><msubsup><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">]</mo><msup><mrow></mrow><mi>Τ</mi></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="105"><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo stretchy="true">¯</mo></mover><msubsup><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo></mrow></math></mathml><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>i</mi><mrow><mn>2</mn><mi>n</mi><msub><mrow></mrow><mi>a</mi></msub></mrow></munderover><mrow></mrow></mstyle></mrow></math></mathml><i>W</i><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml><i>y</i><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>      (17) </p>
                </div>
                <div class="p1">
                    <p id="110"><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Ρ</mi><mo>^</mo></mover><mo>=</mo><mi>Ρ</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>-</mo><mi>Κ</mi><msub><mrow></mrow><mrow><mi>t</mi><mspace width="0.25em" /></mrow></msub><mi>Ρ</mi><msubsup><mrow></mrow><mrow><mover accent="true"><mi>y</mi><mo stretchy="true">¯</mo></mover><msub><mrow></mrow><mrow><mi>t</mi><mspace width="0.25em" /></mrow></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mrow><mi>t</mi><mspace width="0.25em" /></mrow></msub></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mi>Κ</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mspace width="0.25em" /></mrow><mi>Τ</mi></msubsup></mrow></math></mathml>      (18) </p>
                </div>
                <div class="p1">
                    <p id="112">通过最后步骤的计算, 将生成来自已知提议分布的样本粒子。其中每个样品粒的权重已知, 并进行归一化处理。由此将CBWH和UPF集成到CAMS中, 以构建一个可靠且高效的人体异常行为检测和识别系统。</p>
                </div>
                <h4 class="anchor-tag" id="113" name="113"><b>1.4 图像稀疏表达</b></h4>
                <div class="p1">
                    <p id="114">异常行为图像检测的稀疏表达流程如下:先针对训练样本建立查询字典库, 再根据查询字典库进行稀疏重构样本, 最后通过比较重构稀疏度, 对异常行为图像进行检测。图像稀疏表达如图2所示, 其中<b><i>x</i>∈<i>R</i></b><sup><i>m</i>×<i>l</i></sup>表示原始特征数据, <b><i>D</i>∈<i>R</i></b><sup><i>m</i>×<i>n</i></sup>表示查询字典库, <i>α</i>∈<b><i>R</i></b><sup><i>l</i>×<i>n</i></sup>为系数矩阵, 同时也是<i>x</i>的稀疏表示。</p>
                </div>
                <div class="area_img" id="115">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907039_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 图像稀疏表达" src="Detail/GetImg?filename=images/JYRJ201907039_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 图像稀疏表达  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907039_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="116">稀疏表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="117"><mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">α</mi><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>α</mi></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><mo>-</mo><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">α</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">α</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mrow></math></mathml>      (19) </p>
                </div>
                <div class="p1">
                    <p id="119">式中:<i>λ</i>表示权重系数, ‖<i>α</i>‖<sub>1</sub>表示系数矩阵的稀疏度。设定异常行为图像检测的特征数据为<i>sample</i><sub>test</sub>∈<i>R</i><sup><i>m</i></sup>, 它在查询字典库上的表示系数为:</p>
                </div>
                <div class="p1">
                    <p id="120"><mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>ε</mi><mo>′</mo></msup><mo>=</mo><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mi>ε</mi></munder><mo stretchy="false">∥</mo><mi>s</mi><mi>a</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>e</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">D</mi><mi>ε</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>      (20) </p>
                </div>
                <div class="p1">
                    <p id="122">重构误差<i>φ</i>为:</p>
                </div>
                <div class="p1">
                    <p id="123"><i>φ</i>=‖<i>sample</i><sub>test</sub>-<b><i>D</i></b><i>ε</i>′‖<sub>2</sub>      (21) </p>
                </div>
                <div class="p1">
                    <p id="124">比较重构误差与阈值, 判定样本<i>sample</i><sub>test</sub>是否为异常行为。</p>
                </div>
                <h3 id="125" name="125" class="anchor-tag"><b>2 实验与分析</b></h3>
                <h4 class="anchor-tag" id="126" name="126"><b>2.1 实验基础</b></h4>
                <div class="p1">
                    <p id="127">为验证所提方案的可行性和有效性, 基于Windows 10平台使用MATLAB (R2016a) 进行了实验, 该模型运行于6核i7-8700处理器, 8 GB RAM的惠普690-076ccn台式计算机上。其数据来源的视频文件通过Canon HF R806百万像素数码摄像机采集, 分辨率设置为350×320, 速率32帧/秒。通过将视频进行格式转换后加载到传统的CAMS算法和提出的跟踪方案中以观察其检测和识别性能。</p>
                </div>
                <div class="p1">
                    <p id="128">所提跟踪检测方案流程大致如下:首先基于帧间差异确定视频序列中的图像变化;其次通过在二值图像上设置阈值来提取轮廓, 以得到关于目标对象的特征向量, 并利用目标对象周围的统计像素值来计算颜色直方图;最终通过反投影恢复原始对象的颜色概率分布。当跟踪目标对象被遮挡时, UPF模块利用轨迹历史来预测下一组帧中的对象的位置;当跟踪目标对象在其背景中具有相似颜色的其他对象时, CBWH模块用于提供信息使CAMS算法聚焦于目标对象而非背景。实验主要设置无障碍遮蔽、有障碍物遮蔽和背景中存在相似颜色其他对象三种场景下所提方法与传统CAMS方法的对比案例, 其具体实验步骤和结果如下。</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129"><b>2.2 无遮挡场景下的跟踪性能对比</b></h4>
                <div class="p1">
                    <p id="130">本组实验通过使用一组没有任何障碍物遮挡的视频文件, 分四次对所提方法和传统CAMS算法的检测和识别性能进行检验。图3为使用提方法和传统CAMS方法的一组人体运动检测和跟踪结果。</p>
                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907039_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 分别在50, 150, 250和350帧进行人体运动跟踪" src="Detail/GetImg?filename=images/JYRJ201907039_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 分别在50, 150, 250和350帧进行人体运动跟踪  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907039_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>
                                <p class="img_note"> ( (a) - (d) 为传统CAMS方法; (e) - (h) 为所提方法) </p>

                </div>
                <div class="p1">
                    <p id="132">从图3所示的结果可以看出, 所提多技术跟踪策略能准确估计从初始帧 (图3 (e) ) 到最终帧 (图3 (h) ) 的人体运动路径。由于没有障碍物遮挡, CAMS算法也正确地估计了人体运动的路径 (如图3 (a) - (d) 。在所有帧中, 所提方法和CAMS在沿X和Y轴对目标对象路径估计方面的性能如图4所示。可以看出所提方法具有与传统CAMS方法相似的跟踪性能。在四个不同实验中, 通过使用均方误差 (MSE) 来对所提方法和CAMS方法沿两X和Y轴对目标对象路径估计的准确性进行比较, 其结果如表1所示。</p>
                </div>
                <div class="area_img" id="134">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907039_13400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 无障碍路径估计结果" src="Detail/GetImg?filename=images/JYRJ201907039_13400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 无障碍路径估计结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907039_13400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="135">
                    <p class="img_tit"><b>表1 所提方法和无障碍CAMS的跟踪结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="135" border="1"><tr><td><br />试验数量</td><td colspan="2">CAMS法MSE</td><td colspan="2">所提方法MSE</td></tr><tr><td><br /></td><td>X轴</td><td>Y轴</td><td>X轴</td><td>Y轴</td></tr><tr><td><br />1</td><td>0.25</td><td>0.23</td><td>0.27</td><td>0.22</td></tr><tr><td><br />2</td><td>0.19</td><td>0.17</td><td>0.14</td><td>0.15</td></tr><tr><td><br />3</td><td>0.23</td><td>0.15</td><td>0.14</td><td>0.18</td></tr><tr><td><br />4</td><td>0.24</td><td>0.23</td><td>0.19</td><td>0.13</td></tr><tr><td><br />平均值<br />±标准</td><td>0.227±<br /> 0.023</td><td>0.195±<br /> 0.053</td><td>0.185±<br />0.035</td><td>0.170±<br />0.063</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="136">通过计算四次实验结果可得, 提方法沿X轴和Y轴的平均估计误差分别为0.185%和0.170%, 而CAMS方法沿X轴和Y轴的平均估计误差分别为0.227%和0.195%。从实验结果可以看出, 传统的CAMS方法在没有障碍物的情况下能够正确估计视频序列中目标对象的路径。</p>
                </div>
                <h4 class="anchor-tag" id="137" name="137"><b>2.3 存在障碍物遮挡时的跟踪性能对比</b></h4>
                <div class="p1">
                    <p id="138">本组实验以一系列面部视频为实验对象, 引入尺寸约为210 mm×297 mm的A4白纸作障碍物对目标对象进行遮挡以比较所提方法和传统的CAMS算法对目标对象的跟踪性能, 其实验结果表明, 提出的混合跟踪方法因引入无味粒子滤波器的预测能力, 可以在目标对象被遮挡或者恢复时保持较好的跟踪性能。针对传统方法和所提方法, 分别沿X和Y轴对目标对象路径进行了估计, 其结果如图5所示。</p>
                </div>
                <div class="area_img" id="140">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907039_14000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 目标对象被遮挡时路径估计结果" src="Detail/GetImg?filename=images/JYRJ201907039_14000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 目标对象被遮挡时路径估计结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907039_14000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="141">由图5可知, 在有遮挡场景中提出的方法能够正确地估计并跟踪目标对象的路径。传统CAMS方法在无遮挡时表现良好, 但当完全遮挡时, 在沿X轴 (280.2, 105) 丢失了物体路径的完整轨迹。沿Y轴跟踪效果与X轴相似, 丢失轨迹的处为 (269.2, 87.8) 。进一步分析两种方法的平均跟踪精度, 结果如表2所示。</p>
                </div>
                <div class="area_img" id="142">
                    <p class="img_tit"><b>表2 所提出方法与CAMS算法在有遮挡情况下的跟踪结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="142" border="1"><tr><td><br />试验数量</td><td colspan="2">CAMS法MSE</td><td colspan="2">所提方法MSE</td></tr><tr><td><br /></td><td>X轴</td><td>Y轴</td><td>X轴</td><td>Y轴</td></tr><tr><td><br />1</td><td>0.49</td><td>0.24</td><td>0.29</td><td>0.17</td></tr><tr><td><br />2</td><td>0.45</td><td>0.54</td><td>0.14</td><td>0.20</td></tr><tr><td><br />3</td><td>0.57</td><td>0.43</td><td>0.15</td><td>0.19</td></tr><tr><td><br />4</td><td>0.52</td><td>0.33</td><td>0.09</td><td>0.15</td></tr><tr><td><br />平均值<br />±标准</td><td>0.5075±<br />0.232</td><td>0.385±<br />0.168</td><td>0.167±<br />0.021</td><td>0.177±<br />0.034</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="143">根据表2中所示的目标对象路径估计结果, 可以观察到所提方法在X和Y轴上实现了82.8%的平均估计精度, 而传统的CAMS方法由于障碍物的遮挡, 其平均估计精度仅为55.37%。该结果也说明UPF技术的引入, 对系统在存在障碍物遮挡的场景中对目标对象的跟踪和识别性能具有一定的改进能力。</p>
                </div>
                <h4 class="anchor-tag" id="144" name="144"><b>2.4 在公开数据集UMN上的实验验证</b></h4>
                <div class="p1">
                    <p id="145">实验所用UMN数据集的包含3个不同拥挤场景, 分别采用3个不同场景对异常行为进行检测。如图6所示, (a) - (c) 为正常帧, (d) - (f) 为存在异常行为的异常帧。采用所提算法与传统光流法和社会力模型等方法分别在三个情景中进行比较, 其中, 传统光流法和社会力模型的结果参考自文献<citation id="179" type="reference">[<a class="sup">20</a>]</citation>。实验结果通过绘制接收者操作特性曲线 (receiver operating characteristic curve, ROC) 来表示, 如图7所示。</p>
                </div>
                <div class="area_img" id="146">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907039_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 公开数据集UMN中正常帧 (a-c) 和异常帧 (d-f)" src="Detail/GetImg?filename=images/JYRJ201907039_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 公开数据集UMN中正常帧 (a-c) 和异常帧 (d-f)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907039_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="147">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907039_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同方法在公开数据集UMN中的异常探测ROC曲线" src="Detail/GetImg?filename=images/JYRJ201907039_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同方法在公开数据集UMN中的异常探测ROC曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907039_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="148">图7中, S1、S2、S3分别代表UMN公开数据集中的三个不同场景, 从图中可以看出, 在不同场景下, 所提方法都较传统光流法和社会力模型等方法有更好的异常行为识别效果。这是因为提出的方法为最小化背景特征的对定位精度的影响, 引入了CBWH技术来刻画目标对象与背景之间的特征差异, 提高了对目标物体的跟踪精度。</p>
                </div>
                <h4 class="anchor-tag" id="149" name="149"><b>2.5 存在背景影响的跟踪性能对比</b></h4>
                <div class="p1">
                    <p id="150">本节实验目标对象背景中存在与其相似的其他对象, 主要检验传统CAMS方法和所提方法在老年人摔倒等异常行为方面的检测和识别效果。实验结果如图8所示, (a) - (c) 为传统CAMS算法, (d) - (f) 为所提方法。尽管背景中存在与其跟踪目标相似颜色的其他对象, 算法也能保持对视频序列中目标对象的良好跟踪效果, 而传统CAMS方法却不能较好地检测和识别该异常行为。</p>
                </div>
                <div class="area_img" id="151">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907039_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 传统CAMS算法和所提出算法在50帧、100帧和150帧处当背景中存在其他类似物体时对异常行为的检测情况" src="Detail/GetImg?filename=images/JYRJ201907039_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 传统CAMS算法和所提出算法在50帧、100帧和150帧处当背景中存在其他类似物体时对异常行为的检测情况  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907039_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="152">此外, 分析所提方法和传统的CAMS算法分别沿X和Y轴对移动小球进行路径估计情况, 其结果如图9所示。可以看出, 无论背景中是否存在与目标对象颜色相近的其他物体, 所提方法都能够正确地估计目标物体沿X和Y轴的路径。CAMS算法仅能在开始阶段具有较好的跟踪效果, 而分别在沿X轴 (77.3, 135.5) , 沿Y轴 (39.5, 193.7) 处丢失对目标对象完整路径的估计。分析两种方法沿X和Y轴对目标对象的跟踪的MSE, 其结果如表3所示。</p>
                </div>
                <div class="area_img" id="154">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907039_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 当目标对象背景中有相似颜色的其他物体时的路径估计结果" src="Detail/GetImg?filename=images/JYRJ201907039_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 当目标对象背景中有相似颜色的其他物体时的路径估计结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907039_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="155">
                    <p class="img_tit"><b>表3 当目标对象具有相似颜色属性的背景对象时, 跟踪所提出方法和CAMS的结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="155" border="1"><tr><td><br />试验数量</td><td colspan="2">CAMS法MSE</td><td colspan="2">所提方法MSE</td></tr><tr><td><br /></td><td>X轴</td><td>Y轴</td><td>X轴</td><td>Y轴</td></tr><tr><td><br />1</td><td>0.58</td><td>0.46</td><td>0.17</td><td>0.15</td></tr><tr><td><br />2</td><td>0.34</td><td>0.44</td><td>0.13</td><td>0.09</td></tr><tr><td><br />3</td><td>0.53</td><td>0.56</td><td>0.21</td><td>0.15</td></tr><tr><td><br />4</td><td>0.55</td><td>0.64</td><td>0.22</td><td>0.21</td></tr><tr><td><br />平均值<br />±标准</td><td>0.5±<br />0.123</td><td>0.525±<br />0.143</td><td>0.182±<br />0.036</td><td>0.15±<br />0.032</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="156">根据表3中对目标对象路径估计的统计结果显示, 所提方法在X和Y轴上的平均估计精度为83.4%, 而由于背景中与目标对象颜色相似的其他对象的存在, 传统的CAMS方法估计精度仅为48.75%。所提方法由于引入了CBWH技术, 使得跟踪算法能够从相似颜色对象中准确检测并跟踪目标对象, 从而实现系统跟踪性能的改进。</p>
                </div>
                <div class="p1">
                    <p id="157">此外, 进一步将所提方法与CAMS引导粒子滤波器 (CAMS+PF) 和CAMS引导卡尔曼滤波器 (CAMS+KF) 进行运动跟踪的性能评估比较, 以处理粒子所花时间为对比指标, 其结果如图10所示。</p>
                </div>
                <div class="area_img" id="158">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907039_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 同时估计目标物体路径时处理粒子所花费的时间对比" src="Detail/GetImg?filename=images/JYRJ201907039_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 同时估计目标物体路径时处理粒子所花费的时间对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907039_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="159">三次实验结果显示, CAMS+PF和CAMS+KF处理粒子以跟踪目标所需平均时间分别为0.09 s和0.088 2 s, 所提方法用时最短, 为0.065 s。这再次说明所提对象跟踪方法相对于现有方法有较强的鲁棒性和较高的精确性, 更具有快速估计目标对象的路径的优点。</p>
                </div>
                <h3 id="160" name="160" class="anchor-tag"><b>3 结 语</b></h3>
                <div class="p1">
                    <p id="161">针对室内人体异常行为检测与识别问题, 集成了CAMS、CBWH和UPF技术, 提出了一种对目标对象检测与识别的混合算法, 同时利用三种不同场景, 对比了所提算法与传统CAMS在路径跟踪和目标检测方面的性能比较。实验结果表明, 所提方法在有障碍物遮挡和目标颜色与背景中有相似对象的情况下, 具有更好的识别和跟踪性能, 对于提高室内人体异常行为的检测与识别的准确性和快速性具有重要意义。</p>
                </div>
                <div class="p1">
                    <p id="162">但目前研究大多局限于单个摄像机的目标对象跟踪与识别, 对于复杂场景下多摄像机中目标对象的跟踪与识别问题仍亟待解决。整合CAMS、CBWH和UPF三种技术, 提出针对有障碍物遮挡和背景中具有相似颜色目标对象的目标检测与识别方法, 将有望提高在拥挤场景下多个摄像机中目标对象跟踪与识别的快速性和准确性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201705015&amp;v=MTE5NDJmU2RyRzRIOWJNcW85RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVcnZJSVQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 邵振峰, 蔡家骏, 王中元, 等.面向智能监控摄像头的监控视频大数据分析处理[J].电子与信息学报, 2017, 39 (5) :1116-1122.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201703003&amp;v=MDQ4MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVydklJVGZUZTdHNEg5Yk1ySTlGWjRRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 邓磊, 陈宝华, 赖伟良, 等.三维监控系统中基于三维重构的交互式标定[J].电子学报, 2017, 45 (3) :527-533.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZDF201704023&amp;v=MDU0MzZxQnRHRnJDVVI3cWZadVp0RnlqaFVydklMemZQYUxHNEg5Yk1xNDlIWjRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 潘志安, 朱三元.移动摄像视频的多运动目标实时跟踪算法[J].控制工程, 2017, 24 (4) :836-843.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201801029&amp;v=MzIzOTF0RnlqaFVydklOaWZZWkxHNEg5bk1ybzlIYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 沈铮, 吴薇.基于图像处理的公交车内人群异常情况检测[J].计算机工程与设计, 2018, 39 (1) :165-171.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201801046&amp;v=MTQ2MDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVydklMelRaWkxHNEg5bk1ybzlCWW9RS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 罗建华.基于改进提升模型的视频目标跟踪算法[J].计算机应用与软件, 2018, 35 (1) :261-263.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBX201304014&amp;v=MDM5MDJqSmRyRzRIOUxNcTQ5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVcnZJTFM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 侯晴宇, 卞春江, 逯力红, 等.红外图像中快速小目标的均值移位跟踪[J].哈尔滨工业大学学报, 2013, 45 (4) :79-83.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep-cascade cascading 3d deep neural networks for fast anomaly detection and localization in crowded scenes">

                                <b>[7]</b> Sabokrou M, Fayyaz M, Fathy M, et al.Deep-Cascade:Cascading 3D Deep Neural Networks for Fast Anomaly Detection and Localization in Crowded Scenes[J].IEEE Transactions on Image Processing, 2017, 26 (4) :1992-2004.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Social network model for crowd anomaly detection and localization">

                                <b>[8]</b> Chaker R, Aghbari Z A, Junejo I N.Social Network Model for Crowd Anomaly Detection and Localization[J].Pattern Recognition, 2017, 61:266-281.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Target tracking based on the improved Camshift method">

                                <b>[9]</b> Xiu C, Ba F.Target tracking based on the improved Camshift method[C]// 2016 Chinese Control and Decision Conference (CCDC) .IEEE, 2016.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201303008&amp;v=MDAxNTMzenFxQnRHRnJDVVI3cWZadVp0RnlqaFVydklJanJQZExHNEg5TE1ySTlGYklRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 陈文会, 张晶, 樊养余, 等.一种基于背景减法和帧差的运动目标检测算法[J].电子设计工程, 2013, 21 (3) :24-26.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Directional prediction Cam Shift algorithm based on adaptive search pattern for moving object tracking">

                                <b>[11]</b> Hsia C H, Liou Y J, Chiang J S.Directional Prediction CamShift algorithm based on Adaptive Search Pattern for moving object tracking[J].Journal of Real-Time Image Processing, 2016, 12 (1) :183-195.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Radar target detection method based on particle filter theory under correlated non-Gaussian clutter backgrounds">

                                <b>[12]</b> Feng X, Jiang J, Lin P, et al.Radar target detection method based on particle filter theory under correlated non-Gaussian clutter backgrounds[C]// IET International Radar Conference 2015.IET, 2016.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SHJT201610020&amp;v=MDAyOTJGeWpoVXJ2SU5pWEJlckc0SDlmTnI0OUhaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 张赛钰, 朱小玲, 汪衍广, 等.基于帧差法与Mean-shift算法相结合的运动熔滴识别与跟踪方法[J].上海交通大学学报, 2016, 50 (10) :1605-1608.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201607002&amp;v=MTIzODI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVXJ2SUx6N0Jkckc0SDlmTXFJOUZab1FLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 王宇霞, 赵清杰, 蔡艺明, 等.基于自重构粒子滤波算法的目标跟踪[J].计算机学报, 2016, 39 (7) :1294-1306.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201609019&amp;v=MTc0MjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVydklMejdCWmJHNEg5Zk1wbzlFYllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 杨超, 蔡晓东, 王丽娟, 等.一种改进的CAMShift跟踪算法及人脸检测框架[J].计算机工程与科学, 2016, 38 (9) :1863-1869.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust mean-shift tracking with corrected background-weighted histogram">

                                <b>[16]</b> Ning J, Zhang L, Zhang D, et al.Robust mean-shift tracking with corrected background-weighted histogram[J].Iet Computer Vision, 2012, 6 (1) :62-69.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201405049&amp;v=MTg3MTZVcnZJTHo3QmJiRzRIOVhNcW85QmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 基于三维直方图修正和灰度熵分解的图像分割[J].计算机工程, 2014, 40 (5) :234-237.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAJT201511012&amp;v=MTk3MTh0R0ZyQ1VSN3FmWnVadEZ5amhVcnZJUFN6QmVyRzRIOVROcm85RVpvUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 崔汪莉, 卫军胡, 纪鹏, 等.基于加权局部梯度直方图的头部三维姿态估计[J].西安交通大学学报, 2015, 49 (11) :71-76.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJTT&amp;filename=SJTT13121200151870&amp;v=MTk4OTVHZXJxUVRNbndaZVp0RmlubFVyeklJRm9WYmhJPU5pZmZlcks3SDlQTnJZOUZaZTRPQkhzNW9CTVQ2VDRQUUgvaXJSZA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> Yang Y, Jia Y X, Rong C Z, et al.Object Tracking Based on Corrected Background-Weighted Histogram Mean Shift and Kalman Filter[J].Advanced Materials Research, 2013, 765-767:720-725.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Celestial navigation in deep space exploration using spherical simplex unscented particle filter">

                                <b>[20]</b> Zhao F, Ge S S, Jie Z, et al.Celestial navigation in deep space exploration using spherical simplex unscented particle filter[J].Iet Signal Processing, 2018, 12 (4) :463-470.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201907039" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907039&amp;v=MjY1MDBGckNVUjdxZlp1WnRGeWpoVXJ2SUx6VFpaTEc0SDlqTXFJOUdiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
