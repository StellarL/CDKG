<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135647889162500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201906040%26RESULT%3d1%26SIGN%3dfHT3yOLqlQ4EZ8ejzciIOholUEY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201906040&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201906040&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201906040&amp;v=MDE0NjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXZtVkwzTEx6VFpaTEc0SDlqTXFZOUJaSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#43" data-title="&lt;b&gt;1 多视图对象分割&lt;/b&gt; "><b>1 多视图对象分割</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="&lt;b&gt;1.1 颜色模型&lt;/b&gt;"><b>1.1 颜色模型</b></a></li>
                                                <li><a href="#52" data-title="&lt;b&gt;1.2 几何模型&lt;/b&gt;"><b>1.2 几何模型</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;1.3 MRF能量方程的构造与求解&lt;/b&gt;"><b>1.3 MRF能量方程的构造与求解</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#75" data-title="&lt;b&gt;2 Matting边缘优化&lt;/b&gt; "><b>2 Matting边缘优化</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="&lt;b&gt;2.1 模糊边界检测&lt;/b&gt;"><b>2.1 模糊边界检测</b></a></li>
                                                <li><a href="#82" data-title="&lt;b&gt;2.2 边界优化&lt;/b&gt;"><b>2.2 边界优化</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#87" data-title="&lt;b&gt;3 三维重建&lt;/b&gt; "><b>3 三维重建</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#95" data-title="&lt;b&gt;4 结果及分析&lt;/b&gt; "><b>4 结果及分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#105" data-title="&lt;b&gt;5 结 语&lt;/b&gt; "><b>5 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#74" data-title="图1 Graph Cut分割示意图">图1 Graph Cut分割示意图</a></li>
                                                <li><a href="#97" data-title="图2 拍摄示意图">图2 拍摄示意图</a></li>
                                                <li><a href="#99" data-title="图3 室内物体分割结果">图3 室内物体分割结果</a></li>
                                                <li><a href="#100" data-title="图4 室外物体分割结果">图4 室外物体分割结果</a></li>
                                                <li><a href="#102" data-title="图5 采用不同方法分割后三维重建结果">图5 采用不同方法分割后三维重建结果</a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;表1 分割和重建消耗时间对比 &lt;/b&gt;"><b>表1 分割和重建消耗时间对比 </b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="123">


                                    <a id="bibliography_1" title=" Jian M, Jung C.Interactive Image Segmentation Using Adaptive Constraint Propagation.[J].IEEE Transactions on Image Processing, 2016, 25 (3) :1301-1311." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interactive image segmentation using adaptive constraint propagation">
                                        <b>[1]</b>
                                         Jian M, Jung C.Interactive Image Segmentation Using Adaptive Constraint Propagation.[J].IEEE Transactions on Image Processing, 2016, 25 (3) :1301-1311.
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_2" title=" Wang T C, Liu M Y, Zhu J Y, et al.High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs[EB].arXiv:1711.11585, 2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs[EB]">
                                        <b>[2]</b>
                                         Wang T C, Liu M Y, Zhu J Y, et al.High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs[EB].arXiv:1711.11585, 2017.
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_3" title=" 高理文, 林小桦, 罗晓牧.结合简单交互和标记分水岭的复杂背景叶片图像分割方法[J].计算机应用与软件, 2016, 33 (8) :211-215, 241." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201608048&amp;v=MTUxODhIOWZNcDQ5QmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5dm1WTDNMTHpUWlpMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         高理文, 林小桦, 罗晓牧.结合简单交互和标记分水岭的复杂背景叶片图像分割方法[J].计算机应用与软件, 2016, 33 (8) :211-215, 241.
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_4" title=" Lee C, Jang W D, Sim J Y, et al.Multiple Random Walkers and Their Application to Image Cosegmentation[C]//2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .IEEE, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiple random walkers and their application to image cosegmentation">
                                        <b>[4]</b>
                                         Lee C, Jang W D, Sim J Y, et al.Multiple Random Walkers and Their Application to Image Cosegmentation[C]//2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .IEEE, 2015.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_5" title=" Rother C, Minka T, Blake A, et al.Cosegmentation of Image Pairs by Histogram Matching—Incorporating a Global Constraint into MRFs[C]//Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.IEEE, 2006." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cosegmentation of Image Pairs by Histogram Matching—Incorporating a Global Constraint into MRFs">
                                        <b>[5]</b>
                                         Rother C, Minka T, Blake A, et al.Cosegmentation of Image Pairs by Histogram Matching—Incorporating a Global Constraint into MRFs[C]//Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.IEEE, 2006.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_6" title=" Mukherjee L, Singh V, Dyer C R.Half-integrality based algorithms for cosegmentation of images[C]//2009 IEEE Conference on Computer Vision and Pattern Recognition.IEEE, 2009." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Half-integrality based algorithms for cosegmentation of images">
                                        <b>[6]</b>
                                         Mukherjee L, Singh V, Dyer C R.Half-integrality based algorithms for cosegmentation of images[C]//2009 IEEE Conference on Computer Vision and Pattern Recognition.IEEE, 2009.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_7" title=" Hochbaum D S, Singh V.An efhcient algorithm for co-segmentation[C]//Proceedings of International Conference on Computer Vision (ICCV) , 2009." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An efficient algorithm for Co-segmentation">
                                        <b>[7]</b>
                                         Hochbaum D S, Singh V.An efhcient algorithm for co-segmentation[C]//Proceedings of International Conference on Computer Vision (ICCV) , 2009.
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_8" title=" Vicente S, Kolmogorov V, Rother C.Cosegmentation Revisited:Models and Optimization[C]//European Conference on Computer Vision.Springer-Verlag, 2010." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cosegmentation revisited:models and optimization">
                                        <b>[8]</b>
                                         Vicente S, Kolmogorov V, Rother C.Cosegmentation Revisited:Models and Optimization[C]//European Conference on Computer Vision.Springer-Verlag, 2010.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_9" title=" Li Y, Jian S, Tang C K, et al.Lazy Snapping[J].Acm Transactions on Graphics, 2004, 23 (3) :303-308." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098096&amp;v=MjMyMTVUNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJMTBUYUJFPU5pZklZN0s3SHRqTnI0OUZaT0lIREhVL29CTQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Li Y, Jian S, Tang C K, et al.Lazy Snapping[J].Acm Transactions on Graphics, 2004, 23 (3) :303-308.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_10" title=" Meng T, Ayed I B, Marin D, et al.Secrets of GrabCut and Kernel K-Means[C]//IEEE International Conference on Computer Vision.2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Secrets of GrabCut and Kernel K-means">
                                        <b>[10]</b>
                                         Meng T, Ayed I B, Marin D, et al.Secrets of GrabCut and Kernel K-Means[C]//IEEE International Conference on Computer Vision.2016.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_11" title=" Johnson J, Varnousfaderani E S, Cholakkal H, et al.Sparse Coding for Alpha Matting[J].IEEE Transactions on Image Processing, 2016, 25 (7) :3032-3043." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparse coding for alpha matting">
                                        <b>[11]</b>
                                         Johnson J, Varnousfaderani E S, Cholakkal H, et al.Sparse Coding for Alpha Matting[J].IEEE Transactions on Image Processing, 2016, 25 (7) :3032-3043.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_12" title=" Levin A, Weiss Y.A closed form solution to natural image matting[C]//IEEE Computer Society Conference on Computer Vision &amp;amp; Pattern Recognition.IEEE Computer Society, 2006." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A closed form solution to natural image matting">
                                        <b>[12]</b>
                                         Levin A, Weiss Y.A closed form solution to natural image matting[C]//IEEE Computer Society Conference on Computer Vision &amp;amp; Pattern Recognition.IEEE Computer Society, 2006.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_13" title=" Lowe D G.Distinctive Image Features from Scale-Invariant Keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MjI5ODdPcDR4RmJlc09ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FkWitadUZpdmxVTHpQSWwwPU5qN0Jhck80SHRI&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Lowe D G.Distinctive Image Features from Scale-Invariant Keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_14" title=" Raposo C, Antunes M, Barreto J A P.Piecewise-Planar StereoScan:Sequential Structure and Motion Using Plane Primitives[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2018, 40 (8) :1918-1931." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Piecewise-Planar StereoScan:Sequential Structure and Motion Using Plane Primitives">
                                        <b>[14]</b>
                                         Raposo C, Antunes M, Barreto J A P.Piecewise-Planar StereoScan:Sequential Structure and Motion Using Plane Primitives[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2018, 40 (8) :1918-1931.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(06),209-213+247 DOI:10.3969/j.issn.1000-386x.2019.06.039            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种用于三维重建的多视图前景目标自动分割算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E6%AD%A3%E4%BC%9F&amp;code=24917604&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱正伟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E9%9D%99&amp;code=25352141&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张静</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A5%B6%E9%B9%8F&amp;code=09666013&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">饶鹏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E5%BF%BB&amp;code=32842209&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈忻</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B8%B8%E5%B7%9E%E5%A4%A7%E5%AD%A6&amp;code=0268985&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">常州大学</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E4%B8%8A%E6%B5%B7%E6%8A%80%E6%9C%AF%E7%89%A9%E7%90%86%E7%A0%94%E7%A9%B6%E6%89%80&amp;code=0268985&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院上海技术物理研究所</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>基于序列图像的三维物体重建之前, 从图像中分割前景目标可节约大量时间。但传统的分割算法需要通过用户输入来确定前、后景, 而基于图像的三维重建需要大量的图像, 造成极大的人工浪费。为此提出一种用于三维重建的多视图前景目标自动分割算法。对每个图像进行颜色一致性和几何一致性分析, 确定前景和后景大致区域, 得到初始输入, 并以此构建能量方程。使用Graph Cut算法求解方程得到粗略分割结果;使用Matting细化分割边界, 得到高质量的分割结果;使用分割后图片重建出物体三维模型。实验结果表明, 该算法可自动分割出多视图图像的前景目标, 且具有极高的准确率和良好的边缘。将该算法用于三维重建的前期图像处理, 可大大提高三维重建的速度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维重建;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E5%8A%A8%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自动分割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%89%B2%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图割算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E8%A7%86%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多视图;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    朱正伟, 教授, 主研领域:三维重建, 虚拟现实及其应用。;
                                </span>
                                <span>
                                    张静, 硕士生。;
                                </span>
                                <span>
                                    饶鹏, 研究员。;
                                </span>
                                <span>
                                    陈忻, 硕士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-14</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61772090);</span>
                    </p>
            </div>
                    <h1><b>AN AUTOMATIC SEGMENTATION ALGORITHM FOR MULTI-VIEW FOREGROUND OBJECT IN 3D RECONSTRUCTION</b></h1>
                    <h2>
                    <span>Zhu Zhengwei</span>
                    <span>Zhang Jing</span>
                    <span>Rao Peng</span>
                    <span>Chen Xin</span>
            </h2>
                    <h2>
                    <span>Changzhou University</span>
                    <span>Shanghai Institute of Technical Physics, Chinese Academy of Sciences</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Before the reconstruction of 3 D objects based on sequence images, it is possible to save time by segmenting the foreground targets. However, traditional segmentation algorithms need to determine the front and back views through user input, while image-based 3 D reconstruction requires a large number of images, resulting in a great waste of manual work. This paper proposed an automatic segmentation algorithm for multi-view foreground object in 3 D reconstruction. We performed color consistency and geometric consistency analysis for each image so as to determine the foreground and background regions and obtain the initial input, and the energy equation was constructed. The rough segmentation result was obtained by solving the equation with graph cut algorithm. We adopted Matting to refine the segmentation boundary to obtain high-quality segmentation results. The segmentation image was used to reconstruct the 3 D model of the object. The results show that the algorithm can automatically segment the foreground target of multi-view image with high accuracy and good edge. The algorithm can be used for the early image processing of 3 D reconstruction, which can greatly improve the speed of 3 D reconstruction.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=3D%20reconstruction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">3D reconstruction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Automatic%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Automatic segmentation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Graph%20cut%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Graph cut algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-view&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multi-view;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-14</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="31" name="31" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="32">多视图前景目标分割是指从来自不同视点的多个图像中分割前景对象, 其在计算机视觉中有着重要应用。在多视图立体视觉中, 为了减小时间成本, 三维重建的第一步通常就是对前景目标进行精确提取。另外, 前景目标分割也是目标跟踪的重要步骤。</p>
                </div>
                <div class="p1">
                    <p id="33">在多视图中分割前景目标最简单的方法是单独处理每幅图像, 分别分割出前景目标。一般来讲, 这类方法<citation id="151" type="reference"><link href="123" rel="bibliography" /><link href="125" rel="bibliography" /><link href="127" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>需要通过用户交互来获取如每个前景目标的边界框或前、背景涂鸦等初始输入。而基于图像的三维重建往往需要大量的图像, 大量对图像进行分割是对人力的浪费。</p>
                </div>
                <div class="p1">
                    <p id="34">用于三维重建的多视图图像具有相同的前景对象, 因此考虑利用不同输入图像之间颜色、纹理、形状等外观属性的统计相似性, 采用协同分割的思想进行多视图图像前景目标的分割<citation id="152" type="reference"><link href="129" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。Rother等<citation id="153" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出了一种基于马尔科夫随机场 (MRF) 的能量模型, 并在模型中加入匹配公共部分的外观直方图的全局约束, 通过TRGC优化对模型近似求解来实现多图像前景目标协同分割。Mukherjee等<citation id="154" type="reference"><link href="133" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>建立了类似于文献<citation id="155" type="reference">[<a class="sup">4</a>]</citation>的能量模型, 但与其不同的是, Mukherjee等通过二范式来衡量前景直方图之间的差异, 并采用二次伪布尔优化来近似求解分割结果。与文献<citation id="158" type="reference">[<a class="sup">5</a>,<a class="sup">6</a>]</citation>的惩罚模型不同, Hochbaum等<citation id="156" type="reference"><link href="135" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>建立了奖励模型。Vicente等<citation id="157" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>将能量函数进行了优化, 优化后的函数包含平滑项和全局约束, 并提出了基于Boyov-Jolly模型的扩展模型。然而, 这些方法仅在分辨率相对较低的图像中进行粗略分割, 且分割边界也不够精细, 分割出的前景目标不能满足三维重建的需求。此外, 文献<citation id="159" type="reference">[<a class="sup">6</a>,<a class="sup">7</a>]</citation>仍需根据用户交互建立先验模型。因此, 本文在先前的方法基础上进行了改进, 实现多视图前景目标自动分割。</p>
                </div>
                <div class="p1">
                    <p id="35">前景目标分割及重建方法步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="36"><b>Step 1</b> 对输入图像进行颜色、几何一致性测量;</p>
                </div>
                <div class="p1">
                    <p id="37"><b>Step 2</b> 构建基于MRF的能量函数;</p>
                </div>
                <div class="p1">
                    <p id="38"><b>Step 3</b> 利用Graph Cut迭代求解能量函数, 得到第一次分割结果;</p>
                </div>
                <div class="p1">
                    <p id="39"><b>Step 4</b> KL散度检测颜色混合区域;</p>
                </div>
                <div class="p1">
                    <p id="40"><b>Step 5</b> 对颜色混合区域使用Matting细化边界, 得到第二次分割结果;</p>
                </div>
                <div class="p1">
                    <p id="41"><b>Step 6</b> 将精细分割后的多视图照片用于三维重建得到前景物体三维模型。</p>
                </div>
                <div class="p1">
                    <p id="42">本文算法大致可分为三个阶段, 首先通过对图像进行颜色、几何一致性分析, 确定前景目标所在区域。然后构建能量方程, 方程的数据项使用多个输入图像上的颜色和几何一致性来定义的似然相似度, 平滑项使用在每个输入图像中单独定义的图像的局部结构。之后利用Graph Cut算法迭代地更新颜色和几何测量值, 初步实现前景目标分割。为了使分割更加贴近物体边界, 本文引入第二阶段算法对分割结果进一步细化, 通过评估局部像素带内的颜色分步来确定前景背景颜色混合的未知区域, 并使用Matting细化前景对象的分割边界, 得到高质量的分割结果。算法的第三阶段将以上分割的结果用于三维物体重建, 以此提高三维重建的速度。本文算法在多图像分割上避免了大量的人工交互, 能够自动从多视图图像中分割出前景目标, 即使对于高分辨率图像, 本文算法仍能获得良好的分割边缘。将该算法用于三维重建的前期图像处理, 可大大提高三维重建的速度。</p>
                </div>
                <h3 id="43" name="43" class="anchor-tag"><b>1 多视图对象分割</b></h3>
                <h4 class="anchor-tag" id="44" name="44"><b>1.1 颜色模型</b></h4>
                <div class="p1">
                    <p id="45">本文用高斯混合模型GMM为每个图像的前景和背景颜色分布构建颜色模型, 并根据颜色模型计算某像素点属于前景和背景的可能性。此外, 在构建GMM之前先使用双边滤波去除图像噪声及微小细节, 避免颜色分布的过度拟合。本文的高斯混合模型包括前景GMM和背景GMM, 定义如下:</p>
                </div>
                <div class="p1">
                    <p id="46" class="code-formula">
                        <mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>G</mi><msub><mrow></mrow><mi>f</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mn>5</mn></munderover><mi>w</mi></mstyle><msubsup><mrow></mrow><mi>f</mi><mi>c</mi></msubsup><mo>⋅</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>μ</mi><msubsup><mrow></mrow><mi>f</mi><mi>c</mi></msubsup><mo>, </mo><mi>σ</mi><msubsup><mrow></mrow><mi>f</mi><mi>c</mi></msubsup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>G</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mn>5</mn></munderover><mi>w</mi></mstyle><msubsup><mrow></mrow><mi>b</mi><mi>c</mi></msubsup><mo>⋅</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>μ</mi><msubsup><mrow></mrow><mi>b</mi><mi>c</mi></msubsup><mo>, </mo><mi>σ</mi><msubsup><mrow></mrow><mi>b</mi><mi>c</mi></msubsup><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="47">式中:<i>I</i><sub><i>k</i></sub> (<i>x</i>) 表示第<i>k</i>个输入图像中第<i>x</i>个的像素的颜色;<i>G</i><sub>f</sub>是依据前景目标颜色分布构造的颜色模型;<mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>G</mi><msub><mrow></mrow><mtext>f</mtext></msub><mo stretchy="false">) </mo></mrow></math></mathml>表示像素<i>I</i><sub><i>k</i></sub> (<i>x</i>) 是前景<i>G</i><sub>f</sub>的概率;<i>w</i><mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>f</mtext><mi>c</mi></msubsup></mrow></math></mathml>·<i>N</i> (<i>I</i><sub><i>k</i></sub> (<i>x</i>) |<i>μ</i><sup><i>c</i></sup><sub>f</sub>, <i>σ</i><sup><i>c</i></sup><sub>f</sub>) 是加权高斯分量, 其在前景标签上均值和方差分别表示为<i>μ</i><mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>f</mtext><mi>c</mi></msubsup></mrow></math></mathml>、<i>σ</i><mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>f</mtext><mi>c</mi></msubsup></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="52" name="52"><b>1.2 几何模型</b></h4>
                <div class="p1">
                    <p id="53">为了实现所有视图中一致前景目标的分割, 本文假设在所有不同视点前景对象都完全位于摄像机视野范围内。对于输入的多视图图像的每个视点, 通过检查点在图像上的投影是否在当前的前景二值分割范围内, 可以投票给假设点<i>H</i> (<i>x</i>) 。为了测量前景的几何一致性, 本文使用S型函数 (Sigmoid Function) 定义如下所示的几何模型:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>Η</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mrow><mo> (</mo><mrow><mo>-</mo><mi>λ</mi><mrow><mo> (</mo><mrow><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mfrac><mi>Κ</mi><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow><mo>) </mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">式中:<i>s</i><sub><i>k</i></sub> (<i>x</i>) =max (<i>p</i><sub><i>k</i></sub> (<i>H</i> (<i>x</i>) ) ) 是投票最高得分, <i>K</i>是输入图像的数量, 参数<i>λ</i>用于控制能量函数形状, 在本文中<i>λ</i>=20。若投票最高得分<i>s</i><sub><i>k</i></sub> (<i>x</i>) 小于<i>K</i>, 则认为此像素几何不一致。</p>
                </div>
                <h4 class="anchor-tag" id="56" name="56"><b>1.3 MRF能量方程的构造与求解</b></h4>
                <h4 class="anchor-tag" id="57" name="57"><b>1.3.1 MRF能量方程的构造</b></h4>
                <div class="p1">
                    <p id="58">第一阶段的分割目标是在多视图图像<i>I</i>={<i>I</i><sub>1</sub>, <i>I</i><sub>2</sub>, …, <i>I</i><sub><i>n</i></sub>}中, 估计前景目标的二值掩码图像<i>X</i>={<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, …, <i>X</i><sub><i>n</i></sub>}, 其中<i>n</i>表示输入图像的数量。在MRF框架中, 此阶段的分割可被表述为单一能量函数<citation id="160" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。在先前研究的基础上, 本文构造了如下能量方程:</p>
                </div>
                <div class="p1">
                    <p id="59"><i>E</i>=<i>λE</i><sub>d</sub>+<i>E</i><sub>n</sub>      (3) </p>
                </div>
                <div class="p1">
                    <p id="60">式中:<i>E</i><sub>d</sub>为能量方程的数据项, <i>E</i><sub>d</sub>=<i>ρ</i> (<i>x</i>) <i>E</i><sub>c</sub>+ (1-<i>ρ</i> (<i>x</i>) ) ·<i>E</i><sub>g</sub>。<i>E</i><sub>n</sub>为能量方程的平滑项, <i>E</i><sub>n</sub>=<i>λ</i><sub>nc</sub>·<i>E</i><sub>nc</sub>+<i>λ</i><sub>ng</sub>·<i>E</i><sub>ng</sub>。与先前研究不同的是, 本文能量方程的数据项包括颜色模型<i>E</i><sub>c</sub>和几何模型<i>E</i><sub>g</sub>。对颜色模型中概率取负对数, 可将最大后验概率估计问题转换为MRF框架中的能量最小化问题。</p>
                </div>
                <div class="p1">
                    <p id="61">数据项中参数<i>ρ</i>表示权重, 用来平衡颜色和几何一致性。</p>
                </div>
                <div class="p1">
                    <p id="62"><mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>G</mi><msub><mrow></mrow><mtext>f</mtext></msub><mo stretchy="false">) </mo><mo>-</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>G</mi><msub><mrow></mrow><mtext>b</mtext></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>G</mi><msub><mrow></mrow><mtext>f</mtext></msub><mo stretchy="false">) </mo><mo>+</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi>G</mi><msub><mrow></mrow><mtext>b</mtext></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow></mfrac></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="64">像素颜色与前景GMM和背景GMM距离接近时, 相应减小颜色模型的权重, 同时增加几何模型的权重。<i>P</i> (<i>I</i><sub><i>k</i></sub> (<i>x</i>) |<i>G</i><sub>f</sub>表示像素<i>I</i><sub><i>k</i></sub> (<i>x</i>) 是前景<i>G</i><sub>f</sub>的概率。</p>
                </div>
                <div class="p1">
                    <p id="65">平滑项用来主要体现相邻像素之间不连续的惩罚, 本文使用颜色能量<i>E</i><sub>nc</sub>和几何能量<i>E</i><sub>ng</sub>定义两个相邻节点<i>x</i><sub><i>p</i></sub>和<i>x</i><sub><i>q</i></sub>的能量, 如式 (5) 、式 (6) 所示:</p>
                </div>
                <div class="p1">
                    <p id="66"><mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>c</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>p</mi><mo>, </mo><mi>q</mi></mrow></msub><mrow><mrow><mo>|</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>q</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle><mo>⋅</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">[</mo><mo>-</mo><mi>β</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">]</mo></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="68"><mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>g</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msubsup><mrow></mrow><mi>p</mi><mi>i</mi></msubsup><mo>, </mo><mi>x</mi><msubsup><mrow></mrow><mi>q</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>p</mi><mo>, </mo><mi>q</mi></mrow></msub><mrow><mrow><mo>|</mo><mrow><mi>x</mi><msubsup><mrow></mrow><mi>p</mi><mi>i</mi></msubsup><mo>, </mo><mi>x</mi><msubsup><mrow></mrow><mi>q</mi><mi>j</mi></msubsup></mrow><mo>|</mo></mrow></mrow></mstyle><mo>⋅</mo><mtext>e</mtext><mtext>n</mtext><msub><mrow></mrow><mi>b</mi></msub></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="70">式中:参数<i>β</i>由图像的对比度决定, 图像本身对比度越低, <i>β</i>值越大, en<sub><i>b</i></sub>表示背景能量。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71"><b>1.3.2 MRF能量方程的求解</b></h4>
                <div class="p1">
                    <p id="72">本文使用图割 (Graph Cut) 算法对式 (3) 中的能量方程进行求解, 以此得到第一阶段二值分割的结果。在Graph Cut中, 图像的分割可以看作像素标记问题, 本文将前景目标和背景的标签分别设为1和0, 将最小化图割问题转换为最小化能量方程问题, 从而实现前景目标和背景的分割。</p>
                </div>
                <div class="p1">
                    <p id="73">Graph Cut分割原理如图1所示。首先使用无向图表示要分割的图像, Graph Cut图包括普通顶点和两个终端顶点, 顶点具体对应输入图像的每个像素, 图中连接两个相邻顶点的线叫做边, 每条边都有非负的权值, 在图割中可以权值可以理解为分割代价。图割的目标就是求解令边的权值之和最小时得最小割 (min cut) 。由于最小割等价与网络的最大流, 因此本文采用文献<citation id="161" type="reference">[<a class="sup">10</a>]</citation>的方法最小化能量方程, 迭代地对能量方程进行求解, 直至<i>E</i>收敛。</p>
                </div>
                <div class="area_img" id="74">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906040_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Graph Cut分割示意图" src="Detail/GetImg?filename=images/JYRJ201906040_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 Graph Cut分割示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906040_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="75" name="75" class="anchor-tag"><b>2 Matting边缘优化</b></h3>
                <div class="p1">
                    <p id="76">第一阶段通过使用Graph Cut迭代地求解能量函数, 得到初步分割结果。若将分割结果直接用于三维重建, 相对粗糙的边缘会降低三维模型的完整度, 因此引入第二阶段过程, 使用Matting<citation id="162" type="reference"><link href="143" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>将部分前景目标分割边缘进一步优化。</p>
                </div>
                <h4 class="anchor-tag" id="77" name="77"><b>2.1 模糊边界检测</b></h4>
                <div class="p1">
                    <p id="78">首先检测第一阶段分割边缘中模糊的边界, 也就是前景和背景不确定的区域。本文使用局部边界区域中的KL散度 (Kullback-Leibler divergence) 衡量前景-背景的不确定程度。局部颜色混合的效果近似于两种不同颜色的线性组合<citation id="163" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 因此使用线性模型衡量局部颜色分步的KL散度, 公式如下:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mi>L</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mi>d</mi></mstyle><mo stretchy="false"> (</mo><msup><mi>Ι</mi><mo>′</mo></msup><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>C</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mrow><mi>log</mi></mrow><mfrac><mrow><msup><mi>Ι</mi><mo>′</mo></msup><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>C</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><msup><mi>Ι</mi><mo>′</mo></msup><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>C</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">式中:<i>N</i> (<i>x</i>) 是<i>x</i>周围的局部窗口;<i>I</i>′<sub><i>k</i></sub> (<i>y</i>) 是<i>I</i><sub><i>k</i></sub> (<i>y</i>) 在局部颜色线性模型上的投影颜色;<i>d</i> (<i>I</i>′<sub><i>k</i></sub> (<i>y</i>) -<i>C</i><sub>0</sub>) 是在归一化的lαβ颜色空间中测量的欧氏距离;<i>C</i><sub>0</sub>和<i>C</i><sub>1</sub>分别是估计的局部颜色现行模型上两个终点的RGB颜色。</p>
                </div>
                <div class="p1">
                    <p id="81">沿第一阶段分割的边界均匀地采样种子点, 并使用上述线性模型衡量每个种子点局部颜色分部的KL散度。边界清晰附近的区域, 颜色样本集中在线性模型的两端, 而边界模糊的区域, 颜色样本的分布会集中在线性模型的中间。通过找到投影颜色靠近局部线性模型中间的像素, 可以检测出第一阶段分割结果中前景—背景不确定区域。</p>
                </div>
                <h4 class="anchor-tag" id="82" name="82"><b>2.2 边界优化</b></h4>
                <div class="p1">
                    <p id="83">为了能得到更精细的分割结果, 同时提高计算效率, 仅对第一阶段分割结果中前景-背景不确定区域使用Matting进行边缘优化, 求解alpha matte的目标函数:</p>
                </div>
                <div class="p1">
                    <p id="84"><i>a</i><sup>*</sup>=arg min<sub><i>α</i></sub><i>α</i><sup>T</sup><b><i>L</i></b><i>α</i>+<i>λ</i><sub>1</sub> (<i>α</i>-<i>α</i><sub>g</sub>) <sup>T</sup> (<i>α</i>-<i>α</i><sub>g</sub>) +</p>
                </div>
                <div class="p1">
                    <p id="85"><i>λ</i><sub>2</sub> (<i>α</i>-<i>α</i><sub>b</sub>) <sup>T</sup><b><i>W</i></b> (<i>α</i>-<i>α</i><sub>b</sub>)      (8) </p>
                </div>
                <div class="p1">
                    <p id="86">式中:<b><i>L</i></b>是Matting拉普拉斯矩阵;<i>α</i><sub>g</sub>是第一阶段分割结果;<i>α</i><sub>b</sub>是边界像素的约束;<b><i>W</i></b>是对角矩阵, 如果像素是边界像素, 则其输入等于1, 否则为0;<i>λ</i><sub>1</sub>、<i>λ</i><sub>2</sub>是平衡两个约束的权重。</p>
                </div>
                <h3 id="87" name="87" class="anchor-tag"><b>3 三维重建</b></h3>
                <div class="p1">
                    <p id="88">考虑到重建成本和通用性问题, 本文选取更常见的普通相机, 从多视图图像中恢复物体三维结构。三维重建方法步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="89"><b>Step 1</b> SIFT算法进行特征点检测;</p>
                </div>
                <div class="p1">
                    <p id="90"><b>Step 2</b> SIFT算法完成特征点之间的匹配;</p>
                </div>
                <div class="p1">
                    <p id="91"><b>Step 3</b> SFM技术得到稀疏点云;</p>
                </div>
                <div class="p1">
                    <p id="92"><b>Step 4</b> 通过CMVS获得稠密点云;</p>
                </div>
                <div class="p1">
                    <p id="93"><b>Step 5</b> MeshLab软件生成物体三维模型。</p>
                </div>
                <div class="p1">
                    <p id="94">将分割后的多视图图像序列作为三维重建的输入, 首先使用SIFT<citation id="164" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>检测特征点, 并在不同图像之间进行特征点的匹配。然后利用SFM技术建立三维物体的稀疏点云, 稠密点云则通过将稀疏点云输入CMVS<citation id="165" type="reference"><link href="149" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>获得, 最后使用MeshLab软件生成物体三维模型。</p>
                </div>
                <h3 id="95" name="95" class="anchor-tag"><b>4 结果及分析</b></h3>
                <div class="p1">
                    <p id="96">为了验证分割算法的有效性及其对重建结果的影响, 本文首先进行了数据的采集。数据采集使用一台相机环绕物体拍摄得到。本文所用相机的型号是 (索尼ILCE-7RM2) , 镜头型号SEL50F18, 焦距50 mm, 拍摄角度差值约20°。在无遮挡的情况下拍摄示意图如图2所示。每组数据由20张尺寸为1 200×800的图像组成。</p>
                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906040_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 拍摄示意图" src="Detail/GetImg?filename=images/JYRJ201906040_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 拍摄示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906040_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="98">为了说明分割算法的效果及不同分割算法对三维重建的影响, 本文在采集的数据上进行了测试, 并将无图像分割、利用Grab Cut算法分割以及使用本文分割算法的多视图图像及三维重建结果进行了定性与定量的比较。其中, 图3、图4是对室内物体和室外物体进行数据采集、自动分割的结果, 从左到右分别为原图、Grab Cut分割结果、本文分割结果。结果显示, 在前景后景颜色分布较为接近时, 单纯依靠Grab Cut算法难以得到良好的分割边缘, 而本文的分割算法能在无需人工交互的前提下自动分割得到完整的前景目标。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906040_09900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 室内物体分割结果" src="Detail/GetImg?filename=images/JYRJ201906040_09900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 室内物体分割结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906040_09900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906040_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 室外物体分割结果" src="Detail/GetImg?filename=images/JYRJ201906040_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 室外物体分割结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906040_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="101">图5展示了对无分割、Grab Cut方法分割、本文算法分割后的多视图图像进行三维重建的结果。由于Grab Cut算法在分割时损失了一部分的边缘信息, 导致三维重建结果不够完整。</p>
                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906040_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 采用不同方法分割后三维重建结果" src="Detail/GetImg?filename=images/JYRJ201906040_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 采用不同方法分割后三维重建结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906040_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="103">为了进一步评价本文算法, 将一组照片不分割、Grab Cut算法、本文算法分割的分割和重建总时间进行了对比, 对比结果如表1所示。对于单幅图像分割, Grab Cut平均需要14.26 s, 而本文算法平均需要12.00 s;不对图像进行任何分割, 直接进行三维重建需要耗时12 652.47 s, 使用Grab Cut分割后再重建需4 915.59 s, 本文算法分割后重建需5 568.76 s。本文算法分割后重建时间更长是由于其边缘完整, 保留了更多的特征点, 在重建结果上也可清晰地看到本文算法分割后重建结果大幅度优于Grab Cut分割再重建的结果。</p>
                </div>
                <div class="area_img" id="104">
                    <p class="img_tit"><b>表1 分割和重建消耗时间对比 </b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">s</p>
                    <table id="104" border="1"><tr><td>算法</td><td>图像分割</td><td>三维重建</td><td>总和</td></tr><tr><td><br />不分割</td><td>0</td><td>12 652.47</td><td>12 652.47</td></tr><tr><td><br />GrabCut</td><td>287.15</td><td>4 915. 59</td><td>5 232.74</td></tr><tr><td><br />本文算法</td><td>241.84</td><td>5 568.76</td><td>6 810.60</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="105" name="105" class="anchor-tag"><b>5 结 语</b></h3>
                <div class="p1">
                    <p id="106">图像分割作为图像处理的基础, 在计算机视觉领域有着不可忽视的作用。如仍采用人工交互方式进行多视图图像的前景目标分割, 过程过于繁琐且浪费人力。本文提出一种用于三维重建的前景目标自动分割算法, 首先根据图像序列的颜色一致性和几何一致性, 确定前景后景大致区域, 并以此构建能量方程, 用Graph Cut求解能量方程得到粗略分割结果;然后使用Matting细化分割边界, 得到高质量的分割结果;最后使用分割后图片重建出物体三维模型。实验表明, 本文提出的分割算法速度快、分割质量高、无需人工交互, 将本文分割算法用于三维重建前期图像处理, 可在大幅度缩短三维重建时间的同时, 获得与不分割时精度相当的三维模型。</p>
                </div>
                <div class="p1">
                    <p id="107">今后的研究将考虑将多视图图像前景自动分割和物体三维重建集成在同一程序内, 实现自动的基于序列图像的物体三维重建。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="123">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interactive image segmentation using adaptive constraint propagation">

                                <b>[1]</b> Jian M, Jung C.Interactive Image Segmentation Using Adaptive Constraint Propagation.[J].IEEE Transactions on Image Processing, 2016, 25 (3) :1301-1311.
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs[EB]">

                                <b>[2]</b> Wang T C, Liu M Y, Zhu J Y, et al.High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs[EB].arXiv:1711.11585, 2017.
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201608048&amp;v=MTEyMzJwNDlCYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2bVZMM0xMelRaWkxHNEg5Zk0=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 高理文, 林小桦, 罗晓牧.结合简单交互和标记分水岭的复杂背景叶片图像分割方法[J].计算机应用与软件, 2016, 33 (8) :211-215, 241.
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiple random walkers and their application to image cosegmentation">

                                <b>[4]</b> Lee C, Jang W D, Sim J Y, et al.Multiple Random Walkers and Their Application to Image Cosegmentation[C]//2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .IEEE, 2015.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cosegmentation of Image Pairs by Histogram Matching—Incorporating a Global Constraint into MRFs">

                                <b>[5]</b> Rother C, Minka T, Blake A, et al.Cosegmentation of Image Pairs by Histogram Matching—Incorporating a Global Constraint into MRFs[C]//Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.IEEE, 2006.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Half-integrality based algorithms for cosegmentation of images">

                                <b>[6]</b> Mukherjee L, Singh V, Dyer C R.Half-integrality based algorithms for cosegmentation of images[C]//2009 IEEE Conference on Computer Vision and Pattern Recognition.IEEE, 2009.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An efficient algorithm for Co-segmentation">

                                <b>[7]</b> Hochbaum D S, Singh V.An efhcient algorithm for co-segmentation[C]//Proceedings of International Conference on Computer Vision (ICCV) , 2009.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cosegmentation revisited:models and optimization">

                                <b>[8]</b> Vicente S, Kolmogorov V, Rother C.Cosegmentation Revisited:Models and Optimization[C]//European Conference on Computer Vision.Springer-Verlag, 2010.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098096&amp;v=MjExNDBJMTBUYUJFPU5pZklZN0s3SHRqTnI0OUZaT0lIREhVL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Li Y, Jian S, Tang C K, et al.Lazy Snapping[J].Acm Transactions on Graphics, 2004, 23 (3) :303-308.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Secrets of GrabCut and Kernel K-means">

                                <b>[10]</b> Meng T, Ayed I B, Marin D, et al.Secrets of GrabCut and Kernel K-Means[C]//IEEE International Conference on Computer Vision.2016.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparse coding for alpha matting">

                                <b>[11]</b> Johnson J, Varnousfaderani E S, Cholakkal H, et al.Sparse Coding for Alpha Matting[J].IEEE Transactions on Image Processing, 2016, 25 (7) :3032-3043.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A closed form solution to natural image matting">

                                <b>[12]</b> Levin A, Weiss Y.A closed form solution to natural image matting[C]//IEEE Computer Society Conference on Computer Vision &amp; Pattern Recognition.IEEE Computer Society, 2006.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MDk3MzhIT3A0eEZiZXNPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaXZsVUx6UElsMD1OajdCYXJPNEh0&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Lowe D G.Distinctive Image Features from Scale-Invariant Keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Piecewise-Planar StereoScan:Sequential Structure and Motion Using Plane Primitives">

                                <b>[14]</b> Raposo C, Antunes M, Barreto J A P.Piecewise-Planar StereoScan:Sequential Structure and Motion Using Plane Primitives[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2018, 40 (8) :1918-1931.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201906040" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201906040&amp;v=MDE0NjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXZtVkwzTEx6VFpaTEc0SDlqTXFZOUJaSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
