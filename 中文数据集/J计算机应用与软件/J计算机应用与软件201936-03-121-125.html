<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135822876065000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201903024%26RESULT%3d1%26SIGN%3dL5dWyKy3rWRICO3DkVE3cCKasRM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201903024&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201903024&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201903024&amp;v=MjE5NDU3cWZadVp0Rnk3bFdyL01MelRaWkxHNEg5ak1ySTlIWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;1 字典学习理论&lt;/b&gt; "><b>1 字典学习理论</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="&lt;b&gt;1.1 稀疏编码阶段&lt;/b&gt;"><b>1.1 稀疏编码阶段</b></a></li>
                                                <li><a href="#48" data-title="&lt;b&gt;1.2 字典更新阶段&lt;/b&gt;"><b>1.2 字典更新阶段</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#72" data-title="&lt;b&gt;2 实验步骤&lt;/b&gt; "><b>2 实验步骤</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#75" data-title="&lt;b&gt;2.1 数据来源与预处理&lt;/b&gt;"><b>2.1 数据来源与预处理</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;2.2 特征提取&lt;/b&gt;"><b>2.2 特征提取</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;2.3 SVM分类&lt;/b&gt;"><b>2.3 SVM分类</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#90" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#98" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#74" data-title="图1 实验流程图">图1 实验流程图</a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;表1 实验数据样本划分结果&lt;/b&gt;"><b>表1 实验数据样本划分结果</b></a></li>
                                                <li><a href="#82" data-title="图2 训练字典过程">图2 训练字典过程</a></li>
                                                <li><a href="#84" data-title="图3 时间序列">图3 时间序列</a></li>
                                                <li><a href="#85" data-title="图4 提取的特征">图4 提取的特征</a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;表2 字典学习分类结果&lt;/b&gt;"><b>表2 字典学习分类结果</b></a></li>
                                                <li><a href="#93" data-title="图5 分类的ROC曲线">图5 分类的ROC曲线</a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;表3 本文以其他方法分类结果的对比&lt;/b&gt;"><b>表3 本文以其他方法分类结果的对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Itani S, Lecron F, Fortemps P. A multi-level classification framework for multi-site medical data: application to the ADHD- 200 collection[J]. Expert Systems with Applications, 2017, 91:36-45." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A multi-level classification framework for multi-site medical data: application to the ADHD- 200 collection">
                                        <b>[1]</b>
                                         Itani S, Lecron F, Fortemps P. A multi-level classification framework for multi-site medical data: application to the ADHD- 200 collection[J]. Expert Systems with Applications, 2017, 91:36-45.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Riaz A, Asad M, Alonso E, et al. Fusion of fMRI and non-imaging data for ADHD classification[J]. Computerized Medical Imaging &amp;amp; Graphics the Official Journal of the Computerized Medical Imaging Society, 2017, 65:115-128." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fusion of fMRI and non-imaging data for ADHD classification">
                                        <b>[2]</b>
                                         Riaz A, Asad M, Alonso E, et al. Fusion of fMRI and non-imaging data for ADHD classification[J]. Computerized Medical Imaging &amp;amp; Graphics the Official Journal of the Computerized Medical Imaging Society, 2017, 65:115-128.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Sato J R, Hoexter M Q, Fujita A, et al. Evaluation of pattern recognition and feature extraction methods in ADHD prediction[J].Frontiers in Systems Neuroscience, 2012, 6 (4) :68-82." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Evaluation of pattern recognition and feature extraction methods in ADHD prediction">
                                        <b>[3]</b>
                                         Sato J R, Hoexter M Q, Fujita A, et al. Evaluation of pattern recognition and feature extraction methods in ADHD prediction[J].Frontiers in Systems Neuroscience, 2012, 6 (4) :68-82.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Dai D, Wang J, Jing H, et al. Classification of ADHD children through multimodal magnetic resonance imaging[J]. Front Syst Neurosci, 2012, 6:63-71." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classification of ADHD children through multimodal magnetic resonance imaging">
                                        <b>[4]</b>
                                         Dai D, Wang J, Jing H, et al. Classification of ADHD children through multimodal magnetic resonance imaging[J]. Front Syst Neurosci, 2012, 6:63-71.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Dey S, Rao A R, Shah M. Attributed graph distance measure for automatic detection of attention deficit hyperactive disordered subjects[J]. Frontiers in Neural Circuits, 2014, 8: 64." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attributed graph distance measure for automatic detection of attention deficit hyperactive disordered subjects">
                                        <b>[5]</b>
                                         Dey S, Rao A R, Shah M. Attributed graph distance measure for automatic detection of attention deficit hyperactive disordered subjects[J]. Frontiers in Neural Circuits, 2014, 8: 64.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 谭颖, 张涛, 谭睿, 等.基于小波变换与SVM的ADHD病人分类[J].电子科技大学学报, 2015, 44 (5) :789-794." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DKDX201505026&amp;v=MDk3ODFTYlBkckc0SDlUTXFvOUhZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeTdsV3IzUEk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         谭颖, 张涛, 谭睿, 等.基于小波变换与SVM的ADHD病人分类[J].电子科技大学学报, 2015, 44 (5) :789-794.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Heuvel M P V D, Pol H E H. Exploring the brain network: A review on resting-state fMRI functional connectivity[J]. Eur Neuropsychopharmacol, 2010, 20 (8) :519-534." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501921802&amp;v=MjY1MDRGaW5sVXJ6SUpsNGRhQlU9TmlmT2ZiSzdIdEROcW85RWJla09CSHc3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Heuvel M P V D, Pol H E H. Exploring the brain network: A review on resting-state fMRI functional connectivity[J]. Eur Neuropsychopharmacol, 2010, 20 (8) :519-534.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Daubechies I, Roussos E, Takerkart S, et al. Independent component analysis for brain fMRI does not select for independence.[J]. Proceedings of the National Academy of Sciences of the United States of America, 2009, 106 (26) :10415-10422." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Independent component analysis for brain fMRI does not select for independence">
                                        <b>[8]</b>
                                         Daubechies I, Roussos E, Takerkart S, et al. Independent component analysis for brain fMRI does not select for independence.[J]. Proceedings of the National Academy of Sciences of the United States of America, 2009, 106 (26) :10415-10422.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Eavani H, Filipovych R, Davatzikos C, et al. Sparse dictionary learning of resting state fMRI networks[C]//International Workshop on Pattern Recognition in Neuroimaging. IEEE, 2012:73-76." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparse dictionary learning of resting state fMRI networks">
                                        <b>[9]</b>
                                         Eavani H, Filipovych R, Davatzikos C, et al. Sparse dictionary learning of resting state fMRI networks[C]//International Workshop on Pattern Recognition in Neuroimaging. IEEE, 2012:73-76.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Li Y F, Feng X C. Coupled dictionary learning method for image decomposition[J]. Science China (Information Sciences) , 2013, 56 (3) :1-10." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13062800021671&amp;v=MTIzOTJaT2tPQ25zNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUpsNGRhQlU9Tmo3QmFySzdIdGZPcDQ5Rg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Li Y F, Feng X C. Coupled dictionary learning method for image decomposition[J]. Science China (Information Sciences) , 2013, 56 (3) :1-10.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Hu J, Tan Y P. Nonlinear dictionary learning with application to image classification[J]. Pattern Recognition, 2017, 75: 282-291." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinear dictionary learning with application to image classification">
                                        <b>[11]</b>
                                         Hu J, Tan Y P. Nonlinear dictionary learning with application to image classification[J]. Pattern Recognition, 2017, 75: 282-291.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Varoquaux G, Gramfort A, Pedregosa F, et al. Multi-subject dictionary learning to segment an atlas of brain spontaneous activity[M]//Information Processing in Medical Imaging. Springer Berlin Heidelberg, 2011:562-573." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-subject dictionary learning to segment an atlas of brain spontaneous activity">
                                        <b>[12]</b>
                                         Varoquaux G, Gramfort A, Pedregosa F, et al. Multi-subject dictionary learning to segment an atlas of brain spontaneous activity[M]//Information Processing in Medical Imaging. Springer Berlin Heidelberg, 2011:562-573.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Bellec P, Chu C, Chouinard-Decorte F, et al. The Neuro Bureau ADHD- 200 Preprocessed repository[J]. Neuroimage, 2016, 144 (Pt B) :275-186." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Neuro Bureau ADHD- 200 Preprocessed repository">
                                        <b>[13]</b>
                                         Bellec P, Chu C, Chouinard-Decorte F, et al. The Neuro Bureau ADHD- 200 Preprocessed repository[J]. Neuroimage, 2016, 144 (Pt B) :275-186.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" HD- 200 Consortium. The ADHD- 200 Consortium: A Model to Advance the Translational Potential of Neuroimaging in Clinical Neuroscience[J].Frontiers in Systems Neuroscience, 2012, 6:62." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The ADHD- 200 Consortium: A Model to Advance the Translational Potential of Neuroimaging in Clinical Neuroscience">
                                        <b>[14]</b>
                                         HD- 200 Consortium. The ADHD- 200 Consortium: A Model to Advance the Translational Potential of Neuroimaging in Clinical Neuroscience[J].Frontiers in Systems Neuroscience, 2012, 6:62.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Xue T, Bai L, Chen S, et al. Neural specificity of acupuncture stimulation from support vector machine classification analysis[J]. Magnetic Resonance Imaging, 2011, 29 (7) :943-950." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100393926&amp;v=MzI2ODVNbndaZVp0RmlubFVyeklKbDRkYUJVPU5pZk9mYks3SHRET3JvOUZaK0lNQlg0L29CTVQ2VDRQUUgvaXJSZEdlcnFRVA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Xue T, Bai L, Chen S, et al. Neural specificity of acupuncture stimulation from support vector machine classification analysis[J]. Magnetic Resonance Imaging, 2011, 29 (7) :943-950.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(03),121-125 DOI:10.3969/j.issn.1000-386x.2019.03.023            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>fMRI在注意缺陷多动障碍症的应用</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%A5%A0&amp;code=14287400&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李楠</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%8A%B3%E8%8A%B3&amp;code=24744299&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张芳芳</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%AA%E5%8E%9F%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0077528&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">太原理工大学信息与计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>注意缺陷多动障碍ADHD (Attention Deficit Hyperactivity Disorder) 是一种常见的心理障碍疾病。针对静息态功能磁共振rs-fMRI (Rest state-functional magnetic resonance imaging) 成像的ADHD分类问题, 提出一种基于字典学习的特征提取方法对ADHD病人与正常人进行分类。利用字典学习对训练样本提取不同的成分因素, 得到一个四维脑图像;用参数矢量化将脑图像的时间序列转化为一维数组, 得到ADHD病人和正常人的特征;利用支持向量机 (SVM) 进行分类。实验结果显示, 基于字典学习的特征提取的方法得到的平均分类准确率达到77.60%, 表明该方法有助于对ADHD病人与正常人的分类, 为ADHD病人与正常人分类的研究提供了一种方法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ADHD&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ADHD;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=rs-fMRI&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">rs-fMRI;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AD%97%E5%85%B8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">字典学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SVM&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SVM;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李楠, 硕士生, 主研领域:功能磁共振成像的应用, 机器学习。;
                                </span>
                                <span>
                                    张芳芳, 硕士生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-02</p>

            </div>
                    <h1><b>APPLICATION OF FMRI IN ATTENTION DEFICIT HYPERACTIVITY DISORDER</b></h1>
                    <h2>
                    <span>Li Nan</span>
                    <span>Zhang Fangfang</span>
            </h2>
                    <h2>
                    <span>College of Information and Computer Science, Taiyuan University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Attention deficit hyperactivity disorder (ADHD) is a common mental disorder. Aiming at the classification of ADHD in rest state-functional magnetic resonance imaging (rs-fMRI) , we proposed a feature extraction based on dictionary learning to classify ADHD patients and normal people. Dictionary learning was used to extract different components from training samples, and a four-dimensional brain image was obtained. Then we used parameter vectorization to transform the time series of brain images into a one-dimensional array, and got the characteristics of ADHD patients and normal people, and used SVM to classify them. The experimental results show that the average classification accuracy of the feature extraction based on dictionary learning is 77.60%. The method is helpful for the classification of ADHD patients and normal people, and provides a method for the study of the classification of ADHD patients and normal people.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ADHD&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ADHD;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=rs-fMRI&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">rs-fMRI;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Dictionary%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Dictionary learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SVM&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SVM;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-02</p>
                            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="34">ADHD是一种常见的神经发育和精神障碍疾病<citation id="100" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 主要症状有注意力不集中、注意时间短暂、活动过度等, 如果不及时诊断和治疗, 会影响患者学业、身心健康及以后的家庭生活和社交能力。目前, ADHD的发病机制尚未完全了解, 其诊断主要依赖于行为分析<citation id="101" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 其诊断方法用2000年美国提出第四版DSM (Diagnostic and Statistical Manual of Mental Disorders) 测评表进行诊断, 由1～100分进行测评, 这种方法误诊、漏诊率比较高, 为了提高ADHD的诊断率, 近年来ADHD分类研究就成了神经影像领域的一个研究热点<citation id="102" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。rs-fMRI是一种神经影像学方式, 且基于rs-fMRI神经影像的数据研究精神疾病的分类方法已经开展了很多研究, rs-fMRI技术已广泛应用于脑的基础研究和临床诊断。</p>
                </div>
                <div class="p1">
                    <p id="35">目前, 已有大量研究者对ADHD展开研究而且取得了较多的科研成果, 研究主要集中在以下两个方面: (1) 通过脑功能网络对ADHD进行分类, 2012年Dai等<citation id="103" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出了功能连接的方法对ADHD进行分类, 得到的分类结果为65.87%;2014年Dey等<citation id="104" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>构建脑功能网络的方法对ADHD进行分类, 得到的分类结果为72.55%, 分类结果有明显提高, 但是上述方法构造脑功能网络后均需要进行特征选择、降维, 最后结合分类器进行分类, 实验过程复杂, 需要耗费更多的时间。 (2) 通过特征提取与分类器结合进行分类, 2015年谭颖等<citation id="105" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了基于小波变换与SVM的方法对ADHD进行分类, 得到的分类结果为62.7%, 这类方法实验过程简单, 耗费时间短, 但是这类方法的分类结果可以进一步提高, 为ADHD病人的研究提供更有效的方法。</p>
                </div>
                <div class="p1">
                    <p id="36">针对上述问题, 近年来, 很多学者用ICA (Independent Component Correlation Algorithm) 的方法研究rs-fMRI数据, 但是ICA算法用于rs-fMRI数据存在局限性。首先, 无论是在时间还是空间上, ICA是基于成分因素的独立性假设, 违反了这些假设, ICA的性能就会降低<citation id="106" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>;其次, ICA成功用于rs-fMRI数据是由于其处理稀疏分量<citation id="107" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。字典学习算法因其具有更稀疏的表示而受到学者的关注和研究<citation id="108" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 所以本文提出了字典学习的特征提取方法对ADHD病人与正常人进行分类。字典学习算法在图像去噪、图像修复、面部识别<citation id="109" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、图像分类<citation id="110" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>等领域有广泛的应用, 且发展前景广阔。为了将字典学习算法应用到神经影像领域中, 本文利用字典学习对rs-fMRI进行特征提取, 最后用分类算法SVM对其进行分类。字典学习特征提取的方法比ICA提取的特征更稳定, 与其他方法相比, 耗费的时间也比较短, 而且得到的分类结果优于其他方法。实验结果证明了字典学习特征提取方法有助于对ADHD的分类, 对ADHD的分类研究提供了一种新方法。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag"><b>1 字典学习理论</b></h3>
                <div class="p1">
                    <p id="38">字典学习的最终目的是通过训练数据找到我们所需要的字典, 字典对特征提取有至关重要的作用, 本文通过rs-fMRI数据训练出一个理想的字典, 并以最小重构误差为准则求出稀疏表示, 即得到rs-fMRI数据的稀疏分量。求得字典和稀疏表示的的原理如下:</p>
                </div>
                <div class="p1">
                    <p id="39">字典学习<citation id="111" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>的目的是把<b><i>Y</i></b>矩阵分解成<b><i>D</i></b>和<b><i>X</i></b>矩阵:<b><i>Y</i>≈<i>D</i>×<i>X</i></b>, 即给定一组信号<b><i>Y</i></b>=[<i>Y</i><sub>1</sub>, <i>Y</i><sub>2</sub>, …, <i>Y</i><sub><i>N</i></sub>], 我们的目标是找到一组信号<b><i>Y</i></b>的线性表示:[<i>Y</i><sub>1</sub>, <i>Y</i><sub>2</sub>, …, <i>Y</i><sub><i>N</i></sub>]≈<b><i>D</i></b>[<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, …, <i>X</i><sub><i>N</i></sub>], <b><i>D</i></b>称为字典, <b><i>X</i></b>为稀疏编码, 且稀疏编码<b><i>X</i></b>要尽可能稀疏, 字典<b><i>D</i></b>的每一列都是一个归一化向量, 字典学习的目标函数为:</p>
                </div>
                <div class="p1">
                    <p id="40"><mathml id="41"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">{</mo><mi mathvariant="bold-italic">D</mi><mo>, </mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">}</mo><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>D</mi><mo>, </mo><mi>X</mi></mrow></munder><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Y</mi><mo>-</mo><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">X</mi></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mrow><mo>|</mo><mi mathvariant="bold-italic">X</mi><mo>|</mo></mrow><msub><mrow></mrow><mn>0</mn></msub><mo>≤</mo><mi>L</mi></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="42">式中:<i>L</i>为稀疏度约束参数。因为式 (1) 中有两个未知变量<b><i>D</i>、<i>X</i></b>, 所以其求解方法是先固定字典<b><i>D</i></b>, 再去最小化稀疏编码<b><i>X</i></b>。这样交替更新字典<b><i>D</i></b>和稀疏编码<b><i>X</i></b>, 直到满足迭代终止条件为止, 得到的<b><i>D</i></b>和<b><i>X</i></b>即为我们所求解的<b><i>D</i></b>和<b><i>X</i></b>。所以字典学习包括两个阶段, 稀疏编码阶段和字典更新阶段。</p>
                </div>
                <h4 class="anchor-tag" id="43" name="43"><b>1.1 稀疏编码阶段</b></h4>
                <div class="p1">
                    <p id="44">假设稀疏参数<b><i>X</i></b>=[<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, …, <i>X</i><sub><i>N</i></sub>], 字典<b><i>D</i></b>=[<i>d</i><sub>1</sub>, <i>d</i><sub>2</sub>, …, <i>d</i><sub><i>k</i></sub>], 我们的目的是根据字典<b><i>D</i></b>使得<b><i>X</i></b>尽量稀疏, 由式 (1) 得:</p>
                </div>
                <div class="p1">
                    <p id="45"><mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><mrow><mi>min</mi></mrow><msub><mrow></mrow><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mrow><mo>|</mo><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">D</mi><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mrow><mo>|</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>0</mn></msub><mo>≤</mo><mi>l</mi></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="47">式中:<i>i</i>=1, 2, …, <i>N</i>, <i>l</i>为稀疏度约束参数。</p>
                </div>
                <h4 class="anchor-tag" id="48" name="48"><b>1.2 字典更新阶段</b></h4>
                <div class="p1">
                    <p id="49">通过稀疏编码阶段, 我们已经知道样本的编码<b><i>X</i></b>, 然后交替更新字典和编码。我们根据逐列更新的方法更新字典, 如果我们现在更新到字典的第<i>k</i>列<i>d</i><sub><i>k</i></sub>, 编码矩阵<b><i>X</i></b>对应的第<i>k</i>行<i>x</i><sub><i>k</i></sub>、<i>d</i><sub><i>k</i></sub>和<i>x</i><sub><i>k</i></sub>分别为:</p>
                </div>
                <div class="p1">
                    <p id="50"><mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mfrac><mrow><mi>E</mi><msub><mrow></mrow><mi>k</mi></msub><mi>x</mi><msubsup><mrow></mrow><mi>k</mi><mrow><mtext>r</mtext><mtext>o</mtext><mtext>w</mtext><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></msubsup></mrow><mrow><mrow><mo>|</mo><mrow><mi>E</mi><msub><mrow></mrow><mi>k</mi></msub><mi>x</mi><msubsup><mrow></mrow><mi>k</mi><mrow><mtext>r</mtext><mtext>o</mtext><mtext>w</mtext><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></msubsup></mrow><mo>|</mo></mrow></mrow></mfrac><msub><mrow></mrow><mn>2</mn></msub></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="52"><mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><msubsup><mrow></mrow><mi>k</mi><mrow><mtext>r</mtext><mtext>o</mtext><mtext>w</mtext></mrow></msubsup><mo>=</mo><mrow><mi>sgn</mi></mrow><mo stretchy="false"> (</mo><mi>d</mi><msubsup><mrow></mrow><mi>k</mi><mtext>Τ</mtext></msubsup><mi>E</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo><mo>⋅</mo><mrow><mo> (</mo><mrow><mrow><mo>|</mo><mrow><mi>d</mi><msubsup><mrow></mrow><mi>k</mi><mtext>Τ</mtext></msubsup><mi>E</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>|</mo></mrow><mo>-</mo><mfrac><mi>α</mi><mn>2</mn></mfrac><mn>1</mn><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><mo stretchy="false">) </mo></mrow><mtext>Τ</mtext></msubsup></mrow><mo>) </mo></mrow><msub><mrow></mrow><mo>+</mo></msub></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="54">式中:<mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mi>i</mi><mo>≠</mo><mi>k</mi></mrow><mi>Κ</mi></munderover><mi>d</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mtext>r</mtext><mtext>o</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="56" name="56"><b>1.2.1</b> 构造残差向量</h4>
                <div class="p1">
                    <p id="57">首先用<i>x</i><sub><i>i</i></sub>和<i>d</i><sub><i>i</i></sub>相乘重构出数据, 然后计算出残差向量:</p>
                </div>
                <div class="p1">
                    <p id="58"><mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">E</mi><msub><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>=</mo><mi>Y</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mi>i</mi><mo>≠</mo><mi>k</mi></mrow><mi>Κ</mi></munderover><mi>d</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msubsup><mrow></mrow><mrow><mi>i</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mrow><mtext>r</mtext><mtext>o</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="60">式中:<i>j</i>=1, 2, …, <i>N</i>, <b><i>E</i></b><sub><i>k</i><sub><i>j</i></sub></sub>为第<i>j</i>列的残差向量, 由式 (5) 可以得出每列的残差向量, 所以最后构造出的残差向量为:</p>
                </div>
                <div class="p1">
                    <p id="61"><b><i>E</i></b><sub><i>k</i></sub>=[<b><i>E</i></b><sub><i>k</i><sub>1</sub></sub>, <b><i>E</i></b><sub><i>k</i><sub>2</sub></sub>, …, <b><i>E</i></b><sub><i>k</i><sub><i>N</i></sub></sub>]      (6) </p>
                </div>
                <h4 class="anchor-tag" id="62" name="62"><b>1.2.2</b> 更新字典</h4>
                <div class="p1">
                    <p id="63">由式 (3) 、式 (4) 和式 (5) 得:</p>
                </div>
                <div class="p1">
                    <p id="64"><mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><msubsup><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mrow><mtext>r</mtext><mtext>o</mtext><mtext>w</mtext></mrow></msubsup><mo>=</mo><mrow><mi>sgn</mi></mrow><mo stretchy="false"> (</mo><mi>d</mi><msubsup><mrow></mrow><mi>k</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">E</mi><msub><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo stretchy="false">) </mo><mo>⋅</mo><mrow><mo> (</mo><mrow><mrow><mo>|</mo><mrow><mi>d</mi><msubsup><mrow></mrow><mi>k</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">E</mi><msub><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub></mrow><mo>|</mo></mrow><mo>-</mo><mfrac><mi>α</mi><mn>2</mn></mfrac><mn>1</mn><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><mo stretchy="false">) </mo></mrow><mtext>Τ</mtext></msubsup></mrow><mo>) </mo></mrow><msub><mrow></mrow><mo>+</mo></msub></mrow></math></mathml>      (7) </p>
                </div>
                <div class="area_img" id="124">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201903024_12400.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="68">iter=iter+1      (9) </p>
                </div>
                <div class="p1">
                    <p id="69">当<image id="70" type="formula" href="images/JYRJ201903024_07000.jpg" display="inline" placement="inline"><alt></alt></image>时, 重复式 (7) 、式 (8) 、式 (9) , 直到满足<image id="71" type="formula" href="images/JYRJ201903024_07100.jpg" display="inline" placement="inline"><alt></alt></image>时, 迭代终止, <i>ε</i>为重构误差允许的最大值, 最后得出稀疏编码<b><i>X</i></b>和字典<b><i>D</i></b>。</p>
                </div>
                <h3 id="72" name="72" class="anchor-tag"><b>2 实验步骤</b></h3>
                <div class="p1">
                    <p id="73">实验步骤分为三步: (1) 数据的获取及训练集和测试集的划分; (2) 用字典学习算法进行特征提取; (3) 利用SVM分类进行分类, 具体的流程框图如图1所示。</p>
                </div>
                <div class="area_img" id="74">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903024_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 实验流程图" src="Detail/GetImg?filename=images/JYRJ201903024_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 实验流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903024_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>2.1 数据来源与预处理</b></h4>
                <div class="p1">
                    <p id="76">本文研究的rs-fMRI数据来自Neuro Bureau<citation id="112" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提供的预处理ADHD- 200<citation id="113" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>全球竞赛数据集中北京大学的数据集。数据库共有244个被试, 其中ADHD被试101人, 健康被试143人, 所有被试均为右利手, 平均年龄为12岁, 智力水平在80分以上, 且没有神经系统疾病、精神分裂症、发育障碍、情感障碍及药物依赖。本文选择数据库里所有的被试进行实验。实验数据的预处理步骤包括运动校正、时间层校正、配准、高斯平滑及被试间的配准<citation id="114" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="77">在实验中, 将数据集划分为训练样本和测试样本, 实验数据样本划分结果如表1所示。</p>
                </div>
                <div class="area_img" id="78">
                    <p class="img_tit"><b>表1 实验数据样本划分结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="78" border="1"><tr><td>实验</td><td>样本</td><td>被试个数</td><td>正常被试</td><td>ADHD被试</td></tr><tr><td rowspan="2"><br />实验一</td><td><br />训练</td><td>220</td><td>127</td><td>93</td></tr><tr><td><br />测试</td><td>24</td><td>17</td><td>7</td></tr><tr><td rowspan="2"><br />实验二</td><td><br />训练</td><td>200</td><td>114</td><td>86</td></tr><tr><td><br />测试</td><td>44</td><td>31</td><td>13</td></tr><tr><td rowspan="2"><br />实验三</td><td><br />训练</td><td>190</td><td>105</td><td>85</td></tr><tr><td><br />测试</td><td>54</td><td>38</td><td>16</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>2.2 特征提取</b></h4>
                <div class="p1">
                    <p id="80">在rs-fMRI的研究中, 特征提取过程对分类准确率有重要影响。本文采用字典学习提取成分因素的方法进行特征提取。</p>
                </div>
                <div class="p1">
                    <p id="81">首先对字典进行初始化, 即对字典函数的参数进行设置, 其中稀疏度为1, 字典迭代20次, 最重要的是设置成分因素, 通过提取不同的成分因素对结果的影响, 最终在实验中选择提取13个成分因素。这些成分因素分别对应若干个体素, 然后用划分好的训练样本对字典进行训练, 最终得到稀疏矩阵<b><i>X</i></b>。图2为训练字典的过程。</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903024_082.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 训练字典过程" src="Detail/GetImg?filename=images/JYRJ201903024_082.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 训练字典过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903024_082.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="83">稀疏矩阵<b><i>X</i></b>包含提取13个成分因素, 每个成分因素又包含63 061个体素, 即X=[13, 63 061], 将所有体素映射到MNI (Montreal Neurological Institute) 标准模板上, 得到一个包含所有体素的四维脑图像。将包含所有体素的四维脑图像与每个被试对象进行拟合, 得到每个被试对象的时间序列, 由于得到的时间序列包含13个成分因素, 不能直接进行分类, 所以通过参数矢量化 (vectorize=ture) 将每个被试对象的时间序列转化为一维数组, 得到的一维数组即为提取的每个被试对象的特征。其中一个被试对象的时间序列如图3所示, 一个被试对象提取的特征如图4所示。图3和图4为同一个被试对象。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903024_084.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 时间序列" src="Detail/GetImg?filename=images/JYRJ201903024_084.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 时间序列  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903024_084.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903024_085.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 提取的特征" src="Detail/GetImg?filename=images/JYRJ201903024_085.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 提取的特征  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903024_085.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="86" name="86"><b>2.3 SVM分类</b></h4>
                <div class="p1">
                    <p id="87">由于rs-fMRI数据是线性可分的<citation id="116" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>, 所以本文选择线性SVM分类器<citation id="117" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>进行分类, 惩罚参数<i>C</i>=1。在SVM分类之前, 首先把ADHD病人的类别标签labels标记为1, 正常人的类别标签标labels标记为0, 每个被试分别对应一个特征向量和一个类别标签labels。然后将特征向量和类别标签labels输入到SVM分类器进行分类。最后用特异性、灵敏度、分类准确率以及ROC (receiver operating characteristic) 曲线来量化分类器的性能。各个性能指标的计算方法如下:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>S</mi><mi>Ν</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac></mtd></mtr><mtr><mtd><mi>S</mi><mi>Ρ</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ν</mi></mrow><mrow><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac></mtd></mtr><mtr><mtd><mi>A</mi><mi>C</mi><mi>C</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac></mtd></mtr><mtr><mtd><mi>F</mi><mi>Ρ</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>Ρ</mi></mrow><mrow><mi>F</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi></mrow></mfrac></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">式中:<i>SN</i>为灵敏度, 也称真阳性率, 指正确判断ADHD病人的程度, 即实际有病且被正确诊断的百分比;<i>SP</i>为特异性, 指正确判断正常人的程度, 即实际无病且被正确诊断为无病的百分比;<i>ACC</i>为分类准确率, 即正确判断所有被试的程度;<i>TP</i>为真阳性个数, 即ADHD病人正确分类的个数;<i>TN</i>真阴性个数, 即正常被试正确分类的个数;<i>FP</i>假阳性个数, 即正常被试错误分类的个数;<i>FN</i>假阴性个数, 即ADHD病人错误分类的个数;<i>FPR</i>为假阳性率。ROC曲线的横坐标为FPR, 纵坐标为SN, 曲线下的面积可以反映分类器的性能, 面积越大, 分类器的性能越好<citation id="118" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。</p>
                </div>
                <h3 id="90" name="90" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="91">为了排除单次实验结果的偶然性及训练集和测试集的划分影响实验结果的真实性, 本文将数据集划分为训练集和测试集, 分别进行三次实验, 实验一的测试集为24个被试对象, 实验二的测试集为44个被试对象, 实验三的测试集为54个被试对象, 对三次实验的结果进行均值化得到最终的分类准确率。用字典学习分别对训练集提取特征, 然后利用参数矢量化将提取的特征转化为一维数组, 最后利用SVM分类器对一维数组进行分类, 字典学习的分类结果如表2所示, 分类的ROC曲线如图5所示。</p>
                </div>
                <div class="area_img" id="92">
                    <p class="img_tit"><b>表2 字典学习分类结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">%</p>
                    <p class="img_note"></p>
                    <table id="92" border="1"><tr><td><br />实验</td><td>特异性</td><td>灵敏度</td><td>分类准确率</td></tr><tr><td><br />实验一</td><td>94.11</td><td>57.14</td><td>83.33</td></tr><tr><td><br />实验二</td><td>93.54</td><td>38.46</td><td>77.27</td></tr><tr><td><br />实验三</td><td>86.84</td><td>37.50</td><td>72.22</td></tr><tr><td><br />平均</td><td>91.49</td><td>44.36</td><td>77.60</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903024_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 分类的ROC曲线" src="Detail/GetImg?filename=images/JYRJ201903024_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 分类的ROC曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903024_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="94">特征提取的方法对分类器的性能有显著影响, 为了与本文提出的方法进行对比, 选择ICA的特征提取的方法进行对比, 其他条件相同的情况下, 用ICA对rs-fMRI进行特征提取, 最后结合SVM分类器对提取的特征进行分类, ICA特征提取方法得到的平均分类准确率为71.92%, 表3为本文方法与ICA及文献中的分类结果进行比较。</p>
                </div>
                <div class="area_img" id="95">
                    <p class="img_tit"><b>表3 本文以其他方法分类结果的对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="95" border="1"><tr><td><br />方法</td><td>特异性</td><td>灵敏度</td><td>分类准确率</td></tr><tr><td><br />文献[4]</td><td>89.80</td><td>22.52</td><td>65.87</td></tr><tr><td><br />文献[6]</td><td>64.50</td><td>60.10</td><td>62.70</td></tr><tr><td><br />ICA</td><td>70.07</td><td>69.75</td><td>71.92</td></tr><tr><td><br />字典学习</td><td>91.49</td><td>44.36</td><td>77.60</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="96">从表2可以看出三个实验的平均分类准确率为77.60%, 实验一的分类准确率最高, 达到83.33%, 且分类灵敏度和特异性较好, 实验二和实验三的分类准确率和灵敏度明显低于实验一。从ROC曲线也可以看出, 实验一的ROC曲线下的面积达到0.76, 实验二和实验三的ROC曲线下的面积只有0.60左右, 实验一的曲线下的面积明显大于实验二和实验三曲线下的面积, 综上所述, 在本文的实验过程中, 实验一的分类性能较好。</p>
                </div>
                <div class="p1">
                    <p id="97">从表3可以看出, 文献<citation id="119" type="reference">[<a class="sup">4</a>]</citation>通过构建脑功能网络对ADHD进行分类, 得到的分类结果为65.87%, 而且构建脑功能网络的过程复杂, 需要耗费更多的时间;文献<citation id="120" type="reference">[<a class="sup">6</a>]</citation>通过小波变换与SVM对ADHD进行分类, 得到的分类结果为62.7%, 小波变换作为一种传统的方法, 应用在很多领域, 但是文献<citation id="121" type="reference">[<a class="sup">6</a>]</citation>是提取了大尺度功能时间序列的平均信号, 对ADHD分类有一定的局限性;ICA特征提取的方法对ADHD分类, 得到的分类结果为71.92%, ICA提取的特征为独立分量, 但是有研究表明, ICA应用于rs-fMRI, 是由于其处理稀疏分量, 而不是独立分量, 所以针对ICA提取的独立分量而不是稀疏分量;本文用字典学习的特征提取方法对ADHD进行分类, 得到的平均分类准确率为77.60%, 字典学习提取rs-fMRI的稀疏分量, 在稳定性方面优于ICA, 大大缩短了特征提取的时间, 分类的结果分别比文献<citation id="122" type="reference">[<a class="sup">4</a>]</citation>、文献<citation id="123" type="reference">[<a class="sup">6</a>]</citation>、ICA方法提高了11.73%、14.9%、5.68%, 实验结果验证了字典学习算法应用在rs-fMRI领域的有效性。由以上分析可知, 基于字典学习特征提取的方法对ADHD的分类结果有明显的提升, 其与SVM结合有助于ADHD病人与正常人的分类。</p>
                </div>
                <h3 id="98" name="98" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="99">随着脑科学的不断发展, 本文针对rs-fMRI数据提出了一种基于字典学习的特征提取方法, 对ADHD病人与正常人的特征进行分类。实验得到的平均分类准确率为77.60%, 在研究中发现, 本文提出的字典学习的特征提取方法有助于ADHD病人与正常人的分类。但是本文提出的字典学习提取的不同成分因素针对的是全脑的体素, 没有对全脑的体素进行选择, 所以在以后的学习和研究中, 重点对字典学习提取的部分体素和特征进行学习和研究, 进一步探讨字典学习提取的不同成分因素对ADHD病人与正常人分类的影响。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A multi-level classification framework for multi-site medical data: application to the ADHD- 200 collection">

                                <b>[1]</b> Itani S, Lecron F, Fortemps P. A multi-level classification framework for multi-site medical data: application to the ADHD- 200 collection[J]. Expert Systems with Applications, 2017, 91:36-45.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fusion of fMRI and non-imaging data for ADHD classification">

                                <b>[2]</b> Riaz A, Asad M, Alonso E, et al. Fusion of fMRI and non-imaging data for ADHD classification[J]. Computerized Medical Imaging &amp; Graphics the Official Journal of the Computerized Medical Imaging Society, 2017, 65:115-128.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Evaluation of pattern recognition and feature extraction methods in ADHD prediction">

                                <b>[3]</b> Sato J R, Hoexter M Q, Fujita A, et al. Evaluation of pattern recognition and feature extraction methods in ADHD prediction[J].Frontiers in Systems Neuroscience, 2012, 6 (4) :68-82.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classification of ADHD children through multimodal magnetic resonance imaging">

                                <b>[4]</b> Dai D, Wang J, Jing H, et al. Classification of ADHD children through multimodal magnetic resonance imaging[J]. Front Syst Neurosci, 2012, 6:63-71.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attributed graph distance measure for automatic detection of attention deficit hyperactive disordered subjects">

                                <b>[5]</b> Dey S, Rao A R, Shah M. Attributed graph distance measure for automatic detection of attention deficit hyperactive disordered subjects[J]. Frontiers in Neural Circuits, 2014, 8: 64.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DKDX201505026&amp;v=MjUzMTN5N2xXcnJJSVNiUGRyRzRIOVRNcW85SFlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 谭颖, 张涛, 谭睿, 等.基于小波变换与SVM的ADHD病人分类[J].电子科技大学学报, 2015, 44 (5) :789-794.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501921802&amp;v=MDY2OTgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUpsNGRieEk9TmlmT2ZiSzdIdEROcW85RWJla09CSHc3b0JNVDZUNFBRSA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Heuvel M P V D, Pol H E H. Exploring the brain network: A review on resting-state fMRI functional connectivity[J]. Eur Neuropsychopharmacol, 2010, 20 (8) :519-534.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Independent component analysis for brain fMRI does not select for independence">

                                <b>[8]</b> Daubechies I, Roussos E, Takerkart S, et al. Independent component analysis for brain fMRI does not select for independence.[J]. Proceedings of the National Academy of Sciences of the United States of America, 2009, 106 (26) :10415-10422.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparse dictionary learning of resting state fMRI networks">

                                <b>[9]</b> Eavani H, Filipovych R, Davatzikos C, et al. Sparse dictionary learning of resting state fMRI networks[C]//International Workshop on Pattern Recognition in Neuroimaging. IEEE, 2012:73-76.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13062800021671&amp;v=MDU1ODk0OUZaT2tPQ25zNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUpsNGRieEk9Tmo3QmFySzdIdGZPcA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Li Y F, Feng X C. Coupled dictionary learning method for image decomposition[J]. Science China (Information Sciences) , 2013, 56 (3) :1-10.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinear dictionary learning with application to image classification">

                                <b>[11]</b> Hu J, Tan Y P. Nonlinear dictionary learning with application to image classification[J]. Pattern Recognition, 2017, 75: 282-291.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-subject dictionary learning to segment an atlas of brain spontaneous activity">

                                <b>[12]</b> Varoquaux G, Gramfort A, Pedregosa F, et al. Multi-subject dictionary learning to segment an atlas of brain spontaneous activity[M]//Information Processing in Medical Imaging. Springer Berlin Heidelberg, 2011:562-573.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Neuro Bureau ADHD- 200 Preprocessed repository">

                                <b>[13]</b> Bellec P, Chu C, Chouinard-Decorte F, et al. The Neuro Bureau ADHD- 200 Preprocessed repository[J]. Neuroimage, 2016, 144 (Pt B) :275-186.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The ADHD- 200 Consortium: A Model to Advance the Translational Potential of Neuroimaging in Clinical Neuroscience">

                                <b>[14]</b> HD- 200 Consortium. The ADHD- 200 Consortium: A Model to Advance the Translational Potential of Neuroimaging in Clinical Neuroscience[J].Frontiers in Systems Neuroscience, 2012, 6:62.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100393926&amp;v=MTI3MjJLN0h0RE9ybzlGWitJTUJYNC9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklKbDRkYnhJPU5pZk9mYg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Xue T, Bai L, Chen S, et al. Neural specificity of acupuncture stimulation from support vector machine classification analysis[J]. Magnetic Resonance Imaging, 2011, 29 (7) :943-950.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201903024" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201903024&amp;v=MjE5NDU3cWZadVp0Rnk3bFdyL01MelRaWkxHNEg5ak1ySTlIWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekduN3dzK29VNlNWOTQwdlJjaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
