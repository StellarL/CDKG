<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135626352033750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201907036%26RESULT%3d1%26SIGN%3dauzXTtH%252bdncqt5qQLA4A1XpEr9A%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907036&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907036&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907036&amp;v=Mjk4Njl1WnRGeWpoVXIzTUx6VFpaTEc0SDlqTXFJOUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#25" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#29" data-title="&lt;b&gt;1 神经网络模型&lt;/b&gt; "><b>1 神经网络模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#33" data-title="&lt;b&gt;1.1 特征提取网络&lt;/b&gt;"><b>1.1 特征提取网络</b></a></li>
                                                <li><a href="#37" data-title="&lt;b&gt;1.2 注意力结构&lt;/b&gt;"><b>1.2 注意力结构</b></a></li>
                                                <li><a href="#42" data-title="&lt;b&gt;1.3 多尺度特种融合预测层&lt;/b&gt;"><b>1.3 多尺度特种融合预测层</b></a></li>
                                                <li><a href="#46" data-title="&lt;b&gt;1.4 Merge BN&lt;/b&gt;"><b>1.4 Merge BN</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#67" data-title="&lt;b&gt;2 实验结果分析&lt;/b&gt; "><b>2 实验结果分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#68" data-title="&lt;b&gt;2.1 实验环境与数据&lt;/b&gt;"><b>2.1 实验环境与数据</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;2.2 脐橙数据集实验&lt;/b&gt;"><b>2.2 脐橙数据集实验</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;2.3 主观实验结果&lt;/b&gt;"><b>2.3 主观实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#82" data-title="&lt;b&gt;3 结 语&lt;/b&gt; "><b>3 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#32" data-title="图1 模型结构图">图1 模型结构图</a></li>
                                                <li><a href="#35" data-title="&lt;b&gt;表1 特征提取网络参数表&lt;/b&gt;"><b>表1 特征提取网络参数表</b></a></li>
                                                <li><a href="#44" data-title="图2 预测层结构图">图2 预测层结构图</a></li>
                                                <li><a href="#71" data-title="图3 标注过程图">图3 标注过程图</a></li>
                                                <li><a href="#76" data-title="图4 网络训练过程收敛曲线图">图4 网络训练过程收敛曲线图</a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;表2 各网络对比结果&lt;/b&gt;"><b>表2 各网络对比结果</b></a></li>
                                                <li><a href="#81" data-title="图5 果梗、脐部检测效果">图5 果梗、脐部检测效果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 李江波.脐橙表面缺陷的快速检测方法研究[D].浙江大学, 2012." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1012312661.nh&amp;v=MjAxNDJDVVI3cWZadVp0RnlqaFVyM01WRjI2SExDNUhOZktycEViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         李江波.脐橙表面缺陷的快速检测方法研究[D].浙江大学, 2012.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 胡发焕, 董增文, 匡以顺.基于机器视觉的脐橙品质在线分级检测系统[J].中国农业大学学报, 2016, 21 (3) :112-118." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYDX201603015&amp;v=MjM4NDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVyM01LelRQZHJHNEg5Zk1ySTlFWVlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         胡发焕, 董增文, 匡以顺.基于机器视觉的脐橙品质在线分级检测系统[J].中国农业大学学报, 2016, 21 (3) :112-118.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 周云成, 许童羽, 郑伟, 等.基于深度卷积神经网络的番茄主要器官分类识别方法[J].农业工程学报, 2017, 33 (15) :219-226." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201715028&amp;v=MDE0MTZxQnRHRnJDVVI3cWZadVp0RnlqaFVyM01LelRNZTdHNEg5Yk5xbzlIYklRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         周云成, 许童羽, 郑伟, 等.基于深度卷积神经网络的番茄主要器官分类识别方法[J].农业工程学报, 2017, 33 (15) :219-226.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 杨国国, 鲍一丹, 刘子毅.基于图像显著性分析与卷积神经网络的茶园害虫定位与识别[J].农业工程学报, 2017, 33 (6) :156-162." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201706020&amp;v=MjE4ODFyQ1VSN3FmWnVadEZ5amhVcjNNS3pUTWU3RzRIOWJNcVk5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         杨国国, 鲍一丹, 刘子毅.基于图像显著性分析与卷积神经网络的茶园害虫定位与识别[J].农业工程学报, 2017, 33 (6) :156-162.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 朱冬梅, 王敏.基于卷积神经网络的脐橙品质分类研究[J].赣南师范大学学报, 2018, 39 (6) :25-28." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GNSY201806007&amp;v=MzE5OThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVyM01JaVBZZDdHNEg5bk1xWTlGWTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         朱冬梅, 王敏.基于卷积神经网络的脐橙品质分类研究[J].赣南师范大学学报, 2018, 39 (6) :25-28.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Iandola F, Moskewicz M, Karayev S, et al.Densenet:Implementing efficient convnet descriptor pyramids[EB].arXiv preprint arXiv:1404.1869, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Densenet:Implementing efficient convnet descriptor pyramids[EB]">
                                        <b>[6]</b>
                                         Iandola F, Moskewicz M, Karayev S, et al.Densenet:Implementing efficient convnet descriptor pyramids[EB].arXiv preprint arXiv:1404.1869, 2014.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Ren S, He K, Girshick R, et al.Faster r-cnn:Towards real-time object detection with region proposal networks[C]//Advances in neural information processing systems.2015:91-99." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Faster R-CNN: Towards real-time object detection with region pro-posal networks">
                                        <b>[7]</b>
                                         Ren S, He K, Girshick R, et al.Faster r-cnn:Towards real-time object detection with region proposal networks[C]//Advances in neural information processing systems.2015:91-99.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Redmon J, Divvala S, Girshick R, et al.You only look once:Unified, real-time object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.2016:779-788." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=You Only Look Once:Unified,Real-Time Object Detection">
                                        <b>[8]</b>
                                         Redmon J, Divvala S, Girshick R, et al.You only look once:Unified, real-time object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.2016:779-788.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Liu W, Anguelov D, Erhan D, et al.Ssd:Single shot multibox detector[C]//European conference on computer vision.Springer, Cham, 2016:21-37." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SSD:single shot multi box detector">
                                        <b>[9]</b>
                                         Liu W, Anguelov D, Erhan D, et al.Ssd:Single shot multibox detector[C]//European conference on computer vision.Springer, Cham, 2016:21-37.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Shen Z, Liu Z, Li J, et al.Dsod:Learning deeply supervised object detectors from scratch[C]//The IEEE International Conference on Computer Vision (ICCV) .2017, 1:1937-1945." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DSOD:Learning Deeply Supervised Object Detectors from Scratch">
                                        <b>[10]</b>
                                         Shen Z, Liu Z, Li J, et al.Dsod:Learning deeply supervised object detectors from scratch[C]//The IEEE International Conference on Computer Vision (ICCV) .2017, 1:1937-1945.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Ioffe S, Szegedy C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[EB].arXiv preprint arXiv:1502.03167, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift[EB]">
                                        <b>[11]</b>
                                         Ioffe S, Szegedy C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[EB].arXiv preprint arXiv:1502.03167, 2015.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(07),208-212 DOI:10.3969/j.issn.1000-386x.2019.07.035            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于卷积神经网络的脐橙果梗脐部检测算法及应用</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%9C%E9%9B%A8%E4%BA%AD&amp;code=42231771&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杜雨亭</a>
                                <a href="javascript:;">李功燕</a>
                                <a href="javascript:;">许绍云</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%A4%A7%E5%AD%A6%E5%BE%AE%E7%94%B5%E5%AD%90%E5%AD%A6%E9%99%A2&amp;code=1698842&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院大学微电子学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E5%BE%AE%E7%94%B5%E5%AD%90%E7%A0%94%E7%A9%B6%E6%89%80&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京微电子研究所</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>脐橙瑕疵检测突出问题是脐橙的果梗、脐部与瑕疵难以区分。针对这一问题, 提出一种利用深度学习物体检测技术对脐橙的果梗脐部进行检测的算法。该模型以顺序卷积与跳跃式卷积共同提取深度特征;融合注意力机制加强待检测物体位置权重, 在权重重分配的特征层上进行多尺度上下层信息融合, 使用融合后的特征层进行默认框提取;对训练得到的模型进行模型压缩, 进一步提升模型时间性能。实验结果表明, 基于该模型能够准确实时识别定位出果梗、脐部不会与瑕疵产生误判, 模型检测正确检测率达到90.6%, 单幅图片预测时间降低为15 ms。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%84%90%E6%A9%99&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">脐橙;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">物体检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">注意力机制;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    杜雨亭, 硕士生, 主研领域:图像算法, 计算机视觉。;
                                </span>
                                <span>
                                    李功燕, 研究员。;
                                </span>
                                <span>
                                    许绍云, 助理研究员。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-07</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划项目 (2018YFD0700300);</span>
                    </p>
            </div>
                    <h1><b>A DETECTION ALGORITHM FOR STEM END AND BLOSSOM END OF NAVEL ORANGE BASED ON CONVOLUTIONAL NEURAL NETWORK AND ITS APPLICATION</b></h1>
                    <h2>
                    <span>Du Yuting</span>
                    <span>Li Gongyan</span>
                    <span>Xu Shaoyun</span>
            </h2>
                    <h2>
                    <span>School of Microelectronics, University of Chinese Academy of Science</span>
                    <span>Institute of Microelectronics of Chinese Academy of Sciences</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The prominent problem in the detection of navel orange is that the stem end, blossom end and defect of navel orange are difficult to distinguish. For this problem, we proposed an algorithm for detecting navel orange stem end and blossom end by using deep learning object detection technology. The model extracted depth features together with sequential convolution and skip-connectional convolution. The fusion attention mechanism strengthened the position weight of the object to be detected, and multi-scale upper and lower information fusion was performed on the feature layer of weight redistribution. The feature layer performed default box extraction. The model obtained by training was model-compressed to further improve the model time performance. The experimental results show that based on the model, the fruit stem end can be accurate and real-time identified, and the blossom end is not misjudged with the defect. The correct detection rate of the model detection is 90.6%, and the prediction time of the single picture is reduced to 15 ms.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Navel%20orange&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Navel orange;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Object%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Object detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Attention%20mechanism&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Attention mechanism;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-07</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="25" name="25" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="26">我国是农业大国, 也是水果生产大国, 果品产业是我国种植业中位列粮食蔬菜之后的第三大产业, 是我国农村经济发展的支柱产业之一, 也是农民就业增收的重要途径。柑橘包括柑、橘、橙等, 是世界第一大水果, 占水果总量的1/4。2009年我国柑橘总产量是2 521.1万吨, 但出口量仅占3.9%。一个关键原因就是我国水果商品化处理水平低, 水果分级是其商品化处理的重要环节。</p>
                </div>
                <div class="p1">
                    <p id="27">在水果分级中, 水果表面瑕疵是作为分级的决定性判别标准之一, 而瑕疵识别中, 脐橙的果梗、脐部不能算作瑕疵, 因此需要准确识别从瑕疵中去除。果梗、脐部仅通过颜色、形状等方法难以与瑕疵区分, 李江波<citation id="84" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>采用直接利用硬件设备避免脐橙的果梗、脐部不会出现的所拍摄的图片中, 这样对水果的固定要求高, 拍摄面会有损失。胡焕发等<citation id="85" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>直接利用颜色分量区分果梗与瑕疵, 该方法适用性较窄, 并且最容易与瑕疵混淆的脐部没有被涉及。多数脐橙瑕疵识别相关研究都没有对脐橙的果梗、脐部进行识别, 脐橙果梗、脐部识别是一个难点问题。相比于传统方法, 近年兴起的卷积神经网络 (CNN) 能够直接从数据中自我学习特征, 具有泛化性能好, 适应性强的特点, 能够很好地完成物体识别检测任务, 已用于水果识别<citation id="86" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>和病虫害的检测<citation id="87" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。朱冬梅等<citation id="88" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>直接利用卷积神经网络对脐橙进行分类, 该方法利用了卷积神经网络能有学习深度特征的优点, 由于脐橙是自然产物, 直接对脐橙分类在制作数据集时难以定义分别数目, 并且分级指标应该按照客户要求定义。Iandola等<citation id="89" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出的DenseNet是目前效果最好的特征提取网络, 使用跳跃式卷积连接方式参数被重复利用, 减少了网络参数量, 提升网络训练效率。Ren等<citation id="90" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出基于CNN的Faster RCNN物体检测方法, 该方法基于两步训练方法, 首先利用RPN (Regional proposal network) 网络提取覆盖所有物体的默认检测框, 然后使用另一个卷积神经网络训练得到物体位置和坐标。该方法识别准确率高, 但是时间效率极差, 达不到实时要求。Redmon等<citation id="91" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出基于CNN的YOLO (You only look once) 物体检测方法, 该方法实时检测物体, 是端对端的检测方法, 按照7×7大小划分图片, 每个划分的图片部分为默认检测框, 对小物体检测效率极差, 物体检测准确度效果较差。Liu等<citation id="92" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出基于CNN的SSD (single shot detector) 深度学习物体检测方法, 该方法在多尺度卷积层上设置不同大小默认提取框, 兼顾速度的同时提高了检测的精度, 但是针对本文问题模型参数冗余, 时间达不到要求。Shen等<citation id="93" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提取基于DenseNet的Dsod物体检测方法, 该方法使用dense结构设计物体检测框架, 使得检测准确度有所提升, 但是时间效率较差。</p>
                </div>
                <div class="p1">
                    <p id="28">本文以脐橙果梗、脐部为研究目标, 对自然环境下采集的脐橙进行识别检测研究, 提出结合注意力机制以SSD为基本框架的改进模型, 以达到实时准确检测脐橙果梗、脐部的目的。</p>
                </div>
                <h3 id="29" name="29" class="anchor-tag"><b>1 神经网络模型</b></h3>
                <div class="p1">
                    <p id="30">为了实时准确检测脐橙果梗、脐部, 利用较少的参数以及计算量在保持检测精度的同时提高时间性能, 设计如图1所示网络模型。本文模型在衡量时间效率以及准确度的基础上, 使用SSD为基本框架, 借鉴DSOD网络模型物体识别准确度高的优势, 简化DSOD模型, 在该框架基础上提升物体检测时间, 为进一步提升准确度, 加入注意力机制。本文网络模型相比其他检测框架, 专门为脐橙数据集设计, 根据脐橙果梗、脐部实际大小设计检测层的层数, 网络结构设计加入更多检测实时性的考虑, 预测时, 加入Merge BN操作进一步提升时间效率。</p>
                </div>
                <div class="p1">
                    <p id="31">该网络模型包括四个主要部分:特征提取网络, 注意力模块, 多尺度特征融合的检测模块, 模型处理模块。特征提取网络主要用于提取深度特征, 得到输入图像的特征图。注意力模块是用于更新特征图的权重, 将权重更多的分配到要检测的物体上。多尺度特征融合检测层是将特征图池化为不同尺度, 从上到下融合邻近不同尺度信息组成新的特征层, 在融合特征层上进行默认框提取工作, 详细结构如图1所示。模型处理是训练模型结束, 为了进一步提高时间性能, 利用Merge BN操作, 将BN层去除, 实现整个模型压缩。</p>
                </div>
                <div class="area_img" id="32">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907036_032.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 模型结构图" src="Detail/GetImg?filename=images/JYRJ201907036_032.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 模型结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907036_032.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="33" name="33"><b>1.1 特征提取网络</b></h4>
                <div class="p1">
                    <p id="34">本网络结构的特征提取层利用线性结构与跳跃式结构融合的方式共同提取特征。首先, 使用一个线性堆叠的steam结构, 利用3个3×3卷积, 进行初步的特征提取。多个3×3的卷积既能减少卷积的参数量, 又能与7×7卷积有相同的感受野, 是目前特征提取卷积层最常用的大小。后接一个6层的Dense Block进一步特征提取, Dense Block的特点是网络中每一层都直接与前面层相连接, 实现特征的重复利用。这样的设计使得Dense Block结构比其他网络结构效率更高, 它每一层只需要学习很少的特征, 参数量和计算量显著减少。Dense Block内部结构是采用一个1×1卷积加上一个3×3卷积, 先用1×1卷积的作用是进行维度缩小, 然后利用3×3卷积进行特征提取。此结构降低了计算量以及参数量, 有利于网络快速训练以及模型简化。网络结构见图1特征提取模块, 特征提取层网络的参数设计结构如表1所示。</p>
                </div>
                <div class="area_img" id="35">
                    <p class="img_tit"><b>表1 特征提取网络参数表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="35" border="1"><tr><td colspan="2">类型</td><td>输出尺寸</td><td>核尺寸</td><td>步长</td></tr><tr><td colspan="2"><br />输入</td><td>3×300×300</td><td>-</td><td>-</td></tr><tr><td rowspan="4"><br />Steam</td><td><br />卷积</td><td>64×75×75</td><td>3×3 conv</td><td>4</td></tr><tr><td><br />卷积</td><td>64×75×75</td><td>3×3 conv</td><td>1</td></tr><tr><td><br />卷积</td><td>128×75×75</td><td>3×3 conv</td><td>1</td></tr><tr><td><br />池化</td><td>128×38×38</td><td>3×3 max pooling</td><td>2</td></tr><tr><td colspan="2">Dense Block</td><td>416×38×38</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn><mspace width="0.25em" /><mtext>c</mtext><mtext>o</mtext><mtext>n</mtext><mtext>v</mtext></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn><mspace width="0.25em" /><mtext>c</mtext><mtext>o</mtext><mtext>n</mtext><mtext>v</mtext></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>×</mo><mn>6</mn></mrow></math></td><td>1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="36">在参数设计上, 在第一层使用步长为4, 直接将300×300的输入尺寸降低为75×75, 接下来的卷积层提取浅层特征时, 计算量和参数量都比较小, 池化处理后的特征层作为多尺度预测的第一层, 用最小的参数量和计算量实现浅层特征预测的目的。</p>
                </div>
                <h4 class="anchor-tag" id="37" name="37"><b>1.2 注意力结构</b></h4>
                <div class="p1">
                    <p id="38">注意力是一个非常常见的, 但是又容易被忽略的东西。在人眼的视觉系统中, 人会把注意力放在自己感兴趣的事物上。注意力机制将特征层的权重重新分配, 待检测物体权重变大, 背景权重变小。本文利用了通道域注意力机制, 先对函数进行一个全局均值化, 即把通道内的所有特征值相加再平均。公式如下:</p>
                </div>
                <div class="p1">
                    <p id="39"><mathml id="40"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>z</mi><msub><mrow></mrow><mi>c</mi></msub><mo>=</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>s</mi><mi>q</mi></mrow></msub><mo stretchy="false"> (</mo><mi>u</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>W</mi><mo>×</mo><mi>Η</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>W</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Η</mi></munderover><mi>u</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="41">式中:<i>W</i>、<i>H</i>分别代表feature map的宽和高, <i>u</i><sub><i>c</i></sub> (<i>i</i>, <i>j</i>) 表示feature map像素点的值。然后, 利用两个全连接来训练通道间的相关性, 第一个全连接把<i>C</i>通道压缩成<i>C</i>/<i>r</i>通道来降低计算量, 后面跟RELU激活函数, 第二个全连接恢复成<i>C</i>通道, 后连Sigmoid激活函数。最后将经过Sigmoid函数产生的结果与原始特征进行点乘操作, 增加待检测物体的权重。注意力结构示意如图1中注意力模块所示。</p>
                </div>
                <h4 class="anchor-tag" id="42" name="42"><b>1.3 多尺度特种融合预测层</b></h4>
                <div class="p1">
                    <p id="43">本网络结构采用的是多尺度融合的预测结构, 所谓多尺度就是采用大小不同的特征图, CNN网络一般前面的特征图比较大, 后面会逐渐采用stride=2的卷积或者池化来降低特征图大小, 一个比较大的特征图和一个比较小的特征图, 它们都用来做检测。这样做的好处是比较大的特征图来用来检测相对较小的目标, 而小的特征图负责检测大目标。利用上下层信息融合, 预测的结构改变成dense的连接方式, 该结构在大量减少需要学习的模型参数的同时, 进一步提升模型性能。预测模块结构如图2所示。</p>
                </div>
                <div class="area_img" id="44">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907036_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 预测层结构图" src="Detail/GetImg?filename=images/JYRJ201907036_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 预测层结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907036_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="45">在脐橙数据集中, 果梗、脐部在图片中的大小最大不超过图片的1/3, 因此在多尺度检测中仅使用38×38、19×19、10×10的尺度足以检测物体, 余下的尺度例如5×5、3×3、1×1对脐橙数据集是多余的。为了网络的时间效率, 在不影响精度的前提下, 本文仅采用三个较大尺度进行检测, 用较大尺度feature map检测较小的物体。使用dense的形式从上到下融合相邻尺度, 能够进一步利用参数, 并且更好地利用上下信息。Down-sample结构是利用1×1卷积和3×3卷积, 1×1卷积作用是维度缩小, 减少计算量和参数量, 设置stride=2的3×3卷积来降低特征图大小, 利用组合操作, 连接相邻feature map, 在此组合的feature map上提取默认框进行训练。</p>
                </div>
                <h4 class="anchor-tag" id="46" name="46"><b>1.4 Merge BN</b></h4>
                <div class="p1">
                    <p id="47">BN层<citation id="94" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>是对数据进行归一化处理。对于每个隐层神经元, 把逐渐在非线性函数映射后向取值区间极限饱和区靠拢的输入分布强制拉回到均值为0方差为1的标准的正态分布, 使得非线性变换函数的输入值落入对输入比较敏感的区域, 以此避免梯度消失问题。BN层的使用给网络带来很大的益处, 如网络收敛速度加快、开始学习率可以设置较大等。BN层处理的步骤如下所示:</p>
                </div>
                <div class="p1">
                    <p id="48"> (1) 计算一个mini-batch的均值:</p>
                </div>
                <div class="p1">
                    <p id="49"><mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi><msub><mrow></mrow><mi>B</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>x</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="51"> (2) 计算一个mini-batch的方差:</p>
                </div>
                <div class="p1">
                    <p id="52"><mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><msubsup><mrow></mrow><mi>B</mi><mn>2</mn></msubsup><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="54"> (3) 利用均值以及方差对数据归一化:</p>
                </div>
                <div class="p1">
                    <p id="55"><mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mstyle><mo>^</mo></mover><mo>=</mo><mfrac><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mrow><msqrt><mrow><mi>σ</mi><msubsup><mrow></mrow><mi>B</mi><mn>2</mn></msubsup><mo>+</mo><mi>ε</mi></mrow></msqrt></mrow></mfrac></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="57"> (4) 利用自学习参数<i>γ</i>、<i>β</i>得到BN操作后的数据结果:</p>
                </div>
                <div class="p1">
                    <p id="58"><mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>γ</mi><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mstyle><mo>^</mo></mover><mo>+</mo><mi>β</mi></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="60">式中:<i>B</i>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>m</i></sub>}表示一个mini-batch的数据, <i>y</i><sub><i>i</i></sub>是输出结果。</p>
                </div>
                <div class="p1">
                    <p id="61">本文中所使用的深度学习框架如图1所示, 每个卷积层基本与一个BN层相连, BN层使得训练过程中不用关注太多参数调整问题, 并且数据的归一化带来了训练的速度增加, 但是同样也带来了额外的参数以及多余的网络层数。因此, 图像的检测时间会有所增加。本文采用Merge BN操作将BN层与卷积层合并, 显著提升了图像检测的时间性能。根据式 (4) , 可以反向推导BN层合并到原来卷积层权重和偏差的公式如下:</p>
                </div>
                <div class="p1">
                    <p id="62"><mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msub><mo>=</mo><mi>W</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>l</mtext><mtext>d</mtext></mrow></msub><mfrac><mi>γ</mi><mrow><msqrt><mrow><mi>σ</mi><msubsup><mrow></mrow><mi>B</mi><mn>2</mn></msubsup><mo>+</mo><mi>ε</mi></mrow></msqrt></mrow></mfrac></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="64"><mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>b</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msub><mo>=</mo><mi>b</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>l</mtext><mtext>d</mtext></mrow></msub><mfrac><mi>γ</mi><mrow><msqrt><mrow><mi>σ</mi><msubsup><mrow></mrow><mi>B</mi><mn>2</mn></msubsup><mo>+</mo><mi>ε</mi></mrow></msqrt></mrow></mfrac><mo>+</mo><mi>β</mi><mo>-</mo><mfrac><mrow><mi>γ</mi><mi>μ</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mrow><msqrt><mrow><mi>σ</mi><msubsup><mrow></mrow><mi>B</mi><mn>2</mn></msubsup><mo>+</mo><mi>ε</mi></mrow></msqrt></mrow></mfrac></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="66">首先把卷积层权重以及BN层的参数读取出来, 根据式 (6) 和式 (7) , 将BN层参数汇合到卷积层中去;其次将模型结构中的BN层去掉, 得到的新模型就是最终检测所需要的模型。</p>
                </div>
                <h3 id="67" name="67" class="anchor-tag"><b>2 实验结果分析</b></h3>
                <h4 class="anchor-tag" id="68" name="68"><b>2.1 实验环境与数据</b></h4>
                <div class="p1">
                    <p id="69">实验的硬件环境为:CPU:56 Intel (R) Xeon (R) CPU E5-2683 v3@2.00 GHz;GPU:NVIDIA TITAN Xp, 12 GB显存。软件环境为Ubuntu 16.04以及caffe框架。</p>
                </div>
                <div class="p1">
                    <p id="70">本文采用深度学习物体检测方法检测果梗、脐部。目前没有相关的数据集是脐橙检测的, 因此需要自己制作相关数据集的标注工作。本研究共标注19 760幅图片, 按照随机交叉验证准则, 30%作为测试集 (共5 928幅) , 剩下的作为训练集。数据集标注借助开源标注工具LabelImage, 直接生成类似于Pascal VOC数据集的标注结果, 标注过程如图3所示。</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907036_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 标注过程图" src="Detail/GetImg?filename=images/JYRJ201907036_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 标注过程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907036_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="72">目前衡量检测问题的主要指标是mAP (mean Average Precision) 和前向预测时间, 本文主要从这两个指标衡量本文使用的模型与原始模型, 在尽可能不损失精度的情况下, 降低检测时间, 能够正确实时检测脐橙的果梗、脐部。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73"><b>2.2 脐橙数据集实验</b></h4>
                <div class="p1">
                    <p id="74">采用本文网络结构进行参数训练, 训练过程中学习率的设置非常重要, 如果学习率过大, 很容易导致误差震荡, 无法收敛到全局最优值, 如果学习率过小, 网络收敛又很慢, 并且容易收敛到局部最优值。在整个学习过程中, 采用multi-step动态调整学习率大小的策略, 开始的时候设置较大的学习率, 在step为8 000、16 000的时候分别降低学习率, 可以使得网络达到最优状态。</p>
                </div>
                <div class="p1">
                    <p id="75">本网络采用脐橙数据集进行网络训练过程如图4所示。横轴表示的是训练迭代的次数, 左边纵轴表示的是训练时的损失值, 右边纵轴表示的是训练过程中验证集的平均正确率 (mean Average Precision, mAP) 。从图4可以看出在8 000、16 000处降低学习率时, 损失有明显的下降趋势, 在20 000迭代次数之前, 网络收敛速度较快, 测试的mAP也有明显的增加。在最后阶段loss和mAP趋于稳定, 表示网络已经收敛到最优。在脐橙数据集上, mAP指标为90.6%。</p>
                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907036_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 网络训练过程收敛曲线图" src="Detail/GetImg?filename=images/JYRJ201907036_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 网络训练过程收敛曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907036_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="77">本文训练次数为30 000, 在最优模型下测试前向时间为23 ms, 经过merge BN操作后, 前向测试时间为15 ms。本文基于SSD基本检测框架, 借鉴使用DSOD网络的dense结构设计的模型结构。各网络对比结果如表2所示, 本文方法与SSD与DSOD检测方法进行比较, 所用的测试集是脐橙数据集, 本文所采用的模型是在时间性能和准确度性能上都是最好的。由表2可知, 注意力机制对准确度的提升有良好的效果。</p>
                </div>
                <div class="area_img" id="78">
                    <p class="img_tit"><b>表2 各网络对比结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="78" border="1"><tr><td><br />识别方法</td><td>mAP/%</td><td>时间/ms</td></tr><tr><td><br />SSD-300</td><td>85.1</td><td>60</td></tr><tr><td><br />DSOD-300</td><td>89.3</td><td>75</td></tr><tr><td><br />Ours no attention</td><td>86.5</td><td>22</td></tr><tr><td><br />Ours+attention</td><td>90.6</td><td>23</td></tr><tr><td><br />Ours+attention+Merge BN</td><td><b>90.6</b></td><td><b>15</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>2.3 主观实验结果</b></h4>
                <div class="p1">
                    <p id="80">图5为果梗、脐部检测效果, (a) 、 (b) 、 (c) 三列图分别显示了使用本文改进的深度学习物体检测算法以及应用所建立的脐橙数据集对脐橙果梗、脐部以及各种瑕疵影响下的检测效果。从图中可以看出, 在脐部与溃疡极度相似以及大脐部难以判别的情况下, 依然可以准确地检测出果梗、脐部, 本文的算法适用于脐橙的瑕疵检测系统。</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907036_08100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 果梗、脐部检测效果" src="Detail/GetImg?filename=images/JYRJ201907036_08100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 果梗、脐部检测效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907036_08100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="82" name="82" class="anchor-tag"><b>3 结 语</b></h3>
                <div class="p1">
                    <p id="83">在脐橙数据集中, 本文网络结构加入注意力机制后, 在保证实时的前提下依旧能够保证极高的精度, 在时间以及精度上超过了SSD、DSOD模型。在加入Merge BN模型处理步骤后, 进一步大幅度提高了时间, 所以该结构能够满足脐橙的果梗、脐部检测的工作, 从而进一步完成脐橙的瑕疵检测工作。但是目前本文所做的工作还有一些不足:所建立的脐橙数据集仅仅是脐橙的一个表面, 在工业上一般是对脐橙整个表面进行检测, 因此应用于工业还需要加入一些策略, 所有表面形成一定的联系。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1012312661.nh&amp;v=MTAzMjIyNkhMQzVITmZLcnBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVcjNNVkY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 李江波.脐橙表面缺陷的快速检测方法研究[D].浙江大学, 2012.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYDX201603015&amp;v=MTg2NTF0RnlqaFVyM01LelRQZHJHNEg5Zk1ySTlFWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 胡发焕, 董增文, 匡以顺.基于机器视觉的脐橙品质在线分级检测系统[J].中国农业大学学报, 2016, 21 (3) :112-118.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201715028&amp;v=MTAwMjF6VE1lN0c0SDliTnFvOUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVXIzTUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 周云成, 许童羽, 郑伟, 等.基于深度卷积神经网络的番茄主要器官分类识别方法[J].农业工程学报, 2017, 33 (15) :219-226.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201706020&amp;v=MDU2OTlNS3pUTWU3RzRIOWJNcVk5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVcjM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 杨国国, 鲍一丹, 刘子毅.基于图像显著性分析与卷积神经网络的茶园害虫定位与识别[J].农业工程学报, 2017, 33 (6) :156-162.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GNSY201806007&amp;v=MDM1NTc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVcjNNSWlQWWQ3RzRIOW5NcVk5Rlk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 朱冬梅, 王敏.基于卷积神经网络的脐橙品质分类研究[J].赣南师范大学学报, 2018, 39 (6) :25-28.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Densenet:Implementing efficient convnet descriptor pyramids[EB]">

                                <b>[6]</b> Iandola F, Moskewicz M, Karayev S, et al.Densenet:Implementing efficient convnet descriptor pyramids[EB].arXiv preprint arXiv:1404.1869, 2014.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Faster R-CNN: Towards real-time object detection with region pro-posal networks">

                                <b>[7]</b> Ren S, He K, Girshick R, et al.Faster r-cnn:Towards real-time object detection with region proposal networks[C]//Advances in neural information processing systems.2015:91-99.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=You Only Look Once:Unified,Real-Time Object Detection">

                                <b>[8]</b> Redmon J, Divvala S, Girshick R, et al.You only look once:Unified, real-time object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.2016:779-788.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SSD:single shot multi box detector">

                                <b>[9]</b> Liu W, Anguelov D, Erhan D, et al.Ssd:Single shot multibox detector[C]//European conference on computer vision.Springer, Cham, 2016:21-37.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DSOD:Learning Deeply Supervised Object Detectors from Scratch">

                                <b>[10]</b> Shen Z, Liu Z, Li J, et al.Dsod:Learning deeply supervised object detectors from scratch[C]//The IEEE International Conference on Computer Vision (ICCV) .2017, 1:1937-1945.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift[EB]">

                                <b>[11]</b> Ioffe S, Szegedy C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[EB].arXiv preprint arXiv:1502.03167, 2015.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201907036" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907036&amp;v=Mjk4Njl1WnRGeWpoVXIzTUx6VFpaTEc0SDlqTXFJOUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
