<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136396903252500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201903032%26RESULT%3d1%26SIGN%3dNyRVUmYxCTIvW4pxCEyDYk6NLgs%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201903032&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201903032&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201903032&amp;v=MDE3MzNpRGxWcnJNTHpUWlpMRzRIOWpNckk5R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#29" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;1 出租车识别&lt;/b&gt; "><b>1 出租车识别</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="&lt;b&gt;2 出租车识别&lt;/b&gt; "><b>2 出租车识别</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="&lt;b&gt;2.1 ViBe基本算法&lt;/b&gt;"><b>2.1 ViBe基本算法</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;2.2 改进ViBe算法&lt;/b&gt;"><b>2.2 改进ViBe算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="&lt;b&gt;3 基于多特征融合的人体姿态识别&lt;/b&gt; "><b>3 基于多特征融合的人体姿态识别</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#86" data-title="&lt;b&gt;3.1 特征提取&lt;/b&gt;"><b>3.1 特征提取</b></a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;3.2 姿态识别&lt;/b&gt;"><b>3.2 姿态识别</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#115" data-title="&lt;b&gt;4 实验结果与分析&lt;/b&gt; "><b>4 实验结果与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#136" data-title="&lt;b&gt;5 结 语&lt;/b&gt; "><b>5 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#34" data-title="图1 私揽检测算法流程图">图1 私揽检测算法流程图</a></li>
                                                <li><a href="#41" data-title="图2 常用Haar特征模板">图2 常用Haar特征模板</a></li>
                                                <li><a href="#43" data-title="图3 出租车区域检测结果">图3 出租车区域检测结果</a></li>
                                                <li><a href="#78" data-title="图4 各运动目标检测算法结果">图4 各运动目标检测算法结果</a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;表1 不同方法鬼影消失帧数&lt;/b&gt;"><b>表1 不同方法鬼影消失帧数</b></a></li>
                                                <li><a href="#84" data-title="图5 人车位置关系">图5 人车位置关系</a></li>
                                                <li><a href="#90" data-title="图6 人体外接椭圆参数变化过程">图6 人体外接椭圆参数变化过程</a></li>
                                                <li><a href="#107" data-title="图7 人体运动剧烈程度系数变化过程">图7 人体运动剧烈程度系数变化过程</a></li>
                                                <li><a href="#120" data-title="图8 不同行为特征变化">图8 不同行为特征变化</a></li>
                                                <li><a href="#123" data-title="图9 实际环境视频集">图9 实际环境视频集</a></li>
                                                <li><a href="#131" data-title="图10 私揽行为检测结果">图10 私揽行为检测结果</a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;表2 不同方法下实际环境视频集检测结果&lt;/b&gt;"><b>表2 不同方法下实际环境视频集检测结果</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;表3 不同方法下实际环境视频集检测结果&lt;/b&gt;"><b>表3 不同方法下实际环境视频集检测结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 王伟耀.人工智能技术在智慧交通领域中的应用[J].电子技术与软件工程, 2018 (3) :251." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZRU201803199&amp;v=MDI4ODFUZlplN0c0SDluTXJJNU1iWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGaURsVnJyUEk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         王伟耀.人工智能技术在智慧交通领域中的应用[J].电子技术与软件工程, 2018 (3) :251.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Zhuang X, Kang W, Wu Q. Real-time vehicle detection with foreground-based cascade classifier[J]. Iet Image Processing, 2016, 10 (4) :289-296." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time vehicle detection with foreground-based cascade classifier">
                                        <b>[2]</b>
                                         Zhuang X, Kang W, Wu Q. Real-time vehicle detection with foreground-based cascade classifier[J]. Iet Image Processing, 2016, 10 (4) :289-296.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 尹宏鹏, 陈波, 柴毅, 等.基于视觉的目标检测与跟踪综述[J].自动化学报, 2016, 42 (10) :1466-1489." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201610002&amp;v=MDgwNjg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGaURsVnJyUEtDTGZZYkc0SDlmTnI0OUZab1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         尹宏鹏, 陈波, 柴毅, 等.基于视觉的目标检测与跟踪综述[J].自动化学报, 2016, 42 (10) :1466-1489.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 高健焮, 陈健.基于改进ViBe算法的运动目标检测方法[J].计算机应用, 2017, 37 (S2) :99-102." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY2017S2025&amp;v=MDkyMjJDVVI3cWZadVpzRmlEbFZyclBMejdCZDdHNEg5YXZyWTlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         高健焮, 陈健.基于改进ViBe算法的运动目标检测方法[J].计算机应用, 2017, 37 (S2) :99-102.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 史瑞环, 吴斌, 李务军, 等.一种改进的融合帧差法的ViBe算法[J].微型机与应用, 2016, 35 (4) :44-45, 49." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201604015&amp;v=MDgwMTR6cXFCdEdGckNVUjdxZlp1WnNGaURsVnJyUE1qWEJkN0c0SDlmTXE0OUVZWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         史瑞环, 吴斌, 李务军, 等.一种改进的融合帧差法的ViBe算法[J].微型机与应用, 2016, 35 (4) :44-45, 49.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 罗瑞奇, 钟忺, 钟珞, 等.一种改进Haar-like特征的车辆识别算法[J].武汉大学学报 (理学版) , 2018, 64 (3) :244-248." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=WHDY201803007&amp;v=Mjc5MDFpWFBkN0c0SDluTXJJOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGaURsVnJyUE0=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         罗瑞奇, 钟忺, 钟珞, 等.一种改进Haar-like特征的车辆识别算法[J].武汉大学学报 (理学版) , 2018, 64 (3) :244-248.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 余小角, 郭景, 徐凯, 等.一种基于类Haar特征和AdaBoost算法的前车检测方法[J].微型机与应用, 2017, 36 (13) :22-25." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201713008&amp;v=MzA2MDJYQmQ3RzRIOWJOckk5RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGxWcnJQTWo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         余小角, 郭景, 徐凯, 等.一种基于类Haar特征和AdaBoost算法的前车检测方法[J].微型机与应用, 2017, 36 (13) :22-25.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Kumar P D, Sukadev M . A new Wronskian change detection model based codebook background subtraction for visual surveillance applications[J]. Journal of Visual Communication and Image Representation, 2018." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A new Wronskian change detection model based codebook background subtraction for visual surveillance applications">
                                        <b>[8]</b>
                                         Kumar P D, Sukadev M . A new Wronskian change detection model based codebook background subtraction for visual surveillance applications[J]. Journal of Visual Communication and Image Representation, 2018.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 瞿中, 辛宁, 廖春梅.结合背景更新和亮度范围的改进Codebook模型算法[J].计算机应用与软件, 2016, 33 (11) :153-156." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201611036&amp;v=MDk4NTdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGxWcnJQTHpUWlpMRzRIOWZOcm85R1k=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         瞿中, 辛宁, 廖春梅.结合背景更新和亮度范围的改进Codebook模型算法[J].计算机应用与软件, 2016, 33 (11) :153-156.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 王红茹, 童伟.基于自适应高斯模型的实效运动目标检测算法[J].计算机工程与设计, 2016, 37 (10) :2700-2704." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201610023&amp;v=MjkwNDVMRzRIOWZOcjQ5SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGxWcnJQTmlmWVo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         王红茹, 童伟.基于自适应高斯模型的实效运动目标检测算法[J].计算机工程与设计, 2016, 37 (10) :2700-2704.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Mukherjee S, Singh K K. Human action and event recognition using a novel descriptor based on improved dense trajectories[J].Multimedia Tools &amp;amp; Applications, 2017 (6) :1-18." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Human action and event recognition using a novel descriptor based on improved dense trajectories">
                                        <b>[11]</b>
                                         Mukherjee S, Singh K K. Human action and event recognition using a novel descriptor based on improved dense trajectories[J].Multimedia Tools &amp;amp; Applications, 2017 (6) :1-18.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 姬建光. 基于形状上下文的物体匹配与识别研究[D]. 兰州:西北师范大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016241764.nh&amp;v=MzIyNTVxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGxWcnJQVkYyNkdMRzhIOWJLcTVFYlBJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         姬建光. 基于形状上下文的物体匹配与识别研究[D]. 兰州:西北师范大学, 2016.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" 张恒瑜. 基于卷积神经网络的多部位人体检测[D]. 北京:北京工业大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016785778.nh&amp;v=MjkwMjJDVVI3cWZadVpzRmlEbFZyclBWRjI2R0xTd0c5YkxwNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         张恒瑜. 基于卷积神经网络的多部位人体检测[D]. 北京:北京工业大学, 2016.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(03),168-173+209 DOI:10.3969/j.issn.1000-386x.2019.03.031            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>视频监控中私自揽客违法行为检测</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%8B%A5%E6%9D%A8&amp;code=40033883&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张若杨</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B4%BE%E5%85%8B%E6%96%8C&amp;code=35809221&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贾克斌</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E9%B9%8F%E5%AE%87&amp;code=06299059&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘鹏宇</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%83%A8&amp;code=0034856&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京工业大学信息学部</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%85%88%E8%BF%9B%E4%BF%A1%E6%81%AF%E7%BD%91%E7%BB%9C%E5%8C%97%E4%BA%AC%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0041796&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">先进信息网络北京实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%9C%AA%E6%9D%A5%E7%BD%91%E7%BB%9C%E7%A7%91%E6%8A%80%E9%AB%98%E7%B2%BE%E5%B0%96%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">未来网络科技高精尖创新中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着数字视频监控技术的普及与应用, 基于视频监控信息的出租车行业智能化管理成为可能。特别是在强化道路交通的安全管理, 缓解执法人员压力等方面发挥了重要作用, 但目前尚缺少针对出租车运营管理与分析的智能化处理技术。对此, 提出一种私自揽客行为检测算法。使用Haar特征结合Adaboost分类器对出租车进行识别;利用改进的ViBe算法提取运动人体目标, 并快速消除鬼影干扰;判断人车位置关系, 并提取人在上车过程中的多姿态特征, 送入SVM分类器进行训练, 实现对人体行为的分类。实验结果表明:该方法能够适应复杂环境, 抗干扰能力较强, 可实时检测私揽行为是否发生。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A7%81%E8%87%AA%E6%8F%BD%E5%AE%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">私自揽客;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%87%BA%E7%A7%9F%E8%BD%A6%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">出租车识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">运动目标检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%A7%BF%E6%80%81%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多姿态特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持向量机;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张若杨, 硕士生, 主研领域:图像与视频信号处理。;
                                </span>
                                <span>
                                    贾克斌, 教授。;
                                </span>
                                <span>
                                    刘鹏宇, 副教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-08</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61672064);</span>
                                <span>北京市自然科学基金项目 (4172001);</span>
                                <span>北京市交通行业科技项目 (2017058);</span>
                    </p>
            </div>
                    <h1><b>ILLEGAL BEHAVIOR DETECTION OF CARRYING PASSENGERS PRIVATELY IN VIDEO SURVEILLANCE</b></h1>
                    <h2>
                    <span>Zhang Ruoyang</span>
                    <span>Jia Kebin</span>
                    <span>Liu Pengyu</span>
            </h2>
                    <h2>
                    <span>Faculty of Information Technology, Beijing University of Technology</span>
                    <span>Beijing Laboratory of Advanced Information Networks</span>
                    <span>Advanced Innovation Center for Future Internet Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the popularization and application of digital video surveillance technology, intelligent management of taxi industry based on video surveillance information becomes possible. Especially, it plays an important role in strengthening the safety management of road traffic and relieving the pressure of law enforcement personnel. However, there is still a lack of intelligent processing technology for taxi operation management and analysis. In this regard, this paper studied a detection algorithm of private passenger behavior. We used Haar feature and Adaboost classifier to recognize the taxis. The improved ViBe algorithm was used to extract the moving human target, and the ghost interference was quickly eliminated. We judged the position relationship between human and vehicle, and extracted the multi-attitude features of human in the process of boarding, and then sent them to SVM classifier for training, so as to realize the classification of human behavior. The experimental results show that the method can adapt to complex environment, has strong anti-jamming ability, and can detect the occurrence of private passenger behavior in real time.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Carrying%20passengers%20privately&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Carrying passengers privately;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Taxi%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Taxi recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Moving%20target%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Moving target detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-attitude%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multi-attitude feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Support%20vector%20machine&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Support vector machine;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-08</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="29" name="29" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="30">近年来, 随着数字视频技术的迅猛发展, 道路交通管理非现场执法的应用率越来越高, 不仅强化了道路交通的安全管理, 还极大地缓解了执法人员不足与人情执法的问题, 管理效果十分明显。可以说, 加大非现场执法工作的力度已经成为了破解道路交通管理工作难题最可靠、最有效的办法之一, 它在推进交通执法工作长足发展的过程中发挥着不可替代的作用。</p>
                </div>
                <div class="p1">
                    <p id="31">出租车行业是交通运输行业不可或缺的一部分, 特别像北京地区, 由于人口众多、人流量大、公共交通分担率偏低, 使得公众对于出租车需求量日益增长, 这直接导致了出租车在运营过程中存在的问题日趋复杂。尤其在机场、火车站等人流量极大区域, 出租车违规私揽导致挪车不及时, 很容易造成拥堵、追尾甚至人员伤亡。因此对特殊区域私揽<citation id="138" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>行为的有效检测和识别成为亟待解决的问题之一。</p>
                </div>
                <div class="p1">
                    <p id="32">综上所述, 开展针对私揽行为的检测识别有极大的应用价值, 能使公共区域车辆人员的安全得到进一步保障。本文以检测识别私揽行为为主要研究方向, 针对人体行为识别展开深入研究, 为私揽行为的检测识别提供重要依据。</p>
                </div>
                <div class="p1">
                    <p id="33">目前在文献中还没有针对出租车私自揽客行为自动检测方法的报道。针对交通监控环境下背景相对静态的特点, 本文研究了一种基于交通视频的私自揽客行为检测方法, 主要流程如图1所示。首先进行出租车识别<citation id="139" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>并提取运动人体前景, 判断行人是否出现在出租车区域中;然后提取有上车可能的行人的多姿态特征, 将其送入SVM分类器进行训练;最后识别人体上车行为, 确定监控视频中是否存在私揽行为。</p>
                </div>
                <div class="area_img" id="34">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903032_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 私揽检测算法流程图" src="Detail/GetImg?filename=images/JYRJ201903032_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 私揽检测算法流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903032_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="35">针对静止背景下的运动目标检测一般有帧间差分法、背景差分法、光流法<citation id="140" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等比较成熟的检测算法。ViBe算法<citation id="141" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>是一种新颖、快速及有效的运动目标检测算法, 该算法思想简单、运算效率高, 且初始化背景建模无需训练, 可以快速对背景进行有效建模。但检测结果中易出现鬼影, 极大地影响到后续的人体特征提取的准确性。</p>
                </div>
                <div class="p1">
                    <p id="36">本文针对传统ViBe算法消除鬼影速度较慢的不足, 提出了一种改进的ViBe算法, 能够快速消除鬼影, 并针对人体上车行为识别难度大的特点, 设计了一种基于多特征融合的识别方法。最后结合目标检测与人体行为识别技术形成一套完整的私揽行为检测方法。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag"><b>1 出租车识别</b></h3>
                <div class="p1">
                    <p id="38">在交通监控视频中, 场景具有一定复杂性, 出租车与私家车相混合, 而私揽行为指的是在道路的落客区域, 出租车司机发生停车, 允许乘客上车并最终驶离的行为过程。因此需要先对出租车进行识别, 以区分出租车私揽违法行为和私家车正常接人行为。</p>
                </div>
                <div class="p1">
                    <p id="39">本文提取出租车的Haar<citation id="142" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>特征, 并将其送入Adaboost<citation id="143" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>分类器进行训练, 最后检测视频中的出租车。</p>
                </div>
                <div class="p1">
                    <p id="40">Haar特征指的是一种矩形特征, 其值表示为黑色矩形区域的灰度值与白色矩形区域的灰度值的差, 以此来生成图像特征矩阵。不同的Haar特征模型功能也不相同, 常用的Haar特征模板如图2所示。</p>
                </div>
                <div class="area_img" id="41">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903032_041.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 常用Haar特征模板" src="Detail/GetImg?filename=images/JYRJ201903032_041.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 常用Haar特征模板  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903032_041.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="42">Adaboost算法是一种改进的Boosting算法。该算法不需要弱分类器的先验知识。它的核心是为相同的训练集训练不同的弱分类器, 然后将这些弱分类器合成强分类器, 最后将强分类器级联成最终分类器。图3是由分类器进行级联和检测出租车的过程。</p>
                </div>
                <div class="area_img" id="43">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903032_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 出租车区域检测结果" src="Detail/GetImg?filename=images/JYRJ201903032_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 出租车区域检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903032_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="44">通过在图像上使用不同大小的矩形窗口来进行多尺度扫描, 并使用级联分类器来判断扫描的每个矩形窗口。如果一个矩形窗口特性通过了所有的级联分类器, 表明该区域是出租车区域, 并获取当前图像中车辆的位置;否则, 表示该区域不是出租车区域。</p>
                </div>
                <div class="p1">
                    <p id="45">本文采用训练集包含2 767张出租车区域正样本和7 219张环境负样本, 正样本统一归一化为28×20大小, 负样本归一化为480×360大小。同时设置每三个弱分类器构成一个强分类器, 最终将训练好的Haar-Adaboost分类器用交通监控视频进行测试, 实验结果如图3所示。实验结果表明, 本文方法能够有效且实时检测出租车, 且能够适应夜晚等较为复杂的环境。</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag"><b>2 出租车识别</b></h3>
                <div class="p1">
                    <p id="47">行人是发生私揽行为时的主要目标, 同时也是大量存在于交通监控视频中的运动目标。在对传统的检测算法深入研究的基础上, 考虑到交通监控视频中摄像头的角度会时常发生变化, 本文对初始化背景建模快的ViBe算法做出了改进, 提取人体前景。</p>
                </div>
                <h4 class="anchor-tag" id="48" name="48"><b>2.1 ViBe基本算法</b></h4>
                <div class="p1">
                    <p id="49">ViBe算法是一种基于背景差分法的前景分离算法, 该算法检测效果较好, 可以适应背景变化较大的场景, 但容易造成检测结果中出现鬼影。</p>
                </div>
                <div class="p1">
                    <p id="50">ViBe算法主要包含三个步骤:背景建模、前景检测和模型更新。</p>
                </div>
                <div class="p1">
                    <p id="51">在背景建模过程中, 该算法采用视频第一帧来初始化背景模型, 为每一个像素点创建一个样本集存储该像素点的背景模型, 利用像素点极其邻居像素点的像素值随机填充样本模型, 完成初始化背景建模。</p>
                </div>
                <div class="p1">
                    <p id="52">在前景检测过程中, 为了确定待分类像素是否属于背景点, 需同该像素点的背景模型做比较, 检测两者间的相似度, 具体方法为:定义一个以<i>p</i> (<i>x</i>) 为中心, <i>R</i>为半径的球体<i>S</i><sub><i>R</i></sub> (<i>p</i> (<i>x</i>) ) , 用<i>U</i>表示背景模型<i>M</i> (<i>x</i>) 与球体<i>S</i><sub><i>R</i></sub> (<i>p</i> (<i>x</i>) ) 的交集, <i>U</i>表示一个相似度函数, 当<i>U</i>大于一个给定的阈值<i>U</i><sub>min</sub>时, 待分类像素<i>p</i> (<i>x</i>) 与背景相似, 分类为背景, 其数学表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="53"><i>U</i>={<i>S</i><sub><i>R</i></sub> (<i>p</i> (<i>x</i>) ) ∩{<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, …, <i>p</i><sub><i>N</i></sub>}}      (1) </p>
                </div>
                <div class="p1">
                    <p id="54">根据式 (1) , 计算<i>p</i> (<i>x</i>) 与<i>N</i>个背景样本的欧氏距离, 判断是否小于阈值<i>R</i>。在实际处理中, 一旦找到<i>U</i><sub>min</sub>个样本匹配时, 就认为该像素点为背景。</p>
                </div>
                <div class="p1">
                    <p id="55">在模型更新的过程中, ViBe算法不仅考虑当前像素与其历史样本之间的关系, 还考虑到当前像素与其邻居像素之间的关系, 使每一个背景点有的概率更新自己的模型样本值及其邻居点的模型样本值。算法的空间更新策略保证了背景图像中空间信息的连续性, 从而对相机的轻微抖动也有一定适应性。</p>
                </div>
                <h4 class="anchor-tag" id="56" name="56"><b>2.2 改进ViBe算法</b></h4>
                <div class="p1">
                    <p id="57">在原始ViBe算法前景检测过程中使用简单的欧式距离判断像素点属于前景或背景, 并不能适用于所有情况, 尤其对阴影的分类效果较差。因此本文使用Codebook<citation id="144" type="reference"><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>算法中的颜色扭曲度对前景像素点进行分析, 旨在尽可能地消除阴影对真实运动目标的影响, 具体过程如下:</p>
                </div>
                <div class="p1">
                    <p id="58">1) 修改背景样本集中向量<b><i>p</i></b><sub><i>i</i></sub>为 (<i>R</i><sub><i>i</i></sub>, <i>G</i><sub><i>i</i></sub>, <i>B</i><sub><i>i</i></sub>) 。</p>
                </div>
                <div class="p1">
                    <p id="59">2) 读取当前帧像素点向量<b><i>x</i></b><sub><i>t</i></sub>= (<i>R</i>, <i>G</i>, <i>B</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="60">3) 要计算待分类像素与背景模型的相似度, 比较条件为像素点的颜色扭曲度, 如下所示:</p>
                </div>
                <div class="area_img" id="149">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201903032_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="63">式中:</p>
                </div>
                <div class="area_img" id="150">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201903032_15000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="66">4) 判断相似度是否小于给定阈值, 若满足条件, 则匹配次数加1。</p>
                </div>
                <div class="p1">
                    <p id="67">5) 判断匹配次数是否达到<i>U</i><sub>min</sub>, 达到则认为该像素点为背景。</p>
                </div>
                <div class="p1">
                    <p id="68">同时, 为了改善鬼影消失过慢的不足, 本文借鉴Codebook算法中6元组的思想。在原方法中每个像素点只建立了背景样本集, 使得在模型更新过程中所有样本在同一时刻被更新概率相同, 难以快速消除鬼影。故本文在原有基础上引入背景样本点未被更新时间, 作为该样本点更新概率的权值依据, 具体改进方案如下:</p>
                </div>
                <div class="p1">
                    <p id="69">1) 修改背景样本集中向量 (<i>R</i><sub><i>i</i></sub>, <i>B</i><sub><i>i</i></sub>, <i>G</i><sub><i>i</i></sub>) 为 (<i>R</i><sub><i>i</i></sub>, <i>B</i><sub><i>i</i></sub>, <i>G</i><sub><i>i</i></sub>, <i>λ</i><sub><i>i</i></sub>) 。</p>
                </div>
                <div class="p1">
                    <p id="70">2) 若将该像素点分类为背景点, 则计算当前时刻所有样本的被更新概率, 保证未被更新时间越小的样本点被更新概率越小, 计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="71"><mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>ϕ</mtext><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>λ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>λ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="73">3) 依照计算得到的概率更新样本背景。</p>
                </div>
                <div class="p1">
                    <p id="74">4) 将最新被更新的样本点的未被更新时间置为0, 其余样本点的未被更新时间加1。</p>
                </div>
                <div class="p1">
                    <p id="75">下面通过一组视频图像分别按照三帧差分法、背景差分法、混合高斯法<citation id="145" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、原始ViBe算法和本文的改进ViBe算法进行人物前景提取, 得到前景提取结果如图4所示。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903032_07800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 各运动目标检测算法结果" src="Detail/GetImg?filename=images/JYRJ201903032_07800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 各运动目标检测算法结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903032_07800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="79">由图4可见:本文的算法对人物前景提取的效果最佳, 准确性高;三帧差分法容易造成较大空洞;背景差分法和混合高斯方法在存在静止目标突然运动时情况下效果较差;原始ViBe算法效果较好, 但鬼影仍对真实目标提取有较大干扰。</p>
                </div>
                <div class="p1">
                    <p id="80">其次, 为了评估本文提出的ViBe算法消除鬼影的速度, 分别使用混合高斯法、原始ViBe算法和本文算法对鬼影消失的帧数进行了统计, 如表1所示。</p>
                </div>
                <div class="area_img" id="81">
                    <p class="img_tit"><b>表1 不同方法鬼影消失帧数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="81" border="1"><tr><td><br />方法</td><td>视频1</td><td>视频2</td><td>视频3</td><td>视频4</td></tr><tr><td><br />本文方法</td><td>43帧</td><td>37帧</td><td>52帧</td><td>48帧</td></tr><tr><td><br />混合高斯法</td><td>157帧</td><td>124帧</td><td>183帧</td><td>171帧</td></tr><tr><td><br />原始ViBe方法</td><td>57帧</td><td>51帧</td><td>61帧</td><td>60帧</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="82">由表1可见:本文的算法消除鬼影所需要的帧数最少, 速度最快;混合高斯法消除鬼影速度较慢;原始ViBe算法稍慢于本文算法。</p>
                </div>
                <div class="p1">
                    <p id="83">在此基础上, 结合提取到的人体前景与识别出的出租车区域, 计算人体质心与出租车中心的距离, 当行人处于车辆区域范围内时, 则可以认为该行人与车辆有构成私揽违法行为的可能。实验发现, 所检测出的人体质心存在于以出租车质心为圆心, 到四角长度为半径的一侧扇形内时, 检测效果较好, 如图5所示。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903032_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 人车位置关系" src="Detail/GetImg?filename=images/JYRJ201903032_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 人车位置关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903032_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="85" name="85" class="anchor-tag"><b>3 基于多特征融合的人体姿态识别</b></h3>
                <h4 class="anchor-tag" id="86" name="86"><b>3.1 特征提取</b></h4>
                <div class="p1">
                    <p id="87">乘客在上车过程中会逐渐从出租车远处接近, 在车门附近停顿, 并伴有弯腰、拉车门、屈体等动作, 与交通环境中的其他行为有明显区别。本文基于私自揽客的特点对乘客的多种特征进行提取。</p>
                </div>
                <div class="p1">
                    <p id="88">运动目标的标识方法取决于运动目标的区域形状及其连通性, 采用外接区域的方法能够很直观地反映出运动人体的轮廓。因此本文选取与人体拟合度更高的最小外接椭圆作为其中一个特征。</p>
                </div>
                <div class="p1">
                    <p id="89">一个椭圆由其中心坐标、其方向以及其长短轴长度定义。在私揽行为发生过程中, 行人会首先从远处向出租车接近, 这段时间私揽行为的人体特征与人体行走基本一致。当乘客走近出租车准备上车时, 会停顿并打开车门, 然后弯腰上车, 在弯腰上车的过程中, 人体竖直距离会降低, 人体最小外接椭圆的长轴会减小, 这是一个明显区别于正常行走行为的特征。人体最小外接椭圆参数变化过程如图6所示。</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903032_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 人体外接椭圆参数变化过程" src="Detail/GetImg?filename=images/JYRJ201903032_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 人体外接椭圆参数变化过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903032_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="91">人体最小外接椭圆的参数需要计算图像的矩, 对于连续图像<i>f</i> (<i>x</i>, <i>y</i>) , 矩的定义由如下:</p>
                </div>
                <div class="p1">
                    <p id="92"><i>m</i><sub><i>pq</i></sub>=∫<mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo>-</mo><mi>∞</mi></mrow><mrow><mo>+</mo><mi>∞</mi></mrow></msubsup></mrow></math></mathml>∫<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo>-</mo><mi>∞</mi></mrow><mrow><mo>+</mo><mi>∞</mi></mrow></msubsup></mrow></math></mathml><i>x</i><sup><i>p</i></sup><i>y</i><sup><i>q</i></sup><i>f</i> (<i>x</i>, <i>y</i>) d<i>x</i>d<i>y</i>      (5) </p>
                </div>
                <div class="p1">
                    <p id="95">椭圆的中心是通过计算具有零阶一阶空间矩的质心坐标得到的, 其公式如下:</p>
                </div>
                <div class="p1">
                    <p id="96"><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>x</mi><mo>¯</mo></mover><mo>=</mo><mi>m</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>0</mn></mrow></msub><mo>/</mo><mi>m</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>0</mn></mrow></msub><mo>, </mo><mover accent="true"><mi>y</mi><mo>¯</mo></mover><mo>=</mo><mi>m</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>1</mn></mrow></msub><mo>/</mo><mi>m</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>0</mn></mrow></msub></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="98">人体外接椭圆倾角由长轴与水平线之间的夹角确定, 通过二阶中心距计算:</p>
                </div>
                <div class="p1">
                    <p id="99"><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>θ</mi><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mi>arctan</mi></mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mn>2</mn><mi>μ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub></mrow><mrow><mi>μ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>0</mn></mrow></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>2</mn></mrow></msub></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="101">为了确定椭圆的长轴与短轴, 需要分别计算最小和最大惯性矩<i>I</i><sub>min</sub>和<i>I</i><sub>max</sub>, 它们可以通过评估协方差矩阵的特征值得到, <i>I</i><sub>min</sub>和<i>I</i><sub>max</sub>计算如下:</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>Ι</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>μ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>0</mn></mrow></msub><mo>+</mo><mi>μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>2</mn></mrow></msub><mo>-</mo><msqrt><mrow><mo stretchy="false"> (</mo><mi>μ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>0</mn></mrow></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>2</mn></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mn>4</mn><mi>μ</mi><msubsup><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow><mn>2</mn></msubsup></mrow></msqrt></mrow><mn>2</mn></mfrac></mtd></mtr><mtr><mtd><mi>Ι</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>μ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>0</mn></mrow></msub><mo>+</mo><mi>μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>2</mn></mrow></msub><mo>+</mo><msqrt><mrow><mo stretchy="false"> (</mo><mi>μ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>0</mn></mrow></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>2</mn></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mn>4</mn><mi>μ</mi><msubsup><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow><mn>2</mn></msubsup></mrow></msqrt></mrow><mn>2</mn></mfrac></mtd></mtr></mtable><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">然后, 给出最佳拟合椭圆的长轴与短轴:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>a</mi><mo>=</mo><mrow><mo> (</mo><mrow><mfrac><mn>4</mn><mtext>π</mtext></mfrac></mrow><mo>) </mo></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>4</mn></mfrac></mrow></msup><mrow><mo>[</mo><mrow><mfrac><mrow><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>3</mn></msup></mrow><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub></mrow></mfrac></mrow><mo>]</mo></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>8</mn></mfrac></mrow></msup><mtext> </mtext><mi>b</mi><mo>=</mo><mrow><mo> (</mo><mrow><mfrac><mn>4</mn><mtext>π</mtext></mfrac></mrow><mo>) </mo></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>4</mn></mfrac></mrow></msup><mrow><mo>[</mo><mrow><mfrac><mrow><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>3</mn></msup></mrow><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub></mrow></mfrac></mrow><mo>]</mo></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>8</mn></mfrac></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">根据以上人体外接椭圆的确定方法求得特征向量<b><i>E</i></b>=[<i>a</i>, <i>b</i>, <i>θ</i>]。</p>
                </div>
                <div class="p1">
                    <p id="106">第二个特征表示目标运动的剧烈程度, 该特征利用MHI对运动运动剧烈程度进行量化。在乘客打开车门后上车的过程中, 人体会在较短的时间内有一个急速下坠的动作, 这就会使得这段时间人体的运动会更加剧烈, 与上车前的运动程度有明显区分。人体运动剧烈程度系数变化过程如图7所示。</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903032_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 人体运动剧烈程度系数变化过程" src="Detail/GetImg?filename=images/JYRJ201903032_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 人体运动剧烈程度系数变化过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903032_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="108">表示运动剧烈程度的系数<i>C</i><sub>motion</sub>计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="109"><mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>o</mtext><mtext>t</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>b</mi><mi>l</mi><mi>o</mi><mi>b</mi></mrow></munder><mi>Η</mi></mstyle><msub><mrow></mrow><mi>τ</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mrow><mi>n</mi><mi>u</mi><mi>m</mi><mo stretchy="false"> (</mo><mi>p</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi><mi>s</mi><mo>∈</mo><mi>b</mi><mi>l</mi><mi>o</mi><mi>b</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="111">式中:<i>blob</i>为前景闭包;<i>H</i><sub><i>τ</i></sub> (<i>x</i>, <i>y</i>, <i>t</i>) 为运动历史图像。<i>C</i><sub>motion</sub>∈[0%, 100%], <i>C</i><sub>motion</sub>=0%表示没有运动的像素点, <i>C</i><sub>motion</sub>=100%表示区域内所有像素点都在运动。</p>
                </div>
                <div class="p1">
                    <p id="112">综合多种特征, 从而得到了多特征融合的人体姿态特征向量<b><i>B</i></b><sub><i>i</i></sub>=[<i>a</i>, <i>b</i>, <i>θ</i>, <i>C</i><sub>motion</sub>]。</p>
                </div>
                <h4 class="anchor-tag" id="113" name="113"><b>3.2 姿态识别</b></h4>
                <div class="p1">
                    <p id="114">由于判断行人是否发生上车行为是一个二分类问题, 因此提取人体特征后, 我们选择支持向量机<citation id="146" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>的分类器对人体行为进行建模和分类。该方法通过将数据非线性映射到高维空间做出非线性决策, 使用较少样本即可以训练出效果较好的支持向量机模型。本文算法选用RBF核函数进行训练。</p>
                </div>
                <h3 id="115" name="115" class="anchor-tag"><b>4 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="116">首先验证乘客上车行为与其他行为在特征上的区别。本文提取了人体上车行为以及人体行走和跑步两种交通监控视频中的常见人体行为的人体姿态特征。人体多特征如图8所示。</p>
                </div>
                <div class="area_img" id="120">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903032_12000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同行为特征变化" src="Detail/GetImg?filename=images/JYRJ201903032_12000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同行为特征变化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903032_12000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="121">视频进行到第30帧时行人准备上出租车, 构成一起私揽行为。根据不同行为的多姿态特征可以看出, 乘客上车行为在人体最小外接椭圆的长轴变化与短轴变化以及<i>C</i><sub>motion</sub>变化上都与其他两种行为有明显区分, 而通过椭圆角度变化则难以有效区分。因此本文在实验过程中只对上述三种有明显区分的特征进行了训练。</p>
                </div>
                <div class="p1">
                    <p id="122">实验选取实际交通监控视频进行测试。实际交通视频集包括328段视频, 环境为首都机场执法大队的非现场执法环境, 如图9所示。其中存在私揽违规行为的视频共有97段, 测试视频时长皆为1～3 min。</p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903032_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 实际环境视频集" src="Detail/GetImg?filename=images/JYRJ201903032_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 实际环境视频集  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903032_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="124">对所有待检测视频进行检测, 检测结果标准为:属于乘客上车行为并正确检测的数目<i>TB</i>;属于乘客上车行为并未正确检测的数目<i>FB</i>;属于其他行为并没有错误报警的数目<i>TO</i>;属于其他行为并误报警的数目<i>FO</i>。则检测乘客上车行为正确率可定义为:</p>
                </div>
                <div class="p1">
                    <p id="125"><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>B</mi><mo>+</mo><mi>Τ</mi><mi>Ο</mi></mrow><mrow><mi>Τ</mi><mi>B</mi><mo>+</mo><mi>F</mi><mi>B</mi><mo>+</mo><mi>Τ</mi><mi>Ο</mi><mo>+</mo><mi>F</mi><mi>Ο</mi></mrow></mfrac></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="127">检测乘客上车行为的查全率定义为:</p>
                </div>
                <div class="p1">
                    <p id="128"><mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>B</mi></mrow><mrow><mi>Τ</mi><mi>B</mi><mo>+</mo><mi>F</mi><mi>B</mi></mrow></mfrac></mrow></math></mathml>      (12) </p>
                </div>
                <div class="p1">
                    <p id="130">实验中分别使用本文方法、形状上下文方法<citation id="147" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、原始<i>ViBe</i>方法以及多部位建模<citation id="148" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>方法对乘客上车行为进行检测。其中使用本文方法对乘客上车行为进行检测的结果如图10所示, 检测到人车位置靠近时显示“<i>low</i>”字样, 表示有发生私揽行为的可能;检测到人车位置靠近并识别出人体上车行为时显示“<i>high</i>”字样, 表示私揽行为发生可能性极高。</p>
                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903032_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 私揽行为检测结果" src="Detail/GetImg?filename=images/JYRJ201903032_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 私揽行为检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903032_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="132">表2给出了在实际环境中不同方法对乘客上车行为进行检测的正确率和查全率。可以看出本文算法在实际视频集下的检测效果远远优于其他几种方法。但由于实际环境较为复杂, 人体与车辆之间时常会发生交叉、遮挡等现象, 且有其他行人与车辆出现在监控视频中, 使得提取感兴趣目标受到干扰, 导致本文算法仍有不少误检与漏检现象存在。</p>
                </div>
                <div class="area_img" id="133">
                    <p class="img_tit"><b>表2 不同方法下实际环境视频集检测结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="133" border="1"><tr><td><br />方法</td><td><i>R</i>/%</td><td><i>N</i>/%</td></tr><tr><td><br />本文方法</td><td>70.3</td><td>67.3</td></tr><tr><td><br />形状上下文方法</td><td>29.8</td><td>48.5</td></tr><tr><td><br />原始<i>ViBe</i>方法</td><td>57.7</td><td>60.4</td></tr><tr><td><br />多部位建模方法</td><td>49.0</td><td>57.1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="134">同时对算法处理时间进行了测试。表3给出了几种方法的平均每帧处理时间和一帧最长处理时间。可以看出本文算法的处理时间与使用原始<i>ViBe</i>的方法无明显区别, 但较其他两种方法略慢, 不过平均每帧处理速度依然在40 <i>ms</i>以内, 可以达到实时检测的标准。</p>
                </div>
                <div class="area_img" id="135">
                    <p class="img_tit"><b>表3 不同方法下实际环境视频集检测结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="135" border="1"><tr><td><br />方法</td><td>平均每帧处理<br />时间/<i>ms</i></td><td>一帧最长处理<br />时间/<i>ms</i></td></tr><tr><td><br />本文方法</td><td>32</td><td>121</td></tr><tr><td><br />形状上下文方法</td><td>25</td><td>98</td></tr><tr><td><br />原始<i>ViBe</i>方法</td><td>31</td><td>118</td></tr><tr><td><br />多部位建模方法</td><td>27</td><td>107</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="136" name="136" class="anchor-tag"><b>5 结 语</b></h3>
                <div class="p1">
                    <p id="137">本文研究的出租车识别与私揽违章行为检测方法是一种用于自动检测交通违法违章私揽行为的方法。针对原始ViBe算法易产生鬼影的缺点做出了改进, 使得鬼影可以快速消失, 并结合人体前景与出租车区域判断人车位置关系, 初步判定私揽发生的可能性, 后续提取人体上车过程中的多姿态特征, 送入SVM分类器训练, 识别人体行为, 准确判定私揽行为。本文方法能够检测一些特定场景下如机场、火车站、公交枢纽等地私揽行为是否存在, 为交通安全预警, 便于执法取证。因此, 本文方法在智能交通领域具有广阔的应用前景、广泛的适用性和参考价值, 为城市交通规范性建设和发展提供了保证。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZRU201803199&amp;v=MjY4MTNpRGxWcnJQSVRmWmU3RzRIOW5Nckk1TWJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 王伟耀.人工智能技术在智慧交通领域中的应用[J].电子技术与软件工程, 2018 (3) :251.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time vehicle detection with foreground-based cascade classifier">

                                <b>[2]</b> Zhuang X, Kang W, Wu Q. Real-time vehicle detection with foreground-based cascade classifier[J]. Iet Image Processing, 2016, 10 (4) :289-296.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201610002&amp;v=MzA5NDFyQ1VSN3FmWnVac0ZpRGxWcnJQS0NMZlliRzRIOWZOcjQ5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 尹宏鹏, 陈波, 柴毅, 等.基于视觉的目标检测与跟踪综述[J].自动化学报, 2016, 42 (10) :1466-1489.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY2017S2025&amp;v=MjYwMzFzRmlEbFZyclBMejdCZDdHNEg5YXZyWTlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 高健焮, 陈健.基于改进ViBe算法的运动目标检测方法[J].计算机应用, 2017, 37 (S2) :99-102.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201604015&amp;v=MDIwMDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGxWcnJQTWpYQmQ3RzRIOWZNcTQ5RVlZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 史瑞环, 吴斌, 李务军, 等.一种改进的融合帧差法的ViBe算法[J].微型机与应用, 2016, 35 (4) :44-45, 49.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=WHDY201803007&amp;v=MjYzODBGckNVUjdxZlp1WnNGaURsVnJyUE1pWFBkN0c0SDluTXJJOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 罗瑞奇, 钟忺, 钟珞, 等.一种改进Haar-like特征的车辆识别算法[J].武汉大学学报 (理学版) , 2018, 64 (3) :244-248.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201713008&amp;v=MTQ4ODNCZDdHNEg5Yk5ySTlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRmlEbFZyclBNalg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 余小角, 郭景, 徐凯, 等.一种基于类Haar特征和AdaBoost算法的前车检测方法[J].微型机与应用, 2017, 36 (13) :22-25.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A new Wronskian change detection model based codebook background subtraction for visual surveillance applications">

                                <b>[8]</b> Kumar P D, Sukadev M . A new Wronskian change detection model based codebook background subtraction for visual surveillance applications[J]. Journal of Visual Communication and Image Representation, 2018.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201611036&amp;v=MjcwMTZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGaURsVnJyUEx6VFpaTEc0SDlmTnJvOUc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 瞿中, 辛宁, 廖春梅.结合背景更新和亮度范围的改进Codebook模型算法[J].计算机应用与软件, 2016, 33 (11) :153-156.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201610023&amp;v=MTI0MjhIOWZOcjQ5SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGxWcnJQTmlmWVpMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 王红茹, 童伟.基于自适应高斯模型的实效运动目标检测算法[J].计算机工程与设计, 2016, 37 (10) :2700-2704.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Human action and event recognition using a novel descriptor based on improved dense trajectories">

                                <b>[11]</b> Mukherjee S, Singh K K. Human action and event recognition using a novel descriptor based on improved dense trajectories[J].Multimedia Tools &amp; Applications, 2017 (6) :1-18.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016241764.nh&amp;v=MTE4NjZxZlp1WnNGaURsVnJyUFZGMjZHTEc4SDliS3E1RWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 姬建光. 基于形状上下文的物体匹配与识别研究[D]. 兰州:西北师范大学, 2016.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016785778.nh&amp;v=MDEyOTdCdEdGckNVUjdxZlp1WnNGaURsVnJyUFZGMjZHTFN3RzliTHA1RWJQSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 张恒瑜. 基于卷积神经网络的多部位人体检测[D]. 北京:北京工业大学, 2016.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201903032" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201903032&amp;v=MDE3MzNpRGxWcnJNTHpUWlpMRzRIOWpNckk5R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
