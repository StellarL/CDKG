<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134079784318750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJYRJ201911034%26RESULT%3d1%26SIGN%3d1awKnBheRSpqctCSLHJHUn3k7cg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201911034&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201911034&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201911034&amp;v=MTI3NjVMT2VaZVZ1RnkvaFViN0lMelRaWkxHNEg5ak5ybzlHWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#61" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#68" data-title="&lt;b&gt;1 数据采集与预处理&lt;/b&gt; "><b>1 数据采集与预处理</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#69" data-title="&lt;b&gt;1.1 IQ数据采集&lt;/b&gt;"><b>1.1 IQ数据采集</b></a></li>
                                                <li><a href="#71" data-title="&lt;b&gt;1.2 数据预处理&lt;/b&gt;"><b>1.2 数据预处理</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="&lt;b&gt;2 MPSK识别算法模型&lt;/b&gt; "><b>2 MPSK识别算法模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#86" data-title="&lt;b&gt;2.1 ReSENet网络&lt;/b&gt;"><b>2.1 ReSENet网络</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;2.2 模型优化&lt;/b&gt;"><b>2.2 模型优化</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#119" data-title="&lt;b&gt;3 实 验&lt;/b&gt; "><b>3 实 验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#120" data-title="&lt;b&gt;3.1 参数配置&lt;/b&gt;"><b>3.1 参数配置</b></a></li>
                                                <li><a href="#122" data-title="&lt;b&gt;3.2 实验结果与分析&lt;/b&gt;"><b>3.2 实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#150" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#81" data-title="图1 BPSK/QPSK/8PSK的时频图">图1 BPSK/QPSK/8PSK的时频图</a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;表1 时频图数据集划分情况&lt;/b&gt;"><b>表1 时频图数据集划分情况</b></a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;表2 ReSENet网络结构图&lt;/b&gt;"><b>表2 ReSENet网络结构图</b></a></li>
                                                <li><a href="#92" data-title="图2 ReSE模块结构图">图2 ReSE模块结构图</a></li>
                                                <li><a href="#93" data-title="图3 ResNeXt结构单元示意图">图3 ResNeXt结构单元示意图</a></li>
                                                <li><a href="#94" data-title="图4 SE模块结构图">图4 SE模块结构图</a></li>
                                                <li><a href="#96" data-title="图5 神经元的内积">图5 神经元的内积</a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;表3 测试集的识别率&lt;/b&gt;"><b>表3 测试集的识别率</b></a></li>
                                                <li><a href="#126" data-title="图6 ReSENet提取的特征图">图6 ReSENet提取的特征图</a></li>
                                                <li><a href="#129" data-title="图7 SE模块对ReSENet网络性能影响">图7 SE模块对ReSENet网络性能影响</a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;表4 不同梯度下降算法的参数设置&lt;/b&gt;"><b>表4 不同梯度下降算法的参数设置</b></a></li>
                                                <li><a href="#135" data-title="图8 不同梯度下降算法效果对比">图8 不同梯度下降算法效果对比</a></li>
                                                <li><a href="#138" data-title="图9 不同激活函数效果对比">图9 不同激活函数效果对比</a></li>
                                                <li><a href="#141" data-title="图10 ReSENet与其他网络结构训练准确率对比">图10 ReSENet与其他网络结构训练准确率对比</a></li>
                                                <li><a href="#211" data-title="图1 1 Re SENet与其他网络结构测试集效果对比">图1 1 Re SENet与其他网络结构测试集效果对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="212">


                                    <a id="bibliography_1" title=" Zibar D,Winther O,Granceschi N,et al.Nonlinear impairment compensation using expectation maximization for dispersion managed and unmanaged PDM 16-QAM transmission[J].Optics Express,2012,20(26):181-96." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinear impairment compensation using expectation maximization for dispersion managed and unmanaged PDM 16-QAM transmission">
                                        <b>[1]</b>
                                         Zibar D,Winther O,Granceschi N,et al.Nonlinear impairment compensation using expectation maximization for dispersion managed and unmanaged PDM 16-QAM transmission[J].Optics Express,2012,20(26):181-96.
                                    </a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_2" title=" Jarajreh M A,Giacoumidis E,Aldaya I,et al.Artificial neural network nonlinear equalizer for coherent optical OFDM[J].IEEE Photonics Technology Letters,2015,27(4):387-390." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Artificial Neural Network Nonlinear Equalizer for Coherent Optical OFDM">
                                        <b>[2]</b>
                                         Jarajreh M A,Giacoumidis E,Aldaya I,et al.Artificial neural network nonlinear equalizer for coherent optical OFDM[J].IEEE Photonics Technology Letters,2015,27(4):387-390.
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_3" title=" Wang D S,Zhang M,Fu M X,et al.Nonlinearity mitigation using a machine learning detector based on k-Nearest neighbors[J].IEEE Photonics Technology Letters,2016,28(19):2102-2105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinearity Mitigation Using a Machine Learning Detector Based on k-Nearest Neighbors">
                                        <b>[3]</b>
                                         Wang D S,Zhang M,Fu M X,et al.Nonlinearity mitigation using a machine learning detector based on k-Nearest neighbors[J].IEEE Photonics Technology Letters,2016,28(19):2102-2105.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_4" title=" Wang D S,Zhang M,Li Z,et al.Nonlinear decision boundary created by a machine learning-based classifier to mitigate nonlinear phase noise[C]//European Conference on Optical Communication.Piscataway,NJ:IEEE,2015:1-3." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinear decision boundary created by a machine learning-based classifier to mitigate nonlinear phase noise">
                                        <b>[4]</b>
                                         Wang D S,Zhang M,Li Z,et al.Nonlinear decision boundary created by a machine learning-based classifier to mitigate nonlinear phase noise[C]//European Conference on Optical Communication.Piscataway,NJ:IEEE,2015:1-3.
                                    </a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_5" title=" Sermanet P,Eigen D,Zhang X,et al.OverFeat:integrated recognition,localization and detection using convolutional networks[EB].Eprint Arxiv:1312.6229,2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=OverFeat:integrated recognition,localization and detection using convolutional networks[EB]">
                                        <b>[5]</b>
                                         Sermanet P,Eigen D,Zhang X,et al.OverFeat:integrated recognition,localization and detection using convolutional networks[EB].Eprint Arxiv:1312.6229,2013.
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_6" title=" Krizhevsky A,Sutkyever I,Hinton G E.ImageNet classification with deep convolutional neural networks[C]//Proceedings of the 25th International Conference on Neural Information Processing Systems—Volume 1.Lake Tahoe,Nevada,USA:Curran Associates Inc,2012:1097-1105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Net Classification with Deep Convolutional Neural Networks">
                                        <b>[6]</b>
                                         Krizhevsky A,Sutkyever I,Hinton G E.ImageNet classification with deep convolutional neural networks[C]//Proceedings of the 25th International Conference on Neural Information Processing Systems—Volume 1.Lake Tahoe,Nevada,USA:Curran Associates Inc,2012:1097-1105.
                                    </a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     Szegedy C,Liu W,Jia Y Q,et al.Going deeper with convolutions[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,Las Vegas,NV,United States:IEEE,2015:1-9.</a>
                                </li>
                                <li id="226">


                                    <a id="bibliography_8" title=" Simonyan K,Zisserman A.Very deep convolutional networks for large-scale image recognition[EB].Eprint ArXiv:1409.1556,2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition[EB]">
                                        <b>[8]</b>
                                         Simonyan K,Zisserman A.Very deep convolutional networks for large-scale image recognition[EB].Eprint ArXiv:1409.1556,2014.
                                    </a>
                                </li>
                                <li id="228">


                                    <a id="bibliography_9" title=" Szegedy C,Vanhoucke V,Ioffe S,et al.Rethinking the inception architecture for computer vision[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:2818-2826." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rethinking the inception architecture for computer vision">
                                        <b>[9]</b>
                                         Szegedy C,Vanhoucke V,Ioffe S,et al.Rethinking the inception architecture for computer vision[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:2818-2826.
                                    </a>
                                </li>
                                <li id="230">


                                    <a id="bibliography_10" title=" He K M,Zhang X Y,Ren S Q,et al.Deep residual learning for image recognition[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2015:770-778." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">
                                        <b>[10]</b>
                                         He K M,Zhang X Y,Ren S Q,et al.Deep residual learning for image recognition[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2015:770-778.
                                    </a>
                                </li>
                                <li id="232">


                                    <a id="bibliography_11" title=" Xie S,Girshick R,Dollar P,et al.Aggregated residual transformations for deep neural networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,Honolulu,Hawaii,USA:2016:5987-5995." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Aggregated Residual Transformations for Deep Neural Networks">
                                        <b>[11]</b>
                                         Xie S,Girshick R,Dollar P,et al.Aggregated residual transformations for deep neural networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,Honolulu,Hawaii,USA:2016:5987-5995.
                                    </a>
                                </li>
                                <li id="234">


                                    <a id="bibliography_12" title=" Huang G,Liu Z,Maaten L V D,et al.Densely connected convolutional networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:2261-2269." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Densely Connected Convolutional Networks">
                                        <b>[12]</b>
                                         Huang G,Liu Z,Maaten L V D,et al.Densely connected convolutional networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:2261-2269.
                                    </a>
                                </li>
                                <li id="236">


                                    <a id="bibliography_13" title=" 薛伟,钱平.基于小波变换和神经网络模型的数字调制识别方法[J].计算机应用与软件,2012,29(8):210-213." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201208059&amp;v=MDA1NDVMRzRIOVBNcDQ5QWJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hVYjdMTHpUWlo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         薛伟,钱平.基于小波变换和神经网络模型的数字调制识别方法[J].计算机应用与软件,2012,29(8):210-213.
                                    </a>
                                </li>
                                <li id="238">


                                    <a id="bibliography_14" title=" Hauser S C,Headley W C,Michaels A J.Signal detection effects on deep neural networks utilizing raw IQ for modulation classification[C]//Military Communications Conference.Baltimore,MD,USA:IEEE,2017:121-127." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Signal detection effects on deep neural networks utilizing raw IQ for modulation classification">
                                        <b>[14]</b>
                                         Hauser S C,Headley W C,Michaels A J.Signal detection effects on deep neural networks utilizing raw IQ for modulation classification[C]//Military Communications Conference.Baltimore,MD,USA:IEEE,2017:121-127.
                                    </a>
                                </li>
                                <li id="240">


                                    <a id="bibliography_15" title=" O’Shea T J,Corgan J,Clancy T C.Convolutional radio modulation recognition networks[C]//International Conference on Engineering Applications of Neural Networks.Aberdeen,United Kingdom:Springer International Publishing,2016:213-226." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Convolutional radio modulation recognition networks,&amp;quot;">
                                        <b>[15]</b>
                                         O’Shea T J,Corgan J,Clancy T C.Convolutional radio modulation recognition networks[C]//International Conference on Engineering Applications of Neural Networks.Aberdeen,United Kingdom:Springer International Publishing,2016:213-226.
                                    </a>
                                </li>
                                <li id="242">


                                    <a id="bibliography_16" title=" West N E,O’Shea T J.Deep architectures for modulation recognition[C]//International Symposium on Dynamic Spectrum Access Networks (DySPAN) Piscataway,NJ,USA:IEEE,2017:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep architectures for modulation recognition">
                                        <b>[16]</b>
                                         West N E,O’Shea T J.Deep architectures for modulation recognition[C]//International Symposium on Dynamic Spectrum Access Networks (DySPAN) Piscataway,NJ,USA:IEEE,2017:1-6.
                                    </a>
                                </li>
                                <li id="244">


                                    <a id="bibliography_17" title=" 陈敏华,李杨,张武雄.基于卷积神经网络的信道均衡算法[J].计算机应用与软件,2017,34(9):257-261." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201709050&amp;v=MDMxOThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvaFViN0xMelRaWkxHNEg5Yk1wbzlBWkk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         陈敏华,李杨,张武雄.基于卷积神经网络的信道均衡算法[J].计算机应用与软件,2017,34(9):257-261.
                                    </a>
                                </li>
                                <li id="246">


                                    <a id="bibliography_18" title=" Zhang M,Diao M,Guo L M.Convolutional neural networks for automatic cognitive radio waveform recognition[J].IEEE Access,2017,5:11074-11082." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for automatic cognitive radio waveform recognition">
                                        <b>[18]</b>
                                         Zhang M,Diao M,Guo L M.Convolutional neural networks for automatic cognitive radio waveform recognition[J].IEEE Access,2017,5:11074-11082.
                                    </a>
                                </li>
                                <li id="248">


                                    <a id="bibliography_19" title=" Wang D S,Zhang M,Li Z,et al.Modulation format recognition and OSNR estimation using CNN-5ased deep learning[J].IEEE Photonics Technology Letters,2017,29(19):1667-1670." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modulation Format Recognition and OSNR Estimation Using CNN-based Deep Learning">
                                        <b>[19]</b>
                                         Wang D S,Zhang M,Li Z,et al.Modulation format recognition and OSNR estimation using CNN-5ased deep learning[J].IEEE Photonics Technology Letters,2017,29(19):1667-1670.
                                    </a>
                                </li>
                                <li id="250">


                                    <a id="bibliography_20" title=" Zhang J,Li Y,Yin J P.Modulation classification method for frequency modulation signals based on the time–frequency distribution and CNN[J].IET Radar,Sonar &amp;amp; Navigation,2018,12(2):244-249." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modulation classification method for frequency modulation signals based on the time–frequency distribution and CNN">
                                        <b>[20]</b>
                                         Zhang J,Li Y,Yin J P.Modulation classification method for frequency modulation signals based on the time–frequency distribution and CNN[J].IET Radar,Sonar &amp;amp; Navigation,2018,12(2):244-249.
                                    </a>
                                </li>
                                <li id="252">


                                    <a id="bibliography_21" title=" Karra K,Kuzdeba S,Petersen J.Modulation recognition using hierarchical deep neural networks[C]//2017 IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN).IEEE,2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modulation recognition using hierarchical deep neural networks">
                                        <b>[21]</b>
                                         Karra K,Kuzdeba S,Petersen J.Modulation recognition using hierarchical deep neural networks[C]//2017 IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN).IEEE,2017.
                                    </a>
                                </li>
                                <li id="254">


                                    <a id="bibliography_22" title=" Peng S,Jiang H,Wang H,et al.Modulation classification using convolutional Neural Network based deep learning model[C]//Wireless and Optical Communication Conference.Newark,NJ,USA:IEEE,2017:1-5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modulation classification using convolutional Neural Network based deep learning model">
                                        <b>[22]</b>
                                         Peng S,Jiang H,Wang H,et al.Modulation classification using convolutional Neural Network based deep learning model[C]//Wireless and Optical Communication Conference.Newark,NJ,USA:IEEE,2017:1-5.
                                    </a>
                                </li>
                                <li id="256">


                                    <a id="bibliography_23" title=" Hu J,Li S,Albanie S,et al.Squeeze-and-Excitation Networks[EB].Eprint ArXiv:1709.01507,2018." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Squeeze-and-Excitation Networks[EB]">
                                        <b>[23]</b>
                                         Hu J,Li S,Albanie S,et al.Squeeze-and-Excitation Networks[EB].Eprint ArXiv:1709.01507,2018.
                                    </a>
                                </li>
                                <li id="258">


                                    <a id="bibliography_24" title=" Maas A L,Hannun A Y,Ng A Y.Rectifier nonlinearities improve neural network acoustic models[C]//Proceedings of the 30th International Conference on Machine Learning,Athlanta,Georgia,USA:JMLR,2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rectifier nonlinearities improve neural network acoustic models">
                                        <b>[24]</b>
                                         Maas A L,Hannun A Y,Ng A Y.Rectifier nonlinearities improve neural network acoustic models[C]//Proceedings of the 30th International Conference on Machine Learning,Athlanta,Georgia,USA:JMLR,2013.
                                    </a>
                                </li>
                                <li id="260">


                                    <a id="bibliography_25" title=" Lin M,Chen Q,Yan S.Network in network[EB].arXiv preprint arXiv:1312.4400,2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Network in network[EB]">
                                        <b>[25]</b>
                                         Lin M,Chen Q,Yan S.Network in network[EB].arXiv preprint arXiv:1312.4400,2013.
                                    </a>
                                </li>
                                <li id="262">


                                    <a id="bibliography_26" title=" Kingma D P,Ba J.Adam:A method for stochastic optimization[EB].arXiv preprint arXiv:1412.6980,2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adam:A method for stochastic optimization[EB]">
                                        <b>[26]</b>
                                         Kingma D P,Ba J.Adam:A method for stochastic optimization[EB].arXiv preprint arXiv:1412.6980,2014.
                                    </a>
                                </li>
                                <li id="264">


                                    <a id="bibliography_27" title=" Goodfellow I,Bengio Y,Courville A.深度学习[M].赵申剑,黎彧君,符天凡,等译.北京:人民邮电出版社,2017,142-144." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787115461476000&amp;v=MzEyNThVU21EZDlTSDduM3hFOWZidm5LcmlmWnU5dUZDcmxVN2pNSWw4WFhGcXpHYks1RzlYS3JvdENZdXNQREJNOHp4&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[27]</b>
                                         Goodfellow I,Bengio Y,Courville A.深度学习[M].赵申剑,黎彧君,符天凡,等译.北京:人民邮电出版社,2017,142-144.
                                    </a>
                                </li>
                                <li id="266">


                                    <a id="bibliography_28" >
                                        <b>[28]</b>
                                     Glorot X,Bengio Y.Understanding the difficulty of training deep feedforward neural networks[J].Journal of Machine Learning Research,2010,9:249-256.</a>
                                </li>
                                <li id="268">


                                    <a id="bibliography_29" title=" Ruder S.An overview of gradient descent optimization algorithms[EB].Eprint ArXiv:1609.04747,2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An overview of gradient descent optimization algorithms[EB]">
                                        <b>[29]</b>
                                         Ruder S.An overview of gradient descent optimization algorithms[EB].Eprint ArXiv:1609.04747,2016.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(11),202-209 DOI:10.3969/j.issn.1000-386x.2019.11.033            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于卷积神经网络的多进制相位调制信号识别算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E4%BD%A9%E5%86%9B&amp;code=41407209&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴佩军</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BE%AF%E8%BF%9B&amp;code=25811201&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">侯进</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%95%E5%BF%97%E8%89%AF&amp;code=41407210&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吕志良</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E9%9B%A8%E7%81%B5&amp;code=40507527&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘雨灵</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E8%8C%82&amp;code=27780543&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐茂</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E7%AC%91%E8%AF%AD&amp;code=35271699&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张笑语</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%9B%BE&amp;code=40507528&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈曾</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8D%97%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0218487&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西南交通大学信息科学与技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%88%90%E9%83%BD%E5%8D%8E%E6%97%A5%E9%80%9A%E8%AE%AF%E6%8A%80%E6%9C%AF%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8&amp;code=0933582&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">成都华日通讯技术有限公司</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>由于多进制相位调制子类信号相似度高,传统的信号识别方法和机器学习算法难以实现特征的自动提取和准确的分类。针对此问题,提出一种基于时频图和深度卷积神经网络的识别算法。将实测信号通过短时傅里叶变换转换成时频图作为实验数据,并设计一个33层的卷积神经网络ReSENet对特征进行自动提取和调制识别。该网络融合了经典模型ResNext和SENet的优点,能通过深度学习和特征重定向学习到数据中复杂抽象的特征。为进一步提高ReSENet的性能,分别从梯度下降算法、激活函数等方面对模型进行优化。与现有方法相比,该算法在对多进制相位调制信号识别上有更优的分类表现。实验结果显示,最终的识别准确率达到99.9%,验证了该算法的有效性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B0%83%E5%88%B6%E4%BF%A1%E5%8F%B7%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">调制信号识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%AD%E6%97%B6%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">短时傅里叶变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%B6%E9%A2%91%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">时频图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    吴佩军，硕士生，主研领域:计算机视觉，深度学习。;
                                </span>
                                <span>
                                    侯进，副教授。;
                                </span>
                                <span>
                                    吕志良，硕士生。;
                                </span>
                                <span>
                                    刘雨灵，硕士生。;
                                </span>
                                <span>
                                    徐茂，硕士生。;
                                </span>
                                <span>
                                    张笑语，高工。;
                                </span>
                                <span>
                                    陈曾，硕士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-26</p>

                    <p>

                            <b>基金：</b>
                                                        <span>浙江大学CAD&amp;CG国家重点实验室开放课题(A1923);</span>
                                <span>成都市科技项目(2015-HM01-00050-SF);</span>
                    </p>
            </div>
                    <h1><b>MULTI-PHASE MODULATION SIGNAL RECOGNITION ALGORITHM BASED ON CONVOLUTIONAL NEURAL NETWORK</b></h1>
                    <h2>
                    <span>Wu Peijun</span>
                    <span>Hou Jin</span>
                    <span>Lü Zhiliang</span>
                    <span>Liu Yuling</span>
                    <span>Xu Mao</span>
                    <span>Zhang Xiaoyu</span>
                    <span>Chen Zeng</span>
            </h2>
                    <h2>
                    <span>School of Information Science and Technology, Southwest Jiaotong University</span>
                    <span>Chengdu Huari Communication Technology Co., Ltd.</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Due to the high similarity of multi-phase modulated signals, traditional signal recognition methods and machine learning algorithms are difficult to achieve automatic feature extraction and accurate classification. To overcome the problems mentioned above, we proposed a recognition algorithm based on time-frequency graphs and deep convolutional neural network. The measured signals were converted into time-frequency graphs by short-time Fourier transform as experimental data. Then, a 33-layer convolutional neural network ReSENet was designed for automatic feature extraction and modulation recognition. Combining the advantages of the classic models ResNext and SENet, ReSENet was capable of learning complex and abstract features of data through deep learning and feature redirection. In order to further improve the performance of ReSENet, the model was optimized from the aspects of gradient descent algorithm, activation function, etc. Compared with the existing methods, the proposed algorithm has better performance for multi-phase modulation signal recognition. Experiments conducted on the measured data have verified the effectiveness of the proposed algorithm with an accuracy of 99.9%.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Modulation%20signal%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Modulation signal recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20neural%20networks&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional neural networks;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Short-time%20Fourier%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Short-time Fourier transform;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Time-frequency%20diagram&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Time-frequency diagram;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deep learning;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-26</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="61" name="61" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="62">多进制数字相位调制技术是现代通信系统中常用的数字调制技术之一。如何有效地识别出多进制数字相位调制(Multiple Phase Shift Keying,MPSK)信号中的BPSK、QPSK和8PSK信号一直是调制识别领域内人们关注的一个热点和难点问题。</p>
                </div>
                <div class="p1">
                    <p id="63">在传统的调制信号识别领域,主要采用基于统计和基于决策的两大类方法进行识别。然而传统方法具有求解参数多、计算公式复杂等缺点。</p>
                </div>
                <div class="p1">
                    <p id="64">近年来,大量的机器学习算法,如期望最大值算法<citation id="270" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、反向传播人工神经网络<citation id="271" type="reference"><link href="214" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、k邻近算法<citation id="272" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>以及支持向量机<citation id="273" type="reference"><link href="218" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等算法被逐渐应用于调制信号识别领域内,并取得了一定的成效。</p>
                </div>
                <div class="p1">
                    <p id="65">卷积神经网络(Con1volution Neural Network,CNN)作为机器学习算法的一大重要分支,近年来在图像识别领域取得了许多重要突破。深层卷积神经网络更容易提取到数据的抽象特征,获得不同数据类别间的隐式表达,有利于捕捉图像数据中的关键信息<citation id="274" type="reference"><link href="220" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。Krizhevshky等<citation id="275" type="reference"><link href="222" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了AlexNet模型,它指出随着网络层数的加深,可以学习图像中的复杂高维特征,提升分类准确率。此外,AlexNet使用Relu作为激活函数,降低了参数计算量;并且使用了dropout技术在训练时剔除某些神经元,避免模型的过拟合。但AlexNet在浅层时使用如9×9、11×11的大卷积核提取特征,具有运算开销大的缺点。VGG<citation id="276" type="reference"><link href="226" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>通过使用多个3×3的卷积核代替AlexNet的大卷积核,减少了运算参数,改进了AlexNet运算开销大的缺点。与此同时,Inception V1<citation id="277" type="reference"><link href="224" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>通过提出一种分解-变换-聚合的结构:使用1×1、3×3和5×5的卷积核并行合并,并在合并后接1×1卷积核以减少特征数量。随着CNN层数的加深,容易出现梯度扩散。此时单纯地加深网络层数难以提升识别准确率。因此,文献<citation id="278" type="reference">[<a class="sup">9</a>]</citation>在Inception V1的基础上加入了批量正则化层(Batch Normalization,BN),提出了Inception V3模型,BN层的加入能够提升网络的泛化能力。ResNet<citation id="279" type="reference"><link href="230" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>将输入信息跨层传递并与卷积后的输出相加,在不增加网络层数的情况下保留了丰富的高维信息,进一步解决了梯度扩散的问题。何凯明等<citation id="280" type="reference"><link href="232" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出了ResNeXt模型,在文献<citation id="281" type="reference">[<a class="sup">10</a>]</citation>的结构中加入了文献<citation id="282" type="reference">[<a class="sup">9</a>]</citation>的分解-变换-聚合思想,使得ResNeXt能够在不增加网络复杂度的情况下提升准确率。文献<citation id="283" type="reference">[<a class="sup">12</a>]</citation>提出了DenseNet模型,能够有效地解决梯度消失的问题,并且在大幅度减少参数量的前提下,强化了特征传播、支持特征重用。</p>
                </div>
                <div class="p1">
                    <p id="66">近年来,CNN在调制信号识别领域内也开始逐渐兴起,并取得了一定的成效。薛伟等<citation id="284" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>利用小波变换提取MFSK、MPSK和MQAM信号的特征参数,再将提取的特征输入到三层的人工神经网络中进行训练,取得了较好的分类效果,但此方法需要人工提取参数特征,且人工神经网络相比深层CNN提取特征的能力有限。Hauser等<citation id="285" type="reference"><link href="238" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>利用原始IQ数据作为4层CNN的输入,实现了8类调制信号的识别,识别准确率达到了80%。文献<citation id="286" type="reference">[<a class="sup">15</a>]</citation>将原始IQ数据输入到4层CNN进行训练,对不同信噪比的调制信号进行了识别分类,模型在高信噪比情况下识别准确率较高,随着信噪比的减小,准确率降低,最终在测试集上达到66.9%的准确率。文献<citation id="287" type="reference">[<a class="sup">16</a>]</citation>参考文献<citation id="288" type="reference">[<a class="sup">9</a>]</citation>提出的Inception结构,设计了一个三层的CNN提取原始IQ数据的特征,再将提取的特征输入到长短期记忆网络(Long Short-Term Memory,LSTM)进行分类,实现了PSK、QAM和FSK等调制信号的分类识别,识别准确率最终达到了87%。但这一方法对MQAM的子类信号识别准确率不高,16QAM和64QAM的准确率均只有40%左右。文献<citation id="296" type="reference">[<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>]</citation>都为利用原始IQ数据输入到浅层CNN中进行分类,取得了一定的成效。考虑到CNN对于丰富的图像信息的提取效果,将IQ数据经过变换生成图像数据训练的研究也逐渐增多,已有方法说明调制信号的图像信息较原始IQ数据,能够提升CNN的分类准确率。陈敏华等<citation id="289" type="reference"><link href="244" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>提出一种基于CNN的信道均衡算法,利用星座图实现了QPSK的识别,达到了82%的准确率,但信号种类单一,识别难度较小。Zhang等<citation id="290" type="reference"><link href="246" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>将雷达信号的时频图输入到一个5层的卷积网络进行特征提取,再将提取的特征输入到多层感知机,实现了8类雷达信号的分类,最终准确率达到了93.7%。Wang等<citation id="291" type="reference"><link href="248" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>提出了一个基于调制信号眼图的6层CNN,实现了RZ-OOK、NRZ-OOK、RZ-DPSK和4PAM的识别。Zhang等<citation id="292" type="reference"><link href="250" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>利用信号时频图输入到一个5层的CNN中,实现了LFM、SFM、PFM、FSK及未调制信号的识别,达到了99.1%的准确率,但此方法对于FSK信号识别准确率较低,大约为90%。Karra等<citation id="293" type="reference"><link href="252" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>提出了一种分层深度神经网络,利用IQ数据经过FFT变换得到信号时频图,实现了一个11类信号的分类器,最终达到了90%的总准确率,但该网络对于QPSK、8PSK和16QAM的识别效果均低于70%。Peng等<citation id="294" type="reference"><link href="254" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>利用调制信号的星座图输入CNN的经典模型AlexNet中进行训练,实现了QPSK、8PSK、16QAM和64QAM的分类,但模型对16QAM和64QAM识别效果差,低信噪比情况下16QAM和64QAM准确率仅有80%,相比文献<citation id="295" type="reference">[<a class="sup">15</a>]</citation>,单类调制信号的子类识别效果有了显著提升。</p>
                </div>
                <div class="p1">
                    <p id="67">目前存在的分类方法中,主要使用浅层CNN进行调制信号的识别,且CNN多用于不同种类调制信号的识别,但对于单类调制信号子分类的识别研究不多。单类调制信号子分类之间相似度比不同种类间信号大,使用原始IQ数据识别难度大,利用图像信息可以提升其分类准确率。针对上述问题,本文采用IQ信号的时频图作为训练数据,并用深层的CNN以提取图像的高维特征,这样既避免了依靠人工设计复杂分类器,又实现了相似度较高信号的自动识别。</p>
                </div>
                <h3 id="68" name="68" class="anchor-tag"><b>1 数据采集与预处理</b></h3>
                <h4 class="anchor-tag" id="69" name="69"><b>1.1 IQ数据采集</b></h4>
                <div class="p1">
                    <p id="70">为收集实验所需的MPSK的三类子信号BPSK/QPSK/8PSK,本文采用Agilent E4438矢量信号发生器发射信号,通过天线使用R&amp;S ESMD接收机进行接收。采集过程中参数设置如下:固定滤波带宽为150 KHz,频点583 M,频谱带宽为500 kHz,滤波器为矩形滤波器。为了客观真实地反映信号特征,本文在进行数据采集时,采用以1 kHz为步长从24 kHz变化至30 kHz的7种码率和以10 dBm为步长从-20 dBm变化至-50 dBm的4种幅度交叉组合,得到28种信号。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71"><b>1.2 数据预处理</b></h4>
                <div class="p1">
                    <p id="72">对于调制信号,时频图具有重要的意义,其特征通常蕴藏于相位随时间的变化中,时间和频率两者具有紧密的联系。从统计的角度看,时频图能比较完整地包含信号的关键信息。因此,利用时频图进行分类识别是信号进行分类识别中最有效的途径之一。短时傅里叶变换(Short-Time Fourier Transform,STFT)通过加窗对时域信号进行无限等长细分,每个细分部分近似平稳,进一步对每个加窗细分部分进行傅里叶变换,从而得到IQ数据的二维时频谱。</p>
                </div>
                <div class="p1">
                    <p id="73">短时傅里叶变换形式表示为:</p>
                </div>
                <div class="p1">
                    <p id="74"><i>STFTP</i>{<i>x</i>[<i>n</i>]}(<i>m</i>,<i>ω</i>)=<mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>n</mi></munder><mi>x</mi></mstyle><mo stretchy="false">[</mo><mi>n</mi><mo stretchy="false">]</mo><mi>ω</mi><mo stretchy="false">[</mo><mi>n</mi><mo>-</mo><mi>m</mi><mo stretchy="false">]</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mi>j</mi><mi>ω</mi><mi>n</mi><mo stretchy="false">)</mo></mrow></math></mathml>(1)</p>
                </div>
                <div class="p1">
                    <p id="76">式中:<i>ω</i>(<i>n</i>)为窗函数,<i>x</i>[<i>n</i>]为输入信号序列,<i>n</i>为时域采样点数。</p>
                </div>
                <div class="p1">
                    <p id="77">由于海明窗能够加宽主瓣减小旁瓣,波动性小,能够有效抑制MPSK信号的频谱泄露,因此本文采用海明窗函数作为STFT变换的窗函数。海明窗函数表示为:</p>
                </div>
                <div class="p1">
                    <p id="78"><i>ω</i>[<i>n</i>]=0.54-(0.46×cos(<i>n</i>/<i>N</i>))      (2)</p>
                </div>
                <div class="p1">
                    <p id="79">式中:<i>n</i>为输入信号序列,<i>N</i>为FFT点数,本文中<i>N</i>设为2 048。</p>
                </div>
                <div class="p1">
                    <p id="80">采集的IQ数据通过STFT变换,即可得到MPSK信号的时频图,如图1所示。通过图1可以看出MPSK信号的时频图相似程度极高,肉眼很难完全区分。</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911034_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 BPSK/QPSK/8PSK的时频图" src="Detail/GetImg?filename=images/JYRJ201911034_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 BPSK/QPSK/8PSK的时频图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911034_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="82">由于MPSK信号的时频图的形式较为固定,若在预处理中加入翻转、随机剪裁等数据增强的处理并不会提升实际应用中的准确率,反而会导致模型在实际应用中的识别效果不佳、泛化性差。因此在数据集的预处理过程中,本文仅将图像的大小缩放为112×112像素,不进行对比度、亮度和随机剪裁等操作。</p>
                </div>
                <div class="p1">
                    <p id="83">生成的所有时频图被随机划分成训练集、验证集和测试集三个部分,并设定数据类别的标签,数据划分情况如表1所示。</p>
                </div>
                <div class="area_img" id="84">
                    <p class="img_tit"><b>表1 时频图数据集划分情况</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="84" border="1"><tr><td><br />标签</td><td>信号类型</td><td>训练样本</td><td>验证样本</td><td>测试样本</td></tr><tr><td><br />0</td><td>BPSK</td><td>5 000</td><td>1 000</td><td>1 000</td></tr><tr><td><br />1</td><td>QPSK</td><td>5 000</td><td>1 000</td><td>1 000</td></tr><tr><td><br />2</td><td>8PSK</td><td>5 000</td><td>1 000</td><td>1 000</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="85" name="85" class="anchor-tag"><b>2 MPSK识别算法模型</b></h3>
                <h4 class="anchor-tag" id="86" name="86"><b>2.1 ReSENet网络</b></h4>
                <div class="p1">
                    <p id="87">目前,已经有诸多优秀模型在图像识别领域内取得了良好成效。本文受深度卷积神经网络ResNeXt<citation id="297" type="reference"><link href="232" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>启发,设计了一个33层的CNN网络ReSENet,用以提取信号的高维特征,并进行识别。ReSENet的整体结构如表2所示。</p>
                </div>
                <div class="area_img" id="88">
                    <p class="img_tit"><b>表2 ReSENet网络结构图</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="88" border="1"><tr><td>输出大小</td><td>ReSENet</td><td>内核大小</td><td>步长</td></tr><tr><td><br />56×56</td><td>卷积层</td><td>3×3</td><td>2</td></tr><tr><td><br />28×28</td><td>最大池化层</td><td>3×3</td><td>2</td></tr><tr><td><br />28×28</td><td>ReSE模块×3</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="89"><b>续表2</b></p>
                </div>
                <div class="area_img" id="90">
                    <p class="img_tit"> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="90" border="1"><tr><td>输出大小</td><td>ReSENet</td><td>内核大小</td><td>步长</td></tr><tr><td><br />14×14</td><td>ReSE模块×3</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math></td></tr><tr><td><br />7×7</td><td>ReSE模块×3</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn></mtd></mtr><mtr><mtd><mn>3</mn><mo>×</mo><mn>3</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>×</mo><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math></td></tr><tr><td colspan="4"><br />全局平均池化层</td></tr><tr><td colspan="4"><br />Softmax层</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="91">在设计过程中,本文结合文献<citation id="298" type="reference">[<a class="sup">23</a>]</citation>的SENet网络能够强调有用通道中信息的特点,加入了SENet中的SE模块作为ReSENet的基础模块ReSE。ReSE模块结构如图2所示。图2中ResNeXt单元结构和SE模块分别如图3和图4所示。</p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911034_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 ReSE模块结构图" src="Detail/GetImg?filename=images/JYRJ201911034_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 ReSE模块结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911034_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911034_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 ResNeXt结构单元示意图" src="Detail/GetImg?filename=images/JYRJ201911034_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 ResNeXt结构单元示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911034_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911034_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 SE模块结构图" src="Detail/GetImg?filename=images/JYRJ201911034_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 SE模块结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911034_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="95">ResNeXt以VGG网络<citation id="299" type="reference"><link href="226" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>的卷积层堆叠设计为基础,其结构单元是一种多分支同构的结构,该结构继承了Inception V1<citation id="300" type="reference"><link href="224" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>中分解-变换-聚合的思想。多分支同构类似于神经元的内积,神经元的内积示意图如图5所示,内积可以看作是分解-变换-聚合思想的简单表达:首先,将输入向量<i><b>X</b></i>分为<i>D</i>个低维向量[<i><b>x</b></i><sub>1</sub>,<i><b>x</b></i><sub>2</sub>,…,<i><b>x</b></i><sub><i>D</i></sub>];其次,通过低维向量和对应权相量做内积得到低维表达式,其中第<i>i</i>(<i>i</i>=1,2,…,<i>D</i>)个向量<i><b>x</b></i><sub><i>i</i></sub>加权变换后的表达式为<i>w</i><sub><i>i</i></sub><i><b>x</b></i><sub><i>i</i></sub>;最后,将<i>D</i>个低维表达式相加并聚合得到<mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>。在多分支同构中,上一层网络的输出张量<i><b>x</b></i>对应神经元内积中的<i><b>X</b></i>,令<image href="images/JYRJ201911034_154.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub><i>i</i></sub>(<i><b>x</b></i>)为<i><b>x</b></i>被<image href="images/JYRJ201911034_155.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub><i>i</i></sub>函数投影的低维嵌入,最终聚合后的变换表达式为:<image href="images/JYRJ201911034_156.jpg" type="" display="inline" placement="inline"><alt></alt></image>(<i><b>x</b></i>)=<mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml><image href="images/JYRJ201911034_158.jpg" type="" display="inline" placement="inline"><alt></alt></image>(<i><b>x</b></i>)。其中,<i>C</i>为<i><b>x</b></i>分解的低维向量个数,即多分支同构的分支数量。</p>
                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911034_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 神经元的内积" src="Detail/GetImg?filename=images/JYRJ201911034_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 神经元的内积  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911034_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="97">由于时频图的各种特征对识别的贡献不一,卷积层在低层提取轮廓、纹理等特征,在高层提取抽象特征,卷积层提取的特征无法由人为辨别是否有效,而SE模块的特征重定向功能解决了上述问题。特征重定向通过学习全局信息,能够自动判断每个特征通道的重要程度,并对特征通道设定权重,显式地建立特征通道之间的相互依赖关系,从而强调有用特征,抑制对识别贡献少的特征。SE模块主要分为两部分:挤压模块Squeeze和激励模块Excitation。SE模块实现特征重定向的步骤如算法1所示。</p>
                </div>
                <div class="p1">
                    <p id="98"><b>算法1</b> SE模块的特征重定向</p>
                </div>
                <div class="p1">
                    <p id="99">步骤1:将卷积后的特征的全局空间信息分通道压缩,压缩方式为全局平均池化,计算式表示为:</p>
                </div>
                <div class="p1">
                    <p id="100"><mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>z</mi><msub><mrow></mrow><mi>c</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Η</mi><mo>×</mo><mi>W</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Η</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>W</mi></munderover><mi>u</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>c</mi></msub></mrow></math></mathml>      (3)</p>
                </div>
                <div class="p1">
                    <p id="101">式中:<i>u</i><sub><i>c</i></sub>为卷积后的三维特征,其通道数、高和宽分别用<i>C</i>、<i>H</i>和<i>W</i>表示;<i>z</i><sub><i>c</i></sub>为压缩后的新信道信息。</p>
                </div>
                <div class="p1">
                    <p id="102">步骤2:将新信道信息通过sigmoid激活函数激活以捕获信道间的非线性互斥关系。此外,SE模块使用了两个全连接层<mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><msub><mrow></mrow><mn>1</mn></msub><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mfrac><mi>C</mi><mi>R</mi></mfrac><mo>×</mo><mi>C</mi></mrow></msup></mrow></math></mathml>和<mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><msub><mrow></mrow><mn>2</mn></msub><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>C</mi><mo>×</mo><mfrac><mi>C</mi><mi>R</mi></mfrac></mrow></msup></mrow></math></mathml>作为阈值以限制模型的复杂度,计算式表示为:</p>
                </div>
                <div class="p1">
                    <p id="103"><i>s</i>=<i>σ</i>(<i>g</i>(<i>z</i>,<i>W</i>))=<i>σ</i>(<i>W</i><sub>2</sub><i>δ</i>(<i>W</i><sub>1</sub><i>z</i>))      (4)</p>
                </div>
                <div class="p1">
                    <p id="104">式中:<i>σ</i>为sigmoid激活函数,<i>σ</i>为Relu函数,<i>W</i><sub>1</sub>和<i>W</i><sub>2</sub>中的降维比例<i>R</i>可自行设置为4、16、64等,<i>s</i>为捕获的信道间非线性互斥关系。</p>
                </div>
                <div class="p1">
                    <p id="105">步骤3:将步骤2中得到的权重加权到每个通道的特征上,完成通道维度上的特征重定向,计算式表示为:</p>
                </div>
                <div class="p1">
                    <p id="106"><mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>x</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mstyle><mo>∼</mo></mover><mo>=</mo><mi>s</mi><mo>⋅</mo><mi>u</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></math></mathml>      (5)</p>
                </div>
                <div class="p1">
                    <p id="107">式中:<mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>x</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mstyle><mo>∼</mo></mover></mrow></math></mathml>为完成特征重定向后的通道信息。</p>
                </div>
                <div class="p1">
                    <p id="108">经过多次卷积提取特征后,将得到的特征图输入到全局平均池化层(Global Average Pooling,GAP)中。GAP能够强化特征图与分类之间的关系。利用GAP代替传统CNN中的全连接层能够更好地避免整体网络结构的过拟合<citation id="301" type="reference"><link href="260" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>。然后,将经过GAP的特征图输入到softmax层中,最后利用交叉熵损失函数计算预测概率与真实类别的误差,从而实现了MPSK信号的分类。</p>
                </div>
                <h4 class="anchor-tag" id="109" name="109"><b>2.2 模型优化</b></h4>
                <div class="p1">
                    <p id="110">此外,本文对ReSENet网络做出了以下优化:</p>
                </div>
                <div class="p1">
                    <p id="111">(1) 梯度下降算法用于更新和计算梯度,使其逼近或达到最优解,从而最小化损失函数。Adam算法<citation id="302" type="reference"><link href="262" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>相对原本的ResNeXt使用的Momentum梯度下降算法,具有学习率自适应、对选择的超参数鲁棒性高的优点,所以本文采用了文献<citation id="303" type="reference">[<a class="sup">26</a>]</citation>中的Adam算法。</p>
                </div>
                <div class="p1">
                    <p id="112">(2) 采用LeakyRelu<citation id="304" type="reference"><link href="258" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>作为本文的激活函数,减少Relu激活函数神经元死亡从而进一步缓解梯度消失问题,提升网络性能。LeakyRelu的表达式如下:</p>
                </div>
                <div class="area_img" id="113">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201911034_11300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="115">式中:<i>α</i><sub><i>i</i></sub>其中是一个很小的常数(本文取0.01),<i>y</i><sub><i>i</i></sub>是经过激活函数后的结果,<i>x</i><sub><i>i</i></sub>是图像进行卷积操作后的结果。</p>
                </div>
                <div class="p1">
                    <p id="116">(3) 加入了L2正则化<citation id="305" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>以减少模型与时频图中噪声信息的相关性,减少过拟合。</p>
                </div>
                <div class="p1">
                    <p id="117">(4) 使用3×3的卷积核<citation id="306" type="reference"><link href="226" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>,而非ResNeXt提出的7×7卷积核,在兼顾卷积获取的信息同时提升网络的运算效率。</p>
                </div>
                <div class="p1">
                    <p id="118">(5) 使用了Xavier初始化,可以提升模型的训练速度及分类准确率<citation id="307" type="reference"><link href="266" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>。</p>
                </div>
                <h3 id="119" name="119" class="anchor-tag"><b>3 实 验</b></h3>
                <h4 class="anchor-tag" id="120" name="120"><b>3.1 参数配置</b></h4>
                <div class="p1">
                    <p id="121">本文使用图形工作站训练神经网络,显卡为 GTX 1080Ti,处理器为Inter(R) Core(R) CPU i7-8700k 3.70 GHz,内存为16 GB。软件环境为Windows 10系统,使用TensorFlow 1.8.0深度学习框架,开发语言为Python 3.5。ResNeXt中分支数量设为4,SE模块中的降维比例<i>R</i>设为4。网络的初始学习率设置为0.001,学习步长设置为4 000步,batch size设置为32。</p>
                </div>
                <h4 class="anchor-tag" id="122" name="122"><b>3.2 实验结果与分析</b></h4>
                <div class="p1">
                    <p id="123">将制作的时频图数据输入到ReSENet中进行训练,模型在4 000步达到收敛,识别准确率为99.9%,其在测试集上的识别率如表3所示。</p>
                </div>
                <div class="area_img" id="124">
                    <p class="img_tit"><b>表3 测试集的识别率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="124" border="1"><tr><td><br />MPSK类别</td><td>标签</td><td>识别准确率/%</td></tr><tr><td><br />BPSK</td><td>0</td><td>99.9</td></tr><tr><td><br />QPSK</td><td>1</td><td>100</td></tr><tr><td><br />8PSK</td><td>2</td><td>99.8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="125">图6为ReSENet在不同层数不同训练步数所提取的时频图特征,可以看出在网络低层提取的低维特征与时频图具有相似性,随着层数加深和训练步数的增加,提取的特征越抽象。</p>
                </div>
                <div class="area_img" id="126">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911034_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 ReSENet提取的特征图" src="Detail/GetImg?filename=images/JYRJ201911034_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 ReSENet提取的特征图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911034_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="127" name="127"><b>3.2.1 有无SE模块的对比</b></h4>
                <div class="p1">
                    <p id="128">本文对SE模块对ReSENet网络性能的影响进行了实验,结果如图7所示。</p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911034_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 SE模块对ReSENet网络性能影响" src="Detail/GetImg?filename=images/JYRJ201911034_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 SE模块对ReSENet网络性能影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911034_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="130">在深度学习中,损失函数和准确率常用于评价模型的分类性能。观察图7可以得出,含有SE模块的模型在训练过程中准确率和损失更快达到最优,且波动较小。最终含有SE模块的准确率为99.9%,损失为0.020 4;不含SE模块的模型准确率为98.2%,损失为0.001 3。SE模块的加入提升了1.7%的准确率,并且损失下降了0.001 3,证明了SE模块的特征重定向功能对模型的性能提升具有显著效果。</p>
                </div>
                <h4 class="anchor-tag" id="131" name="131"><b>3.2.2 不同梯度下降算法的比较</b></h4>
                <div class="p1">
                    <p id="132">为了验证Adam算法对模型的性能,本文与Momentum、SGD及Adagrad三种不同的梯度下降算法进行了对比实验。参考了文献<citation id="308" type="reference">[<a class="sup">29</a>]</citation>中的梯度下降算法优化器的参数设置,再经过调参试验,最终本文所采用的参数设置如表4所示。</p>
                </div>
                <div class="area_img" id="133">
                    <p class="img_tit"><b>表4 不同梯度下降算法的参数设置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="133" border="1"><tr><td><br />梯度下降算法</td><td>参数设置</td></tr><tr><td><br />Adam</td><td>常数:1E-08</td></tr><tr><td><br />Adagrad</td><td>学习率:0.001</td></tr><tr><td><br />Momtentum</td><td>Momentum:0.9</td></tr><tr><td><br />SGD</td><td>学习率:0.001</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="134">图8分别显示了使用不同梯度下降算法的ReSENet的损失及准确率随步数变化的情况。由图8可知, 不论在准确率还是损失的收敛效果上,Adam算法在1 000步时已达到了明显优于其他算法的效果,在后续训练过程中也一直稳定,验证了Adam算法的有效性。</p>
                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911034_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同梯度下降算法效果对比" src="Detail/GetImg?filename=images/JYRJ201911034_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同梯度下降算法效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911034_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="136" name="136"><b>3.2.3 不同激活函数的比较</b></h4>
                <div class="p1">
                    <p id="137">图9为不同激活函数对模型的影响,观察图9可知,LeakyRelu函数相较于sigmoid函数具有更好的准确率,相较于Relu激活函数更快达到准确率最优值且波动较小,说明使用LeakyRelu函数提高了模型的稳定性。</p>
                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911034_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 不同激活函数效果对比" src="Detail/GetImg?filename=images/JYRJ201911034_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 不同激活函数效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911034_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="139" name="139"><b>3.2.4 与其他神经网络的对比</b></h4>
                <div class="p1">
                    <p id="140">为了验证本文方法的性能,本文对ReSENet、文献<citation id="309" type="reference">[<a class="sup">19</a>]</citation>提出的6层CNN网络(CNN-6)和文献<citation id="310" type="reference">[<a class="sup">20</a>]</citation>提出的5层CNN网络(CNN-5)使用同样的样本集分别进行实验。如图10所示,ReSENet的训练准确率远超过CNN-6<citation id="311" type="reference"><link href="248" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>、CNN-5<citation id="312" type="reference"><link href="250" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>,达到99.9%。</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911034_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 ReSENet与其他网络结构训练准确率对比" src="Detail/GetImg?filename=images/JYRJ201911034_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 ReSENet与其他网络结构训练准确率对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911034_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="142">为进一步显示模型性能的差异,采用同类论文中常用的混淆矩阵显示测试集上的实验结果。如图11所示,图中横轴表示类别的真实种类,纵轴表示预测种类。以图11(a)为例,BPSK总计1 000幅,其中999幅预测正确,只有1幅被误判为QPSK。由图11可知,CNN-6对BPSK识别效果良好,但对QPSK及8PSK的识别效果较差;CNN-5对每类信号的识别较为均衡,但对各类信号的识别准确率均较低。而ReSENet对每类图片均具有最好的识别效果,对三类信号的识别准确率达99.9%,较CNN-6提升了18.5%,较CNN-5提升了26.7%。</p>
                </div>
                <div class="area_img" id="211">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911034_21100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 1 Re SENet与其他网络结构测试集效果对比" src="Detail/GetImg?filename=images/JYRJ201911034_21100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 1 Re SENet与其他网络结构测试集效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911034_21100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="146">可以看出,本文使用的ReSENet结构具有三大优点:</p>
                </div>
                <div class="p1">
                    <p id="147">(1) CNN-6<citation id="313" type="reference"><link href="248" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>、CNN-5<citation id="314" type="reference"><link href="250" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>均采用层数较少的卷积神经网络,而ReSENet具有27层多分支并行结构,网络越深越宽,其对应的滤波器能够提取到越复杂抽象的特征,越利于信号的准确分类。</p>
                </div>
                <div class="p1">
                    <p id="148">(2) CNN-6和CNN-5的卷积核尺寸分别为5×5、9×9而ReSENet使用了多个3×3和1×1卷积核进行堆叠,以减少每步参数的计算量。</p>
                </div>
                <div class="p1">
                    <p id="149">(3) 本文加入的SE模块能够学习特征通道间的相互依赖关系,提升有用特征通道对识别准确率的贡献。</p>
                </div>
                <h3 id="150" name="150" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="151">本文针对MPSK子类信号难以用传统方法自动识别、现有方法识别准确率较低的问题,提出了一种新的深度卷积神经网络模型ReSENet。经过实验验证,本文提出的ReSENet在MPSK数据集的分类上具有优秀的表现,识别准确率达到99.9%,实现了特征自提取的目的,解决了已有方法对调制信号子类识别准确率不高的问题。但本文仅对MPSK子信号的识别进行了研究,在后续工作中,可以考虑将进一步完善网络,将其应用于多种调制信号,如MFSK、ASK和QAM等子类混合的识别任务中。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="212">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinear impairment compensation using expectation maximization for dispersion managed and unmanaged PDM 16-QAM transmission">

                                <b>[1]</b> Zibar D,Winther O,Granceschi N,et al.Nonlinear impairment compensation using expectation maximization for dispersion managed and unmanaged PDM 16-QAM transmission[J].Optics Express,2012,20(26):181-96.
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Artificial Neural Network Nonlinear Equalizer for Coherent Optical OFDM">

                                <b>[2]</b> Jarajreh M A,Giacoumidis E,Aldaya I,et al.Artificial neural network nonlinear equalizer for coherent optical OFDM[J].IEEE Photonics Technology Letters,2015,27(4):387-390.
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinearity Mitigation Using a Machine Learning Detector Based on k-Nearest Neighbors">

                                <b>[3]</b> Wang D S,Zhang M,Fu M X,et al.Nonlinearity mitigation using a machine learning detector based on k-Nearest neighbors[J].IEEE Photonics Technology Letters,2016,28(19):2102-2105.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinear decision boundary created by a machine learning-based classifier to mitigate nonlinear phase noise">

                                <b>[4]</b> Wang D S,Zhang M,Li Z,et al.Nonlinear decision boundary created by a machine learning-based classifier to mitigate nonlinear phase noise[C]//European Conference on Optical Communication.Piscataway,NJ:IEEE,2015:1-3.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=OverFeat:integrated recognition,localization and detection using convolutional networks[EB]">

                                <b>[5]</b> Sermanet P,Eigen D,Zhang X,et al.OverFeat:integrated recognition,localization and detection using convolutional networks[EB].Eprint Arxiv:1312.6229,2013.
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Net Classification with Deep Convolutional Neural Networks">

                                <b>[6]</b> Krizhevsky A,Sutkyever I,Hinton G E.ImageNet classification with deep convolutional neural networks[C]//Proceedings of the 25th International Conference on Neural Information Processing Systems—Volume 1.Lake Tahoe,Nevada,USA:Curran Associates Inc,2012:1097-1105.
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 Szegedy C,Liu W,Jia Y Q,et al.Going deeper with convolutions[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,Las Vegas,NV,United States:IEEE,2015:1-9.
                            </a>
                        </p>
                        <p id="226">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition[EB]">

                                <b>[8]</b> Simonyan K,Zisserman A.Very deep convolutional networks for large-scale image recognition[EB].Eprint ArXiv:1409.1556,2014.
                            </a>
                        </p>
                        <p id="228">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rethinking the inception architecture for computer vision">

                                <b>[9]</b> Szegedy C,Vanhoucke V,Ioffe S,et al.Rethinking the inception architecture for computer vision[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:2818-2826.
                            </a>
                        </p>
                        <p id="230">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">

                                <b>[10]</b> He K M,Zhang X Y,Ren S Q,et al.Deep residual learning for image recognition[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2015:770-778.
                            </a>
                        </p>
                        <p id="232">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Aggregated Residual Transformations for Deep Neural Networks">

                                <b>[11]</b> Xie S,Girshick R,Dollar P,et al.Aggregated residual transformations for deep neural networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,Honolulu,Hawaii,USA:2016:5987-5995.
                            </a>
                        </p>
                        <p id="234">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Densely Connected Convolutional Networks">

                                <b>[12]</b> Huang G,Liu Z,Maaten L V D,et al.Densely connected convolutional networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:2261-2269.
                            </a>
                        </p>
                        <p id="236">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201208059&amp;v=MjA2MzlMTHpUWlpMRzRIOVBNcDQ5QWJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hVYjc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 薛伟,钱平.基于小波变换和神经网络模型的数字调制识别方法[J].计算机应用与软件,2012,29(8):210-213.
                            </a>
                        </p>
                        <p id="238">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Signal detection effects on deep neural networks utilizing raw IQ for modulation classification">

                                <b>[14]</b> Hauser S C,Headley W C,Michaels A J.Signal detection effects on deep neural networks utilizing raw IQ for modulation classification[C]//Military Communications Conference.Baltimore,MD,USA:IEEE,2017:121-127.
                            </a>
                        </p>
                        <p id="240">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Convolutional radio modulation recognition networks,&amp;quot;">

                                <b>[15]</b> O’Shea T J,Corgan J,Clancy T C.Convolutional radio modulation recognition networks[C]//International Conference on Engineering Applications of Neural Networks.Aberdeen,United Kingdom:Springer International Publishing,2016:213-226.
                            </a>
                        </p>
                        <p id="242">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep architectures for modulation recognition">

                                <b>[16]</b> West N E,O’Shea T J.Deep architectures for modulation recognition[C]//International Symposium on Dynamic Spectrum Access Networks (DySPAN) Piscataway,NJ,USA:IEEE,2017:1-6.
                            </a>
                        </p>
                        <p id="244">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201709050&amp;v=MjQyNDc0SDliTXBvOUFaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9oVWI3TEx6VFpaTEc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 陈敏华,李杨,张武雄.基于卷积神经网络的信道均衡算法[J].计算机应用与软件,2017,34(9):257-261.
                            </a>
                        </p>
                        <p id="246">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for automatic cognitive radio waveform recognition">

                                <b>[18]</b> Zhang M,Diao M,Guo L M.Convolutional neural networks for automatic cognitive radio waveform recognition[J].IEEE Access,2017,5:11074-11082.
                            </a>
                        </p>
                        <p id="248">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modulation Format Recognition and OSNR Estimation Using CNN-based Deep Learning">

                                <b>[19]</b> Wang D S,Zhang M,Li Z,et al.Modulation format recognition and OSNR estimation using CNN-5ased deep learning[J].IEEE Photonics Technology Letters,2017,29(19):1667-1670.
                            </a>
                        </p>
                        <p id="250">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modulation classification method for frequency modulation signals based on the time–frequency distribution and CNN">

                                <b>[20]</b> Zhang J,Li Y,Yin J P.Modulation classification method for frequency modulation signals based on the time–frequency distribution and CNN[J].IET Radar,Sonar &amp; Navigation,2018,12(2):244-249.
                            </a>
                        </p>
                        <p id="252">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modulation recognition using hierarchical deep neural networks">

                                <b>[21]</b> Karra K,Kuzdeba S,Petersen J.Modulation recognition using hierarchical deep neural networks[C]//2017 IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN).IEEE,2017.
                            </a>
                        </p>
                        <p id="254">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modulation classification using convolutional Neural Network based deep learning model">

                                <b>[22]</b> Peng S,Jiang H,Wang H,et al.Modulation classification using convolutional Neural Network based deep learning model[C]//Wireless and Optical Communication Conference.Newark,NJ,USA:IEEE,2017:1-5.
                            </a>
                        </p>
                        <p id="256">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Squeeze-and-Excitation Networks[EB]">

                                <b>[23]</b> Hu J,Li S,Albanie S,et al.Squeeze-and-Excitation Networks[EB].Eprint ArXiv:1709.01507,2018.
                            </a>
                        </p>
                        <p id="258">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rectifier nonlinearities improve neural network acoustic models">

                                <b>[24]</b> Maas A L,Hannun A Y,Ng A Y.Rectifier nonlinearities improve neural network acoustic models[C]//Proceedings of the 30th International Conference on Machine Learning,Athlanta,Georgia,USA:JMLR,2013.
                            </a>
                        </p>
                        <p id="260">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Network in network[EB]">

                                <b>[25]</b> Lin M,Chen Q,Yan S.Network in network[EB].arXiv preprint arXiv:1312.4400,2013.
                            </a>
                        </p>
                        <p id="262">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adam:A method for stochastic optimization[EB]">

                                <b>[26]</b> Kingma D P,Ba J.Adam:A method for stochastic optimization[EB].arXiv preprint arXiv:1412.6980,2014.
                            </a>
                        </p>
                        <p id="264">
                            <a id="bibliography_27" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787115461476000&amp;v=Mjg3NzU5ZmJ2bktyaWZadTl1RkNybFU3ak1JbDhYWEZxekdiSzVHOVhLcm90Q1l1c1BEQk04enhVU21EZDlTSDduM3hF&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[27]</b> Goodfellow I,Bengio Y,Courville A.深度学习[M].赵申剑,黎彧君,符天凡,等译.北京:人民邮电出版社,2017,142-144.
                            </a>
                        </p>
                        <p id="266">
                            <a id="bibliography_28" >
                                    <b>[28]</b>
                                 Glorot X,Bengio Y.Understanding the difficulty of training deep feedforward neural networks[J].Journal of Machine Learning Research,2010,9:249-256.
                            </a>
                        </p>
                        <p id="268">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An overview of gradient descent optimization algorithms[EB]">

                                <b>[29]</b> Ruder S.An overview of gradient descent optimization algorithms[EB].Eprint ArXiv:1609.04747,2016.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201911034" />
        <input id="dpi" type="hidden" value="96" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201911034&amp;v=MTI3NjVMT2VaZVZ1RnkvaFViN0lMelRaWkxHNEg5ak5ybzlHWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
