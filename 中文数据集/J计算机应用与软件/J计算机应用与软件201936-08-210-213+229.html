<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135612692033750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201908037%26RESULT%3d1%26SIGN%3dC%252bGFBcIsHPJREbLqpuE1V30DTis%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201908037&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201908037&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201908037&amp;v=MDkzMjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1WYnJBTHpUWlpMRzRIOWpNcDQ5R1k0UUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;1 算法描述&lt;/b&gt; "><b>1 算法描述</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#33" data-title="&lt;b&gt;1.1 LLE分类算法描述及缺陷&lt;/b&gt;"><b>1.1 LLE分类算法描述及缺陷</b></a></li>
                                                <li><a href="#45" data-title="&lt;b&gt;1.2 改进分类算法描述&lt;/b&gt;"><b>1.2 改进分类算法描述</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#60" data-title="&lt;b&gt;2 实验与性能分析&lt;/b&gt; "><b>2 实验与性能分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="&lt;b&gt;2.1 图像分类效果分析&lt;/b&gt;"><b>2.1 图像分类效果分析</b></a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;2.2 降维效果分析&lt;/b&gt;"><b>2.2 降维效果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#74" data-title="&lt;b&gt;3 结 语&lt;/b&gt; "><b>3 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="图1 利用LLE算法将3D降维到2D数据局部嵌入结果">图1 利用LLE算法将3D降维到2D数据局部嵌入结果</a></li>
                                                <li><a href="#48" data-title="图2 Mod-LLE算法的局部相邻区域的优化结果">图2 Mod-LLE算法的局部相邻区域的优化结果</a></li>
                                                <li><a href="#64" data-title="图3 局部线性嵌入LLE算法分类效果">图3 局部线性嵌入LLE算法分类效果</a></li>
                                                <li><a href="#64" data-title="图3 局部线性嵌入LLE算法分类效果">图3 局部线性嵌入LLE算法分类效果</a></li>
                                                <li><a href="#66" data-title="&lt;b&gt;表1 Mod-LLE和LLE分类识别正确率比较&lt;/b&gt;"><b>表1 Mod-LLE和LLE分类识别正确率比较</b></a></li>
                                                <li><a href="#70" data-title="图4 S-curve 数据集">图4 S-curve 数据集</a></li>
                                                <li><a href="#71" data-title="图5 S-curve 数据集在&lt;i&gt;N&lt;/i&gt;=2 000情况下样本点散点图">图5 S-curve 数据集在<i>N</i>=2 000情况下样本点散点图</a></li>
                                                <li><a href="#72" data-title="图6 LLE针对S-curve 数据集的2维嵌入效果">图6 LLE针对S-curve 数据集的2维嵌入效果</a></li>
                                                <li><a href="#73" data-title="图7 Mod-LLE针对S-curve 数据集的2维嵌入效果">图7 Mod-LLE针对S-curve 数据集的2维嵌入效果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Fang Y, Li H, Ma Y, et al.Dimensionality Reduction of Hyperspectral Images Based on Robust Spatial Information Using Locally Linear Embedding[J].IEEE Geoscience and Remote Sensing Letters, 2014, 11 (10) :1712-1716." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dimensionality Reduction of Hyperspectral Images Based on Robust Spatial Information Using Locally Linear Embedding">
                                        <b>[1]</b>
                                         Fang Y, Li H, Ma Y, et al.Dimensionality Reduction of Hyperspectral Images Based on Robust Spatial Information Using Locally Linear Embedding[J].IEEE Geoscience and Remote Sensing Letters, 2014, 11 (10) :1712-1716.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Cao H, Zhang H, Wang C, et al.Supervised Locally Linear Embedding for polarimetric SAR image classification[C]//2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS) .IEEE, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Supervised Locally Linear Embedding for polarimetric SAR image classification">
                                        <b>[2]</b>
                                         Cao H, Zhang H, Wang C, et al.Supervised Locally Linear Embedding for polarimetric SAR image classification[C]//2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS) .IEEE, 2016.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Liu Y, Zhang Y, Yu Z, et al.Incremental supervised locally linear embedding for machinery fault diagnosis[J].Engineering Applications of Artificial Intelligence, 2016, 50:60-70." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9CD6853C7985B3E37A20BC78C692C2E7&amp;v=MDQ3MjIxOU9nemxwR0V6Y0xEblI4K1lDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4THU1eGFBPU5pZk9mYnJMYXRmRXFvdzJZK0lIQ1E0NnVoVVVteg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Liu Y, Zhang Y, Yu Z, et al.Incremental supervised locally linear embedding for machinery fault diagnosis[J].Engineering Applications of Artificial Intelligence, 2016, 50:60-70.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Ward J L, Lumsden S L.Locally linear embedding:dimension reduction of massive protostellar spectra[J].Monthly Notices of the Royal Astronomical Society, 2016, 461 (2) :2250-2256." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Locally linear embedding:dimension reduction of massive protostellar spectra">
                                        <b>[4]</b>
                                         Ward J L, Lumsden S L.Locally linear embedding:dimension reduction of massive protostellar spectra[J].Monthly Notices of the Royal Astronomical Society, 2016, 461 (2) :2250-2256.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 刘方原, 夏克文, 牛文佳.改进重构权值的局部线性嵌入算法[J].中国图象图形学报, 2018, 23 (1) :52-60." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201801006&amp;v=MTMzMzQ5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1WYnJBUHlyZmJMRzRIOW5Ncm8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         刘方原, 夏克文, 牛文佳.改进重构权值的局部线性嵌入算法[J].中国图象图形学报, 2018, 23 (1) :52-60.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 文仕学, 孙磊, 杜俊.渐进学习语音增强方法在语音识别中的应用[J].小型微型计算机系统, 2018, 39 (1) :1-6." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201801001&amp;v=MDE5NTMzenFxQnRHRnJDVVI3cWZadVp0RnlqbVZickFQVFhjZHJHNEg5bk1ybzlGWllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         文仕学, 孙磊, 杜俊.渐进学习语音增强方法在语音识别中的应用[J].小型微型计算机系统, 2018, 39 (1) :1-6.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Scholkopf B, Smola A J, M&#252;ller K R.Nonlinear Component Analysis as a Kernel Eigenvalue Problem[J].Neural Computation, 1998, 10 (5) :1299-1319." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500011613&amp;v=MTI2MTlHZXJxUVRNbndaZVp0RmlubFVyeklJRjBTYnhvPU5pZkpaYks5SHRqTXFvOUZaT29PQ24wNm9CTVQ2VDRQUUgvaXJSZA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Scholkopf B, Smola A J, M&#252;ller K R.Nonlinear Component Analysis as a Kernel Eigenvalue Problem[J].Neural Computation, 1998, 10 (5) :1299-1319.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Roweis S T, Saul L K.Nonlinear dimensionality reduction by locally linear embedding[J].Science, 2000, 290 (5500) :2323-2326." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinear dimensionality reduction by locally linear embedding">
                                        <b>[8]</b>
                                         Roweis S T, Saul L K.Nonlinear dimensionality reduction by locally linear embedding[J].Science, 2000, 290 (5500) :2323-2326.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Zhang L, Tao D, Liu W.Supervised Hessian Eigenmap for dimensionality reduction[C]//2015 IEEE 16th International Conference on Communication Technology (ICCT) .IEEE, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Supervised Hessian Eigenmap for dimensionality reduction">
                                        <b>[9]</b>
                                         Zhang L, Tao D, Liu W.Supervised Hessian Eigenmap for dimensionality reduction[C]//2015 IEEE 16th International Conference on Communication Technology (ICCT) .IEEE, 2016.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Zhao C, Wang C, Hua L, et al.Recognition of Control Chart Pattern Using Improved Supervised Locally Linear Embedding and Support Vector Machine[J].Procedia Engineering, 2017, 174:281-288." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDE1C0CBEC28D78B168D9823FAC722481&amp;v=MDc3NzZDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4THU1eGFBPU5pZk9mY2ZOSDZMTTNQMHdGK2tIZUhzeHZSY1Y0a3QwUUgzaDJtTkdmckNXUWJLZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Zhao C, Wang C, Hua L, et al.Recognition of Control Chart Pattern Using Improved Supervised Locally Linear Embedding and Support Vector Machine[J].Procedia Engineering, 2017, 174:281-288.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Deng T, Deng Y, Shi Y, et al.Research on Improved Locally Linear Embedding Algorithm[J].Communications in Computer &amp;amp; Information Science, 2014, 472:88-92." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Research on Improved Locally Linear Embedding Algorithm">
                                        <b>[11]</b>
                                         Deng T, Deng Y, Shi Y, et al.Research on Improved Locally Linear Embedding Algorithm[J].Communications in Computer &amp;amp; Information Science, 2014, 472:88-92.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Huang R S.Information Technology in an Improved Supervised Locally Linear Embedding for Recognizing Speech Emotion[J].Advanced Materials Research, 2014, 1014:375-378." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJTT&amp;filename=SJTT14080400081656&amp;v=MjE1MjFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRjBTYnhvPU5pZmZlcks4SHRuTXE0OUZaT01PQ25rL29CTVQ2VDRQUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Huang R S.Information Technology in an Improved Supervised Locally Linear Embedding for Recognizing Speech Emotion[J].Advanced Materials Research, 2014, 1014:375-378.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(08),210-213+229 DOI:10.3969/j.issn.1000-386x.2019.08.036            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种面向图像分类的流形学习降维算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%BC%80%E5%8D%97&amp;code=35768690&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘开南</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%86%AF%E6%96%B0%E6%89%AC&amp;code=28986375&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">冯新扬</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B5%E8%B6%85&amp;code=27532718&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邵超</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%89%E4%BA%9A%E5%AD%A6%E9%99%A2%E4%BF%A1%E6%81%AF%E4%B8%8E%E6%99%BA%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1698351&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三亚学院信息与智能工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8D%97%E8%B4%A2%E7%BB%8F%E6%94%BF%E6%B3%95%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0885939&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河南财经政法大学计算机与信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>数据挖掘中的流形学习降维算法可以应用于图像分类等领域。提出一种面向图像分类的流形学习降维算法Mod-LLE (Modified Locally Linear Embedding) 。该算法是针对高维数据的局部线性嵌入降维算法的改进, 其整合了图像识别信息来更好地改善优化效果, 达到在处理过程中保证原始数据固有的拓扑组成结构。以标准数据集作为案例进行测试。图像分类功能测试与降维性能测试结果表明:该算法对于人脸图像的分类精度比较高, 降维性能良好。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B5%81%E5%BD%A2%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">流形学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%80%E9%83%A8%E7%BA%BF%E6%80%A7%E5%B5%8C%E5%85%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">局部线性嵌入;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人脸识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">降维算法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    刘开南, 教授, 主研领域:数据挖掘, 模式识别。;
                                </span>
                                <span>
                                    冯新扬, 讲师。;
                                </span>
                                <span>
                                    邵超, 教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61202285);</span>
                                <span>科技部国家重点研发计划项目 (2017YFC0306400);</span>
                                <span>海南省自然科学基金面上项目 (618MS082);</span>
                    </p>
            </div>
                    <h1><b>A MANIFOLD LEARNING DIMENSIONALITY REDUCTION ALGORITHM FOR IMAGE CLASSIFICATION</b></h1>
                    <h2>
                    <span>Liu Kainan</span>
                    <span>Feng Xinyang</span>
                    <span>Shao Chao</span>
            </h2>
                    <h2>
                    <span>School of Information and Intelligent Engineering, University of Sanya</span>
                    <span>School of Computer and Information Engineering, Henan University of Economics and Law</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Manifold learning dimensionality reduction algorithm is a important tools for data mining such as image classfication applications. This paper proposed a manifold learning dimensionality reduction algorithm called Mod-LLE (Modified Locally Linear Embedding) for image classification. It is a improved modify version of locally linear embedding algorithm.It integrated the identification information of the data to keep the correlation composition of initiate data and explored the intrinsic topology to hunting hidden relationships of the data. A seriers of experiments were done for testing Mod-LLE using standard data sets.The experiments results show that the algorithm can obtain a high classification accuracy for image classification, and it has a better dimensionality reduction performance.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Manifold%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Manifold learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Locally%20linear%20embedding%20(LLE)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Locally linear embedding (LLE) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Image classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Face%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Face recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Dimensionality%20reduction%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Dimensionality reduction algorithm;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-15</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="27" name="27" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="28">在人工智能与数据挖掘问题中, 最常见的是高维数据的提取与分析。近年来提出的高维数据降维算法和特征提取算法, 它们在模式识别、图像分类中已取得了较好的结果<citation id="76" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>, 这些算法关注于寻找原始数据集特征表示中有价值的信息, 在图像分类技术中得到了广泛应用。</p>
                </div>
                <div class="p1">
                    <p id="29">降维算法的目的是为了揭示出在高维数据空间中样本数据的固有的组成特性<citation id="80" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>。传统的线性降维算法有主成分分析法 (principal component analysis, PCA) 、线性判别分析法 (linear discriminant analysis, LDA) 、多维尺度分析法 (multi-dimensional scaling, MDS) 等。基于流形学习的降维方法有核函数主成分分析法 (kernel PCA<citation id="77" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>) 、局部线性嵌入分析法 (locally linear embedding, LLE) <citation id="78" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、黑塞局部线性嵌入方法<citation id="79" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、ISOMAP分析法、拉普拉斯特征映射 (Laplacian Eigenmaps, LE) , 局部保持投影分析法 (locality preserving projections, LPP) 和局部切空间对齐分析法 (local tangent space alignment, LTSA) 。这些算法都可以针对样本数据在高维数据空间完成降维<citation id="81" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>。但是同时它们也会破坏原始数据固有的组成结构, 而且当高维数据空间中数据点处于非均匀性状态时, 会导致降维后数据的嵌入结果比较差。</p>
                </div>
                <div class="p1">
                    <p id="30">为了解决这个问题, 本文提出了一种面向图像分类的新型流形学习算法, 它是针对局部线性嵌入算法的改进, 称为Mod-LLE。Mod-LLE算法整合了识别信息来更好地改善优化效果, 这样就可以保证高维原始数据固有的拓扑组成结构信息。把Mod-LLE算法应用到数据挖掘的图像分类领域, 通过实验证明, Mod-LLE方法与LLE降维算法比较起来, 可以获得比较好的图像分类效果和降维效果。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>1 算法描述</b></h3>
                <div class="p1">
                    <p id="32">本节主要描述高维数据降维算法Mod-LLE, 它主要针对图像的分类这个数据挖掘类应用。把高维图像样本数据映射到低维图像数据的过程中, Mod-LLE算法整合了图像数据的识别信息, 这样就可以保证原始数据的相互组成关系信息。整体来说, Mod-LLE算法通过寻求高维数据固有的拓扑结构来更好地发现数据之间隐藏的关系, 同时寻找具有代表性的维度信息。</p>
                </div>
                <h4 class="anchor-tag" id="33" name="33"><b>1.1 LLE分类算法描述及缺陷</b></h4>
                <div class="p1">
                    <p id="34">原始LLE降维算法中, 假设<b><i>X</i></b>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>N</i></sub>}是在<i>R</i><sup><i>D</i></sup>空间中<i>N</i>个样本的数据集, 这里<i>x</i><sub><i>i</i></sub>∈<i>R</i><sup><i>D</i></sup> (<i>i</i>=1, 2, …, <i>N</i>) , <i>D</i>是数据集的维度。</p>
                </div>
                <div class="p1">
                    <p id="35">在每个数据点<i>x</i><sub><i>i</i></sub>处, 使用<i>x</i><sub><i>i</i></sub>所选择的<i>k</i>个邻居来表示局部线性组成情况。优化权重是通过下面的优化方法来完成的:</p>
                </div>
                <div class="p1">
                    <p id="36"><mathml id="37"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>arg</mi></mrow><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>w</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="38" class="code-formula">
                        <mathml id="38"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mtext> </mtext><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="39">通过权重矩阵<b><i>W</i></b>={<i>w</i><sub><i>i</i></sub>= (<i>w</i><sub><i>i</i>1</sub>, <i>w</i><sub><i>i</i>2</sub>, …, <i>w</i><sub><i>iN</i></sub>) }<sup>T</sup>来完成重构, LLE算法把<b><i>X</i></b>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>N</i></sub>}映射到<b><i>Y</i></b>={<i>y</i><sub>1</sub>, <i>y</i><sub>2</sub>, …, <i>y</i><sub><i>N</i></sub>}, 这里<b><i>Y</i></b>是一个低维数据空间, 根据下式, <b><i>Y</i></b>中保持了高维数据的局部固有属性。</p>
                </div>
                <div class="p1">
                    <p id="40"><mathml id="41"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>arg</mi></mrow><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="42">s.t. <b><i>YY</i></b><sup>T</sup>=<b><i>I</i></b></p>
                </div>
                <div class="p1">
                    <p id="43">这里<b><i>I</i></b>是一个具有<i>N</i>×<i>N</i>的单位矩阵, LLE算法通过这些过程完成优化, 它可以获得<i>d</i>个特征向量, 这样就可以把<b><i>Y</i></b>构造到一个低维数据空间。当高维空间中样本数据是均匀的时候, LLE算法被认为是一个好的降维算法;但是当高维空间中样本数据是非均匀的时候, LLE算法破坏了原始数据的局部固有拓扑组成, 会导致一个比较坏的低维嵌入结果。图1显示了这种情况, 把3维数据空间降到2维数据空间, 可以看到LLE算法完全改变了原始局部数据固有拓扑结构组成。</p>
                </div>
                <div class="area_img" id="44">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908037_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 利用LLE算法将3D降维到2D数据局部嵌入结果" src="Detail/GetImg?filename=images/JYRJ201908037_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 利用LLE算法将3D降维到2D数据局部嵌入结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908037_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="45" name="45"><b>1.2 改进分类算法描述</b></h4>
                <div class="p1">
                    <p id="46">LLE算法使用重新构造权重{<i>w</i><sub><i>ij</i></sub>}来保证原始数据的固有拓扑组成, 但是对于每个<i>x</i><sub><i>i</i></sub>, LLE算法不能反映出与信息最相近的<i>k</i>个邻居密度信息。</p>
                </div>
                <div class="p1">
                    <p id="47">为了克服这个缺陷, Mod-LLE算法可以保证原始数据的本身固有的拓扑组成结构。在Mod-LLE中, 使用识别信息来更好地提取高维数据内部类的距离信息。这样做的目的是在映射一个非均匀分布的高维数据避免一起带入了不同类的样本点。如图2所示。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908037_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 Mod-LLE算法的局部相邻区域的优化结果" src="Detail/GetImg?filename=images/JYRJ201908037_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 Mod-LLE算法的局部相邻区域的优化结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908037_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="49">这里设计的目标函数使用下面的公式来描述:</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>arg</mi></mrow><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>α</mi><mo stretchy="false">∥</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>k</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></munderover><mi>w</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mn>1</mn></msubsup><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>-</mo><mi>β</mi><mo stretchy="false">∥</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>k</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>w</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51">s.t. <b><i>YY</i></b><sup>T</sup>=<b><i>I</i></b></p>
                </div>
                <div class="p1">
                    <p id="52">式中:<i>α</i> 和 <i>β</i>是两个比例因子, 用来统一与调整不同的权重所占的比例, <i>α</i>+<i>β</i>=1。</p>
                </div>
                <div class="p1">
                    <p id="53">Mod-LLE针对高维图像分类降维方法可以用下面的流程来表示。</p>
                </div>
                <div class="p1">
                    <p id="54">输入: <i>D</i> 维数据空间中<i>N</i>个样本中的<i>X</i>个数据集;</p>
                </div>
                <div class="p1">
                    <p id="55">步骤1:对每个 <i>x</i><sub><i>i</i></sub>, 寻找<i>k</i>个最接近邻居;</p>
                </div>
                <div class="p1">
                    <p id="56">步骤2:根据式 (1) 计算局部重构权重{<i>w</i><sub><i>ij</i></sub>};</p>
                </div>
                <div class="p1">
                    <p id="57">步骤3: 在<i>R</i><sup><i>d</i></sup>低维数据空间中映射数据集<i>X</i>→<b><i>Y</i></b>;</p>
                </div>
                <div class="p1">
                    <p id="58">步骤4:通过优化式 (3) 的目标函数来对<b><i>Y</i></b>进行优化, 得到最后的结果;</p>
                </div>
                <div class="p1">
                    <p id="59">输出: 降维嵌入后的结果 <b><i>Y</i></b>。</p>
                </div>
                <h3 id="60" name="60" class="anchor-tag"><b>2 实验与性能分析</b></h3>
                <h4 class="anchor-tag" id="61" name="61"><b>2.1 图像分类效果分析</b></h4>
                <div class="p1">
                    <p id="62">为了测试Mod-LLE算法的性能, 选择脸部图像分类为示例, 这些数据来自于FFace数据集<citation id="82" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。为了测试算法在面对非均匀分布数据的效果, 随机选择了300幅人脸作为样本, 这些都是有高维空间的观察数据。根据图像面部表情, 利用Mod-LLE把这些数据集分到5个不同的类别中:正常脸部表情 (neutral) ;高兴脸部表情 (happiness) ; 生气脸部表情 (anger) ; 吐舌脸部表情 (tongued) ; 撅嘴脸部表情 (pouty) 。</p>
                </div>
                <div class="p1">
                    <p id="63">表1显示了LLE方法和Mod-LLE的识别精度。其中, 图3 (a) 和 (b) 显示了FFace 数据集中这些图像Mod-LLE方法和LLE方法分类到2维空间后的效果, 在最接近邻居个数<i>k</i>=6的情况下LLE和 Mod-LLE算法完成了性能比较。从表1和图3可以清楚地看出, Mod-LLE算法可以在2维数据空间中清楚地分离出高兴脸部表情、生气脸部表情和正常脸部表情, 精度都达到90%以上, 人脸图片分类效果明显优于LLE算法。</p>
                </div>
                <div class="area_img" id="64">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908037_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 局部线性嵌入LLE算法分类效果" src="Detail/GetImg?filename=images/JYRJ201908037_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 局部线性嵌入LLE算法分类效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908037_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="64">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908037_06401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 局部线性嵌入LLE算法分类效果" src="Detail/GetImg?filename=images/JYRJ201908037_06401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 局部线性嵌入LLE算法分类效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908037_06401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="66">
                    <p class="img_tit"><b>表1 Mod-LLE和LLE分类识别正确率比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="66" border="1"><tr><td><br />人脸图像数据</td><td>Mod-LLE正确<br />识别率</td><td>LLE正确识<br />别率</td></tr><tr><td><br />正常neutral</td><td>91</td><td>70</td></tr><tr><td><br />高兴happiness</td><td>92</td><td>76</td></tr><tr><td><br />生气anger</td><td>93</td><td>73</td></tr><tr><td><br />吐舌tongued</td><td>83.5</td><td>61.5</td></tr><tr><td><br />撅嘴pouty</td><td>86</td><td>69</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="67" name="67"><b>2.2 降维效果分析</b></h4>
                <div class="p1">
                    <p id="68">这个部分主要测试Mod-LLE算法的降维性。测试的数据集来自于图4所示<i>R</i><sup>3</sup>空间的人工智能S-curve数据集。图5显示的是S-curve数据集的散点图。可以看出, S-curve的数据由2 000个高维、非线性、流形随机产生的点组成。在最接近邻居个数<i>k</i>=16的情况下, 把S-curve数据集从3维空间嵌入到2维流形空间中。Mod-LLE 和 LLE的计算结果如图6和图7所示。</p>
                </div>
                <div class="p1">
                    <p id="69">值得注意的是, <i>k</i>是每个样本点<i>x</i><sub><i>i</i></sub>被选择的最接近邻居个数, 从图7中可以清楚的看到, Mod-LLE算法可以很好地保持S-curve数据集固有的拓扑组成情况。LLE算法正好相反, 图6显示它对S-curve数据集的固有的拓扑组成情况进行了很大改变, 没有保持多维数据的一致性。分析原因是Mod-LLE算法在重新构造权重矩阵时{<i>w</i><sub><i>ij</i></sub>}可以保证原始数据的固有拓扑组成。而且式 (3) 是线性无关, 具有最优近似解, <i>α</i> 和 <i>β</i>是两个比例因子, 它们和最接近邻居个数<i>k</i>都很好进行调整, 使Mod-LLE有很好的降维效果。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908037_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 S-curve 数据集" src="Detail/GetImg?filename=images/JYRJ201908037_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 S-curve 数据集  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908037_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908037_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 S-curve 数据集在N=2 000情况下样本点散点图" src="Detail/GetImg?filename=images/JYRJ201908037_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 S-curve 数据集在<i>N</i>=2 000情况下样本点散点图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908037_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908037_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 LLE针对S-curve 数据集的2维嵌入效果" src="Detail/GetImg?filename=images/JYRJ201908037_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 LLE针对S-curve 数据集的2维嵌入效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908037_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908037_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 Mod-LLE针对S-curve 数据集的2维嵌入效果" src="Detail/GetImg?filename=images/JYRJ201908037_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 Mod-LLE针对S-curve 数据集的2维嵌入效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908037_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="74" name="74" class="anchor-tag"><b>3 结 语</b></h3>
                <div class="p1">
                    <p id="75">本文提出了一个面向图像分类的流形学习降维算法Mod-LLE, 它基于局部邻居优化策略, 整合了图像识别信息用于高维数据集降维。Mod-LLE在低维数据空间中可以获得比较好的内部类分类效果, 并保持了高维原始数据固有的拓扑组成信息。实验结果表明, Mod-LLE算法在人脸图像分类算法上有很好的分类效果, 在降维效果上优于之前的LLE算法。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dimensionality Reduction of Hyperspectral Images Based on Robust Spatial Information Using Locally Linear Embedding">

                                <b>[1]</b> Fang Y, Li H, Ma Y, et al.Dimensionality Reduction of Hyperspectral Images Based on Robust Spatial Information Using Locally Linear Embedding[J].IEEE Geoscience and Remote Sensing Letters, 2014, 11 (10) :1712-1716.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Supervised Locally Linear Embedding for polarimetric SAR image classification">

                                <b>[2]</b> Cao H, Zhang H, Wang C, et al.Supervised Locally Linear Embedding for polarimetric SAR image classification[C]//2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS) .IEEE, 2016.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9CD6853C7985B3E37A20BC78C692C2E7&amp;v=MTkxMDFyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4THU1eGFBPU5pZk9mYnJMYXRmRXFvdzJZK0lIQ1E0NnVoVVVtejE5T2d6bHBHRXpjTERuUjgrWUNPTnZGU2lXVw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Liu Y, Zhang Y, Yu Z, et al.Incremental supervised locally linear embedding for machinery fault diagnosis[J].Engineering Applications of Artificial Intelligence, 2016, 50:60-70.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Locally linear embedding:dimension reduction of massive protostellar spectra">

                                <b>[4]</b> Ward J L, Lumsden S L.Locally linear embedding:dimension reduction of massive protostellar spectra[J].Monthly Notices of the Royal Astronomical Society, 2016, 461 (2) :2250-2256.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201801006&amp;v=MTM1MjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVZickFQeXJmYkxHNEg5bk1ybzlGWW9RS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 刘方原, 夏克文, 牛文佳.改进重构权值的局部线性嵌入算法[J].中国图象图形学报, 2018, 23 (1) :52-60.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201801001&amp;v=MDM3NDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1WYnJBUFRYY2RyRzRIOW5Ncm85RlpZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 文仕学, 孙磊, 杜俊.渐进学习语音增强方法在语音识别中的应用[J].小型微型计算机系统, 2018, 39 (1) :1-6.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500011613&amp;v=MjkyMzNGMFNieG89TmlmSlpiSzlIdGpNcW85RlpPb09DbjA2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Scholkopf B, Smola A J, Müller K R.Nonlinear Component Analysis as a Kernel Eigenvalue Problem[J].Neural Computation, 1998, 10 (5) :1299-1319.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinear dimensionality reduction by locally linear embedding">

                                <b>[8]</b> Roweis S T, Saul L K.Nonlinear dimensionality reduction by locally linear embedding[J].Science, 2000, 290 (5500) :2323-2326.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Supervised Hessian Eigenmap for dimensionality reduction">

                                <b>[9]</b> Zhang L, Tao D, Liu W.Supervised Hessian Eigenmap for dimensionality reduction[C]//2015 IEEE 16th International Conference on Communication Technology (ICCT) .IEEE, 2016.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDE1C0CBEC28D78B168D9823FAC722481&amp;v=MDE1MzlIWWZPR1FsZkJyTFUwNXR0aHhMdTV4YUE9TmlmT2ZjZk5INkxNM1Awd0Yra0hlSHN4dlJjVjRrdDBRSDNoMm1OR2ZyQ1dRYktlQ09OdkZTaVdXcjdKSUZwbWFCdQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Zhao C, Wang C, Hua L, et al.Recognition of Control Chart Pattern Using Improved Supervised Locally Linear Embedding and Support Vector Machine[J].Procedia Engineering, 2017, 174:281-288.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Research on Improved Locally Linear Embedding Algorithm">

                                <b>[11]</b> Deng T, Deng Y, Shi Y, et al.Research on Improved Locally Linear Embedding Algorithm[J].Communications in Computer &amp; Information Science, 2014, 472:88-92.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJTT&amp;filename=SJTT14080400081656&amp;v=MDY3OThvPU5pZmZlcks4SHRuTXE0OUZaT01PQ25rL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlGMFNieA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Huang R S.Information Technology in an Improved Supervised Locally Linear Embedding for Recognizing Speech Emotion[J].Advanced Materials Research, 2014, 1014:375-378.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201908037" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201908037&amp;v=MDkzMjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1WYnJBTHpUWlpMRzRIOWpNcDQ5R1k0UUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
