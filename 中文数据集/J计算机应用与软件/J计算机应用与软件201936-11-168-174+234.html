<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134079615568750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJYRJ201911029%26RESULT%3d1%26SIGN%3dOEcakcm%252bBJXCRcRNeP3TZFS%252fjrA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201911029&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201911029&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201911029&amp;v=MTg2MzZxQnRHRnJDVVJMT2VaZVZ1RnkvaFVMck5MelRaWkxHNEg5ak5ybzlIYllRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#48" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#53" data-title="&lt;b&gt;1 回波信号预处理&lt;/b&gt; "><b>1 回波信号预处理</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="&lt;b&gt;1.1 无载波超宽带雷达回波信号模型&lt;/b&gt;"><b>1.1 无载波超宽带雷达回波信号模型</b></a></li>
                                                <li><a href="#70" data-title="&lt;b&gt;1.2 回波信号特征处理&lt;/b&gt;"><b>1.2 回波信号特征处理</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#82" data-title="&lt;b&gt;2 基于卷积神经网络的识别算法&lt;/b&gt; "><b>2 基于卷积神经网络的识别算法</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#105" data-title="&lt;b&gt;3 实 验&lt;/b&gt; "><b>3 实 验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#106" data-title="&lt;b&gt;3.1 实验验证&lt;/b&gt;"><b>3.1 实验验证</b></a></li>
                                                <li><a href="#115" data-title="&lt;b&gt;3.2 算法对比&lt;/b&gt;"><b>3.2 算法对比</b></a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;3.3 综合分析&lt;/b&gt;"><b>3.3 综合分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#132" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#64" data-title="图1 SIR-20探地雷达">图1 SIR-20探地雷达</a></li>
                                                <li><a href="#66" data-title="&lt;b&gt;表1 8种人体动作&lt;/b&gt;"><b>表1 8种人体动作</b></a></li>
                                                <li><a href="#69" data-title="图2 原始雷达回波">图2 原始雷达回波</a></li>
                                                <li><a href="#278" data-title="图3 处理后的人体动作回波数据">图3 处理后的人体动作回波数据</a></li>
                                                <li><a href="#278" data-title="图3 处理后的人体动作回波数据">图3 处理后的人体动作回波数据</a></li>
                                                <li><a href="#87" data-title="图4 卷积运算示意图">图4 卷积运算示意图</a></li>
                                                <li><a href="#89" data-title="图5 CNN网络示意图">图5 CNN网络示意图</a></li>
                                                <li><a href="#108" data-title="图6 基于CNN的人体动作识别系统流程图">图6 基于CNN的人体动作识别系统流程图</a></li>
                                                <li><a href="#110" data-title="图7 损失函数变化情况">图7 损失函数变化情况</a></li>
                                                <li><a href="#112" data-title="图8 验证集准确率变化情况">图8 验证集准确率变化情况</a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;表2 卷积神经网络识别结果&lt;/b&gt;"><b>表2 卷积神经网络识别结果</b></a></li>
                                                <li><a href="#118" data-title="图9 主成分特征">图9 主成分特征</a></li>
                                                <li><a href="#119" data-title="图10 主成分排序图">图10 主成分排序图</a></li>
                                                <li><a href="#122" data-title="&lt;b&gt;表3 PCA+SVM实验结果&lt;/b&gt;"><b>表3 PCA+SVM实验结果</b></a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;表4 实验结果对比&lt;/b&gt;"><b>表4 实验结果对比</b></a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;表5 基于雷达的动作识别方法对比&lt;/b&gt;"><b>表5 基于雷达的动作识别方法对比</b></a></li>
                                                <li><a href="#130" data-title="图11 识别准确率对比">图11 识别准确率对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="209">


                                    <a id="bibliography_1" title="李瑞峰，王亮亮，王珂．人体动作行为识别研究综述[J]．模式识别与人工智能，2014,27(1):35-48．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201401005&amp;v=MjIzNTVxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hVTHJNS0Q3WWJMRzRIOVhNcm85RllZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        李瑞峰，王亮亮，王珂．人体动作行为识别研究综述[J]．模式识别与人工智能，2014,27(1):35-48．
                                    </a>
                                </li>
                                <li id="211">


                                    <a id="bibliography_2" title="Chaquet J M,Carmona E J,Fern&#225;ndez-Caballero A.A survey of video datasets for human action and activity recognition[J].Computer Vision and Image Understanding,2013,117(6):633-659．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900015781&amp;v=MjQ3NjdGWk9vS0MzUTRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lKMW9YYnhZPU5pZk9mYks3SHRUTXBvOQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Chaquet J M,Carmona E J,Fern&#225;ndez-Caballero A.A survey of video datasets for human action and activity recognition[J].Computer Vision and Image Understanding,2013,117(6):633-659．
                                    </a>
                                </li>
                                <li id="213">


                                    <a id="bibliography_3" title="Poppe R.A survey on vision-based human action recognition[J].Image and vision computing,2010,28(6):976-990．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201348902&amp;v=MjM2NTVJSjFvWGJ4WT1OaWZPZmJLN0h0RE9yWTlFWis4SEJYdzdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViLw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        Poppe R.A survey on vision-based human action recognition[J].Image and vision computing,2010,28(6):976-990．
                                    </a>
                                </li>
                                <li id="215">


                                    <a id="bibliography_4" title="LE Vanbang，朱煜，NGUYEN Anhtu．深度图像手势分割及HOG-SVM手势识别方法研究[J]．计算机应用与软件，2016,33(12):122-126．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201612031&amp;v=MTU1NzR6cXFCdEdGckNVUkxPZVplVnVGeS9oVUxyTUx6VFpaTEc0SDlmTnJZOUdaWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        LE Vanbang，朱煜，NGUYEN Anhtu．深度图像手势分割及HOG-SVM手势识别方法研究[J]．计算机应用与软件，2016,33(12):122-126．
                                    </a>
                                </li>
                                <li id="217">


                                    <a id="bibliography_5" title="Lara O D,Labrador M A.A survey on human activity recognition using wearable sensors[J].IEEE Comm Unications Surveys and Tutorials,2013,15(3):1192-1209．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A survey on human activity recognition using wearable sensors">
                                        <b>[5]</b>
                                        Lara O D,Labrador M A.A survey on human activity recognition using wearable sensors[J].IEEE Comm Unications Surveys and Tutorials,2013,15(3):1192-1209．
                                    </a>
                                </li>
                                <li id="219">


                                    <a id="bibliography_6" title="Pu Q,Gupta S,Gollakota S,et al.Whole-home gesture recognition using wireless signals[C]//Proceedings of the19th annual international conference on Mobile computing&amp;amp;net Working.ACM,2013:27-38．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Whole-home gesture recognition using wireless signals">
                                        <b>[6]</b>
                                        Pu Q,Gupta S,Gollakota S,et al.Whole-home gesture recognition using wireless signals[C]//Proceedings of the19th annual international conference on Mobile computing&amp;amp;net Working.ACM,2013:27-38．
                                    </a>
                                </li>
                                <li id="221">


                                    <a id="bibliography_7" title="蒋留兵，李骢，车俐．超宽带雷达人体动作识别[J]．电子测量与仪器学报，2018,32(1):129-134．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZIY201801018&amp;v=MDQwMzFNcm85RWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hVTHJNSVRmQ2Q3RzRIOW4=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        蒋留兵，李骢，车俐．超宽带雷达人体动作识别[J]．电子测量与仪器学报，2018,32(1):129-134．
                                    </a>
                                </li>
                                <li id="223">


                                    <a id="bibliography_8" title="刘熠辰，徐丰．基于雷达技术的手势识别[J]．中国电子科学研究院学报，2016,11(6):609-613．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KJPL201606010&amp;v=MTIwNTJGeS9oVUxyTUxpZmJZckc0SDlmTXFZOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        刘熠辰，徐丰．基于雷达技术的手势识别[J]．中国电子科学研究院学报，2016,11(6):609-613．
                                    </a>
                                </li>
                                <li id="225">


                                    <a id="bibliography_9" title="Adib F,Hsu C Y,Mao H,et al.Capturing the human figure through a wall[J].ACM Transactions on Graphics(TOG),2015,34(6):219．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM593E8BB28F4573A7D5FD5AE4F004028E&amp;v=MjczNTBGbjcwa0pUUTZYcUdRMWViYVVSN0xxQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhodzd5OHhhdz1OaWZJWTdheEhhVEUzZjFIYkowTENYczZ2aA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Adib F,Hsu C Y,Mao H,et al.Capturing the human figure through a wall[J].ACM Transactions on Graphics(TOG),2015,34(6):219．
                                    </a>
                                </li>
                                <li id="227">


                                    <a id="bibliography_10" title="Lien J,Gillian N,Karagozler M E,et al.Soli:Ubiquitous gesture sensing with millimeter wave radar[J].ACM Transactions on Graphics(TOG),2016,35(4):142．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM65A264899256392CD5AEB9192E7D8E90&amp;v=MDExNTBPZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHc3eTh4YXc9TmlmSVk3VzliOVBLcTRkTWJla0tDbjh3eldWbjcwNElPbmJqcFJCQWZzYWNNTA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        Lien J,Gillian N,Karagozler M E,et al.Soli:Ubiquitous gesture sensing with millimeter wave radar[J].ACM Transactions on Graphics(TOG),2016,35(4):142．
                                    </a>
                                </li>
                                <li id="229">


                                    <a id="bibliography_11" title="张翼，朱玉鹏，程永强，等．基于微多普勒特征的人体目标雷达回波信号分析[J]．信号处理，2009,25(10):1616-1623．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXCN200910024&amp;v=MTY5NDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvaFVMck1QVFhJWUxHNEh0ak5yNDlIWUlRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        张翼，朱玉鹏，程永强，等．基于微多普勒特征的人体目标雷达回波信号分析[J]．信号处理，2009,25(10):1616-1623．
                                    </a>
                                </li>
                                <li id="231">


                                    <a id="bibliography_12" title="Chen V C.Advances in applications of radar micro-Doppler signatures[C]//2014 IEEE Conference on Antenna Measurements&amp;amp;Applications(CAMA).IEEE,2014．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Advances in applications of radar micro-Doppler signatures">
                                        <b>[12]</b>
                                        Chen V C.Advances in applications of radar micro-Doppler signatures[C]//2014 IEEE Conference on Antenna Measurements&amp;amp;Applications(CAMA).IEEE,2014．
                                    </a>
                                </li>
                                <li id="233">


                                    <a id="bibliography_13" title="Cagliyan B,Gurbuz S Z.Micro-Doppler-Based human activity classification using the mote-scale bumblebee radar[J].IEEE Geoscience and Remote Sensing Letters,2015,12(10):2135-2139．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Micro-Doppler-Based human activity classification using the mote-scale bumblebee radar">
                                        <b>[13]</b>
                                        Cagliyan B,Gurbuz S Z.Micro-Doppler-Based human activity classification using the mote-scale bumblebee radar[J].IEEE Geoscience and Remote Sensing Letters,2015,12(10):2135-2139．
                                    </a>
                                </li>
                                <li id="235">


                                    <a id="bibliography_14" title="Fan T,Ma C,Gu Z,et al.Wireless hand gesture recognition based on continuous-wave Doppler radar sensors[J].IEEE Transactions on Microwave Theory and Techniques,2016,64(11):4012-4020．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Wireless hand gesture recognition based on continuous-wave Doppler radar sensors">
                                        <b>[14]</b>
                                        Fan T,Ma C,Gu Z,et al.Wireless hand gesture recognition based on continuous-wave Doppler radar sensors[J].IEEE Transactions on Microwave Theory and Techniques,2016,64(11):4012-4020．
                                    </a>
                                </li>
                                <li id="237">


                                    <a id="bibliography_15" title="Li G,Zhang R,Ritchie M,et al.Sparsity-driven microDoppler feature extraction for dynamic hand gesture recognition[J].IEEE Transactions on Aerospace and Electronic Systems,2018,54(2):655-665．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparsity-driven microDoppler feature extraction for dynamic hand gesture recognition">
                                        <b>[15]</b>
                                        Li G,Zhang R,Ritchie M,et al.Sparsity-driven microDoppler feature extraction for dynamic hand gesture recognition[J].IEEE Transactions on Aerospace and Electronic Systems,2018,54(2):655-665．
                                    </a>
                                </li>
                                <li id="239">


                                    <a id="bibliography_16" title="王俊，郑彤，雷鹏，等．基于卷积神经网络的手势动作雷达识别方法[J]．北京航空航天大学学报，2018,44(6):1117-1123．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJHK201806001&amp;v=MjE3MjRaYkc0SDluTXFZOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9oVUxyTUp5ZkQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        王俊，郑彤，雷鹏，等．基于卷积神经网络的手势动作雷达识别方法[J]．北京航空航天大学学报，2018,44(6):1117-1123．
                                    </a>
                                </li>
                                <li id="241">


                                    <a id="bibliography_17" title="Park J,Cho S H.IR-UWB radar sensor for human gesture recognition by using machine learning[C]//2016 IEEE 18th International Conference on High Performance Computing and Communications;IEEE 14th International Conference on Smart City;IEEE 2nd International Conference on Data Science and Systems(HPCC/Smart City/DSS).IEEE,2016:1246-1249．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=IR-UWB radar sensor for human gesture recognition by using machine learning">
                                        <b>[17]</b>
                                        Park J,Cho S H.IR-UWB radar sensor for human gesture recognition by using machine learning[C]//2016 IEEE 18th International Conference on High Performance Computing and Communications;IEEE 14th International Conference on Smart City;IEEE 2nd International Conference on Data Science and Systems(HPCC/Smart City/DSS).IEEE,2016:1246-1249．
                                    </a>
                                </li>
                                <li id="243">


                                    <a id="bibliography_18" title="Bryan J D,Kwon J,Lee N,et al.Application of ultra-wide band radar for classification of human activities[J].IET Radar,Sonar&amp;amp;Navigation,2012,6(3):172-179．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Application of ultra-wide band radar for classification of human activities">
                                        <b>[18]</b>
                                        Bryan J D,Kwon J,Lee N,et al.Application of ultra-wide band radar for classification of human activities[J].IET Radar,Sonar&amp;amp;Navigation,2012,6(3):172-179．
                                    </a>
                                </li>
                                <li id="245">


                                    <a id="bibliography_19" title="刘建伟，刘媛，罗雄麟．深度学习研究进展[J]．计算机应用研究，2014,31(7):1921-1930,1942．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201407002&amp;v=MTM5NjZPZVplVnVGeS9oVUxyTUx6N1NaTEc0SDlYTXFJOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        刘建伟，刘媛，罗雄麟．深度学习研究进展[J]．计算机应用研究，2014,31(7):1921-1930,1942．
                                    </a>
                                </li>
                                <li id="247">


                                    <a id="bibliography_20" title="Kim Y,Toomajian B.Hand gesture recognition using microDoppler signatures with convolutional neural network[J].IEEE Access,2016,4:7125-7130．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hand Gesture Recognition Using Micro-Doppler Signatures with Convolutional Neural Network">
                                        <b>[20]</b>
                                        Kim Y,Toomajian B.Hand gesture recognition using microDoppler signatures with convolutional neural network[J].IEEE Access,2016,4:7125-7130．
                                    </a>
                                </li>
                                <li id="249">


                                    <a id="bibliography_21" title="Seyfio&lt;image id=&quot;276&quot; type=&quot;formula&quot; href=&quot;images/JYRJ201911029_27600.jpg&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;lu M S，zbayogˇlu A M,G&#252;rb&#252;z S Z.Deep convolutional autoencoder for radar-based classification of similar aided and unaided human activities[J].IEEE Transactions on Aerospace and Electronic Systems,2018,54(4):1709-1723．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep convolutional autoencoder for radar-based classification of similar aided and unaided human activities">
                                        <b>[21]</b>
                                        Seyfio&lt;image id=&quot;276&quot; type=&quot;formula&quot; href=&quot;images/JYRJ201911029_27600.jpg&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;lu M S，zbayogˇlu A M,G&#252;rb&#252;z S Z.Deep convolutional autoencoder for radar-based classification of similar aided and unaided human activities[J].IEEE Transactions on Aerospace and Electronic Systems,2018,54(4):1709-1723．
                                    </a>
                                </li>
                                <li id="251">


                                    <a id="bibliography_22" title="Zhang Z,Tian Z,Zhou M.Latern:dynamic continuous hand gesture recognition using FMCW radar sensor[J].IEEE Sensors Journal,2018,18(8):3278-3289．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Latern dynamic continuous hand gesture recognition using FMCW radar sensor">
                                        <b>[22]</b>
                                        Zhang Z,Tian Z,Zhou M.Latern:dynamic continuous hand gesture recognition using FMCW radar sensor[J].IEEE Sensors Journal,2018,18(8):3278-3289．
                                    </a>
                                </li>
                                <li id="253">


                                    <a id="bibliography_23" title="黎海涛．超宽带雷达关键技术研究[D]．成都:电子科技大学，2000." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=2000003162.nh&amp;v=MDM0MzBES3JaRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9oVUxyTVYxMjdIck80SGQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                        黎海涛．超宽带雷达关键技术研究[D]．成都:电子科技大学，2000.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(11),168-174+234 DOI:10.3969/j.issn.1000-386x.2019.11.028            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于卷积神经网络的雷达人体动作识别方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%92%8B%E7%95%99%E5%85%B5&amp;code=15585924&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蒋留兵</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%AD%8F%E5%85%89%E8%90%8C&amp;code=42455129&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">魏光萌</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%BD%A6%E4%BF%90&amp;code=15584834&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">车俐</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E5%B9%BF%E8%A5%BF%E6%97%A0%E7%BA%BF%E5%AE%BD%E5%B8%A6%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0269119&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林电子科技大学广西无线宽带通信与信号处理重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林电子科技大学计算机与信息安全学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>利用雷达来识别人体动作对环境要求较低,且避免了摄像头带来的的隐私问题。针对这种需求,提出一种基于超宽带雷达和深度学习算法的人体动作识别方法。利用超宽带雷达的高距离分辨力,并针对人体动作的动态特性,提取出人体目标的距离-时间二维特征,弥补单一距离特征的不足。针对特征图采用一种经过优化的卷积神经网络进行识别。通过SIR-20高速探地雷达平台进行数据采集,对8种不同的人体动作进行识别,最终达到了平均99.2%的正确识别率,验证了该方法的可行性和有效性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E4%BD%93%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人体动作识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B6%85%E5%AE%BD%E5%B8%A6%E9%9B%B7%E8%BE%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">超宽带雷达;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    蒋留兵，研究员，主研领域:雷达信号处理。;
                                </span>
                                <span>
                                    魏光萌，硕士生。;
                                </span>
                                <span>
                                    车俐，高级实验师。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(61561010);</span>
                                <span>广西自然科学基金项目(2017GXNSFAA198089);</span>
                                <span>广西重点研发计划项目(桂科AB18126003,AB16380316);</span>
                    </p>
            </div>
                    <h1><b>HUMAN MOTION RECOGNITION METHOD BY RADAR BASED ON CNN</b></h1>
                    <h2>
                    <span>Jiang Liubing</span>
                    <span>Wei Guangmeng</span>
                    <span>Che Li</span>
            </h2>
                    <h2>
                    <span>Guangxi Wireless Broadband Communication and Signal Processing Key Laboratory, Guilin University of Electronic Technology</span>
                    <span>School of Computer Science and Information Security, Guilin University of Electronic Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The use of radar to recognize human movements has low environmental requirements and avoids privacy issues caused by cameras. Addressing this need, this paper proposes a human motion recognition method based on Ultra-Wide-Band(UWB) radar and deep learning algorithm. Considering the high distance resolution of UWB radar and the dynamic characteristics of the human body movement, the method extracted the distance-time two-dimensional feature of the human body target. It covered the shortage of the single distance feature. For feature maps, an optimized convolution neural network was adopted to perform recognition. Data collection was carried out on the SIR-20 high-speed ground-penetrating radar platform, and 8 different human movements were identified. It achieves the correct recognition rate of 99.2% on average, which successfully verifies the feasibility and effectiveness of the motion recognition method.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Human%20motion%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Human motion recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=UWB%20radar&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">UWB radar;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=CNN&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">CNN;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-25</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="48" name="48" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="49">检测和识别人体动作对于安全监控、人机交互、辅助驾驶和人体健康监测等方面有着重要的意义<citation id="255" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。目前的研究多是基于摄像头来进行识别<citation id="258" type="reference"><link href="211" rel="bibliography" /><link href="213" rel="bibliography" /><link href="215" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>,摄像头对于光照和视距等环境要求很高,且存在侵犯隐私的隐患。因此,有学者尝试用其他传感器<citation id="259" type="reference"><link href="217" rel="bibliography" /><link href="219" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>代替摄像头来感知动作。其中雷达<citation id="260" type="reference"><link href="221" rel="bibliography" /><link href="223" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>具有较好的前景,雷达对光线、视距等环境要求极低,甚至可以忽略静态障碍物实现穿墙识别<citation id="256" type="reference"><link href="225" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,并且已有较成熟的应用<citation id="257" type="reference"><link href="227" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="50">对人体动作的雷达回波进行特征选择和提取是识别的关键,根据雷达的微多普勒效应,当人体相对于雷达天线产生运动时,从回波信号中可以得到相应的微多普勒特征<citation id="262" type="reference"><link href="229" rel="bibliography" /><link href="231" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>。文献<citation id="263" type="reference">[<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</citation>通过提取微多普勒特征,采用不同的识别方法对多个人体动作进行识别,达到较高的准确率。文献<citation id="261" type="reference">[<a class="sup">16</a>]</citation>中通过融合距离-微多普勒二维特征,对四种手势动作实现了有效识别。但大多数基于多普勒雷达的研究没有充分地利用时间维的连续性特征。根据人体动作的特性,每个动作在持续的时间内是有时间相关性的,这种特性应该在识别中被考虑。超宽带雷达带宽比较大,距离分辨力较好,可以分辨人体的多个散射点,并返回各个散射点的距离特征。高距离分辨率的特点和良好的目标识别能力,使其很适合用来感知人体动作<citation id="264" type="reference"><link href="241" rel="bibliography" /><link href="243" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="51">近年来,机器学习和深度学习<citation id="265" type="reference"><link href="245" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>算法给雷达动作识别的性能带来很大提升。文献<citation id="266" type="reference">[<a class="sup">20</a>]</citation>提取手势的微多普勒特征,采用深度卷积神经网络(DCNN)进行识别,对7种手势达到了93.1%的识别准确率。文献<citation id="267" type="reference">[<a class="sup">21</a>]</citation>中提出了一种利用三层深度卷积编码器来对12种人体动作进行识别的方法,相对于SVM(支持向量机)提高了17.3%的识别率。文献<citation id="268" type="reference">[<a class="sup">22</a>]</citation>中提出了一种基于3D-CNN的手势识别系统。但深度学习算法对于数据量的需求较大,易发生过拟合现象,导致识别效果不好。在雷达识别系统中,数据的采集和处理较繁琐,没有公开的数据集来训练模型,所以如何在较少数据量的基础上达到较高的识别准确率,也是当前的研究热点。</p>
                </div>
                <div class="p1">
                    <p id="52">基于上述分析,本文提出了一种基于卷积神经网络的雷达人体动作识别方法,利用无载波超宽带雷达搭建实验系统,提取人体多个散射中心的距离信息和时间连续性特征,生成时间-距离二维特征图;再采用一种改进的卷积神经网络进行特征提取和识别。本文算法对8种典型动作进行识别,达到较高的识别准确率,具有可行性和应用价值。</p>
                </div>
                <h3 id="53" name="53" class="anchor-tag"><b>1 回波信号预处理</b></h3>
                <h4 class="anchor-tag" id="54" name="54"><b>1.1 无载波超宽带雷达回波信号模型</b></h4>
                <div class="p1">
                    <p id="55">超宽带雷达<citation id="269" type="reference"><link href="251" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>(Ultra-Wide-Band,UWB)也被称为脉冲雷达,在精确定位、目标识别等研究中得到广泛应用。超宽带是指这种雷达的一个主要技术特点——占用带宽非常大。超宽带雷达一般不使用载波,而是使用时域脉冲来传输信息。最常用的发射信号是窄脉冲形式的无载波信号,虽然这种信号受限于平均功率,所以限制了雷达的作用距离,但是很适用于目标特性研究。本文采用这种信号来感知并分析人体动作,理论研究中常采用高斯信号来表示窄脉冲形式无载波信号:</p>
                </div>
                <div class="p1">
                    <p id="56"><i>s</i>(<i>t</i>)=<i>A</i> exp[-<i>a</i><sup>2</sup>(<i>t</i>-<i>t</i><sub><i>m</i></sub>)<sup>2</sup>]      (1)</p>
                </div>
                <div class="p1">
                    <p id="57">式中:<i>A</i>表示幅度;<mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>a</mi><mo>=</mo><mfrac><mrow><mn>2</mn><msqrt><mtext>π</mtext></msqrt></mrow><mi>Τ</mi></mfrac><mo>,</mo><mi>Τ</mi></mrow></math></mathml>表示脉冲持续时间。</p>
                </div>
                <div class="p1">
                    <p id="58">雷达信号的固有的距离分辨率的公式为<i>C</i>/(2<i>B</i>),其中,<i>C</i>为光速,<i>B</i>为信号带宽,距离分辨率取决于信号带宽,所以超宽带雷达的距离分辨率较高。本文充分利用超宽带雷达的这种特性,研究人体目标的多散射中心,对回波采用理想的多散射中心点模型,雷达回波中包括多个散射点的距离信息。回波模型为:</p>
                </div>
                <div class="p1">
                    <p id="59"><mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi>A</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>δ</mi><mo stretchy="false">(</mo><mi>t</mi><mo>-</mo><mi>τ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="60">式中:<i>h</i><sub>(</sub><sub><i>t</i></sub><sub>)</sub>表示接收的回波信号;<i>M</i>表示散射中心点的个数;<i>A</i><sub><i>i</i></sub>表示每个散射中心点的强度(幅度);<i>τ</i><sub><i>i</i></sub>表示时间延迟。脉冲响应用Dirac-delta函数来描述,其表达式为:</p>
                </div>
                <div class="area_img" id="277">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201911029_27700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="63">本文中使用的超宽带雷达实验平台为美国GSSI公司研发的SIR-20高性能探地雷达,是GPR系列中最新的产品。SIR-20系统预装了信号采集软件,由一台笔记本电脑控制。本文实验时的雷达参数如下:雷达天线中心频率为400 MHz,带宽为800 MHz,分辨率为5 ps,天线增益为约3 dBI,扫描速率设置为每秒100次,每次扫描采样点设置为512个。测试的数据可以保存在PC机上,图1为SIR-20雷达设备实物。</p>
                </div>
                <div class="area_img" id="64">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 SIR-20探地雷达" src="Detail/GetImg?filename=images/JYRJ201911029_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 SIR-20探地雷达  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="65">在实测过程中,雷达天线距离地面1 m,人体目标与雷达天线的距离为3.5 m,测试者身高为175 cm,采集8种动作数据,表1为动作描述,每种动作重复50次。图2为本文实验采集的原始回波数据示意图。</p>
                </div>
                <div class="area_img" id="66">
                    <p class="img_tit"><b>表1 8种人体动作</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="66" border="1"><tr><td><br />编号</td><td>动作类别</td></tr><tr><td><br />1</td><td>向前走</td></tr><tr><td><br />2</td><td>向前摔倒</td></tr><tr><td><br />3</td><td>向后摔倒</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="67"><b>续表1</b></p>
                </div>
                <div class="area_img" id="68">
                    <p class="img_tit"> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="68" border="1"><tr><td><br />编号</td><td>动作类别</td></tr><tr><td><br />4</td><td>原地摔倒</td></tr><tr><td><br />5</td><td>跳跃</td></tr><tr><td><br />6</td><td>原地坐下</td></tr><tr><td><br />7</td><td>原地旋转</td></tr><tr><td><br />8</td><td>静止站立</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 原始雷达回波" src="Detail/GetImg?filename=images/JYRJ201911029_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 原始雷达回波  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="70" name="70"><b>1.2 回波信号特征处理</b></h4>
                <div class="p1">
                    <p id="71">超宽带雷达的人体动作原始回波信号中包括了人体多个散射中心点的距离信息,可以作为区别每个动作的依据,但是部分不同动作的距离信息相似度较大,单独的距离信息不足以对所有动作进行准确的分类,所以必须研究并提取新的动作特征。</p>
                </div>
                <div class="p1">
                    <p id="72">为了避免单一距离特征的不足,本文采取将距离信息与时间维特征融合的方法,即提取距离信息随时间变化的特征信息。特征提取和数据处理步骤为:</p>
                </div>
                <div class="p1">
                    <p id="73"><b>第一步</b> 将回波中同一时刻的散射点距离信息转为序列信息,单一时刻序列反映多个散射点的距离信息;</p>
                </div>
                <div class="p1">
                    <p id="74"><b>第二步</b> 将距离信息序列在时间轴上排列,得到所有散射点距离信息序列随时间变化的二维特征;</p>
                </div>
                <div class="p1">
                    <p id="75"><b>第三步</b> 对二维特征数据进行归一化处理,消除幅度敏感性;</p>
                </div>
                <div class="p1">
                    <p id="76"><b>第四步</b> 将所有的动作特征数据统一为128×128大小的矩阵,经过处理的人体动作回波数据如图3所示。</p>
                </div>
                <div class="area_img" id="278">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_27800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 处理后的人体动作回波数据" src="Detail/GetImg?filename=images/JYRJ201911029_27800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 处理后的人体动作回波数据  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_27800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="278">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_27801.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 处理后的人体动作回波数据" src="Detail/GetImg?filename=images/JYRJ201911029_27801.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 处理后的人体动作回波数据  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_27801.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="81">因为在特征提取中考虑到时间维特征,所以处理后的数据不仅能够表现出人体所有散射中心的距离信息,并且可以体现出动作过程中的散射中心距离随时间变化的规律。从图3中可以看出,不同动作之间表现出了较明显的差异,显著增强了动作之间的可分性,为下一步的识别提供了基础。</p>
                </div>
                <h3 id="82" name="82" class="anchor-tag"><b>2 基于卷积神经网络的识别算法</b></h3>
                <div class="p1">
                    <p id="83">通过对回波处理我们得到了人体动作的二维特征信息,接下来需要进一步提取深度特征以及识别。深度学习算法在学习目标特征和识别上具有很大优势,近几年被广泛应用在各个领域中,尤其是CNN在图像处理和识别领域表现出色。它可以通过独特的卷积计算和多层的网络结构提取目标的多层特征,并根据这些特征参数进行识别。与传统的特征提取方法相比,不但不需要人工去提取特征,省去了很多工作量,而且在识别率上也有较大的提升<citation id="270" type="reference"><link href="245" rel="bibliography" /><link href="247" rel="bibliography" /><sup>[<a class="sup">19</a>,<a class="sup">20</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="84">卷积神经网络是神经网络的一种,因为在网络的内部采用了卷积计算而称为卷积神经网络。最简单的单层卷积神经网络一般包括卷积层、激活层和池化层。卷积层的作用是提取特征,通过预先设定的卷积核对输入的数据进行特征映射。第一个卷积层的输入为原始矩阵,后面的卷积层的输入为上一层的特征图,每个卷积核与输入进行卷积都会产生一个特征图。每层中输入都会与卷积核进行卷积计算,卷积核在输入矩阵上按照预设的步长滑动,滑动一次则进行一次卷积。假设输入的二维数据矩阵为<i><b>A</b></i>(<i>m</i>,<i>n</i>),卷积核为<i>K</i>(<i>i</i>,<i>j</i>),步长为1,那么这个卷积层的输出<i><b>S</b></i>为:</p>
                </div>
                <div class="p1">
                    <p id="85"><mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">S</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mi>Κ</mi><mo>×</mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>m</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>n</mi></munder><mi mathvariant="bold-italic">A</mi></mstyle></mrow></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>-</mo><mi>m</mi><mo>,</mo><mi>j</mi><mo>-</mo><mi>n</mi><mo stretchy="false">)</mo><mi>Κ</mi><mo stretchy="false">(</mo><mi>m</mi><mo>,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (4)</p>
                </div>
                <div class="p1">
                    <p id="86">图4演示了矩阵上的卷积运算原理。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 卷积运算示意图" src="Detail/GetImg?filename=images/JYRJ201911029_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 卷积运算示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="88">本文中采用深度卷积神经网络来对人体动作进行特征提取和识别,并且针对雷达回波信号处理生成的二维特征图,设计了一种改进的CNN网络模型。通过在网络中采用Drop-out层、添加L2正则化项、LRN(局部响应归一化)层等方法来避免过拟合和提高识别性能,使模型在数量较小的雷达数据集能够充分学习特征,达到不错的识别率。图5为本文所用CNN网络示意图。</p>
                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 CNN网络示意图" src="Detail/GetImg?filename=images/JYRJ201911029_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 CNN网络示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="90">网络大致上可以分为5个隐层结构,前4层是卷积层,包含卷积计算,并且在前两个隐层中加入LRN层,最后一个卷积层的输出通过全连接层,再通过Drop-out层来调整,最后通过全连接层连接到输出层,输出识别的类别。网络内部采用ReLU(修正线性单元)作为神经元的激活函数,输出层采用Softmax函数来得到最后的输出类别。</p>
                </div>
                <div class="p1">
                    <p id="91">过拟合是指模型在训练集上准确率较高,但是在测试集上预测准确率较低,代表模型的“学习能力”太强,导致学习到了很多不重要的特征。在样本较少而网络内部参数较多时,容易产生过拟合现象,降低识别率。一般防止过拟合的思想是对模型的权重参数进行“惩罚”,或者对参数的数量进行严格的控制,这样的话这些参数的大小和数量就不会太大,越小或越少的参数代表模型越简单,相对于复杂的模型,简单的模型不易产生过拟合现象。为了抑制过拟合问题,本文采取以下几种方法来对卷积神经网络进行改进:</p>
                </div>
                <div class="p1">
                    <p id="92">(1) 加入Dropout层。在神经网络的训练过程中,将网络单元的权重参数按照一定的概率将其暂时从网络中丢弃,即每个批次的训练过程中,都随机忽略一定的隐层节点参数。这样每次训练的网络是不一样的,通过训练大量不同的网络采用模型平均作为输出,可以平均识别的准确率。另外由于随机的忽略掉了一些参数,避免了某些特征只在固定的组合下才产生作用,可以让网络去学习数据集的共性而不是某些样本的一些特性,Dropout是CNN中防止过拟合现象提高准确率的一个较好的方法。</p>
                </div>
                <div class="p1">
                    <p id="93">(2) 在损失函数后加上正则化项。损失函数是指训练过程中预测值与实际值的误差,神经网络迭代过程中通过计算梯度来使损失函数尽可能减小,当损失函数收敛时,表示模型已经在训练集上已经完成拟合。在深度神经网络的拟合过程中通常倾向于尽可能地减小权值,最后构造出一个所有参数都比较小的模型。因为参数值小的模型能适应不同的数据集,也在一定程度上避免了过拟合现象。若网络中的参数值很大,那么只要数据偏移一点点,就会对预测结果造成很大的影响,但如果参数值足够小,数据偏移对预测结果造成的影响较小。所以在损失函数后加入L2正则化项,假设参数为<i>θ</i>,<i>h</i><sub><i>θ</i></sub>是目标函数(即预测值),<i>h</i><sub><i>θ</i></sub>(<i>x</i>)即为输出值,未添加L2正则化项的损失函数<i>J</i>(<i>θ</i>)如下:</p>
                </div>
                <div class="p1">
                    <p id="94"><mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>m</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false">(</mo></mstyle><mi>h</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>-</mo><mi>y</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (5)</p>
                </div>
                <div class="p1">
                    <p id="95">按照梯度下降法来迭代,学习率设为<i>α</i>,则参数<i>θ</i>的更新规律为:</p>
                </div>
                <div class="p1">
                    <p id="96"><i>θ</i><sub><i>j</i></sub>:<mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>α</mi><mfrac><mn>1</mn><mi>m</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false">(</mo></mstyle><mi>h</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>-</mo><mi>y</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mi>x</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml>      (6)</p>
                </div>
                <div class="p1">
                    <p id="97">如果在损失函数<i>J</i>(<i>θ</i>)之后加上L2正则化项:</p>
                </div>
                <div class="p1">
                    <p id="98"><mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mi>λ</mi><mrow><mn>2</mn><mi>m</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>θ</mi></mstyle><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="99">式中:<i>λ</i>为正则化参数。那么<i>θ</i><sub><i>j</i></sub>的更新公式如下:</p>
                </div>
                <div class="p1">
                    <p id="100"><i>θ</i><sub><i>j</i></sub>:<mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub><mrow><mo>(</mo><mrow><mn>1</mn><mo>-</mo><mi>α</mi><mfrac><mi>λ</mi><mi>m</mi></mfrac></mrow><mo>)</mo></mrow><mo>-</mo><mi>α</mi><mfrac><mn>1</mn><mi>m</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false">(</mo></mstyle><mi>h</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>-</mo><mi>y</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mi>x</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="101">从式(8)可以看出,添加L2正则化项的参数每次迭代更新时,<i>θ</i><sub><i>j</i></sub>都要先乘上一个(0,1)区间的因子,所以<i>θ</i><sub><i>j</i></sub>不断减小,相对于未添加正则化项的迭代公式来说,参数<i>θ</i><sub><i>j</i></sub>更小。</p>
                </div>
                <div class="p1">
                    <p id="102">(3) 加入局部响应归一化层(Local Response Normalization,LRN)。LRN借鉴了生物神经系统中的侧抑制概念(指被激活的神经元抑制相邻的神经元),对神经网络的局部神经元建立竞争机制,使得其中响应比较大的权值参数变得相对更大,并抑制其他反馈较小的神经元参数。这样可以使模型更关注那些对预测结果影响较大的特征,而忽略影响较小的特征,增强了模型的泛化能力,提高识别率。具体计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="103"><mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>b</mi><msubsup><mrow></mrow><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mi>i</mi></msubsup><mo>=</mo><mi>a</mi><msubsup><mrow></mrow><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mi>i</mi></msubsup><mo>/</mo><mrow><mo>(</mo><mrow><mi>k</mi><mo>+</mo><mi>α</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>max</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mi>i</mi><mo>-</mo><mi>n</mi><mo>/</mo><mn>2</mn><mo stretchy="false">)</mo></mrow><mrow><mi>min</mi><mo stretchy="false">(</mo><mi>Ν</mi><mo>-</mo><mn>1</mn><mo>,</mo><mi>i</mi><mo>+</mo><mi>n</mi><mo>/</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></munderover><mo stretchy="false">(</mo></mstyle><mi>a</mi><msubsup><mrow></mrow><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mi>j</mi></msubsup><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>)</mo></mrow><msup><mrow></mrow><mi>β</mi></msup></mrow></math></mathml>      (9)</p>
                </div>
                <div class="p1">
                    <p id="104">式中:<i>a</i><mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>表示第<i>i</i>个卷积核在(<i>x</i>,<i>y</i>)处经过激活函数ReLU后的输出;<i>n</i>是同一位置上临近的feature map的数目;<i>N</i>是该层中卷积核的总数;参数<i>k</i>、<i>α</i>、<i>β</i>都是超参数,根据具体情况设置。可以看出,LRN即为“每个特征图”除以“临近半径以内的其他特征图的平方和”。</p>
                </div>
                <h3 id="105" name="105" class="anchor-tag"><b>3 实 验</b></h3>
                <h4 class="anchor-tag" id="106" name="106"><b>3.1 实验验证</b></h4>
                <div class="p1">
                    <p id="107">基于上述方法,搭建基于卷积神经网络的UWB人体动作识别系统,识别流程如图6所示,主要分为数据采集、数据处理和识别算法三个关键部分。通过雷达设备采集人体动作的回波,对回波信号进行预处理和特征提取,生成动作数据集。将数据集分为训练集和测试集,训练集用来训练卷积神经网络,学习人体动作特征,训练完成后使用测试集来测试性能,得到识别结果,并通过分析测试结果来调整卷积神经网络内部参数,以期达到更高的性能。识别算法验证环境采用Python 3.6编程语言和Google研发的TensorFlow深度学习框架。</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 基于CNN的人体动作识别系统流程图" src="Detail/GetImg?filename=images/JYRJ201911029_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 基于CNN的人体动作识别系统流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="109">将实测的原始数据集按照3∶1的比例分为训练集和测试集,在单次实验中,训练集和测试集相互独立。为了减少因数据集划分产生的误差,保证实验结果的有效性,重复进行了5次训练和验证,每次实验都重新划分训练集和测试集。损失函数用来衡量网络模型收敛情况,本文中的损失函数使用交叉熵,当损失函数稳定在一个极小值附近,不再发生较大变化时,认为CNN模型已收敛,学习过程结束,训练完成。图7表示单次训练中损失函数(训练集误差)随迭代次数的变化,可以看出,经过多次训练,最后损失函数稳定在0.006左右,说明网络模型在训练集上经过训练已经收敛,达到稳定状态。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 损失函数变化情况" src="Detail/GetImg?filename=images/JYRJ201911029_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 损失函数变化情况  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_110.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="111">另外,在训练过程中从训练集中取出一部分数据作为验证集来实时检验模型在训练过程中的拟合情况,图8表示验证集的分类准确率随迭代次数变化的趋势,可以看出,最后在验证集上达到了超过99.9%的准确率。</p>
                </div>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 验证集准确率变化情况" src="Detail/GetImg?filename=images/JYRJ201911029_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 验证集准确率变化情况  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="113">在训练集上完成所有训练后,使用测试集来测试模型的识别性能,分别测试5次训练产生的模型,准确率如表2所示,得到平均正确识别率为99.2%。可以看出,本文方法识别准确率非常高,进而验证了本文方法的有效性。</p>
                </div>
                <div class="area_img" id="114">
                    <p class="img_tit"><b>表2 卷积神经网络识别结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="114" border="1"><tr><td><br />实验次数</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td><br />准确率</td><td>1</td><td>0.97</td><td>1</td><td>1</td><td>0.99</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="115" name="115"><b>3.2 算法对比</b></h4>
                <div class="p1">
                    <p id="116">为了更好地验证本文方法的识别性能,将在本文的实测数据集上与文献<citation id="271" type="reference">[<a class="sup">8</a>,<a class="sup">18</a>]</citation>中的特征提取和识别算法进行对比,对处理过的回波信号特征矩阵采用主成分分析(PCA)方法提取主成分特征,再通过支持向量机(SVM)分类器进行分类识别。</p>
                </div>
                <div class="p1">
                    <p id="117">首先用PCA对雷达回波特征矩阵进行降维,得到数个特征向量。对任意一个动作样本,将样本数据向特征向量投影,得到的投影系数作为动作的特征表示,最后使用SVM分类器对这些不同的投影系数向量分类,来进行动作识别。PCA会根据各个主成分特征对应的方差进行排序,方差较大的特征对于样本数据的贡献率较大。图9显示了对雷达回波特征图使用PCA方法后提取的多个主成分特征,为了选择贡献率较大的前<i>n</i>个主成分。图10显示了前50个主成分特征所对应的方差。</p>
                </div>
                <div class="area_img" id="118">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 主成分特征" src="Detail/GetImg?filename=images/JYRJ201911029_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 主成分特征  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 主成分排序图" src="Detail/GetImg?filename=images/JYRJ201911029_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 主成分排序图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="120">由图10可以看出,越往前的特征的贡献率较大,而越往后的特征贡献率越小,通过多次实验对比,发现采用前15个主成分特征作为分类特征时效果较好。将数据集按照3∶1的比例分为训练集和测试集,得到数据集的投影系数,利用训练集的投影系数训练出SVM分类器,再用测试集来进行识别,验证性能。本文的SVM分类器中核函数采用性能较好的高斯核,分类器中的惩罚因子C和gamma参数值采用网格搜索的方式选择最优值。</p>
                </div>
                <div class="p1">
                    <p id="121">实验结果如表3所示,经过多次实验,PCA+SVM的特征提取和识别算法平均识别准确率为93%,将不同动作分别分析,发现该识别算法虽然对于部分动作达到了接近100%的准确率,但对向前摔倒、向后摔倒,原地摔倒等区分度较小的动作识别率较低,无法提取不同动作中的细微差异,直接导致总体识别率不高。</p>
                </div>
                <div class="area_img" id="122">
                    <p class="img_tit"><b>表3 PCA+SVM实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="122" border="1"><tr><td>动作编号</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td></tr><tr><td><br />准确率</td><td>1</td><td>0.90</td><td>0.83</td><td>0.78</td><td>0.92</td><td>1</td><td>1</td><td>1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="123">在相同数据集的基础上,对比本文与文献<citation id="272" type="reference">[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">18</a>]</citation>之间的识别算法和性能差异,结果如表4所示。</p>
                </div>
                <div class="area_img" id="124">
                    <p class="img_tit"><b>表4 实验结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="124" border="1"><tr><td>算法</td><td>识别算法</td><td>类别</td><td>识别率</td></tr><tr><td><br />文献[7]</td><td>离散小波变换+SVM</td><td>9</td><td>91.89%</td></tr><tr><td><br />文献[8,18]</td><td>PCA+SVM</td><td>8</td><td>93%</td></tr><tr><td><br />本文算法</td><td>DCNN</td><td>8</td><td>99.2%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="125">通过对比实验结果可知,相对于文献<citation id="273" type="reference">[<a class="sup">7</a>]</citation>来说,本文采用的优化的DCNN算法识别性能更好,提取的雷达回波中的人体动作特征更准确;相对于采用文献<citation id="274" type="reference">[<a class="sup">8</a>,<a class="sup">18</a>]</citation>中的特征提取和识别方法来处理本文的实测数据集来说,本文采用算法效果更好,并且对于区分度较低的相似动作也能准确识别。</p>
                </div>
                <h4 class="anchor-tag" id="126" name="126"><b>3.3 综合分析</b></h4>
                <div class="p1">
                    <p id="127">与文献中已有的利用雷达来识别人体动作的方法进行综合对比,从特征选取和识别方法两个角度来分析,表5列出了多个参考文献中的人体动作识别系统。</p>
                </div>
                <div class="area_img" id="128">
                    <p class="img_tit"><b>表5 基于雷达的动作识别方法对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="128" border="1"><tr><td>算法</td><td>特征信息</td><td>识别方法</td><td>动作类数</td></tr><tr><td><br />文献[13]</td><td>微多普勒</td><td>KNN分类器</td><td>3</td></tr><tr><td><br />文献[20]</td><td>微多普勒</td><td>DCNN</td><td>7</td></tr><tr><td><br />文献[8]</td><td>微多普勒</td><td>PCA+SVM</td><td>7</td></tr><tr><td><br />文献[21]</td><td>微多普勒</td><td>卷积自编码器</td><td>12</td></tr><tr><td><br />文献[16]</td><td>距离-多普勒</td><td>DCNN</td><td>4</td></tr><tr><td><br />文献[22]</td><td>时频图流</td><td>3D-CNN+LSTM</td><td>8</td></tr><tr><td><br />文献[18]</td><td>距离信息</td><td>PCA+SVM</td><td>8</td></tr><tr><td><br />文献[7]</td><td>时间-距离特征</td><td>离散小波变换+SVM</td><td>9</td></tr><tr><td><br />对比实验</td><td>时间-距离特征</td><td>二维PCA+SVM</td><td>8</td></tr><tr><td><br />本文方法</td><td>时间-距离特征</td><td>DCNN</td><td>8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="129">图11为上述方法的识别准确率对比,可以看出,本文所提出的基于超宽带雷达的人体动作识别方法性能较好。从特征选取角度分析,采用时间-距离特征作为识别依据的方法均可以达到90%以上的识别准确率,证明了本文特征选取的合理性。此外,在本文所用的特征数据集上,基于深度卷积神经网络的识别效果优于文献<citation id="275" type="reference">[<a class="sup">7</a>]</citation>以及3.2节中的对比实验。</p>
                </div>
                <div class="area_img" id="130">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911029_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 识别准确率对比" src="Detail/GetImg?filename=images/JYRJ201911029_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 识别准确率对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911029_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="131">经过算法对比和综合分析可知,本文方法具有较高的识别性能,可以实现准确的人体动作识别。此外,由于本文所用的人体动作数据集规模较小,在实际应用中,为了加强模型的泛化性和实用性,可适当增大数据集的范围,或者采用多个不同人体目标的动作作为训练集。</p>
                </div>
                <h3 id="132" name="132" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="133">本文通过研究动态人体目标散射点特征,结合超宽带雷达的特性,提出了一种基于卷积神经网络的雷达人体动作识别方法。采用超宽带雷达感知人体动作,提取出人体动作的雷达回波中的时间—距离特征,生成二维特征图像矩阵,再将特征矩阵输入到卷积神经网络模型中进行训练和识别。实验证明该方法在实测的8种真实动作数据上达到了99.2%的识别准确率,系统可以对人体动作进行准确识别,验证了本文方法的可行性和有效性。与传统方法相比,本文方法不但提高了总体识别准确率,而且提高了对多种相似动作的识别准确率,识别性能更好。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="209">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201401005&amp;v=MzExMDdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvaFVMck1LRDdZYkxHNEg5WE1ybzlGWVlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>李瑞峰，王亮亮，王珂．人体动作行为识别研究综述[J]．模式识别与人工智能，2014,27(1):35-48．
                            </a>
                        </p>
                        <p id="211">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900015781&amp;v=MzAxOTE9TmlmT2ZiSzdIdFRNcG85RlpPb0tDM1E0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSjFvWGJ4WQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Chaquet J M,Carmona E J,Fernández-Caballero A.A survey of video datasets for human action and activity recognition[J].Computer Vision and Image Understanding,2013,117(6):633-659．
                            </a>
                        </p>
                        <p id="213">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201348902&amp;v=MTgwMDdtVWIvSUoxb1hieFk9TmlmT2ZiSzdIdERPclk5RVorOEhCWHc3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5ag==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>Poppe R.A survey on vision-based human action recognition[J].Image and vision computing,2010,28(6):976-990．
                            </a>
                        </p>
                        <p id="215">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201612031&amp;v=MTEzMzdMck1MelRaWkxHNEg5Zk5yWTlHWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvaFU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>LE Vanbang，朱煜，NGUYEN Anhtu．深度图像手势分割及HOG-SVM手势识别方法研究[J]．计算机应用与软件，2016,33(12):122-126．
                            </a>
                        </p>
                        <p id="217">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A survey on human activity recognition using wearable sensors">

                                <b>[5]</b>Lara O D,Labrador M A.A survey on human activity recognition using wearable sensors[J].IEEE Comm Unications Surveys and Tutorials,2013,15(3):1192-1209．
                            </a>
                        </p>
                        <p id="219">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Whole-home gesture recognition using wireless signals">

                                <b>[6]</b>Pu Q,Gupta S,Gollakota S,et al.Whole-home gesture recognition using wireless signals[C]//Proceedings of the19th annual international conference on Mobile computing&amp;net Working.ACM,2013:27-38．
                            </a>
                        </p>
                        <p id="221">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZIY201801018&amp;v=MTU0NTdCdEdGckNVUkxPZVplVnVGeS9oVUxyTUlUZkNkN0c0SDluTXJvOUViSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>蒋留兵，李骢，车俐．超宽带雷达人体动作识别[J]．电子测量与仪器学报，2018,32(1):129-134．
                            </a>
                        </p>
                        <p id="223">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KJPL201606010&amp;v=MTIyODdlWmVWdUZ5L2hVTHJNTGlmYllyRzRIOWZNcVk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>刘熠辰，徐丰．基于雷达技术的手势识别[J]．中国电子科学研究院学报，2016,11(6):609-613．
                            </a>
                        </p>
                        <p id="225">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM593E8BB28F4573A7D5FD5AE4F004028E&amp;v=Mjc3NTNGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHc3eTh4YXc9TmlmSVk3YXhIYVRFM2YxSGJKMExDWHM2dmhGbjcwa0pUUTZYcUdRMWViYVVSN0xxQ09OdkZTaVdXcjdKSQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Adib F,Hsu C Y,Mao H,et al.Capturing the human figure through a wall[J].ACM Transactions on Graphics(TOG),2015,34(6):219．
                            </a>
                        </p>
                        <p id="227">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM65A264899256392CD5AEB9192E7D8E90&amp;v=MTAzODMzNWRoaHc3eTh4YXc9TmlmSVk3VzliOVBLcTRkTWJla0tDbjh3eldWbjcwNElPbmJqcFJCQWZzYWNNTE9mQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>Lien J,Gillian N,Karagozler M E,et al.Soli:Ubiquitous gesture sensing with millimeter wave radar[J].ACM Transactions on Graphics(TOG),2016,35(4):142．
                            </a>
                        </p>
                        <p id="229">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXCN200910024&amp;v=MTQ5NDVMRzRIdGpOcjQ5SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hVTHJNUFRYSVk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>张翼，朱玉鹏，程永强，等．基于微多普勒特征的人体目标雷达回波信号分析[J]．信号处理，2009,25(10):1616-1623．
                            </a>
                        </p>
                        <p id="231">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Advances in applications of radar micro-Doppler signatures">

                                <b>[12]</b>Chen V C.Advances in applications of radar micro-Doppler signatures[C]//2014 IEEE Conference on Antenna Measurements&amp;Applications(CAMA).IEEE,2014．
                            </a>
                        </p>
                        <p id="233">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Micro-Doppler-Based human activity classification using the mote-scale bumblebee radar">

                                <b>[13]</b>Cagliyan B,Gurbuz S Z.Micro-Doppler-Based human activity classification using the mote-scale bumblebee radar[J].IEEE Geoscience and Remote Sensing Letters,2015,12(10):2135-2139．
                            </a>
                        </p>
                        <p id="235">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Wireless hand gesture recognition based on continuous-wave Doppler radar sensors">

                                <b>[14]</b>Fan T,Ma C,Gu Z,et al.Wireless hand gesture recognition based on continuous-wave Doppler radar sensors[J].IEEE Transactions on Microwave Theory and Techniques,2016,64(11):4012-4020．
                            </a>
                        </p>
                        <p id="237">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparsity-driven microDoppler feature extraction for dynamic hand gesture recognition">

                                <b>[15]</b>Li G,Zhang R,Ritchie M,et al.Sparsity-driven microDoppler feature extraction for dynamic hand gesture recognition[J].IEEE Transactions on Aerospace and Electronic Systems,2018,54(2):655-665．
                            </a>
                        </p>
                        <p id="239">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJHK201806001&amp;v=MDg5MDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hVTHJNSnlmRFpiRzRIOW5NcVk5RlpZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>王俊，郑彤，雷鹏，等．基于卷积神经网络的手势动作雷达识别方法[J]．北京航空航天大学学报，2018,44(6):1117-1123．
                            </a>
                        </p>
                        <p id="241">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=IR-UWB radar sensor for human gesture recognition by using machine learning">

                                <b>[17]</b>Park J,Cho S H.IR-UWB radar sensor for human gesture recognition by using machine learning[C]//2016 IEEE 18th International Conference on High Performance Computing and Communications;IEEE 14th International Conference on Smart City;IEEE 2nd International Conference on Data Science and Systems(HPCC/Smart City/DSS).IEEE,2016:1246-1249．
                            </a>
                        </p>
                        <p id="243">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Application of ultra-wide band radar for classification of human activities">

                                <b>[18]</b>Bryan J D,Kwon J,Lee N,et al.Application of ultra-wide band radar for classification of human activities[J].IET Radar,Sonar&amp;Navigation,2012,6(3):172-179．
                            </a>
                        </p>
                        <p id="245">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201407002&amp;v=MzIyMDllVnVGeS9oVUxyTUx6N1NaTEc0SDlYTXFJOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>刘建伟，刘媛，罗雄麟．深度学习研究进展[J]．计算机应用研究，2014,31(7):1921-1930,1942．
                            </a>
                        </p>
                        <p id="247">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hand Gesture Recognition Using Micro-Doppler Signatures with Convolutional Neural Network">

                                <b>[20]</b>Kim Y,Toomajian B.Hand gesture recognition using microDoppler signatures with convolutional neural network[J].IEEE Access,2016,4:7125-7130．
                            </a>
                        </p>
                        <p id="249">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep convolutional autoencoder for radar-based classification of similar aided and unaided human activities">

                                <b>[21]</b>Seyfio<image id="276" type="formula" href="images/JYRJ201911029_27600.jpg" display="inline" placement="inline"><alt></alt></image>lu M S，zbayogˇlu A M,Gürbüz S Z.Deep convolutional autoencoder for radar-based classification of similar aided and unaided human activities[J].IEEE Transactions on Aerospace and Electronic Systems,2018,54(4):1709-1723．
                            </a>
                        </p>
                        <p id="251">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Latern dynamic continuous hand gesture recognition using FMCW radar sensor">

                                <b>[22]</b>Zhang Z,Tian Z,Zhou M.Latern:dynamic continuous hand gesture recognition using FMCW radar sensor[J].IEEE Sensors Journal,2018,18(8):3278-3289．
                            </a>
                        </p>
                        <p id="253">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=2000003162.nh&amp;v=MDk3NTh0R0ZyQ1VSTE9lWmVWdUZ5L2hVTHJNVjEyN0hyTzRIZERLclpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b>黎海涛．超宽带雷达关键技术研究[D]．成都:电子科技大学，2000.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201911029" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201911029&amp;v=MTg2MzZxQnRHRnJDVVJMT2VaZVZ1RnkvaFVMck5MelRaWkxHNEg5ak5ybzlIYllRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
