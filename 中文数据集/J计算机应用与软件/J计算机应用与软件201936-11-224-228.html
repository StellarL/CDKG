<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134081641818750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJYRJ201911037%26RESULT%3d1%26SIGN%3dXhowpAxXOba4u%252b2C7%252bUxteHkosU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201911037&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201911037&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201911037&amp;v=Mjk0MDZHNEg5ak5ybzlHWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvaFZMN09MelRaWkw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;1 卷积神经网络模型&lt;/b&gt; "><b>1 卷积神经网络模型</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#40" data-title="&lt;b&gt;2 图像风格迁移算法&lt;/b&gt; "><b>2 图像风格迁移算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="&lt;b&gt;2.1 算法设计&lt;/b&gt;"><b>2.1 算法设计</b></a></li>
                                                <li><a href="#57" data-title="&lt;b&gt;2.2 算法实现&lt;/b&gt;"><b>2.2 算法实现</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#60" data-title="&lt;b&gt;3 实 验&lt;/b&gt; "><b>3 实 验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="&lt;b&gt;3.1 实验搭建环境&lt;/b&gt;"><b>3.1 实验搭建环境</b></a></li>
                                                <li><a href="#64" data-title="&lt;b&gt;3.2 实验过程与结果&lt;/b&gt;"><b>3.2 实验过程与结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#79" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#34" data-title="图1 VGG19网络在图像风格迁移的工作流程">图1 VGG19网络在图像风格迁移的工作流程</a></li>
                                                <li><a href="#35" data-title="图2 VGG19网络结构图">图2 VGG19网络结构图</a></li>
                                                <li><a href="#39" data-title="图3 VGG19网络第一层和第四层的可视化对比">图3 VGG19网络第一层和第四层的可视化对比</a></li>
                                                <li><a href="#59" data-title="图4 图像风格迁移技术的实现流程">图4 图像风格迁移技术的实现流程</a></li>
                                                <li><a href="#67" data-title="图5 迭代20次后的人像合成图">图5 迭代20次后的人像合成图</a></li>
                                                <li><a href="#70" data-title="图6 上海外滩和梵高-星月夜的内容图、样式图和合成图">图6 上海外滩和梵高-星月夜的内容图、样式图和合成图</a></li>
                                                <li><a href="#71" data-title="图7 目标内容图、迭代次数为44、50、150的合成图">图7 目标内容图、迭代次数为44、50、150的合成图</a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;表1 不同网络模型在不同迭代次数下的总损失度&lt;/b&gt;"><b>表1 不同网络模型在不同迭代次数下的总损失度</b></a></li>
                                                <li><a href="#75" data-title="图8 对比VGG16和VGG19两种模型合成图">图8 对比VGG16和VGG19两种模型合成图</a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;表2 VGG19迭代45次下调整权重占比损失度&lt;/b&gt;"><b>表2 VGG19迭代45次下调整权重占比损失度</b></a></li>
                                                <li><a href="#104" data-title="图9 三种不同权重占比合成效果图">图9 三种不同权重占比合成效果图</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="105">


                                    <a id="bibliography_1" title=" Lecun Y,Bengio Y,Hinton G.Deep learning[J].Nature,2015,521(7553):436-444." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Deep Learning&amp;quot;">
                                        <b>[1]</b>
                                         Lecun Y,Bengio Y,Hinton G.Deep learning[J].Nature,2015,521(7553):436-444.
                                    </a>
                                </li>
                                <li id="107">


                                    <a id="bibliography_2" title=" Gatys L A,Ecker A S,Bethge M.Texture and art with deep neural networks[J].Current Opinion in Neurobiology,2017,46:178-186." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESD4DD2CBC9D88E822183D83486692F7C9&amp;v=MjkyODFSUVM0andKUUh6bXBCUXpjTERpUXNtV0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHc3eTR3YUE9TmlmT2ZjZThhcVhPM1AwMmJaOEhCQWt4eg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Gatys L A,Ecker A S,Bethge M.Texture and art with deep neural networks[J].Current Opinion in Neurobiology,2017,46:178-186.
                                    </a>
                                </li>
                                <li id="109">


                                    <a id="bibliography_3" title=" 陈淑環,韦玉科,徐乐,等.基于深度学习的图像风格迁移研究综述[J].计算机应用研究,2019,36(8):2250-2255." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201908002&amp;v=MTIxMjc0SDlqTXA0OUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9oVkw3QUx6N1NaTEc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         陈淑環,韦玉科,徐乐,等.基于深度学习的图像风格迁移研究综述[J].计算机应用研究,2019,36(8):2250-2255.
                                    </a>
                                </li>
                                <li id="111">


                                    <a id="bibliography_4" title=" Gatys L A,Ecker A S,Bethge M.A neural algorithm of artistic style[DB].eprint arXiv:1508.06576,2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A neural algorithm of artistic style[DB]">
                                        <b>[4]</b>
                                         Gatys L A,Ecker A S,Bethge M.A neural algorithm of artistic style[DB].eprint arXiv:1508.06576,2015.
                                    </a>
                                </li>
                                <li id="113">


                                    <a id="bibliography_5" title=" Gatys L A,Ecker A S,Bethge M.Image style transfer using convolutional neural networks[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition(CVPR).IEEE,2016:2414-2423." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image style transfer using convolutional neural networks">
                                        <b>[5]</b>
                                         Gatys L A,Ecker A S,Bethge M.Image style transfer using convolutional neural networks[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition(CVPR).IEEE,2016:2414-2423.
                                    </a>
                                </li>
                                <li id="115">


                                    <a id="bibliography_6" title=" Ulyanov D,Lebedev V,Vedaldi A,et al.Texture networks:feed-forward synthesis of textures and stylized images[EB].eprint arXiv:1603.03417,2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Texture networks:feed-forward synthesis of textures and stylized images[EB]">
                                        <b>[6]</b>
                                         Ulyanov D,Lebedev V,Vedaldi A,et al.Texture networks:feed-forward synthesis of textures and stylized images[EB].eprint arXiv:1603.03417,2016.
                                    </a>
                                </li>
                                <li id="117">


                                    <a id="bibliography_7" title=" Zhu J Y,Park T,Isola P,et al.Unpaired image-to-image translation using cycle-consistent adversarial networks[C]//IEEE International Conference on Computer Vision.IEEE Computer Society,2017:2242-2251." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unpaired image-to-image translation using cycle-consistent adversarial networks">
                                        <b>[7]</b>
                                         Zhu J Y,Park T,Isola P,et al.Unpaired image-to-image translation using cycle-consistent adversarial networks[C]//IEEE International Conference on Computer Vision.IEEE Computer Society,2017:2242-2251.
                                    </a>
                                </li>
                                <li id="119">


                                    <a id="bibliography_8" title=" Johnson J,Alahi A,Fei-Fei L.Perceptual losses for real-time style transfer and super-resolution[C]//ECCV:European Conference on Computer Vision,2016:694-711" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Perceptual losses for real-time style transfer and super-resolution">
                                        <b>[8]</b>
                                         Johnson J,Alahi A,Fei-Fei L.Perceptual losses for real-time style transfer and super-resolution[C]//ECCV:European Conference on Computer Vision,2016:694-711
                                    </a>
                                </li>
                                <li id="121">


                                    <a id="bibliography_9" title=" Dumoulin V,Shlens J,Kudlur M.A Learned Representation For Artistic Style[EB].eprint arXiv:1610.07629,2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Learned Representation For Artistic Style[EB]">
                                        <b>[9]</b>
                                         Dumoulin V,Shlens J,Kudlur M.A Learned Representation For Artistic Style[EB].eprint arXiv:1610.07629,2016.
                                    </a>
                                </li>
                                <li id="123">


                                    <a id="bibliography_10" title=" 操江峰.基于深度学习的图像与视频风格化研究与实现[D].北京:中国科学院大学,2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017183567.nh&amp;v=MjAwMzF1RnkvaFZMN0FWRjI2R2JLd0hkVEtxSkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         操江峰.基于深度学习的图像与视频风格化研究与实现[D].北京:中国科学院大学,2017.
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_11" title=" 王茜,陈一民,丁友东.基于改进卷积神经网络的机动车图像分类算法[J].计算机应用与软件,2018,35(7):263-266,298." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201807048&amp;v=MDU4MjVMRzRIOW5NcUk5QmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hWTDdBTHpUWlo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         王茜,陈一民,丁友东.基于改进卷积神经网络的机动车图像分类算法[J].计算机应用与软件,2018,35(7):263-266,298.
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_12" title=" Simonyan K,Zisserman A.Very Deep Convolutional Networks for Large-Scale Image Recognition[EB].eprint arXiv:1409.1556,2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition[EB]">
                                        <b>[12]</b>
                                         Simonyan K,Zisserman A.Very Deep Convolutional Networks for Large-Scale Image Recognition[EB].eprint arXiv:1409.1556,2014.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(11),224-228 DOI:10.3969/j.issn.1000-386x.2019.11.036            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种VGGNet的图像风格迁移算法设计与实现</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%A9%B7&amp;code=14681534&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王婷</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E8%88%AA&amp;code=08687242&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李航</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E6%99%BA&amp;code=39409887&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡智</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%88%E9%98%B3%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%BD%AF%E4%BB%B6%E5%AD%A6%E9%99%A2&amp;code=0219467&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">沈阳师范大学软件学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对卷积神经网络在实现图像风格迁移中出现的图像失真及精度较差问题,提出一种基于卷积神经网络的图像风格迁移算法。分析传统的纹理重构算法,采用拟牛顿法之一的L-BFGS优化方法对其进行改进。利用Gram矩阵计算图片中的纹理、颜色和视觉信息,提取一幅普通图片和一幅具有代表性的艺术性图像的两种高层抽象特征表示,从而生成具有原内容和艺术性风格的合成图像。在深度学习Keras框架的基础上,设计一种卷积神经网络的图像风格迁移算法。实验结果表明,适度地选择迭代次数可观察合成图像的匹配程度,该算法可提高准确度并降低计算复杂度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像风格迁移;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Keras&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Keras;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=VGGNet&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">VGGNet;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王婷，硕士生，主研领域:深度学习，图像识别。;
                                </span>
                                <span>
                                    李航，教授。;
                                </span>
                                <span>
                                    胡智，教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-20</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(60970112);</span>
                    </p>
            </div>
                    <h1><b>DESIGN AND IMPLEMENTATION OF IMAGE STYLE MIGRATION ALGORITHM BASED ON VGGNET</b></h1>
                    <h2>
                    <span>Wang Ting</span>
                    <span>Li Hang</span>
                    <span>Hu Zhi</span>
            </h2>
                    <h2>
                    <span>College of Software, Shenyang Normal University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problem of image distortion and poor accuracy in image style migration based on convolutional neural network, we proposed an image style migration algorithm based on convolution neural network. We analyzed the traditional texture reconstruction algorithm, and used the L-BFGS optimization method of quasi Newton method to improve it. Then, we used the Gram matrix to calculate the texture, color and visual information in the picture, and extracted two high-level abstract features of a common picture and a representative artistic image to generate a composite image with original content and artistic style. On the basis of Keras framework of deep learning, we designed an image style migration algorithm based on convolution neural network. The experimental results show that the appropriate number of iterations can be selected to observe the matching degree of the composite image, and the proposed algorithm can improve the accuracy and reduce computation complexity.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20style%20migration&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Image style migration;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Keras&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Keras;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=VGGNet&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">VGGNet;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deep learning;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-20</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="27" name="27" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="28">图像风格迁移是指利用机器学习算法学习艺术画作的风格,并将这种风格应用到另一幅图片上的技术<citation id="129" type="reference"><link href="105" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。简单来讲,风格迁移和纹理生成是紧密相关的<citation id="130" type="reference"><link href="107" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>,这种技术的趣味性就是将一幅照片在内容保持不变的情况下被渲染成有艺术风格的新画作。</p>
                </div>
                <div class="p1">
                    <p id="29">图像风格迁移主要包括基于图像迭代和基于模型迭代两个方面<citation id="131" type="reference"><link href="107" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。传统的图像风格迁移都是基于图像局部特征的统计模型手动建模,旧式的手工数学建模方法耗时耗力、效果不佳。2015年,Gatys等<citation id="132" type="reference"><link href="113" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>开创性地提出基于神经网络的图像迁移算法后,图像的风格迁移已不再局限于只基于笔触、物理模型的绘制和纹理合成的非参数图像迁移。文中的基于图像迭代和基于模型迭代两大创新点引起了热潮,这一技术越来越多地应用于众多应用领域。文献<citation id="133" type="reference">[<a class="sup">6</a>]</citation>提出一种利用内容图和训练好的前向网络结合的方法,通过求解全局最优解转换成用前向网络接近最优解来合成具有新纹理的网络。文献<citation id="134" type="reference">[<a class="sup">7</a>]</citation>利用GAN(Generative Adversarial Networks)网络对抗训练模型,增加了图片转换的多样性。文献<citation id="135" type="reference">[<a class="sup">8</a>]</citation>提出采用感知损失函数代替逐像素差距的损失函数,实现实时风格转换和图像超分倍率重建。文献<citation id="136" type="reference">[<a class="sup">9</a>]</citation>提出了<i>N</i>个风格共用一个模型的方式,缓解了模型存储所消耗的空间问题,实现实时的风格插补并可应用在视频上。文献<citation id="137" type="reference">[<a class="sup">10</a>]</citation>设计了一种转换神经网路U-StyleNet,并采用迁移学习的方法解决了网络参数初始化导致输出图像有黑块或亮块的问题,同时加快了网络的训练速度。2016年上线的手机APP Prisma综合了图像风格迁移技术和人工智能技术,获取世界的艺术大师和主要流派的艺术风格,它是基于深度学习的图像风格化应用非常成功的实例。Artisto APP可直接将视频处理为艺术性的风格化,从抽象主义到现代派大师毕加索的立体主义。</p>
                </div>
                <div class="p1">
                    <p id="30">本文主要基于图像迭代的图像迁移方法,采用预训练卷积神经网络<citation id="138" type="reference"><link href="125" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>(Visual Geometry Group-Network,VGG-Net)模型和快速灵活的Keras深度学习框架作为核心组件来实现图像风格迁移。预训练的VGG-19卷积模型<citation id="139" type="reference"><link href="127" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>具有较快的收敛速度和更好的泛化特性,整个VGG19网络的卷积核对一幅图片的轮廓线条的刺激以及颜色刺激更为敏感。实验证明基于VGGNet的图像风格迁移算法将损失度降低至最低时,VGGNet模型的性能最好,合成图片的匹配度最佳,并降低了实现复杂度。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>1 卷积神经网络模型</b></h3>
                <div class="p1">
                    <p id="32">在机器学习中,卷积神经网络(Convolutional Neural Network,CNN)是一种深度前馈人工神经网络。它的人工神经元可以响应一部分覆盖范围内的周围单元,包括卷积层、池化层和全连接层等。CNN的基本结构包括两层:特征提取层和特征映射层。卷积神经网络以其局部权值共享的特殊结构在图像处理、图像识别、图像分割等有着独特的优越性。权值共享降低了网络的复杂性,多维输入向量的图像可直接输入网络,避免了复杂的数据重建。</p>
                </div>
                <div class="p1">
                    <p id="33">卷积神经网络中被证明图像识别能力出色的VGGNet在2014年ILSVRC比赛中取得定位任务第一名和分类任务第二名的优异成绩,具有较好的泛化能力。因此,实现图像风格迁移的过程中,使用含19个参数的标准VGG网络,包含16个卷积层和5个池化层。VGG19和普通的VGGNet稍有区别,VGGNet通常是利用全连接层输出物体类别,而VGG19在图像风格迁移中提取特征时,通过输入特征后直接输出对应这种特征的图片。选择深层’block5_conv2’卷积层提取内容特征;选择’block1_conv1’至’block5_conv1’的五个从低维到高维过渡的卷积层提取样式特征。图1为VGG19网络在图像风格迁移中的工作流程,图2为VGG19网络结构图。</p>
                </div>
                <div class="area_img" id="34">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911037_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 VGG19网络在图像风格迁移的工作流程" src="Detail/GetImg?filename=images/JYRJ201911037_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 VGG19网络在图像风格迁移的工作流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911037_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="35">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911037_035.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 VGG19网络结构图" src="Detail/GetImg?filename=images/JYRJ201911037_035.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 VGG19网络结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911037_035.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="36">VGG19的拓展性较强,迁移到其他图片数据集上的泛化性较好;结构简单,整个图2网络结构使用相同尺寸大小为3×3的卷积核和池化尺寸大小2×2。三个3×3的卷积核相当于一个7×7卷积核的感受域,数量更少、模型更具有判别性、便于加快训练;池化层选择平均池化代替最大池化,利用RELU激活函数提高优化率。因此,在实现图像风格迁移中,选择VGG19可有效地缩短训练时间、提高图像识别的精度。</p>
                </div>
                <div class="p1">
                    <p id="37">深度学习的模型很难看到其中的内部结构,但是对于卷积神经网络来说,它能以可视化的形式看到内部特征表示。常见的三种可视化方法为卷积核输出的可视化、卷积核的可视化和热度图的可视化。使用可视化方法可以使图像风格迁移过程中卷积核感受图像的方式,以及通过热度图定位图像中物体的位置更加容易。</p>
                </div>
                <div class="p1">
                    <p id="38">VGG19中卷积的过程就是特征提取的过程,每一个卷积核代表着一种特征。在可视化卷积核的过程中,低层次的卷积核对目标图像的颜色、边缘信息感兴趣,提取的特征是简单的检测点和线等。随着层次的不断加深,内容越来越抽象和复杂,卷积层感知图像中的物体位置更准确,提取的特征通常是复杂的特定物体。图3为VGG19网络第一层和第四层的可视化对比。</p>
                </div>
                <div class="area_img" id="39">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911037_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 VGG19网络第一层和第四层的可视化对比" src="Detail/GetImg?filename=images/JYRJ201911037_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 VGG19网络第一层和第四层的可视化对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911037_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="40" name="40" class="anchor-tag"><b>2 图像风格迁移算法</b></h3>
                <div class="p1">
                    <p id="41">图像风格迁移算法通过内容、样式和风格三方面给每张图片编写损失函数。为了开始改变生成的图像以最大限度地减少损失函数,本文算法使用不同的权重进行图像迁移的实现。算法设计过程中,使用多个内容图层,伴随VGG19感受野的增大,精确内容相似度;使用多个风格图层,在损失函数中添加更多不同风格的图片;加入全变分去噪,缓解合成图像中含有不必要的颗粒情况。</p>
                </div>
                <h4 class="anchor-tag" id="42" name="42"><b>2.1 算法设计</b></h4>
                <div class="p1">
                    <p id="43">图片风格化的算法主要包含最重要的三部分:内容重构、风格表示和样式转换。风格本质是各种空间尺度中图像的纹理、颜色、视觉图案等。本文算法通过定义内容损失函数保证从上层看生成的图片与原始图片类似;通过风格损失函数尝试获取所有空间比例的样式图片的外观;利用L-BFGS算法优化最终的总变化损失值。Gram矩阵计算在特定空间尺度模式下不同维度之间特征激活值的相关性,保证合成图和样式图具有相同的纹理。</p>
                </div>
                <h4 class="anchor-tag" id="44" name="44">(1) 内容重构。</h4>
                <div class="p1">
                    <p id="45">设定<mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>p</mi><mo>→</mo></mover></math></mathml>和<mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>→</mo></mover></math></mathml>为目标内容图像和生成的合成图像,<i>P</i><sup><i>l</i></sup>和<i>F</i><sup><i>l</i></sup>为<mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>p</mi><mo>→</mo></mover></math></mathml>和<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>→</mo></mover></math></mathml>在<i>l</i>层的特征表示。元素<i>F</i><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup></mrow></math></mathml>表示第<i>l</i>层的第<i>i</i>个滤波器在位置层上的激活响应。指定某一层的特征表示,使生成的新图片<mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>→</mo></mover></math></mathml>在该层的特征表示<i>P</i><sup><i>l</i></sup>等于原来的特征表示<i>F</i><sup><i>l</i></sup>,目的是匹配合成图片和内容图片。内容损失函数公式如下:</p>
                </div>
                <div class="p1">
                    <p id="46"><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>n</mtext><mtext>t</mtext><mtext>e</mtext><mtext>n</mtext><mtext>t</mtext></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>p</mi><mo>→</mo></mover><mo>,</mo><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo>,</mo><mi>l</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></munder><mo stretchy="false">(</mo></mstyle><mi>F</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><mo>-</mo><mi>Ρ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (1)</p>
                </div>
                <h4 class="anchor-tag" id="47" name="47">(2) 风格表示。</h4>
                <div class="p1">
                    <p id="48">利用Gram矩阵计算样式图片中的纹理、颜色和视觉图案信息,公式如下:</p>
                </div>
                <div class="p1">
                    <p id="49"><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi>F</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow><mi>l</mi></msubsup><mi>F</mi><msubsup><mrow></mrow><mrow><mi>j</mi><mi>k</mi></mrow><mi>l</mi></msubsup></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="50">设定风格图片为<mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>a</mi><mo>→</mo></mover><mo>,</mo></mrow></math></mathml>对应第<i>l</i>层的Gram矩阵分别为<i><b>A</b></i><sup><i>l</i></sup>和<i><b>G</b></i><sup><i>l</i></sup>,定义总损失公式为:</p>
                </div>
                <div class="p1">
                    <p id="51"><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msub><mrow></mrow><mi>l</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mn>4</mn><mi>Ν</mi><msubsup><mrow></mrow><mi>l</mi><mn>2</mn></msubsup><mi>Μ</mi><msubsup><mrow></mrow><mi>l</mi><mn>2</mn></msubsup></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></munder><mo stretchy="false">(</mo></mstyle><mi mathvariant="bold-italic">G</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><mo>-</mo><mi mathvariant="bold-italic">A</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (3)</p>
                </div>
                <div class="p1">
                    <p id="52">样式损失函数为:</p>
                </div>
                <div class="p1">
                    <p id="53"><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>t</mtext><mtext>y</mtext><mtext>l</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>0</mn></mrow><mi>L</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mi>l</mi></msub><mi>E</mi><msub><mrow></mrow><mi>l</mi></msub></mrow></math></mathml>      (4)</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54">(3) 风格转换。</h4>
                <div class="p1">
                    <p id="55">利用L-BFGS梯度下降算法优化生成的总损失度,调整<i>α</i>和<i>β</i>权重系数可调整content或style在生成图中的比重。总损失函数为:</p>
                </div>
                <div class="p1">
                    <p id="56"><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>o</mtext><mtext>t</mtext><mtext>a</mtext><mtext>l</mtext></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>p</mi><mo>→</mo></mover><mo>,</mo><mover accent="true"><mi>a</mi><mo>→</mo></mover><mo>,</mo><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mi>α</mi><mi>L</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>n</mtext><mtext>t</mtext><mtext>e</mtext><mtext>n</mtext><mtext>t</mtext></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>p</mi><mo>→</mo></mover><mo>,</mo><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo stretchy="false">)</mo><mo>+</mo><mi>β</mi><mi>L</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>t</mtext><mtext>y</mtext><mtext>l</mtext><mtext>e</mtext></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>a</mi><mo>→</mo></mover><mo>,</mo><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo stretchy="false">)</mo></mrow></math></mathml>      (5)</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57"><b>2.2 算法实现</b></h4>
                <div class="p1">
                    <p id="58">本文的核心思想是利用卷积神经网络将目标图像的内容特征表示和风格图像的特征表示进行分离,最后进行高度化合成。在实现过程中,分别将内容图像和艺术风格图像输入到预训练好的VGG19模型,接收图像的VGG19模型分别提取这两幅图片中的全局特征和抽象特征,计算这两种图片和生成图片的图层激活函数值。神经网络中不同层级的激活值使得图像内容在各种空间尺度上进行分解,使用三幅图上计算的图层激活值来定义内容损失值、样式损失值和总损失值loss。从随机噪声图像开始,利用基于Scipy库的L-BFGS优化算法设置随梯度下降过程并最小化的总损失函数值,设置迭代次数后生成具有原内容和新风格的合成图像。具体的技术实现流程如图4所示。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911037_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 图像风格迁移技术的实现流程" src="Detail/GetImg?filename=images/JYRJ201911037_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 图像风格迁移技术的实现流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911037_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="60" name="60" class="anchor-tag"><b>3 实 验</b></h3>
                <h4 class="anchor-tag" id="61" name="61"><b>3.1 实验搭建环境</b></h4>
                <div class="p1">
                    <p id="62">实验使用Keras框架搭建网络,本实验中Keras框架由纯Python编写的基于Tensorflow为后端。它是一个高层神经网络的API,可以迅速地将想法转换为结果,允许简单而快速的原型设计,更适配卷积神经网络,模型库中含有很多经典的模型使得深度学习的建模与算法设计较为方便。实验硬件平台为Intel(R) Core(TM) i7-4790 CPU主频3.60 GHz,16 GB内存,AMD Radeon R5 340 CPU。</p>
                </div>
                <div class="p1">
                    <p id="63">为验证不同内容图片与不同艺术风格的迁移效果,本文进行了大量的实验。为突出研究的趣味性和艺术性,本文仅仅给出了选择素描人像、上海外滩作为目标内容图片,选择具有代表性的梵高作品《星月夜》和色彩鲜明的油画两种风格作为艺术风格图作为案例。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64"><b>3.2 实验过程与结果</b></h4>
                <div class="p1">
                    <p id="65"><b>实验1</b> 选择素描人像作为目标内容图片,色彩鲜明的油画作为艺术风格图。</p>
                </div>
                <div class="p1">
                    <p id="66">实验1使用了两幅素描人像图像和油画风格图像。图5为原始人像图、油画和迭代优化20次生成的合成效果图。设置迭代训练次数20次,style weight=1,content weight=0.025。通过实验效果得知,图像风格迁移算法在本组实验图片中可有效的实现,但存在训练速度较慢、图片有失真现象,以及不能自然地将样式转移到原始图片中并结合等问题。</p>
                </div>
                <div class="area_img" id="67">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911037_06700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 迭代20次后的人像合成图" src="Detail/GetImg?filename=images/JYRJ201911037_06700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 迭代20次后的人像合成图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911037_06700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="68"><b>实验2</b> 选择上海外滩作为目标内容图片,梵高的《星月夜》作为艺术风格图。</p>
                </div>
                <div class="p1">
                    <p id="69">在实验2中分别选择上海外滩和梵高画作《星月夜》分别作为内容图和风格图。实验设置环境与实验1相同,但迭代优化次数增加至150次。图6中,(a)为目标图上海外滩、(b)为艺术风格图星月夜、(c)为合成效果图。图7中,生成第45张图的损失值1.017 29e+08最低,第46次到第150次迭代中,损失值从9.981 48e+07降低至4.217 42e+07。这说明迭代45次时,两幅图像合成的匹配度最高,但样式不够清晰,随着迭代次数的增加,样式转移度越来越高,但纹理清晰度下降。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911037_07000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 上海外滩和梵高-星月夜的内容图、样式图和合成图" src="Detail/GetImg?filename=images/JYRJ201911037_07000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 上海外滩和梵高-星月夜的内容图、样式图和合成图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911037_07000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911037_07100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 目标内容图、迭代次数为44、50、150的合成图" src="Detail/GetImg?filename=images/JYRJ201911037_07100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 目标内容图、迭代次数为44、50、150的合成图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911037_07100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="72">为测试文中算法的有效性,改进实验1的不足,在本组实验中增加了VGGNet网络中的VGG16模型。具体模型区别如下:VGG16包含13个卷积层,VGG19包含16个卷积层。两种模型均迭代150次,对比实验结果如表1所示。</p>
                </div>
                <div class="area_img" id="73">
                    <p class="img_tit"><b>表1 不同网络模型在不同迭代次数下的总损失度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="73" border="1"><tr><td colspan="2"><br />VGG16</td><td colspan="2">VGG19</td></tr><tr><td>迭代次数</td><td>损失度</td><td>迭代次数</td><td>损失度</td></tr><tr><td><br />0</td><td>1.165 32e+09</td><td>0</td><td>1.869 96e+09</td></tr><tr><td><br />45</td><td>1.005 89e+07</td><td>45</td><td>1.017 29e+08</td></tr><tr><td><br />50</td><td>9.577 13e+06</td><td>50</td><td>9.205 96e+07</td></tr><tr><td><br />100</td><td>6.592 95e+06</td><td>100</td><td>5.298 82e+07</td></tr><tr><td><br />150</td><td>5.602 36e+06</td><td>150</td><td>4.217 42e+07</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="74">可以看出,VGG16和VGG19模型均在迭代45次时损失度最低,合成匹配度最高。但随着迭代次数增加至150次,VGG19模型的合成损失度明显低于VGG16模型。图8为VGG16和VGG19两种模型的合成图。通过150次迭代优化后,明显看出VGG19图像迁移的合成图效果更好,而VGG16合成图出现明显的失真效果。本文提出的算法对于层数较高的卷积神经网络VGG19模型具有一定的优势,虽然利用两种不同的VGGNet模型,但匹配程度最佳均为第45次迭代,VGG19在合成图片的过程中准确率更高,合成效果更优。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911037_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 对比VGG16和VGG19两种模型合成图" src="Detail/GetImg?filename=images/JYRJ201911037_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 对比VGG16和VGG19两种模型合成图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911037_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="76">依据风格转换总损失函数公式,调整content和style的所占比重,可看出不同效果的实验结果图。合理选择比重所占比,才可实现匹配度较佳的风格迁移技术。表2为VGG19训练图片迭代次数45次的不同content和style占比损失度表。图9为三种不同权重占比合成效果图。增加内容权重占比可提高合成图中的内容原始度,设置style weight=0.025、content weight=1,样式图星月夜迁移效果明显下降。设置style weight=1、content weight=0.5时,内容图上海外滩较清晰。设置style weight=1、content weight=0.025时实现图像迁移算法后的合成匹配度最佳、损失度最低。</p>
                </div>
                <div class="area_img" id="77">
                    <p class="img_tit"><b>表2 VGG19迭代45次下调整权重占比损失度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="77" border="1"><tr><td>Style weight</td><td>0.025</td><td>1</td><td>1</td></tr><tr><td><br />Content weight</td><td>1</td><td>0.5</td><td>0.025</td></tr><tr><td><br />Loss</td><td>7.621 09e+07</td><td>2.435 19e+08</td><td>1.017 29e+08</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="104">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911037_10400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 三种不同权重占比合成效果图" src="Detail/GetImg?filename=images/JYRJ201911037_10400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 三种不同权重占比合成效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911037_10400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="79" name="79" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="80">本文在Gatys等提出的Gram矩阵算法基础上,采用灵活性较好的VGG19网络作为核心模型,提出了一种基于VGGNet的图像风格迁移算法设计与实现,有效地实现了不同风格图像间的风格迁移。实验表明,本文算法适用于风格迁移,能够生成逼真的艺术性合成图像,在深度学习Keras框架的基础上,实现过程较为简单,选择合理的迭代训练次数可使得损失度降到最低、合成图片的匹配度最佳。生成对抗网络和变分自编码器(Variational Auto-encoder,VAE)网络的诞生可能对解决这些问题有很大帮助,需进一步研究和讨论。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="105">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Deep Learning&amp;quot;">

                                <b>[1]</b> Lecun Y,Bengio Y,Hinton G.Deep learning[J].Nature,2015,521(7553):436-444.
                            </a>
                        </p>
                        <p id="107">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESD4DD2CBC9D88E822183D83486692F7C9&amp;v=MDY1OTZhQnVIWWZPR1FsZkNwYlEzNWRoaHc3eTR3YUE9TmlmT2ZjZThhcVhPM1AwMmJaOEhCQWt4elJRUzRqd0pRSHptcEJRemNMRGlRc21XQ09OdkZTaVdXcjdKSUZwbQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Gatys L A,Ecker A S,Bethge M.Texture and art with deep neural networks[J].Current Opinion in Neurobiology,2017,46:178-186.
                            </a>
                        </p>
                        <p id="109">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201908002&amp;v=MjIzNTJPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hWTDdBTHo3U1pMRzRIOWpNcDQ5RlpvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 陈淑環,韦玉科,徐乐,等.基于深度学习的图像风格迁移研究综述[J].计算机应用研究,2019,36(8):2250-2255.
                            </a>
                        </p>
                        <p id="111">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A neural algorithm of artistic style[DB]">

                                <b>[4]</b> Gatys L A,Ecker A S,Bethge M.A neural algorithm of artistic style[DB].eprint arXiv:1508.06576,2015.
                            </a>
                        </p>
                        <p id="113">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image style transfer using convolutional neural networks">

                                <b>[5]</b> Gatys L A,Ecker A S,Bethge M.Image style transfer using convolutional neural networks[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition(CVPR).IEEE,2016:2414-2423.
                            </a>
                        </p>
                        <p id="115">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Texture networks:feed-forward synthesis of textures and stylized images[EB]">

                                <b>[6]</b> Ulyanov D,Lebedev V,Vedaldi A,et al.Texture networks:feed-forward synthesis of textures and stylized images[EB].eprint arXiv:1603.03417,2016.
                            </a>
                        </p>
                        <p id="117">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unpaired image-to-image translation using cycle-consistent adversarial networks">

                                <b>[7]</b> Zhu J Y,Park T,Isola P,et al.Unpaired image-to-image translation using cycle-consistent adversarial networks[C]//IEEE International Conference on Computer Vision.IEEE Computer Society,2017:2242-2251.
                            </a>
                        </p>
                        <p id="119">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Perceptual losses for real-time style transfer and super-resolution">

                                <b>[8]</b> Johnson J,Alahi A,Fei-Fei L.Perceptual losses for real-time style transfer and super-resolution[C]//ECCV:European Conference on Computer Vision,2016:694-711
                            </a>
                        </p>
                        <p id="121">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Learned Representation For Artistic Style[EB]">

                                <b>[9]</b> Dumoulin V,Shlens J,Kudlur M.A Learned Representation For Artistic Style[EB].eprint arXiv:1610.07629,2016.
                            </a>
                        </p>
                        <p id="123">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017183567.nh&amp;v=MzAzMDZLd0hkVEtxSkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvaFZMN0FWRjI2R2I=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 操江峰.基于深度学习的图像与视频风格化研究与实现[D].北京:中国科学院大学,2017.
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201807048&amp;v=MjA0MTZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9oVkw3QUx6VFpaTEc0SDluTXFJOUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 王茜,陈一民,丁友东.基于改进卷积神经网络的机动车图像分类算法[J].计算机应用与软件,2018,35(7):263-266,298.
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition[EB]">

                                <b>[12]</b> Simonyan K,Zisserman A.Very Deep Convolutional Networks for Large-Scale Image Recognition[EB].eprint arXiv:1409.1556,2014.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201911037" />
        <input id="dpi" type="hidden" value="96" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201911037&amp;v=Mjk0MDZHNEg5ak5ybzlHWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvaFZMN09MelRaWkw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
