<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135612593283750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201908033%26RESULT%3d1%26SIGN%3dIm64V5BFzE0SyaKa8OwhdLDSfEQ%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201908033&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201908033&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201908033&amp;v=MDkzMTZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWptVmIzQUx6VFpaTEc0SDlqTXA0OUc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;1 颜色特征&lt;/b&gt; "><b>1 颜色特征</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#57" data-title="&lt;b&gt;2 纹理特征&lt;/b&gt; "><b>2 纹理特征</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="&lt;b&gt;2.1 双树复小波变换&lt;/b&gt;"><b>2.1 双树复小波变换</b></a></li>
                                                <li><a href="#64" data-title="&lt;b&gt;2.2 多参数灰度共生矩阵&lt;/b&gt;"><b>2.2 多参数灰度共生矩阵</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#96" data-title="&lt;b&gt;3 二级分区下颜色融合纹理的检索算法&lt;/b&gt; "><b>3 二级分区下颜色融合纹理的检索算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#101" data-title="&lt;b&gt;3.1 区域划分与局部区域特征提取&lt;/b&gt;"><b>3.1 区域划分与局部区域特征提取</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;3.2 基于KPCA的特征选择&lt;/b&gt;"><b>3.2 基于KPCA的特征选择</b></a></li>
                                                <li><a href="#138" data-title="&lt;b&gt;3.3 算法步骤&lt;/b&gt;"><b>3.3 算法步骤</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#147" data-title="&lt;b&gt;4 实验结果及分析&lt;/b&gt; "><b>4 实验结果及分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#158" data-title="&lt;b&gt;4.1 不同分区级别对比&lt;/b&gt;"><b>4.1 不同分区级别对比</b></a></li>
                                                <li><a href="#162" data-title="&lt;b&gt;4.2 相似性度量的选取&lt;/b&gt;"><b>4.2 相似性度量的选取</b></a></li>
                                                <li><a href="#170" data-title="&lt;b&gt;4.3 特征选择前后比较&lt;/b&gt;"><b>4.3 特征选择前后比较</b></a></li>
                                                <li><a href="#174" data-title="&lt;b&gt;4.4 检索结果与分析&lt;/b&gt;"><b>4.4 检索结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#190" data-title="&lt;b&gt;5 结 语&lt;/b&gt; "><b>5 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="图1 一维双树复小波变换">图1 一维双树复小波变换</a></li>
                                                <li><a href="#99" data-title="图2 示例图像及其分块">图2 示例图像及其分块</a></li>
                                                <li><a href="#107" data-title="图3 分区示例图">图3 分区示例图</a></li>
                                                <li><a href="#161" data-title="&lt;b&gt;表1 不同分区级别实验结果&lt;/b&gt;"><b>表1 不同分区级别实验结果</b></a></li>
                                                <li><a href="#167" data-title="图4 4种相似性度量方式平均precision曲线图">图4 4种相似性度量方式平均precision曲线图</a></li>
                                                <li><a href="#168" data-title="图5 4种相似性度量方式平均recall曲线图">图5 4种相似性度量方式平均recall曲线图</a></li>
                                                <li><a href="#172" data-title="&lt;b&gt;表2 特征选择前后实验结果对比&lt;/b&gt;"><b>表2 特征选择前后实验结果对比</b></a></li>
                                                <li><a href="#176" data-title="图6 文献">图6 文献</a></li>
                                                <li><a href="#177" data-title="图7 文献">图7 文献</a></li>
                                                <li><a href="#178" data-title="图8 文献">图8 文献</a></li>
                                                <li><a href="#179" data-title="图9 TCAC">图9 TCAC</a></li>
                                                <li><a href="#180" data-title="图10 本文算法">图10 本文算法</a></li>
                                                <li><a href="#183" data-title="图11 图库1不同算法平均precision曲线图">图11 图库1不同算法平均precision曲线图</a></li>
                                                <li><a href="#184" data-title="图12 图库1不同算法平均recall曲线图">图12 图库1不同算法平均recall曲线图</a></li>
                                                <li><a href="#185" data-title="图13 图库2不同算法平均precision曲线图">图13 图库2不同算法平均precision曲线图</a></li>
                                                <li><a href="#186" data-title="图14 图库2不同算法平均recall曲线图">图14 图库2不同算法平均recall曲线图</a></li>
                                                <li><a href="#188" data-title="&lt;b&gt;表3 图库1各类图像平均精确度&lt;/b&gt;"><b>表3 图库1各类图像平均精确度</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Datta R, Joshi D, Li J, et al.Image retrieval:Ideas, influences, and trends of the new age[J].Acm Computing Surveys, 2008, 40 (2) :1-60." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000017673&amp;v=MjAwOThkR2VycVFUTW53WmVadEZpbmxVcnpJSUYwU2FCbz1OaWZJWTdLN0h0ak5yNDlGWk9vSUNuczZvQk1UNlQ0UFFIL2lyUg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Datta R, Joshi D, Li J, et al.Image retrieval:Ideas, influences, and trends of the new age[J].Acm Computing Surveys, 2008, 40 (2) :1-60.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Liu P, Guo J M, Chamnongthai K, et al.Fusion of color histogram and LBP-based features for texture image retrieval and classification[J].Information Sciences, 2017, 390:95-111." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDE2B6E58E0195D30A1429E00CD3B9FA5&amp;v=MDM2Njl0dGh4THU1d3FBPU5pZk9mY2ZOSEtQSzJvcE5FZXNPQlhsTnpCWmk2enQvUVFyaXJHRkJlc0NkTTh1YUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Liu P, Guo J M, Chamnongthai K, et al.Fusion of color histogram and LBP-based features for texture image retrieval and classification[J].Information Sciences, 2017, 390:95-111.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Jacob I J, Srinivasagan K G, Jayapriya K.Local oppugnant color texture pattern for image retrieval system[J].Pattern Recognition Letter, 2014, 42:72-78." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14021300017568&amp;v=MTgxODFCTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlGMFNhQm89TmlmT2ZiSzhIdFBOckk5RlpPb0lDWG94bw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Jacob I J, Srinivasagan K G, Jayapriya K.Local oppugnant color texture pattern for image retrieval system[J].Pattern Recognition Letter, 2014, 42:72-78.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Dubey S R, Jalal A S.Apple disease classification using color, texture and shape features from images[J].Signal Image &amp;amp; Video Processing, 2016, 10 (5) :819-826." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Apple disease classification using color,texture and shape features from images">
                                        <b>[4]</b>
                                         Dubey S R, Jalal A S.Apple disease classification using color, texture and shape features from images[J].Signal Image &amp;amp; Video Processing, 2016, 10 (5) :819-826.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Qin C, Sun M, Chang C C.Perceptual Hashing for Color Images Based on Hybrid Extraction of Structural Features[J].Signal Processing, 2017, 142:194-205." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8C0A3BB179E68D22F85ADDB639441AF6&amp;v=MjM2NTgxRVkrSjZDblJOelJSbDRqb01QQXVRcWhFOGZiYVZOTXlaQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeEx1NXdxQT1OaWZPZmJ2TEhxRFAzZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Qin C, Sun M, Chang C C.Perceptual Hashing for Color Images Based on Hybrid Extraction of Structural Features[J].Signal Processing, 2017, 142:194-205.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Wang X Y, Zhang B B, Yang H Y.Content-based image retrieval by integrating color and texture features[J].Multimedia Tools &amp;amp; Applications, 2014, 68 (3) :545-569." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14030300026936&amp;v=MDk3NDNKQlg4L29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlGMFNhQm89Tmo3QmFySzhIdExNckk5RlpPaw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Wang X Y, Zhang B B, Yang H Y.Content-based image retrieval by integrating color and texture features[J].Multimedia Tools &amp;amp; Applications, 2014, 68 (3) :545-569.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 刘颖, 范九伦, 李宗, 等.现勘图像数据库检索技术实例探讨[J].西安邮电大学学报, 2015, 20 (3) :11-20." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAYD201503002&amp;v=MDQ4ODdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVZiM0FQU3pTYXJHNEg5VE1ySTlGWm9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         刘颖, 范九伦, 李宗, 等.现勘图像数据库检索技术实例探讨[J].西安邮电大学学报, 2015, 20 (3) :11-20.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 刘颖, 胡丹, 范九伦.现勘图像检索综述[J].电子学报, 2018, 46 (3) :761-768." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201803035&amp;v=MzA2NjZHNEg5bk1ySTlHWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVZiM0FJVGZUZTc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         刘颖, 胡丹, 范九伦.现勘图像检索综述[J].电子学报, 2018, 46 (3) :761-768.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 兰蓉, 贾世英.基于纹理与颜色特征融合的刑侦图像检索算法[J].西安邮电大学学报, 2016, 21 (2) :57- 62." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAYD201602011&amp;v=MjY5NDBQU3pTYXJHNEg5Zk1yWTlFWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVZiM0E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         兰蓉, 贾世英.基于纹理与颜色特征融合的刑侦图像检索算法[J].西安邮电大学学报, 2016, 21 (2) :57- 62.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 兰蓉, 郭思忱, 贾世英.基于纹理与形状特征融合的刑侦图像检索算法[J].计算机工程与设计, 2018, 39 (4) :1106-1110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201804036&amp;v=MDM0NDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1WYjNBTmlmWVpMRzRIOW5NcTQ5R1lvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         兰蓉, 郭思忱, 贾世英.基于纹理与形状特征融合的刑侦图像检索算法[J].计算机工程与设计, 2018, 39 (4) :1106-1110.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 刘颖, 黄源, 高梓铭.刑侦图像检索中的特征提取及相似性度量[J].西安邮电大学学报, 2014, 19 (6) :11-16." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAYD201406004&amp;v=MjkwODJDVVI3cWZadVp0RnlqbVZiM0FQU3pTYXJHNEg5WE1xWTlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         刘颖, 黄源, 高梓铭.刑侦图像检索中的特征提取及相似性度量[J].西安邮电大学学报, 2014, 19 (6) :11-16.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Sch&#246;lkopf B, Smola A, M&#252;ller K R.Kernel principal component analysis[C]//Artificial Neural Networks-ICANN’97, Lecture Notes in Computer Science, 1997, 1327:583-588." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Kernel Principal Component Analysis">
                                        <b>[12]</b>
                                         Sch&#246;lkopf B, Smola A, M&#252;ller K R.Kernel principal component analysis[C]//Artificial Neural Networks-ICANN’97, Lecture Notes in Computer Science, 1997, 1327:583-588.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Huang J, Ravi Kumar S, Mitra M, et al.Spatial Color Indexing and Applications[C]//Proceedings of the Sixth International Conference on Computer Vision.IEEE Computer Society, 1998:602." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatial color indexing and applications">
                                        <b>[13]</b>
                                         Huang J, Ravi Kumar S, Mitra M, et al.Spatial Color Indexing and Applications[C]//Proceedings of the Sixth International Conference on Computer Vision.IEEE Computer Society, 1998:602.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Chang T, Kuo C C J.Texture analysis and classification with tree-structured wavelet transform[J].IEEE Transactions on Image Processing, 1993, 2 (4) :429-441." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Texture analysis and classification with tree-structured wavelet transform">
                                        <b>[14]</b>
                                         Chang T, Kuo C C J.Texture analysis and classification with tree-structured wavelet transform[J].IEEE Transactions on Image Processing, 1993, 2 (4) :429-441.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Yu B, Jia B, Ding L, et al.Hybrid dual-tree complex wavelet transform and support vector machine for digital multi-focus image fusion[J].Neurocomputing, 2016, 182 (C) :1-9." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES22DD96EDC50AD93E815FD86EC4E8584A&amp;v=MjU0NTVtYUJ1SFlmT0dRbGZCckxVMDV0dGh4THU1d3FBPU5pZk9mYkc2YXFYRnFmb3hGKzRQZlFnd3pHTWI2em9MUEhmazJXRXhETHFSVGI3dUNPTnZGU2lXV3I3SklGcA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Yu B, Jia B, Ding L, et al.Hybrid dual-tree complex wavelet transform and support vector machine for digital multi-focus image fusion[J].Neurocomputing, 2016, 182 (C) :1-9.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Jung C, Yang Q, Sun T, et al.Low Light Image Enhancement with Dual-Tree Complex Wavelet Transform[J].Journal of Visual Communication &amp;amp; Image Representation, 2016, 42:28-36." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES52441A5C9E3F5DA49D834A50FECFDE7D&amp;v=MTY2NDA1dHRoeEx1NXdxQT1OaWZPZmJhNkd0WE4zb28yYlo0TWVubE52aElhbmpkK1RBN25yR1JBQ3NUZ01MM3JDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Jung C, Yang Q, Sun T, et al.Low Light Image Enhancement with Dual-Tree Complex Wavelet Transform[J].Journal of Visual Communication &amp;amp; Image Representation, 2016, 42:28-36.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Pare S, Bhandari A K, Kumar A, et al.An optimal Color Image Multilevel Thresholding Technique using Grey-Level Co-occurrence Matrix[J].Expert Systems with Applications, 2017, 87:335-362." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8A8695937C6E3550ECE18202EF1A56B0&amp;v=MDk1NTBmQnJMVTA1dHRoeEx1NXdxQT1OaWZPZmJ2SkZ0ZkZxb1pHWTVnSmVYODh5aFptbVVwOFFIM2lybWREZU1PUlE4aWZDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         Pare S, Bhandari A K, Kumar A, et al.An optimal Color Image Multilevel Thresholding Technique using Grey-Level Co-occurrence Matrix[J].Expert Systems with Applications, 2017, 87:335-362.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Wu J, Wang J, Liu L.Feature extraction via KPCA for classification of gait patterns[J].Human Movement Science, 2007, 26 (3) :393-411." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300393553&amp;v=MzI0NjVUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSUYwU2FCbz1OaWZPZmJLN0h0RE9ySTlGWitJTUNYazZvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Wu J, Wang J, Liu L.Feature extraction via KPCA for classification of gait patterns[J].Human Movement Science, 2007, 26 (3) :393-411.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" 黄源.基于区域语义模板的刑侦图像检索算法研究[D].西安:西安邮电大学, 2015." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015649701.nh&amp;v=MDk5MDM2RzdXOEY5Yk1ycEViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVZiM0FWRjI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         黄源.基于区域语义模板的刑侦图像检索算法研究[D].西安:西安邮电大学, 2015.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" Murala S, Maheshwari R P, Balasubramanian R.Directional local extrema patterns:a ne-w descriptor for content based image retrieval[J].International Journal of Multimedia Information Retrieval, 2012, 1 (3) :191-203." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Directional local extrema patterns a ne-w descriptor for content based image retrieval">
                                        <b>[20]</b>
                                         Murala S, Maheshwari R P, Balasubramanian R.Directional local extrema patterns:a ne-w descriptor for content based image retrieval[J].International Journal of Multimedia Information Retrieval, 2012, 1 (3) :191-203.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(08),181-188 DOI:10.3969/j.issn.1000-386x.2019.08.032            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>二级分区下颜色融合纹理的刑侦图像检索</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">兰蓉</a>
                                <a href="javascript:;">母保洋</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1698419&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安邮电大学通信与信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E7%8E%B0%E5%9C%BA%E5%8B%98%E9%AA%8C%E5%BA%94%E7%94%A8%E6%8A%80%E6%9C%AF%E5%85%AC%E5%AE%89%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">电子信息现场勘验应用技术公安部重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%99%95%E8%A5%BF%E7%9C%81%E6%97%A0%E7%BA%BF%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E5%9B%BD%E9%99%85%E5%90%88%E4%BD%9C%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陕西省无线通信与信息处理技术国际合作研究中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>多数刑侦图像检索算法缺乏图像局部特征的提取, 从而导致检索精确度较低。对此, 提出一种新的二级分区下颜色融合纹理的刑侦图像检索算法。该算法采用二级分区将图像划分成多个局部区域;提取局部区域的颜色自相关图特征和双树复小波结合多方向多参数的灰度共生矩阵的纹理特征;以串行的方式融合局部区域特征。使用核主成分分析法 (Kernel Principle Component Analysis, KPCA) 进行特征选择, 以欧式距离作为相似性度量实现检索。通过在两个刑侦图库的实验结果表明, 该算法的平均精确度均高于传统的刑侦图像检索算法, 具有良好的检索效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%8C%E7%BA%A7%E5%88%86%E5%8C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">二级分区;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A2%9C%E8%89%B2%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">颜色特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">纹理特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8C%BA%E5%9F%9F%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">区域融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征选择;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    兰蓉, 副教授, 主研领域:模式识别, 决策分析。;
                                </span>
                                <span>
                                    母保洋, 硕士生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-16</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61571361, 61671377);</span>
                                <span>陕西省教育厅科学研究计划项目 (6JK1709);</span>
                                <span>西安邮电大学西邮新星团队项目 (xyt2016-01);</span>
                    </p>
            </div>
                    <h1><b>CRIMINAL INVESTIGATION IMAGE RETRIEVAL BASED ON COLOR AND TEXTURE FUSED UNDER TWO-STAGE PARTITION</b></h1>
                    <h2>
                    <span>Lan Rong</span>
                    <span>Mu Baoyang</span>
            </h2>
                                    <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Most criminal investigation image retrieval algorithms lack the extraction of image local features, which leads to low retrieval accuracy. To solve this problem, we proposed a novel criminal investigation image retrieval algorithm based on color and texture fused under two-stage partition. We used two-stage partition to divide the image into several local regions, extracted the color auto-correlogram features of the local region and the texture features of the dual-tree complex wavelet combined with the gray level co-occurrence matrix of multi-direction and multi-parameter, and fused the local region features in a serial way. Then we adopted the kernel principal component analysis (KPCA) to select features, and used Euclidean distance as similarity measure to achieve retrieval. The experimental results of two criminal investigation image databases show that the average accuracy of the algorithm is higher than that of the traditional algorithm, and it has a good retrieval effect.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Two-stage%20partition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Two-stage partition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Color%20features&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Color features;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Textural%20features&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Textural features;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Regional%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Regional fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Feature%20selection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Feature selection;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-16</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="44">随着犯罪率的不断上升, 采用现场拍摄图像来获取、保存犯罪证据已经成为公安机关的一种常用手段。因此, 对刑侦图像进行快速、准确、专业地处理显得尤为重要。其中, 对于刑侦图像检索算法的研究可以有效提高办案效率, 因此受到广泛关注。</p>
                </div>
                <div class="p1">
                    <p id="45">现存的刑侦图像检索算法主要是基于内容的图像检索<citation id="193" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation> (Content-based image retrieval, CBIR) 。在CBIR中, 图像以视觉内容来建立索引, 如颜色<citation id="194" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、纹理<citation id="195" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、形状<citation id="196" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、结构特征<citation id="197" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等, 计算查询图像与目标图像的相似度, 按照特征匹配进行检索<citation id="198" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。但是由于刑侦图像数据库 (Crime Scene Investigation, CSI) 具有图像包含多目标、场景复杂、目标不确定的特点<citation id="199" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 使其不同于一般的自然图像库, 所以目前国内外关于刑侦图像检索算法的研究相对较少<citation id="200" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。为了提高刑侦图像检索的准确性, 文献<citation id="201" type="reference">[<a class="sup">9</a>]</citation>提出一种将颜色距结合8方向6参数的灰度共生矩阵的检索方法, 但是8方向中存在4对共线方向, 因此容易产生特征冗余。文献<citation id="202" type="reference">[<a class="sup">10</a>]</citation>将形状特征应用到刑侦图像检索中, 但是其检索准确率有待提升。文献<citation id="203" type="reference">[<a class="sup">11</a>]</citation>将三层小波变换结合非等间隔量化的HSV直方图实现检索, 但是提取的颜色特征缺乏空间信息。以上3种算法均缺乏对图像局部区域特征的提取, 因此影响了检索的准确率。</p>
                </div>
                <div class="p1">
                    <p id="46">针对上述算法对图像局部区域特征描述的缺陷, 基于算法的有效性与复杂度的考虑, 本文采用二级分区将图像划分成局部子块区域, 同时以颜色自相关图作为子块的颜色特征, 以双树复小波结合多方向多参数的灰度共生矩阵作为子块的纹理特征, 以串行的方式融合子块区域特征, 再利用 KPCA<citation id="204" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>进行特征选择, 剔除冗余数据, 降低算法计算复杂度, 并以欧式距离作为相似性度量, 提出二级分区下颜色融合纹理的刑侦图像检索算法, 并以实验验证其检索性能。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag"><b>1 颜色特征</b></h3>
                <div class="p1">
                    <p id="48">由于刑侦图像均由现场拍摄获得, 包含丰富的颜色信息, 所以颜色信息是反映刑侦图像的重要特征之一。本文选取包含像素点空间颜色信息的颜色自相关图作为颜色特征。</p>
                </div>
                <div class="p1">
                    <p id="49">由于常用于图像颜色特征提取的颜色直方图只统计了不同颜色在图像中所占比例, 缺乏对图像像素点颜色空间信息的描述。为此, 颜色相关图 (Color Correlogram) 与颜色自相关图 (Color Auto-correlogram, CAC) <citation id="205" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>被提出。</p>
                </div>
                <div class="p1">
                    <p id="50">颜色相关图表示的是图像<i>I</i>不同像素点颜色值之间的空间关系。设<i>p</i><sub>1</sub>、<i>p</i><sub>2</sub>是图像的任意两个像素点, <i>p</i><sub>1</sub>∈<i>T</i><sub><i>c</i><sub><i>i</i></sub></sub>, <i>p</i><sub>2</sub>∈<i>T</i><sub><i>c</i><sub><i>j</i></sub></sub>等价于<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>∈<i>I</i>, 则颜色相关图的定义如下:</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>c</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Ρ</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false">[</mo><mi>p</mi><msub><mrow></mrow><mn>1</mn></msub><mo>∈</mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>, </mo><mi>p</mi><msub><mrow></mrow><mn>2</mn></msub><mo>∈</mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>c</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>, </mo><mrow><mo>|</mo><mrow><mi>p</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>p</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>|</mo></mrow><mo>=</mo><mi>k</mi><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">颜色自相关图是颜色相关图的简化, 定义为:</p>
                </div>
                <div class="p1">
                    <p id="53"><i>α</i><mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>c</mi><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml> (<i>I</i>) =<i>γ</i><mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>c</mi><mo>, </mo><mi>c</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml> (<i>I</i>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="56">与颜色相关图相比, 颜色自相关图只计算具有相同颜色像素点之间的空间关系, 计算复杂度低、计算速度快、存储空间小, 所以本文选取包含空间信息的颜色自相关图作为图像颜色特征<b><i>T</i></b><sub><i>ci</i></sub>。</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag"><b>2 纹理特征</b></h3>
                <div class="p1">
                    <p id="58">除颜色信息之外, 刑侦图像中很多种类, 如指纹、轮胎等图像还包含着丰富的纹理信息。仅采用颜色特征描述, 容易造成算法对图像的区分度较低的不足, 因此本文选择双树复小波融合灰度共生矩阵提取图像的纹理特征。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59"><b>2.1 双树复小波变换</b></h4>
                <div class="p1">
                    <p id="60">经典的小波变换<citation id="206" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>在提取纹理特征时存在平移敏感、方向选择不足等缺点。为解决此问题, Kingsbury等于1998年提出双树复小波变换 (Dual-tree Complex Wavelet Transform, DT-CWT) <citation id="207" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。DT-CWT是由两个平行的小波树A和B构成的, 变换公式为:</p>
                </div>
                <div class="p1">
                    <p id="61"><i>ψ</i> (<i>t</i>) =<i>ψ</i><sub><i>r</i></sub> (<i>t</i>) +<i>jψ</i><sub><i>j</i></sub> (<i>t</i>)      (3) </p>
                </div>
                <div class="p1">
                    <p id="62">式中:实部<i>ψ</i><sub><i>r</i></sub> (<i>t</i>) 由上小波树A生成, 虚部<i>ψ</i><sub><i>j</i></sub> (<i>t</i>) 由下小波树B生成, 且树A的滤波器长度为偶数, 树B的滤波器长度为奇数, 目的是保证滤波器之间的半采样延迟。有关实验结论表明该方法能够显著改善离散小波变换的平移敏感性, 并能够产生±75°、±45°、±15°六个不同方向的高频子图<citation id="208" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。在上述方向提取图像系数矩阵, 能够更为具体地描述图像的纹理, 同时保留边缘等细节信息。一维双树复小波变换如图1所示。</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 一维双树复小波变换" src="Detail/GetImg?filename=images/JYRJ201908033_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 一维双树复小波变换  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="64" name="64"><b>2.2 多参数灰度共生矩阵</b></h4>
                <div class="p1">
                    <p id="65">灰度共生矩阵是像素之间距离和角度的矩阵函数, 它通过计算图像中具有一定距离和方向的两个像素点灰度之间的相关性来反映图像纹理在间隔、方向、变化幅度以及快慢上的综合信息。</p>
                </div>
                <div class="p1">
                    <p id="66">设大小为<i>M</i>×<i>N</i>的图像的像素坐标 (<i>x</i>, <i>y</i>) 的灰度分布为<i>f</i> (<i>x</i>, <i>y</i>) , 那么灰度共生矩阵可以表示为在角度<i>θ</i>方向上灰度值分别为<i>f</i> (<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>) =<i>i</i>和<i>f</i> (<i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>) =<i>j</i>距离为<i>d</i>的频率相关矩阵<citation id="209" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="67"><b><i>P</i></b>=[<i>p</i><sub><i>ij</i></sub> (<i>d</i>, <i>θ</i>) ]      (4) </p>
                </div>
                <div class="p1">
                    <p id="68">设图像的灰度级用<i>L</i>表示, 当<i>θ</i>取0°、45°、90°、135°时, 灰度共生矩阵表示如下:</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>d</mi><mo>, </mo><mn>0</mn><mo>°</mo><mo stretchy="false">) </mo><mo>=</mo><mo>#</mo><mo stretchy="false">{</mo><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mo>, </mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>∈</mo><mi>L</mi><mo>×</mo><mi>L</mi><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mi>d</mi><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70"><i>y</i><sub>2</sub>-<i>y</i><sub>1</sub>=0, <i>f</i> (<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>) =<i>i</i>, <i>f</i> (<i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>) =<i>j</i>}      (5) </p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>d</mi><mo>, </mo><mn>4</mn><mn>5</mn><mo>°</mo><mo stretchy="false">) </mo><mo>=</mo><mo>#</mo><mo stretchy="false">{</mo><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mo>, </mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>∈</mo><mi>L</mi><mo>×</mo><mi>L</mi><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mi>d</mi><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72"><i>y</i><sub>2</sub>-<i>y</i><sub>1</sub>=<i>d</i>, <i>f</i> (<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>) =<i>i</i>, <i>f</i> (<i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>) =<i>j</i>}      (6) </p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>d</mi><mo>, </mo><mn>9</mn><mn>0</mn><mo>°</mo><mo stretchy="false">) </mo><mo>=</mo><mo>#</mo><mo stretchy="false">{</mo><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mo>, </mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>∈</mo><mi>L</mi><mo>×</mo><mi>L</mi><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mn>0</mn><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74"><i>y</i><sub>2</sub>-<i>y</i><sub>1</sub>=<i>d</i>, <i>f</i> (<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>) =<i>i</i>, <i>f</i> (<i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>) =<i>j</i>}      (7) </p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>d</mi><mo>, </mo><mn>1</mn><mn>3</mn><mn>5</mn><mo>°</mo><mo stretchy="false">) </mo><mo>=</mo><mo>#</mo><mo stretchy="false">{</mo><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mo>, </mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>∈</mo></mtd></mtr><mtr><mtd><mi>L</mi><mo>×</mo><mi>L</mi><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mo>-</mo><mi>d</mi><mo>, </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76"><i>y</i><sub>2</sub>-<i>y</i><sub>1</sub>=<i>d</i>, <i>f</i> (<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>) =<i>i</i>, <i>f</i> (<i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>) =<i>j</i>}      (8) </p>
                </div>
                <div class="p1">
                    <p id="77">在计算灰度共生矩阵时, 为了避免过多的灰度级带来的庞大的计算量, 首先将灰度级均匀量化为16级, 然后再进行相关计算。在得到的灰度共生矩阵的基础上, 通过以下6个参数来描述纹理:</p>
                </div>
                <div class="p1">
                    <p id="78"><mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>s</mi><mi>m</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mi>p</mi></mstyle></mrow></mstyle><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="80"><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mi>n</mi><mi>t</mi><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mi>p</mi></mstyle></mrow></mstyle><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mrow><mi>log</mi></mrow><mo stretchy="false">{</mo><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">}</mo></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="82"><mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>o</mi><mi>n</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi>i</mi><mo>-</mo><mi>j</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="84"><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mi>d</mi><mi>m</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mrow><mfrac><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow><mrow><mo stretchy="false">[</mo><mn>1</mn><mo>+</mo><mo stretchy="false"> (</mo><mi>i</mi><mo>-</mo><mi>j</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">]</mo></mrow></mfrac></mrow></mstyle></mrow></mstyle></mrow></math></mathml>      (12) </p>
                </div>
                <div class="p1">
                    <p id="86"><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>o</mi><mi>r</mi><mo>=</mo><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mi>i</mi></mstyle></mrow></mstyle><mo>×</mo><mi>j</mi><mo>×</mo><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mi>u</mi><msub><mrow></mrow><mi>x</mi></msub><mi>u</mi><msub><mrow></mrow><mi>y</mi></msub></mrow><mo>) </mo></mrow><mo>/</mo><mi>δ</mi><msub><mrow></mrow><mi>x</mi></msub><mi>δ</mi><msub><mrow></mrow><mi>y</mi></msub></mrow></math></mathml>      (13) </p>
                </div>
                <div class="p1">
                    <p id="88"><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi>i</mi><mo>-</mo><mi>u</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>×</mo><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (14) </p>
                </div>
                <div class="p1">
                    <p id="90">在式 (13) 、式 (14) 中:</p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msub><mrow></mrow><mi>x</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mi>i</mi></mstyle></mrow></mstyle><mo>×</mo><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mtext> </mtext><mi>u</mi><msub><mrow></mrow><mi>y</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>i</mi><mi>L</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>j</mi><mi>L</mi></munderover><mi>j</mi></mstyle></mrow></mstyle><mo>×</mo><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><msubsup><mrow></mrow><mi>x</mi><mn>2</mn></msubsup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi>i</mi><mo>-</mo><mi>u</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>×</mo><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><msubsup><mrow></mrow><mi>y</mi><mn>2</mn></msubsup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi>i</mi><mo>-</mo><mi>u</mi><msub><mrow></mrow><mi>y</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>×</mo><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">式 (9) -式 (14) 分别表示能量、熵、惯性矩、逆差距、相关指数、方差。通过这6个参数, 图像纹理的特性被有效地表达。统计0°、45°、90°、135°四个方向下的六个纹理参数, 这样就可以得到24个纹理特征值, 较传统的四参数灰度共生矩阵法, 可以提取到更丰富的纹理特征。此纹理特征比文献<citation id="210" type="reference">[<a class="sup">9</a>]</citation>的八方向的灰度共生矩阵纹理特征的计算复杂度更低, 也减少了因4对共线方向所产生的特征冗余。</p>
                </div>
                <div class="p1">
                    <p id="95">由于灰度共生矩阵是对尺度纹理特性的一种描述, 所以可以弥补双树复小波缺少对不同尺度纹理空间分布描述的缺陷。因此双树复小波融合灰度共生矩阵能够提取更为细致的纹理特征<b><i>T</i></b><sub><i>ti</i></sub>。</p>
                </div>
                <h3 id="96" name="96" class="anchor-tag"><b>3 二级分区下颜色融合纹理的检索算法</b></h3>
                <div class="p1">
                    <p id="97">由于刑侦图像的特殊性, 融合图像全局的颜色特征与纹理特征仅涉及图像全局信息, 对于图像区域的局部细节信息提取不足, 缺乏对图像目标与背景的区分。</p>
                </div>
                <div class="p1">
                    <p id="98">如图2所示, 从人眼直观感受的角度看, 该图的目标与背景颜色相近, 使得图像检索结果易受背景影响。同时, 由于匕首这类作案工具的形状特点, 使得该图像中目标相对背景而言, 所占像素的比例相对较小, 即, 图像中大部分区域是背景, 并不包含有效目标。此时, 常用的全局特征提取方式容易使目标区域的特征淹没在大量无效的背景区域的特征中, 从而造成检索结果的准确性降低。若对该图像进行区域划分, 可将其分为包含目标的局部区域与不包含目标的背景局部区域两类图像块。此时, 针对划分后的局部区域图像块, 分别提取其颜色特征与纹理特征, 这种特征将包含原图像的局部空间结构信息。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 示例图像及其分块" src="Detail/GetImg?filename=images/JYRJ201908033_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 示例图像及其分块  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="100">为获取更有效的刑侦图像特征描述, 本文算法先对图像进行区域划分, 再提取局部区域的颜色特征与纹理特征, 最后融合局部区域特征对图像进行刻画。</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101"><b>3.1 区域划分与局部区域特征提取</b></h4>
                <div class="p1">
                    <p id="102">为了将图像划分为目标区域与背景区域两类, 且尽可能降低算法的复杂度, 本文采用简单区域划分方式。假设图像的大小为<i>M</i>×<i>N</i>, 划分后子块的大小为<i>m</i>×<i>n</i>, 图像与子块的关系如下:</p>
                </div>
                <div class="p1">
                    <p id="103"><i>M</i>=2<i>m N</i>=2<i>n</i>      (15) </p>
                </div>
                <div class="p1">
                    <p id="104">由此得到<mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mi>Μ</mi><mi>m</mi></mfrac><mo>×</mo><mfrac><mi>Ν</mi><mi>n</mi></mfrac></mrow></math></mathml>个局部区域, 称之为一级分区。若对各个局部区域再以此方式划分, 称之为二级分区, 如图3所示。最终划分区域的个数<i>Ω</i>与区域划分级别<i>ξ</i>的关系如下:</p>
                </div>
                <div class="p1">
                    <p id="106"><i>Ω</i>=4<sup><i>ξ</i></sup>      (16) </p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 分区示例图" src="Detail/GetImg?filename=images/JYRJ201908033_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 分区示例图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="108">在刑侦图像中以这种方式划分区域, 若划分出对图像区分度贡献不大、没有实质性目标的空白区域图像块, 则把这些区域的特征值统一赋值为1或者0。</p>
                </div>
                <div class="p1">
                    <p id="109">按上述方式划分区域后, 按照图3中的图像块数字顺序分别依次提取各区域的颜色特征与纹理特征, 构成局部区域特征[<b><i>T</i></b><sub><i>ci</i></sub>, <b><i>T</i></b><sub><i>ti</i></sub>], 以串行的方式把各个局部区域特征融合, 融合后的图像特征向量为<b><i>T</i>=[<i>T</i></b><sub><i>c</i>1</sub>, <b><i>T</i></b><sub><i>t</i>1</sub>, <b><i>T</i></b><sub><i>c</i>2</sub>, <b><i>T</i></b><sub><i>t</i>2</sub>, …, <b><i>T</i></b><sub><i>ci</i></sub>, <b><i>T</i></b><sub><i>ti</i></sub>, …, <b><i>T</i></b><sub><i>cΩ</i></sub>, <b><i>T</i></b><sub><i>tΩ</i></sub>], 其中<i>Ω</i>代表图像块的个数。</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110"><b>3.2 基于KPCA的特征选择</b></h4>
                <div class="p1">
                    <p id="111">由于上述融合局部区域特征获得的图像特征向量存在维度过高和空间特征冗余的缺陷, 从而影响检索准确率并降低算法运行效率。因此, 有必要对融合后的特征向量进行特征选择, 在提高算法效率的同时改善检索精度。由于刑侦图像内容丰富, 特征之间一般存在非线性关系, 因此本文选择KPCA<citation id="211" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>进行特征选择。</p>
                </div>
                <div class="p1">
                    <p id="112">KPCA方法通过核函数把线性不可分的数据映射到高维空间中, 使用主成分分析法进行降维。给定样本数据<i>X</i><sub><i>t</i></sub>, <i>t</i>=1, 2, …, <i>N</i>, <i>N</i>为输入样本的个数, 定义<i>Φ</i>:<b><i>R</i></b><sup><i>M</i></sup>→<b><i>F</i></b>, <i>X</i><sub><i>t</i></sub>→<i>Φ</i> (<i>X</i><sub><i>t</i></sub>) , <b><i>R</i></b><sup><i>M</i></sup>为输入空间, <b><i>F</i></b>为映射空间。定义<b><i>m</i></b><sup><i>Φ</i></sup>, <b><i>e</i></b>为:</p>
                </div>
                <div class="p1">
                    <p id="113"><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mi>Φ</mi></msup><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi mathvariant="bold-italic">Φ</mi></mstyle><mo stretchy="false"> (</mo><mi>X</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>, <b><i>e</i></b>=[1, 1, …, 1]∈<b><i>R</i></b><sup>1×<i>N</i></sup></p>
                </div>
                <div class="p1">
                    <p id="115">其中<b><i>R</i></b><sup>1×<i>N</i></sup>为样本空间。</p>
                </div>
                <div class="p1">
                    <p id="116"><b><i>F</i></b>的协方差矩阵为:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Σ</mi><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">Φ</mi><mo stretchy="false"> (</mo><mi>X</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mi>Φ</mi></msup><mi mathvariant="bold-italic">e</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Φ</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mi>Φ</mi></msup><mi mathvariant="bold-italic">e</mi><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">其中<i>X</i>=[<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, …, <i>X</i><sub><i>N</i></sub>]。</p>
                </div>
                <div class="p1">
                    <p id="119">KPCA是求解特征值<i>λ</i><sub><i>K</i></sub><b><i>V</i></b><sub><i>K</i></sub>=∑<b><i>V</i></b><sub><i>K</i></sub>, 其中<i>λ</i><sub><i>K</i></sub>对应的特征向量为<b><i>V</i></b><sub><i>K</i></sub>。若<b><i>K</i></b>表示式 (17) 所示的核矩阵, 则由式 (18) 、式 (19) 可推导出式 (20) 、式 (21) 。</p>
                </div>
                <div class="p1">
                    <p id="120"><b><i>K</i>={<i>K</i></b> (<i>X</i><sub><i>t</i></sub>, <i>X</i><sub><i>j</i></sub>) }<sub><i>tj</i></sub>={<i>Φ</i> (<i>X</i><sub><i>t</i></sub>) , <i>Φ</i> (<i>X</i><sub><i>j</i></sub>) }<sub><i>tj</i></sub>      (17) </p>
                </div>
                <div class="p1">
                    <p id="121"><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Κ</mi></mstyle><mo>∼</mo></mover><mo>=</mo><mo stretchy="false">{</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Κ</mi></mstyle><mo>∼</mo></mover><mo stretchy="false"> (</mo><mi>X</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">}</mo><msub><mrow></mrow><mrow><mi>t</mi><mi>j</mi></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">Φ</mi><mo stretchy="false"> (</mo><mi>X</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mi>φ</mi></msup><mi mathvariant="bold-italic">e</mi><mo>, </mo><mi mathvariant="bold-italic">Φ</mi><mo stretchy="false"> (</mo><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mi>φ</mi></msup><mi mathvariant="bold-italic">e</mi><mo>, </mo><mo stretchy="false">}</mo><msub><mrow></mrow><mrow><mi>t</mi><mi>j</mi></mrow></msub></mrow></math></mathml>      (18) </p>
                </div>
                <div class="p1">
                    <p id="123"><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>Κ</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">Φ</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mi>φ</mi></msup><mi mathvariant="bold-italic">e</mi><mo stretchy="false">}</mo><mi mathvariant="bold-italic">α</mi><msub><mrow></mrow><mi>Κ</mi></msub><mfrac><mn>1</mn><mrow><msqrt><mrow><mi>λ</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></msqrt></mrow></mfrac></mrow></math></mathml>      (19) </p>
                </div>
                <div class="p1">
                    <p id="125"><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Κ</mi></mstyle><mo>∼</mo></mover><mo>=</mo><mrow><mo> (</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mi mathvariant="bold-italic">e</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">e</mi></mrow><mo>) </mo></mrow><mi mathvariant="bold-italic">Κ</mi><mrow><mo> (</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mi mathvariant="bold-italic">e</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">e</mi></mrow><mo>) </mo></mrow></mrow></math></mathml>      (20) </p>
                </div>
                <div class="p1">
                    <p id="127"><mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>λ</mi><msub><mrow></mrow><mi>Κ</mi></msub><mi mathvariant="bold-italic">α</mi><msub><mrow></mrow><mi>Κ</mi></msub><mo>=</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Κ</mi></mstyle><mo>∼</mo></mover><mi mathvariant="bold-italic">α</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></math></mathml>      (21) </p>
                </div>
                <div class="p1">
                    <p id="129">让<mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Φ</mi><mo>^</mo></mover><mo stretchy="false"> (</mo><mi>z</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">Φ</mi><mo stretchy="false"> (</mo><mi>z</mi><mo stretchy="false">) </mo><mo>-</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mi>φ</mi></msup><mo>, </mo><mi mathvariant="bold-italic">β</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></math></mathml>表示映射<i>Φ</i> (<i>z</i>) 中第<i>K</i>个分量的映射, 因此:</p>
                </div>
                <div class="p1">
                    <p id="131"><mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">β</mi><msub><mrow></mrow><mi>Κ</mi></msub><mo>=</mo><mover accent="true"><mi mathvariant="bold-italic">Φ</mi><mo>^</mo></mover><mo stretchy="false"> (</mo><mi>z</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>Κ</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mfrac><mrow><mi mathvariant="bold-italic">α</mi><msub><mrow></mrow><mrow><mi>Κ</mi><mi>t</mi></mrow></msub></mrow><mrow><msqrt><mrow><mi>λ</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></msqrt></mrow></mfrac></mrow></mstyle><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Κ</mi></mstyle><mo>∼</mo></mover><mo stretchy="false"> (</mo><mi>z</mi><mo>, </mo><mi>X</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (22) </p>
                </div>
                <div class="p1">
                    <p id="133">通过上述分析, 基于KPCA的特征选择步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="134"> (1) 提取图像库中所有图像的特征, 得到特征矩阵<i>Γ</i>, 图像的特征向量为<b><i>F</i></b><sub><i>l</i></sub>=[<i>f</i><sub>1</sub>, <i>f</i><sub>2</sub>, …, <i>f</i><sub><i>N</i></sub>], <i>f</i><sub><i>t</i></sub>∈<b><i>R</i></b><sup>2 016</sup>。其中, 向量维度= (颜色特征维度+纹理特征维度) ×区域个数。</p>
                </div>
                <div class="p1">
                    <p id="135"> (2) 针对特征矩阵<i>Γ</i>, 选择高斯核函数, 根据式 (17) 、式 (20) 得到核矩阵<b><i>K</i></b>和<mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Κ</mi></mstyle><mo>∼</mo></mover></mrow></math></mathml>, 然后由式 (21) 获得<i>λ</i><sub><i>K</i></sub>和<i>α</i><sub><i>K</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="137"> (3) 取<i>α</i><sub><i>K</i></sub>的前<i>p</i>个分量用于式 (22) 做投影, 即在KPCA空间降维后, 选择<i>β</i>=[<i>β</i><sub>1</sub>, <i>β</i><sub>2</sub>, …, <i>β</i><sub><i>p</i></sub>]作为用于相似性计算的特征向量。</p>
                </div>
                <h4 class="anchor-tag" id="138" name="138"><b>3.3 算法步骤</b></h4>
                <div class="p1">
                    <p id="139">本文提出二级分区下颜色融合纹理的刑侦图像检索算法, 具体算法步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="140"><b>步骤1</b> 区域划分。按照4.1节将图像进行二级区域划分, 划分后的区域个数为<i>K</i>。</p>
                </div>
                <div class="p1">
                    <p id="141"><b>步骤2</b> 特征提取。依次提取各局部区域的颜色自相关图特征<b><i>T</i></b><sub><i>ci</i></sub>和双树复小波融合6参数4方向的灰度共生矩阵的纹理特征<b><i>T</i></b><sub><i>ti</i></sub>, 并将<b><i>T</i></b><sub><i>ci</i></sub>和<b><i>T</i></b><sub><i>ti</i></sub>融合, 以此获得局部区域特征[<b><i>T</i></b><sub><i>ci</i></sub>, <b><i>T</i></b><sub><i>ti</i></sub>]。</p>
                </div>
                <div class="p1">
                    <p id="142"><b>步骤3</b> 区域融合。以串行的方式融合局部区域特征构成图像特征向量, 并进行特征归一化处理。归一化图像特征为:</p>
                </div>
                <div class="p1">
                    <p id="143" class="code-formula">
                        <mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Τ</mi><mo stretchy="true">¯</mo></mover><mo>=</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mi>c</mi><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mi>t</mi><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mi>c</mi><mn>2</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mi>t</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mi>c</mi><mi>i</mi></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mi>t</mi><mi>i</mi></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mi>c</mi><mi>Ω</mi></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mi>t</mi><mi>Ω</mi></mrow></msub><mo stretchy="false">]</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="144"><b>步骤4</b> 特征选择。采用KPCA技术对归一化图像特征<mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Τ</mi><mo stretchy="true">¯</mo></mover></mrow></math></mathml>进行特征选择, 得到降维后的特征向量<b><i>T</i></b>′用于相似性度量。</p>
                </div>
                <div class="p1">
                    <p id="146"><b>步骤5</b> 相似性度量。计算目标图像特征与刑侦图像库中的图像特征之间的欧式距离, 将计算结果作为相似度, 并按从小到大排序, 得出检索结果。</p>
                </div>
                <h3 id="147" name="147" class="anchor-tag"><b>4 实验结果及分析</b></h3>
                <div class="p1">
                    <p id="148">本文算法的仿真系统环境为Windows 10, CPU为Intel Core i5-3230M, 双核, 运存为8GB, 操作系统为64位, 编程软件为MATLAB R2016a。</p>
                </div>
                <div class="p1">
                    <p id="149">算法仿真实验图库来自实用现勘 (Crime Scene Investigation, CSI) 数据库。图库1是文献<citation id="212" type="reference">[<a class="sup">10</a>]</citation>所采用的300幅刑侦图像库, 共6类, 分别为轮胎、汽车、现场、鞋印、作案工具以及指纹, 每类50幅, 除现场外, 其他5类图像均目标单一。图库2<citation id="213" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>是具有代表性的CSI子库, 分为车辆、道路、建筑、门、指纹、鞋印、工具、血迹共8类, 每类50幅, 总共400幅, 均为多目标图像。</p>
                </div>
                <div class="p1">
                    <p id="150">本文使用的评价指标为精确度 (precision) 和召回率 (recall) , 计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="151"><mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>R</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mi>R</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>      (23) </p>
                </div>
                <div class="p1">
                    <p id="153"><mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>R</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mi>R</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>      (24) </p>
                </div>
                <div class="p1">
                    <p id="155">式中:<i>R</i><sub>1</sub>为检索返回的相似图像数目, <i>R</i><sub>2</sub>为检索返回的图像数目, <i>R</i><sub>3</sub>为图库中同类图像的数目。</p>
                </div>
                <div class="p1">
                    <p id="156">本文在图库1上对分区级别与相似性度量的选取进行测试实验, 每一次确定<i>R</i><sub>2</sub>值, 所有图像均参与检索。选取平均精确度和平均召回率作为算法评价指标。</p>
                </div>
                <div class="p1">
                    <p id="157">基于算法时效性的考虑, 实验中颜色自相关图中的距离个数、像素点间距<i>k</i>以及灰度共生矩阵中的<i>d</i>均取值1, 特征选择中<i>p</i>取值为275。</p>
                </div>
                <h4 class="anchor-tag" id="158" name="158"><b>4.1 不同分区级别对比</b></h4>
                <div class="p1">
                    <p id="159">由于不同分区级别会有不同的实验结果, 因此本文在图库1中通过分别对不同级别的分区处理进行测试实验, 由于考虑到分区越多, 算法复杂度增加, 时效性降低, 因此只比较前三级分区的实验结果, 如表1所示。</p>
                </div>
                <div class="p1">
                    <p id="160">如表1中的平均精确度与召回率所示, 当返回图像为24幅时, 有88.61%的图像与检索图像相似, 检索结果最优。由于分区过少时, 过大的图像块对局部区域信息表达较粗略, 没有实质性区分图像的目标与背景;而分区过多时, 过小的图像块又难以表达图像的局部区域信息。因此本文算法选取二级分区作为图像的区域划分方式。</p>
                </div>
                <div class="area_img" id="161">
                    <p class="img_tit"><b>表1 不同分区级别实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="161" border="1"><tr><td rowspan="2" colspan="2"><br />评价指标</td><td colspan="5"><br />ξ</td></tr><tr><td colspan="2"><br />一级</td><td colspan="2">二级</td><td>三级</td></tr><tr><td><br /><i>Precision</i></td><td colspan="2">84.81</td><td colspan="2">88.61</td><td colspan="2">83.52</td></tr><tr><td><br /><i>recall</i></td><td colspan="2">40.71</td><td colspan="2">42.53</td><td colspan="2">40.09</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="162" name="162"><b>4.2 相似性度量的选取</b></h4>
                <div class="p1">
                    <p id="163">在图像检索中, 检索结果易受相似性度量方式的影响。本文在图库1中通过大量的测试实验对欧式距离、街区距离、d<sub>1</sub>距离<citation id="214" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>以及切比雪夫距离共4种常用的相似性度量公式进行检索结果对比, 其中d<sub>1</sub>距离的计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="164"><mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Τ</mi><mo>, </mo><mi mathvariant="bold-italic">Q</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>Μ</mi><mo>′</mo></msup></munderover><mrow><mfrac><mrow><mrow><mo>|</mo><mrow><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>q</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow><mrow><mn>1</mn><mo>+</mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi>q</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac></mrow></mstyle></mrow></math></mathml>      (25) </p>
                </div>
                <div class="p1">
                    <p id="166">式中:<b><i>T</i></b>=[<i>t</i><sub>1</sub>, <i>t</i><sub>2</sub>, …, <i>t</i><sub><i>M</i></sub>]为图像库的任意图像的特征向量, <b><i>Q</i></b>=[<i>q</i><sub>1</sub>, <i>q</i><sub>2</sub>, …, <i>q</i><sub><i>M</i></sub>]为查询图像的特征向量, <i>M</i>为特征向量的维度。<i>R</i><sub>2</sub>取不同值时的实验结果如图4与图5所示。</p>
                </div>
                <div class="area_img" id="167">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_167.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 4种相似性度量方式平均precision曲线图" src="Detail/GetImg?filename=images/JYRJ201908033_167.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 4种相似性度量方式平均precision曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_167.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="168">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_168.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 4种相似性度量方式平均recall曲线图" src="Detail/GetImg?filename=images/JYRJ201908033_168.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 4种相似性度量方式平均recall曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_168.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="169">图4与图5表明, 采用欧式距离作为相似性度量进行检索, 其精确度和召回率均高于其他三种度量方式。文献<citation id="215" type="reference">[<a class="sup">8</a>]</citation>的实验结果表明街区距离在刑侦图像检索中表现较好, 原因在于提取的特征存在冗余与异常数据的情况, 同时街区距离对数据计算的鲁棒性较好。而本文算法由于在相似性度量前加入KPCA特征选择, 冗余与异常数据被去除, 所以在欧式距离相似性度量下本文算法表现最佳。因此本文算法选择欧式距离作为检索的相似性度量能保持较好的检索性能。</p>
                </div>
                <h4 class="anchor-tag" id="170" name="170"><b>4.3 特征选择前后比较</b></h4>
                <div class="p1">
                    <p id="171">为验证特征选择对于检索结果的影响, 本文在2个图库上进行特征选择前后的检索平均精确度与召回率对比, 结果如表2所示。</p>
                </div>
                <div class="area_img" id="172">
                    <p class="img_tit"><b>表2 特征选择前后实验结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="172" border="1"><tr><td rowspan="2"><br />图库</td><td colspan="2"><br />特征选择前</td><td colspan="2">本文算法</td></tr><tr><td>precision</td><td>recall</td><td>precision</td><td>recall</td></tr><tr><td>1</td><td>79.93</td><td>15.99</td><td>93.73</td><td>18.74</td></tr><tr><td><br />2</td><td>42.18</td><td>8.44</td><td>47.98</td><td>9.59</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="173">由表2可知, 在精确度与召回率上, 本文算法的检索结果优于特征选择前的检索结果。原因在于本文算法采用KPCA进行特征选择, 剔除冗余特征的同时降低图像特征的维度, 从而降低了计算复杂度, 同时改善算法的检索性能, 检索精确度与召回率均有所提升。</p>
                </div>
                <h4 class="anchor-tag" id="174" name="174"><b>4.4 检索结果与分析</b></h4>
                <div class="p1">
                    <p id="175">为直观地显示本文算法的检索优势, 由于图库1中的示例图像2的目标与背景颜色相近, 因此选取其作为检索目标图像。将相关的文献<citation id="216" type="reference">[<a class="sup">9</a>]</citation>、文献<citation id="217" type="reference">[<a class="sup">10</a>]</citation>、文献<citation id="218" type="reference">[<a class="sup">11</a>]</citation>、TCAC (Texture and Color Auto-correlogram) 以及本文算法做检索结果对比。其中的TCAC是本文所设计的颜色融合纹理的检索对比算法, 该算法采用多参数的灰度共生矩阵结合双树复小波提取图像的纹理特征, 再融合由颜色自相关图提取的图像的颜色特征, 从而获得图像的融合特征, 并以街区距离作为相似性度量方式实现检索。检索结果如图6-图10所示。返回图像数为10幅。篇幅有限, 图库2检索示例不再展示。</p>
                </div>
                <div class="area_img" id="176">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_176.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 文献[9]" src="Detail/GetImg?filename=images/JYRJ201908033_176.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 文献<citation id="219" type="reference">[<a class="sup">9</a>]</citation>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_176.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="177">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_177.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 文献[10]" src="Detail/GetImg?filename=images/JYRJ201908033_177.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 文献<citation id="220" type="reference">[<a class="sup">10</a>]</citation>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_177.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="178">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_178.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 文献[11]" src="Detail/GetImg?filename=images/JYRJ201908033_178.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 文献<citation id="221" type="reference">[<a class="sup">11</a>]</citation>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_178.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="179">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_179.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 TCAC" src="Detail/GetImg?filename=images/JYRJ201908033_179.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 TCAC  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_179.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="180">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_180.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 本文算法" src="Detail/GetImg?filename=images/JYRJ201908033_180.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 本文算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_180.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="181">从检索结果中的相似刀具图像可以看出, 本文算法由于采用二级分区处理, 将待检索图像划分为含有目标和不含有目标的两类图像块, 提取的图像特征在一定程度上包含对图像的背景与目标的区分, 而且具有空间结构信息, 因此检索出10幅相似图像, 优于其他4种算法的检索结果, 具有良好的检索效果。</p>
                </div>
                <div class="p1">
                    <p id="182">为客观评价本文算法的整体检索性能, 将文献<citation id="222" type="reference">[<a class="sup">9</a>]</citation>、文献<citation id="223" type="reference">[<a class="sup">10</a>]</citation>、文献<citation id="224" type="reference">[<a class="sup">11</a>]</citation>、TCAC以及本文算法在2个图库上的平均精确度与平均召回率实验结果进行比对, <i>R</i><sub>2</sub>取不同值时的实验结果曲线图如图11-图14所示。</p>
                </div>
                <div class="area_img" id="183">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 图库1不同算法平均precision曲线图" src="Detail/GetImg?filename=images/JYRJ201908033_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 图库1不同算法平均precision曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="184">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_184.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 图库1不同算法平均recall曲线图" src="Detail/GetImg?filename=images/JYRJ201908033_184.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 图库1不同算法平均recall曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_184.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="185">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_185.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图13 图库2不同算法平均precision曲线图" src="Detail/GetImg?filename=images/JYRJ201908033_185.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图13 图库2不同算法平均precision曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_185.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="186">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908033_186.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图14 图库2不同算法平均recall曲线图" src="Detail/GetImg?filename=images/JYRJ201908033_186.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图14 图库2不同算法平均recall曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908033_186.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="187">如图11-图14中平均精确度与召回率曲线图所示, 本文算法的曲线图均高于其他4种算法的曲线图, 表现出良好的检索效果。首先, 在图库1上, 当<i>R</i><sub>2</sub>=10时, 本文算法比文献<citation id="225" type="reference">[<a class="sup">9</a>]</citation>、文献<citation id="226" type="reference">[<a class="sup">10</a>]</citation>、文献<citation id="227" type="reference">[<a class="sup">11</a>]</citation>、TCAC这4种算法在平均精确度上平均高出11.38%, 说明本文提出的分区域特征提取融合能够有效地提升刑侦图像检索精确度;其次, 在图库2上, 当<i>R</i><sub>2</sub>=10时, 本文算法比文献<citation id="228" type="reference">[<a class="sup">9</a>]</citation>、文献<citation id="229" type="reference">[<a class="sup">10</a>]</citation>、文献<citation id="230" type="reference">[<a class="sup">11</a>]</citation>、TCAC这4种算法在平均精确度上平均高出5.37%, 说明本文算法对于多目标刑侦图像检索也具有较好的鲁棒性。由于文献<citation id="231" type="reference">[<a class="sup">9</a>]</citation>、文献<citation id="232" type="reference">[<a class="sup">10</a>]</citation>、文献<citation id="233" type="reference">[<a class="sup">11</a>]</citation>以及TCAC是图像的全局特征融合, 存在对图像局部特征信息提取不足的缺陷, 检索精确度较低。而本文算法在前期经过分区域处理后, 首先以图像的各个局部区域进行特征提取, 提取的图像特征包含图像的局部空间信息。其次, 融合局部区域特征来充分刻画图像, 获得图像的更加丰富的特征信息。因此对图像之间的区分度更高, 检索结果较好。为进一步体现本文算法在刑侦图像库的各个类别上的检索性能优势, 统计<i>R</i><sub>2</sub>=10时, 图库1在各类图像的平均精确度实验结果, 如表3所示。</p>
                </div>
                <div class="area_img" id="188">
                    <p class="img_tit"><b>表3 图库1各类图像平均精确度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="188" border="1"><tr><td>类别</td><td>文献[9]</td><td>文献[10]</td><td>文献[11]</td><td>TCAC</td><td>本文算法</td></tr><tr><td><br />轮胎</td><td>67.20</td><td>75.20</td><td>74.00</td><td>93.20</td><td>96.00</td></tr><tr><td><br />汽车</td><td>88.40</td><td>95.20</td><td>92.80</td><td>62.80</td><td>94.80</td></tr><tr><td><br />现场</td><td>60.40</td><td>76.40</td><td>71.00</td><td>85.60</td><td>93.60</td></tr><tr><td><br />鞋印</td><td>62.00</td><td>72.20</td><td>80.20</td><td>83.20</td><td>83.80</td></tr><tr><td><br />指纹</td><td>100.00</td><td>99.40</td><td>100.00</td><td>100.00</td><td>100.00</td></tr><tr><td><br />作案工具</td><td>70.80</td><td>86.80</td><td>97.20</td><td>88.20</td><td>94.20</td></tr><tr><td><br />平均</td><td>74.80</td><td>84.20</td><td>85.87</td><td>85.50</td><td>93.97</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="189">从表3可知, 3种文献算法以及TCAC的检索精确度不高, 而本文算法针对所有类的平均精确度为93.97%, 尤其是轮胎、汽车、现场、指纹、作案工具这5类图像的平均精确度均处于90%以上, 高于其他4种检索算法的检索结果。</p>
                </div>
                <h3 id="190" name="190" class="anchor-tag"><b>5 结 语</b></h3>
                <div class="p1">
                    <p id="191">针对现存的刑侦图像检索算法对图像局部区域特征信息提取不足的缺陷, 本文提出一种二级分区下颜色融合纹理的刑侦图像检索算法。通过本文算法与特征选择前的算法对比实验结果可知, 在局部区域特征融合后, KPCA特征选择可以降低算法的计算复杂度, 有效提高检索性能以及算法的鲁棒性;通过本文算法与4种算法的对比实验结果可知, 将图像分区域特征提取并进行区域融合, 与已有的刑侦图像检索算法相比, 在加入图像空间结构信息的同时, 充分利用了图像的局部区域特征, 可以有效地提高刑侦图像检索的准确性。</p>
                </div>
                <div class="p1">
                    <p id="192">但是本文算法在纹理特征的提取过程上仍然具有一定的复杂度, 未来将改进算法的纹理特征提取过程, 以进一步提高检索精确度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000017673&amp;v=MzE0NDVUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSUYwU2FCbz1OaWZJWTdLN0h0ak5yNDlGWk9vSUNuczZvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Datta R, Joshi D, Li J, et al.Image retrieval:Ideas, influences, and trends of the new age[J].Acm Computing Surveys, 2008, 40 (2) :1-60.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDE2B6E58E0195D30A1429E00CD3B9FA5&amp;v=MDgyNzdxQT1OaWZPZmNmTkhLUEsyb3BORWVzT0JYbE56QlppNnp0L1FRcmlyR0ZCZXNDZE04dWFDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4THU1dw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Liu P, Guo J M, Chamnongthai K, et al.Fusion of color histogram and LBP-based features for texture image retrieval and classification[J].Information Sciences, 2017, 390:95-111.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14021300017568&amp;v=MzEzNDRhQm89TmlmT2ZiSzhIdFBOckk5RlpPb0lDWG94b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSUYwUw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Jacob I J, Srinivasagan K G, Jayapriya K.Local oppugnant color texture pattern for image retrieval system[J].Pattern Recognition Letter, 2014, 42:72-78.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Apple disease classification using color,texture and shape features from images">

                                <b>[4]</b> Dubey S R, Jalal A S.Apple disease classification using color, texture and shape features from images[J].Signal Image &amp; Video Processing, 2016, 10 (5) :819-826.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8C0A3BB179E68D22F85ADDB639441AF6&amp;v=MTUwOTlQM2YxRVkrSjZDblJOelJSbDRqb01QQXVRcWhFOGZiYVZOTXlaQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeEx1NXdxQT1OaWZPZmJ2TEhxRA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Qin C, Sun M, Chang C C.Perceptual Hashing for Color Images Based on Hybrid Extraction of Structural Features[J].Signal Processing, 2017, 142:194-205.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14030300026936&amp;v=MTY1NjZxUVRNbndaZVp0RmlubFVyeklJRjBTYUJvPU5qN0Jhcks4SHRMTXJJOUZaT2tKQlg4L29CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Wang X Y, Zhang B B, Yang H Y.Content-based image retrieval by integrating color and texture features[J].Multimedia Tools &amp; Applications, 2014, 68 (3) :545-569.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAYD201503002&amp;v=MzIxNjJ6U2FyRzRIOVRNckk5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1WYjNBUFM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 刘颖, 范九伦, 李宗, 等.现勘图像数据库检索技术实例探讨[J].西安邮电大学学报, 2015, 20 (3) :11-20.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201803035&amp;v=MTIyNzZxQnRHRnJDVVI3cWZadVp0RnlqbVZiM0FJVGZUZTdHNEg5bk1ySTlHWVlRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 刘颖, 胡丹, 范九伦.现勘图像检索综述[J].电子学报, 2018, 46 (3) :761-768.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAYD201602011&amp;v=MDkwNzBmTXJZOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWptVmIzQVBTelNhckc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 兰蓉, 贾世英.基于纹理与颜色特征融合的刑侦图像检索算法[J].西安邮电大学学报, 2016, 21 (2) :57- 62.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201804036&amp;v=MDYzMDVMRzRIOW5NcTQ5R1lvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1WYjNBTmlmWVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 兰蓉, 郭思忱, 贾世英.基于纹理与形状特征融合的刑侦图像检索算法[J].计算机工程与设计, 2018, 39 (4) :1106-1110.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XAYD201406004&amp;v=MTU2OTR6cXFCdEdGckNVUjdxZlp1WnRGeWptVmIzQVBTelNhckc0SDlYTXFZOUZZSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 刘颖, 黄源, 高梓铭.刑侦图像检索中的特征提取及相似性度量[J].西安邮电大学学报, 2014, 19 (6) :11-16.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Kernel Principal Component Analysis">

                                <b>[12]</b> Schölkopf B, Smola A, Müller K R.Kernel principal component analysis[C]//Artificial Neural Networks-ICANN’97, Lecture Notes in Computer Science, 1997, 1327:583-588.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatial color indexing and applications">

                                <b>[13]</b> Huang J, Ravi Kumar S, Mitra M, et al.Spatial Color Indexing and Applications[C]//Proceedings of the Sixth International Conference on Computer Vision.IEEE Computer Society, 1998:602.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Texture analysis and classification with tree-structured wavelet transform">

                                <b>[14]</b> Chang T, Kuo C C J.Texture analysis and classification with tree-structured wavelet transform[J].IEEE Transactions on Image Processing, 1993, 2 (4) :429-441.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES22DD96EDC50AD93E815FD86EC4E8584A&amp;v=MTA0NjdHUWxmQnJMVTA1dHRoeEx1NXdxQT1OaWZPZmJHNmFxWEZxZm94Ris0UGZRZ3d6R01iNnpvTFBIZmsyV0V4RExxUlRiN3VDT052RlNpV1dyN0pJRnBtYUJ1SFlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Yu B, Jia B, Ding L, et al.Hybrid dual-tree complex wavelet transform and support vector machine for digital multi-focus image fusion[J].Neurocomputing, 2016, 182 (C) :1-9.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES52441A5C9E3F5DA49D834A50FECFDE7D&amp;v=MjYxMTUwNXR0aHhMdTV3cUE9TmlmT2ZiYTZHdFhOM29vMmJaNE1lbmxOdmhJYW5qZCtUQTduckdSQUNzVGdNTDNyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Jung C, Yang Q, Sun T, et al.Low Light Image Enhancement with Dual-Tree Complex Wavelet Transform[J].Journal of Visual Communication &amp; Image Representation, 2016, 42:28-36.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8A8695937C6E3550ECE18202EF1A56B0&amp;v=MTg2ODFidkpGdGZGcW9aR1k1Z0plWDg4eWhabW1VcDhRSDNpcm1kRGVNT1JROGlmQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeEx1NXdxQT1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> Pare S, Bhandari A K, Kumar A, et al.An optimal Color Image Multilevel Thresholding Technique using Grey-Level Co-occurrence Matrix[J].Expert Systems with Applications, 2017, 87:335-362.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300393553&amp;v=MTcyMTg5RlorSU1DWGs2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSUYwU2FCbz1OaWZPZmJLN0h0RE9ySQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Wu J, Wang J, Liu L.Feature extraction via KPCA for classification of gait patterns[J].Human Movement Science, 2007, 26 (3) :393-411.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015649701.nh&amp;v=MjE1ODl1WnRGeWptVmIzQVZGMjZHN1c4RjliTXJwRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> 黄源.基于区域语义模板的刑侦图像检索算法研究[D].西安:西安邮电大学, 2015.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Directional local extrema patterns a ne-w descriptor for content based image retrieval">

                                <b>[20]</b> Murala S, Maheshwari R P, Balasubramanian R.Directional local extrema patterns:a ne-w descriptor for content based image retrieval[J].International Journal of Multimedia Information Retrieval, 2012, 1 (3) :191-203.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201908033" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201908033&amp;v=MDkzMTZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWptVmIzQUx6VFpaTEc0SDlqTXA0OUc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
