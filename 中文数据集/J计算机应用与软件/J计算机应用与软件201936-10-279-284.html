<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135566379221250%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJYRJ201910049%26RESULT%3d1%26SIGN%3djEJz1XZ931NEXc9HPl4fA%252fzU4J4%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201910049&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201910049&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201910049&amp;v=MDYxMDFyQ1VSN3FmWnVadEZ5bmxVcjNPTHpUWlpMRzRIOWpOcjQ5QmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#35" data-title="&lt;b&gt;1 基础知识&lt;/b&gt; "><b>1 基础知识</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#36" data-title="&lt;b&gt;1.1 典型相关分析&lt;/b&gt;"><b>1.1 典型相关分析</b></a></li>
                                                <li><a href="#41" data-title="&lt;b&gt;1.2 惩罚项的提出&lt;/b&gt;"><b>1.2 惩罚项的提出</b></a></li>
                                                <li><a href="#51" data-title="&lt;b&gt;1.3 模型的提出&lt;/b&gt;"><b>1.3 模型的提出</b></a></li>
                                                <li><a href="#57" data-title="&lt;b&gt;1.4 模型的求解以及算法设计&lt;/b&gt;"><b>1.4 模型的求解以及算法设计</b></a></li>
                                                <li><a href="#90" data-title="&lt;b&gt;1.5 算法的收敛性分析&lt;/b&gt;"><b>1.5 算法的收敛性分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#116" data-title="&lt;b&gt;2 模型仿真&lt;/b&gt; "><b>2 模型仿真</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#117" data-title="&lt;b&gt;2.1 构造模拟数据&lt;/b&gt;"><b>2.1 构造模拟数据</b></a></li>
                                                <li><a href="#119" data-title="&lt;b&gt;2.2 参数选取&lt;/b&gt;"><b>2.2 参数选取</b></a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;2.3 评价标准&lt;/b&gt;"><b>2.3 评价标准</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;2.4 实验结果与分析&lt;/b&gt;"><b>2.4 实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#147" data-title="&lt;b&gt;3 结 语&lt;/b&gt; "><b>3 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#127" data-title="&lt;b&gt;表1 模拟数据集上的五折交叉验证结果&lt;/b&gt;"><b>表1 模拟数据集上的五折交叉验证结果</b></a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;续表1&lt;/b&gt;"><b>续表1</b></a></li>
                                                <li><a href="#131" data-title="图1 典型向量&lt;i&gt;&lt;b&gt;u&lt;/b&gt;&lt;/i&gt;的真实值">图1 典型向量<i><b>u</b></i>的真实值</a></li>
                                                <li><a href="#132" data-title="图2 l&lt;sub&gt;2&lt;/sub&gt;惩罚下的典型向量&lt;i&gt;&lt;b&gt;u&lt;/b&gt;&lt;/i&gt;">图2 l<sub>2</sub>惩罚下的典型向量<i><b>u</b></i></a></li>
                                                <li><a href="#133" data-title="图3 随机分组后l&lt;sub&gt;2,1&lt;/sub&gt;惩罚下的典型向量&lt;i&gt;&lt;b&gt;u&lt;/b&gt;&lt;/i&gt;">图3 随机分组后l<sub>2,1</sub>惩罚下的典型向量<i><b>u</b></i></a></li>
                                                <li><a href="#134" data-title="图4 随机分组l&lt;sub&gt;2,1&lt;/sub&gt;惩罚下&lt;i&gt;&lt;b&gt;u&lt;/b&gt;&lt;/i&gt;的位置还原图">图4 随机分组l<sub>2,1</sub>惩罚下<i><b>u</b></i>的位置还原图</a></li>
                                                <li><a href="#135" data-title="图5 随机分组后l&lt;sub&gt;1,2&lt;/sub&gt;惩罚下的典型向量&lt;i&gt;&lt;b&gt;u&lt;/b&gt;&lt;/i&gt;">图5 随机分组后l<sub>1,2</sub>惩罚下的典型向量<i><b>u</b></i></a></li>
                                                <li><a href="#136" data-title="图6 随机分组l&lt;sub&gt;1,2&lt;/sub&gt;惩罚下&lt;i&gt;&lt;b&gt;u&lt;/b&gt;&lt;/i&gt;的位置还原图">图6 随机分组l<sub>1,2</sub>惩罚下<i><b>u</b></i>的位置还原图</a></li>
                                                <li><a href="#137" data-title="图7 典型向量&lt;i&gt;&lt;b&gt;v&lt;/b&gt;&lt;/i&gt;的真实值">图7 典型向量<i><b>v</b></i>的真实值</a></li>
                                                <li><a href="#138" data-title="图8 l&lt;sub&gt;2&lt;/sub&gt;惩罚下的典型向量&lt;i&gt;&lt;b&gt;v&lt;/b&gt;&lt;/i&gt;">图8 l<sub>2</sub>惩罚下的典型向量<i><b>v</b></i></a></li>
                                                <li><a href="#139" data-title="图9 随机分组后l&lt;sub&gt;2,1&lt;/sub&gt;惩罚下的典型向量&lt;i&gt;&lt;b&gt;v&lt;/b&gt;&lt;/i&gt;">图9 随机分组后l<sub>2,1</sub>惩罚下的典型向量<i><b>v</b></i></a></li>
                                                <li><a href="#140" data-title="图10 随机分组后l&lt;sub&gt;2,1&lt;/sub&gt;惩罚下&lt;i&gt;&lt;b&gt;v&lt;/b&gt;&lt;/i&gt;的位置还原图">图10 随机分组后l<sub>2,1</sub>惩罚下<i><b>v</b></i>的位置还原图</a></li>
                                                <li><a href="#141" data-title="图11 随机分组后l&lt;sub&gt;1,2&lt;/sub&gt;惩罚下的典型向量&lt;i&gt;&lt;b&gt;v&lt;/b&gt;&lt;/i&gt;">图11 随机分组后l<sub>1,2</sub>惩罚下的典型向量<i><b>v</b></i></a></li>
                                                <li><a href="#142" data-title="图12 随机分组后l&lt;sub&gt;1,2&lt;/sub&gt;惩罚下&lt;i&gt;&lt;b&gt;v&lt;/b&gt;&lt;/i&gt;的位置还原图">图12 随机分组后l<sub>1,2</sub>惩罚下<i><b>v</b></i>的位置还原图</a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;表2 三种方法估计的典型向量的AUC&lt;/b&gt;"><b>表2 三种方法估计的典型向量的AUC</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Espezua S,Villanueva E,Maciel C D,et al.A Projection Pursuit Framework for Supervised Dimension Reduction of High Dimensional Small Sample Datasets[J].Neurocomputing,2015,149:767-776." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700312640&amp;v=MDQ1NDBGaW5sVXJ6SUlWNFZhQnM9TmlmT2ZiSzhIOURNcUk5Rlorb05Dbmc1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Espezua S,Villanueva E,Maciel C D,et al.A Projection Pursuit Framework for Supervised Dimension Reduction of High Dimensional Small Sample Datasets[J].Neurocomputing,2015,149:767-776.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Zhu L,Miao L,Zhang D.Iterative Laplacian Score for Feature Selection[C]//Chinese Conference on Pattern Recognition.Springer,Berlin,Heidelberg,2012:80-87." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Iterative Laplacian Score for Feature Selection">
                                        <b>[2]</b>
                                         Zhu L,Miao L,Zhang D.Iterative Laplacian Score for Feature Selection[C]//Chinese Conference on Pattern Recognition.Springer,Berlin,Heidelberg,2012:80-87.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Villegas M,Paredes R.Dimensionality Reduction by Minimizing Nearest-Neighbor Classification Error[J].Pattern Recognition Letters,2011,32(4):633-639." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300413610&amp;v=MjY1NjNRVE1ud1plWnRGaW5sVXJ6SUlWNFZhQnM9TmlmT2ZiSzdIdERPckk5RllPb01DbjA1b0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Villegas M,Paredes R.Dimensionality Reduction by Minimizing Nearest-Neighbor Classification Error[J].Pattern Recognition Letters,2011,32(4):633-639.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Guyon I,Elisseeff A.An Introduction to Variable and Feature Selection[J].Journal of Machine Learning Research,2003,3(6):1157-1182." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An introduction to variable and feature selection">
                                        <b>[4]</b>
                                         Guyon I,Elisseeff A.An Introduction to Variable and Feature Selection[J].Journal of Machine Learning Research,2003,3(6):1157-1182.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Hotelling H.Relations between Two Sets of Variates[J].Biometrika,1936,28(3/4):321-377." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Relations between two sets of variates">
                                        <b>[5]</b>
                                         Hotelling H.Relations between Two Sets of Variates[J].Biometrika,1936,28(3/4):321-377.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Du L,Zhang T,Liu K,et al.Sparse Canonical Correlation Analysis Via Truncated l&lt;sub&gt;1&lt;/sub&gt;-norm with Application to Brain Imaging Genetics[C]//IEEE International Conference on Bioinformatics &amp;amp; Biomedicine.2017:707-711." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparse Canonical Correlation Analysis Via Truncated l1-norm with Application to Brain Imaging Genetics">
                                        <b>[6]</b>
                                         Du L,Zhang T,Liu K,et al.Sparse Canonical Correlation Analysis Via Truncated l&lt;sub&gt;1&lt;/sub&gt;-norm with Application to Brain Imaging Genetics[C]//IEEE International Conference on Bioinformatics &amp;amp; Biomedicine.2017:707-711.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Li Y,Zhu J.L1-norm Quantile Regression[J].Journal of Computational and Graphical Statistics,2008,17(1):163-185." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800004455&amp;v=MjQxMDRRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSVY0VmFCcz1Oam5CYXJLN0h0Zk9wNDlGWk9zTENIazhvQk1UNlQ0UA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Li Y,Zhu J.L1-norm Quantile Regression[J].Journal of Computational and Graphical Statistics,2008,17(1):163-185.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Hardoon D R,Shawe-Taylor J.Sparse Canonical Correlation Analysis[J].Machine Learning,2011,83(3):331-353." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13102400001703&amp;v=MDE2NjNQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlWNFZhQnM9Tmo3QmFySzdIOUhPcTQ5RlpPc09DM3c2b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Hardoon D R,Shawe-Taylor J.Sparse Canonical Correlation Analysis[J].Machine Learning,2011,83(3):331-353.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Zhang Z,Zhao M,Chow T W S.Binary and Multi-Class Group Sparse Canonical Correlation Analysis for Feature Extraction and Classification[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering,2013,25(10):2192-2205." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Binary-and multi-class group sparse canonical correlation analysis for feature extraction and classification">
                                        <b>[9]</b>
                                         Zhang Z,Zhao M,Chow T W S.Binary and Multi-Class Group Sparse Canonical Correlation Analysis for Feature Extraction and Classification[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering,2013,25(10):2192-2205.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Kong D,Fujimaki R,Liu J,et al.Exclusive Feature Learning on Arbitrary Structures Via l&lt;sub&gt;1,2&lt;/sub&gt;-norm[C]//Advances in Neural Information Processing Systems.2014:1655-1663." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exclusive feature learning on arbitrary structures via l1,2-norm">
                                        <b>[10]</b>
                                         Kong D,Fujimaki R,Liu J,et al.Exclusive Feature Learning on Arbitrary Structures Via l&lt;sub&gt;1,2&lt;/sub&gt;-norm[C]//Advances in Neural Information Processing Systems.2014:1655-1663.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Huang Y,Liu J.Exclusive Sparsity Norm Minimization with Random Groups Via Cone Projection[J].IEEE Transactions on Neural Networks and Learning Systems,2018(99):1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exclusive Sparsity Norm Minimization with Random Groups Via Cone Projection">
                                        <b>[11]</b>
                                         Huang Y,Liu J.Exclusive Sparsity Norm Minimization with Random Groups Via Cone Projection[J].IEEE Transactions on Neural Networks and Learning Systems,2018(99):1-9.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Tibshirani R.Regression Shrinkage and Selection Via the Lasso[J].Journal of the Royal Statistical Society,1996,58(1):267-288." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14120603924782&amp;v=MTk0NzlQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlWNFZhQnM9TmlmWWVySzhIOVBNcVk5R2Jla0xDM1E3b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Tibshirani R.Regression Shrinkage and Selection Via the Lasso[J].Journal of the Royal Statistical Society,1996,58(1):267-288.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Du L,Huang H,Yan J,et al.Structured Sparse Canonical Correlation Analysis for Brain Imaging Genetics:An Improved Graphnet Method[J].Bioinformatics,2016,32(10):1544." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Structured sparse canonical correlation analysis for brain imaging genetics:an improved GraphNet method">
                                        <b>[13]</b>
                                         Du L,Huang H,Yan J,et al.Structured Sparse Canonical Correlation Analysis for Brain Imaging Genetics:An Improved Graphnet Method[J].Bioinformatics,2016,32(10):1544.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Xi C,Han L.An Efficient Optimization Algorithm for Structured Sparse CCA,with Applications to eQTL Mapping[J].Statistics in Biosciences,2012,4(1):3-26." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Efficient Optimization Algorithm for Structured Sparse CCA,with Applications to eQTL Mapping">
                                        <b>[14]</b>
                                         Xi C,Han L.An Efficient Optimization Algorithm for Structured Sparse CCA,with Applications to eQTL Mapping[J].Statistics in Biosciences,2012,4(1):3-26.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(10),279-284 DOI:10.3969/j.issn.1000-386x.2019.10.048            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于l</b><sub><b>1,2</b></sub><b>惩罚典型相关分析的特征选择</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E8%BF%8E%E5%88%A9&amp;code=42911576&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵迎利</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%87%AF%E6%98%8E&amp;code=06453202&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王凯明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%82%96%E7%8E%89%E6%9F%B1&amp;code=27508691&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">肖玉柱</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AE%8B%E5%AD%A6%E5%8A%9B&amp;code=23593269&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">宋学力</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E5%AE%89%E5%A4%A7%E5%AD%A6%E7%90%86%E5%AD%A6%E9%99%A2&amp;code=0054413&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长安大学理学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>特征选择是多模态高维数据机器学习的一个热点问题,而过拟合和过稀疏是特征选择需要克服的关键问题。对此提出以l<sub>1,2</sub>范数作为惩罚项兼顾稀疏作用和光滑作用,以组内稀疏来防止过拟合,以组间光滑来防止过稀疏,通过优化数据间的相关性来实现特征选择。然而对一般数据而言,群组信息又很难获得,所以对于群组信息缺失的数据,应用随机分组获得群组信息,最终实现兼顾组间光滑和组内稀疏优点的特征选择。模拟实验结果表明,该方法能较完整地选择出两模态数据间的关联特征,并且去除不相关特征。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征选择;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%B8%E5%9E%8B%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">典型相关分析;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=l%26lt%3Bsub%26gt%3B1%2C2%26lt%3B%2Fsub%26gt%3B%E8%8C%83%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">l&lt;sub&gt;1,2&lt;/sub&gt;范数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%8F%E6%9C%BA%E5%88%86%E7%BB%84&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">随机分组;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    赵迎利，硕士生，主研领域:机器学习。;
                                </span>
                                <span>
                                    王凯明，副教授。;
                                </span>
                                <span>
                                    肖玉柱，副教授。;
                                </span>
                                <span>
                                    宋学力，教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-31</p>

                    <p>

                            <b>基金：</b>
                                                        <span>长安大学中央高校基本科研业务费专项资金项目(310812163504);</span>
                    </p>
            </div>
                    <h1><b>FEATURE SELECTION BASED ON l</b><sub><b>1,2</b></sub><b>PENALIZED CANONICAL CORRELATION ANALYSIS</b></h1>
                    <h2>
                    <span>Zhao Yingli</span>
                    <span>Wang Kaiming</span>
                    <span>Xiao Yuzhu</span>
                    <span>Song Xueli</span>
            </h2>
                    <h2>
                    <span>School of Science, Chang&apos;an University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In machine learning of multi-modal and high-dimensional data, feature selection is a hot research issue, and over-fitting and over-sparseness are the key problem needed to be solved. Focusing on this problem, we proposed l<sub>1,2</sub> norm as penalty term to take into account both sparsity and smoothness, to prevent over-fitting by intra-group sparsity, to prevent over-sparsity by inter-group smothness, and to achieve feature selection by optimizing the correlation between data. However, for general data, the group information is difficult to obtain, so for the data without given group information, the random-grouping method was used to obtain it, and finally feature-selection was realized considering both inter-group smoothness and intra-group sparsity. The simulation results show that the proposed method can select features completely and remove the unrelated features as well.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Feature%20selection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Feature selection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Canonical%20correlation%20analysis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Canonical correlation analysis;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=l%26lt%3Bsub%26gt%3B1%2C2%26lt%3B%2Fsub%26gt%3B-norm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">l&lt;sub&gt;1,2&lt;/sub&gt;-norm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Random%20grouping&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Random grouping;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-31</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="31" name="31" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="32">从古至今,人们认识(学习)事物的渠道都是多样的。比如,对某疾病诊断,古代中医通过望、闻、问、切四种方式来了解患者;而现代的医生可以通过化验体液、B超、CT、核磁共振和脑电图等多种检查手段来采集患者的数据,以此了解患者的状况。以机器学习的观点,患者可以称为医生学习的一个样本,医生以不同方式采集到患者的数据称作样本的特征,不同的采集方式称为不同的模态。然而,高维特征的多模态数据中不可避免地会含有不相关和冗余的特征。事实上,在机器学习领域,这是一个普遍的现象。对于特定的学习任务,数据的真实维度<citation id="183" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>往往比采样数据的维度低得多<citation id="184" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。所以,需要对样本特征的所在空间降维,防止维数灾难<citation id="185" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>或者过拟合。降维的方法大致可分为特征提取和特征选择两类。按照某种学习准则或者统计准则,最大可能地保留相关的特征,去除不相关或者冗余特征,这就是特征选择<citation id="186" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>问题。</p>
                </div>
                <div class="p1">
                    <p id="33">特征选择的统计准则有很多,稀疏典型相关分析<citation id="192" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>(Sparse canonical correlation analysis,SCCA)是一种通过提取具有最大相关性的典型相关变量,并且通过稀疏典型向量来实现特征选择的方法。 l<sub>1</sub>范数是稀疏典型向量的一种常用的具有凸性和连续性的正则化方法<citation id="187" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>,文献<citation id="188" type="reference">[<a class="sup">8</a>]</citation>就是通过l<sub>1</sub>范数惩罚典型相关向量来实现特征选择。由于数据的群组信息是数据固有的系统机理信息或者满足某种统计信息的特征子集,所以在特征选择的任务里考虑特征的群组信息是必要而且重要的。为了在特征选择里兼顾数据的群组信息,文献<citation id="189" type="reference">[<a class="sup">9</a>]</citation>引入了l<sub>2,1</sub>范数惩罚的典型相关分析(CCA)模型,该惩罚对数据特征实现了组间稀疏。事实上,对于某些特定问题的数据,不仅不同的群组之间会有不相关或者冗余特征,而且组内往往也会存在不相关或者冗余特征,所以,特征的组内稀疏也是重要的甚至必要的。文献<citation id="190" type="reference">[<a class="sup">10</a>]</citation>发现了l<sub>1,2</sub>范数作为学习目标的正则约束可实现组内稀疏的作用。综上,无论l<sub>2,1</sub>还是l<sub>1,2</sub>约束,都需要数据的群组信息。当数据集中的群组信息未知或者不可用时,这种组间或者组内稀疏方法的应用会受到限制。文献<citation id="191" type="reference">[<a class="sup">11</a>]</citation>提出的特征随机分组方法,使得组信息缺失条件下的组内稀疏成为可能。所以,本文主要研究多模态高维数据的特征选择问题,应用l<sub>1,2</sub>范数兼顾群组信息作为稀疏惩罚项,通过优化数据之间的相关性来实现特征选择。</p>
                </div>
                <div class="p1">
                    <p id="34">本文的主要思想有:1) 考虑数据的组内稀疏问题,选择向量的l<sub>1,2</sub>范数惩罚CCA;2) 对于组信息缺失的数据,应用随机分组方法产生组信息;3) 从应用的角度,这种方法可以更完整地选取相关特征,所以适用于对特征查全要求较高的实际问题,如某些恶性传染病或者肿瘤疾病的特征选择问题。</p>
                </div>
                <h3 id="35" name="35" class="anchor-tag"><b>1 基础知识</b></h3>
                <h4 class="anchor-tag" id="36" name="36"><b>1.1 典型相关分析</b></h4>
                <div class="p1">
                    <p id="37">给定两个数据集<i><b>X</b></i>∈<b>R</b><sup><i>n</i></sup><sup>×</sup><sup><i>p</i></sup>、<i><b>Y</b></i>∈<b>R</b><sup><i>n</i></sup><sup>×</sup><sup><i>q</i></sup>,其中,<i><b>X</b></i>包含有<i>n</i>个样本、<i>p</i>个特征;<i><b>Y</b></i>包含有<i>n</i>个样本、<i>q</i>个特征。CCA<citation id="193" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>是以最大的相关性找到数据<i><b>X</b></i>和<i><b>Y</b></i>特征之间的典型相关变量,模型表示如下:</p>
                </div>
                <div class="p1">
                    <p id="38"><mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>u</mi><mo>,</mo><mi>v</mi></mrow></munder><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mi mathvariant="bold-italic">v</mi></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="39">s.t. <i><b>u</b></i><sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Xu</b></i>=1, <i><b>v</b></i><sup>T</sup><i><b>Y</b></i><sup>T</sup><i><b>Yv</b></i>=1</p>
                </div>
                <div class="p1">
                    <p id="40">式中: <i><b>u</b></i>和<i><b>v</b></i>分别表示<i><b>X</b></i>和<i><b>Y</b></i>对应的典型向量。</p>
                </div>
                <h4 class="anchor-tag" id="41" name="41"><b>1.2 惩罚项的提出</b></h4>
                <div class="p1">
                    <p id="42">向量<i><b>w</b></i>=[<i>w</i><sub>1</sub>,<i>w</i><sub>2</sub>,…,<i>w</i><sub><i>d</i></sub>]<sup>T</sup>∈<b>R</b><sup><i>d</i></sup>的<i>l</i><sub>1,2</sub>范数可表示为<citation id="194" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="43">‖<i><b>w</b></i>‖<sub>1,2</sub>=<mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>g</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><msup><mrow></mrow><mi>g</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="44">式中: 将<i><b>w</b></i>按分量分成<i>G</i>个组,<i><b>w</b></i><sup><i>g</i></sup>表示第<i>g</i>个组。</p>
                </div>
                <div class="p1">
                    <p id="45">基于此范数,构造本文优化目标所需的惩罚项<i>P</i><sub>1</sub>、<i>P</i><sub>2</sub>。</p>
                </div>
                <div class="p1">
                    <p id="46">假设数据<i><b>X</b></i>按特征分为<i>G</i>组,对其典型向量<i><b>u</b></i>=[<i>u</i><sub>1</sub>,<i>u</i><sub>2</sub>,…,<i>u</i><sub><i>p</i></sub>]<sup>T</sup>构造惩罚项<i>P</i><sub>1</sub>,表示为:</p>
                </div>
                <div class="p1">
                    <p id="47"><i>P</i><sub>1</sub>=‖<i><b>u</b></i>‖<sub><i>G</i></sub>=<mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>g</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mi>g</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>g</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mo stretchy="false">(</mo></mstyle><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>π</mi><msub><mrow></mrow><mi>g</mi></msub></mrow></munder><mo stretchy="false">|</mo></mstyle><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>      (3)</p>
                </div>
                <div class="p1">
                    <p id="48">式中:<i>π</i><sub><i>g</i></sub>是第<i>g</i>组的指标集。相应地,把数据集<i><b>Y</b></i>的特征分为<i>H</i>组,对应的<i><b>v</b></i>=[<i>v</i><sub>1</sub>,<i>v</i><sub>2</sub>,…,<i>v</i><sub><i>q</i></sub>]<sup>T</sup>构造惩罚项<i>P</i><sub>2</sub>,表示为:</p>
                </div>
                <div class="p1">
                    <p id="49"><i>P</i><sub>2</sub>=‖<i><b>v</b></i>‖<sub><i>H</i></sub>=<mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>h</mi><mo>=</mo><mn>1</mn></mrow><mi>Η</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msup><mrow></mrow><mi>h</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>h</mi><mo>=</mo><mn>1</mn></mrow><mi>Η</mi></munderover><mo stretchy="false">(</mo></mstyle><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>π</mi><msub><mrow></mrow><mi>h</mi></msub></mrow></munder><mo stretchy="false">|</mo></mstyle><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>      (4)</p>
                </div>
                <div class="p1">
                    <p id="50">式中: <i>π</i><sub><i>h</i></sub>是第<i>h</i>组的指标集。</p>
                </div>
                <h4 class="anchor-tag" id="51" name="51"><b>1.3 模型的提出</b></h4>
                <div class="p1">
                    <p id="52">本文针对数据组信息不全甚至缺失的特征选择问题,分别将数据<i><b>X</b></i><b>、</b><i><b>Y</b></i>按特征随机分成互不相交的<i>G</i>、<i>H</i>组并尽可能地让每组包含相同数目的特征,在典型相关分析的框架内引入惩罚项<i>P</i><sub>1</sub>、<i>P</i><sub>2</sub>,构造目标函数如下:</p>
                </div>
                <div class="p1">
                    <p id="53"><mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>u</mi><mo>,</mo><mi>v</mi></mrow></munder><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mi mathvariant="bold-italic">v</mi><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></math></mathml><mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>g</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mi>g</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>h</mi><mo>=</mo><mn>1</mn></mrow><mi>Η</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msup><mrow></mrow><mi>h</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>      (5)</p>
                </div>
                <div class="p1">
                    <p id="54">s.t. <i><b>u</b></i><sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Xu</b></i>=1,<i><b>v</b></i><sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Xv</b></i>=1</p>
                </div>
                <div class="p1">
                    <p id="55">式中: <i><b>u</b></i><sup><i>g</i></sup>和<i><b>v</b></i><sup><i>h</i></sup>分别表示根据特征被随机分组后对应的第<i>g</i>组和第<i>h</i>组。</p>
                </div>
                <div class="p1">
                    <p id="56">这样,我们通过正则项<i>P</i><sub>1</sub>、<i>P</i><sub>2</sub>惩罚<i><b>X</b></i>和<i><b>Y</b></i>的典型向量<i><b>u</b></i><b>、</b><i><b>v</b></i>,以及稀疏随机分组后的组内特征,实现携带组关联信息的特征选择。</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57"><b>1.4 模型的求解以及算法设计</b></h4>
                <div class="p1">
                    <p id="58">由于大多数应用<i>l</i><sub>1</sub>稀疏约束的正则优化问题都采用软阈值算法求解,而为了求解简便,都会假设特征之间正交,即<i><b>X</b></i><sup>T</sup><i><b>X</b></i>=<i><b>I</b></i><b>、</b><i><b>Y</b></i><sup>T</sup><i><b>Y</b></i>=<i><b>I</b></i><citation id="195" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。然而,在大多数真实数据中,这个假设是不合理的,因为特征之间往往不具有正交的特性。所以这个假设将会不可避免的限制识别有意义的关联信息。为了克服这个局限性,本文利用拉格朗日乘子法,采用交替最小二乘法解决这个优化问题。为了求解方便,将式(5)转化为如下等价形式:</p>
                </div>
                <div class="p1">
                    <p id="59"><mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">u</mi><mo>,</mo><mi mathvariant="bold-italic">v</mi></mrow></munder><mo>-</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mi mathvariant="bold-italic">v</mi><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></math></mathml><mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>g</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mi>g</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>h</mi><mo>=</mo><mn>1</mn></mrow><mi>Η</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msup><mrow></mrow><mi>h</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>      (6)</p>
                </div>
                <div class="p1">
                    <p id="60">s.t. <i><b>u</b></i><sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Xu</b></i>=1,<i><b>v</b></i><sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Xv</b></i>=1</p>
                </div>
                <div class="p1">
                    <p id="61">首先对式(6)构造拉格朗日方程:</p>
                </div>
                <div class="p1">
                    <p id="62"><i>L</i>(<i><b>u</b></i><b>,</b><i><b>v</b></i>,<i>λ</i>,<i>β</i>)=-<i><b>u</b></i><sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Yv</b></i>+<i>λ</i><sub>1</sub>‖<i><b>u</b></i>‖<sub><i>G</i></sub>+<i>λ</i><sub>2</sub>‖<i><b>v</b></i>‖<sub><i>H</i></sub>+<i>β</i><sub>1</sub>(‖<i><b>Xu</b></i>‖<mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>-1)+<i>β</i><sub>2</sub>(‖<i><b>Yv</b></i>‖<mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>-1)      (7)</p>
                </div>
                <div class="p1">
                    <p id="64">式中:<i>β</i><sub>1</sub>、<i>β</i><sub>2</sub>为拉格朗日乘子,可利用交叉验证估计。  考虑到本文使用的惩罚项<i>P</i><sub>1</sub>、<i>P</i><sub>2</sub>中含有<i>l</i><sub>1</sub>范数,如果|<i>u</i><sub><i>i</i></sub>|=0、|<i>v</i><sub><i>j</i></sub>|=0,则目标函数<i>L</i>在0点处不可微,可以通过分别给<i>u</i><sub><i>i</i></sub>、<i>v</i><sub><i>j</i></sub>加上一个很小的正数<i>ξ</i>来改善。</p>
                </div>
                <div class="p1">
                    <p id="65">然后对<i><b>u</b></i>和<i><b>v</b></i>分别求偏导,利用极值存在的必要条件得到:</p>
                </div>
                <div class="p1">
                    <p id="66"><mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">u</mi></mrow></mfrac><mo>=</mo><mo>-</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mi mathvariant="bold-italic">v</mi><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mstyle><mo>^</mo></mover><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>p</mi></msub><mo>+</mo><mi>β</mi><msub><mrow></mrow><mn>1</mn></msub><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">u</mi><mo>=</mo><mn>0</mn></mrow></math></mathml>      (8)</p>
                </div>
                <div class="p1">
                    <p id="67"><mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">v</mi></mrow></mfrac><mo>=</mo><mo>-</mo><mi mathvariant="bold-italic">Y</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">u</mi><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mstyle><mo>^</mo></mover><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>q</mi></msub><mo>+</mo><mi>β</mi><msub><mrow></mrow><mn>2</mn></msub><mi mathvariant="bold-italic">Y</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mi mathvariant="bold-italic">v</mi><mo>=</mo><mn>0</mn></mrow></math></mathml>      (9)</p>
                </div>
                <div class="p1">
                    <p id="68">即:</p>
                </div>
                <div class="p1">
                    <p id="69"><mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mstyle><mo>^</mo></mover><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>p</mi></msub><mo>+</mo><mi>β</mi><msub><mrow></mrow><mn>1</mn></msub><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">u</mi><mo>=</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mi mathvariant="bold-italic">v</mi></mrow></math></mathml>      (10)</p>
                </div>
                <div class="p1">
                    <p id="70"><mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mstyle><mo>^</mo></mover><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>q</mi></msub><mo>+</mo><mi>β</mi><msub><mrow></mrow><mn>2</mn></msub><mi mathvariant="bold-italic">Y</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mi mathvariant="bold-italic">v</mi><mo>=</mo><mi mathvariant="bold-italic">Y</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">u</mi></mrow></math></mathml>      (11)</p>
                </div>
                <div class="p1">
                    <p id="71">最后求解式(10)和式(11)得到:</p>
                </div>
                <div class="p1">
                    <p id="72"><mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">u</mi><mo>=</mo><mo stretchy="false">(</mo><mi>β</mi><msub><mrow></mrow><mn>1</mn></msub><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mi mathvariant="bold-italic">v</mi><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mstyle><mo>^</mo></mover><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>      (12)</p>
                </div>
                <div class="p1">
                    <p id="73"><mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">v</mi><mo>=</mo><mo stretchy="false">(</mo><mi>β</mi><msub><mrow></mrow><mn>2</mn></msub><mi mathvariant="bold-italic">Y</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Y</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">u</mi><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mstyle><mo>^</mo></mover><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>      (13)</p>
                </div>
                <div class="p1">
                    <p id="74">式(12)中:<mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mstyle><mo>^</mo></mover></mrow></math></mathml>表示块对角矩阵,其第<i>g</i>个对角块的对角线元素为<mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>g</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mi>G</mi></msub></mrow></mfrac><mo>,</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>p</mi></msub></mrow></math></mathml>表示元素全为1的<i>p</i>维列向量。式(13)中:<mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mstyle><mo>^</mo></mover></mrow></math></mathml>表示块对角矩阵,其第<i>h</i>个对角块的对角线元素为<mathml id="169"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mi>Η</mi></msub></mrow></mfrac><mo>,</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>q</mi></msub></mrow></math></mathml>元素全为1的<i>q</i>维列向量。</p>
                </div>
                <div class="p1">
                    <p id="75">模型算法的伪代码如算法1所示。</p>
                </div>
                <div class="p1">
                    <p id="76"><b>算法1</b> 模型算法</p>
                </div>
                <div class="p1">
                    <p id="77">Input: <i><b>X</b></i>=[<i>x</i><sub>1</sub>,<i>x</i><sub>2</sub>,…,<i>x</i><sub><i>n</i></sub>]<sup>T</sup>,<i><b>Y</b></i>=[<i>y</i><sub>1</sub>,<i>y</i><sub>2</sub>,…,<i>y</i><sub><i>n</i></sub>]<sup>T</sup></p>
                </div>
                <div class="p1">
                    <p id="78">Output: 典型变量<i><b>u</b></i>和<i><b>v</b></i></p>
                </div>
                <div class="p1">
                    <p id="79">1) 初始值<i>t</i>=0,<i>u</i><sup><i>t</i></sup>,<i>v</i><sup><i>t</i></sup>;</p>
                </div>
                <div class="p1">
                    <p id="80">2) While not converged do</p>
                </div>
                <div class="p1">
                    <p id="81">3) 计算<mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mstyle><mo>^</mo></mover><msub><mrow></mrow><mi>t</mi></msub></mrow></math></mathml>,对角线上的每一个元素<mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>g</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mi>G</mi></msub></mrow></mfrac><mo>;</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="82">4) 固定<i>v</i><sup><i>t</i></sup>,解<i>u</i><sup><i>t</i></sup><sup>+1</sup>;</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>5</mn><mo stretchy="false">)</mo><mspace width="0.25em" /><mi>u</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><mi>β</mi><msub><mrow></mrow><mn>1</mn></msub><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mstyle><mo>^</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">6) 计算<mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mstyle><mo>^</mo></mover><msub><mrow></mrow><mi>t</mi></msub></mrow></math></mathml>,对角线上的每一个元素<mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mrow><mi>h</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mi>Η</mi></msub></mrow></mfrac><mo>;</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="85">7) 固定<i>u</i><sup><i>t</i></sup><sup>+1</sup>,解 <i>v</i><sup><i>t</i></sup><sup>+1</sup>;</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>8</mn><mo stretchy="false">)</mo><mspace width="0.25em" /><mi>v</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><mi>β</mi><msub><mrow></mrow><mn>2</mn></msub><mi mathvariant="bold-italic">Y</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Y</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mstyle><mo>^</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>;</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">9) <i>t</i>=<i>t</i>+1;</p>
                </div>
                <div class="p1">
                    <p id="88">10) end while</p>
                </div>
                <div class="p1">
                    <p id="89">11) 返回<i><b>u</b></i>和<i><b>v</b></i>的值</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90"><b>1.5 算法的收敛性分析</b></h4>
                <div class="p1">
                    <p id="91">受文献<citation id="196" type="reference">[<a class="sup">13</a>]</citation>的启发,下面给出本文算法的收敛性分析。算法的目标的是求解式(6)的最小值,所以根据单调有界原理,算法的收敛性证明可转化为验证目标函数具有以下两个性质:1) 目标函数有下界;2) 目标函数单调递减。</p>
                </div>
                <div class="p1">
                    <p id="92">首先验证目标函数有下界。为方便起见,在式(7)中,记:</p>
                </div>
                <div class="p1">
                    <p id="93"><mathml id="174"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mo stretchy="false">(</mo><mi>λ</mi><mo>,</mo><mi>β</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">u</mi><mo>,</mo><mi mathvariant="bold-italic">v</mi></mrow></munder><mi>L</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><mo>,</mo><mi mathvariant="bold-italic">v</mi><mo>,</mo><mi>λ</mi><mo>,</mo><mi>β</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (14)</p>
                </div>
                <div class="p1">
                    <p id="94">下面证明式(14)中函数<i>N</i>(<i>λ</i>,<i>β</i>)有下界。</p>
                </div>
                <div class="p1">
                    <p id="95">根据式(6)和式(7)可知,显然<i>N</i>(<i>λ</i>,<i>β</i>)≤-<i><b>u</b></i><sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Yv</b></i>。</p>
                </div>
                <div class="p1">
                    <p id="96">分别对<i>N</i>中的<i>β</i><sub>1</sub>、<i>β</i><sub>2</sub>求偏导,有:</p>
                </div>
                <div class="p1">
                    <p id="97"><mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi>Μ</mi></mrow><mrow><mo>∂</mo><mi>β</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac><mo>=</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">u</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>-</mo><mn>1</mn><mo>=</mo><mn>0</mn></mrow></math></mathml>      (15)</p>
                </div>
                <div class="p1">
                    <p id="98"><mathml id="176"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi>Μ</mi></mrow><mrow><mo>∂</mo><mi>β</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>=</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Y</mi><mi mathvariant="bold-italic">v</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>-</mo><mn>1</mn><mo>=</mo><mn>0</mn></mrow></math></mathml>      (16)</p>
                </div>
                <div class="p1">
                    <p id="99">这表明: 1) 当<i><b>u</b></i><b>,</b><i><b>v</b></i>∈[-1,1]、-<i><b>u</b></i><sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Yv</b></i>∈[-1,1];2) max<i>N</i>(<i>λ</i>,<i>β</i>)=-<i><b>u</b></i><sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Yv</b></i>。</p>
                </div>
                <div class="p1">
                    <p id="100">令:</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ν</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mrow><mi>max</mi></mrow><mspace width="0.25em" /><mi>Ν</mi><mo stretchy="false">(</mo><mi>λ</mi><mo>,</mo><mi>β</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mi>max</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">u</mi><mo>,</mo><mi mathvariant="bold-italic">v</mi></mrow></munder><mi>L</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><mo>,</mo><mi mathvariant="bold-italic">v</mi><mo>,</mo><mi>λ</mi><mo>,</mo><mi>β</mi><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mo>-</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Y</mi><mi mathvariant="bold-italic">v</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">即<i>N</i><sup>*</sup>∈[-1,1],即证得目标函数有下界。</p>
                </div>
                <div class="p1">
                    <p id="103">然后验证目标函数单调递减。为了证明目标函数的单调递减性质,对向量<i><b>w</b></i>的<i>l</i><sub>1,2</sub>范数引入如下引理。</p>
                </div>
                <div class="p1">
                    <p id="104"><b>引理1</b><citation id="197" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup><sup><b>10</b></sup><sup>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="105"><mathml id="177"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>g</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><msup><mrow></mrow><mi>t</mi></msup><mo stretchy="false">)</mo><msup><mrow></mrow><mi>g</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>≤</mo><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>g</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><msup><mrow></mrow><mi>g</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>      (18)</p>
                </div>
                <div class="p1">
                    <p id="106">式中:<i><b>w</b></i><sup><i>t</i></sup>、<i><b>w</b></i>表示两个非零向量,<i><b>w</b></i><sup><i>t</i></sup>表示<i><b>w</b></i>更新后的值,<i><b>w</b></i><b>、</b><i><b>w</b></i><sup><i>t</i></sup>按分量分成<i>G</i>个组,<i><b>w</b></i><sup><i>g</i></sup>、(<i><b>w</b></i><sup><i>t</i></sup>)<sup><i>g</i></sup>表示第<i>g</i>个组中的部分分量。</p>
                </div>
                <div class="p1">
                    <p id="107">利用引理1,把目标函数单调递减证明分为两步。</p>
                </div>
                <div class="p1">
                    <p id="108">第一步,对于目标函数<i>L</i>(<i><b>u</b></i><b>,</b><i><b>v</b></i>,<i>λ</i>,<i>β</i>),固定<i><b>v</b></i>解<i><b>u</b></i>时,关于<i><b>u</b></i>的目标函数变为如下形式:</p>
                </div>
                <div class="p1">
                    <p id="109"><i>L</i>(<i><b>u</b></i><b>,</b><i><b>v</b></i>)=-<i><b>u</b></i><sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Yv</b></i>+<i>λ</i><sub>1</sub><mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>g</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mi>g</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo>+</mo><mi>β</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">u</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>      (19)</p>
                </div>
                <div class="p1">
                    <p id="110">由引理1并且从算法的第8)步可得:</p>
                </div>
                <div class="p1">
                    <p id="111">-(<i><b>u</b></i><sup><i>t</i></sup>)<sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Yv</b></i>+<i>λ</i><sub>1</sub><mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>g</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mi>t</mi></msup><mo stretchy="false">)</mo><msup><mrow></mrow><mi>g</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>+<i>β</i><sub>1</sub>‖<i><b>Xu</b></i><sup><i>t</i></sup>‖≤-<i><b>u</b></i><sup>T</sup><i><b>X</b></i><sup>T</sup><i><b>Yv</b></i>+<i>λ</i><sub>1</sub><mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>g</mi><mo>=</mo><mn>1</mn></mrow><mi>G</mi></munderover><mo stretchy="false">(</mo></mstyle><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mi>g</mi></msup><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>+<i>β</i><sub>1</sub>‖<i><b>Xu</b></i>‖      (20)</p>
                </div>
                <div class="p1">
                    <p id="113">这就证明了第一步,<i>L</i>(<i><b>u</b></i><sup><i>t</i></sup>,<i><b>v</b></i>)≤<i>L</i>(<i><b>u</b></i><b>,</b><i><b>v</b></i>)。</p>
                </div>
                <div class="p1">
                    <p id="114">第二步,类似地,对于目标函数<i>L</i>(<i><b>u</b></i><b>,</b><i><b>v</b></i>,<i>λ</i>,<i>β</i>),固定<i><b>u</b></i><sup><i>t</i></sup>解<i><b>v</b></i>时,同第一步证明,可得<i>L</i>(<i><b>u</b></i><sup><i>t</i></sup>,<i><b>v</b></i><sup><i>t</i></sup>)≤<i>L</i>(<i><b>u</b></i><sup><i>t</i></sup>,<i><b>v</b></i>)。</p>
                </div>
                <div class="p1">
                    <p id="115">综上,可以证明<i>L</i>(<i><b>u</b></i><sup><i>t</i></sup>,<i><b>v</b></i><sup><i>t</i></sup>)≤<i>L</i>(<i><b>u</b></i><b>,</b><i><b>v</b></i>),即算法在每次的迭代过程中,目标函数是单调递减的,所以由单调有界原理,模型的算法是收敛的。</p>
                </div>
                <h3 id="116" name="116" class="anchor-tag"><b>2 模型仿真</b></h3>
                <h4 class="anchor-tag" id="117" name="117"><b>2.1 构造模拟数据</b></h4>
                <div class="p1">
                    <p id="118">为了验证算法的有效性和正确性,本文构造了一组模拟数据对算法进行测试。给定<i><b>X</b></i><b>、</b><i><b>Y</b></i>的样本数为80,特征数分别为100、120,模拟实验的数据集生成方法如下<citation id="198" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>:1) 预先设定数据集<i><b>X</b></i><b>、</b><i><b>Y</b></i>的结构,分别产生<i><b>u</b></i>和<i><b>v</b></i>;2) 生成潜在变量<i>ξ</i>～<i>N</i>(0,<i><b>I</b></i><sub><i>n</i></sub><sub>×</sub><sub><i>n</i></sub>);3) 生成数据<i><b>X</b></i>,其样本满足<i>x</i><sub><i>i</i></sub>～<i>N</i>(<i>ξ</i><sub><i>i</i></sub><i><b>u</b></i>,<i>Σ</i><sub><i>x</i></sub>), (<i>Σ</i><sub><i>x</i></sub>)<sub><i>pl</i></sub>=exp<sup>-|</sup><sup><i>u</i></sup><sub><sup><i>p</i></sup></sub><sup>-</sup><sup><i>u</i></sup><sub><sup><i>l</i></sup></sub><sup>|</sup>,<i>u</i><sub><i>ρ</i></sub>、<i>u</i><sub><i>l</i></sub>分别为<i><b>u</b></i>的第<i>ρ</i>、<i>l</i>个坐标;4) 生成数据集<i><b>Y</b></i>,其样本满足<i>y</i><sub><i>i</i></sub>～<i>N</i>(<i>ξ</i><sub><i>i</i></sub><i>v</i>,<i>Σ</i><sub><i>y</i></sub>),其中(<i>Σ</i><sub><i>y</i></sub>)<sub><i>pl</i></sub>=exp<sup>-|</sup><sup><i>v</i></sup><sub><sup><i>p</i></sup></sub><sup>-</sup><sup><i>v</i></sup><sub><sup><i>l</i></sup></sub><sup>|</sup>,<i>v</i><sub><i>ρ</i></sub>、<i>v</i><sub><i>l</i></sub>分别为<i><b>v</b></i>的第<i>ρ</i>、<i>l</i>个坐标。将<i><b>X</b></i>中的特征随机分为10个不相交的组,将<i><b>Y</b></i>中的特征随机分为12个不相交的组。</p>
                </div>
                <h4 class="anchor-tag" id="119" name="119"><b>2.2 参数选取</b></h4>
                <div class="p1">
                    <p id="120">式(12)和式(13)中有四个可调参数,采用五折交叉验证,将所有的样本随机分成五份,其中四份作为训练集,剩余的一份样本作为测试集进行测试,从[10<sup>-2</sup>,10<sup>-1</sup>,10<sup>0</sup>,10<sup>1</sup>,10<sup>2</sup>]中产生最优的参数。</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121"><b>2.3 评价标准</b></h4>
                <div class="p1">
                    <p id="122">实验的评价标准为找到与真实相关系数最接近的一组,为了尽可能地减小因选择训练集与测试集的差异而对结果造成的影响,本文选择5次实验中训练集与测试集所得的相关系数之差最小的一组<i><b>u</b></i>和<i><b>v</b></i>作为最终的结果,具体形式为:</p>
                </div>
                <div class="p1">
                    <p id="123"><mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Δ</mtext><mrow><mi>c</mi><mi>o</mi><mi>r</mi><mi>r</mi></mrow><mo>=</mo><mfrac><mn>1</mn><mi>k</mi></mfrac></mrow></math></mathml><mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false">|</mo></mstyle><mi>c</mi><mi>o</mi><mi>r</mi><mi>r</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo>-</mo><mi>c</mi><mi>o</mi><mi>r</mi><mi>r</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msub><mo stretchy="false">|</mo></mrow></math></mathml>      (21)</p>
                </div>
                <div class="p1">
                    <p id="124">式中: <i>corr</i>表示Pearson相关系数,<i>k</i>表示交叉验证的次数(此处<i>k</i>=5),<i>corr</i><sub>train</sub>=<i>corr</i>(<i>X</i><sub>train</sub><i><b>u</b></i>,<i>Y</i><sub>train</sub><i><b>v</b></i>),<i>X</i><sub>train</sub>、<i>Y</i><sub>train</sub>表示训练集,<i>corr</i><sub>test</sub>=<i>corr</i>(<i>X</i><sub>test</sub><i><b>u</b></i>,<i>Y</i><sub>test</sub><i><b>v</b></i>),<i>X</i><sub>test</sub>、<i>Y</i><sub>test</sub>表示测试集,<i><b>u</b></i><b>、</b><i><b>v</b></i>分别表示由训练集得到的典型向量。</p>
                </div>
                <h4 class="anchor-tag" id="125" name="125"><b>2.4 实验结果与分析</b></h4>
                <div class="p1">
                    <p id="126">本文对同一组数据集采用五折交叉验证的方法将基于l<sub>2</sub>范数和基于l<sub>2,1</sub>范数的典型相关分析的特征选  择方法与本文的方法作对比,分别得到三种方法下的每一折的相关系数与其对应的平均值对比表,分别关于典型变量<i><b>u</b></i><b>、</b><i><b>v</b></i>的实验效果对比图和估计的典型变量的AUC对比表,如表1所示。</p>
                </div>
                <div class="area_img" id="127">
                    <p class="img_tit"><b>表1 模拟数据集上的五折交叉验证结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="127" border="1"><tr><td rowspan="2"><br />方法</td><td colspan="2"><br />训练结果</td><td colspan="2">测试结果</td></tr><tr><td>相关系数<br />(真值=<br />0.571 1)</td><td>绝对<br />误差<br />(均值)</td><td>相关系数<br />(真值=<br />0.571 1)</td><td>绝对<br />误差<br />(均值)</td></tr><tr><td>l<sub>2</sub>范数<br />惩罚的<br />CCA</td><td>0.527 9<br />0.504 8<br />0.426 0<br />0.563 4<br />0.574 5</td><td>0.519 3<br />(-0.051 8)</td><td>0.668 2<br />0.541 9<br />0.522 1<br />0.647 2<br />0.170 4</td><td>0.510 0<br />(-0.061 1)<br /></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="128">
                    <p class="img_tit"><b>续表1</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="128" border="1"><tr><td rowspan="2"><br />方法</td><td colspan="2"><br />训练结果</td><td colspan="2">测试结果</td></tr><tr><td>相关系数<br />(真值=<br />0.571 1)</td><td>绝对<br />误差<br />(均值)</td><td>相关系数<br />(真值=<br />0.571 1)</td><td>绝对<br />误差<br />(均值)</td></tr><tr><td>l<sub>2,1</sub>范数<br />惩罚的<br />CCA</td><td>0.597 3<br />0.636 8<br />0.655 8<br />0.506 8<br />0.567 7</td><td>0.592 9<br />(+0.021 8)</td><td>0.657 2<br />0.397 7<br />0.158 0<br />0.840 6<br />0.675 1</td><td>0.545 7<br />(-0.025 4)</td></tr><tr><td><br />l<sub>1,2</sub>范数<br />惩罚的<br />CCA</td><td>0.484 3<br />0.514 0<br />0.566 6<br />0.629 9<br />0.471 2</td><td>0.533 2<br />(-0.037 9)</td><td>0.749 2<br />0.668 1<br />0.527 8<br />0.209 1<br />0.599 5</td><td>0.550 8<br />(-0.020 3)</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="129">表1给出了三种方法下的五折交叉验证后训练集与测试集的相关系数的估计值。可以看出,在训练集上,基于l<sub>2,1</sub>范数特征选择的方法有较小的平均估计误差;但是在测试集上,基于l<sub>1,2</sub>范数特征选择的方法有较小的平均估计误差。一般而言,测试集上的结果比训练集上的结果更能体现模型的泛化性能<citation id="200" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="130">图1和图7给出了典型向量<i><b>u</b></i><b>、</b><i><b>v</b></i>设计的真实值(后均称为真实值)。图2和图8分别表示基于l<sub>2</sub>范数的特征选择方法得到的<i><b>u</b></i>和<i><b>v</b></i>。图3和图5分别表示基于l<sub>2,1</sub>范数和l<sub>1,2</sub>范数的特征选择方法应用随机分组得到的<i><b>u</b></i>。图9和图11分别表示基于l<sub>2,1</sub>范数和l<sub>1,2</sub>范数的特征选择方法应用随机分组得到的<i><b>v</b></i>。为了更清晰直观地展示实验效果,将图3、图5中的<i><b>u</b></i>和图9、图11中的<i><b>v</b></i>按照特征索引还原之后分别得到图4、图6和图10、图12。</p>
                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 典型向量u的真实值" src="Detail/GetImg?filename=images/JYRJ201910049_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 典型向量<i><b>u</b></i>的真实值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 l2惩罚下的典型向量u" src="Detail/GetImg?filename=images/JYRJ201910049_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 l<sub>2</sub>惩罚下的典型向量<i><b>u</b></i>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 随机分组后l2,1惩罚下的典型向量u" src="Detail/GetImg?filename=images/JYRJ201910049_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 随机分组后l<sub>2,1</sub>惩罚下的典型向量<i><b>u</b></i>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="134">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 随机分组l2,1惩罚下u的位置还原图" src="Detail/GetImg?filename=images/JYRJ201910049_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 随机分组l<sub>2,1</sub>惩罚下<i><b>u</b></i>的位置还原图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 随机分组后l1,2惩罚下的典型向量u" src="Detail/GetImg?filename=images/JYRJ201910049_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 随机分组后l<sub>1,2</sub>惩罚下的典型向量<i><b>u</b></i>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="136">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 随机分组l1,2惩罚下u的位置还原图" src="Detail/GetImg?filename=images/JYRJ201910049_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 随机分组l<sub>1,2</sub>惩罚下<i><b>u</b></i>的位置还原图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="137">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 典型向量v的真实值" src="Detail/GetImg?filename=images/JYRJ201910049_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 典型向量<i><b>v</b></i>的真实值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 l2惩罚下的典型向量v" src="Detail/GetImg?filename=images/JYRJ201910049_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 l<sub>2</sub>惩罚下的典型向量<i><b>v</b></i>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 随机分组后l2,1惩罚下的典型向量v" src="Detail/GetImg?filename=images/JYRJ201910049_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 随机分组后l<sub>2,1</sub>惩罚下的典型向量<i><b>v</b></i>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="140">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 随机分组后l2,1惩罚下v的位置还原图" src="Detail/GetImg?filename=images/JYRJ201910049_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 随机分组后l<sub>2,1</sub>惩罚下<i><b>v</b></i>的位置还原图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_140.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 随机分组后l1,2惩罚下的典型向量v" src="Detail/GetImg?filename=images/JYRJ201910049_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 随机分组后l<sub>1,2</sub>惩罚下的典型向量<i><b>v</b></i>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910049_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 随机分组后l1,2惩罚下v的位置还原图" src="Detail/GetImg?filename=images/JYRJ201910049_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 随机分组后l<sub>1,2</sub>惩罚下<i><b>v</b></i>的位置还原图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910049_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="143">从图2、图4与图1的对比中可以看出,基于l<sub>2</sub>范数和基于l<sub>2,1</sub>范数的特征选择的方法估计出的<i><b>u</b></i>的非零坐标位置与真实位置存在较大差异。具体的,在图1中可以看到20&lt;<i>i</i>&lt;40、80&lt;<i>i</i>&lt;90时<i>u</i><sub><i>i</i></sub>≠0,但是在图2、图4的对应位置出现了多处零值,0&lt;<i>i</i>&lt;20、40&lt;<i>i</i>&lt;80以及90&lt;<i>i</i>&lt;100时<i>u</i><sub><i>i</i></sub>=0,但是在图4的对应位置出现了多处非零值,对于典型向量<i><b>v</b></i>也有类似的实验结果。这说明基于l<sub>2</sub>范数和基于l<sub>2,1</sub>范数的特征选择方法存在对相关特征过度稀疏的现象。在图6与图1,图12与图7的对比中并不存在这些现象。这表明基于l<sub>1,2</sub>范数的特征选择方法能够全面识别出重要特征而且去掉不相关特征。</p>
                </div>
                <div class="p1">
                    <p id="144">表2给出了三种方法的典型变量的AUC(ROC曲线下方的面积),一般来说,AUC越大表明模型的预测性能越好。从表中可以看出基于l<sub>1,2</sub>范数特征选择的方法估计出的<i><b>u</b></i>和<i><b>v</b></i>的AUC明显大于基于l<sub>2</sub>范数和基于l<sub>2,1</sub>范数的特征选择方法估计出的<i><b>u</b></i>和<i><b>v</b></i>的AUC。</p>
                </div>
                <div class="area_img" id="145">
                    <p class="img_tit"><b>表2 三种方法估计的典型向量的AUC</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="145" border="1"><tr><td><br />方法</td><td>估计值<b><i>u</i></b></td><td>估计值<b><i>v</i></b></td></tr><tr><td><br />l<sub>2</sub>范数惩罚的CCA</td><td>0.677 2</td><td>0.722 3</td></tr><tr><td><br />l<sub>2,1</sub>范数惩罚的CCA</td><td>0.777 8</td><td>0.777 8</td></tr><tr><td><br />l<sub>1,2</sub>范数惩罚的CCA</td><td>1.00</td><td>1.00</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="146">实验结果表明,本文提出的基于l<sub>1,2</sub>范数典型相关分析的特征选择的方法不仅能够估计出两模态数据间精确的相关系数,而且在去掉不相关特征的同时能够准确识别出两模态数据中所有重要的特征。</p>
                </div>
                <h3 id="147" name="147" class="anchor-tag"><b>3 结 语</b></h3>
                <div class="p1">
                    <p id="148">本文提出了一种无先验组内稀疏典型相关的特征选择方法。通过将数据特征随机分成互不相交的组并尽可能地让每组包含相同数目的特征,以l<sub>1.2</sub>范数作为正则项惩罚CCA,对组内信息应用l<sub>1</sub>范数,组间信息应用l<sub>2</sub>范数,实现了关联特征的选择。模拟数据的实验表明,基于随机分组的组内稀疏特征选择模型选择的特征更加全面,漏选的特征更少,适用于某些恶性传染病或者肿瘤疾病的特征选择。</p>
                </div>
                <div class="p1">
                    <p id="149">本文的方法对于两模态数据取得较好的效果,现实生活中也存在三模态甚至更多模态的数据,所以需扩展本文的模型至三模态甚至更高模态的模型,实现特征选择将是下一步研究的重点。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700312640&amp;v=MjM1MzBmT2ZiSzhIOURNcUk5Rlorb05Dbmc1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSVY0VmFCcz1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Espezua S,Villanueva E,Maciel C D,et al.A Projection Pursuit Framework for Supervised Dimension Reduction of High Dimensional Small Sample Datasets[J].Neurocomputing,2015,149:767-776.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Iterative Laplacian Score for Feature Selection">

                                <b>[2]</b> Zhu L,Miao L,Zhang D.Iterative Laplacian Score for Feature Selection[C]//Chinese Conference on Pattern Recognition.Springer,Berlin,Heidelberg,2012:80-87.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300413610&amp;v=MzAwMzBxUVRNbndaZVp0RmlubFVyeklJVjRWYUJzPU5pZk9mYks3SHRET3JJOUZZT29NQ24wNW9CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Villegas M,Paredes R.Dimensionality Reduction by Minimizing Nearest-Neighbor Classification Error[J].Pattern Recognition Letters,2011,32(4):633-639.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An introduction to variable and feature selection">

                                <b>[4]</b> Guyon I,Elisseeff A.An Introduction to Variable and Feature Selection[J].Journal of Machine Learning Research,2003,3(6):1157-1182.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Relations between two sets of variates">

                                <b>[5]</b> Hotelling H.Relations between Two Sets of Variates[J].Biometrika,1936,28(3/4):321-377.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparse Canonical Correlation Analysis Via Truncated l1-norm with Application to Brain Imaging Genetics">

                                <b>[6]</b> Du L,Zhang T,Liu K,et al.Sparse Canonical Correlation Analysis Via Truncated l<sub>1</sub>-norm with Application to Brain Imaging Genetics[C]//IEEE International Conference on Bioinformatics &amp; Biomedicine.2017:707-711.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800004455&amp;v=MjAwODVCTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlWNFZhQnM9TmpuQmFySzdIdGZPcDQ5RlpPc0xDSGs4bw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Li Y,Zhu J.L1-norm Quantile Regression[J].Journal of Computational and Graphical Statistics,2008,17(1):163-185.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13102400001703&amp;v=MDQ5MjFCTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlWNFZhQnM9Tmo3QmFySzdIOUhPcTQ5RlpPc09DM3c2bw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Hardoon D R,Shawe-Taylor J.Sparse Canonical Correlation Analysis[J].Machine Learning,2011,83(3):331-353.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Binary-and multi-class group sparse canonical correlation analysis for feature extraction and classification">

                                <b>[9]</b> Zhang Z,Zhao M,Chow T W S.Binary and Multi-Class Group Sparse Canonical Correlation Analysis for Feature Extraction and Classification[J].IEEE Transactions on Knowledge &amp; Data Engineering,2013,25(10):2192-2205.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exclusive feature learning on arbitrary structures via l1,2-norm">

                                <b>[10]</b> Kong D,Fujimaki R,Liu J,et al.Exclusive Feature Learning on Arbitrary Structures Via l<sub>1,2</sub>-norm[C]//Advances in Neural Information Processing Systems.2014:1655-1663.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exclusive Sparsity Norm Minimization with Random Groups Via Cone Projection">

                                <b>[11]</b> Huang Y,Liu J.Exclusive Sparsity Norm Minimization with Random Groups Via Cone Projection[J].IEEE Transactions on Neural Networks and Learning Systems,2018(99):1-9.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14120603924782&amp;v=MjE0Mjc4SDlQTXFZOUdiZWtMQzNRN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlWNFZhQnM9TmlmWWVySw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Tibshirani R.Regression Shrinkage and Selection Via the Lasso[J].Journal of the Royal Statistical Society,1996,58(1):267-288.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Structured sparse canonical correlation analysis for brain imaging genetics:an improved GraphNet method">

                                <b>[13]</b> Du L,Huang H,Yan J,et al.Structured Sparse Canonical Correlation Analysis for Brain Imaging Genetics:An Improved Graphnet Method[J].Bioinformatics,2016,32(10):1544.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Efficient Optimization Algorithm for Structured Sparse CCA,with Applications to eQTL Mapping">

                                <b>[14]</b> Xi C,Han L.An Efficient Optimization Algorithm for Structured Sparse CCA,with Applications to eQTL Mapping[J].Statistics in Biosciences,2012,4(1):3-26.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201910049" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201910049&amp;v=MDYxMDFyQ1VSN3FmWnVadEZ5bmxVcjNPTHpUWlpMRzRIOWpOcjQ5QmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
