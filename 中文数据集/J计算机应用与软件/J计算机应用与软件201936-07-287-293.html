<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135628991877500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201907050%26RESULT%3d1%26SIGN%3daWkEos5MVEaHXmKfg37qLo5kPKE%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907050&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907050&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907050&amp;v=MjczNTBadEZ5amhWcnZBTHpUWlpMRzRIOWpNcUk5QVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#29" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#39" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#63" data-title="&lt;b&gt;2 基于FOBOS的ENLF模型&lt;/b&gt; "><b>2 基于FOBOS的ENLF模型</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#131" data-title="&lt;b&gt;3 BENLF模型&lt;/b&gt; "><b>3 BENLF模型</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#203" data-title="&lt;b&gt;4 实验结果及分析&lt;/b&gt; "><b>4 实验结果及分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#235" data-title="&lt;b&gt;5 结 语&lt;/b&gt; "><b>5 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#205" data-title="&lt;b&gt;表1 数据集描述&lt;/b&gt;"><b>表1 数据集描述</b></a></li>
                                                <li><a href="#218" data-title="图1 在D1上RMSE比较">图1 在D1上RMSE比较</a></li>
                                                <li><a href="#220" data-title="图2 在D2上RMSE比较">图2 在D2上RMSE比较</a></li>
                                                <li><a href="#220" data-title="图2 在D2上RMSE比较">图2 在D2上RMSE比较</a></li>
                                                <li><a href="#223" data-title="图3 D1的LFs值分布">图3 D1的LFs值分布</a></li>
                                                <li><a href="#226" data-title="图4 D2的LFs值分布">图4 D2的LFs值分布</a></li>
                                                <li><a href="#226" data-title="图4 D2的LFs值分布">图4 D2的LFs值分布</a></li>
                                                <li><a href="#228" data-title="图5 模型预测精度比较">图5 模型预测精度比较</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Luo X, Zhou M C, Xia Y, et al.Generating Highly Accurate Predictions for Missing QoS Data via Aggregating Nonnegative Latent Factor Models[J].IEEE Transactions on Neural Networks and Learning Systems, 2016, 27 (3) :524-537." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generating Highly Accurate Predictions for Missing QoS Data via Aggregating Nonnegative Latent Factor Models">
                                        <b>[1]</b>
                                         Luo X, Zhou M C, Xia Y, et al.Generating Highly Accurate Predictions for Missing QoS Data via Aggregating Nonnegative Latent Factor Models[J].IEEE Transactions on Neural Networks and Learning Systems, 2016, 27 (3) :524-537.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Tak&#225;cs G, Pil&#225;szy I, N&#233;meth B, et al.Scalable collaborative filtering approaches for large recommender systems[J].Journal of Machine Learning Research, 2009, 10:623-656." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scalable collaborative filtering approaches for large reeommender systems">
                                        <b>[2]</b>
                                         Tak&#225;cs G, Pil&#225;szy I, N&#233;meth B, et al.Scalable collaborative filtering approaches for large recommender systems[J].Journal of Machine Learning Research, 2009, 10:623-656.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Wang D, Chen Y, Guo J, et al.Elastic-net regularized latent factor analysis-based models for recommender systems[J].Neurocomputing, 2018, 329:66-74." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES5053F72384481DE6709B90EF392A9B9B&amp;v=MDExNTBQdENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHhMeTZ4S0E9TmlmT2ZiYTRHOUs2cUkxR2JPOExCSDFOdWhBVTZqWVBRWCtYMmhFOGU4T2RONw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Wang D, Chen Y, Guo J, et al.Elastic-net regularized latent factor analysis-based models for recommender systems[J].Neurocomputing, 2018, 329:66-74.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 陈婷, 朱青, 周梦溪, 等.社交网络环境下基于信任的推荐算法[J].软件学报, 2017, 28 (3) :721-731." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201703016&amp;v=MTY5NDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFZydkFOeWZUYkxHNEg5Yk1ySTlFWW9RS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         陈婷, 朱青, 周梦溪, 等.社交网络环境下基于信任的推荐算法[J].软件学报, 2017, 28 (3) :721-731.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 刘海洋, 王志海, 黄丹, 等.基于评分矩阵局部低秩假设的成列协同排名算法[J].软件学报, 2015, 26 (11) :2981-2993." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201511019&amp;v=MjE3MjRiTEc0SDlUTnJvOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVnJ2QU55ZlQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         刘海洋, 王志海, 黄丹, 等.基于评分矩阵局部低秩假设的成列协同排名算法[J].软件学报, 2015, 26 (11) :2981-2993.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Pan J J, Pan S J, Jie Y, et al.Tracking mobile users in wireless networks via semi-supervised co-localization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (3) :587-600." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tracking Mobile Users in Wireless Networks via Semi-Supervised Colocalization">
                                        <b>[6]</b>
                                         Pan J J, Pan S J, Jie Y, et al.Tracking mobile users in wireless networks via semi-supervised co-localization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (3) :587-600.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Zhang S, Wang W, Ford J, et al.Learning from incomplete ratings using non-negative matrix factorization[C]//Proceedings of the Sixth SIAM International Conference on Data Mining.DBLP, 2006:549-553." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning from incomplete ratings using non-negative matrix factorization">
                                        <b>[7]</b>
                                         Zhang S, Wang W, Ford J, et al.Learning from incomplete ratings using non-negative matrix factorization[C]//Proceedings of the Sixth SIAM International Conference on Data Mining.DBLP, 2006:549-553.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Cacheda F, V&#237;ctor Carneiro, Diego Fern&#225;ndez, et al.Comparison of collaborative filtering algorithms:Limitations of current techniques and proposals for scalable, high-performance recommender systems[J].Acm Transactions on the Web, 2011, 5 (1) :1-33." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000104471&amp;v=MTM5NjZNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSUZvUmJobz1OaWZJWTdLN0h0ak5yNDlGWmVzTENIczRvQg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Cacheda F, V&#237;ctor Carneiro, Diego Fern&#225;ndez, et al.Comparison of collaborative filtering algorithms:Limitations of current techniques and proposals for scalable, high-performance recommender systems[J].Acm Transactions on the Web, 2011, 5 (1) :1-33.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Luo X, Shang M, Li S.Efficient Extraction of Non-negative Latent Factors from High-Dimensional and Sparse Matrices in Industrial Applications[C]//2016 IEEE 16th International Conference on Data Mining (ICDM) .IEEE, 2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient Extraction of Non-negative Latent Factors from High-Dimensional and Sparse Matrices in Industrial Applications">
                                        <b>[9]</b>
                                         Luo X, Shang M, Li S.Efficient Extraction of Non-negative Latent Factors from High-Dimensional and Sparse Matrices in Industrial Applications[C]//2016 IEEE 16th International Conference on Data Mining (ICDM) .IEEE, 2017.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Tibshirani R J.Regression Shrinkage and Selection via the LASSO[J].Journal of the Royal Statistical Society.Series B:Methodological, 1996, 58 (1) :267-288." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14120603924782&amp;v=MDM0MzA0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRm9SYmhvPU5pZlllcks4SDlQTXFZOUdiZWtMQzNRN29CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Tibshirani R J.Regression Shrinkage and Selection via the LASSO[J].Journal of the Royal Statistical Society.Series B:Methodological, 1996, 58 (1) :267-288.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Zou H, Hastie T.Regularization and variable selection via the elastic net[J].Journal of the Royal Statistical Society, 2005, 67 (2) :301-320." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001256895&amp;v=MzExMDdjYXJPNEh0SE5yWXBEYk9JS1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1Rml2bFU3dk5KRlk9Tmlm&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Zou H, Hastie T.Regularization and variable selection via the elastic net[J].Journal of the Royal Statistical Society, 2005, 67 (2) :301-320.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Duchi J C, Singer Y.Efficient Learning using Forward-Backward Splitting[C]//Proceedings of the 22nd International Conference on Neural Information Processing Systems.Curran Associates Inc., 2009:495-503." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient learning using forward-backward splitting">
                                        <b>[12]</b>
                                         Duchi J C, Singer Y.Efficient Learning using Forward-Backward Splitting[C]//Proceedings of the 22nd International Conference on Neural Information Processing Systems.Curran Associates Inc., 2009:495-503.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Herlocker J L, Konstan J A, Terveen L G, et al.Evaluating collaborative filtering recommender systems[J].ACM Transactions on Information Systems, 2004, 22 (1) :5-53." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000099855&amp;v=MzAxOTE9TmlmSVk3SzdIdGpOcjQ5RlpPSUdCSGs4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSUZvUmJobw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Herlocker J L, Konstan J A, Terveen L G, et al.Evaluating collaborative filtering recommender systems[J].ACM Transactions on Information Systems, 2004, 22 (1) :5-53.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(07),287-293 DOI:10.3969/j.issn.1000-386x.2019.07.049            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于弹性网络正则化的隐因子预测模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B4%BA%E6%96%87%E7%81%8F&amp;code=42231783&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贺文灏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%BE%B7%E8%B4%A4&amp;code=33200514&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王德贤</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%93%E8%90%8D&amp;code=14922395&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邓萍</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E9%94%90&amp;code=41830074&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘锐</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8D%8E%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0048238&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西华师范大学计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8D%97%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0218487&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西南交通大学信息科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在大数据预测中, 通常采用SGD<sub>L</sub>F模型对高维稀疏矩阵中的缺失数据进行预测。由于SGD<sub>L</sub>F模型仅有L<sub>2</sub>正则化项对目标函数进行约束, 不能调整隐因子的分布, 这样导致模型不能很好地描述目标矩阵中实体特性, 损失了模型精度。用FOBOS算法构造一个同时用L<sub>1</sub>和L<sub>2</sub>限制目标函数的弹性网络ENLF模型, ENLF很好地调整隐因子的分布并提高了模型性能。为了进一步提高ENLF模型的性能, 在其中加入偏差, 构造BENLF模型。在大型商业数据集上的实验表明, ENLF和BENLF模型的预测精度和模型稀疏性等性能有显著提高。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E7%BB%B4%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高维稀疏矩阵;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%90%E5%9B%A0%E5%AD%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">隐因子;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%A7%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大数据;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    贺文灏, 本科生, 主研领域:智能物联网, 推荐系统。;
                                </span>
                                <span>
                                    王德贤, 硕士生。;
                                </span>
                                <span>
                                    邓萍, 博士生。;
                                </span>
                                <span>
                                    刘锐, 讲师。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金面上项目 (61871330);</span>
                                <span>国家大学生创新创业专项基金项目 (201510638047, 201810638020x);</span>
                                <span>四川省教育厅重点项目 (15ZA048, 13ZA0015);</span>
                                <span>四川省科技厅支撑项目 (2018GFW0151);</span>
                                <span>西华师范大学英才基金资助课题 (17YC150, 17YC149);</span>
                    </p>
            </div>
                    <h1><b>LATENT FACTOR PREDICTION MODEL BASED ON ELASTIC NETWORK REGULARIZATION</b></h1>
                    <h2>
                    <span>He Wenhao</span>
                    <span>Wang Dexian</span>
                    <span>Deng Ping</span>
                    <span>Liu Rui</span>
            </h2>
                    <h2>
                    <span>School of Computer Science, China West Normal University</span>
                    <span>College of Information Science and Technology, Southwest Jiaotong University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In big data prediction, the SGD<sub>L</sub>F model is a common method to predict missing data in high-dimensional sparse matrices. Since the SGD<sub>L</sub>F model only constrains the objective function by the L<sub>2</sub> regularization term, which cannot regulate the distribution of latent factor. Thus, the model fails to be so accurate to describe the entity features in the target matrix well. In order to solve this problem, this paper proposed a FOBOS algorithm to construct an elastic network ENLF model, using L<sub>1</sub> and L<sub>2</sub> to limit the objective function. ENLF regulated the distribution of latent factors and improved the performance of the model. To further improve the performance of the ENLF model, we integrated the bias into the ENLF and constructd the BENLF model. The experiments on large industrial datasets show that the prediction accuracy and model sparsity of the ENLF and BENLF models are significantly improved.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=High-dimensional%20sparse%20matrix&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">High-dimensional sparse matrix;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Latent%20factor&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Latent factor;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Big%20data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Big data;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-25</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="29" name="29" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="30">在信息数据爆炸式发展的大数据时代, 用户要在过载且关联度很低的信息中去选择和发现有用的知识, 这给用户带来很大的挑战。研究表明, 虽然过载的信息能更好地满足用户需求, 但也会降低用户的决策质量。</p>
                </div>
                <div class="p1">
                    <p id="31">互联网是当今最好的信息共享渠道, 但它也会造成信息过载。因此用户通常需要借助搜索引擎、推荐系统等工具来有效地过滤无关信息, 仅保留最能满足用户需求的数据。在用户短时间不能处理和筛选海量信息的领域中, 通常借助推荐系统来处理信息。推荐系统现在运用到各个领域中, 包括电子商务、科学研究、在线约会、智慧教育等相关领域。</p>
                </div>
                <div class="p1">
                    <p id="32">推荐系统高效的处理高维稀疏 (High Dimensional Sparse, HiDS) 矩阵, 并精准地预测稀疏矩阵中的缺失数据。基于协同过滤的推荐系统是推荐系统中的重要分支。在协同过滤推荐系统中LF (Latent Factor) 分解技术最受青睐。LF的工作原理是通过将目标矩阵中的实体映射到两个低维的隐特空间, 并通过目标矩阵中的已知数据建立一系列的目标函数。通过LF模型求解可以高效精准地预测模型中的缺失数据。因此, LF模型被大量的学者广泛应用于推荐系统中<citation id="239" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>, 其中代表性的模型有 SVD++模型<citation id="240" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>、概率矩阵分解模型<citation id="237" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>和非参数化贝叶斯LF模型<citation id="238" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>等。</p>
                </div>
                <div class="p1">
                    <p id="33">由于在HiDS矩阵中的已知数据分布是不平衡的, 导致目标函数的高度不平衡。因此, 仅用隐因子模型来进行HiDS矩阵中缺失数据的预测是不适定的, 无法得到全局最优解。为解决这个问题通常采用Tikhonov正则化的方式来保持它的一般性<citation id="241" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="34">通过集成Tikhonov正则化即为L<sub>2</sub>范数到目标函数可以高效地防止模型过拟, 增强模型的通用性, 但是并不能调整隐因子 (Latent Factors, LFs) 的分布。在之前的研究中<citation id="243" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>表明实体在线性和双线性模型中仅和特征空间的部分维度相关, 即实体仅属于本分的实体簇。从这一角度而言, 进一步调整实体间LFs的分布, 能更加精确地描述实体所倾向的实体簇, 增强模型的性能。在传统的线性和双线性问题中已经证明了L<sub>1</sub>正则化能很好地调整模型目标系统参数的分布<citation id="244" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>, 但由于L<sub>1</sub>正则化不可微的原因, 导致在LF模型通常仅加入L2正则化来对目标函数进行限制。基于此, 本文中通过向前次梯度向后截断 (Forward-looking sub-gradients and forward-backward splitting, FOBOS) 方法<citation id="242" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>来构造一个弹性网络隐因子 (Elastic Network Latent Factor, ENLF) 模型, 将L<sub>1</sub>和L<sub>2</sub>同时整合到目标函数中, 提高模型性能。本文主要贡献:</p>
                </div>
                <div class="p1">
                    <p id="35">① 基于FOBOS方法提出了一个ENLF模型。</p>
                </div>
                <div class="p1">
                    <p id="36">② 在ENLF模型中加入偏差提出BENLF (Biased ENLF) 模型, 增强模型性能。</p>
                </div>
                <div class="p1">
                    <p id="37">③ ENLF和BENLF模型的算法设计和分析。</p>
                </div>
                <div class="p1">
                    <p id="38">④ 在来自工业应用的2个数据集上验证模型的性能。</p>
                </div>
                <h3 id="39" name="39" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="40">定义:令<i>M</i>和 <i>N</i>表示两个实体集合, <b><i>R</i></b><sup>|<i>M</i>|×|<i>N</i>|</sup>为HiDS目标矩阵<b><i>R</i></b>。<i>r</i><sub><i>m</i>, <i>n</i></sub>用于描述矩阵<b><i>R</i></b>中对应的第<i>m</i>行和第<i>n</i>列实体间的关系。<i>Λ</i>和<i>Γ</i>分别表示<b><i>R</i></b>中实体间已知关系集合和实体间未知关系集合, 其中|<i>Λ</i>|&lt;&lt;|<i>Γ</i>|。通过映射对应实体到隐因子空间<b><i>U</i></b>和<b><i>V</i></b>中, 其中<mathml id="41"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">U</mi><mo>×</mo><mi mathvariant="bold-italic">V</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>=</mo><mover accent="true"><mi mathvariant="bold-italic">R</mi><mo>^</mo></mover><mo>, </mo><mover accent="true"><mi mathvariant="bold-italic">R</mi><mo>^</mo></mover></mrow></math></mathml>逼近于目标矩阵<b><i>R</i>。<i>U</i></b>和<b><i>V</i></b>分别为<i>f</i>×<b><i>U</i></b>和<i>f</i>×<b><i>V</i></b>的隐因子矩阵, <i>f</i>为隐因子空间的维度<i>f</i>&lt;&lt;min{|<i>M</i>|, |<i>N</i>|}。<b><i>U</i></b>和<b><i>V</i></b>分别表示为输出的隐因子。</p>
                </div>
                <div class="p1">
                    <p id="42">用LF模型来处理高维稀疏矩阵时, 本文仅聚焦于目标矩阵中的已知数据<i>Λ</i>。为了衡量目标矩阵<b><i>R</i></b>中的已知数据和隐因子空间中对应的实体的预测值之间的差异, 通常采用欧几里德距离公式<citation id="245" type="reference"><link href="3" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">3</a>]</sup></citation>来构造目标函数, 表示为:</p>
                </div>
                <div class="p1">
                    <p id="43" class="code-formula">
                        <mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi>U</mi><mo>, </mo><mi>V</mi></mrow></munder><mi>ε</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">U</mi><mo>, </mo><mi mathvariant="bold-italic">V</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>r</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>∈</mo><mi>Λ</mi></mrow></munder><mrow><mrow><mo> (</mo><mrow><mi>r</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>f</mi></munderover><mi>u</mi></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mi>v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow></msub></mrow><mo>) </mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="44">式中:<i>f</i>表示隐因子矩阵的维度。<i>u</i><sub><i>m</i>, <i>k</i></sub>和<i>v</i><sub><i>n</i>, <i>k</i></sub>分别是低秩隐因子矩阵<b><i>U</i></b>中第<i>m</i>行第<i>k</i>个值和矩阵<b><i>V</i></b>中的对应的第<i>n</i>列第<i>k</i>个值。</p>
                </div>
                <div class="p1">
                    <p id="45">在之前的研究中<citation id="246" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>已证明随机梯度下降 (Stochastic Gradient Descent, SGD) 算法在求解LF模型的高效性。因此应用SGD算法来求解目标函数时经常考虑在每个训练实例上的瞬时损失。瞬时损失目标函数为:</p>
                </div>
                <div class="p1">
                    <p id="46"><mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>=</mo><mrow><mo> (</mo><mrow><mi>r</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>f</mi></munderover><mi>u</mi></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mi>v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow></msub></mrow><mo>) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="48">式中:在{<i>u</i><sub><i>m</i>, <i>k</i></sub>, <i>v</i><sub><i>n</i>, <i>k</i></sub>|<i>k</i>=1～<i>f</i>}中每一个决策参数都要执行SGD算法来最小化瞬时损失<i>ε</i><sub><i>m</i>, <i>n</i></sub>, 这个求解<i>ε</i><sub><i>m</i>, <i>n</i></sub>的过程对应于<i>Λ</i>中的实体迭代来实现<i>ε</i> (<b><i>U</i>, <i>V</i></b>) 的局部最优解。式 (2) 是不适定的, 它会导致模型过拟合。为了解决这样的问题, 通常通过加入正则化项来解决, 具体表示为:</p>
                </div>
                <div class="p1">
                    <p id="49"><i>Ψ</i><sub><i>m</i>, <i>n</i></sub>=<i>ε</i><sub><i>m</i>, <i>n</i></sub>+<i>μ</i><mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mi>α</mi></msubsup></mrow></math></mathml>, <i>Ψ</i><sub><i>m</i>, <i>n</i></sub>=<i>ε</i><sub><i>m</i>, <i>n</i></sub>+<i>λ</i>‖<b><i>u</i></b><sub><i>m</i></sub>‖<mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>α</mi><mi>α</mi></msubsup></mrow></math></mathml>+<i>λ</i>‖<b><i>v</i></b><sub><i>n</i></sub>‖<mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>α</mi><mi>α</mi></msubsup></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="53">式中:‖·‖<sub><i>α</i></sub> 计算对应向量的L<sub>α</sub>正则化值, <b><i>u</i></b><sub><i>m</i></sub>和<b><i>v</i></b><sub><i>n</i></sub>分别表示在<b><i>U</i></b>和<b><i>V</i></b>中第<i>m</i>行和第<i>n</i>列向量。<i>λ</i>为正则化系数。</p>
                </div>
                <div class="p1">
                    <p id="54">当<i>α</i>=1时, 由式 (3) 得:</p>
                </div>
                <div class="p1">
                    <p id="55"><i>μ</i><sup>1</sup><sub><i>m</i>, <i>n</i></sub>=<i>λ</i>‖<b><i>u</i></b><sub><i>m</i></sub>‖<sub>1</sub>+<i>λ</i>‖<b><i>v</i></b><sub><i>n</i></sub>‖<sub>1</sub></p>
                </div>
                <div class="p1">
                    <p id="56"><i>Ψ</i><sub><i>m</i>, <i>n</i></sub>=<i>ε</i><sub><i>m</i>, <i>n</i></sub>+<i>λ</i>‖<b><i>u</i></b><sub><i>m</i></sub>‖<sub>1</sub>+<i>λ</i>‖<b><i>v</i></b><sub><i>n</i></sub>‖<sub>1</sub>      (4) </p>
                </div>
                <div class="p1">
                    <p id="57">式 (4) 用L<sub>1</sub>正则化对目标函数进行限制, L<sub>1</sub>能很好地保持模型的稀疏性, 调整模型中隐因子的分布, 但由于仅用L<sub>1</sub>正则化来对目标函数进行限制会导致模型的精度损失严重且L<sub>1</sub>不可导。</p>
                </div>
                <div class="p1">
                    <p id="58">当<i>α</i>=2时, 由式 (3) 得:</p>
                </div>
                <div class="p1">
                    <p id="59"><i>μ</i><sup>2</sup><sub><i>m</i>, <i>n</i></sub>=<i>λ</i>‖<b><i>u</i></b><sub><i>m</i></sub>‖<sup>2</sup><sub>2</sub>+<i>λ</i>‖<b><i>v</i></b><sub><i>n</i></sub>‖<sup>2</sup><sub>2</sub></p>
                </div>
                <div class="p1">
                    <p id="60"><i>Ψ</i><sub><i>m</i>, <i>n</i></sub>=<i>ε</i><sub><i>m</i>, <i>n</i></sub>+<i>λ</i>‖<b><i>u</i></b><sub><i>m</i></sub>‖<sup>2</sup><sub>2</sub>+<i>λ</i>‖<b><i>v</i></b><sub><i>n</i></sub>‖<sup>2</sup><sub>2</sub>      (5) </p>
                </div>
                <div class="p1">
                    <p id="61">式 (5) 用L<sub>2</sub>正则化对目标函数进行限制, L<sub>2</sub>能很好地保持模型的一般性, 因此在一般模型中我们通常用式 (5) 作为目标函数来构造一个SGD_LF模型求解隐因子<citation id="247" type="reference"><link href="3" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">3</a>]</sup></citation>。由于L<sub>2</sub>不能调整隐因子模型中隐因子的分布和改变实体特征的稀疏性, 因此对单一实体而言其实体特征就会和很多非相关簇也存在关联关系, 导致在隐因子预测模型中精准损失, 在基于隐因子的社区检测中不能很好地预测实体所属的社区关系。</p>
                </div>
                <div class="p1">
                    <p id="62">为了解决以上分别仅用L<sub>1</sub>和L<sub>2</sub>限制目标函数时存在的问题, 本文通过FOBOS的方法来构建一个同时用L<sub>1</sub>和L<sub>2</sub>来限制的目标函数的ENLF模型。</p>
                </div>
                <h3 id="63" name="63" class="anchor-tag"><b>2 基于FOBOS的ENLF模型</b></h3>
                <div class="p1">
                    <p id="64">弹性网络是一种有效的优化框架, 其将L<sub>1</sub>和L<sub>2</sub>正则化项整合到凸函数<i>ε</i> (<b><i>U</i>, <i>V</i></b>) 对目标函数进行限制, 构成弹性网络隐因子模型的目标函数。其中弹性网络正则化项表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="65"><i>μ</i><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mi>e</mi></msubsup></mrow></math></mathml>=<i>λ</i><sub>1</sub>‖<b><i>u</i></b><sub><i>m</i></sub>‖<sub>1</sub>+<i>λ</i><sub>1</sub>‖<b><i>v</i></b><sub><i>n</i></sub>‖<sub>1</sub>+<i>λ</i><sub>2</sub>‖<b><i>u</i></b><sub><i>m</i></sub>‖<mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>+<i>λ</i><sub>2</sub>‖<b><i>v</i></b><sub><i>n</i></sub>‖<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="69">式中:<i>λ</i><sub>1</sub>和<i>λ</i><sub>2</sub>分别为正则化项参数, 它们用于平衡L<sub>1</sub>和L<sub>2</sub>对模型的影响。在式 (1) 中加入正则化项可得:</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>τ</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>r</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>∈</mo><mi>Λ</mi></mrow></munder><mrow><mrow><mo> (</mo><mrow><mi>r</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>f</mi></munderover><mi>u</mi></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mi>v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow></msub></mrow><mo>) </mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71"><i>λ</i><sub>1</sub>‖<b><i>v</i></b><sub><i>n</i></sub>‖<sub>1</sub>+<i>λ</i><sub>2</sub>‖<b><i>u</i></b><sub><i>m</i></sub>‖<mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>+<i>λ</i><sub>2</sub>‖<b><i>v</i></b><sub><i>n</i></sub>‖<mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="74">用FOBOS来构建ENLF模型时, 它将整个目标函数优化任务分为:1) 非限制的随机次梯度下降;2) 弹性正则化的整合及更新。按照FOBOS的思想求解目标函数式 (7) 时, 首先通过随机梯度下降算法 (Stochastic Gradient Descent, SGD) 来对式 (2) 进行求解。<i>u</i><mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>表示<i>u</i><sub><i>m</i>, <i>k</i></sub>在<i>t</i>次更新后点状态。因此, 可得到第<i>t</i>+1次时的迭代解:</p>
                </div>
                <div class="p1">
                    <p id="76"><i>u</i><sup><i>t</i>+12</sup><sub><i>m</i>, <i>k</i></sub>=<i>u</i><sup> (<i>t</i>) </sup><sub><i>m</i>, <i>k</i></sub>+<i>η</i> (<i>r</i><sub><i>m</i>, <i>n</i></sub>-<sup> (<i>t</i>) </sup><sub><i>m</i>, <i>n</i></sub>) <i>v</i><sup> (<i>t</i>) </sup><sub><i>n</i>, <i>k</i></sub></p>
                </div>
                <div class="p1">
                    <p id="77"><sup> (<i>t</i>) </sup><sub><i>m</i>, <i>n</i></sub>=∑<i>fk</i>=1<i>u</i><sup> (<i>t</i>) </sup><sub><i>m</i>, <i>k</i></sub><i>v</i><sup> (<i>t</i>) </sup><sub><i>n</i>, <i>k</i></sub>      (8) </p>
                </div>
                <div class="p1">
                    <p id="78">式中:<mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>为非限制的次梯度u<sub>m, k</sub>在t次更新后的暂时结果, η表示学习率。在式 (8) 中加入正则化项对其进行优化时, 应遵循优化目标结果应该和非限制的次梯度更新后的暂时结果保持接近的思想, 因此目标函数可写为:</p>
                </div>
                <div class="p1">
                    <p id="80"><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>←</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub></mrow></munder><mrow><mo> (</mo><mrow><mrow><mo> (</mo><mrow><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>-</mo><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup></mrow><mo>) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>η</mi><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mi>e</mi></msubsup></mrow><mo>) </mo></mrow></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="82">在式 (9) 更新时, 隐因子空间只有部分的隐因子和μ<mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mi>e</mi></msubsup></mrow></math></mathml>相关, 因此可得:</p>
                </div>
                <div class="p1">
                    <p id="84">u<sup> (t+1) </sup><sub>m, k</sub>←argmin<i>u</i><sub><i>m</i>, <i>k</i></sub><i>u</i><sub><i>m</i>, <i>k</i></sub>-<i>u</i><sup><i>t</i>+12</sup><sub><i>m</i>, <i>k</i></sub><sup>2</sup>+<i>ημ</i><sup><i>e</i></sup><sub><i>m</i>, <i>n</i></sub> (<i>u</i><sub><i>m</i>, <i>k</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="85"><i>μ</i><sup><i>e</i></sup><sub><i>m</i>, <i>n</i></sub> (<i>u</i><sub><i>m</i>, <i>k</i></sub>) =<i>λ</i><sub>1</sub>|<i>u</i><sub><i>m</i>, <i>k</i></sub>|abs+<i>λ</i><sub>2</sub> (<i>u</i><sub><i>m</i>, <i>k</i></sub>) <sup>2</sup>      (10) </p>
                </div>
                <div class="p1">
                    <p id="86">式中:|·|<sub>abs</sub>表示求绝对值即为对单元素更新时当前更新元素的L<sub>1</sub>正则化项约束, 同理 (·) <sup>2</sup>即为|·|<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>。由于式 (10) 为关于<i>u</i><sub><i>m</i>, <i>k</i></sub>的凸函数, 因此0一定属于次梯度的目标集合上, 因此有:</p>
                </div>
                <div class="p1">
                    <p id="88"><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>-</mo><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>+</mo><mi>η</mi><mfrac><mrow><mo>∂</mo><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mi>e</mi></msubsup><mo stretchy="false"> (</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mo stretchy="false">) </mo></mrow><mrow><mo>∂</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub></mrow></mfrac><mo>=</mo><mn>0</mn></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="90">在计算式 (11) 时, 由于<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mi>e</mi></msubsup><mo stretchy="false"> (</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mo stretchy="false">) </mo></mrow><mrow><mo>∂</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub></mrow></mfrac></mrow></math></mathml>中存在不可导的情况, 因此用软阈值的方法进行处理。首先将式 (11) 中可导的部分分离, 可得:</p>
                </div>
                <div class="p1">
                    <p id="92"><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>-</mo><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mfrac><mrow><mo>∂</mo><mo stretchy="false">|</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mo stretchy="false">|</mo><msub><mrow></mrow><mrow><mtext>a</mtext><mtext>b</mtext><mtext>s</mtext></mrow></msub></mrow><mrow><mo>∂</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub></mrow></mfrac><mo>=</mo><mn>0</mn></mrow></math></mathml>      (12) </p>
                </div>
                <div class="p1">
                    <p id="94">式中:将<i>u</i><sub><i>m</i>, <i>k</i></sub>的系数2折进了<i>λ</i><sub>2</sub>中, 通过整理可得更新公式如下:</p>
                </div>
                <div class="p1">
                    <p id="95"><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mrow><mo> (</mo><mrow><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mfrac><mrow><mo>∂</mo><mrow><mo>|</mo><mrow><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub></mrow><mo>|</mo></mrow><msub><mrow></mrow><mrow><mtext>a</mtext><mtext>b</mtext><mtext>s</mtext></mrow></msub></mrow><mrow><mo>∂</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></math></mathml>      (13) </p>
                </div>
                <div class="p1">
                    <p id="97">通过设置软阈值, 对式 (13) 进行分析可得<i>u</i><sub><i>m</i>, <i>k</i></sub>的更新规则如下:</p>
                </div>
                <div class="p1">
                    <p id="98"><i>u</i><sub><i>m</i>, <i>k</i></sub>&gt;0⇒<i>u</i><sub><i>m</i>, <i>k</i></sub>=11+<i>ηλ</i><sub>2</sub><i>u</i><sup><i>t</i>+12</sup><sub><i>m</i>, <i>k</i></sub>-<i>ηλ</i><sub>1</sub>&gt;0⇒<i>u</i><sup><i>t</i>+12</sup><sub><i>m</i>, <i>k</i></sub>&gt;<i>ηλ</i><sub>1</sub></p>
                </div>
                <div class="p1">
                    <p id="99"><i>u</i><sub><i>m</i>, <i>k</i></sub>&lt;0⇒<i>u</i><sub><i>m</i>, <i>k</i></sub>=11+<i>ηλ</i><sub>2</sub><i>u</i><sup><i>t</i>+12</sup><sub><i>m</i>, <i>k</i></sub>+<i>ηλ</i><sub>1</sub>&lt;0⇒<i>u</i><sup><i>t</i>+12</sup><sub><i>m</i>, <i>k</i></sub>&lt;-<i>ηλ</i><sub>1</sub>      (14) </p>
                </div>
                <div class="p1">
                    <p id="100">当<mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>属于[-<i>λ</i><sub>1</sub>, <i>λ</i><sub>1</sub>]时, <i>u</i><sub><i>m</i>, <i>k</i></sub>=0。因此根据FOBOS构建的ENLF模型<i>u</i><sub><i>m</i>, <i>k</i></sub>更新公式如下:</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>←</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mrow><mo> (</mo><mrow><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&gt;</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mrow><mo> (</mo><mrow><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&lt;</mo><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mn>0</mn><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>&lt;</mo><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&lt;</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">同样地, 可得<i>v</i><sub><i>n</i>, <i>k</i></sub>的更新公式如下:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>←</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mrow><mo> (</mo><mrow><mi>v</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mi>v</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&gt;</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mrow><mo> (</mo><mrow><mi>v</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>v</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&lt;</mo><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mn>0</mn><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>&lt;</mo><mi>v</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&lt;</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">根据FOBOS算法推理, 可得ENLF模型实现的算法伪代码如算法1所示。</p>
                </div>
                <div class="p1">
                    <p id="106">算法1 ENLF算法</p>
                </div>
                <div class="area_img" id="250">
                                <img alt="" src="Detail/GetImg?filename=images/JYRJ201907050_25000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="250">
                                <img alt="" src="Detail/GetImg?filename=images/JYRJ201907050_25001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="131" name="131" class="anchor-tag"><b>3 BENLF模型</b></h3>
                <div class="p1">
                    <p id="132">在之前的研究中可得<citation id="248" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 隐因子模型中加入偏差能很好地提高模型精度。它的原理是在隐因子训练过程中仅通过已知评分来训练隐因子, 但是由于在目标矩阵中实体间产生关系会与每个实体间的差异不同而产生不同的关系值。如在电影评分项目中, 不同年龄、群体、职业等差异对物品的评分都有自己的倾向性。加入偏差能在很好地考虑到不同实体间的差异的前提下, 得到更好的模型性能。</p>
                </div>
                <div class="p1">
                    <p id="133">在ENLF模型中加入训练偏差<i>T</i><sub><i>m</i>, <i>n</i></sub>来提高模型的性能。因此在用SGD求解模型, 训练单一实例时预测值为:</p>
                </div>
                <div class="p1">
                    <p id="134"><mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>ϕ</mtext><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>+</mo><mover accent="true"><mi>r</mi><mo>^</mo></mover><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>, </mo><mover accent="true"><mi>r</mi><mo>^</mo></mover><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>f</mi></munderover><mi>u</mi></mstyle><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mi>v</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>      (17) </p>
                </div>
                <div class="p1">
                    <p id="136">式中:ϕ<mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>表示加入偏差后的<i>r</i><sub><i>m</i>, <i>n</i></sub>预测值, 其中有:</p>
                </div>
                <div class="p1">
                    <p id="138"><i>T</i><sub><i>m</i>, <i>n</i></sub>=<i>c</i><sub><i>m</i></sub>+<i>c</i><sub><i>n</i></sub>      (18) </p>
                </div>
                <div class="p1">
                    <p id="139">式中:<i>c</i><sub><i>m</i></sub>和<i>c</i><sub><i>n</i></sub>分别为目标矩阵行和列对应实体的训练偏差。加入偏差后的目标函数式 (7) 改写为:</p>
                </div>
                <div class="p1">
                    <p id="140" class="code-formula">
                        <mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>r</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>∈</mo><mi>Λ</mi></mrow></munder><mrow><mrow><mo> (</mo><mrow><mi>r</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>-</mo><mi>c</mi><msub><mrow></mrow><mi>m</mi></msub><mo>-</mo><mi>c</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>f</mi></munderover><mi>u</mi></mstyle><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mi>v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow></msub></mrow><mo>) </mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="141"><i>ηκ</i><mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mi>e</mi></msubsup></mrow></math></mathml>      (19) </p>
                </div>
                <div class="p1">
                    <p id="143"><i>κ</i><mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mi>e</mi></msubsup></mrow></math></mathml>=<i>λ</i><sub>1</sub>‖<b><i>u</i></b><sub><i>m</i></sub>‖<sub>1</sub>+<i>λ</i><sub>1</sub>‖<b><i>v</i></b><sub><i>n</i></sub>‖<sub>1</sub>+<i>λ</i><sub>1</sub>‖<i>c</i><sub><i>m</i></sub>‖<sub>1</sub>+</p>
                </div>
                <div class="p1">
                    <p id="145"><i>λ</i><sub>1</sub>‖<i>c</i><sub><i>n</i></sub>‖<sub>1</sub>+<i>λ</i><sub>2</sub>‖<b><i>u</i></b><sub><i>m</i></sub>‖<mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>+<i>λ</i><sub>2</sub>‖<b><i>v</i></b><sub><i>n</i></sub>‖<mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>+</p>
                </div>
                <div class="p1">
                    <p id="148"><i>λ</i><sub>2</sub>‖<i>c</i><sub><i>m</i></sub>‖<mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>+<i>λ</i><sub>2</sub>‖<i>c</i><sub><i>n</i></sub>‖<mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="151">为了更好表示数学公式推导, 令:</p>
                </div>
                <div class="p1">
                    <p id="152"><mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>e</mi><mi>r</mi><mi>r</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo><mi>r</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>-</mo><mi>c</mi><msubsup><mrow></mrow><mi>m</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>-</mo><mi>c</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>f</mi></munderover><mi>u</mi></mstyle><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mi>v</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>      (20) </p>
                </div>
                <div class="p1">
                    <p id="154">与ENLF模型推导类似, 通过SGD对式 (19) 进行求解, 对应实体偏差更新公式为:</p>
                </div>
                <div class="p1">
                    <p id="155" class="code-formula">
                        <mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mi>m</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>←</mo><mi>c</mi><msubsup><mrow></mrow><mi>m</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>+</mo><mi>η</mi><mrow><mo> (</mo><mrow><mi>e</mi><mi>r</mi><mi>r</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mfrac><mrow><mo>∂</mo><mo stretchy="false">|</mo><mi>c</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">|</mo><msub><mrow></mrow><mrow><mtext>a</mtext><mtext>b</mtext><mtext>s</mtext></mrow></msub></mrow><mrow><mo>∂</mo><mi>c</mi><msub><mrow></mrow><mi>m</mi></msub></mrow></mfrac><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mi>c</mi><msub><mrow></mrow><mi>m</mi></msub></mrow><mo>) </mo></mrow></mtd></mtr><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>←</mo><mi>c</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>+</mo><mi>η</mi><mrow><mo> (</mo><mrow><mi>e</mi><mi>r</mi><mi>r</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mfrac><mrow><mo>∂</mo><mo stretchy="false">|</mo><mi>c</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">|</mo><msub><mrow></mrow><mrow><mtext>a</mtext><mtext>b</mtext><mtext>s</mtext></mrow></msub></mrow><mrow><mo>∂</mo><mi>c</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></mfrac><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mi>c</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>) </mo></mrow></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="156">由于L<sub>1</sub>范数不可导, 通过软阈值的方式来处理偏差的更新, 得到<i>c</i><sub><i>m</i></sub>的更新公式为:</p>
                </div>
                <div class="p1">
                    <p id="157" class="code-formula">
                        <mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mi>m</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>=</mo><mi>c</mi><msubsup><mrow></mrow><mi>m</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>+</mo><mi>η</mi><mrow><mo> (</mo><mrow><mi>e</mi><mi>r</mi><mi>r</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mi>c</mi><msub><mrow></mrow><mi>m</mi></msub></mrow><mo>) </mo></mrow></mtd></mtr><mtr><mtd><mspace width="0.25em" /><mi>c</mi><msubsup><mrow></mrow><mi>m</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>←</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mi>m</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mi>c</mi><msubsup><mrow></mrow><mi>m</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>&gt;</mo><mi>η</mi><mi>λ</mi></mtd></mtr><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mi>m</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>+</mo><mi>η</mi><mi>λ</mi><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>c</mi><msubsup><mrow></mrow><mi>m</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>&lt;</mo><mo>-</mo><mi>η</mi><mi>λ</mi></mtd></mtr><mtr><mtd><mn>0</mn><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>c</mi><msubsup><mrow></mrow><mi>m</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>&lt;</mo><mo stretchy="false">|</mo><mi>η</mi><mi>λ</mi><mo stretchy="false">|</mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="158">同理, 可得到<i>c</i><sub><i>n</i></sub>的更新公式为:</p>
                </div>
                <div class="p1">
                    <p id="159" class="code-formula">
                        <mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>=</mo><mi>c</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>+</mo><mi>η</mi><mo stretchy="false"> (</mo><mi>e</mi><mi>r</mi><mi>r</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mi>c</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mspace width="0.25em" /><mi>c</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>←</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mi>c</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>&gt;</mo><mi>η</mi><mi>λ</mi></mtd></mtr><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>+</mo><mi>η</mi><mi>λ</mi><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>c</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>&lt;</mo><mo>-</mo><mi>η</mi><mi>λ</mi></mtd></mtr><mtr><mtd><mn>0</mn><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>c</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>_</mo><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mo>&lt;</mo><mo stretchy="false">|</mo><mi>η</mi><mi>λ</mi><mo stretchy="false">|</mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="160">根据ENLF模型推导, 可得<mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ω</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>表示为在BENLF中非限制的次梯度, 其更新如下:</p>
                </div>
                <div class="p1">
                    <p id="162"><mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ω</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>=</mo><mi>u</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>+</mo><mi>η</mi><mo>⋅</mo><mi>e</mi><mi>r</mi><mi>r</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>⋅</mo><mi>v</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>      (24) </p>
                </div>
                <div class="p1">
                    <p id="164">类似ENLF中<i>u</i><sub><i>m</i>, <i>k</i></sub>的更新可得到在BENLF中<i>u</i><sub><i>m</i>, <i>k</i></sub>的更新如下:</p>
                </div>
                <div class="p1">
                    <p id="165" class="code-formula">
                        <mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msub><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>←</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mrow><mo> (</mo><mrow><mi>ω</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mi>ω</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&gt;</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mrow><mo> (</mo><mrow><mi>ω</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>ω</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&lt;</mo><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mn>0</mn><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>&lt;</mo><mi>ω</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&lt;</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="166">令<mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>为<i>v</i><sub><i>n</i>, <i>k</i></sub>在第<i>t</i>次非限制梯度时的临时结果。同样可得到在BENLF中<i>v</i><sub><i>n</i>, <i>k</i></sub>的更新如下:</p>
                </div>
                <div class="p1">
                    <p id="168" class="code-formula">
                        <mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>←</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mrow><mo> (</mo><mrow><mi>δ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mi>δ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&gt;</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mrow><mo> (</mo><mrow><mi>δ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>δ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&lt;</mo><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd><mn>0</mn><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo>-</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>&lt;</mo><mi>δ</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>, </mo><mi>k</mi></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msubsup><mo>&lt;</mo><mi>η</mi><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="169">BENLF模型实现的算法伪代码如算法2所示。</p>
                </div>
                <div class="p1">
                    <p id="170">算法2 BENLF模型</p>
                </div>
                <div class="area_img" id="251">
                                <img alt="" src="Detail/GetImg?filename=images/JYRJ201907050_25100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="251">
                                <img alt="" src="Detail/GetImg?filename=images/JYRJ201907050_25101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="203" name="203" class="anchor-tag"><b>4 实验结果及分析</b></h3>
                <div class="p1">
                    <p id="204">在来自商业应用中的真实数据集上进行测试, 验证模型性能。数据集描述如表1所示。</p>
                </div>
                <div class="area_img" id="205">
                    <p class="img_tit"><b>表1 数据集描述</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="205" border="1"><tr><td>名称</td><td>|Φ|+|Ω|</td><td>|M|</td><td>|N|</td><td>来源</td></tr><tr><td><br />MovieLens</td><td>20 000 263</td><td>138 493</td><td>26 744</td><td>MovieLens</td></tr><tr><td><br />Flixter</td><td>8 196 077</td><td>147 612</td><td>48 794</td><td>Flixter</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="206">数据集1:MovieLens 20M 数据集 (下文中简称MovieLens为D1) , 由明尼苏达大学通过MovieLens 网站收集, 该数据集中包含了共138 493个用户和26 744 项项目之间的关系, 其中共有20 000 263已知评分项。该数据集的稀疏性为0.54%, 其稀疏性计算如下:</p>
                </div>
                <div class="p1">
                    <p id="207">稀疏性= (矩阵中已知数目/矩阵总数) ×100%</p>
                </div>
                <div class="p1">
                    <p id="208">数据集2:Flixter 数据集 (下文中简称Flixter 为D2) , 是用于测试推荐预测算法模型性能的重要数据集, 共有147 612个用户对48 794个项目评分, 其中已知评分数据项为8 196 007万条, 该数据集的稀疏性为0.11%。</p>
                </div>
                <div class="p1">
                    <p id="209">性能评价度量:由于本文是针对HiDS矩阵缺失数据的预测, 因此用预测数据作为模型性能的验证。采取均方根误差<citation id="249" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation> (Root Mean Square Error, RMSE) 来衡量模型对HiDS矩阵中缺失数据的预测精度。令<i>Ω</i>为测试数据集, 有|<i>Λ</i>|=|ϑ|+|<i>Ω</i>|。<i>Ω</i>和训练数据集ϑ中的数据不重合:</p>
                </div>
                <div class="p1">
                    <p id="210"><mathml id="211"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>Μ</mi><mi>S</mi><mi>E</mi><mo>=</mo><msqrt><mrow><mfrac><mrow><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>r</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>, </mo><mi>v</mi></mrow></msub></mrow></munder><mo stretchy="false"> (</mo></mstyle><mi>r</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>, </mo><mi>v</mi></mrow></msub><mo>-</mo><mover accent="true"><mi>r</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mo>, </mo><mi>v</mi></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>) </mo></mrow></mrow><mrow><mo stretchy="false">|</mo><mi>Ω</mi><mo stretchy="false">|</mo></mrow></mfrac></mrow></msqrt></mrow></math></mathml>      (27) </p>
                </div>
                <div class="p1">
                    <p id="212">式中:<mathml id="213"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>r</mi><mo>^</mo></mover></math></mathml><sub><i>m</i>, <i>n</i></sub>表示测试实例<i>r</i><sub><i>m</i>, <i>n</i></sub>∈<i>Ω</i>的预测。RMSE的值越小, 表示预测值和真实值间相差越小, 即表示模型性能越好。相反, 值越高则表示预测精度越低, 模型性能越差。</p>
                </div>
                <div class="p1">
                    <p id="214">本文实验中隐因子空间维度设为<i>f</i>=20, 实验中的每个数据集, 均采用20%～80%的比例来构造训练-测试数据和5折交叉验证来评估每个模型性能, 即将数据集分为5部分, 随机选取其中的1部分作为测试数据集, 剩余的4部分作为训练数据集。训练过程的停止条件设置为:1) 训练的迭代次数达到1 000轮;2) 相邻两次迭代得到的精度差小于1.0e×10<sup>-5</sup>。</p>
                </div>
                <div class="p1">
                    <p id="215">设置SGD_LF模型和本文提出的ENLF和BENLF两种模型进行性能比较, 相关实验结果如图1-图5所示。其中:图1、图2分别表示ENLF模型在D1和D2数据集上正则化系数<i>λ</i><sub>1</sub>和<i>λ</i><sub>2</sub>网格搜索的实验结果。</p>
                </div>
                <div class="p1">
                    <p id="216">图3、图4分别表示在D1和D2上的<i>λ</i><sub>1</sub>对隐因子分布的影响。图5比较三个模型在分别在D1和D2上的预测精度。</p>
                </div>
                <div class="area_img" id="218">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907050_21800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 在D1上RMSE比较" src="Detail/GetImg?filename=images/JYRJ201907050_21800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 在D1上RMSE比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907050_21800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="220">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907050_22000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 在D2上RMSE比较" src="Detail/GetImg?filename=images/JYRJ201907050_22000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 在D2上RMSE比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907050_22000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="220">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907050_22001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 在D2上RMSE比较" src="Detail/GetImg?filename=images/JYRJ201907050_22001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 在D2上RMSE比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907050_22001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="223">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907050_22300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 D1的LFs值分布" src="Detail/GetImg?filename=images/JYRJ201907050_22300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 D1的LFs值分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907050_22300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="226">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907050_22600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 D2的LFs值分布" src="Detail/GetImg?filename=images/JYRJ201907050_22600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 D2的LFs值分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907050_22600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="226">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907050_22601.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 D2的LFs值分布" src="Detail/GetImg?filename=images/JYRJ201907050_22601.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 D2的LFs值分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907050_22601.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="228">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907050_22800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 模型预测精度比较" src="Detail/GetImg?filename=images/JYRJ201907050_22800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 模型预测精度比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907050_22800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="229">首先, 在图1和图2分别给出了ENLF算法在D1和D2数据集上正则化系数<i>λ</i><sub>1</sub>和<i>λ</i><sub>2</sub>网格搜索训练实验结果, <i>η</i>均设置为0.001, 有以下结论:</p>
                </div>
                <div class="p1">
                    <p id="230">① ENLF模型精度高于SGD_LF模型。当<i>λ</i><sub>1</sub>=0时, ENLF算法等价于SGD_LF模型。如图1 (d) 所示, 当<i>λ</i><sub>2</sub>=1e<sup>-4</sup>且<i>λ</i><sub>1</sub>=0时, SGD_LF模型精度为:0.796, 当<i>λ</i><sub>2</sub>=1e<sup>-4</sup>且<i>λ</i><sub>1</sub>=5e<sup>-4</sup>时, 可得ENLF模型精度为0.791, ENLF模型精度高于SGD_LF模型0.5%。同样的情况在根据在D2上也可得到, 在图2 (c) 中可得, ENLF模型精度比SGD_LF模型高0.25%。</p>
                </div>
                <div class="p1">
                    <p id="231">② ENLF模型比SGD_LF模型能更好地调整模型的隐因子分布, 体现对应实体所属的社区关系。由图3可知, 在D1上, 随着L<sub>1</sub>系数的不断增大, 图3中为零的LFs数量越多, LFs分布图形态也相应改变。同样的情况在D2图4上也能看到。ENLF模型能提高隐因子模型的稀疏性。</p>
                </div>
                <div class="p1">
                    <p id="232">为了更好地比较BENLF模型、ENLF模型和SGD_LF模型的性能, 实验得到了在<i>η</i>=0.005时模型训练图, 对模型进行更加详细的比较, 如图5所示, 可得到如下结论:</p>
                </div>
                <div class="p1">
                    <p id="233">① BENLF模型精度远高于ENLF和SGD_LF模型性能, 如图5 (a) 所示, BENLF模型的预测精度为0.868, ENLF和SGD_LF模型精度分别为0.921和0.925, BNILF分别比ENLF和SGD_LF模型精度高出5.75%和6.16%。同样的情况在D2上图5 (b) 中可见, BNILF分别比ENLF和SGD_LF高出1.01%和1.13%。</p>
                </div>
                <div class="p1">
                    <p id="234">② BENLF模型的收敛速度远高于ENLF和SGD_LF模型, 如图5 (a) 所示, BENLF模型的收敛轮数为37, ENLF和SGD_LF模型的收敛轮数分别为58和60轮, BENLF的收敛速度分别是1.56和1.62倍。同样的情况在D2也能得到。BENLF模型的收敛速度分别比ENLF和SGD_LF模型快1.15和1.23倍。</p>
                </div>
                <h3 id="235" name="235" class="anchor-tag"><b>5 结 语</b></h3>
                <div class="p1">
                    <p id="236">本文实现了一个同时带有L<sub>1</sub>和L<sub>2</sub>的弹性正则化ENLF模型。该模型不仅能通过L<sub>2</sub>来防止模型过拟合, 也能通过L<sub>1</sub>来改变隐因子的分布, 提高模型预测精度。本文在提出ENLF模型基础上又加入偏差, 构建了BENLF模型, 对比ENLF模型和SGD_LF模型, 发现BENLF模型大大提高了模型的精度和收敛速度。在下一步工作中, 将聚焦于模型参数自适应选择的相关研究, 提高模型的效率。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generating Highly Accurate Predictions for Missing QoS Data via Aggregating Nonnegative Latent Factor Models">

                                <b>[1]</b> Luo X, Zhou M C, Xia Y, et al.Generating Highly Accurate Predictions for Missing QoS Data via Aggregating Nonnegative Latent Factor Models[J].IEEE Transactions on Neural Networks and Learning Systems, 2016, 27 (3) :524-537.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scalable collaborative filtering approaches for large reeommender systems">

                                <b>[2]</b> Takács G, Pilászy I, Németh B, et al.Scalable collaborative filtering approaches for large recommender systems[J].Journal of Machine Learning Research, 2009, 10:623-656.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES5053F72384481DE6709B90EF392A9B9B&amp;v=MTgwMDdIWWZPR1FsZkJyTFUwNXR0aHhMeTZ4S0E9TmlmT2ZiYTRHOUs2cUkxR2JPOExCSDFOdWhBVTZqWVBRWCtYMmhFOGU4T2RON1B0Q09OdkZTaVdXcjdKSUZwbWFCdQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Wang D, Chen Y, Guo J, et al.Elastic-net regularized latent factor analysis-based models for recommender systems[J].Neurocomputing, 2018, 329:66-74.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201703016&amp;v=MTEzMzdydkFOeWZUYkxHNEg5Yk1ySTlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 陈婷, 朱青, 周梦溪, 等.社交网络环境下基于信任的推荐算法[J].软件学报, 2017, 28 (3) :721-731.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201511019&amp;v=MTU0NTdCdEdGckNVUjdxZlp1WnRGeWpoVnJ2QU55ZlRiTEc0SDlUTnJvOUViWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 刘海洋, 王志海, 黄丹, 等.基于评分矩阵局部低秩假设的成列协同排名算法[J].软件学报, 2015, 26 (11) :2981-2993.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tracking Mobile Users in Wireless Networks via Semi-Supervised Colocalization">

                                <b>[6]</b> Pan J J, Pan S J, Jie Y, et al.Tracking mobile users in wireless networks via semi-supervised co-localization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (3) :587-600.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning from incomplete ratings using non-negative matrix factorization">

                                <b>[7]</b> Zhang S, Wang W, Ford J, et al.Learning from incomplete ratings using non-negative matrix factorization[C]//Proceedings of the Sixth SIAM International Conference on Data Mining.DBLP, 2006:549-553.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000104471&amp;v=MTIyODd3WmVadEZpbmxVcnpJSUZvUmJobz1OaWZJWTdLN0h0ak5yNDlGWmVzTENIczRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Cacheda F, Víctor Carneiro, Diego Fernández, et al.Comparison of collaborative filtering algorithms:Limitations of current techniques and proposals for scalable, high-performance recommender systems[J].Acm Transactions on the Web, 2011, 5 (1) :1-33.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient Extraction of Non-negative Latent Factors from High-Dimensional and Sparse Matrices in Industrial Applications">

                                <b>[9]</b> Luo X, Shang M, Li S.Efficient Extraction of Non-negative Latent Factors from High-Dimensional and Sparse Matrices in Industrial Applications[C]//2016 IEEE 16th International Conference on Data Mining (ICDM) .IEEE, 2017.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14120603924782&amp;v=Mjc3NTM5UE1xWTlHYmVrTEMzUTdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRm9SYmhvPU5pZlllcks4SA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Tibshirani R J.Regression Shrinkage and Selection via the LASSO[J].Journal of the Royal Statistical Society.Series B:Methodological, 1996, 58 (1) :267-288.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001256895&amp;v=MTAzODNEYk9JS1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1Rml2bFU3dk5KRlk9TmlmY2FyTzRIdEhOcllw&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Zou H, Hastie T.Regularization and variable selection via the elastic net[J].Journal of the Royal Statistical Society, 2005, 67 (2) :301-320.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient learning using forward-backward splitting">

                                <b>[12]</b> Duchi J C, Singer Y.Efficient Learning using Forward-Backward Splitting[C]//Proceedings of the 22nd International Conference on Neural Information Processing Systems.Curran Associates Inc., 2009:495-503.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000099855&amp;v=MTQ5NDVpbmxVcnpJSUZvUmJobz1OaWZJWTdLN0h0ak5yNDlGWk9JR0JIazhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0Rg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Herlocker J L, Konstan J A, Terveen L G, et al.Evaluating collaborative filtering recommender systems[J].ACM Transactions on Information Systems, 2004, 22 (1) :5-53.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201907050" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907050&amp;v=MjczNTBadEZ5amhWcnZBTHpUWlpMRzRIOWpNcUk5QVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
