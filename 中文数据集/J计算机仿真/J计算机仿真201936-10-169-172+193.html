<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139209677631250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201910036%26RESULT%3d1%26SIGN%3d79kHFsv5YmbuSg3yKqIjMMudfl0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201910036&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201910036&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201910036&amp;v=MTkwNTdCdEdGckNVUjdxZlp1WnBGeXptVUxyT0x6N0JkTEc0SDlqTnI0OUdZb1FLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#23" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;2 虚拟实验室手势交互感知&lt;/b&gt; "><b>2 虚拟实验室手势交互感知</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#28" data-title="&lt;b&gt;2.1 手势大数据集构建&lt;/b&gt;"><b>2.1 手势大数据集构建</b></a></li>
                                                <li><a href="#49" data-title="&lt;b&gt;2.2 手势交互感知&lt;/b&gt;"><b>2.2 手势交互感知</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#86" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#95" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#91" data-title="&lt;b&gt;图1 不同研究成果手势移动距离对比&lt;/b&gt;"><b>图1 不同研究成果手势移动距离对比</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;图2 不同研究成果失效率对比&lt;/b&gt;"><b>图2 不同研究成果失效率对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 张彦彬,陈晓春.基于特征空间切分建模的变形手势跟踪算法[J].机器人,2018,40(4):401-412." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201804002&amp;v=MDY3NDlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5em1VTHJPTHp6WmZMRzRIOW5NcTQ5RlpvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[1]</b>
                                         张彦彬,陈晓春.基于特征空间切分建模的变形手势跟踪算法[J].机器人,2018,40(4):401-412.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 方圆,李明,王萍.基于排队论的虚拟资源共享模式安全性研究[J].电子设计工程,2018,26(2):10-13." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201802003&amp;v=MTgxOTJyWTlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnl6bVVMck9JanJQZExHNEg5bk0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[2]</b>
                                         方圆,李明,王萍.基于排队论的虚拟资源共享模式安全性研究[J].电子设计工程,2018,26(2):10-13.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 邓卫斌,江翔.人机交互中手势图像手指指尖识别方法仿真[J].计算机仿真,2017,34(8):277-280." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201708058&amp;v=MDEyODBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5em1VTHJPTHo3QmRMRzRIOWJNcDQ5QWJJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[3]</b>
                                         邓卫斌,江翔.人机交互中手势图像手指指尖识别方法仿真[J].计算机仿真,2017,34(8):277-280.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 徐治鹏,冯志全,刘慧,等.面向智能电视的隐式手势交互建模与算法[J].计算机辅助设计与图形学学报,2017,29(2):344-353." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201702017&amp;v=MjkzODJDVVI3cWZadVpwRnl6bVVMck9MejdCYUxHNEg5Yk1yWTlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[4]</b>
                                         徐治鹏,冯志全,刘慧,等.面向智能电视的隐式手势交互建模与算法[J].计算机辅助设计与图形学学报,2017,29(2):344-353.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 严权峰,王岳斌,白天,等.基于压缩感知的实时手势检测和跟踪算法[J].计算机工程与应用,2016,52(20):182-187." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201620035&amp;v=MDYwNTR6bVVMck9MejdNYWJHNEg5Zk9yNDlHWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[5]</b>
                                         严权峰,王岳斌,白天,等.基于压缩感知的实时手势检测和跟踪算法[J].计算机工程与应用,2016,52(20):182-187.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 王红霞,王坤.基于加锁机制的静态手势识别方法[J].计算机应用,2016,36(7):1959-1964." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201607040&amp;v=Mjg1NzNJOUJaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXptVUxyT0x6N0JkN0c0SDlmTXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[6]</b>
                                         王红霞,王坤.基于加锁机制的静态手势识别方法[J].计算机应用,2016,36(7):1959-1964.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 施向军,王星尧.基于红外传感器和隐马尔可夫模型的动态手势识别[J].电子器件,2018,41(5):204-208." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZQJ201805040&amp;v=MDgyODk5bk1xbzlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnl6bVVMck9JVGZhWkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[7]</b>
                                         施向军,王星尧.基于红外传感器和隐马尔可夫模型的动态手势识别[J].电子器件,2018,41(5):204-208.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 冯志全,杨学文,徐涛,等.结合手势二进制编码和类-Hausdorff距离的手势识别[J].电子学报,2017,45(9):2281-2291." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201709032&amp;v=MzI0NjRlN0c0SDliTXBvOUdab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXptVUxyT0lUZlQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[8]</b>
                                         冯志全,杨学文,徐涛,等.结合手势二进制编码和类-Hausdorff距离的手势识别[J].电子学报,2017,45(9):2281-2291.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 王民,李泽洋,王纯,等.基于压缩感知与SURF特征的手语关键帧提取算法[J].激光与光电子学进展,2018,55(5):190-197." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201805023&amp;v=MDAzMjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnl6bVVMck9MeXJQWkxHNEg5bk1xbzlIWjRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[9]</b>
                                         王民,李泽洋,王纯,等.基于压缩感知与SURF特征的手语关键帧提取算法[J].激光与光电子学进展,2018,55(5):190-197.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 陈琳,李洁.基于虚拟现实技术的三维影像智能显示系统嵌入式设计[J].现代电子技术,2017,40(8):100-102." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201708029&amp;v=MDQzMjJuUFpMRzRIOWJNcDQ5SGJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5em1VTHJPUFM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[10]</b>
                                         陈琳,李洁.基于虚拟现实技术的三维影像智能显示系统嵌入式设计[J].现代电子技术,2017,40(8):100-102.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(10),169-172+193             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于大数据的虚拟实验室手势交互感知仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E9%B2%81%E4%B9%89&amp;code=23535462&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">杨鲁义</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%90%89%E6%9E%97%E5%A4%A7%E5%AD%A6%E6%9C%BA%E6%A2%B0%E4%B8%8E%E8%88%AA%E7%A9%BA%E8%88%AA%E5%A4%A9%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1046463&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">吉林大学机械与航空航天工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>鉴于人机交互手势感知的重要意义和实际价值及当前相关研究成果存在的感知假阳性率较高等问题,提出基于大数据的虚拟实验室手势交互感知方法。虚拟实验室手势,形成交互感知模型,同时引入包含各种类型人体模型和姿势的数据集CAESAR,以此构建手势大数据集合。分析目标手势基本特征,将手势的图像颜色直方图转换成颜色概率分布形式,构造能够描述手势特征的图像颜色直方图,完成课题研究。实验结果表明,所提方法手势感知连续性能强,在比较短的移动距离内就能够进行手势感知,且失效率要远低于文献成果,具有可靠性和实际应用价值。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%A7%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">大数据;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%99%9A%E6%8B%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">虚拟;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%89%8B%E5%8A%BF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">手势;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%A4%E4%BA%92&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">交互;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%84%9F%E7%9F%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">感知;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    杨鲁义(1983-),男(汉族),吉林长春人,硕士,工程师,主要研究领域为:链条质量检测,压电精密驱动,微小机械控制,非标试验平台控制。&lt;image id="114" type="formula" href="images/JSJZ201910036_11400.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-18</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(51875248);</span>
                    </p>
            </div>
                    <h1><b>Virtual Laboratory Gesture Interaction Perception Simulation Based on Big Data</b></h1>
                    <h2>
                    <span>YANG Lu-yi</span>
            </h2>
                    <h2>
                    <span>Department of Mechanical and Aerospace Engineering, Jilin University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Due to the importance and practical value of human-computer interaction gesture perception and the high false positive perception rate of current research results, this article puts forward a method of gesture interaction perception in virtual laboratory based on big data. Firstly, the virtual laboratory gesture was used to build the interactive perception model. Meanwhile, the data set CAESAR was introduced to construct the big data set of gesture, including various human models and gestures. Then, the basic features of target gesture were analyzed and the image color histogram of gesture was transformed into the form of color probability distribution. Finally, the color histogram describing the gesture features was constructed, and thus to complete this research. Simulation results show that the proposed method has a strong continuity of gesture perception, which can be used for gesture perception within short moving distance. Meanwhile, the failure rate is much lower than that of the literature result. It has better reliability and application value.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Big%20data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Big data;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Virtual&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Virtual;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gesture&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Gesture;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Interaction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Interaction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Perception&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Perception;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-04-18</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="23" name="23" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="24">实验作为教学中不可缺少的一部分,在我国教育发展均衡性较差的背景下,导致学生无法快速准确地理解实验教学<citation id="105" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。综合各种因素,找到一种新的实验教学方式,用其适应发展迅速的教学十分必要。将人机交互技术与虚拟实验相结合,能够高效避免当前实验中产生的不足,并提升实验教学的灵活性,还能够为当前教学改革提供一条新的思路<citation id="104" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。另外,虚拟实验室可以使学习者自由控制及操作虚拟环境,不仅提高了学生的学习兴趣,还在一定程度上缓解了教学资源紧张的现状。</p>
                </div>
                <div class="p1">
                    <p id="25">文献<citation id="106" type="reference">[<a class="sup">4</a>]</citation>中徐治鹏等人将依据视觉的手势交互当作研究重点进行分析,并提出显式交互与隐式交互相结合的手势交互感知算法。利用对依据视觉进行手势交互环境的分析,构建用户行为与智能电视融合下多层次分布式上下文模型,完成上下文信息数据的融合,并识别提取出数据特征。然后构建并实现CDL-DFCM模型以及显隐数据融合下的隐式交互感知模型,检测交互环境中的事件,同时感知用户具体意图。最后完成用户和智能化电视之间的隐式交互。文献<citation id="107" type="reference">[<a class="sup">5</a>]</citation>中严权峰等人指出,利用计算机视觉实现手势识别和跟踪的研究是人机交互中的重要内容,以往的手势识别和跟踪法存在一定缺陷,容易受到各种遮挡和运动模糊等方面的干扰。为此,提出将压缩感知应用至手势识别与跟踪中,将依据识别获取的手势信息和压缩感知下获取的目标信息实行高效的融合操作,以此完成手势识别和跟踪。</p>
                </div>
                <div class="p1">
                    <p id="26">手势交互感知过程中需要注意的事项非常多,上述相关研究成果在手势移动距离和感知的假阳性率方面待优化。为更好地实现手势交互感知,提出基于大数据的虚拟实验室手势交互感知方法。该方法连续性能强,在比较短的移动距离内就能够进行手势感知,且假阳性率低,具有可靠性和实际应用价值。</p>
                </div>
                <h3 id="27" name="27" class="anchor-tag"><b>2 虚拟实验室手势交互感知</b></h3>
                <h4 class="anchor-tag" id="28" name="28"><b>2.1 手势大数据集构建</b></h4>
                <div class="p1">
                    <p id="29">本文利用迭代最近点的方式构建手势大数据集合,整个过程可描述为将模板利用非刚性变形逐渐转换至和目标模型在形状上相似的状态。</p>
                </div>
                <div class="p1">
                    <p id="30">为了更好地构建手势大数据集,引入一个数据集CAESAR,该数据集中包含种类繁多的人体模型和姿势<citation id="108" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。以建立模板和CAESAR数据集之间的映射关系为目的,采用迭代最近点(ICP)的方式,将模板变形至CAESAR中的模型,其中迭代最近点是一种非刚性的对齐模式。CAESAR中模型上具有标记点,该标记点能够高效避免模板在变形时陷入局部最佳状态。</p>
                </div>
                <div class="p1">
                    <p id="31">经过上述简析,利用对一个能量函数进行最小化,使模板变形至CAESAR中任意模型D的姿势。其中,能量函数主要构成部分为</p>
                </div>
                <h4 class="anchor-tag" id="32" name="32">1)模板和<i>D</i>之间的距离项<i>E</i><sub><i>C</i></sub>:</h4>
                <div class="area_img" id="33">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201910036_03300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="34">其中,<i>N</i>代表模板上的点数。针对模板中的各点<i>v</i><sub><i>i</i></sub>,利用kd-tree在<i>D</i>上找出和自身距离最为接近的点<i>c</i><sub><i>i</i></sub>。<i>E</i><sub><i>C</i></sub>描述了这些对应点间存在的距离。<i>w</i><sub><i>i</i></sub>主要是用来描述这些对应点关系具备的可信程度,该值的大小取决于<i>v</i><sub><i>i</i></sub>、<i>c</i><sub><i>i</i></sub>方向量间存在的夹角。</p>
                </div>
                <h4 class="anchor-tag" id="35" name="35">2)模型标记点的误差<i>E</i><sub><i>M</i></sub></h4>
                <div class="area_img" id="36">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201910036_03600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="37">其中,<i>m</i><sub><i>i</i></sub>代表<i>D</i>表面标记点,<i>s</i><sub><i>i</i></sub>代表模板上标记点检索号,<i>P</i>代表标记点数量。</p>
                </div>
                <div class="p1">
                    <p id="38">CAESAR数据集收集数据过程中,在各人体上标记了70多个标记点,同时精准记录了标记点坐标位置。以避免模板变形时存在陷入局部最优的情况,在模板相对应位置将这70多个点标记上<citation id="109" type="reference"><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>。<i>E</i><sub><i>M</i></sub>描述了相应标记点间存在的距离。利用<i>E</i><sub><i>M</i></sub>能够将模板变形至和<i>D</i>相似的坐标与姿势上,方便找到最近点。</p>
                </div>
                <h4 class="anchor-tag" id="39" name="39">3)模板在变形过程中的平滑项<i>E</i><sub><i>S</i></sub></h4>
                <div class="area_img" id="40">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201910036_04000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="41">其中,<i>K</i>代表模板中三角面片的数量,<i>T</i>代表描述三角面片整体改变的仿射矩阵。式(3)中的<i>E</i><sub><i>S</i></sub>主要是应用在避免模板在变形时周围三角面片产生偏差太大的情况,以此防止发生畸形,进而降低手势感知假阳性率。</p>
                </div>
                <h4 class="anchor-tag" id="42" name="42">4)避免模板变形超过预期的约束项<i>E</i><sub><i>I</i></sub>:</h4>
                <div class="area_img" id="43">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201910036_04300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="44">式(4)中,<i>E</i><sub><i>I</i></sub>主要作用为使三角面片产生改变的矩阵更加接近单位阵,以此高效减小平滑项导致的误差值。</p>
                </div>
                <div class="p1">
                    <p id="45">综上,能量函数表达式为</p>
                </div>
                <div class="p1">
                    <p id="46" class="code-formula">
                        <mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo>=</mo><mi>w</mi><msub><mrow></mrow><mi>s</mi></msub><mi>E</mi><msub><mrow></mrow><mi>S</mi></msub><mo>+</mo><mi>w</mi><msub><mrow></mrow><mi>Ι</mi></msub><mi>E</mi><msub><mrow></mrow><mi>Ι</mi></msub><mo>+</mo><mi>w</mi><msub><mrow></mrow><mi>C</mi></msub><mi>E</mi><msub><mrow></mrow><mi>C</mi></msub><mo>+</mo><mi>w</mi><msub><mrow></mrow><mi>Μ</mi></msub><mi>E</mi><msub><mrow></mrow><mi>Μ</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="47">其中,<i>w</i><sub><i>s</i></sub>、<i>w</i><sub><i>I</i></sub>、<i>w</i><sub><i>C</i></sub>、<i>w</i><sub><i>M</i></sub>代表与每项相应的权值。利用对能量函数进行最小化操作,得到模板变形求解结果。在此,采用迭代最近点的方式对能量函数进行最小化,进而得到手势大数据集。该方法构成部分为以下两个阶段:</p>
                </div>
                <div class="p1">
                    <p id="48">在第一个阶段中,因无法精准找到模板和<i>D</i>间存在的对应映射点,由此不考虑<i>E</i><sub><i>C</i></sub>,利用剩余几项使模板变形至和<i>D</i>基本相似的坐标与姿态。<i>E</i><sub><i>M</i></sub>在第一阶段处于主导地位,其可以使模板中各标记点变形至<i>D</i>中相应标记点,利用<i>E</i><sub><i>S</i></sub>、<i>E</i><sub><i>I</i></sub>作为约束条件,确定模板中其它标记点最终坐标。基于上述操作,能够比较精准地找到模板和<i>D</i>间相应点。在第二阶段中,主要是通过<i>E</i><sub><i>C</i></sub>确定模板整体变形流程。此阶段运行迭代过程中迭代的方式会使模板变形至<i>D</i>,一直到收敛的状态。由于每次迭代操作完成后,模板均会更加接近<i>D</i>,找到的相应点就会越精准,由此在每次迭代时,会增加<i>w</i><sub><i>C</i></sub>值。通过<i>w</i><sub><i>C</i></sub>的不断变化,经过多次迭代得到模板收敛结果。这样就能够生成和<i>D</i>在姿态上基本相似的模板,及模板维持点对点关系模型,将这些新得到的模型融合在一起即得到手势大数据集。</p>
                </div>
                <h4 class="anchor-tag" id="49" name="49"><b>2.2 手势交互感知</b></h4>
                <div class="p1">
                    <p id="50">在上述步骤所建手势大数据集的基础下,分别利用手势运行动态轨迹特征识别检测和跟踪的方式完成手势交互感知。</p>
                </div>
                <div class="p1">
                    <p id="51">选取恰当的特征对于虚拟实验室手势交互感知而言十分重要。手势动态轨迹最为基本的三个特征分别为:位置坐标、走势方向和速度<citation id="110" type="reference"><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="52">位置的确定主要依据是手掌质心构成的空间位置坐标,能够直接由手势帧中识别检测出位置特征。该特征分为以下两种:基于不同的手势轨迹起点将位置特征描述成手掌质心和路径中各个点间存在的距离<i>L</i><sub><i>c</i></sub>,其表达式如式(6)所示;由手势轨迹路径中随机一点至起点之间的距离<i>L</i><sub><i>sc</i></sub>,表达式为式(7)。其中,随机点重心是(<i>C</i><sub><i>x</i></sub>,<i>C</i><sub><i>y</i></sub>),<i>t</i>′代表手势轨迹长度。</p>
                </div>
                <div class="p1">
                    <p id="53" class="code-formula">
                        <mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>c</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo>=</mo><mi>E</mi><mo>⋅</mo><msqrt><mrow><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>C</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>C</mi><msub><mrow></mrow><mi>y</mi></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>s</mi><mi>c</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo>=</mo><mi>E</mi><mo>⋅</mo><msqrt><mrow><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="54">上述方向特征描述的是手势动态轨迹任何时刻的方向,该特征能够得到手势在整体运行过程中于空中贯穿的走势,其识别与提取可有效提升手势感知的连续性,以此在尽可能小的移动距离内即可使机器感知到人体手势。该特征主要是以动态手势整体运行路径中各个点位置坐标矢量当作基础,一般包含以下方向特征:动态手势运行路径中心,表达式为式(8);动态手势运行路径中连续的两个点整体走势,表达式为式(9);动态手势运行路径的起点位置与当前指尖点的方向,表达式为式(10)。</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>θ</mi><msub><mrow></mrow><mrow><mn>1</mn><msup><mi>t</mi><mo>′</mo></msup></mrow></msub><mo>=</mo><mi>tan</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo>(</mo><mrow><mfrac><mrow><mi>y</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>C</mi><msub><mrow></mrow><mi>y</mi></msub></mrow><mrow><mi>x</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>C</mi><msub><mrow></mrow><mi>x</mi></msub></mrow></mfrac></mrow><mo>)</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>θ</mi><msub><mrow></mrow><mrow><mn>2</mn><msup><mi>t</mi><mo>′</mo></msup></mrow></msub><mo>=</mo><mi>tan</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo>(</mo><mrow><mfrac><mrow><mi>y</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><msup><mi>t</mi><mo>′</mo></msup></msub></mrow><mrow><mi>x</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><msup><mi>t</mi><mo>′</mo></msup></msub></mrow></mfrac></mrow><mo>)</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>θ</mi><msub><mrow></mrow><mrow><mn>3</mn><msup><mi>t</mi><mo>′</mo></msup></mrow></msub><mo>=</mo><mi>tan</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo>(</mo><mrow><mfrac><mrow><mi>y</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mi>x</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac></mrow><mo>)</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">根据对方向特征<i>θ</i>=(<i>θ</i><sub>1</sub><sub><i>t</i></sub><sub>′</sub>,<i>θ</i><sub>2</sub><sub><i>t</i></sub><sub>′</sub>,<i>θ</i><sub>3</sub><sub><i>t</i></sub><sub>′</sub>)进行对比判断手势运行方向,当三个特征全部是0,则表示手势为静止状态。</p>
                </div>
                <div class="p1">
                    <p id="57">速度作为手势识别提取的重要特征,其在整个识别过程中有着十分关键的作用。利用欧式距离对连续两个点间的运行速度进行计算</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><msub><mrow></mrow><msup><mi>t</mi><mo>′</mo></msup></msub><mo>=</mo><mfrac><mrow><msqrt><mrow><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mrow><msup><mi>t</mi><mo>′</mo></msup><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow><mi>θ</mi></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">上述三个特征混合使用能够有效提升手势交互感知精确性。</p>
                </div>
                <div class="p1">
                    <p id="60">为了使感知结果更加精准,将2.1节所建的手势大数据集合和颜色直方图相结合,并将手势的图像颜色直方图转换成颜色概率分布形式,构造能够描述手势特征的图像颜色直方图,将手势图像的颜色信息当作识别特征进行配准感知。上述方式的优势主要体现在能够基于手势运动变化对窗口大小进行调节并继续跟踪,提升跟踪精准性。</p>
                </div>
                <div class="p1">
                    <p id="61">综上,将手势跟踪感知大体划分成以下几个步骤:</p>
                </div>
                <div class="p1">
                    <p id="62">1)计算反向投影图。综合考虑各种因素会对跟踪感知结果产生影响,将得到的手势序列映射至<i>HSV</i>空间中,同时得到手势序列的颜色分量直方图,在该直方图中得到像素数量,也就是利用矩形框描述手势位置信息。以减小噪声对感知结果产生的影响为目的,利用阈值处理方式对手势图像实施一系列操作。目标手势在概率图范围内的概率值即为反射图像中对应像素点的值。假设图像的大小是<i>I</i><sub>1</sub>×<i>I</i><sub>2</sub>,通过式(12)获取颜色分量数量:</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><mrow><mo>[</mo><mrow><mi>C</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>]</mo></mrow><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ι</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ι</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>,</mo><mi>Τ</mi><mo stretchy="false">(</mo><mi>Μ</mi><mrow><mo>[</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>]</mo></mrow><mo stretchy="false">)</mo><mo>=</mo><mi>C</mi><msub><mrow></mrow><mi>k</mi></msub></mtd></mtr><mtr><mtd><mn>0</mn><mo>,</mo><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow></mrow></mstyle></mrow></mstyle><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">其中,<mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mi>C</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>]</mo></mrow></mrow></math></mathml>代表颜色分量,<mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><mrow><mo>[</mo><mrow><mi>C</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>]</mo></mrow></mrow></math></mathml>代表颜色分量的数量,像素点(<i>i</i>,<i>j</i>)在手势图像颜色空间中像素值是<mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><mo stretchy="false">(</mo><mi>Μ</mi><mrow><mo>[</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>]</mo></mrow><mo stretchy="false">)</mo></mrow></math></mathml>。获取手势直方图之后即得到了反向投影,也就是手势图像颜色概率分布情况。其中,概率分布表达式为</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>p</mi><mrow><mo>[</mo><mrow><mi>Ι</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">式中,<i>I</i>(<i>x</i>,<i>y</i>)代表图像(<i>x</i>,<i>y</i>)位置像素值,<mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mrow><mo>[</mo><mrow><mi>Ι</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><mo>]</mo></mrow></mrow></math></mathml>代表<i>I</i>(<i>x</i>,<i>y</i>)统计量。</p>
                </div>
                <div class="p1">
                    <p id="67">2)识别单帧手势。在该过程中,首先要判断手势图像查询窗口,然后得到查询窗口的中心坐标,最终确定手势模型色彩特征和查询范围之间的分布情况配准与否,如果配准,就表示已经找到目标,反之则继续查询,一直到达到终止条件。</p>
                </div>
                <div class="p1">
                    <p id="68">上述提到的质心可利用式(14)进行计算</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>Μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>0</mn></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>x</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mi>i</mi></mstyle></mrow></mstyle><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>Μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>1</mn></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>x</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mi>y</mi></mstyle></mrow></mstyle><mi>i</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>Μ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>0</mn></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>x</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mi>x</mi></mstyle></mrow></mstyle><mi>i</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">其中,<i>M</i><sub>00</sub>代表零阶矩,<i>M</i><sub>01</sub>、<i>M</i><sub>10</sub>代表<i>x</i>、<i>y</i>一阶矩。</p>
                </div>
                <div class="p1">
                    <p id="71">根据式(14)可得到查询窗口的中心位置坐标</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi><msub><mrow></mrow><mi>c</mi></msub><mo>=</mo><mfrac><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>0</mn></mrow></msub></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>0</mn></mrow></msub></mrow></mfrac></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mi>c</mi></msub><mo>=</mo><mfrac><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>1</mn></mrow></msub></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>0</mn></mrow></msub></mrow></mfrac></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">迭代手势图像之后,假设配准成功,那么进入下一帧迭代过程,反之,查询结束。</p>
                </div>
                <div class="p1">
                    <p id="74">3)跟踪感知目标手势</p>
                </div>
                <div class="p1">
                    <p id="75">根据上述获取的全部图像序列概率分布情况,可获得周期范围内目标手势每帧位置坐标信息,融合这些信息能够获得整个手势运行的路径,该路径即为目标手势跟踪感知。</p>
                </div>
                <div class="p1">
                    <p id="76">将被跟踪感知的手势中心当作查询窗口中心位置,查询窗口通过矩形表征,那么其空间位置能够描述成<sub><i>i</i></sub>(<i>i</i>=1,…,<i>n</i>′)。设定<mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo>=</mo><mrow><mo>[</mo><mrow><mi>p</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>p</mi><msub><mrow></mrow><msup><mi>m</mi><mo>′</mo></msup></msub></mrow><mo>]</mo></mrow><msup><mrow></mrow><mi>Τ</mi></msup></mrow></math></mathml>代表手势模型直方图,其中的<i>m</i>′代表直方图区域数量,则手势直方图可表示为</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><msup><mi>n</mi><mo>′</mo></msup></msub><mo>=</mo><mi>C</mi><msub><mrow></mrow><mi>h</mi></msub><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>n</mi><mo>′</mo></msup></munderover><mrow><mrow><mo>(</mo><mrow><mrow><mo>|</mo><mrow><mfrac><mrow><mover accent="true"><mi>x</mi><mo>˙</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow><mi>h</mi></mfrac></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>)</mo></mrow></mrow></mstyle><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">假设在大数据集备选区域中的手势坐标为<i>x</i><sub><i>i</i></sub>,且其直方图表达式为<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>[</mo><mrow><mi>q</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>q</mi><msub><mrow></mrow><msup><mi>m</mi><mo>′</mo></msup></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><mo>]</mo></mrow><msup><mrow></mrow><mi>Τ</mi></msup></mrow></math></mathml>,针对各<i>q</i><sub><i>u</i></sub>(<i>z</i>)可利用式(17)进行计算</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>q</mi><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>C</mi><msub><mrow></mrow><mi>h</mi></msub><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>n</mi><mo>′</mo></msup></munderover><mrow><mrow><mo>(</mo><mrow><mrow><mo>|</mo><mrow><mfrac><mrow><mi>z</mi><mo>-</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mi>h</mi></mfrac></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>)</mo></mrow></mrow></mstyle><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">其中,待选的目标手势中心位置坐标是<i>z</i>=(<i>x</i>,<i>y</i>),式(18)是目标模型距离计算表达式</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>λ</mi><mrow><mo>[</mo><mrow><mi>p</mi><mo>,</mo><mi>q</mi></mrow><mo>]</mo></mrow><mo>=</mo><msqrt><mrow><mn>1</mn><mo>-</mo><mi>S</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow></msqrt><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">式(18)中,<i>S</i>(<i>z</i>)可表示为:</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>S</mi><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>u</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>m</mi><mo>′</mo></msup></munderover><mrow><msqrt><mrow><mi>p</mi><msub><mrow></mrow><mi>u</mi></msub><mi>q</mi><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow></msqrt></mrow></mstyle><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">其中,<i>S</i>(<i>z</i>)代表上一帧中目标手势跟踪感知信息。由此,虚拟实验室手势交互感知主要是对式(19)进行计算,得到的第一个值为上一帧中目标手势跟踪感知的数据信息。</p>
                </div>
                <div class="p1">
                    <p id="85">通过上述步骤获取目标手势跟踪感知的数据信息,实现手势交互感知仿真。</p>
                </div>
                <h3 id="86" name="86" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="87">为证明该方法的有效性,需进行实验。实验即为在虚拟实验室中进行手势感知的测试。虚拟实验过程中,使用的PC运行配置为:实验操作系统为Microsoft Windows 10旗舰版,内存为4GB,主频为3.2GHz,处理器为Intel酷睿i5—4690k,开发环境为Microsoft Visual Studio,手势摄像设备为Microsoft LifeCam Studio。虚拟实验中使用到的材料,均为基于实际实验尺寸和功能,并利用3dsMax制作得到的,能够仿真实际材料的材质和物理性质。所用虚拟材料能够完成实验需要的各种功能,并模拟真实的实验测试。</p>
                </div>
                <div class="p1">
                    <p id="88">搭建虚拟实验环境之后,利用Unity3D当作引擎,依据3dsMax制作虚拟实验中用到的各种仪器和材料。整个过程不需要使用鼠标和键盘等工具,仅用手势操作整个实验。</p>
                </div>
                <div class="p1">
                    <p id="89">在上述实验环境下,分别在手势移动距离和手势感知的失效率方面验证所提方法性能。其中,手势移动距离主要是验证方法在手势移动多长距离时人机交互才会得到响应。在人机交互响应前提下,移动距离越短,则表示手势感知效果越好,灵敏度越高。</p>
                </div>
                <div class="p1">
                    <p id="90">实验结果如下:</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910036_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                    <img alt="图1 不同研究成果手势移动距离对比" src="Detail/GetImg?filename=images/JSJZ201910036_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
                                </a>
                                <p class="img_tit"><b>图1 不同研究成果手势移动距离对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910036_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="92">当机器能感知到手势,并给出相应反应时,手势移动的距离越短越好。分析图1可知,文献<citation id="111" type="reference">[<a class="sup">4</a>]</citation>方法手势移动距离整体呈较高趋势,表示运行效果不是十分理想。文献<citation id="112" type="reference">[<a class="sup">5</a>]</citation>方法手势移动距离波动比较明显,性能待完善。基于大数据的虚拟实验室手势交互感知方法在对手势识别和跟踪过程中,提取出了手势方向特征向量,该特征能够得到手势在整体运行过程中于空中贯穿的走势,并有效提升手势感知的连续性,进而可在尽可能短的移动距离内使机器感知到人体手势。</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910036_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                    <img alt="图2 不同研究成果失效率对比" src="Detail/GetImg?filename=images/JSJZ201910036_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
                                </a>
                                <p class="img_tit"><b>图2 不同研究成果失效率对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910036_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="94">图2中,本文方法感知结果的失效率最低。该方法在构建手势大数据集时,引入了平滑项,其能够使手势模型避免发生畸形,进而降低了手势交互感知的失效率。</p>
                </div>
                <h3 id="95" name="95" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="96">人机交互已经成为了科学技术进步的重要体现。当前,有关人机交互中的手势识别和感知研究成果众多,但很多成果在性能方面存在着不足。为此,提出基于大数据的虚拟实验室手势交互感知方法。利用构建手势大数据集合和手势特征提取跟踪实现交互感知,并通过实验证明了所提方法具有鲁棒性,性能较为完善。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201804002&amp;v=MDMyMTh0R0ZyQ1VSN3FmWnVacEZ5em1VTHJPTHp6WmZMRzRIOW5NcTQ5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[1]</b> 张彦彬,陈晓春.基于特征空间切分建模的变形手势跟踪算法[J].机器人,2018,40(4):401-412.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201802003&amp;v=MDI5NDNQZExHNEg5bk1yWTlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnl6bVVMck9JanI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[2]</b> 方圆,李明,王萍.基于排队论的虚拟资源共享模式安全性研究[J].电子设计工程,2018,26(2):10-13.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201708058&amp;v=MDkxMzJwNDlBYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnl6bVVMck9MejdCZExHNEg5Yk0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[3]</b> 邓卫斌,江翔.人机交互中手势图像手指指尖识别方法仿真[J].计算机仿真,2017,34(8):277-280.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201702017&amp;v=MDcwMjhIOWJNclk5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5em1VTHJPTHo3QmFMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[4]</b> 徐治鹏,冯志全,刘慧,等.面向智能电视的隐式手势交互建模与算法[J].计算机辅助设计与图形学学报,2017,29(2):344-353.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201620035&amp;v=MTM3MzFwRnl6bVVMck9MejdNYWJHNEg5Zk9yNDlHWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[5]</b> 严权峰,王岳斌,白天,等.基于压缩感知的实时手势检测和跟踪算法[J].计算机工程与应用,2016,52(20):182-187.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201607040&amp;v=MjMzNDhIOWZNcUk5QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5em1VTHJPTHo3QmQ3RzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[6]</b> 王红霞,王坤.基于加锁机制的静态手势识别方法[J].计算机应用,2016,36(7):1959-1964.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZQJ201805040&amp;v=MjU2MjZHNEg5bk1xbzlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnl6bVVMck9JVGZhWkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[7]</b> 施向军,王星尧.基于红外传感器和隐马尔可夫模型的动态手势识别[J].电子器件,2018,41(5):204-208.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201709032&amp;v=MDY4NThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnl6bVVMck9JVGZUZTdHNEg5Yk1wbzlHWm8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[8]</b> 冯志全,杨学文,徐涛,等.结合手势二进制编码和类-Hausdorff距离的手势识别[J].电子学报,2017,45(9):2281-2291.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201805023&amp;v=MDIwNTFNcW85SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5em1VTHJPTHlyUFpMRzRIOW4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[9]</b> 王民,李泽洋,王纯,等.基于压缩感知与SURF特征的手语关键帧提取算法[J].激光与光电子学进展,2018,55(5):190-197.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201708029&amp;v=MTU0MDZxZlp1WnBGeXptVUxyT1BTblBaTEc0SDliTXA0OUhiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[10]</b> 陈琳,李洁.基于虚拟现实技术的三维影像智能显示系统嵌入式设计[J].现代电子技术,2017,40(8):100-102.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201910036" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201910036&amp;v=MTkwNTdCdEdGckNVUjdxZlp1WnBGeXptVUxyT0x6N0JkTEc0SDlqTnI0OUdZb1FLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEowS3NjVGlRcFIybTlUTTlEbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
