<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141818582006250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201904044%26RESULT%3d1%26SIGN%3dGqfBAKK8nK7jtKLKzU8a19FSyaE%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201904044&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201904044&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201904044&amp;v=MTU1NjR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6aFVydkJMejdCZExHNEg5ak1xNDlCWUlRS0RIODQ=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#43" data-title="&lt;b&gt;2 基于滑动窗口滤波器的位姿估计方法&lt;/b&gt; "><b>2 基于滑动窗口滤波器的位姿估计方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="&lt;b&gt;2.1 数学模型的建立与分析&lt;/b&gt;"><b>2.1 数学模型的建立与分析</b></a></li>
                                                <li><a href="#62" data-title="&lt;b&gt;2.2 SWF位姿估计算法&lt;/b&gt;"><b>2.2 SWF位姿估计算法</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;2.3 KF结构滤波算法&lt;/b&gt;"><b>2.3 KF结构滤波算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#108" data-title="&lt;b&gt;3 仿真与分析&lt;/b&gt; "><b>3 仿真与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#118" data-title="&lt;b&gt;3.1 KF结构滤波的效果分析&lt;/b&gt;"><b>3.1 KF结构滤波的效果分析</b></a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;3.2 位姿估计算法的对比分析&lt;/b&gt;"><b>3.2 位姿估计算法的对比分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#133" data-title="&lt;b&gt;4 结语&lt;/b&gt; "><b>4 结语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="&lt;b&gt;图1 位姿估计的数学描述&lt;/b&gt;"><b>图1 位姿估计的数学描述</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;图2 仿真物体模型&lt;/b&gt;"><b>图2 仿真物体模型</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;图3 KF结构滤波效果对比&lt;/b&gt;"><b>图3 KF结构滤波效果对比</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;表1 KF结构滤波的对比结果&lt;/b&gt;"><b>表1 KF结构滤波的对比结果</b></a></li>
                                                <li><a href="#127" data-title="&lt;b&gt;图4 估计轨迹&lt;/b&gt;"><b>图4 估计轨迹</b></a></li>
                                                <li><a href="#131" data-title="&lt;b&gt;表2 位姿估计算法对比&lt;/b&gt;"><b>表2 位姿估计算法对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" H KIM, et al.Real-time 3D reconstruction and 6-DoF tracking with an event camera[C].European Conference on Computer Vision.Springer, 2016:349-364." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time 3D Reconstruction and 6-DoF Tracking with an Event Camera">
                                        <b>[1]</b>
                                         H KIM, et al.Real-time 3D reconstruction and 6-DoF tracking with an event camera[C].European Conference on Computer Vision.Springer, 2016:349-364.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" C XU, et al.Lie-X:Depth Image Based Articulated Object Pose Estimation, Tracking, and Action Recognition on Lie Groups[J].International Journal of Computer Vision, Springer, 2017:1-25." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD032029828A7DB91432F5C4CF0A603F1C&amp;v=Mjg2MjJIT3BvZEhiSm9JZUE0d3poSVE2RWw0TzN1UjJoSkVmN0tYTTd2c0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRCaHdMeSt4S0U9Tmo3QmFyTzdITg==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[2]</b>
                                         C XU, et al.Lie-X:Depth Image Based Articulated Object Pose Estimation, Tracking, and Action Recognition on Lie Groups[J].International Journal of Computer Vision, Springer, 2017:1-25.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" M A FISCHLER, R C BOLLES.Random sample consensus:a paradigm for model fitting with applications to image analysis and automated cartography[J].Communications of the ACM, ACM, 1981, 24 (6) :381-395." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000025011&amp;v=MzE0NDlIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyZklKRm9WYmhzPU5pZklZN0s3SHRqTnI0OUZaT2tLREgwNG9CTVQ2VDRQUQ==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[3]</b>
                                         M A FISCHLER, R C BOLLES.Random sample consensus:a paradigm for model fitting with applications to image analysis and automated cartography[J].Communications of the ACM, ACM, 1981, 24 (6) :381-395.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" D F DEMENTHON, L S DAVIS.Model-based object pose in 25 lines of code[C].European conference on computer vision.Springer, 1992:335-343." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Model-based object pose in 25 lines of code">
                                        <b>[4]</b>
                                         D F DEMENTHON, L S DAVIS.Model-based object pose in 25 lines of code[C].European conference on computer vision.Springer, 1992:335-343.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" C P LU, et al.Fast and globally convergent pose estimation from video images[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, IEEE, 2000, 22 (6) :610–622." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast and Globally Convergent Pose Estimation from Video Images">
                                        <b>[5]</b>
                                         C P LU, et al.Fast and globally convergent pose estimation from video images[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, IEEE, 2000, 22 (6) :610–622.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" V LEPETIT, et al.Epnp:An accurate o (n) solution to the pnp problem[J].International journal of computer vision, Springer, 2009, 81 (2) :155." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003394813&amp;v=MDgzMTBEbFY3dkpKRmM9Tmo3QmFyTzRIdEhQcklaQmJPb01ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FkWitadUZp&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[6]</b>
                                         V LEPETIT, et al.Epnp:An accurate o (n) solution to the pnp problem[J].International journal of computer vision, Springer, 2009, 81 (2) :155.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Y ZHENG et al.Revisiting the pnp problem:A fast, general and optimal solution[C].Proceedings of the IEEE International Conference on Computer Vision.2013:2344-2351." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Revisiting the PnP problem:A fast,general and optimal solution">
                                        <b>[7]</b>
                                         Y ZHENG et al.Revisiting the pnp problem:A fast, general and optimal solution[C].Proceedings of the IEEE International Conference on Computer Vision.2013:2344-2351.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" L FERRAZ, et al.Very fast solution to the PnP problem with algebraic outlier rejection[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.2014:501-508." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very fast solution to the Pn P problem with algebraic outlier rejection">
                                        <b>[8]</b>
                                         L FERRAZ, et al.Very fast solution to the PnP problem with algebraic outlier rejection[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.2014:501-508.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" O S GEDIK, A A ALATAN.RGBD data based pose estimation:Why sensor fusion?[C].Information Fusion (Fusion) , 2015 18th International Conference on.IEEE, 2015:2129-2136." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=RGBD data based pose estimation:Why sensor fusion?">
                                        <b>[9]</b>
                                         O S GEDIK, A A ALATAN.RGBD data based pose estimation:Why sensor fusion?[C].Information Fusion (Fusion) , 2015 18th International Conference on.IEEE, 2015:2129-2136.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 宋亮, 李志, 马兴瑞.基于激光成像雷达的未知目标相对位姿估计算法[J].系统仿真学报, 2017, 29 (5) :1103-1111." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTFZ201705023&amp;v=MDA2NTVoVXJ2QlBUbk5kTEc0SDliTXFvOUhaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXo=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[10]</b>
                                         宋亮, 李志, 马兴瑞.基于激光成像雷达的未知目标相对位姿估计算法[J].系统仿真学报, 2017, 29 (5) :1103-1111.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     陈玉寅, 张文安, 杨旭升.基于视觉传感器和无迹卡尔曼滤波器的运动刚体位姿估计[C].中国第36届中国控制会议, 2017:1266-1269.</a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" C KERL, et al.Dense visual SLAM for RGB-D cameras[C].Intelligent Robots and Systems (IROS) , 2013 IEEE/RSJ International Conference on.IEEE, 2013:2100-2106." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dense visual SLAM for RGB-D cameras">
                                        <b>[12]</b>
                                         C KERL, et al.Dense visual SLAM for RGB-D cameras[C].Intelligent Robots and Systems (IROS) , 2013 IEEE/RSJ International Conference on.IEEE, 2013:2100-2106.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" R A NEWCOMBE, et al.KinectFusion:Real-time dense surface mapping and tracking[C].Mixed and augmented reality (ISMAR) , 2011 10th IEEE international symposium on.IEEE, 2011:127-136." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=KinectFusion:real-time dense surface mapping and tracking">
                                        <b>[13]</b>
                                         R A NEWCOMBE, et al.KinectFusion:Real-time dense surface mapping and tracking[C].Mixed and augmented reality (ISMAR) , 2011 10th IEEE international symposium on.IEEE, 2011:127-136.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" R K&#220;MMERLE, et al.g 2 o:A general framework for graph optimization[C].Robotics and Automation (ICRA) , 2011 IEEE International Conference on.IEEE, 2011:3607–3613." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=g2o:A general framework for graph optimization">
                                        <b>[14]</b>
                                         R K&#220;MMERLE, et al.g 2 o:A general framework for graph optimization[C].Robotics and Automation (ICRA) , 2011 IEEE International Conference on.IEEE, 2011:3607–3613.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" R MUR-ARTAL, J D TARD&#211;S.ORB-SLAM2:An Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras[J].IEEE Transactions on Robotics, IEEE, 2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ORB-SLAM2:An open-source SLAM system for monocular,stereo,and RGB-D cameras">
                                        <b>[15]</b>
                                         R MUR-ARTAL, J D TARD&#211;S.ORB-SLAM2:An Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras[J].IEEE Transactions on Robotics, IEEE, 2017.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" J R SONG.Sliding window filter based unknown object pose estimation[C].Image Processing (ICIP) , 2017 IEEE International Conference on.IEEE, 2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sliding window filter based unknown object pose estimation">
                                        <b>[16]</b>
                                         J R SONG.Sliding window filter based unknown object pose estimation[C].Image Processing (ICIP) , 2017 IEEE International Conference on.IEEE, 2017.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" T D BARFOOT.State Estimation for Robotics[M].Cambridge:Cambridge University Press, 2017:325-329." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=State Estimation for Robotics">
                                        <b>[17]</b>
                                         T D BARFOOT.State Estimation for Robotics[M].Cambridge:Cambridge University Press, 2017:325-329.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(04),209-213+228             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于滑动窗口滤波器的无误差累积位姿估计</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AE%8B%E4%BD%B3%E5%84%92&amp;code=41614094&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">宋佳儒</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E5%A3%AB%E5%BC%BA&amp;code=08516966&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">胡士强</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E6%B0%B8%E8%83%9C&amp;code=23145244&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">杨永胜</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E8%88%AA%E7%A9%BA%E8%88%AA%E5%A4%A9%E5%AD%A6%E9%99%A2&amp;code=0054402&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">上海交通大学航空航天学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对物体位姿估计中需要物体先验信息、运动模型假设和误差累积等问题, 提出一种滑动窗口滤波器的位姿估计方法, 适用于物体先验信息与运动假设均未知的情况, 同时消除了误差累积。为了估计任意物体的位姿, 在每个滑动窗口内采用高斯牛顿算法实现李群空间内物体位姿与结构的迭代优化。采用卡尔曼滤波器并结合位姿与结构的强耦合关系, 通过对物体结构的滤波, 提高结构估计的准确度, 进而提高位姿估计的准确度, 克服误差累积。仿真验证了算法能有效地消除误差累积, 同时提高现有算法位姿估计的准确度;在没有先验信息与假设的条件下, 能达到与先进算法接近的估计结果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BD%8D%E5%A7%BF%E4%BC%B0%E8%AE%A1&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">位姿估计;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%AF%E5%B7%AE%E7%B4%AF%E7%A7%AF&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">误差累积;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%BB%A4%E6%B3%A2%E5%99%A8&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">滑动窗口滤波器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%99%A8&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">卡尔曼滤波器;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    宋佳儒 (1993-) , 女 (汉族) , 新疆石河子市人, 硕士研究生, 主要研究领域为计算机视觉。;
                                </span>
                                <span>
                                    胡士强 (1969-) , 男 (汉族) , 河北人, 教授, 博士研究生导师, 主要研究领域为信息融合技术与图像理解与分析。;
                                </span>
                                <span>
                                    杨永胜 (1972-) , 男 (汉族) , 山西汾阳人, 副教授, 硕士研究生导师, 主要研究领域为飞行器制导与控制。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2017-12-27</p>

            </div>
                    <h1><b>Sliding Window Filter Based Drift-Free Pose Estimation</b></h1>
                    <h2>
                    <span>SONG Jia-ru</span>
                    <span>HU Shi-qiang</span>
                    <span>YANG Yong-sheng</span>
            </h2>
                    <h2>
                    <span>School of Aeronautics and Astronautics, Shanghai Jiao Tong University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To avoid using prior information and motion assumptions of object and to address the error drift, a sliding window filter based object pose estimation algorithm is proposed. The algorithm requires no prior information and motion assumptions and avoids the error drift. To estimate the pose of an arbitrary object, Gauss-Newton method was used within each window to optimize the pose and structure iteratively on SE (3) . To tackle the error drift, Kalman filter and the strong coupling of pose and structure were explored by filtering the structure of object. Structure filtering increases the accuracy of structure estimation and thus the accuracy of estimated pose was increased without error drift. Simulation shows that the proposed algorithm can eliminate the error drift effectively and enhance the accuracy of existing method. Without prior information and assumption, the proposed algorithm can achieve the close estimation results of state-of-art methods.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Pose%20estimation&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Pose estimation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Error%20drift&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Error drift;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Sliding%20window%20filter&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Sliding window filter;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Kalman%20filter&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Kalman filter;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2017-12-27</p>
                            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="38">物体位姿估计在计算机视觉、增强现实 (Augmented Reality AR) 、机器人等领域中非常重要<citation id="136" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。其核心在于估计相机与物体之间的6自由度 (6 Degree of Fredom DOF) 位姿。自1981年物体位姿估计被提出以来<citation id="135" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 学者们基于不同的先验信息, 提出了很多物体位姿估计算法。</p>
                </div>
                <div class="p1">
                    <p id="39">当物体先验信息如大小、形状等已知时, 可以得到物体2D-3D特征点对应关系。POSIT (Pose from Orthography and Scaling with Iterations) <citation id="137" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, OI (Orthogonal Iteration) <citation id="138" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等经典算法广泛应用于特征点2D-3D对应关系已知的情况。但是, 上述算法都未考虑噪声对位姿估计的影响, 同时存在估计不准确和多次迭代的问题。近年来, 针对与物体位姿估计等同的透视n点定位问题 (Perspective-N-Point, PnP) , 学者们分别提出了EPnP (Efficient Perspective-n-Point) <citation id="139" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>, OPnP (Optimal Perspective-n-Point) <citation id="140" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, REPPnP<citation id="141" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等算法来加速位姿求解的迭代过程。其中OPnP算法对噪声具有较好的鲁棒性, REPPnP对外点具有较好的鲁棒性, 但是上述算法都需要基于已知的2D-3D对应关系。</p>
                </div>
                <div class="p1">
                    <p id="40">给定物体运动模型假设时, 如位置常量模型或速度常量模型, 常采用通过滤波器进行物体位姿估计, 来减少噪声的影响。由于观测模型的非线性, 常用的滤波器有扩展卡尔曼滤波 (Extended Kalman Filter, EKF) , 迭代扩展卡尔曼滤波 (Iterative Extended Kalman Filter, IEKF) 和无迹卡尔曼滤波 (Unscented Kalman Filter, UKF) <citation id="142" type="reference"><link href="3" rel="bibliography" /><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>。其主要思想是将物体的6自由度位姿作为系统的状态, 构建运动模型和观测模型, 用滤波器进行状态估计, 从而得到位姿。滤波器的初值一般由ICP算法或者PnP算法给定<citation id="143" type="reference"><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。当假设的运动模型不能很好表征物体实际运动轨迹时, 位姿估计效果不理想。此外, 物体位姿估计的观测模型和运动模型非线性度高, 基于EKF的估计方法不能得到很好的结果。</p>
                </div>
                <div class="p1">
                    <p id="41">当没有物体先验信息及运动模型假设时, 物体位姿估计的难点在于误差累积。误差累积指位姿估计的误差随着时间的增加而增大, 其不仅存在于物体位姿估计中, 也存在于视觉里程计等相机位姿估计中<citation id="145" type="reference"><link href="19" rel="bibliography" /><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>, 主要产生原因是缺少传感器信息。物体位姿估计与视觉里程计都只利用相机作为单一传感器输入, 由于相机存在噪声, 在没有先验信息与假设的情况下, 产生的估计误差无法利用更多传感器信息进行补偿与矫正。针对视觉里程计中的误差累积, 学者们的思路主要为利用多帧的信息来修正误差和图优化的优化方法<citation id="146" type="reference"><link href="25" rel="bibliography" /><link href="29" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">14</a>]</sup></citation>。KinectFusion通过同时重构地图的方式来避免误差累积, 但是效果不是特别明显<citation id="144" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。DVO-SLAM, ORB-SLAM2等算法通过提取关键帧信息、回环检测和全局地图优化的方式进一步避免误差累积, 但是全局优化时间成本交大<citation id="147" type="reference"><link href="25" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">15</a>]</sup></citation>。针对物体位姿估计中误差累积问题, 学者们尚未提出合理的解决方案。</p>
                </div>
                <div class="p1">
                    <p id="42">针对现有物体位姿估计算法中需要先验信息及假设和误差累积的问题, 本文在Song的工作基础上<citation id="148" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 提出一种基于滑动窗口滤波器 (Sliding Window Filter SWF) 的物体位姿估计算法。与前人工作不同的是, 本文的算法适用于没有先验信息与假设的复杂情况, 且采用简单的卡尔曼滤波器 (Kalman Filter KF) 消除了位姿估计的误差累积。每个滑动窗口内, 采用高斯牛顿算法迭代优化物体的位姿与特征点在物体坐标系下的坐标, 即结构, 克服对先验信息与假设的依赖性。同时, 在窗口内引入KF对物体的结构进行滤波, 使结构越来越准确。由于耦合关系的存在, 物体结构准确度的提高也会使位姿的准确度有所提高, 最终克服了现有方法中存在的误差累积问题。仿真结果首先验证了在没有先验信息及假设的条件下KF结构滤波算法可以有效地抑制误差累积, 提高位姿估计准确度;同时通过与先进算法的对比, 验证了本文算法在没有先验信息及假设的情况下可以达到与需要先验信息的先进算法较为接近的位姿估计效果。</p>
                </div>
                <h3 id="43" name="43" class="anchor-tag"><b>2 基于滑动窗口滤波器的位姿估计方法</b></h3>
                <h4 class="anchor-tag" id="44" name="44"><b>2.1 数学模型的建立与分析</b></h4>
                <div class="p1">
                    <p id="45">为了建立SWF, 本文首先对物体位姿估计问题进行数学描述与建模。图1为物体位姿估计的数学描述。由图1可知运动的物体坐标系为<i>F</i><sub><i>b</i></sub>, 相机坐标系为<i>F</i><sub><i>c</i></sub>, 特征点<i>i</i>在<i>F</i><sub><i>b</i></sub>下的坐标<i>p</i><sub><i>i</i></sub>定义为物体的结构。系统的观测值<i>y</i><sub><i>ik</i></sub>=[<i>u</i><sub><i>ik</i></sub>, <i>v</i><sub><i>ik</i></sub>, <i>d</i><sub><i>ik</i></sub>]<sup><i>T</i></sup>为通过RGB-D相机观测的SURF特征点像素坐标和深度值。由于相机存在噪声, 假设观测值会受到高斯噪声<i>n</i><sub><i>ik</i></sub>的影响。没有先验信息与假设的位姿估计仅通过观测值<i>y</i><sub><i>ik</i></sub>来估计<i>F</i><sub><i>b</i></sub>与<i>F</i><sub><i>c</i></sub>之间的相对位姿<i>T</i><sub><i>bc</i></sub>。由于物体的结构是未知的, <i>p</i><sub><i>i</i></sub>同时作为滤波器的状态进行估计, 并为<i>KF</i>结构滤波奠定了基础。</p>
                </div>
                <div class="area_img" id="46">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904044_046.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图1 位姿估计的数学描述" src="Detail/GetImg?filename=images/JSJZ201904044_046.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图1 位姿估计的数学描述</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904044_046.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="47">由相机的针孔以及位姿变换关系可得, <b><i>SWF</i></b>的观测模型为</p>
                </div>
                <div class="p1">
                    <p id="48" class="code-formula">
                        <mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>=</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mi>n</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mtext> </mtext><mi>n</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>∼</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mn>0</mn><mo>, </mo><mi>W</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="49">式中, <b>x</b><sub><b>ik</b></sub>={<b>T</b><sub><b>k</b></sub>, <b>p</b><sub><b>i</b></sub>}为当前时刻被估计的状态。函数<b>g (x</b><sub><b>ik</b></sub>) 先通过位姿<b>T</b><sub><b>k</b></sub>将特征点的在物体坐标系下的坐标<b>p</b><sub><b>i</b></sub>转换为在相机坐标系下的坐标, 再利用相机针孔模型将坐标投影成像素坐标和深度值。因此, 观测模型可表述为两个子函数的复合形式:</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mtext>π</mtext><mo stretchy="false"> (</mo><mi>z</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51">式中, <i>π</i> (·) 与<b>z</b> (·) 分别表示为</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>z</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>D</mi><msup><mrow></mrow><mi>Τ</mi></msup><mi>Τ</mi><msub><mrow></mrow><mi>k</mi></msub><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext>π</mtext><mo stretchy="false"> (</mo><mi>z</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>u</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub></mtd><mtd><mi>v</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub></mtd><mtd><mi>d</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><msup><mrow></mrow><mi>Τ</mi></msup></mtd></mtr><mtr><mtd><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>u</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>v</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>=</mo><mi>F</mi><mi>Κ</mi><mfrac><mn>1</mn><mrow><mi>z</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi><mo>, </mo><mn>3</mn></mrow></msub></mrow></mfrac><mi>z</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>, </mo><mi>d</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mi>z</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">式中, <b>z</b><sub><b>ik</b></sub>=<b>z (x</b><sub><b>ik</b></sub>) =[<b>z</b><sub><b>ik, 1</b></sub><b>z</b><sub><b>ik, 2</b></sub><b>z</b><sub><b>ik, 3</b></sub>]<sup><b>T</b></sup>, <b>1</b><sub><b>n</b></sub> 是<b>n</b>维单位矩阵, 矩阵<b>D、F、K</b>分别定义如下</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn><msub><mrow></mrow><mn>3</mn></msub></mtd></mtr><mtr><mtd><mn>0</mn><msub><mrow></mrow><mrow><mn>1</mn><mo>×</mo><mn>3</mn></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>, </mo><mi>F</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn><msub><mrow></mrow><mn>2</mn></msub></mtd><mtd><mn>0</mn><msub><mrow></mrow><mrow><mn>2</mn><mo>×</mo><mn>1</mn></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>, </mo><mi>Κ</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>f</mi><msub><mrow></mrow><mi>u</mi></msub></mtd><mtd><mn>0</mn></mtd><mtd><mi>c</mi><msub><mrow></mrow><mi>u</mi></msub></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mi>f</mi><msub><mrow></mrow><mi>v</mi></msub></mtd><mtd><mi>c</mi><msub><mrow></mrow><mi>v</mi></msub></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">此外, 观测噪声的协方差矩阵<b>W</b><sub><b>ik</b></sub>定义为</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>σ</mi><msubsup><mrow></mrow><mi>u</mi><mn>2</mn></msubsup></mtd><mtd></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd><mi>σ</mi><msubsup><mrow></mrow><mi>v</mi><mn>2</mn></msubsup></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd></mtd><mtd><mi>σ</mi><msubsup><mrow></mrow><mi>d</mi><mn>2</mn></msubsup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">式中, σ<sub><b>u</b></sub>与σ<sub><b>v</b></sub>来源于特征点匹配的误差;σ<sub><b>d</b></sub>主要来源于深度相机的噪声, 其公式为σ<sub><b>d</b></sub>=<b>1.45×10</b><sup>-<b>3</b></sup><b>d</b><mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow><mn>2</mn></msubsup></mrow></math></mathml>, 可以看出深度值越大噪声越大。</p>
                </div>
                <div class="p1">
                    <p id="59">没有先验信息与假设时位姿估计的关键为式 (<b>3</b>) 。由于相机的针孔模型已知, <b>z (x</b><sub><b>ik</b></sub>) 可利用相机模型与当前帧的观测求解得到, 因此公式等号左侧<b>z (x</b><sub><b>ik</b></sub>) 为已知量<b>z</b><sub><b>ik</b></sub>。同时等号右侧<b>x</b><sub><b>ik</b></sub>={<b>T</b><sub><b>k</b></sub>, <b>p</b><sub><b>i</b></sub>}为未知量, 位姿估计的核心即为利用已知的<b>z (x</b><sub><b>ik</b></sub>) 与式 (<b>3</b>) 来求解位姿与结构<b>T</b><sub><b>k</b></sub>, <b>p</b><sub><b>i</b></sub>。式 (<b>3</b>) 为非线性方程, 因此位姿估计问题常定义为如下优化形式</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>arg</mi><mtext> </mtext><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>Τ</mi><msub><mrow></mrow><mi>k</mi></msub><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>z</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>-</mo><mi>D</mi><msup><mrow></mrow><mi>Τ</mi></msup><mi>Τ</mi><msub><mrow></mrow><mi>k</mi></msub><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">即通过求解位姿与结构<b>T</b><sub><b>k</b></sub>, <b>p</b><sub><b>i</b></sub>使优化函数达到最小值。同时, 由式 (<b>3</b>) 可以看出<b>z (x</b><sub><b>ik</b></sub>) 为已知量时, 满足乘积关系的<b>x</b><sub><b>ik</b></sub>={<b>T</b><sub><b>k</b></sub>, <b>p</b><sub><b>i</b></sub>}有无数种组合, 即位姿与结构存在强耦合关系。因此位姿估计问题存在无穷多解, 对位姿的优化易陷入局部极小值, 进而导致误差累积。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62"><b>2.2 SWF位姿估计算法</b></h4>
                <div class="p1">
                    <p id="63"><b><i>SWF</i></b>通过利用多帧信息同时估计物体的位姿与结构, 一定程度上避免了位姿陷入局部极小值。算法通过高斯牛顿方法在每一个滑动窗口内迭代优化窗口中全部特征点的观测不一致性误差, 实现对系统状态<b>x</b><sub><b>ik</b></sub>={<b>T</b><sub><b>k</b></sub>, <b>p</b><sub><b>i</b></sub>}的估计。因此, 目标函数定义为观测不一致性误差的加权平方和</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><mo>∑</mo><mi>e</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mi>Τ</mi></msup><mi>W</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mi>e</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">式中, 观测不一致性误差定义为</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>e</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>=</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>-</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">基于观测不一致性误差的目标函数即为式 (<b>6</b>) 的变体。为了实现高斯牛顿算法, 需要利用如下状态小扰动策略, 对观测模型进行线性化[<b>17</b>]</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Τ</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mi>exp</mi><mo stretchy="false"> (</mo><mi>ε</mi><msubsup><mrow></mrow><mi>k</mi><mo>^</mo></msubsup><mo stretchy="false">) </mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>≈</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mi>ε</mi><msubsup><mrow></mrow><mi>k</mi><mo>^</mo></msubsup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>p</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi><mo>, </mo><mi>i</mi></mrow></msub><mo>+</mo><mi>D</mi><mtext>V</mtext><msub><mrow></mrow><mtext>i</mtext></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">式中, <b>T</b><sub><b>op, k</b></sub>与<b>p</b><sub><b>op, i</b></sub>为当前状态的工作点, 并设集合<b>x</b><sub><b>op, ik</b></sub>={<b>T</b><sub><b>op, k</b></sub>, <b>p</b><sub><b>op, i</b></sub>};ε<sub><b>k</b></sub>与<i>V</i><sub>i</sub>为当前时刻的状态小扰动, 并设<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>δ</mtext><mtext>x</mtext><msub><mrow></mrow><mrow><mtext>i</mtext><mtext>k</mtext></mrow></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mtext>ε</mtext><msubsup><mrow></mrow><mtext>k</mtext><mtext>Τ</mtext></msubsup></mtd><mtd><mtext>V</mtext><msubsup><mrow></mrow><mtext>i</mtext><mtext>Τ</mtext></msubsup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>;exp 将李群空间上<b>6×1</b>维向量转换成欧式空间<b>4×4</b>维的位姿矩阵;符号∧将<b>6×1</b>维向量转换成<b>4×4</b>维矩阵</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><msubsup><mrow></mrow><mrow><mn>6</mn><mo>×</mo><mn>1</mn></mrow><mo>^</mo></msubsup><mo>=</mo><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>ρ</mi><msub><mrow></mrow><mrow><mn>3</mn><mo>×</mo><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd><mi>φ</mi><msub><mrow></mrow><mrow><mn>3</mn><mo>×</mo><mn>1</mn></mrow></msub></mtd></mtr></mtable><mo>]</mo></mrow><msup><mrow></mrow><mo>^</mo></msup><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>φ</mi><msup><mrow></mrow><mo>×</mo></msup></mtd><mtd><mi>ρ</mi><msub><mrow></mrow><mrow><mn>3</mn><mo>×</mo><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd><mn>0</mn><msub><mrow></mrow><mrow><mn>1</mn><mo>×</mo><mn>3</mn></mrow></msub></mtd><mtd><mn>0</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><msub><mrow></mrow><mrow><mn>4</mn><mo>×</mo><mn>4</mn></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">因此可得到新的优化函数</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>J</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi></mrow></msub><mo stretchy="false">) </mo><mo>-</mo><mi>b</mi><msup><mrow></mrow><mi>Τ</mi></msup><mi>δ</mi><mi>x</mi><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>δ</mi><mi>x</mi><msup><mrow></mrow><mi>Τ</mi></msup><mi>A</mi><mi>δ</mi><mi>x</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">式中, x<sub>op</sub>为窗口内全部状态的工作点集合, δx为状态小扰动量δx<sub>ik</sub>的集合, A和b的定义如下</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>A</mi><mo>=</mo><mi>Η</mi><msup><mrow></mrow><mi>Τ</mi></msup><mi>W</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi>Η</mi><mtext> </mtext><mi>b</mi><mo>=</mo><mi>Η</mi><msup><mrow></mrow><mi>Τ</mi></msup><mi>W</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi>e</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi></mrow></msub><mo stretchy="false">) </mo><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mi>Η</mi><mo>=</mo><mrow><mo>[</mo><mrow><mspace width="0.25em" /><mtable><mtr><mtd><mi>Η</mi><msubsup><mrow></mrow><mrow><mn>1</mn><mn>0</mn></mrow><mi>Τ</mi></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>Η</mi><msubsup><mrow></mrow><mrow><mi>Μ</mi><mn>0</mn></mrow><mi>Τ</mi></msubsup></mtd><mtd><mi>Η</mi><msubsup><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow><mi>Τ</mi></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>Η</mi><msubsup><mrow></mrow><mrow><mi>Μ</mi><mi>Κ</mi></mrow><mi>Τ</mi></msubsup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><msup><mrow></mrow><mi>Τ</mi></msup></mtd></mtr><mtr><mtd><mi>Η</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>=</mo><mi>G</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mi>W</mi><mo>=</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy="false">{</mo><mtable><mtr><mtd><mi>W</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>0</mn></mrow></msub></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>W</mi><msub><mrow></mrow><mrow><mi>Μ</mi><mn>0</mn></mrow></msub></mtd><mtd><mi>W</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>W</mi><msub><mrow></mrow><mrow><mi>Μ</mi><mi>Κ</mi></mrow></msub></mtd></mtr></mtable><mo stretchy="false">}</mo></mtd></mtr><mtr><mtd><mi>e</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mo>[</mo><mrow><mspace width="0.25em" /><mtable><mtr><mtd><mi>e</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>0</mn></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi></mrow></msub><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>e</mi><msub><mrow></mrow><mrow><mi>Μ</mi><mn>0</mn></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi></mrow></msub><mo stretchy="false">) </mo></mtd><mtd><mi>e</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi></mrow></msub><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>e</mi><msub><mrow></mrow><mrow><mi>Μ</mi><mi>Κ</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi></mrow></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mo>]</mo></mrow><msup><mrow></mrow><mi>Τ</mi></msup></mtd></mtr></mtable><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">对目标函数在δx处进行求导, 并设导数为零可得小扰动更新量的公式为</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>δ</mi><mi>x</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mi>b</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">因此, 状态的更新如下</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Τ</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi><mo>, </mo><mi>k</mi></mrow></msub><mo>←</mo><mi>exp</mi><mo stretchy="false"> (</mo><mi>ε</mi><msubsup><mrow></mrow><mi>k</mi><mrow><mo>*</mo><mo>^</mo></mrow></msubsup><mo stretchy="false">) </mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi><mo>, </mo><mi>k</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>p</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi><mo>, </mo><mi>i</mi></mrow></msub><mo>←</mo><mi>p</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi><mo>, </mo><mi>i</mi></mrow></msub><mo>+</mo><mi>D</mi><mtext>V</mtext><msubsup><mrow></mrow><mtext>i</mtext><mo>*</mo></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">之后, 可通过迭代优化求解<i>δx</i>并进行状态的更新, 直到状态<i>x</i><sub><i>ik</i></sub>={<i>T</i><sub><i>k</i></sub>, <i>p</i><sub><i>i</i></sub>}收敛。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81"><b>2.3 KF结构滤波算法</b></h4>
                <div class="p1">
                    <p id="82">根据式 (<b>3</b>) 中位姿与结构的强耦合关系可知, 若物体的结构估计得越准确, 相应的位姿也会估计得越准。本文引入<i>KF</i>, 在滑动窗口内实现对物体结构的进一步滤波, 提高结构与位姿估计的准确度, 进而消除误差累积。</p>
                </div>
                <div class="p1">
                    <p id="83">结构滤波的基本假设为物体是刚体, 即任意时刻物体的结构是不变的。<i>KF</i>的状态为物体的结构<i>p</i><sub><i>i</i></sub>。基于刚性假设, 定义<i>KF</i>的运动模型为:</p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>p</mi><msubsup><mrow></mrow><mi>i</mi><mi>S</mi></msubsup><mo>+</mo><mi>w</mi><msub><mrow></mrow><mi>p</mi></msub><mtext> </mtext><mi>w</mi><msub><mrow></mrow><mi>p</mi></msub><mo>∼</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mn>0</mn><mo>, </mo><mi>Σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>S</mi></msubsup><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="85">式中p<mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>S</mi></msubsup></mrow></math></mathml>为特征点i在物体坐标系下已存储的坐标, 即结构的存储值;w<sub>p</sub>表征物体刚性假设与实际物体的差异。</p>
                </div>
                <div class="p1">
                    <p id="87">KF的观测为当前帧高斯牛顿算法优化的结果p<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>D</mi></msubsup></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="89" class="code-formula">
                        <mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>p</mi><msubsup><mrow></mrow><mi>i</mi><mi>D</mi></msubsup><mo>+</mo><mi>n</mi><msub><mrow></mrow><mi>p</mi></msub><mtext> </mtext><mi>n</mi><msub><mrow></mrow><mi>p</mi></msub><mo>∼</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mn>0</mn><mo>, </mo><mi>Σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>D</mi></msubsup><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="90">其中, 噪声n<sub>p</sub>表征结构估计的不确定度, 即由于特征点匹配的不准确, 滑动窗口滤波器中的p<sub>i</sub>对应的特征点不一定是所存储的特征点i。Σ<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>D</mi></msubsup></mrow></math></mathml>为高斯牛顿算法优化结果p<sub>i</sub>的协方差矩阵。状态的总体协方差矩阵为矩阵A的逆, Σ<mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>D</mi></msubsup></mrow></math></mathml>为A<sup>-<b>1</b></sup>的一部分。</p>
                </div>
                <div class="p1">
                    <p id="93">基于以上模型定义, KF状态的先验估计为</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>p</mi></mstyle><mrow><mspace width="0.25em" /><mo>︶</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>p</mi><msubsup><mrow></mrow><mi>i</mi><mi>S</mi></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">因此, 先验方差为</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext> </mtext><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>Σ</mi></mstyle><mrow><mspace width="0.25em" /><mo>︶</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>Σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>S</mi></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">KF矫正阶段, 第i个特征点的卡尔曼增益K<sub>i</sub>为</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>Σ</mi></mstyle><mrow><mspace width="0.25em" /><mo>︶</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>Σ</mi></mstyle><mrow><mspace width="0.25em" /><mo>︶</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi>Σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>D</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99">通过观测矫正得到的结构后验估计为</p>
                </div>
                <div class="p1">
                    <p id="100" class="code-formula">
                        <mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>p</mi></mstyle><mrow><mspace width="0.25em" /><mo>︶</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><msubsup><mrow></mrow><mi>i</mi><mi>D</mi></msubsup><mo>-</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>p</mi></mstyle><mrow><mspace width="0.25em" /><mo>︶</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="101">因此, 后验方差为</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover accent="true"><mi>Σ</mi><mo>^</mo></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false"> (</mo><mi>Ι</mi><mo>-</mo><mi>Κ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>Σ</mi></mstyle><mrow><mspace width="0.25em" /><mo>︶</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103"><sub>i</sub>与■<sub>i</sub>为结构滤波之后的结果, 该结果不仅结合了已存储的物体结构信息, 也融入了最新的结构估计结果。最后将存储的p<mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>S</mi></msubsup></mrow></math></mathml>Σ<mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>S</mi></msubsup></mrow></math></mathml>的更新为</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>p</mi><msubsup><mrow></mrow><mi>i</mi><mi>S</mi></msubsup><mo>←</mo><mover accent="true"><mi>Ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr><mtr><mtd><mi>Σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>S</mi></msubsup><mo>←</mo><mrow><mover accent="true"><mi>Σ</mi><mo>^</mo></mover></mrow><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr></mtable><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">由此可以看出, KF结合当前帧的结构信息, 对已存储的结构进行了滤波与更新, 使存储结构包含的信息量越来越大, 其准确度随着时间的增加相应地提高。由于存储的结构是高斯牛顿算法中结构的初值, 初值准确度的提高将提高位姿与结构估计的准确度。因此, 位姿估计的准确度会随着时间的增加而有所提高, 最终消除了误差累积。</p>
                </div>
                <h3 id="108" name="108" class="anchor-tag"><b>3 仿真与分析</b></h3>
                <div class="p1">
                    <p id="109">仿真首先验证了<i>KF</i>结构滤波在滑动窗口滤波器算法中误差累积的抑制效果;其次对本文算法与需要先验信息的先进的<i>OPnP</i>算法和需要运动模型假设的经典的<i>IEKF</i>算法进行了对比实验。仿真采用如图<b>2</b>所示的物体模型进行算法验证。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904044_110.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图2 仿真物体模型" src="Detail/GetImg?filename=images/JSJZ201904044_110.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图2 仿真物体模型</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904044_110.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="111">仿真随机提取物体模型表面的一定数目的特征点, 并随机产生复杂的运动轨迹。利用位姿转换关系与观测模型生成观测, 并通过<b>Matlab</b>产生高斯噪声, 构成带有噪声特性的观测数据。实验参数设置:滑动窗口大小<b>10</b>;相机分辨率为<b>640×480</b>;相机内参数为<b><i>f</i></b><sub><b><i>v</i></b></sub>=<b><i>f</i></b><sub><b><i>u</i></b></sub>=<b>800<i>c</i></b><sub><b><i>v</i></b></sub>=<b><i>c</i></b><sub><b><i>u</i></b></sub>=<b>0</b>;观测模型的协方差矩阵参数为:<i>σ</i><sub><b><i>u</i></b></sub>=<b>5.249</b> 像素, <i>σ</i><sub><b><i>v</i></b></sub>=<b>3.937</b> 像素, <i>σ</i><sub><b><i>d</i></b></sub>由公式<i>σ</i><sub><b><i>d</i></b></sub>=<b>1.45×10</b><sup>-<b>3</b></sup><b><i>d</i></b><mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow><mn>2</mn></msubsup></mrow></math></mathml>求解。</p>
                </div>
                <div class="p1">
                    <p id="113">仿真的误差定义为</p>
                </div>
                <div class="p1">
                    <p id="114" class="code-formula">
                        <mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>δ</mi><mi>r</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>δ</mi><mi>r</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>, </mo><mi>k</mi></mrow></msub></mtd><mtd><mi>δ</mi><mi>r</mi><msub><mrow></mrow><mrow><mi>y</mi><mo>, </mo><mi>k</mi></mrow></msub></mtd><mtd><mi>δ</mi><mi>r</mi><msub><mrow></mrow><mrow><mi>z</mi><mo>, </mo><mi>k</mi></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><msup><mrow></mrow><mi>Τ</mi></msup><mo>:</mo><mo>=</mo><mi>r</mi><msubsup><mrow></mrow><mi>c</mi><mrow><mi>b</mi><mi>k</mi><mi>c</mi><mo>*</mo></mrow></msubsup><mo>-</mo><mi>r</mi><msubsup><mrow></mrow><mi>c</mi><mrow><mi>b</mi><mi>k</mi><mi>c</mi></mrow></msubsup></mtd></mtr><mtr><mtd><mi>δ</mi><mi>θ</mi><msubsup><mrow></mrow><mi>k</mi><mo>×</mo></msubsup><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>δ</mi><mi>θ</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>, </mo><mi>k</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>δ</mi><mi>θ</mi><msub><mrow></mrow><mrow><mi>y</mi><mo>, </mo><mi>k</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>δ</mi><mi>θ</mi><msub><mrow></mrow><mrow><mi>z</mi><mo>, </mo><mi>k</mi></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><msup><mrow></mrow><mo>×</mo></msup><mo>:</mo><mo>=</mo><mn>1</mn><mo>-</mo><mi>R</mi><msubsup><mrow></mrow><mrow><mi>b</mi><mi>k</mi><mi>c</mi></mrow><mo>*</mo></msubsup><mi>R</mi><msubsup><mrow></mrow><mrow><mi>b</mi><mi>k</mi><mi>c</mi></mrow><mi>Τ</mi></msubsup><mspace width="0.25em" /></mtd></mtr></mtable><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="115">式中<i>δ</i><b><i>r</i></b><sub><b><i>k</i></b></sub>与<i>δθ</i><sub><b><i>k</i></b></sub>分别为平动误差与旋转误差。误差的平均绝对值定义为</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>Δ</mi><mi>r</mi><msub><mrow></mrow><mi>x</mi></msub></mtd></mtr><mtr><mtd><mi>Δ</mi><mi>r</mi><msub><mrow></mrow><mi>y</mi></msub></mtd></mtr><mtr><mtd><mi>Δ</mi><mi>r</mi><msub><mrow></mrow><mi>z</mi></msub></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mi>Τ</mi></mfrac><mstyle displaystyle="true"><mo>∑</mo><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mo stretchy="false">|</mo><mi>δ</mi><mi>r</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>, </mo><mi>k</mi></mrow></msub><mo stretchy="false">|</mo></mtd></mtr><mtr><mtd><mo stretchy="false">|</mo><mi>δ</mi><mi>r</mi><msub><mrow></mrow><mrow><mi>y</mi><mo>, </mo><mi>k</mi></mrow></msub><mo stretchy="false">|</mo></mtd></mtr><mtr><mtd><mo stretchy="false">|</mo><mi>δ</mi><mi>r</mi><msub><mrow></mrow><mrow><mi>z</mi><mo>, </mo><mi>k</mi></mrow></msub><mo stretchy="false">|</mo></mtd></mtr></mtable><mo>]</mo></mrow></mrow></mstyle><mo>, </mo><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>Δ</mi><mi>θ</mi><msub><mrow></mrow><mi>x</mi></msub></mtd></mtr><mtr><mtd><mi>Δ</mi><mi>θ</mi><msub><mrow></mrow><mi>y</mi></msub></mtd></mtr><mtr><mtd><mi>Δ</mi><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mi>Τ</mi></mfrac><mstyle displaystyle="true"><mo>∑</mo><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mo stretchy="false">|</mo><mi>δ</mi><mi>θ</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>, </mo><mi>k</mi></mrow></msub><mo stretchy="false">|</mo></mtd></mtr><mtr><mtd><mo stretchy="false">|</mo><mi>δ</mi><mi>θ</mi><msub><mrow></mrow><mrow><mi>y</mi><mo>, </mo><mi>k</mi></mrow></msub><mo stretchy="false">|</mo></mtd></mtr><mtr><mtd><mo stretchy="false">|</mo><mi>δ</mi><mi>θ</mi><msub><mrow></mrow><mrow><mi>z</mi><mo>, </mo><mi>k</mi></mrow></msub><mo stretchy="false">|</mo></mtd></mtr></mtable><mo>]</mo></mrow></mrow></mstyle><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">式中平动误差幅值均值的单位为<b>cm</b>, 旋转误差幅值均值的单位为<b>deg</b>。</p>
                </div>
                <h4 class="anchor-tag" id="118" name="118"><b>3.1 KF结构滤波的效果分析</b></h4>
                <div class="p1">
                    <p id="119">在没有先验信息的情况下, 为了直观地表示<b>KF</b>结构滤波对误差累积抑制的效果, 仿真测试了物体模型在<b>1350</b>帧数据下的位姿估计效果并与<b>Song</b>的无<b>KF</b>结构滤波的位姿估计算法<citation id="150" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>进行了对比。图<b>3</b>为本文位姿估计算法与<b>Song</b>的算法估计误差对比图。</p>
                </div>
                <div class="area_img" id="120">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904044_120.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图3 KF结构滤波效果对比" src="Detail/GetImg?filename=images/JSJZ201904044_120.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图3 KF结构滤波效果对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904044_120.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="121">图中黑色曲线为本文算法的位姿估计误差, 灰色曲线为<b>Song</b>的位姿估计误差, 可以看出<b>KF</b>结构滤波对误差累积的抑制效果非常明显。本文算法的估计误差不仅没有随着时间的增加而增大, 而且有减小的趋势, 该趋势在δθ<sub><b>y</b></sub>的估计结果中比较明显。该现象是因为<b>KF</b>利用当前帧位姿估计结果对存储的结构进行滤波与更新, 使位姿估计越来越准。当没有<b>KF</b>结构滤波时, <b>Song</b>的方法误差累积的现象较为明显。比如, 灰色曲线的幅值随着时间的增加缓慢扩大, 直到第<b>1350</b>帧时, 平动误差最大可以达到<b>18cm</b>, 而旋转误差最大可以达到<b>7deg</b>。</p>
                </div>
                <div class="p1">
                    <p id="122">为了量化<b>KF</b>结构滤波的算法效果, 定义算法<b>1</b>改进算法<b>2</b>的百分比为<i>η</i></p>
                </div>
                <div class="p1">
                    <p id="123" class="code-formula">
                        <mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>η</mi><mo>=</mo><mn>1</mn><mo>-</mo><mrow><mo>|</mo><mrow><mfrac><mrow><mtext>Δ</mtext><mi>e</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mtext>Δ</mtext><mi>e</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac></mrow><mo>|</mo></mrow><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="124">式中, Δ<b><i>e</i></b><sub><b>1</b></sub>为算法<b>1</b>的估计误差Δ<b><i>e</i></b><sub><b>2</b></sub>为算法<b>2</b>的估计误差。基于误差越小越好的思想, <i>η</i>越趋近于<b>1</b>代表算法<b>1</b>对算法<b>2</b>改进得越多。仿真误差幅值均值的对比结果见表<b>1</b>。由表<b>1</b>可知, 算法<b>1</b>为本文算法, 算法<b>2</b>为<b><i>Song</i></b>的算法。</p>
                </div>
                <div class="area_img" id="125">
                    <p class="img_tit"><b>表1 KF结构滤波的对比结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="125" border="1"><tr><td><br /></td><td><i>Δ</i>r<sub>x</sub></td><td><i>Δ</i>r<sub>y</sub></td><td><i>Δ</i>r<sub>z</sub></td><td><i>Δ</i>θ<sub>x</sub></td><td><i>Δ</i>θ<sub>y</sub></td><td><i>Δ</i>θ<sub>z</sub></td></tr><tr><td><br />本文</td><td>0.76</td><td>1.07</td><td>1.53</td><td>0.22</td><td>0.48</td><td>0.37</td></tr><tr><td><br />Song</td><td>3.41</td><td>2.95</td><td>4.32</td><td>1.23</td><td>1.06</td><td>2.21</td></tr><tr><td><br />η</td><td>77.7%</td><td>63.7%</td><td>64.6%</td><td>82.1%</td><td>54.7%</td><td>83.3%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="126">可以看出, 本文带有KF结构滤波的滑动窗口滤波器位姿估计算法准确度较Song的算法有较大的改善。图4是本文算法的平动估计轨迹。其中黑色曲线是轨迹真值, 灰色曲线是轨迹估计值。</p>
                </div>
                <div class="area_img" id="127">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904044_127.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图4 估计轨迹" src="Detail/GetImg?filename=images/JSJZ201904044_127.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图4 估计轨迹</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904044_127.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="128">从图<b>4</b>可以看出, 虽然运动轨迹复杂且无规律, 但位姿估计结果基本与真值重合。实验验证了, 本文算法在复杂轨迹下位姿估计的有效性, 算法对误差累积有非常理想的抑制效果。</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129"><b>3.2 位姿估计算法的对比分析</b></h4>
                <div class="p1">
                    <p id="130">为进一步验证本文算法的有效性, 在同等特征点提取噪声条件下, 将算法与先进的<b>OPnP</b>算法和经典的<b>IEKF</b>算法进行了对比实验。由于<b>OPnP</b>需要物体先验信息, 仿真将物体结构真值赋予<b>OPnP</b>; 由于<b>IEKF</b>需要物体运动模型假设, 仿真采用常速度模型假设, 速度为当前运动轨迹下速度真值的均值。表<b>2</b>为误差幅值均值的对比结果。</p>
                </div>
                <div class="area_img" id="131">
                    <p class="img_tit"><b>表2 位姿估计算法对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="131" border="1"><tr><td><br /></td><td><i>Δ</i>r<sub>x</sub></td><td><i>Δ</i>r<sub>y</sub></td><td><i>Δ</i>r<sub>z</sub></td><td><i>Δ</i>θ<sub>x</sub></td><td><i>Δ</i>θ<sub>y</sub></td><td><i>Δ</i>θ<sub>z</sub></td></tr><tr><td><br />本文</td><td>0.76</td><td>1.07</td><td>1.53</td><td>0.22</td><td>0.48</td><td>0.37</td></tr><tr><td><br />OPnP</td><td>0.47</td><td>0.46</td><td>0.43</td><td>0.19</td><td>0.14</td><td>0.26</td></tr><tr><td><br />IEKF</td><td>0.77</td><td>2.05</td><td>0.76</td><td>0.41</td><td>0.26</td><td>0.64</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="132">可以看出, 虽然1350帧的数据量非常大, 对于没有先验信息及假设的估计算法来说, 容易造成误差累积, 比如Song的方法, 但本文算法依然可以得到与采用真值信息作为先验的先进OPnP算法较为接近的估计结果。同时, 与IEKF的对比结果可以看出, 虽然IEKF算法可以通过运动模型假设避免误差累积, 得到理想的估计结果, 但本文算法估计结果整体优于IEKF的估计结果。主要原因为IEKF算法需要基于运动模型假设, 当运动模型不能反映真实运动轨迹时, 位姿估计结果会受到影响。由于本文算法不存在运动模型假设, 故不存在运动模型假设与实际运动不相符的问题, 因此本文算法可应用于更广泛的运动形式。对比实验进一步验证了本文算法在位姿估计问题中的有效性与实用性。</p>
                </div>
                <h3 id="133" name="133" class="anchor-tag"><b>4 结语</b></h3>
                <div class="p1">
                    <p id="134">针对现有物体位姿估计算法中需要先验信息与运动模型假设和误差累积等问题, 本文提出一种基于SWF的位姿估计算法实时估计物体的位姿与结构, 克服了现有算法对先验信息与运动假设的依赖性和误差累积的问题。首先, 通过对观测模型的分析得到物体结构与位姿的强耦合关系。其次, 在每个滑动窗口内, 采用高斯牛顿算法在李群空间内迭代优化物体的位姿与结构。进而, 利用耦合关系在滑动窗口内引入KF对物体的结构进行滤波, 从而消除了误差累积。最后, 通过仿真验证了本文算法不仅有效地避免误差累积, 将前人的位姿估计算法的准确度提高了83.3%, 而且得到与先进算法在需要先验信息的条件下接近的位姿估计效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="154" type="formula" href="images/JSJZ201904044_15400.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">宋佳儒</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time 3D Reconstruction and 6-DoF Tracking with an Event Camera">

                                <b>[1]</b> H KIM, et al.Real-time 3D reconstruction and 6-DoF tracking with an event camera[C].European Conference on Computer Vision.Springer, 2016:349-364.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD032029828A7DB91432F5C4CF0A603F1C&amp;v=MTE3NDhhQnVIWWZPR1FsZkJyTFUwNXRCaHdMeSt4S0U9Tmo3QmFyTzdITkhPcG9kSGJKb0llQTR3emhJUTZFbDRPM3VSMmhKRWY3S1hNN3ZzQ09OdkZTaVdXcjdKSUZwbQ==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[2]</b> C XU, et al.Lie-X:Depth Image Based Articulated Object Pose Estimation, Tracking, and Action Recognition on Lie Groups[J].International Journal of Computer Vision, Springer, 2017:1-25.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000025011&amp;v=MDYwNjhaT2tLREgwNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJmSUpGb1ZiaHM9TmlmSVk3SzdIdGpOcjQ5Rg==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[3]</b> M A FISCHLER, R C BOLLES.Random sample consensus:a paradigm for model fitting with applications to image analysis and automated cartography[J].Communications of the ACM, ACM, 1981, 24 (6) :381-395.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Model-based object pose in 25 lines of code">

                                <b>[4]</b> D F DEMENTHON, L S DAVIS.Model-based object pose in 25 lines of code[C].European conference on computer vision.Springer, 1992:335-343.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast and Globally Convergent Pose Estimation from Video Images">

                                <b>[5]</b> C P LU, et al.Fast and globally convergent pose estimation from video images[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, IEEE, 2000, 22 (6) :610–622.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003394813&amp;v=MTM1MTE0SHRIUHJJWkJiT29NWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaURsVjd2SkpGYz1OajdCYXJP&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[6]</b> V LEPETIT, et al.Epnp:An accurate o (n) solution to the pnp problem[J].International journal of computer vision, Springer, 2009, 81 (2) :155.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Revisiting the PnP problem:A fast,general and optimal solution">

                                <b>[7]</b> Y ZHENG et al.Revisiting the pnp problem:A fast, general and optimal solution[C].Proceedings of the IEEE International Conference on Computer Vision.2013:2344-2351.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very fast solution to the Pn P problem with algebraic outlier rejection">

                                <b>[8]</b> L FERRAZ, et al.Very fast solution to the PnP problem with algebraic outlier rejection[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.2014:501-508.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=RGBD data based pose estimation:Why sensor fusion?">

                                <b>[9]</b> O S GEDIK, A A ALATAN.RGBD data based pose estimation:Why sensor fusion?[C].Information Fusion (Fusion) , 2015 18th International Conference on.IEEE, 2015:2129-2136.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTFZ201705023&amp;v=MTMzNjRSN3FmWnVabUZ5emhVcnZCUFRuTmRMRzRIOWJNcW85SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[10]</b> 宋亮, 李志, 马兴瑞.基于激光成像雷达的未知目标相对位姿估计算法[J].系统仿真学报, 2017, 29 (5) :1103-1111.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 陈玉寅, 张文安, 杨旭升.基于视觉传感器和无迹卡尔曼滤波器的运动刚体位姿估计[C].中国第36届中国控制会议, 2017:1266-1269.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dense visual SLAM for RGB-D cameras">

                                <b>[12]</b> C KERL, et al.Dense visual SLAM for RGB-D cameras[C].Intelligent Robots and Systems (IROS) , 2013 IEEE/RSJ International Conference on.IEEE, 2013:2100-2106.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=KinectFusion:real-time dense surface mapping and tracking">

                                <b>[13]</b> R A NEWCOMBE, et al.KinectFusion:Real-time dense surface mapping and tracking[C].Mixed and augmented reality (ISMAR) , 2011 10th IEEE international symposium on.IEEE, 2011:127-136.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=g2o:A general framework for graph optimization">

                                <b>[14]</b> R KÜMMERLE, et al.g 2 o:A general framework for graph optimization[C].Robotics and Automation (ICRA) , 2011 IEEE International Conference on.IEEE, 2011:3607–3613.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ORB-SLAM2:An open-source SLAM system for monocular,stereo,and RGB-D cameras">

                                <b>[15]</b> R MUR-ARTAL, J D TARDÓS.ORB-SLAM2:An Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras[J].IEEE Transactions on Robotics, IEEE, 2017.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sliding window filter based unknown object pose estimation">

                                <b>[16]</b> J R SONG.Sliding window filter based unknown object pose estimation[C].Image Processing (ICIP) , 2017 IEEE International Conference on.IEEE, 2017.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=State Estimation for Robotics">

                                <b>[17]</b> T D BARFOOT.State Estimation for Robotics[M].Cambridge:Cambridge University Press, 2017:325-329.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201904044" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201904044&amp;v=MTU1NjR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6aFVydkJMejdCZExHNEg5ak1xNDlCWUlRS0RIODQ=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
