<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139247996068750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201910049%26RESULT%3d1%26SIGN%3dyqRtmrmLsIsnDAgptWPeLcaLaMM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201910049&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201910049&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201910049&amp;v=MTk5NTR6cXFCdEdGckNVUjdxZlp1WnBGeS9tVkxySkx6N0JkTEc0SDlqTnI0OUJiWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#35" data-title="&lt;b&gt;2 SURF特征提取与匹配&lt;/b&gt; "><b>2 SURF特征提取与匹配</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#36" data-title="&lt;b&gt;2.1 特征点提取&lt;/b&gt;"><b>2.1 特征点提取</b></a></li>
                                                <li><a href="#43" data-title="&lt;b&gt;2.2 SURF尺度空间与特征点描述&lt;/b&gt;"><b>2.2 SURF尺度空间与特征点描述</b></a></li>
                                                <li><a href="#49" data-title="&lt;b&gt;2.3 特征点匹配&lt;/b&gt;"><b>2.3 特征点匹配</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#57" data-title="&lt;b&gt;3 误匹配剔除算法&lt;/b&gt; "><b>3 误匹配剔除算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="&lt;b&gt;3.1 最小距离阈值法&lt;/b&gt;"><b>3.1 最小距离阈值法</b></a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;3.2 RANSAC算法&lt;/b&gt;"><b>3.2 RANSAC算法</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;3.3 融合误匹配剔除算法&lt;/b&gt;"><b>3.3 融合误匹配剔除算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#80" data-title="&lt;b&gt;4 实验及分析&lt;/b&gt; "><b>4 实验及分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#92" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="&lt;b&gt;图1 9&#215;9框式滤波器模板&lt;/b&gt;"><b>图1 9×9框式滤波器模板</b></a></li>
                                                <li><a href="#45" data-title="&lt;b&gt;图2 SIFT和SURF的图像金字塔&lt;/b&gt;"><b>图2 SIFT和SURF的图像金字塔</b></a></li>
                                                <li><a href="#48" data-title="&lt;b&gt;图3 特征描述向量&lt;/b&gt;"><b>图3 特征描述向量</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;图4 融合剔除算法步骤&lt;/b&gt;"><b>图4 融合剔除算法步骤</b></a></li>
                                                <li><a href="#82" data-title="&lt;b&gt;图5 相邻的两帧图像&lt;/b&gt;"><b>图5 相邻的两帧图像</b></a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;图6 初始匹配结果&lt;/b&gt;"><b>图6 初始匹配结果</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;图7 最小距离法剔除误匹配&lt;/b&gt;"><b>图7 最小距离法剔除误匹配</b></a></li>
                                                <li><a href="#87" data-title="&lt;b&gt;图8 RANSAC剔除误匹配&lt;/b&gt;"><b>图8 RANSAC剔除误匹配</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;图9 本文算法剔除误匹配&lt;/b&gt;"><b>图9 本文算法剔除误匹配</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;表1 实验结果&lt;/b&gt;"><b>表1 实验结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 赵璐璐,等.基于SURF和快速近似最近邻搜索的图像匹配算法[J].计算机应用研究,2013,30(3):921-923." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201303075&amp;v=MTg3NTZxQnRHRnJDVVI3cWZadVpwRnkvbVZMckpMejdTWkxHNEg5TE1ySTlDWVlRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         赵璐璐,等.基于SURF和快速近似最近邻搜索的图像匹配算法[J].计算机应用研究,2013,30(3):921-923.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 陈洁,等.引入极线约束的SURF特征匹配算法[J].中国图象图形学报,2016,21(8):1048-1056." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201608009&amp;v=MTE4NDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L21WTHJKUHlyZmJMRzRIOWZNcDQ5RmJZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         陈洁,等.引入极线约束的SURF特征匹配算法[J].中国图象图形学报,2016,21(8):1048-1056.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 齐乃新,等.一种对错误匹配点鲁棒的多单应矩阵估计方法[J].机器人,2017,39(5):608-619." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201705004&amp;v=MDQ5NjZxZlp1WnBGeS9tVkxySkx6elpmTEc0SDliTXFvOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         齐乃新,等.一种对错误匹配点鲁棒的多单应矩阵估计方法[J].机器人,2017,39(5):608-619.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 常青,张斌,邵金玲.基于SIFT和RANSAC的特征图像匹配方法[J].华东理工大学学报,2012,38(6):747-751." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HLDX201206018&amp;v=MDczNzZWTHJKTFNIUGRyRzRIOVBNcVk5RWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L20=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         常青,张斌,邵金玲.基于SIFT和RANSAC的特征图像匹配方法[J].华东理工大学学报,2012,38(6):747-751.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 雷玉珍,等.基于随机抽样一致算法的误匹配标志点校正方法[J].光学学报,2013,33(3):205-212." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201303030&amp;v=MTM5MzFNckk5R1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L21WTHJKSWpYVGJMRzRIOUw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         雷玉珍,等.基于随机抽样一致算法的误匹配标志点校正方法[J].光学学报,2013,33(3):205-212.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" L Moisan,P Moulon,P Monasse.Automatic Homographic Registration of a Pair of Images,with A Contrario Elimination of Outliers[J].Image Processing on Line,2012-2:329-352." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic Homographic Registration of a Pair of Images, with A Contrario Elimination of Outliers">
                                        <b>[6]</b>
                                         L Moisan,P Moulon,P Monasse.Automatic Homographic Registration of a Pair of Images,with A Contrario Elimination of Outliers[J].Image Processing on Line,2012-2:329-352.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" W Aguilar,et al.A robust Graph Transformation Matching for non-rigid registration[J].Image &amp;amp; Vision Computing,2009,27(7):897-910." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201349086&amp;v=MjYzMDhKMTBUYnhNPU5pZk9mYks3SHRET3JZOUVaKzhHREhRL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJqSQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         W Aguilar,et al.A robust Graph Transformation Matching for non-rigid registration[J].Image &amp;amp; Vision Computing,2009,27(7):897-910.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 刘川熙,等.基于RANSAC的SIFT匹配阈值自适应估计[J].计算机科学,2017,44(s1):157-160." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2017S1036&amp;v=MTY5NDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkvbVZMckpMejdCYjdHNEg5YXZybzlHWW9RS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         刘川熙,等.基于RANSAC的SIFT匹配阈值自适应估计[J].计算机科学,2017,44(s1):157-160.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 程德志,李言俊,余瑞星.基于改进SIFT算法的图像匹配方法[J].计算机仿真,2011,28(7):285-289." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201107070&amp;v=MzI0MzlHRnJDVVI3cWZadVpwRnkvbVZMckpMejdCZExHNEg5RE1xSTlDWklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         程德志,李言俊,余瑞星.基于改进SIFT算法的图像匹配方法[J].计算机仿真,2011,28(7):285-289.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 童莹,张宴.双重检测策略耦合PROSAC技术的图像匹配算法[J].计算机工程与设计,2017,(11):3137-3142." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201711043&amp;v=MjQ2MjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L21WTHJKTmlmWVpMRzRIOWJOcm85Qlo0UUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         童莹,张宴.双重检测策略耦合PROSAC技术的图像匹配算法[J].计算机工程与设计,2017,(11):3137-3142.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" H Bay,et al.Speeded-Up Robust Features[J].Computer Vision &amp;amp; Image Understanding,2008,110(3):404-417." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083888&amp;v=MTEzMjNpclJkR2VycVFUTW53WmVadEZpbmxVcmpJSjEwVGJ4TT1OaWZPZmJLN0h0RE5xbzlFWk9NTUJIUXhvQk1UNlQ0UFFILw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         H Bay,et al.Speeded-Up Robust Features[J].Computer Vision &amp;amp; Image Understanding,2008,110(3):404-417.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" >
                                        <b>[12]</b>
                                     D G Lowe.Object Recognition from Local Scale-Invariant Features[C].IEEE International Conference on Computer Vision.IEEE,2002:1150.</a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" R Kalia,et al.An analysis of the effect of different image preprocessing techniques on the performance of SURF:Speeded Up Robust Features[C].Frontiers of Computer Vision.IEEE,2011:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An analysis of the effect of different image preprocessing techniques on the performance of SURF:Speeded Up Robust Features">
                                        <b>[13]</b>
                                         R Kalia,et al.An analysis of the effect of different image preprocessing techniques on the performance of SURF:Speeded Up Robust Features[C].Frontiers of Computer Vision.IEEE,2011:1-6.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Computer Vision Group-Datasets-RGB-D SLAM Dataset and Benchmark[DB].https://vision.in.tum.de/data/datasets/rgbd-dataset." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Computer Vision Group-Datasets-RGB-D SLAM Dataset and Benchmark[DB]">
                                        <b>[14]</b>
                                         Computer Vision Group-Datasets-RGB-D SLAM Dataset and Benchmark[DB].https://vision.in.tum.de/data/datasets/rgbd-dataset.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(10),233-237             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于随机抽样一致性的误匹配剔除方法研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%96%87%E5%BD%AC&amp;code=38229517&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李文彬</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E7%92%87&amp;code=10762846&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘璇</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%BB%BA%E7%95%85&amp;code=07085513&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张建畅</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%BB%BA%E5%8D%8E&amp;code=07084155&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张建华</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8C%97%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E6%9C%BA%E6%A2%B0%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0149979&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河北工业大学机械工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对图像特征在匹配过程中产生误匹配、漏匹配的问题,对SURF算法与误匹配剔除算法进行了相关的研究。提出最小距离与随机抽样一致性(RANSAC)两种方法相融合的误匹配消除算法。算法首先通过设置适当阈值的最小距离法对特征之间的匹配进行粗略的淘汰,然后利用优化了的RANSAC对其进行精确的剔除。最后,从数据集中的随机选取两帧图像对算法进行了实验验证,表明提出的算法提高了误匹配剔除的效率的同时,保持了正确匹配的数量。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征匹配;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A0%E9%80%9F%E9%B2%81%E6%A3%92%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">加速鲁棒特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%AF%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">误匹配;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%8F%E6%9C%BA%E6%8A%BD%E6%A0%B7%E4%B8%80%E8%87%B4%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">随机抽样一致性;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李文彬(1991-),男(汉族),河南许昌人,硕士研究生,主要研究领域为视觉SLAM。;
                                </span>
                                <span>
                                    刘璇(1980-),女(汉族),河北秦皇岛人,讲师,主要研究领域为智能机器人技术。;
                                </span>
                                <span>
                                    张建畅(1964-),男(汉族),河北深州人,教授,博士研究生导师,主要研究领域为智能机器人技术。;
                                </span>
                                <span>
                                    张建华(1979-),男(汉族),河北邯郸人,教授,硕士研究生导师,主要研究领域为智能机器人技术、视觉SLAM。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-24</p>

                    <p>

                            <b>基金：</b>
                                                        <span>河北省杰出青年科学基金(F2017202062);</span>
                    </p>
            </div>
                    <h1><b>Mismatching Culling Algorithm Based on Minimum Distance and RANSAC Fusion</b></h1>
                    <h2>
                    <span>LI Wen-bin</span>
                    <span>LIU Xuan</span>
                    <span>ZHANG Jian-chang</span>
                    <span>ZHANG Jian-hua</span>
            </h2>
                    <h2>
                    <span>School of Mechanical Engineering,Hebei University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problem of mismatching and missing matching in the matching process of image features, SURF algorithm and mismatch elimination algorithm were studied. On this basis, a mismatch elimination algorithm based on the two methods of minimum distance and random sampling consistency(RANSAC) was proposed. First, the algorithm was used to eliminate the matching between features by setting the minimum distance method of the appropriate threshold, and then the optimized RANSAC was used to eliminate it accurately. Finally, the algorithm was tested through random selection of two frame images from the data set. It shows that the algorithm proposed in this paper improves the efficiency of mismatch rejection and keeps the number of correct matching.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Feature%20matching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Feature matching;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SURF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SURF;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Mis-matching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Mis-matching;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Random%20sample%20consensus(RANSAC)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Random sample consensus(RANSAC);</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-07-24</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="31" name="31" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="32">图像匹配技术在日常生活的相关领域中已经得到了广泛应用,如图像融合、三维重建、虚拟现实、目标识别、遥感图像技术等<citation id="94" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。在图像匹配的过程中,由于现实环境中总存在一些相似的特征,进行特征匹配时会产生不同数量的误匹配。而快速准确地获得高精度的匹配是进行位姿估计、图像配准、图像检索等应用的前提和关键。因此,在图像之间的特征点进行匹配后,如何减少误匹配的数量和提高剔除误匹配算法的运行速度在实际应用中至关重要。</p>
                </div>
                <div class="p1">
                    <p id="33">在剔除误匹配的过程中的相关技术主要有极线约束<citation id="95" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、单应性约束<citation id="96" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等。其中,在极线约束技术中的随机抽样一致性算法<citation id="97" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>在剔除误匹配中得到了广泛的应用<citation id="98" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。近年来,Moisan等人<citation id="99" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了优化的RANSAC算法,该算法有效地降低了计算剔除模型时采集数据的随机性且能够提高匹配关系的质量。Aguilar等人<citation id="100" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>通过在匹配关系中计算出最近邻图的邻接矩阵不断的迭代来消除误匹配,计算较复杂。刘川熙等人<citation id="101" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出自适应阈值的方法从特征匹配的过程选择最优阈值来降低误匹配,该方法从匹配产生的源头来降低误匹配。程德志等人<citation id="102" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>利用准欧式距离来提高图像匹配效率和准确率。童莹等人<citation id="103" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出渐进抽样一致性(PROSAC)算法,对图像之间的匹配点对的质量进行的排序,有效地节省了计算量。但是这些方法在剔除误匹配的过程中,容易减少正确匹配的数量并且较高的计算成本降低了在应用中的实时性。</p>
                </div>
                <div class="p1">
                    <p id="34">本文针对SURF算法对相邻两帧图像进行的特征提取和匹配产生的误匹配问题提出采用融合剔除算法对其进行淘汰。该算法主要采用较大阈值的最小距离法对初始匹配集进行初步的筛选;然后,采用改进了的RANSAC算法对匹配集中的错误匹配进行进一步的淘汰。其中,对初步剔除后的匹配集中正确的匹配数的比例得到很大的提升,RANSAC算法在寻找最优模型时随机抽取正确的匹配关系的概率得到了提高,因此可以减少了迭代的次数,并且在寻找模型时对其进行了验证,减少了错误模型对内点的计算,提高了算法的运行速度和匹配的数量和质量。</p>
                </div>
                <h3 id="35" name="35" class="anchor-tag"><b>2 SURF特征提取与匹配</b></h3>
                <h4 class="anchor-tag" id="36" name="36"><b>2.1 特征点提取</b></h4>
                <div class="p1">
                    <p id="37">SURF算法<citation id="104" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>是通过黑塞矩阵的判别式来计算特征值,其中黑塞尔矩阵由函数的二阶偏导组成,如式(1)所示。如果要计算式(1)中的<i>L</i><sub><i>xx</i></sub>、<i>L</i><sub><i>xy</i></sub>、<i>L</i><sub><i>yy</i></sub>三个元素,则需要使用特定核函数间的卷积计算二阶偏导数并使用高斯函数作为滤波器。</p>
                </div>
                <div class="p1">
                    <p id="38" class="code-formula">
                        <mathml id="38"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>σ</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>σ</mi><mo stretchy="false">)</mo></mtd><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>σ</mi><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>σ</mi><mo stretchy="false">)</mo></mtd><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>y</mi><mi>y</mi></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>σ</mi><mo stretchy="false">)</mo></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="39">为了降低高斯卷积运算过程中成本,Lowe等人<citation id="105" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出了采用高斯差分算法来代替拉普拉斯算法。而Bay等人<citation id="106" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出的采用如图1所示的框式滤波器来对图像进行卷积计算,计算之后分别用<i>D</i><sub><i>xx</i></sub>,<i>D</i><sub><i>yy</i></sub>和<i>D</i><sub><i>xy</i></sub>代替<i>L</i>在<i>x</i>,<i>y</i>,<i>xy</i>三个方向的近似值。因此,<i>H</i>矩阵的行列式的判别式的近似计算可以表示为式(2)</p>
                </div>
                <div class="p1">
                    <p id="40" class="code-formula">
                        <mathml id="40"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>det</mi><mo stretchy="false">(</mo><mi>Η</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>p</mi><mi>p</mi><mi>r</mi><mi>o</mi><mi>x</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msub><mi>D</mi><msub><mrow></mrow><mrow><mi>y</mi><mi>y</mi></mrow></msub><mo>-</mo><mo stretchy="false">(</mo><mi>ω</mi><mi>D</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="41">其中,<i>det</i> (<i>H</i><sub><i>approx</i></sub>)代表了在点 <i>x</i> 附近区域的框式滤波响应值的近似结果,该结果可作为判断该点是否被选为特征点的理论依据。<i>ω</i>是一个协调系数,通常在图像处理的实际应用中取0.9比较合理。</p>
                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910049_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 9&#215;9框式滤波器模板" src="Detail/GetImg?filename=images/JSJZ201910049_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 9×9框式滤波器模板</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910049_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="43" name="43"><b>2.2 SURF尺度空间与特征点描述</b></h4>
                <div class="p1">
                    <p id="44">在模式识别领域中,图像的尺度空间是对一幅图像在不同的解析度下,对不同层的图像函数与高斯函数进行反复的卷积计算的表示,这种处理的方法被象征性的称为图像金字塔。在<i><b>SIFT</b></i>特征检测算法中,构建的多尺度空间是多层的,并且每个层中有几张尺度不同的图片,不同层的图像都是经过降采样得到的,然后对其采用尺寸相同但尺度不同的高斯内核函数在不同的方向上进行卷积计算形成尺度空间函数。这样使每一组图像都需要依赖上一组图像,因此,在不断进行降采样的时候需要比较大的计算量,这样在特征检测中需要花费更长的时间。而<i><b>SURF</b></i>算法中的图像金字塔没有降采样的过程,其图片一直保持原始尺寸不变,而不同层的图片是通过不同大小的高斯模板处理得到的,并且在同一层中的几张图片进行模糊处理时也需要尺度不同的模板函数。该算法因为尺度空间不同层的图像没有相互依赖的降采样的过程,因此允许对不同层的图像同时处理,提高了特征检测和提取的速度。<i><b>SIFT</b></i>算法中的图像金字塔是通过对图像连续降采样建立的结构,并且为了消除图像中的噪音,不断的使用高斯模板对其进行平滑处理。而<i><b>SURF</b></i>算法改变的是高斯滤波器的大小,保持的是原始图片的尺寸不发生改变。<i><b>SIFT</b></i>和<i><b>SURF</b></i>的图像金字塔结构如图<b>2</b>所示。</p>
                </div>
                <div class="area_img" id="45">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910049_045.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 SIFT和SURF的图像金字塔" src="Detail/GetImg?filename=images/JSJZ201910049_045.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 SIFT和SURF的图像金字塔</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910049_045.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="46">为了保证图像中的特征具有旋转不变性的特性,在<i>SURF</i>中以关键点为中心,半径为<b>6</b><i>s</i>(其中<i>s</i>为特征点所在图像金字塔中的尺度值)的特定区域内,统计<b>60</b>度扇形处于每一个角度时,该扇形中的图像点在<i>x</i>和<i>y</i>方向的<i>Haar</i>小波响应值的总和,并给这些响应值设置高斯权重系数,根据响应与特征点的距离来确定其贡献的大小;然后以<b>60</b>度扇形区域内的响应矢量相加以形成新的矢量,以递增的形式遍历整个圆形区域,通过比较矢量的长度来确定特征点主方向。这样,就可以确定不同视角的图像中每一个特征点在环境中的主方向。</p>
                </div>
                <div class="p1">
                    <p id="47">在确定特征点的主方向后,就可以根据局部区域进行特征描述子的计算。在<i>SURF</i>中,首先以特征点为中心取一个<b>20</b><i>s</i>×<b>20</b><i>s</i>的方框。该框的方向作为检测出的特征的主方向,方框的区域分成<b>4×4</b>个矩形区域,在每一个子矩形区域中统计<b>25</b>个像素在<i>dx</i>、<i>dy</i>方向的<i>Haar</i>小波响应的分量。在构建特征向量之前,需要用高斯模板函数对每一个矩形区域中的dx、dy方向进行加权。然后,在每个矩形区域中对dx、|dx|、dy、|dy|求和,从而得到V=(∑dx,∑|dx|,∑dy,∑|dy|)的<b>4</b>维向量。最后,把每个矩形区域的<b>4</b>维向量按照一定的规则连接起来就能得到一个特征点的<b>64</b>维特征向量,如图<b>3</b>所示。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910049_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 特征描述向量" src="Detail/GetImg?filename=images/JSJZ201910049_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 特征描述向量</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910049_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="49" name="49"><b>2.3 特征点匹配</b></h4>
                <div class="p1">
                    <p id="50">在得到图像特征点的向量后,通常采用特征向量之间的相似性作为不同视角下图像特征之间匹配是否成功的判断依据。<i><b>SURF</b></i>算法则是通过欧氏距离的大小作为判断特征向量之间相似度的衡量标准,其距离越小则表示对应的特征点之间的相似度越高。</p>
                </div>
                <div class="p1">
                    <p id="51">相邻两帧图像的特征点的集合分别记为<b>X</b>和<b>Y</b></p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>X</mi><mo>=</mo><mrow><mo>{</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>n</mi></mrow><mo>}</mo></mrow></mtd></mtr><mtr><mtd><mi>Y</mi><mo>=</mo><mrow><mo>{</mo><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>m</mi></mrow><mo>}</mo></mrow></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">因此两个特征点<b>x</b><sub><b>i</b></sub>和<b>y</b><sub><b>i</b></sub>的欧氏距离可由(<b>3</b>)计算为</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msqrt><mrow><mo stretchy="false">(</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>-</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mi>Τ</mi></msup><mo stretchy="false">(</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>-</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo stretchy="false">)</mo></mrow></msqrt><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">其中,<b>D</b><sub><b>xi</b></sub>、<b>D</b><sub><b>yi</b></sub>分别为特征点<b>x</b><sub><b>i</b></sub>、<b>y</b><sub><b>i</b></sub>的特征向量。</p>
                </div>
                <div class="p1">
                    <p id="56">匹配时,计算图像中的特征点<b>x</b><sub><b>i</b></sub>对应的特征向量<b>D</b><sub><b>xi</b></sub>与另一幅图像中的所有向量之间的欧氏距离,选取距离最小且满足一定阈值的对应关系作为两点的匹配。</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag"><b>3 误匹配剔除算法</b></h3>
                <div class="p1">
                    <p id="58">图像匹配过程中采集的图像受场景复杂度和光照等因素的影响,并且特征点在检测和描述过程中都会受外界因素的影响存在一定的误差。因此,即使在不同视角上的同一区域的两帧图像之间在进行特征匹配时也会产生一定数量的误匹配。本研究在欧氏距离进行匹配的前提下,针对最小距离阈值法和<i>RANSAC</i>算法在剔除误匹配过程中存在的问题,提出了两者相融合的误匹配剔除算法。该算法主要首先对初始匹配集中的误匹配进行粗略的剔除,然后进一步对误匹配进行精确的剔除。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59"><b>3.1 最小距离阈值法</b></h4>
                <div class="p1">
                    <p id="60">最小距离阈值法通过计算图像之间的所有匹配对之间的距离,当匹配对满足式(<b>4</b>),则该匹配为正确的匹配;否则剔除该匹配。该方法主要是通过设定不同的阈值来达到剔除误匹配的不同效果。该算法具有原理简单,运行速度快的优点,但当阈值设置不当的情况下,容易产生大量正确的匹配关系被淘汰的结果且剔除后匹配数量可能不足以满足应用的后果。</p>
                </div>
                <div class="p1">
                    <p id="61" class="code-formula">
                        <mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo>&lt;</mo><mi>α</mi><mi>D</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="62">式中,D<sub>i</sub>—第i个匹配对中特征向量的距离;</p>
                </div>
                <div class="p1">
                    <p id="63">D<sub><i>min</i></sub>—初始匹配集中匹配对的最小距离;</p>
                </div>
                <div class="p1">
                    <p id="64">α—设定的阈值。</p>
                </div>
                <h4 class="anchor-tag" id="65" name="65"><b>3.2 RANSAC算法</b></h4>
                <div class="p1">
                    <p id="66">在图像之间的特征点的对应关系已知的情况下,可以计算出图像之间的相对变换关系,即u’=Hu,如式(<b>5</b>)。相对变换矩阵H有<b>8</b>个自由度可以通过<b>4</b>对相对应的特征点对其进行计算求解</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mtable><mtr><mtd><msup><mi>x</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><msup><mi>y</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>)</mo></mrow><mo>=</mo><mrow><mo>(</mo><mrow><mtable><mtr><mtd><mi>h</mi><msub><mrow></mrow><mn>1</mn></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mn>2</mn></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mn>3</mn></msub></mtd></mtr><mtr><mtd><mi>h</mi><msub><mrow></mrow><mn>4</mn></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mn>5</mn></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mn>6</mn></msub></mtd></mtr><mtr><mtd><mi>h</mi><msub><mrow></mrow><mn>7</mn></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mn>8</mn></msub></mtd><mtd><mi>h</mi><msub><mrow></mrow><mn>9</mn></msub></mtd></mtr></mtable></mrow><mo>)</mo></mrow><mspace width="0.25em" /><mrow><mo>(</mo><mrow><mtable><mtr><mtd><mi>x</mi></mtd></mtr><mtr><mtd><mi>y</mi></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>)</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">其中:(x,y)—第K-<b>1</b>帧图像上的特征点 ;(x',y')—第K帧图像上与(x,y)相对应的特征点。</p>
                </div>
                <div class="p1">
                    <p id="69">利用特征点之间的正确对应关系得到图像之间变化的运动模型,通过判断匹配关系是否满足u’=Hu来进行图像之间的误匹配淘汰。通过Hu计算出第K-<b>1</b>帧图像的特征点转换到在第K帧图像上的位置,并计算在第K帧图像中与之对应特征点的误差,通过判断该误差是否小于设定的阈值来进行误匹配的消除。</p>
                </div>
                <div class="p1">
                    <p id="70"><i>RANSAC</i>算法是对带有噪声的数据进行处理的算法,通过不断的迭代来估计出最优数据模型的参数。该算法能够有效的从带有噪声的数据中找出被模型描述的内点数据和偏离模型正常范围的外点数据。这里的外点即为误匹配数据,内点数据为正确的匹配,所以应通过不断的迭代得到最优模型以得到更多的内点。<i>RANSAC</i>在剔除误匹配中的步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="71">步骤<b>1</b>:通过数据集中的第<i>K</i>-<b>1</b>帧与第<i>K</i>帧图像中的特征向量之间的相似性获得图像之间特征点的对应关系,即初始匹配集数据<i>O</i>;</p>
                </div>
                <div class="p1">
                    <p id="72">步骤<b>2</b>:随机从初始匹配集<i>O</i>中选取<b>4</b>对匹配点的数据,利用选取的数据计算初始匹配集<i>O</i>中的模型,即为相对变换的矩阵<i>H</i>;</p>
                </div>
                <div class="p1">
                    <p id="73">步骤<b>3</b>:通过计算得出的剔除误匹配模型中的相对变换矩阵<i>H</i>来判断初始匹配集中那些匹配符合该模型,即为内点,并统计该模型中内点的数量;</p>
                </div>
                <div class="p1">
                    <p id="74">步骤<b>4</b>:设定迭代次数<i>n</i>,对步骤<b>2</b>和步骤<b>3</b>进行迭代,将所得内点数最多的迭代结果作为最终剔除误匹配之后的正确匹配结果。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>3.3 融合误匹配剔除算法</b></h4>
                <div class="p1">
                    <p id="76">考虑到在估计机器人运动过程中需要采集图像的帧数、特征的数量和特征的对应关系,有必要考虑实时性和匹配的准确性的问题。</p>
                </div>
                <div class="p1">
                    <p id="77">在最小距离阈值法进行误匹配的剔除过程存在的主要缺陷是:当选择比较小的阈值时,剔除误匹配后的匹配数量会急剧地减少,并且其中可能还会存在误匹配。对于<i>RANSAC</i>算法的实现过程中,该算法每次的循环都需要为计算误匹配剔除模型随机选取<b>4</b>对匹配点,并且需要判断匹配集中的每一对特征点是否满足该模型,这样反复的判断过程会耗费很多的时间和内存。这里针对最小距离阈值法和<i>RANSAC</i>算法存在的问题进行改进。对误匹配剔除这个阶段主要分为两个步骤:首先用设置较大阈值的最小距离法对初始匹配集进行粗略的筛选;然后,采用改进了的<i>RANSAC</i>算法对匹配集中的错误匹配进行进一步的淘汰,即在<i>RANSAC</i>算法随机抽取样本进行计算最优模型时,可以减少迭代次数同时对样本模型的正确性进行验证,减少用错误的模型对匹配关系进行内点计算。</p>
                </div>
                <div class="p1">
                    <p id="78">对于融合后的提出误匹配的算法步骤如图<b>4</b>所示。首先采用阈值为<b>4</b>的最小距离法对初始匹配集<i>O</i>进行粗略的误匹配剔除得到匹配集<i>O</i><sub><b>1</b></sub>,然后利用改进的<i>RANSAC</i>算法从初步淘汰过的匹配集<i>O</i><sub><b>1</b></sub>中随机选取<b>5</b>对匹配,其中<b>4</b>对用于计算匹配点相对应的模型中的相对变换矩阵<i>H</i>,剩余<b>1</b>对匹配关系用来验证模型中的矩阵<i>H</i>的正确性。当矩阵<i>H</i>不满足匹配关系时,就淘汰该模型,减少匹配集<i>O</i><sub><b>1</b></sub>中其它匹配对的在其中的内点判断。再者,匹配集<i>O</i><sub><b>1</b></sub>是经过剔除误匹配得到的,其中相对来说有比较少的误匹配,因此可以减少对<i>RANSAC</i>算法步骤四中的迭代次数,在这里选取的次数为原来的<b>1/3</b>,即<i>s</i>=<i>n</i>/<b>3</b>。</p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910049_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 融合剔除算法步骤" src="Detail/GetImg?filename=images/JSJZ201910049_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 融合剔除算法步骤</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910049_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="80" name="80" class="anchor-tag"><b>4 实验及分析</b></h3>
                <div class="p1">
                    <p id="81">实验平台采用<b>Windows7</b>操作系统、<b>Intel(R)Core(TM)i5-2450M CPU @ 2.50GHz、4GB</b>内存,编程环境是<b>Visual Studio2013</b>,并且加入了<b>OpenCV2.4.10</b>的开源库。为了更好对本文提出的融合剔除误匹配算法的验证,采用慕尼黑大学用摄像机采集的图像序列<b>fr1/room</b>数据集<citation id="107" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup><sup><b>14</b></sup><sup>]</sup></citation>,其中采集图像的帧率为<b>30fps</b>,像素大小为<b>640×480</b>。这里采用图像集中的第<b>K-1</b>帧和第<b>K</b>帧图像进行误匹配剔除实验,分别如图<b>5(a)、(b</b>)所示。</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910049_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 相邻的两帧图像" src="Detail/GetImg?filename=images/JSJZ201910049_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 相邻的两帧图像</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910049_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="83"><b>SURF</b>特征通过特征向量的相似性进行匹配的初始结果如图<b>6</b>所示。其中不同颜色的圆点代表图像之间进行特征匹配的特征点,图像之间的直线表示的是匹配后的特征的对应关系;由于图像的采集是经过旋转之间图中平行的线代表正确的匹配,交叉的线代表错误的匹配。图<b>6</b>的初始匹配结果表明图像之间的特征点会因各种原因产生错误的匹配。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910049_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 初始匹配结果" src="Detail/GetImg?filename=images/JSJZ201910049_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 初始匹配结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910049_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="85">采用最小距离阈值法和随机采样一致法进行误匹配的结果分别如图<b>7</b>和图<b>8</b>所示。从图<b>6</b>与图<b>7</b>可以看出最小距离法可以有效的减少无匹配的对数。当阈值设置为<b>4</b>时,匹配对数从初始的<b>795</b>降到<b>403</b>,但仍然存在大量的误匹配;阈值设置为<b>2</b>时,匹配对数为<b>47</b>,运行时间为<b>15.3μs</b>。最小距离算法可以有效地降低匹配中误匹配的数量,但匹配的总数量也会急剧下降。图<b>8</b>为采用<b>RANSAC</b>算法是通过寻找最优模型进行剔除误匹配后的匹配对数为<b>126</b>,有效地保证了剔除之后匹配的数量,但在剔除误匹配的过程中花费的时间为<b>89.56ms</b>。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910049_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 最小距离法剔除误匹配" src="Detail/GetImg?filename=images/JSJZ201910049_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 最小距离法剔除误匹配</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910049_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910049_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 RANSAC剔除误匹配" src="Detail/GetImg?filename=images/JSJZ201910049_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图8 RANSAC剔除误匹配</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910049_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="88">本文提出融合的剔除算法采用阈值为<b>4</b>的最小距离与改进的<b>RANSAC</b>对初始匹配中的误匹配进行循序渐进的两次剔除,效果如图<b>9</b>所示。该算法剔除后的匹配对的数量为<b>119</b>,运行的时间为<b>70.58ms</b>。</p>
                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910049_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 本文算法剔除误匹配" src="Detail/GetImg?filename=images/JSJZ201910049_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图9 本文算法剔除误匹配</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910049_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="90">本文主要对最小距离法、<b>RANSAC</b>算法和本文的融合剔除算法在运行时间、正确匹配对数进行了实验对比,如表<b>1</b>所示。实验结果说明提出的算法在运算速度比<b>RANSAC</b>算法快,且正确的匹配对数与之相当;与最小距离法相比有更多的正确的匹配对数。</p>
                </div>
                <div class="area_img" id="91">
                    <p class="img_tit"><b>表1 实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="91" border="1"><tr><td><br />剔除算法</td><td>运行时间</td><td>正确匹配对数</td></tr><tr><td><br />最小距离法</td><td>15.3us</td><td>47</td></tr><tr><td><br />RANSAC</td><td>89.56ms</td><td>126</td></tr><tr><td><br />本文算法</td><td>70.58ms</td><td>119</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="92" name="92" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="93">本文通过SURF算法分析了最小阈值法在误匹配剔除结果中存在正确匹配数量少且还存在少量错误的匹配,同时分析了RANSAC算法在剔除误匹配过程中迭代次数与模型的正确性对运算速度的影响。因此,提出最小距离与RANSAC算法两者相融合的误匹配剔除方法来解决误匹配的效率与正确匹配数量的问题。实验表明,提出的融合剔除误匹配算法与RANSAC算法相比有较快的运算效率,且剔除后的正确匹配的数量多于最小距离阈值法,即该算法在剔除速度和正确匹配数量上进行了折中,能有效地排除误匹配在应用中造成的影响。但提出的融合剔除算法过程中的阈值设置并没有自适应性的特性,这将是以后研究工作中的重点。</p>
                </div>
                <div class="area_img" id="108">
                                <img alt="" src="Detail/GetImg?filename=images/JSJZ201910049_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201303075&amp;v=MDU1MzdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L21WTHJKTHo3U1pMRzRIOUxNckk5Q1k=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 赵璐璐,等.基于SURF和快速近似最近邻搜索的图像匹配算法[J].计算机应用研究,2013,30(3):921-923.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201608009&amp;v=MjE1MzhySlB5cmZiTEc0SDlmTXA0OUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9tVkw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 陈洁,等.引入极线约束的SURF特征匹配算法[J].中国图象图形学报,2016,21(8):1048-1056.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201705004&amp;v=MTYxMTh0R0ZyQ1VSN3FmWnVacEZ5L21WTHJKTHp6WmZMRzRIOWJNcW85RllJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 齐乃新,等.一种对错误匹配点鲁棒的多单应矩阵估计方法[J].机器人,2017,39(5):608-619.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HLDX201206018&amp;v=MDIwODJDVVI3cWZadVpwRnkvbVZMckpMU0hQZHJHNEg5UE1xWTlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 常青,张斌,邵金玲.基于SIFT和RANSAC的特征图像匹配方法[J].华东理工大学学报,2012,38(6):747-751.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201303030&amp;v=MjI5Mjk5TE1ySTlHWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkvbVZMckpJalhUYkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 雷玉珍,等.基于随机抽样一致算法的误匹配标志点校正方法[J].光学学报,2013,33(3):205-212.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic Homographic Registration of a Pair of Images, with A Contrario Elimination of Outliers">

                                <b>[6]</b> L Moisan,P Moulon,P Monasse.Automatic Homographic Registration of a Pair of Images,with A Contrario Elimination of Outliers[J].Image Processing on Line,2012-2:329-352.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012201349086&amp;v=MTY1NDErOEdESFEvb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmpJSjEwVGJ4TT1OaWZPZmJLN0h0RE9yWTlFWg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> W Aguilar,et al.A robust Graph Transformation Matching for non-rigid registration[J].Image &amp; Vision Computing,2009,27(7):897-910.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2017S1036&amp;v=MDQ4MzMzenFxQnRHRnJDVVI3cWZadVpwRnkvbVZMckpMejdCYjdHNEg5YXZybzlHWW9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 刘川熙,等.基于RANSAC的SIFT匹配阈值自适应估计[J].计算机科学,2017,44(s1):157-160.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201107070&amp;v=MzExMTVxcUJ0R0ZyQ1VSN3FmWnVacEZ5L21WTHJKTHo3QmRMRzRIOURNcUk5Q1pJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 程德志,李言俊,余瑞星.基于改进SIFT算法的图像匹配方法[J].计算机仿真,2011,28(7):285-289.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201711043&amp;v=MDQ2MzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9tVkxySk5pZllaTEc0SDliTnJvOUJaNFE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 童莹,张宴.双重检测策略耦合PROSAC技术的图像匹配算法[J].计算机工程与设计,2017,(11):3137-3142.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083888&amp;v=Mjk2NThETnFvOUVaT01NQkhReG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJqSUoxMFRieE09TmlmT2ZiSzdIdA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> H Bay,et al.Speeded-Up Robust Features[J].Computer Vision &amp; Image Understanding,2008,110(3):404-417.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" >
                                    <b>[12]</b>
                                 D G Lowe.Object Recognition from Local Scale-Invariant Features[C].IEEE International Conference on Computer Vision.IEEE,2002:1150.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An analysis of the effect of different image preprocessing techniques on the performance of SURF:Speeded Up Robust Features">

                                <b>[13]</b> R Kalia,et al.An analysis of the effect of different image preprocessing techniques on the performance of SURF:Speeded Up Robust Features[C].Frontiers of Computer Vision.IEEE,2011:1-6.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Computer Vision Group-Datasets-RGB-D SLAM Dataset and Benchmark[DB]">

                                <b>[14]</b> Computer Vision Group-Datasets-RGB-D SLAM Dataset and Benchmark[DB].https://vision.in.tum.de/data/datasets/rgbd-dataset.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201910049" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201910049&amp;v=MTk5NTR6cXFCdEdGckNVUjdxZlp1WnBGeS9tVkxySkx6N0JkTEc0SDlqTnI0OUJiWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
