<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637140153756850000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201908039%26RESULT%3d1%26SIGN%3ddjbMEl%252fguM5kCkcjJZ%252ftTsdXLbg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201908039&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201908039&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201908039&amp;v=MjMzOTN5N25WTC9NTHo3QmRMRzRIOWpNcDQ5R2JZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#23" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;2 多媒体图像连续视觉特征标注&lt;/b&gt; "><b>2 多媒体图像连续视觉特征标注</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#28" data-title="&lt;b&gt;2.1 图像分割&lt;/b&gt;"><b>2.1 图像分割</b></a></li>
                                                <li><a href="#41" data-title="&lt;b&gt;2.2 基于深度特征与语义邻域的图像标注&lt;/b&gt;"><b>2.2 基于深度特征与语义邻域的图像标注</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#79" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#86" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#83" data-title="&lt;b&gt;图1 不同方法图像标注准确性对比&lt;/b&gt;"><b>图1 不同方法图像标注准确性对比</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;图2 不同方法图像标注实时性对比&lt;/b&gt;"><b>图2 不同方法图像标注实时性对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 秦煜, 吴静静, 安伟.基于RANSAC的激光网格标记图像特征提取[J].计算机工程与科学, 2017, 39 (8) :1495-1501." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201708018&amp;v=MDU2MTR6cXFCdEdGckNVUjdxZlp1Wm9GeTduVkwvTUx6N0JaYkc0SDliTXA0OUViSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         秦煜, 吴静静, 安伟.基于RANSAC的激光网格标记图像特征提取[J].计算机工程与科学, 2017, 39 (8) :1495-1501.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 乔良.三维图像视觉下运动关键特征的提取方法改进[J].计算机仿真, 2017, 34 (1) :216-219." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201701051&amp;v=MDIwNTdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5N25WTC9NTHo3QmRMRzRIOWJNcm85QVo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         乔良.三维图像视觉下运动关键特征的提取方法改进[J].计算机仿真, 2017, 34 (1) :216-219.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 熊伟, 徐永力, 崔亚奇, 等.高分辨率合成孔径雷达图像舰船目标几何特征提取方法[J].光子学报, 2018, 47 (1) :49-58." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GZXB201801009&amp;v=MTA5MTVuVkwvTUlqZlRiTEc0SDluTXJvOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeTc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         熊伟, 徐永力, 崔亚奇, 等.高分辨率合成孔径雷达图像舰船目标几何特征提取方法[J].光子学报, 2018, 47 (1) :49-58.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 邱尚明, 李冬睿, 罗拥华.基于互补特征合成的医学图像自动标注[J].控制工程, 2017, 24 (5) :1025-1031." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZDF201705021&amp;v=MzIxMzJPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5N25WTC9NTHpmUGFMRzRIOWJNcW85SFpZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         邱尚明, 李冬睿, 罗拥华.基于互补特征合成的医学图像自动标注[J].控制工程, 2017, 24 (5) :1025-1031.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 杨晓玲, 李志清, 刘雨桐.基于多标签判别字典学习的图像自动标注[J].计算机应用, 2018, 38 (5) :1294-1298." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201805014&amp;v=MDkzNDdmWnVab0Z5N25WTC9NTHo3QmQ3RzRIOW5NcW85RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         杨晓玲, 李志清, 刘雨桐.基于多标签判别字典学习的图像自动标注[J].计算机应用, 2018, 38 (5) :1294-1298.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 曾接贤, 祝小超, 符祥.一种改进的复杂图像线特征提取方法[J].中国图象图形学报, 2018, 15 (12) :1748-1754." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201012007&amp;v=MDg1OThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnk3blZML01QeXJmYkxHNEg5SE5yWTlGWTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         曾接贤, 祝小超, 符祥.一种改进的复杂图像线特征提取方法[J].中国图象图形学报, 2018, 15 (12) :1748-1754.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 任智慧, 徐浩煜, 封松林, 等.基于LSTM网络的序列标注中文分词法[J].计算机应用研究, 2017, 34 (5) :1321-1324." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201705010&amp;v=MDg1MzVFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnk3blZML01MejdTWkxHNEg5Yk1xbzk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         任智慧, 徐浩煜, 封松林, 等.基于LSTM网络的序列标注中文分词法[J].计算机应用研究, 2017, 34 (5) :1321-1324.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 吕钊, 陆雨, 周蚌艳, 等.基于共同空间模式的扫视信号特征提取算法[J].华中科技大学学报 (自然科学版) , 2016, 44 (10) :123-127." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HZLG201610024&amp;v=MDU1MjJmSGFiRzRIOWZOcjQ5SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5N25WTC9NTFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         吕钊, 陆雨, 周蚌艳, 等.基于共同空间模式的扫视信号特征提取算法[J].华中科技大学学报 (自然科学版) , 2016, 44 (10) :123-127.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 刘明, 郝博.航空典型零件快速标注技术[J].工具技术, 2016, 50 (8) :47-50." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GJJS201608016&amp;v=MDU0MDBJaWZCZmJHNEg5Zk1wNDlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnk3blZML00=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         刘明, 郝博.航空典型零件快速标注技术[J].工具技术, 2016, 50 (8) :47-50.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 柯逍, 邹嘉伟, 杜明智, 等.基于蒙特卡罗数据集均衡与鲁棒性增量极限学习机的图像自动标注[J].电子学报, 2017, 45 (12) :2925-2935." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201712014&amp;v=MDc2MzVFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnk3blZML01JVGZUZTdHNEg5Yk5yWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         柯逍, 邹嘉伟, 杜明智, 等.基于蒙特卡罗数据集均衡与鲁棒性增量极限学习机的图像自动标注[J].电子学报, 2017, 45 (12) :2925-2935.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(08),191-194             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>数字式多媒体图像连续视觉特征标注仿真研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%A7%9A%E6%96%87%E5%A9%B7&amp;code=40317290&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">姚文婷</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B1%9F%E8%8F%B2%E9%A3%9E&amp;code=33348065&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">江菲飞</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E8%89%BA%E6%9C%AF%E4%B8%8E%E4%BC%A0%E5%AA%92%E5%AD%A6%E9%99%A2&amp;code=0201951&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安工业大学艺术与传媒学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%99%95%E8%A5%BF%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%89%BA%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0034048&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陕西科技大学设计与艺术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对当前图像标注方法存在准确性低和实时性差的问题, 提出基于深度特征与语义邻域的数字式多媒体图像连续视觉特征标注方法。根据MS算法将数字式多媒体图像划分成多个图像子块, 计算各图像子块区域间权重值。利用Normalized Cuts分割算法融合各子块区域, 获取图像分割结果。以图像分割为依据, 训练图像语义分组, 并利用逐层卷积与逐层采样法将图像抽象成特征向量, 得到各语义组图像特征。将待标注图像也输入至已经训练好的深度网络, 迭代提取特征步骤, 计算待标注图像与各语义组中全部图像视觉特征相似程度, 同时构建邻域图像集合。采用距离值法判断集合中各个语义标签贡献值, 并对贡献值大小进行排列, 得到预测关键词, 即图像特征标注点, 实现图像特征标注。实验结果表明, 方法标注精度和效率均较高, 具有可行性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%AA%92%E4%BD%93%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多媒体图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E8%A7%89%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">视觉特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A0%87%E6%B3%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">标注;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    姚文婷 (1978-) , 女 (汉族) , 甘肃天水人, 硕士, 副教授, 研究方向:视觉传达设计。;
                                </span>
                                <span>
                                    江菲飞 (1984-) , 女 (汉族) , 陕西西安人, 硕士, 讲师, 研究方向:移动端视觉设计研究。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-13</p>

            </div>
                    <h1><b>Simulation Research on Continuous Visual Feature Labeling of Digital Multimedia Image</b></h1>
                    <h2>
                    <span>YAO Wen-ting</span>
                    <span>JIANG Fei-fei</span>
            </h2>
                    <h2>
                    <span>Art and Media School, Xi'an Technological University</span>
                    <span>College of Art and Design, Shanxi Unversity of Science & Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Due to low accuracy and poor real-time performance of current methods, this article put forward a method to label continuous visual feature of digital multimedia image based on depth feature and semantic neighborhood. According to MS algorithm, the digital multimedia image was divided into several image sub-blocks. The weights between sub-blocks were calculated. Normalized Cuts segmentation algorithm was used to fuse each sub-block region, so that the image segmentation results were obtained. Based on image segmentation, image semantic grouping was trained, and then the image was abstracted into feature vectors by layer-by-layer convolution and layer-by-layer sampling method, so that the image feature of each semantic group was obtained. The image to be labeled was also input into the trained depth network, and the feature steps were extracted iteratively. Moreover, the similarity among all visual features in the image to be labeled and each semantic group was computed. Meanwhile, the neighborhood image set was constructed. The method of distance value was used to judge the contribution value of each semantic label in set. In addition, the contribution values were arranged to get the predictive keyword, that is to say the image feature labeling point. Thus, the image feature labeling was achieved. Simulation results show that the proposed method has high labeling precision and efficiency.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multimedia%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multimedia image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Visual%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Visual feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Labeling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Labeling;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-13</p>
                            </div>


        <!--brief start-->
                        <h3 id="23" name="23" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="24">生活中数码相机和摄像机等数字化技术不断普及, 互联网中数字式多媒体图像逐渐增多, 导致人们很难在大规模图像数据中精准找到需要的信息, 使得图像和视频数据有效管理成为了当前研究热点<citation id="89" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。图像和视频标注检索相关技术是解决上述问题的可行途径, 图像标注是其中的关键环节, 依据图像视觉特性, 利用计算机系统生成与图像相应的标注点。以往的图像标注焦点在于图像整体类别, 更倾向于图像分类, 当前图像标注主要是对图像视觉特征进行标注<citation id="88" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。随着图像标注技术不断精进, 有关专家学者提出了很多优秀成果。</p>
                </div>
                <div class="p1">
                    <p id="25">邱尚明<citation id="90" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等人对于图像配准时精度比较低的问题, 提出基于互补特征合成的图像标注方法。过程中, 利用鲁棒特性、梯度直方图特性处理图像, 同时利用互补特征具备的不确定性融合实现图像特征融合, 设计并构建形状及兴趣点视觉特征描述符;利用深度神经网络分类器实现图像特征点配准, 对于深度神经网络的隐藏层级数比较多, 运行实时性差的问题, 通过Hessian矩阵优化神经网络, 将优化后的网络应用至图像配准中, 完成整个标注过程。实验结果表明, 所提方法实时性较强, 但存在标准精度低的问题。杨晓玲<citation id="91" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等人对于图像标注时底层视觉特征和高层语义间存在的鸿沟, 基于当前字典学习, 提出基于多标签判别字典学习的图像标注方法。过程中, 提取出每幅图像中多种类型特征, 设定多种特征组合为字典学习输入信息;构建标签正则化项, 实现原始图像样本标签信息与输入特征数据融合, 将一致性判别字典与一致性正则化项进行有效结合, 并进行字典学习;利用获取的字典、稀疏编码矩阵得到标签稀疏向量, 完成图像语义标注。利用图像数据集对所提方法进行测试, 实验结果表明, 该方法运行过程相对稳定, 但存在标注实时性差的问题。曾接贤<citation id="92" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等人针对复杂图像特征提取标注问题, 提出改进方法。过程中, 通过小波变换处理图像, 进而凸显图像中细节特性;对于处理之后的图像实行Beamlet变换操作, 获取变换系数集合;阈值化过程中, 定义新能量统计, 并在可视化时规定新划线规则, 将新能量统计和新划线规则结合, 从而保障各二进方块仅能够用一条最优基描述;将所有方块中最优基当作线图像特征提取并标注。实验结果表明, 该方法空间复杂度较低, 但存在准确性差的问题。</p>
                </div>
                <div class="p1">
                    <p id="26">由上述有关图像标注方法可以看出, 当前研究成果性能有待完善, 提出基于深度特征与语义邻域的数字式多媒体图像连续视觉特征标注方法。</p>
                </div>
                <h3 id="27" name="27" class="anchor-tag"><b>2 多媒体图像连续视觉特征标注</b></h3>
                <h4 class="anchor-tag" id="28" name="28"><b>2.1 图像分割</b></h4>
                <div class="p1">
                    <p id="29">为了提升图像视觉特征标注效率, 先对图像进行分割。在此, 提出基于MS-Ncuts的图像分割。</p>
                </div>
                <div class="p1">
                    <p id="30">图像分割过程如下:根据MS算法将图像划分成多个图像子块;计算各图像子块区域间权重值;依据Normalized Cuts分割算法融合各子块区域, 获取图像分割结果。</p>
                </div>
                <div class="p1">
                    <p id="31">利用MS算法获取的图像区域能够通过平面加权区域邻接图G (V, E, W) 描述, 即RAG。其中, RAG中涵盖了图像结构与区域之间存在的连通性。以测量图像中相邻区域间存在的不同为目的, 定义一个适当特征空间, 实现图像分割。因图像中颜色特征较为明显, 比较适合分割目标, 选取颜色空间当作图像分割过程中的特征空间<citation id="93" type="reference"><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>。利用MS算法开展图像分割时, 将图像划分为<i>n</i>个区域<i>R</i><sub><i>i</i></sub>, <i>i</i>=1, 2, …, <i>n</i>, 区域均值向量表示形式为<sub><i>R</i><sub><i>i</i></sub></sub>={<sub>1<i>i</i></sub>, <sub>2<i>i</i></sub>, <sub>3<i>i</i></sub>}, 其中, <sub>1<i>i</i></sub>, <sub>2<i>i</i></sub>, <sub>3<i>i</i></sub>代表第<i>i</i>个图像区域在三维颜色空间中均值像素的强度值。选出适当颜色空间对于图像区域融合十分重要, 在此利用<i>L</i>*<i>U</i>*<i>V</i>当作图像分割颜色空间。</p>
                </div>
                <div class="p1">
                    <p id="32">上述中的LUV是颜色空间中一种标准, 它是依据人类视觉针对颜色感知差别构建的, 主要是将其单位化编码与人类视觉进行统一的颜色空间。因其优势较为明显, 被广泛应用至计算机数字式多媒体图像处理中。因LUV构建的颜色空间和人类视觉为统一的, 由此其中的三个分量不可以简单与其它颜色空间分量进行一一对应。针对数字式多媒体图像而言, L表示亮度, U、V表示色度坐标。利用CIEXYZ非线性计算获取L、U、V公式</p>
                </div>
                <div class="p1">
                    <p id="33" class="code-formula">
                        <mathml id="33"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mn>1</mn><mn>6</mn><mo stretchy="false"> (</mo><mi>Y</mi><mo>/</mo><mi>Y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>3</mn></mrow></msup><mo>-</mo><mn>1</mn><mn>6</mn><mo>, </mo><mi>Y</mi><mo>/</mo><mi>Y</mi><msub><mrow></mrow><mi>n</mi></msub><mo>&gt;</mo><mo stretchy="false"> (</mo><mn>6</mn><mo>/</mo><mn>2</mn><mn>9</mn><mo stretchy="false">) </mo><msup><mrow></mrow><mn>3</mn></msup></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mn>2</mn><mn>9</mn><mo>/</mo><mn>3</mn><mo stretchy="false">) </mo><msup><mrow></mrow><mn>3</mn></msup><mo stretchy="false"> (</mo><mi>Y</mi><mo>/</mo><mi>Y</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><mo>, </mo><mi>Y</mi><mo>/</mo><mi>Y</mi><msub><mrow></mrow><mi>n</mi></msub><mo>≤</mo><mo stretchy="false"> (</mo><mn>6</mn><mo>/</mo><mn>2</mn><mn>9</mn><mo stretchy="false">) </mo><msup><mrow></mrow><mn>3</mn></msup></mtd></mtr></mtable></mrow><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>U</mi><mo>=</mo><mn>1</mn><mn>3</mn><mi>L</mi><mo stretchy="false"> (</mo><msup><mi>u</mi><mo>′</mo></msup><mo>-</mo><msup><mi>u</mi><mo>′</mo></msup><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>V</mi><mo>=</mo><mn>1</mn><mn>3</mn><mi>L</mi><mo stretchy="false"> (</mo><msup><mi>v</mi><mo>′</mo></msup><mo>-</mo><msup><mi>v</mi><mo>′</mo></msup><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="34">式中, <i>u</i>′<sub><i>n</i></sub>、<i>v</i>′<sub><i>n</i></sub>代表色度坐标中一个白点。其中</p>
                </div>
                <div class="p1">
                    <p id="35" class="code-formula">
                        <mathml id="35"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>U</mi><mo>=</mo><mfrac><mrow><mn>4</mn><mi>X</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>X</mi><mo>+</mo><mn>1</mn><mn>5</mn><mi>Y</mi><mo>+</mo><mn>3</mn><mi>Ζ</mi><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>V</mi><mo>=</mo><mfrac><mrow><mn>9</mn><mi>X</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>X</mi><mo>+</mo><mn>1</mn><mn>5</mn><mi>Y</mi><mo>+</mo><mn>3</mn><mi>Ζ</mi><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="36">利用选择的颜色空间, 能够获得图像各个分割子区域权值矩阵<i>W</i>。<i>W</i> (<i>U</i>, <i>V</i>) 代表分割区域<i>U</i>、<i>V</i>权重值。</p>
                </div>
                <div class="p1">
                    <p id="37" class="code-formula">
                        <mathml id="37"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><mo stretchy="false"> (</mo><mi>U</mi><mo>, </mo><mi>V</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>exp</mi><mrow><mo>{</mo><mrow><mo>-</mo><mrow><mo>[</mo><mrow><mfrac><mrow><mrow><mo>|</mo><mrow><mi>F</mi><mo stretchy="false"> (</mo><mi>U</mi><mo stretchy="false">) </mo><mo>-</mo><mi>F</mi><mo stretchy="false"> (</mo><mi>V</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow><mrow><mi>d</mi><msub><mrow></mrow><mi>Ι</mi></msub></mrow></mfrac></mrow><mo>]</mo></mrow></mrow><mo>}</mo></mrow><mo>, </mo><mi>U</mi><mtext>和</mtext><mi>V</mi><mtext>相</mtext><mtext>邻</mtext></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="38">式 (6) 中, <i>F</i> (<i>U</i>) 代表图像子区域颜色向量, <mathml id="39"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mo>⋅</mo><mo>|</mo></mrow><msub><mrow></mrow><mn>2</mn></msub></mrow></math></mathml>代表一个矢量二范数, <i>d</i><sub><i>I</i></sub>代表控制图像颜色敏感度的尺度因子。</p>
                </div>
                <div class="p1">
                    <p id="40">基于上述计算与分析, 区域分组自然转换为图像分割问题。提出的MS-Ncuts图像分割法主要是依据MS分割图像子区域得到的, 不是利用初始图像像素获取的。通过子区域代替像素构建的权值矩阵有以下优势:计算复杂度低;提升了分割性能。尽管利用子区域节点进行图像分割和采用像素节点进行图像分割在运行方案上相同, 但采用MS算法构成的图像子区域节点特征和像素节点的特性相比更加可靠<citation id="94" type="reference"><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="41" name="41"><b>2.2 基于深度特征与语义邻域的图像标注</b></h4>
                <div class="p1">
                    <p id="42">基于2.1节图像分割, 利用语义邻域与深度特征相结合的方式实现图像特征标注。</p>
                </div>
                <div class="p1">
                    <p id="43">深度网络利用逐层抽象特征图关键信息, 逐步减小深度网络复杂程度, 以此抽象出通用的图像特征, 进而使图像特征自适应提取。对图像中视觉相似但是语义相似度较低的像素, 假设在语义上无法进行区分, 则会对图像特征标注造成影响。对于该问题, 先划分语义组设计语义近邻, 然后利用视觉相似度组建视觉近邻, 最终依据距离值判断各个语义标签贡献值, 利用对贡献值顺序进行排列, 实现标签预测。</p>
                </div>
                <div class="p1">
                    <p id="44">利用语义邻域进行图像标注流程如下:</p>
                </div>
                <div class="p1">
                    <p id="45">对图像标注中符号进行定义, 设定<i>I</i>={<i>I</i><sub>1</sub>, <i>I</i><sub>2</sub>, …, <i>I</i><sub><i>N</i></sub>}代表训练图像, <i>N</i>代表训练图像数量。<i>E</i>={<i>e</i><sub>1</sub>, <i>e</i><sub>2</sub>, …, <i>e</i><sub><i>m</i></sub>}代表训练集合中含有的关键词, <i>m</i>代表关键词数量。则图像标注的训练集可表示为Ω={ (<i>I</i><sub>1</sub>, <i>e</i><sub>1</sub>) , …, (<i>I</i><sub><i>N</i></sub>, <i>e</i><sub><i>N</i></sub>) }, </p>
                </div>
                <div class="p1">
                    <p id="46">根据上述定义, 给出图像语义邻域定义, 将各关键词中涵盖的所有图像当作一个语义组, 全部关键词对应的语义集合可表示为</p>
                </div>
                <div class="p1">
                    <p id="47" class="code-formula">
                        <mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mover accent="true"><mi>Ι</mi><mo>˜</mo></mover><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mo>, </mo><mo>⋯</mo><mo>, </mo><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>m</mi></msub><mo>, </mo><mover accent="true"><mi>Ι</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">}</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="48">式 (7) 中, <sub><i>i</i></sub>代表与关键词有关联的所有图像, <sub><i>i</i></sub>⊆<i>I</i>。</p>
                </div>
                <div class="p1">
                    <p id="49">根据以上计算, 将图像标注预测问题转化成求解后验概率问题。假设条件概率为<mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mrow><mo>|</mo><mrow><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></mrow><mo stretchy="false">) </mo></mrow></math></mathml>, 其代表关键词<i>e</i><sub><i>k</i></sub>与图像<i>I</i>概率关系, 则利用概率转换表达式可知, 图像关键词预测值计算公式为</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>|</mo><mi>Ι</mi></mrow><mo stretchy="false">) </mo><mo>=</mo><mi>α</mi><msub><mrow></mrow><mrow><mi>Ι</mi><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mfrac><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mrow><mo>|</mo><mrow><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></mrow><mo stretchy="false">) </mo><mo>⋅</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>⋅</mo><mi>W</mi><mo stretchy="false"> (</mo><mi>U</mi><mo>, </mo><mi>V</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">式 (8) 中, <i>P</i> (<i>e</i><sub><i>k</i></sub>) 、<i>P</i> (<i>I</i>) 代表先验概率, 取值为固定的, 即先验概率取值不会对<mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>|</mo><mi>Ι</mi></mrow><mo stretchy="false">) </mo></mrow></math></mathml>预测值产生很大影响。由此给定一幅待标注的数字式多媒体图像<i>I</i>, 其预测关键词能够利用所有关键词预测值顺序进行排列得到, 则</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>e</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mi>arg</mi><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mi>k</mi></munder><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>|</mo><mi>Ι</mi></mrow><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">依据式 (9) 构建待标注图像邻域图像集合, 设定<i>G</i><sub><i>i</i></sub>= (<i>e</i><sub><i>i</i></sub>, <sub><i>i</i></sub>) 表征关键词<i>e</i><sub><i>i</i></sub>对应语义组, 针对待标注图像<i>I</i>, 由<i>G</i><sub><i>i</i></sub>中筛选出和图像<i>I</i>视觉相似程度最高的<i>k</i>幅图像获取局部子集<i>G</i><sub><i>I</i>, <i>i</i></sub>⊆<i>G</i><sub><i>i</i></sub>, 如果所有语义组局部子集均已得到, 合并子集, 最后获得针对<i>I</i>的邻域图像集合:<i>G</i><sub><i>I</i></sub>=<i>G</i><sub><i>I</i>, 1</sub>∪<i>G</i><sub><i>I</i>, 2</sub>∪…∪<i>G</i><sub><i>I</i>, <i>m</i></sub>⊆<i>G</i>。<i>G</i><sub><i>I</i></sub>中不包含相同图像, 进而避免相同图像冗余计算贡献值。依据式 (8) 可知, 针对<mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>|</mo><mi>Ι</mi></mrow><mo stretchy="false">) </mo></mrow></math></mathml>的计算即转换成计算<mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mrow><mo>|</mo><mrow><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></mrow><mo stretchy="false">) </mo></mrow></math></mathml>。针对给定关键词<i>e</i><sub><i>k</i></sub>∈<i>E</i>, 其和图像<i>I</i>组建的概率关系可表示为</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mrow><mo>|</mo><mrow><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></mrow><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>G</mi><msub><mrow></mrow><mi>Ι</mi></msub><mo stretchy="false">) </mo></mrow></munder><mi>α</mi></mstyle><msub><mrow></mrow><mrow><mi>Ι</mi><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>⋅</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">式 (10) 中, <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">) </mo></mrow></math></mathml>用来控制图像中关键词贡献值是否需要增加, 其表达式为</p>
                </div>
                <div class="p1">
                    <p id="61" class="code-formula">
                        <mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>, </mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mo>∈</mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mo>∉</mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="62">式 (10) 中的<i>α</i><sub><i>I</i>, <i>I</i><sub><i>i</i></sub></sub>代表图像<i>I</i><sub><i>i</i></sub>针对图像<i>I</i>贡献值</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>α</mi><msub><mrow></mrow><mrow><mi>Ι</mi><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>=</mo><mfrac><mi>λ</mi><mrow><mi>λ</mi><mo>+</mo><mi>exp</mi><mo stretchy="false"> (</mo><mi>β</mi><mo>⋅</mo><mi>d</mi><mi>i</mi><mi>s</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">式 (12) 中, <i>λ</i>代表固定常数, 通常取值为1。<i>β</i>代表正整数, 主要用来控制近邻图像的贡献值。<i>dis</i> (<i>I</i>, <i>I</i><sub><i>i</i></sub>) 代表图像<i>I</i><sub><i>i</i></sub>和图像<i>I</i>之间归一化之后视觉距离值, 表达式为</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mi>i</mi><mi>s</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Κ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>G</mi><msub><mrow></mrow><mi>Ι</mi></msub></mrow></munder><mo stretchy="false"> (</mo><mi>Κ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">式 (13) 中, <i>K</i> (<i>I</i>, <i>I</i><sub><i>i</i></sub>) 代表图像中两个特征向量之间距离, 在此使用欧式距离获取。</p>
                </div>
                <div class="p1">
                    <p id="67">综合上述计算, 将式 (10) 和式 (12) 代入式 (8) 中, 则关键词贡献值表达式为</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>|</mo><mi>Ι</mi></mrow><mo stretchy="false">) </mo><mi>Θ</mi><mi>p</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mrow><mo>|</mo><mrow><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></mrow><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>G</mi><msub><mrow></mrow><mi>Ι</mi></msub><mo stretchy="false">) </mo></mrow></munder><mrow><mrow><mo> (</mo><mrow><mfrac><mi>λ</mi><mrow><mi>λ</mi><mo>+</mo><mi>exp</mi><mo stretchy="false"> (</mo><mi>β</mi><mo>⋅</mo><mi>d</mi><mi>i</mi><mi>s</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac><mo>⋅</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">) </mo></mrow><mo>) </mo></mrow></mrow></mstyle><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">将式 (14) 代入式 (9) , 能够得到最终待标注图像预测关键词, 即标注点:</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>e</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mi>arg</mi><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mi>k</mi></munder><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>G</mi><msub><mrow></mrow><mi>Ι</mi></msub><mo stretchy="false">) </mo></mrow></munder><mrow><mrow><mo> (</mo><mrow><mfrac><mi>λ</mi><mrow><mi>λ</mi><mo>+</mo><mi>exp</mi><mo stretchy="false"> (</mo><mi>β</mi><mo>⋅</mo><mi>d</mi><mi>i</mi><mi>s</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></mstyle><mo>⋅</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">) </mo></mrow><mo>) </mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71">基于上述计算可知, 预测图像<i>I</i>与邻域图像<i>I</i><sub><i>i</i></sub>之间视觉距离值越小, <i>I</i><sub><i>i</i></sub>标签贡献值就越大, 反之则越小。因<i>I</i><sub><i>i</i></sub>由指定语义组中筛选, 保障了语义与视觉双向相似性, 解决了视觉相似语义相似程度大的问题。因邻域图像集合中图像由各语义组中筛选, 其兼顾着各语义标签, 防止了邻域集合中某种类型语义图像太多或者太少, 进而提升标签传播效果, 以此提升图像特征标注准确性。</p>
                </div>
                <div class="p1">
                    <p id="72">结合以上分析, 利用语义邻域与深度特征标注数字式多媒体图像连续视觉特征框架可描述为:</p>
                </div>
                <div class="p1">
                    <p id="73">1) 训练数字式多媒体图像语义分组, 也就是将一个标签涵盖的全部图像当作一个语义组, 同时依据组将训练图像输入至已经训练好的深度网络中。</p>
                </div>
                <div class="p1">
                    <p id="74">2) 利用逐层卷积与逐层采样法将数字式多媒体图像抽象成特征向量, 同时获取各语义组图像特征。</p>
                </div>
                <div class="p1">
                    <p id="75">3) 将待标注图像输入至已经训练好的深度网络中。</p>
                </div>
                <div class="p1">
                    <p id="76">4) 与步骤2) 相同, 对待标注图像进行层层卷积与采样, 同时提取图像特征。</p>
                </div>
                <div class="p1">
                    <p id="77">5) 按照式 (13) 计算待标注图像与各语义组中全部图像视觉相似程度, 同时构建邻域图像集合。</p>
                </div>
                <div class="p1">
                    <p id="78">6) 利用上述预测图像标签表达式计算贡献值, 同时将贡献值按照大小进行排序, 并获得预测关键词, 即标注点, 以此完成数字式多媒体图像连续视觉特征标注。</p>
                </div>
                <h3 id="79" name="79" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="80">为验证基于深度特征与语义邻域的数字式多媒体图像连续视觉特征标注方法实际价值, 进行一次仿真。实验平台搭建在Windows XP, 3.0 GHz CPU, 2GB内存硬件平台上, 实验数据来源于图像标注通用的Corel 5K图像库, 实验数据集合中一共有5000幅图像。</p>
                </div>
                <div class="p1">
                    <p id="81">实验过程中, 分别以图像标注准确性和实时性两方面为测试指标, 得到的实验结果如下。</p>
                </div>
                <div class="p1">
                    <p id="82">分析图1可知, 文献<citation id="95" type="reference">[<a class="sup">4</a>]</citation>方法图像标注准确率曲线变化不大, 最高约为85%;文献<citation id="96" type="reference">[<a class="sup">6</a>]</citation>方法图像标注准确率曲线前期呈上下浮动状态, 后期呈直线下降趋势, 表示该方法持续性不强, 可靠性较差;基于深度特征与语义邻域的数字式多媒体图像连续视觉特征标注方法运行准确率曲线随着待处理图像数量不断增加持平稳状态, 最高约为99%。所提方法在图像特征标注中, 考虑到邻域图像集合中图像从各语义组中筛选, 能够兼顾着各语义标签, 以此防止了邻域集合中发生某种类型语义图像太多或者太少情况, 也就增强了标签传播效果, 进而提升图像特征标注准确率。</p>
                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201908039_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 不同方法图像标注准确性对比" src="Detail/GetImg?filename=images/JSJZ201908039_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 不同方法图像标注准确性对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201908039_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="84">从图2中可明显看出, 所提方法标注效率要高于文献<citation id="97" type="reference">[<a class="sup">5</a>]</citation>方法。所提方法为提升图像特征标注效率, 利用MS-Ncuts算法对图像进行了有效分割, 不仅为增强图像标注实时性提供了支撑, 还能够在一定程度上提高图像标注精度, 以此提升方法运行整体性能。</p>
                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201908039_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同方法图像标注实时性对比" src="Detail/GetImg?filename=images/JSJZ201908039_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 不同方法图像标注实时性对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201908039_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="86" name="86" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="87">鉴于图像标注重要性, 提出基于深度特征与语义邻域的数字式多媒体图像连续视觉特征标注方法。利用图像分割为特征标注奠定基础, 通过深度特征与语义邻域相结合, 实现了图像特征标注。实验结果表明, 该方法具有鲁棒性。</p>
                </div>
                <div class="area_img" id="98">
                                <img alt="" src="Detail/GetImg?filename=images/JSJZ201908039_09800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201708018&amp;v=MjMwMTh0R0ZyQ1VSN3FmWnVab0Z5N25WTC9NTHo3QlpiRzRIOWJNcDQ5RWJJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 秦煜, 吴静静, 安伟.基于RANSAC的激光网格标记图像特征提取[J].计算机工程与科学, 2017, 39 (8) :1495-1501.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201701051&amp;v=MDc3NDNCZExHNEg5Yk1ybzlBWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnk3blZML01Mejc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 乔良.三维图像视觉下运动关键特征的提取方法改进[J].计算机仿真, 2017, 34 (1) :216-219.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GZXB201801009&amp;v=MTM2MDdmWnVab0Z5N25WTC9NSWpmVGJMRzRIOW5Ncm85RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 熊伟, 徐永力, 崔亚奇, 等.高分辨率合成孔径雷达图像舰船目标几何特征提取方法[J].光子学报, 2018, 47 (1) :49-58.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZDF201705021&amp;v=MDcwNzVuVkwvTUx6ZlBhTEc0SDliTXFvOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeTc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 邱尚明, 李冬睿, 罗拥华.基于互补特征合成的医学图像自动标注[J].控制工程, 2017, 24 (5) :1025-1031.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201805014&amp;v=MDg2NDBMejdCZDdHNEg5bk1xbzlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnk3blZML00=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 杨晓玲, 李志清, 刘雨桐.基于多标签判别字典学习的图像自动标注[J].计算机应用, 2018, 38 (5) :1294-1298.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201012007&amp;v=Mjg5NjhadVpvRnk3blZML01QeXJmYkxHNEg5SE5yWTlGWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 曾接贤, 祝小超, 符祥.一种改进的复杂图像线特征提取方法[J].中国图象图形学报, 2018, 15 (12) :1748-1754.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201705010&amp;v=MjkyODk5Yk1xbzlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnk3blZML01MejdTWkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 任智慧, 徐浩煜, 封松林, 等.基于LSTM网络的序列标注中文分词法[J].计算机应用研究, 2017, 34 (5) :1321-1324.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HZLG201610024&amp;v=MDg3NTFvRnk3blZML01MVGZIYWJHNEg5Zk5yNDlIWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 吕钊, 陆雨, 周蚌艳, 等.基于共同空间模式的扫视信号特征提取算法[J].华中科技大学学报 (自然科学版) , 2016, 44 (10) :123-127.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GJJS201608016&amp;v=MTI5MTQ5RVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5N25WTC9NSWlmQmZiRzRIOWZNcDQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 刘明, 郝博.航空典型零件快速标注技术[J].工具技术, 2016, 50 (8) :47-50.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201712014&amp;v=MTM0MDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnk3blZML01JVGZUZTdHNEg5Yk5yWTlFWUlRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 柯逍, 邹嘉伟, 杜明智, 等.基于蒙特卡罗数据集均衡与鲁棒性增量极限学习机的图像自动标注[J].电子学报, 2017, 45 (12) :2925-2935.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201908039" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201908039&amp;v=MjMzOTN5N25WTC9NTHo3QmRMRzRIOWpNcDQ5R2JZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JOOW42MnpYRXFvaytYcVVzVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
