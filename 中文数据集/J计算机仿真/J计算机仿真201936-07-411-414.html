<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637140804131513750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201907089%26RESULT%3d1%26SIGN%3dspIy6bTJdGtrhv6OI%252bxZh39PTog%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201907089&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201907089&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201907089&amp;v=MDAwNDFyQ1VSN3FmWnVabkZ5amdVci9NTHo3QmRMRzRIOWpNcUk5TmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#38" data-title="&lt;b&gt;2 逻辑迭代三帧差分法&lt;/b&gt; "><b>2 逻辑迭代三帧差分法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#39" data-title="&lt;b&gt;2.1 三帧差分法&lt;/b&gt;"><b>2.1 三帧差分法</b></a></li>
                                                <li><a href="#41" data-title="&lt;b&gt;2.2 逻辑迭代三帧差分法&lt;/b&gt;"><b>2.2 逻辑迭代三帧差分法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="&lt;b&gt;3 基于视觉注意机制的行人目标检测&lt;/b&gt; "><b>3 基于视觉注意机制的行人目标检测</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="&lt;b&gt;3.1 显著性特征计算&lt;/b&gt;"><b>3.1 显著性特征计算</b></a></li>
                                                <li><a href="#74" data-title="&lt;b&gt;3.2 显著性特征与行人目标检测结合&lt;/b&gt;"><b>3.2 显著性特征与行人目标检测结合</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#79" data-title="&lt;b&gt;4 实验结果及分析&lt;/b&gt; "><b>4 实验结果及分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="1) 目标特征变化频繁的情况">1) 目标特征变化频繁的情况</a></li>
                                                <li><a href="#86" data-title="2) 目标较小且背景干扰严重">2) 目标较小且背景干扰严重</a></li>
                                                <li><a href="#88" data-title="3) 性能评价">3) 性能评价</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#97" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="&lt;b&gt;图1 算法流程图&lt;/b&gt;"><b>图1 算法流程图</b></a></li>
                                                <li><a href="#82" data-title="&lt;b&gt;图2 视觉显著图&lt;/b&gt;"><b>图2 视觉显著图</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;图3 视频1中三种算法检测结果图&lt;/b&gt;"><b>图3 视频1中三种算法检测结果图</b></a></li>
                                                <li><a href="#87" data-title="&lt;b&gt;图4 视频2中两种算法检测结果图&lt;/b&gt;"><b>图4 视频2中两种算法检测结果图</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;表1 抽样测试结果的行人检测算法&lt;/b&gt;"><b>表1 抽样测试结果的行人检测算法</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="119">


                                    <a id="bibliography_1" title=" 王红茹, 童伟.基于自适应高斯模型的实效运动目标检测算法[J].计算机工程与设计, 2016, 37 (10) :2700- 2704." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201610023&amp;v=MTg0NjdmWnVabkZ5amdVci9NTmlmWVpMRzRIOWZOcjQ5SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         王红茹, 童伟.基于自适应高斯模型的实效运动目标检测算法[J].计算机工程与设计, 2016, 37 (10) :2700- 2704.
                                    </a>
                                </li>
                                <li id="121">


                                    <a id="bibliography_2" title=" 陈俊超, 等.基于背景建模与帧间差分的目标检测改进算法[J].计算机工程, 2011, 增刊 (37) :171-173." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC2011S1056&amp;v=MDYzMzR6cXFCdEdGckNVUjdxZlp1Wm5GeWpnVXIvTUx6N0JiYkc0SDlDdnJvOUFZb1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         陈俊超, 等.基于背景建模与帧间差分的目标检测改进算法[J].计算机工程, 2011, 增刊 (37) :171-173.
                                    </a>
                                </li>
                                <li id="123">


                                    <a id="bibliography_3" title=" 刘尚旺, 胡剑兰.基于生物视觉机制的图像感兴趣区域快速获取方法研究[J].计算机应用与软件, 2016, 33 (9) :171-175." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201609041&amp;v=MjY1MDBGckNVUjdxZlp1Wm5GeWpnVXIvTUx6VFpaTEc0SDlmTXBvOUJaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         刘尚旺, 胡剑兰.基于生物视觉机制的图像感兴趣区域快速获取方法研究[J].计算机应用与软件, 2016, 33 (9) :171-175.
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_4" title=" 于明, 闫必行, 阎刚, 于洋.融合空时显著性的运动目标检测方法[J].计算机仿真, 2013, 30 (4) :402-405." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201304095&amp;v=MTkxNjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amdVci9NTHo3QmRMRzRIOUxNcTQ5TVlZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         于明, 闫必行, 阎刚, 于洋.融合空时显著性的运动目标检测方法[J].计算机仿真, 2013, 30 (4) :402-405.
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_5" title=" 宣东东, 汪军.基于扩散的视觉显著目标检测[J].南华大学学报 (自然科学版) , 2018, 32 (2) :74-80+86." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZNGB201802013&amp;v=MTU3MjRiTEc0SDluTXJZOUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeWpnVXIvTVB5UE0=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         宣东东, 汪军.基于扩散的视觉显著目标检测[J].南华大学学报 (自然科学版) , 2018, 32 (2) :74-80+86.
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_6" title=" Wo Yan, Chen Xi, Han Guoqiang.A saliency detection model using aggregation degree of color texture[J].Signal processing:Image Communication, 2015, (30) :121-136." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700307853&amp;v=MTE0NzhubFVyYklJRnNWYWhZPU5pZk9mYks4SDlETXFJOUZaK3NJQkhrNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Wo Yan, Chen Xi, Han Guoqiang.A saliency detection model using aggregation degree of color texture[J].Signal processing:Image Communication, 2015, (30) :121-136.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_7" title=" Pan Zheng, Liu Shuai.Visual attention feature (VAF) :A novel strategy for visual tracking based on cloud platform in intelligent surveillance systems[J].Journal of Parallel &amp;amp; Distributed Computing, 2018, 120:182–194." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES944487DD214F4DC6B60944315030247F&amp;v=MjkzNThYRXFQc3hadW9MZW5oTnZCQmg3RDkwVEh2aHJSYzFlcktXUWIzcENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRGaHhMMit3S3c9TmlmT2ZicThHdA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Pan Zheng, Liu Shuai.Visual attention feature (VAF) :A novel strategy for visual tracking based on cloud platform in intelligent surveillance systems[J].Journal of Parallel &amp;amp; Distributed Computing, 2018, 120:182–194.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_8" title=" 孙越娇, 等.基于视觉显著模型的遥感图像舰船快速检测[J].激光技术, 2018, 42 (3) :379-384." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGJS201803017&amp;v=MjY5NjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeWpnVXIvTUx5ckJmYkc0SDluTXJJOUVZNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         孙越娇, 等.基于视觉显著模型的遥感图像舰船快速检测[J].激光技术, 2018, 42 (3) :379-384.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_9" title=" 张亚红, 杨欣, 沈雷, 周大可.基于视觉显著性特征的自适应目标跟踪[J].吉林大学学报 (信息科学版) , 2015, 33 (2) :195-200." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CCYD201502013&amp;v=MjQ0NjRSN3FmWnVabkZ5amdVci9NSmk3U2FyRzRIOVRNclk5RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         张亚红, 杨欣, 沈雷, 周大可.基于视觉显著性特征的自适应目标跟踪[J].吉林大学学报 (信息科学版) , 2015, 33 (2) :195-200.
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_10" title=" Wang Weining, Cai Dong, Xu Xiangmin.Visual saliency detection based on region descriptors and prior.knowledge[J].Signal processing:Image Communcation, 2014, (29) :424-433." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14021300033613&amp;v=MDU3MDVGc1ZhaFk9TmlmT2ZiSzhIdFBOckk5RlpPZ01DbjA2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmJJSQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Wang Weining, Cai Dong, Xu Xiangmin.Visual saliency detection based on region descriptors and prior.knowledge[J].Signal processing:Image Communcation, 2014, (29) :424-433.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_11" title=" N Dalal, B Triggs.Histograms of oriented grasients for human detection[C].IEEE International Conference on Computer Vision and Patten Recognition, 2015, (1) :886-893." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Histograms of oriented grasients for human detection">
                                        <b>[11]</b>
                                         N Dalal, B Triggs.Histograms of oriented grasients for human detection[C].IEEE International Conference on Computer Vision and Patten Recognition, 2015, (1) :886-893.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_12" title=" D Gowsikhaa, S Abirami, R Baskaran.Automated human behavior analysis from surveillance videos:a survey[J].Arti Intell Rev.2014, (42) :747-765." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14111900008457&amp;v=MjgxNDVGc1ZhaFk9Tmo3QmFySzhIOUROcG85RlpPc0hDSGsrb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmJJSQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         D Gowsikhaa, S Abirami, R Baskaran.Automated human behavior analysis from surveillance videos:a survey[J].Arti Intell Rev.2014, (42) :747-765.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_13" title=" 陈云彪.基于视觉注意机制的感兴趣目标检测研究[D].厦门大学硕士学位论文, 2014." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014190479.nh&amp;v=MjMyODFGMjZHckt4SHRYTHBwRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeWpnVXIvTVY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         陈云彪.基于视觉注意机制的感兴趣目标检测研究[D].厦门大学硕士学位论文, 2014.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_14" title=" 张艳军, 等.基于视觉注意机制的行人检测方法[J].科技视野, .2015, (15) :98, 168." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KJSJ201515074&amp;v=MTY4MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnlqZ1VyL01MaWZZWkxHNEg5VE5xbzlDWUlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         张艳军, 等.基于视觉注意机制的行人检测方法[J].科技视野, .2015, (15) :98, 168.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_15" title=" 靳培飞, 等.基于感兴趣区域提取的行人检测[J].计算机工程与设计, 2016, 37 (11) :3035-3039." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201611031&amp;v=MDk5NjFpZllaTEc0SDlmTnJvOUdaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeWpnVXIvTU4=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         靳培飞, 等.基于感兴趣区域提取的行人检测[J].计算机工程与设计, 2016, 37 (11) :3035-3039.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(07),411-414             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于视觉注意机制的行人目标检测</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E8%B0%A6&amp;code=09125696&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵谦</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%96%9B%E6%94%B9%E6%A0%B7&amp;code=39441406&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">薛改样</a>
                                <a href="javascript:;">杨新花</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0260299&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安科技大学通信与信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B7%B1%E5%9C%B3%E5%B8%82%E7%A7%91%E5%88%97%E6%8A%80%E6%9C%AF%E8%82%A1%E4%BB%BD%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深圳市科列技术股份有限公司</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在分析现有运动目标检测算法的基础上, 针对三帧差分检测易出现空洞及边缘不连续等问题, 提出一种基于视觉注意机制的行人目标检测算法。该算法首先, 通过借鉴人类视觉显著性现有的研究成果获得视觉显著图;其次, 使用一种逻辑迭代三帧差分法, 将其与基于区域搜索迭代的内轮廓填充法相结合, 获得运动区域, 融合两种算法提取出ROI;最后, 采用HOG特征结合SVM分类器对ROI进行行人检测。对比实验结果表明, 该算法连通性好, 准确率高达97%以上。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E8%A7%89%E6%98%BE%E8%91%97%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">视觉显著图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E5%B8%A7%E5%B7%AE%E5%88%86%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三帧差分法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BD%AE%E5%BB%93%E5%A1%AB%E5%85%85%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">轮廓填充法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%84%9F%E5%85%B4%E8%B6%A3%E5%8C%BA%E5%9F%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">感兴趣区域;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持向量机;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    赵谦 (1977-) , 男 (汉族) , 陕西西安市人, 讲师, 博士, 硕士生导师, 研究领域为视频目标跟踪;
                                </span>
                                <span>
                                    薛改样 (1988-) , 女 (汉族) , 陕西咸阳市人, 硕士研究生, 研究领域为机器学习;;
                                </span>
                                <span>
                                    杨新花 (1989-) , 女 (汉族) , 陕西渭南市人, 硕士研究生, 研究领域为视频目标跟踪。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>陕西省科技计划工业科技攻关 (2017GY-073, 2015GY-023);</span>
                                <span>西安市碑林区应用技术研发 (GX1811);</span>
                    </p>
            </div>
                    <h1><b>The Research of Pedestrian Detection Algorithm Based on Visual Attention</b></h1>
                    <h2>
                    <span>ZHAO Qian</span>
                    <span>XUE Gai-yang</span>
                    <span>YANG Xin-hua</span>
            </h2>
                    <h2>
                    <span>School of Communication and Information Engineering, Xi'an University of Science and Technology</span>
                    <span>Shenzhen Kelie Technology Co., Ltd.</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Based on the analysis of the existing moving target detection algorithm, for the phenomena in three-frame difference detection, such as cavity and edge discontinuity, , a pedestrian object detection algorithm based on visual attention mechanism was proposed. Firstly, we used the existing research results of human visual saliency to obtain the visual saliency map; Secondly, a logical iterative three-frame difference method was used to obtain the motion region combine with a contour filling method based on the local region research. two algorithms were integrated to obtain the region of interest. Finally, HOG features was used combined with support vector machines classifier for pedestrian detection in region of interest. The experimental results show that the algorithm has good connectivity and the accuracy is over 97%.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Visual%20saliency%20map&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Visual saliency map;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Three%20frame%20difference%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Three frame difference detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=A%20contour%20filling%20method&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">A contour filling method;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ROI&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ROI;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SVM&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SVM;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-10</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="34">常用的基于图像序列的运动目标检测算法主要有<citation id="149" type="reference"><link href="119" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>:背景差分法、光流法和帧间差分法。背景差分法能在运动情况很复杂的环境下完整地检测出运动的物体, 但对于背景突变易产生误检, 而且背景模型的选取和更新比较耗时;光流法对光线状态很敏感, 且计算量大, 难以达到实时性;帧间差分法算法简单, 且能快速获取运动区域, 但对于运动过于缓慢的物体易产生空洞现象。文献<citation id="150" type="reference">[<a class="sup">2</a>]</citation>采用背景建模与帧间差分结合的方法, 虽能改善高斯背景建模时的阴影现象, 但易出现拖影和空洞现象, 对于较为复杂的场景检测效果不理想。</p>
                </div>
                <div class="p1">
                    <p id="35">当面对复杂场景时, 人类能够迅速将注意力转移到图像中的感兴趣区域 (Region of Interest, ROI) , 以便对其优先处理, 这就是视觉注意机制。也就是说, ROI是指人类面对一幅图像时首先关注和注意的区域<citation id="151" type="reference"><link href="123" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。心理学研究发现, 在对整个场景的初步感知基础上形成视觉注意, 而对场景的感知分为空间和时间两个部分, 而运动的物体能更加吸引视觉注意<citation id="152" type="reference"><link href="125" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="36">显著目标检测的目的主要是为了提取图像中人类视觉所感兴趣的区域<citation id="153" type="reference"><link href="127" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>, 研究表明, 显著性检测是一种有效的检测方法, 可作为其它任务的预处理步骤, 处理结果是得到显著图, 图中用灰度值代表显著性程度。文献<citation id="154" type="reference">[<a class="sup">6</a>]</citation>采用背景差分法结合显著性特征的方法, 实现了对海底弱小目标的检测, 且准确率较高, 但背景建模及显著性模型两种算法都较为复杂, 且实时性较差。</p>
                </div>
                <div class="p1">
                    <p id="37">针对上述不足, 本文对Itti模型中的颜色空间进行了相应的改进, 获得了颜色、亮度、方向等空间特征显著图, 同时使用了一种逻辑迭代三帧差分法, 并将基于轮廓搜索的空洞填充法引入其中, 融合两种算法, 获得感兴趣区域 (Region Of Interest, ROI) 。最终, 在ROI内利用行人分类器进行检测。</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag"><b>2 逻辑迭代三帧差分法</b></h3>
                <h4 class="anchor-tag" id="39" name="39"><b>2.1 三帧差分法</b></h4>
                <div class="p1">
                    <p id="40">三帧差分法是相邻两帧差分算法的改进, 可有效的滤除因运动而显露出来的背景干扰, 从而获得运动目标轮廓。该算法的基本原理是:首先, 在视频中选取连续三帧图像, 并计算相邻两帧的差值;其次通过选取适当的阈值对其进行二值化处理, 获得相应的二值化图像;最后, 对各像素点处获得的二值图像做“与”运算, 获取共同部分, 得到相应轮廓信息。</p>
                </div>
                <h4 class="anchor-tag" id="41" name="41"><b>2.2 逻辑迭代三帧差分法</b></h4>
                <div class="p1">
                    <p id="42">三帧差分算法虽然能够快速的检测出运动目标的轮廓, 但轮廓不连续且存在较大的空洞, 另外, 该算法不能完整的提取目标信息, 本文采用如下逻辑迭代三帧差分法, 即在原有三帧差分的基础上, 将差分的结果再和前一帧与后一帧差分的结果进行“或”运算, 并使用基于区域搜索迭代的内轮廓填充法对空洞进行填充。</p>
                </div>
                <div class="p1">
                    <p id="43">该算法的实现步骤如下, 假设预处理后连续的三帧图像分别为:<i>f</i><sub>1</sub> (<i>x</i>, <i>y</i>) 、<i>f</i><sub>2</sub> (<i>x</i>, <i>y</i>) 、<i>f</i><sub>3</sub> (<i>x</i>, <i>y</i>) 。首先分别将<i>f</i><sub>1</sub> (<i>x</i>, <i>y</i>) 与<i>f</i><sub>2</sub> (<i>x</i>, <i>y</i>) , <i>f</i><sub>2</sub> (<i>x</i>, <i>y</i>) 与<i>f</i><sub>3</sub> (<i>x</i>, <i>y</i>) , <i>f</i><sub>1</sub> (<i>x</i>, <i>y</i>) 与<i>f</i><sub>3</sub> (<i>x</i>, <i>y</i>) 做差分运算, 得到差分结果。具体操作如</p>
                </div>
                <div class="p1">
                    <p id="44">式 (1) 所示</p>
                </div>
                <div class="area_img" id="45">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201907089_04500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="47">其中, “Θ”表示差分运算。然后将得到的差分结果<i>d</i><sub>1</sub> (<i>x</i>, <i>y</i>) 与<i>d</i><sub>2</sub> (<i>x</i>, <i>y</i>) 二值化处理后进行“与”运算, “与”运算的目的是, 克制目标重叠的现象, 然后将“与”运算的结果与<i>d</i><sub>3</sub> (<i>x</i>, <i>y</i>) 做“或”运算, “或”运算的目的是防止目标出现不连续现象。该改进算法, 可以在一定程度上改善传统算法, 使得目标轮廓更清晰, 内容更丰富。</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag"><b>3 基于视觉注意机制的行人目标检测</b></h3>
                <div class="p1">
                    <p id="49"><i>Itti</i>提出了基于人类视觉特征和视觉系统架构的视觉注意模型<citation id="155" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 该模型是视觉注意机制中较为经典的模型之一<citation id="156" type="reference"><link href="133" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。其基本思想是:首先, 提取图像的颜色、亮度及方向特征, 采用金字塔滤波得到各特征的尺度空间表示, 然后采用中央强化周边抑制的方法计算不同尺度空间的特征差异, 最后进行归一化, 合并各特征显著图, 得到总显著图。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50"><b>3.1 显著性特征计算</b></h4>
                <h4 class="anchor-tag" id="51" name="51">3.1.1 颜色特征</h4>
                <div class="p1">
                    <p id="52">从RGB空间转化到Lab空间的方法如下:首先, 对输入的彩色图像提取<i>R</i>、<i>G</i>、<i>B</i>三通道, 归一化颜色值至[0, 1]区间, 如式 (2) 所示</p>
                </div>
                <div class="area_img" id="53">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201907089_05300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="55">令<i>X</i>, <i>Y</i>, <i>Z</i>为RGB空间向Lab空间转化的中间变量, 具体过程如式 (3) 、 (4) 所示</p>
                </div>
                <div class="area_img" id="56">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201907089_05600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="58"><i>L</i>=116.0×<i>f</i><sub><i>y</i></sub>-16.0</p>
                </div>
                <div class="p1">
                    <p id="59"><i>a</i>=500.0× (<i>f</i><sub><i>x</i></sub>-<i>f</i><sub><i>y</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="60"><i>b</i>=500.0× (<i>f</i><sub><i>y</i></sub>-<i>f</i><sub><i>z</i></sub>)      (4) </p>
                </div>
                <h4 class="anchor-tag" id="61" name="61">3.1.2 亮度特征及方向特征</h4>
                <div class="p1">
                    <p id="62"><mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mo>=</mo><mfrac><mrow><mi>r</mi><mo>+</mo><mi>g</mi><mo>+</mo><mi>b</mi></mrow><mn>3</mn></mfrac></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="64"><i>O</i> ( (<i>θ</i>) =‖<i>IG</i><sub>0</sub> (<i>θ</i>) ‖+‖<i>IG</i><sub><i>π</i>/2</sub> (<i>θ</i>) ‖       (6) </p>
                </div>
                <div class="p1">
                    <p id="65">其中, <i>r</i>, <i>g</i>, <i>b</i>分别为彩色图像的RGB值;<i>I</i>为通过式 (5) 求得的亮度值, <i>G</i> (:) 表示Gabor滤波;<i>θ</i>表示局部方向, <i>θ</i>∈{0°, 45°, 90°, 135°} 。</p>
                </div>
                <div class="p1">
                    <p id="66">视觉显著图 (Saliency Map) 为图像的视觉特征, 表示场景中显著目标的位置和显著性大小信息<citation id="157" type="reference"><link href="135" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。显著性区域指的是与周围区域相比差异明显的区域, 使用中央强化四周弱化的机制对图像的颜色、亮度、方向等特征图进行处理。用不同尺度的图像相减来模拟图像四周与中心的差分, 可得到不同尺度下的视觉刺激图, 做差分运算即可获得相应特征的显著图。如式 (7) 所示。</p>
                </div>
                <div class="p1">
                    <p id="67"><i>M</i> ( (<i>c</i>, <i>s</i>) =|<i>M</i> (<i>c</i>) Θ<i>M</i> (<i>s</i>) |      (7) </p>
                </div>
                <div class="p1">
                    <p id="68">其中, <i>c</i>∈{1, 2, 3}, <i>s</i>∈{3, 4, 5}。首先采用插值法对不同尺度的两幅图像做插值得到相同尺度的图像, 再逐像素进行减法运算, 然后将各特征图归一化。各尺度的特征图相加得到相应特征的显著图, 如式 (8) 所示</p>
                </div>
                <div class="p1">
                    <p id="69"><mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mo>=</mo><munderover><mstyle mathsize="140%" displaystyle="true"><mo>⊕</mo></mstyle><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mn>3</mn></munderover><munderover><mstyle mathsize="140%" displaystyle="true"><mo>⊕</mo></mstyle><mrow><mi>s</mi><mo>=</mo><mn>3</mn></mrow><mn>5</mn></munderover><mi>Ν</mi><mo stretchy="false"> (</mo><mi>Μ</mi><mo stretchy="false"> (</mo><mi>c</mi><mo>, </mo><mi>s</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="71">最后采用求均值的方法将其融合为一幅图像, 获得总显著图, 如式 (9) 所示</p>
                </div>
                <div class="p1">
                    <p id="72"><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mfrac><mrow><mi>Ν</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false">) </mo><mo>+</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>C</mi><mo stretchy="false">) </mo><mo>+</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>Ο</mi><mo stretchy="false">) </mo></mrow><mn>3</mn></mfrac></mrow></math></mathml>      (9) </p>
                </div>
                <h4 class="anchor-tag" id="74" name="74"><b>3.2 显著性特征与行人目标检测结合</b></h4>
                <div class="p1">
                    <p id="75">显著性特征因其操作简单, 结果高效等诸多优点, 一直备受瞩目。到目前为止, 针对静态图像的提取算法已较为成熟。将其引入视频序列中的算法近年来也在不断的涌现<citation id="158" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。但是现有理论依然存在着误检率高、抗干扰能力差等问题。</p>
                </div>
                <div class="p1">
                    <p id="76">本文在前人研究的基础上, 实现了一些算法的改进, 提出了一种基于显著性特征的运动区域检测算法。算法流程如图1所示。</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201907089_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 算法流程图" src="Detail/GetImg?filename=images/JSJZ201907089_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 算法流程图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201907089_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="78">将基于显著性特征的运动区域检测算法引入到行人检测算法当中, 最终提出了一种基于视觉注意机制的行人目标检测方法。该方法对于行人检测的训练部分, 使用OpenCV中已经训练好的支持向量机 (support vector machines, SVM) 分类器完成训练过程, 在检测部分, 首先使用显著性特征的运动区域检测算法, 检测视频中的ROI, 获得包含运动信息的ROI;其次, 提取该区域内各显著目标的HOG特征;最后, 与SVM分类器中的目标进行配对比较。若配对成功则判断其为行人目标, 并在原视频帧中标记出来<citation id="159" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <h3 id="79" name="79" class="anchor-tag"><b>4 实验结果及分析</b></h3>
                <div class="p1">
                    <p id="80">为证明本文算法的有效性和可行性, 本实验采用的硬件系统为Intel Core i5-3230M CPU、2.6GHZ、RAM 4G、64位Windows10操作系统的笔记本电脑, 软件为MATLAB2010a, 部分结果则在Visual Studio2010 和Opencv2.3.1环境下得到。</p>
                </div>
                <div class="p1">
                    <p id="81">图2为采用显著性特征计算方法得到各特征分量的视觉显著图。</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201907089_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 视觉显著图" src="Detail/GetImg?filename=images/JSJZ201907089_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 视觉显著图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201907089_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="83">下面选择了PETS2001中的两段视频其性能进行测试。这些视频包括背景扰动、缓慢目标移动、目标本身的旋转, 目标摄像头距离不断变化等复杂情况<citation id="160" type="reference"><link href="141" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。然后将本文算法与现有算法进行了比较<citation id="161" type="reference"><link href="143" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation> 。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84">1) 目标特征变化频繁的情况</h4>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201907089_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 视频1中三种算法检测结果图" src="Detail/GetImg?filename=images/JSJZ201907089_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 视频1中三种算法检测结果图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201907089_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="86" name="86">2) 目标较小且背景干扰严重</h4>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201907089_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 视频2中两种算法检测结果图" src="Detail/GetImg?filename=images/JSJZ201907089_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 视频2中两种算法检测结果图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201907089_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="88" name="88">3) 性能评价</h4>
                <div class="p1">
                    <p id="89">行人检测算法通常使用漏检率 (False Negative rate) 和误检率 (False Positive rate) 来评定其性能<citation id="162" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。漏检率和误检率越低说明算法的性能越好, 但两者也互相制约, 降低误检率可能会导致漏检率的上升。其中, 漏检率定义如式 (10) 。</p>
                </div>
                <div class="p1">
                    <p id="90">False Negative<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>r</mtext><mtext>a</mtext><mtext>t</mtext><mtext>e</mtext><mo>=</mo><mfrac><mrow><mtext>F</mtext><mtext>a</mtext><mtext>l</mtext><mtext>s</mtext><mtext>e</mtext><mtext>Ν</mtext><mtext>e</mtext><mtext>g</mtext><mtext>a</mtext><mtext>t</mtext><mtext>i</mtext><mtext>v</mtext><mtext>e</mtext><mtext>s</mtext></mrow><mrow><mtext>Τ</mtext><mtext>r</mtext><mtext>u</mtext><mtext>e</mtext><mtext>Ρ</mtext><mtext>o</mtext><mtext>s</mtext><mtext>i</mtext><mtext>t</mtext><mtext>i</mtext><mtext>v</mtext><mtext>e</mtext><mtext>s</mtext><mo>+</mo><mtext>F</mtext><mtext>a</mtext><mtext>l</mtext><mtext>s</mtext><mtext>e</mtext><mtext>Ν</mtext><mtext>e</mtext><mtext>g</mtext><mtext>a</mtext><mtext>t</mtext><mtext>i</mtext><mtext>v</mtext><mtext>e</mtext><mtext>s</mtext></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="92">误检率定义如式 (11) 。</p>
                </div>
                <div class="p1">
                    <p id="93">False Positive<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>r</mtext><mtext>a</mtext><mtext>t</mtext><mtext>e</mtext><mo>=</mo><mfrac><mrow><mtext>F</mtext><mtext>a</mtext><mtext>l</mtext><mtext>s</mtext><mtext>e</mtext><mtext>Ρ</mtext><mtext>o</mtext><mtext>s</mtext><mtext>i</mtext><mtext>t</mtext><mtext>i</mtext><mtext>v</mtext><mtext>e</mtext><mtext>s</mtext></mrow><mrow><mtext>Τ</mtext><mtext>r</mtext><mtext>u</mtext><mtext>e</mtext><mtext>Ν</mtext><mtext>e</mtext><mtext>g</mtext><mtext>a</mtext><mtext>t</mtext><mtext>i</mtext><mtext>v</mtext><mtext>e</mtext><mtext>s</mtext><mo>+</mo><mtext>F</mtext><mtext>a</mtext><mtext>l</mtext><mtext>s</mtext><mtext>e</mtext><mtext>Ρ</mtext><mtext>o</mtext><mtext>s</mtext><mtext>i</mtext><mtext>t</mtext><mtext>i</mtext><mtext>v</mtext><mtext>e</mtext><mtext>s</mtext></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="95">表1为三种方法的五个样本的漏检率及误检率, 从中可以看出, 相比于其它两种算法, 本文算法的误检率比较低, 漏检率低于传统的HOG检测, 与文献<citation id="163" type="reference">[<a class="sup">14</a>]</citation>接近, 说明本文算法融合干扰的能力较强, 但灵敏度不够。本文算法对于目标自身特征的变化具有较强的鲁棒性, 目标姿态的多变使得传统算法检测效率急剧下降, 然而本文算法却可以得到较好的检测效果, 随着目标数目的不断增加以及外界环境所发生的较大变化, 本文算法的检测结果也不甚理想。因此, 如何挖掘显著性与其它图像处理算法的之间的关系, 从而实现合理的算法融合, 将会是以后这个领域的重要研究方向。</p>
                </div>
                <div class="area_img" id="96">
                    <p class="img_tit"><b>表1 抽样测试结果的行人检测算法</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="96" border="1"><tr><td rowspan="2"><br />抽样</td><td colspan="2"><br />传统的HOG 检测</td><td colspan="2">文献[14]方法</td><td colspan="2">本文算法</td></tr><tr><td><br />漏检率</td><td>误检率</td><td>漏检率</td><td>误检率</td><td>漏检率</td><td>误检率</td></tr><tr><td><br />1</td><td>0.3330</td><td>0.3570</td><td>0.0826</td><td>0.1064</td><td>0.0953</td><td>0.0815</td></tr><tr><td><br />2</td><td>0.0347</td><td>0.4780</td><td>0.1207</td><td>0.0286</td><td>0.0502</td><td>0.0253</td></tr><tr><td><br />3</td><td>0.0213</td><td>0.1802</td><td>0.1352</td><td>0.0782</td><td>0.1552</td><td>0.0332</td></tr><tr><td><br />4</td><td>0.2500</td><td>0.1667</td><td>0.0635</td><td>0.0283</td><td>0.0952</td><td>0.0316</td></tr><tr><td><br />5</td><td>0.0648</td><td>0.4682</td><td>0.6667</td><td>0.1459</td><td>0.5683</td><td>0.0308</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="97" name="97" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="98">本文首先提出了一种逻辑迭代三帧差分法, 它是在传统的三帧差分法的技术上对其进行改进, 并使用基于区域搜索迭代的内轮廓填充法对改进产生的空洞进行填充。其次, 将逻辑迭代三帧差分法与改进的显著性特征的运动区域检测算法相融合, 并将其引入行人检测算法中, 提出了一种基于视觉注意机制的行人目标检测算法。</p>
                </div>
                <div class="p1">
                    <p id="99">改进视觉注意模型与运动检测算法相融合, 不仅弥补了视觉注意模型运动信息缺失的不足, 而且对运动检测的目标区域起到增强和滤除干扰的作用。针对传统算法需要在整幅图像区域内提取HOG特征的缺陷, 对比实验结果表明该算法准确性更高、检测效果更理想。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="116" type="formula" href="images/JSJZ201907089_11600.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">赵谦</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="119">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201610023&amp;v=MDA0OTFOcjQ5SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amdVci9NTmlmWVpMRzRIOWY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 王红茹, 童伟.基于自适应高斯模型的实效运动目标检测算法[J].计算机工程与设计, 2016, 37 (10) :2700- 2704.
                            </a>
                        </p>
                        <p id="121">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC2011S1056&amp;v=MDI5OTVnVXIvTUx6N0JiYkc0SDlDdnJvOUFZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeWo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 陈俊超, 等.基于背景建模与帧间差分的目标检测改进算法[J].计算机工程, 2011, 增刊 (37) :171-173.
                            </a>
                        </p>
                        <p id="123">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201609041&amp;v=MTE5NDJUWlpMRzRIOWZNcG85QlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amdVci9NTHo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 刘尚旺, 胡剑兰.基于生物视觉机制的图像感兴趣区域快速获取方法研究[J].计算机应用与软件, 2016, 33 (9) :171-175.
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201304095&amp;v=MDQ4MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnlqZ1VyL01MejdCZExHNEg5TE1xNDlNWVlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 于明, 闫必行, 阎刚, 于洋.融合空时显著性的运动目标检测方法[J].计算机仿真, 2013, 30 (4) :402-405.
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZNGB201802013&amp;v=MDU0MzZxQnRHRnJDVVI3cWZadVpuRnlqZ1VyL01QeVBNYkxHNEg5bk1yWTlFWjRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 宣东东, 汪军.基于扩散的视觉显著目标检测[J].南华大学学报 (自然科学版) , 2018, 32 (2) :74-80+86.
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700307853&amp;v=MzIzOTE2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmJJSUZzVmFoWT1OaWZPZmJLOEg5RE1xSTlGWitzSUJIaw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Wo Yan, Chen Xi, Han Guoqiang.A saliency detection model using aggregation degree of color texture[J].Signal processing:Image Communication, 2015, (30) :121-136.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES944487DD214F4DC6B60944315030247F&amp;v=MTQ2MDRZZk9HUWxmQnJMVTA1dEZoeEwyK3dLdz1OaWZPZmJxOEd0WEVxUHN4WnVvTGVuaE52QkJoN0Q5MFRIdmhyUmMxZXJLV1FiM3BDT052RlNpV1dyN0pJRnBtYUJ1SA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Pan Zheng, Liu Shuai.Visual attention feature (VAF) :A novel strategy for visual tracking based on cloud platform in intelligent surveillance systems[J].Journal of Parallel &amp; Distributed Computing, 2018, 120:182–194.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGJS201803017&amp;v=MDM5MDJyQmZiRzRIOW5Nckk5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amdVci9NTHk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 孙越娇, 等.基于视觉显著模型的遥感图像舰船快速检测[J].激光技术, 2018, 42 (3) :379-384.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CCYD201502013&amp;v=MDAxNTMzenFxQnRHRnJDVVI3cWZadVpuRnlqZ1VyL01KaTdTYXJHNEg5VE1yWTlFWjRRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 张亚红, 杨欣, 沈雷, 周大可.基于视觉显著性特征的自适应目标跟踪[J].吉林大学学报 (信息科学版) , 2015, 33 (2) :195-200.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14021300033613&amp;v=MDAyOTJDbjA2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmJJSUZzVmFoWT1OaWZPZmJLOEh0UE5ySTlGWk9nTQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Wang Weining, Cai Dong, Xu Xiangmin.Visual saliency detection based on region descriptors and prior.knowledge[J].Signal processing:Image Communcation, 2014, (29) :424-433.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Histograms of oriented grasients for human detection">

                                <b>[11]</b> N Dalal, B Triggs.Histograms of oriented grasients for human detection[C].IEEE International Conference on Computer Vision and Patten Recognition, 2015, (1) :886-893.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14111900008457&amp;v=MTIzODJLOEg5RE5wbzlGWk9zSENIaytvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyYklJRnNWYWhZPU5qN0Jhcg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> D Gowsikhaa, S Abirami, R Baskaran.Automated human behavior analysis from surveillance videos:a survey[J].Arti Intell Rev.2014, (42) :747-765.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014190479.nh&amp;v=MTc0MjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnlqZ1VyL01WRjI2R3JLeEh0WExwcEViUElRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 陈云彪.基于视觉注意机制的感兴趣目标检测研究[D].厦门大学硕士学位论文, 2014.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KJSJ201515074&amp;v=MTg3MTZVci9NTGlmWVpMRzRIOVROcW85Q1lJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 张艳军, 等.基于视觉注意机制的行人检测方法[J].科技视野, .2015, (15) :98, 168.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201611031&amp;v=MTk3MTh0R0ZyQ1VSN3FmWnVabkZ5amdVci9NTmlmWVpMRzRIOWZOcm85R1pZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 靳培飞, 等.基于感兴趣区域提取的行人检测[J].计算机工程与设计, 2016, 37 (11) :3035-3039.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201907089" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201907089&amp;v=MDAwNDFyQ1VSN3FmWnVabkZ5amdVci9NTHo3QmRMRzRIOWpNcUk5TmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
