<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141011097760000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201906089%26RESULT%3d1%26SIGN%3dPMzjL6xjuXQpK0ZOq%252fIuJV3YM9I%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201906089&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201906089&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201906089&amp;v=Mjc4NjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N21WNy9MTHo3QmRMRzRIOWpNcVk5TmJZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;2 小尺度图像细节层高频分量的提取方法&lt;/b&gt; "><b>2 小尺度图像细节层高频分量的提取方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#32" data-title="&lt;b&gt;2.1 基于双边滤波器的图像去噪&lt;/b&gt;"><b>2.1 基于双边滤波器的图像去噪</b></a></li>
                                                <li><a href="#42" data-title="&lt;b&gt;2.2 融合双边滤波与改进PCNN的分量提取方法&lt;/b&gt;"><b>2.2 融合双边滤波与改进PCNN的分量提取方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#59" data-title="&lt;b&gt;3 仿真研究&lt;/b&gt; "><b>3 仿真研究</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#74" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="&lt;b&gt;图1 三种不同方法的提取结果对比&lt;/b&gt;"><b>图1 三种不同方法的提取结果对比</b></a></li>
                                                <li><a href="#69" data-title="&lt;b&gt;表1 对比度均方根值对比表&lt;/b&gt;"><b>表1 对比度均方根值对比表</b></a></li>
                                                <li><a href="#72" data-title="&lt;b&gt;表2 拟合度对比结果&lt;/b&gt;"><b>表2 拟合度对比结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 韦瑞峰, 赵荣普, 徐肖庆, 等.基于直方图的红外图像细节增强算法研究[J].红外技术, 2016, 38 (6) :472-475." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWJS201606005&amp;v=MDk5ODBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N21WNy9MTFRyQmZiRzRIOWZNcVk5RllZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         韦瑞峰, 赵荣普, 徐肖庆, 等.基于直方图的红外图像细节增强算法研究[J].红外技术, 2016, 38 (6) :472-475.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 田馨, 廖明生.精确提取InSAR时间去相关分量的方法[J].红外与毫米波学报, 2016, 35 (4) :454-461." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH201604013&amp;v=MjYwODl1Wm5GeTdtVjcvTExUclNackc0SDlmTXE0OUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         田馨, 廖明生.精确提取InSAR时间去相关分量的方法[J].红外与毫米波学报, 2016, 35 (4) :454-461.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 于来行, 冯林, 张晶, et al.自适应融合目标和背景的图像特征提取方法[J].计算机辅助设计与图形学学报, 2016, 28 (8) :1250-1259." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201608006&amp;v=MTQ4ODZHNEg5Zk1wNDlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnk3bVY3L0xMejdCYUw=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         于来行, 冯林, 张晶, et al.自适应融合目标和背景的图像特征提取方法[J].计算机辅助设计与图形学学报, 2016, 28 (8) :1250-1259.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 曾接贤, 祝小超, 符祥.一种改进的复杂图像线特征提取方法[J].中国图象图形学报, 2018, 15 (12) :1748-1754." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201012007&amp;v=MTYwODZHNEg5SE5yWTlGWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnk3bVY3L0xQeXJmYkw=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         曾接贤, 祝小超, 符祥.一种改进的复杂图像线特征提取方法[J].中国图象图形学报, 2018, 15 (12) :1748-1754.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 张元峰, 郝世勇, 司剑飞, 等.基于传输矩阵的电力变压器高频网络参数计算[J].电子设计工程, 2018, 26 (3) :84-88." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201803019&amp;v=MjAyODNQZExHNEg5bk1ySTlFYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnk3bVY3L0xJanI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         张元峰, 郝世勇, 司剑飞, 等.基于传输矩阵的电力变压器高频网络参数计算[J].电子设计工程, 2018, 26 (3) :84-88.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     于来行, 冯林, 张晶, 等.自适应融合目标和背景的图像特征提取方法[J].计算机辅助设计与图形学学报, 2016, 28 (8) :1250-1259.</a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 杨静, 李争.一种基于双边滤波的红外图像细节增强方法[J].激光与红外, 2016, 46 (4) :507-511." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGHW201604026&amp;v=MDY4MTR6cXFCdEdGckNVUjdxZlp1Wm5GeTdtVjcvTEx5ckRlYkc0SDlmTXE0OUhZb1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         杨静, 李争.一种基于双边滤波的红外图像细节增强方法[J].激光与红外, 2016, 46 (4) :507-511.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 施丽红, 刘刚.基于改进蜂群优化的图像分割算法[J].电视技术, 2016, 40 (2) :37-44." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSSS201602008&amp;v=MzE0NzZxQnRHRnJDVVI3cWZadVpuRnk3bVY3L0xJVDdZZmJHNEg5Zk1yWTlGYklRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         施丽红, 刘刚.基于改进蜂群优化的图像分割算法[J].电视技术, 2016, 40 (2) :37-44.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 卢献健, 晏红波, 梁月吉.小波分解层数及分量组合对滑坡预测的影响[J].桂林理工大学学报, 2016, 36 (2) :304-309." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GLGX201602018&amp;v=MTA3MjRSN3FmWnVabkZ5N21WNy9MSWlITWRyRzRIOWZNclk5RWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         卢献健, 晏红波, 梁月吉.小波分解层数及分量组合对滑坡预测的影响[J].桂林理工大学学报, 2016, 36 (2) :304-309.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 郝志成, 吴川, 杨航, 等.基于双边纹理滤波的图像细节增强方法[J].中国光学, 2016, 9 (4) :423-431." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGGA201604005&amp;v=MDk5NjNNYjdHNEg5Zk1xNDlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnk3bVY3L0xQeXI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         郝志成, 吴川, 杨航, 等.基于双边纹理滤波的图像细节增强方法[J].中国光学, 2016, 9 (4) :423-431.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 巨刚, 袁亮, 刘小月, 等.多算法融合的自适应图像增强方法[J].光子学报, 2016, 45 (12) :136-144." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GZXB201612025&amp;v=MjU5MTgvTElqZlRiTEc0SDlmTnJZOUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeTdtVjc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         巨刚, 袁亮, 刘小月, 等.多算法融合的自适应图像增强方法[J].光子学报, 2016, 45 (12) :136-144.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 谢洪森, 周鹏, 栾宝宽, 等.一种海杂波纹理分量提取方法研究[J].雷达科学与技术, 2017, 15 (3) :251-254." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=LDKJ201703005&amp;v=MjA3OTlHRnJDVVI3cWZadVpuRnk3bVY3L0xLU25BWkxHNEg5Yk1ySTlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         谢洪森, 周鹏, 栾宝宽, 等.一种海杂波纹理分量提取方法研究[J].雷达科学与技术, 2017, 15 (3) :251-254.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(06),430-433             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>小尺度图像细节层的高频分量提取仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E9%81%93%E9%9D%99&amp;code=34005134&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨道静</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%88%90%E9%83%BD%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E9%93%B6%E6%9D%8F%E9%85%92%E5%BA%97%E7%AE%A1%E7%90%86%E5%AD%A6%E9%99%A2&amp;code=1699079&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">成都信息工程大学银杏酒店管理学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>目前视觉领域针对图像处理没有相对完善的方案, 缺少有效提取图像的高频分量方法, 因此采用当前方法对小尺度图像细节层的高频分量进行提取时, 存在分量提取效果不佳、图像细节信息不显著以及视觉效果不好等问题, 提出一种基于人工神经网络模型的小尺度图像细节层高频分量提取方法。首先对待处理的小尺度图像进行双边滤波去噪, 对平滑图像进行离散小波变换, 提取出图像细节层中水平细节分量、垂直细节分量、对角细节分量;然后采用人工神经网络模型对提取出的三个细节层分量进行增强处理, 进一步体现细节层的高频分量, 使提取的高频分量更为平滑。仿真实验证明, 所提方法对小尺度图像的高频分量提取精度较高、所需时间较短。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E7%BB%86%E8%8A%82%E5%B1%82&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像细节层;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E9%A2%91%E5%88%86%E9%87%8F%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高频分量提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像处理;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    杨道静 (1982-) , 女 (汉族) , 湖北荆门人, 硕士, 讲师, 研究方向:计算机应用, 图像处理, 数据挖掘。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-27</p>

                    <p>

                            <b>基金：</b>
                                                        <span>四川省教育发展研究中心项目:教育信息化与教育教学的融合研究 (CJF18021);</span>
                                <span>四川省农村发展研究中心项目:成都市“互联网+乡村旅游”发展研究 (CR1603);</span>
                    </p>
            </div>
                    <h1><b>High-frequency component extraction simulation of small-scale image detail layer</b></h1>
                    <h2>
                    <span>YANG Dao-jing</span>
            </h2>
                    <h2>
                    <span>Yinxing Hospitality Management College of CUIT</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>At present, the method for effectively extracting high-frequency component of image in the field of vision is lacked. In current methods, the component extraction effect is poor and the image detail information is not significant. Therefore, a method for extracting high-frequency components in detail layer of small-scale image based on artificial neural network model was presented. Firstly, the bilateral filtering de-noising was performed on the small-scale image to be processed. Secondly, the discrete wavelet transform was applied to the smoothed image, so as to extract the horizontal detail component, the vertical detail component and the diagonal detail component in image detail layer. Then, the artificial neural network model was used to enhance the components in three detail layer and thus to further reflect the high frequency components in detail layer. Thus, the extracted high frequency components could be smoother. Simulation proves that the proposed method has high precision and low time consumption for extracting the high-frequency component in small-scale image.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20detail%20layer&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Image detail layer;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=High%20frequency%20component%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">High frequency component extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Image processing;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-27</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="27" name="27" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="28">计算机和网络技术的飞速发展, 图像、视频等多媒体技术备受关注, 人们可以从图像或视频中直接获得信息, 因此图像处理技术至关重要<citation id="76" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。图像分量提取是图像处理工作中的重点, 很多图像处理都是以图像分量提取为基础, 但当前国内针对小尺度图像细节层进行高频分量提取方法普遍存在精度较差、提取效率低等问题, 且无法满足高频分量检测应用的需求。而基于人工神经网络模型的小尺度图像细节层高频分量提取方法通过人工神经网络模型对提取图像细节层中水平细节分量、垂直细节分量、对角细节分量进行细节增强, 计算过程较为简洁, 保证了提取精度, 同时提高了提取效率, 有效的解决了上述问题, 由于图像分量的提取对图像处理工作具有重大意义, 因此深受广大学者的关注, 同时也出现了很多较好的研究成果。</p>
                </div>
                <div class="p1">
                    <p id="29">文献<citation id="77" type="reference">[<a class="sup">2</a>]</citation>提出一种基于加权量化的图像细节层高频分量提取方法。该方法首先按照视觉选择特性将图像设定为9种新结构元, 并创建图像连通粒属性和图像分层统计模型;然后通过图像分量颜色转换和结构元匹配, 形成相应的细节层图像, 从中统计需提取的高频分量;最后利用自适应高频分量融合模型将高频分量进行组合, 进而实现对图像的高频分量提取。该方法对图像高频分量的提取精确度较低, 效果不显著, 且运行过程较为繁琐, 耗时长。文献<citation id="78" type="reference">[<a class="sup">3</a>]</citation>提出了一种基于复杂图像的高频分量特征提取方法。该方法采用小波变换方法对图像进行去噪处理, 以去除噪声等其他因素产生的影响, 采用Beamlet变换对平滑图像进行变换, 统计出变换系数集合;然后设定阈值和新的能量统计构造最优基, 通过最优基将最佳的高频分量提取出来。采取该方法进行高频分量提取时, 忽略对环境等因素的考虑, 使提取出的高频分量存在不同程度的细节丢失, 提取效果较差。</p>
                </div>
                <div class="p1">
                    <p id="30">针对上述问题, 提出一种基于小尺度图像细节层的高频分量提取方法。实验仿真证明, 所提方法对图像的高频分量提取精确度较高, 图像细节比较清晰, 并且处理后的图像视觉效果较原图没有太大的改变, 保证了图像的视觉效果, 可为图像处理工作提供很大帮助。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>2 小尺度图像细节层高频分量的提取方法</b></h3>
                <h4 class="anchor-tag" id="32" name="32"><b>2.1 基于双边滤波器的图像去噪</b></h4>
                <div class="p1">
                    <p id="33">由于图像在成像过程中会受到环境等因素的影响, 需要对图像进行去噪等处理<citation id="79" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。双边滤波器运行过程简洁, 运算效果高效, 受到图像处理成功案例的启发, Fleishman等相关专家学者在图像三维网格中设定点<i>p</i>的偏转程度量<i>d</i>:</p>
                </div>
                <div class="p1">
                    <p id="34" class="code-formula">
                        <mathml id="34"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>Ν</mi></mrow></munder><mi>W</mi></mstyle><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>p</mi></mrow><mo>|</mo></mrow><mo stretchy="false">) </mo><mi>W</mi><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mo>〈</mo><mi>n</mi><mo>, </mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>p</mi><mo>〉</mo></mrow><mo>|</mo></mrow><mo stretchy="false">) </mo><mo>〈</mo><mi>n</mi><mo>, </mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>p</mi><mo>〉</mo></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>Ν</mi></mrow></munder><mi>W</mi></mstyle><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>p</mi></mrow><mo>|</mo></mrow><mo stretchy="false">) </mo><mi>W</mi><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mo>〈</mo><mi>n</mi><mo>, </mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>p</mi><mo>〉</mo></mrow><mo>|</mo></mrow><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="35">式中:<i>N</i>是点<i>p</i>的相邻区域;<i>n</i>是点法向量;<i>W</i><sub><i>C</i></sub>为决定光滑水平的高斯函数, <i>W</i><sub><i>C</i></sub> (<i>x</i>) =<i>e</i><sup>-<i>x</i><sup>2</sup>/2<i>σ</i><sup>2</sup><sub><i>c</i></sub></sup>, 其中<i>σ</i><sub><i>C</i></sub>值越大, 滤波器的光滑性越好;<i>W</i><sub><i>S</i></sub>是维持特征的高斯函数, <i>W</i><sub><i>S</i></sub> (<i>x</i>) =<i>e</i><sup>-<i>x</i><sup>2</sup>/2<i>σ</i><sup>2</sup><sub><i>S</i></sub></sup>, 其中<i>σ</i><sub><i>S</i></sub>值越小, 滤波器维持特征效果越好。得到偏转程度量<i>d</i>后, 点<i>p</i>的新坐标为:</p>
                </div>
                <div class="p1">
                    <p id="36" class="code-formula">
                        <mathml id="36"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo>=</mo><mi>p</mi><mo>+</mo><mi>d</mi><mo>˚</mo><mi>n</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="37">根据式 (1) 可知, 网格中的双边滤波器其实是部分拟合的一个平面, 在拟合过程中进行优化, 这种优化方式带来的最明显问题是三维网格模型的高曲率区域会出现平滑过渡现象, 从能量扩散的角度分析可知, 高曲率点区域的能量消耗速度快, 只有拟合一个高次曲面才能够减缓或者阻止这种现象<citation id="80" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="38">对不同元素进行归一化处理后, 在图像表面部分创建一个光滑的二次曲面, 可得图像中任意点<i>p</i>的新的标准构架和主曲率, 同时也可得到新的二次曲面<i>S</i><sub><i>p</i></sub>;把该点相邻区域<i>N</i>中点<i>p</i><sub><i>i</i></sub>顺着点<i>p</i>的法方向<i>n</i>到<i>S</i><sub><i>p</i></sub>的距离设定为<i>S</i><sub><i>i</i></sub>, 双边滤波器的形式为:</p>
                </div>
                <div class="p1">
                    <p id="39" class="code-formula">
                        <mathml id="39"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>Ν</mi></mrow></munder><mi>W</mi></mstyle><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>p</mi></mrow><mo>|</mo></mrow><mo stretchy="false">) </mo><mi>W</mi><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>Ν</mi></mrow></munder><mi>W</mi></mstyle><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>p</mi></mrow><mo>|</mo></mrow><mo stretchy="false">) </mo><mi>W</mi><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><mo stretchy="false">) </mo></mrow></mfrac><mo>˚</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="40">将式 (3) 代入到式 (2) , 可得出经过滤波后的新坐标。</p>
                </div>
                <div class="p1">
                    <p id="41">通过上述过程可有效地去除图像噪声, 同时小尺度图像细节信息也得以保持。</p>
                </div>
                <h4 class="anchor-tag" id="42" name="42"><b>2.2 融合双边滤波与改进PCNN的分量提取方法</b></h4>
                <div class="p1">
                    <p id="43">通过对人眼视觉系统特性的分析, 人眼对小尺度图像不同方向的细节高频分量具有不同的分辨率, 能够准确获取具有方向性的视觉元素<citation id="81" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。但是双边滤波算法由于不具有尺度、平移不变性, 使其在增强细节层高频信息时受到较大的限制。为了有效克服双边滤波器的缺点, 结合小波变换算法对人工神经网络模型 (PCNN) 进行改进, 得到LG-PCNN, 并融合双边滤波器来提取细节层高频分量, 并对其进行增强处理<citation id="82" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="44">采用人工神经网络模型处理双边滤波器平滑后的小尺度图像时, 参数设定是整个过程中较为繁琐且重要的工作, 可划分为以下三个步骤:输入相关参数的设定、调节相关参数的设定, 提取阈值的设定, 各个参数在神经网络神经元的行为变化中具有独立性。一般情况下, 人工神经网络模型的参数是事先设定的<citation id="83" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, 利用恒定的参数在一定程度上影响了细节层高频分量的提取效果。所提出的提取方法对直接影响高频分量提取效果的两个参数 (链接强度系数<i>β</i><sub><i>ij</i></sub>和提取阈值<i>θ</i><sub><i>ij</i></sub>) 进行了改进, 获得人工神经网络模型。</p>
                </div>
                <div class="p1">
                    <p id="45">链接强度系数<i>β</i><sub><i>ij</i></sub>负责调控邻近神经元对中心神经元点火周期的影响等级, 该值一般根据实际需求经多次实验来确定, 但在人眼视觉系统中, 神经网络中每个神经元的链接强度不同, 恒定的链接强度在一定程度上限制了对高频分量进一步提取的结果<citation id="84" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。依据人眼视觉系统对细节层高频分量较为敏感这一特点, 人工神经网络模型神经元的链接强度应当与小尺度图像的高频分量相关<citation id="85" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。在其他神经元参数确定的情况下, 参数<i>β</i><sub><i>ij</i></sub>的值越大, 说明人工神经网络模型中的任意神经元受其邻近区域神经元的影响较大, 内部动态项<i>U</i><sub><i>ij</i></sub>变化较为显著。由于小尺度图像像素的梯度在一定程度上能够反映细节层的高频分量, 所以将局部梯度值作为人工神经网络模型的链接强度系数<i>β</i><sub><i>ij</i></sub>, 使<i>β</i><sub><i>ij</i></sub>能够依据链接输入细节层不同的灰度分布特征进行动态设置。选取一个大小为3×3的区域窗口, 设定此区域内中心像素的坐标为 (<i>i</i>, <i>j</i>) , 则其3×3窗口相应的像素坐标可描述为, 即:</p>
                </div>
                <div class="p1">
                    <p id="46" class="code-formula">
                        <mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>B</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>i</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo>-</mo><mn>1</mn></mtd><mtd><mi>i</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>j</mi></mtd><mtd><mi>i</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo>+</mo><mn>1</mn></mtd></mtr><mtr><mtd><mi>i</mi><mo>, </mo><mi>j</mi><mo>-</mo><mn>1</mn></mtd><mtd><mi>i</mi><mo>, </mo><mi>j</mi></mtd><mtd><mi>i</mi><mo>, </mo><mi>j</mi><mo>+</mo><mn>1</mn></mtd></mtr><mtr><mtd><mi>i</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo>-</mo><mn>1</mn></mtd><mtd><mi>i</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>j</mi></mtd><mtd><mi>i</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo>+</mo><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="47">链接强度系数设定如下:</p>
                </div>
                <div class="p1">
                    <p id="48" class="code-formula">
                        <mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>β</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn><mo>/</mo><mi>c</mi><msqrt><mrow><mi>D</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>+</mo><mi>D</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msqrt><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>D</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><msqrt><mrow><mo stretchy="false">[</mo><msup><mi>d</mi><mo>′</mo></msup><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>+</mo><mo stretchy="false">[</mo><msup><mi>d</mi><mo>′</mo></msup><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow></msqrt><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="49">其中, <i>c</i>表示调整系数, <i>I</i>表示传递的转矩, <i>D</i><sub>1</sub> (<i>i</i>, <i>j</i>) 与<i>D</i><sub>2</sub> (<i>i</i>, <i>j</i>) 分别表示此区域内任意像素点到中心像素的距离, <i>d</i>′表示此区域内对角像素与中心像素之间的距离权重系数。</p>
                </div>
                <div class="p1">
                    <p id="50">链接强度系数<i>β</i><sub><i>ij</i></sub>能够按照邻域窗口内像素值的变化动态调整期大小, 不同的像素值有其相应的链接强度系数<citation id="86" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。原始小尺度图像经过小波分解后, 低频分量用于描述小尺度图像细节层的主要信息, 系数之间关联性较大, 其邻域窗口内中心像素与周期像素之间的链接强度也较大;此时激励窗口内邻域同步点火, 使细节层低频分量得到平滑, 而高频分量用于描述细节层边缘信息, 系数之间的关联性较小, 中心像素与邻近像素之间的链接强度也较小, 此时抑制邻域像素同步点火, 进一步突出细节层的细节信息<citation id="87" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="51">提取阈值<i>θ</i><sub><i>ij</i></sub>负责控制人工神经网络模型中神经元是否点火, 也决定着人工神经网络模型的同步脉冲发放特性。为了减少人工神经网络模型对小尺度图像细节层高频分量处理能力的干扰和影响, 在任意神经元提取阈值<i>θ</i><sub><i>ij</i></sub>内捆绑一个抑制信号<i>R</i><sub><i>ij</i></sub>, 用于控制神经元的阈值输出, 使输出结果更符合高频分量的提取需求, 抑制信号<i>R</i><sub><i>ij</i></sub>设定如下:</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>f</mi><mo stretchy="false"> (</mo><mn>1</mn><mo>/</mo><mi>β</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">修正后的动态提取阈值<i>θ</i><sub><i>ij</i></sub>利用下式表示:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>θ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">[</mo><mi>n</mi><mo stretchy="false">]</mo><mo>=</mo><msup><mi>θ</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">[</mo><mi>n</mi><mo stretchy="false">]</mo><mo>+</mo><mi>R</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">其中, <i>n</i>表示人工神经网络模型的迭代次数, <i>θ</i>′<sub><i>ij</i></sub>[<i>n</i>]表示修正前的阈值函数。</p>
                </div>
                <div class="p1">
                    <p id="56">由于人工神经网络模型将最能体现细节层的局部梯度值作为链接强度系数, 并设定在提取的阈值中捆绑抑制信号来增强更多的高频分量。人工神经网络模型用于细节层高频分量的核心原则为:任意一个神经元与其邻近神经元像素灰度值差异越大, <i>β</i><sub><i>ij</i></sub>越小, <i>U</i><sub><i>ij</i></sub>越小, 则<i>β</i><sub><i>ij</i></sub>越大, <i>θ</i><sub><i>ij</i></sub>越大, 邻近神经元越不易同时点火, 这样提取出的小尺度细节层像素灰度值差异较大, 高频分量提取效果越好, 其中<i>α</i>表示分量提取系数, 提取结果如下:</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>U</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">[</mo><mi>n</mi><mo stretchy="false">]</mo><mo>=</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">[</mo><mi>n</mi><mo stretchy="false">]</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mi>β</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>L</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">[</mo><mi>n</mi><mo stretchy="false">]</mo><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>θ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">[</mo><mi>n</mi><mo stretchy="false">]</mo><mo>=</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi>α</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false">) </mo><mi>θ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">[</mo><mi>n</mi><mo>-</mo><mn>1</mn><mo stretchy="false">]</mo><mo>+</mo><mi>Y</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">[</mo><mi>n</mi><mo>-</mo><mn>1</mn><mo stretchy="false">]</mo><mo>+</mo><mi>R</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">以上就完成了小尺度图像细节层的高频分量提取。</p>
                </div>
                <h3 id="59" name="59" class="anchor-tag"><b>3 仿真研究</b></h3>
                <div class="p1">
                    <p id="60">实验平台采用:WINDOWS 7系统, CPU E7500 3.5GHz, 8GB内存;开发环境VS2012, VC++基于OpenCV。选用的实验对象是图像的五组细节层, 分别对图像的细节层做增强处理, 图像尺寸为300*415, 位宽是16bits, 而输出图像更适合8bits灰度图像。</p>
                </div>
                <div class="p1">
                    <p id="61">为了验证所提方法的有效性, 分别采用文献<citation id="88" type="reference">[<a class="sup">2</a>]</citation>方法、文献<citation id="89" type="reference">[<a class="sup">3</a>]</citation>方法和所提方法对小尺度图像细节层的高频分量进行提取, 并对三种方法的提取准确率以及运行时间进行比较, 对比结果如图1所示:</p>
                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201906089_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 三种不同方法的提取结果对比" src="Detail/GetImg?filename=images/JSJZ201906089_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 三种不同方法的提取结果对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201906089_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="63">分析图1可知:三种方法提取高频分量的准确率均达到90%以上, 其中文献<citation id="90" type="reference">[<a class="sup">2</a>]</citation>方法提取高频分量的准确率与文献<citation id="91" type="reference">[<a class="sup">3</a>]</citation>方法和所提方法相比, 其准确率偏低, 由于文献<citation id="92" type="reference">[<a class="sup">2</a>]</citation>方法忽略了图像细节层, 在对高频分量进行组合时, 存在冗余分量, 导致提取结果存在误差。三种方法在提取过程中, 所需时间最多的是文献<citation id="93" type="reference">[<a class="sup">3</a>]</citation>方法, 由于该方法需要对图像进行预处理, 并对处理后的图像进行Beamlet变换, 再进行高频分量提取, 整体运行过程较为繁琐, 因此所需时间较多, 但提取高频分量的精确度较高。文献<citation id="94" type="reference">[<a class="sup">2</a>]</citation>方法和文献<citation id="95" type="reference">[<a class="sup">3</a>]</citation>方法的提取精度均低于所提方法, 证实所提方法提取精确度较高;文献<citation id="96" type="reference">[<a class="sup">2</a>]</citation>方法和文献<citation id="97" type="reference">[<a class="sup">3</a>]</citation>方法的运算时间均高于所提方法, 说明所提方法提取效率较高, 具有可行性。</p>
                </div>
                <div class="p1">
                    <p id="64">为进一步验证所提方法的可信度, 以对比度均方根作为评价指标, 对提取的结果进行准确度评价, 选取对比度均方根 (RMSC) 作为评价指标, 公式为:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>Μ</mi><mi>S</mi><mi>C</mi><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mrow><mi>Μ</mi><mo>⋅</mo><mi>Ν</mi></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mrow><mrow><mo>[</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mover accent="true"><mi>Ι</mi><mo>¯</mo></mover></mrow><mo>]</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">式中:<mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>-</mo><mover accent="true"><mi>Ι</mi><mo>¯</mo></mover></mrow></math></mathml>是图像中像素的平均值;<i>M</i>和<i>N</i>分别是图像的行和列数。</p>
                </div>
                <div class="p1">
                    <p id="68">如果对比度均方根值越大, 说明图像细节层高频信息提取精度越高, 高频信息越丰富, 但是该值过大, 会造成提取的图像亮度过高, 因此该值在100以内且越接近100, 其图像细节层高频信息提取效果越好, 统计结果如表1所示:</p>
                </div>
                <div class="area_img" id="69">
                    <p class="img_tit"><b>表1 对比度均方根值对比表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="69" border="1"><tr><td rowspan="2"><br />图像</td><td colspan="3"><br />对比度均方根值/C</td></tr><tr><td><br />文献[2]方法</td><td>文献[3]方法</td><td>所提方法</td></tr><tr><td><br />细节层A</td><td>140.25</td><td>5.98</td><td>75.35</td></tr><tr><td><br />细节层B</td><td>225.13</td><td>10.24</td><td>79.68</td></tr><tr><td><br />细节层C</td><td>136.59</td><td>21.87</td><td>65.84</td></tr><tr><td><br />细节层D</td><td>148.63</td><td>19.61</td><td>85.65</td></tr><tr><td><br />细节层E</td><td>150.04</td><td>30.88</td><td>89.30</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="70">分析表1可知, 文献<citation id="98" type="reference">[<a class="sup">2</a>]</citation>方法处理的图像对比度均方根值最大, 导致亮度过大视觉效果不好。文献<citation id="99" type="reference">[<a class="sup">3</a>]</citation>方法处理的图像对比度均方根值最小, 造成亮度过低而影响降低图像的分辨率, 影响视觉效果。而所提方法处理后的图像与之相比, 对比度均方根值适中, 对图像的影响不明显, 视觉效果也较好。</p>
                </div>
                <div class="p1">
                    <p id="71">为了进一步验证本文方法的优越性, 利用本文方法、文献<citation id="100" type="reference">[<a class="sup">2</a>]</citation>、文献<citation id="101" type="reference">[<a class="sup">3</a>]</citation>方法进行小尺度图像细节层的高频分量提取与原始视频图像的拟合度对比, 该值越接近1, 说明该方法与原图像的拟合度越高, 提取出来的图像与原图像的相似度越高, 实验结果如表2所示。</p>
                </div>
                <div class="area_img" id="72">
                    <p class="img_tit"><b>表2 拟合度对比结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="72" border="1"><tr><td rowspan="2"><br />实验次数/次</td><td colspan="3"><br />拟合度</td></tr><tr><td><br />文献[2]方法</td><td>文献[3]方法</td><td>所提方法</td></tr><tr><td><br />1</td><td>0.56</td><td>0.78</td><td>0.94</td></tr><tr><td><br />2</td><td>0.64</td><td>0.72</td><td>0.95</td></tr><tr><td><br />3</td><td>0.35</td><td>0.69</td><td>0.92</td></tr><tr><td><br />4</td><td>0.62</td><td>0.70</td><td>0.96</td></tr><tr><td><br />5</td><td>0.51</td><td>0.66</td><td>0.97</td></tr><tr><td><br />6</td><td>0.46</td><td>0.68</td><td>0.95</td></tr><tr><td><br />7</td><td>0.59</td><td>0.75</td><td>0.98</td></tr><tr><td><br />8</td><td>0.43</td><td>0.77</td><td>0.97</td></tr><tr><td><br />9</td><td>0.48</td><td>0.73</td><td>0.98</td></tr><tr><td><br />10</td><td>0.47</td><td>0.74</td><td>0.97</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="73">分析图2可知, 与其他两种方法相比, 文献<citation id="102" type="reference">[<a class="sup">2</a>]</citation>方法与原图的拟合度最低, 因此说明该方法在进行小尺度图像细节层的高频分量提取时, 对原图像的还原度最低, 导致提取到的图像视觉效果最差;文献<citation id="103" type="reference">[<a class="sup">3</a>]</citation>方法的拟合度处在文献<citation id="104" type="reference">[<a class="sup">2</a>]</citation>方法与所提方法之间, 虽然对原图的还原度比文献<citation id="105" type="reference">[<a class="sup">2</a>]</citation>方法要高, 但是始终低于所提方法, 所以经过拟合度实验证明, 本文方法对原图的还原度最高, 因此进一步验证了本文方法对小尺度图像细节层进行高频分量提取时, 其效果最好。</p>
                </div>
                <h3 id="74" name="74" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="75">图像分量提取是图像处理工作中的重点, 因此要对图像分量提取方法进行进一步研究, 因为采用传统提取方法进行小尺度图像细节层高频分量提取时, 存在有效性低、精度差、视觉效果不好等问题。提出一种基于小尺度图像细节层的高频分量提取方法。实验仿真证明, 所提方法对高频分量的提取效果精确, 提取后对图像细节影响较小, 且处理后的图像视觉效果与原图像极为相似, 说明所提方法具有可信度, 能够更好地为图像处理工作提供帮助。但是由于实验对象选取的较少, 因此提取精度方面还有待改进, 对于存在的问题会做进一步研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="107" type="" href="images/JSJZ201906089_10700.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">杨道静</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWJS201606005&amp;v=MDA3MDhadVpuRnk3bVY3L0xMVHJCZmJHNEg5Zk1xWTlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 韦瑞峰, 赵荣普, 徐肖庆, 等.基于直方图的红外图像细节增强算法研究[J].红外技术, 2016, 38 (6) :472-475.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH201604013&amp;v=MDM2NTlMTFRyU1pyRzRIOWZNcTQ5RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N21WNy8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 田馨, 廖明生.精确提取InSAR时间去相关分量的方法[J].红外与毫米波学报, 2016, 35 (4) :454-461.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201608006&amp;v=MTg3ODZHNEg5Zk1wNDlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnk3bVY3L0xMejdCYUw=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 于来行, 冯林, 张晶, et al.自适应融合目标和背景的图像特征提取方法[J].计算机辅助设计与图形学学报, 2016, 28 (8) :1250-1259.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201012007&amp;v=MDEzNTR6cXFCdEdGckNVUjdxZlp1Wm5GeTdtVjcvTFB5cmZiTEc0SDlITnJZOUZZNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 曾接贤, 祝小超, 符祥.一种改进的复杂图像线特征提取方法[J].中国图象图形学报, 2018, 15 (12) :1748-1754.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201803019&amp;v=MTQyMDNVUjdxZlp1Wm5GeTdtVjcvTElqclBkTEc0SDluTXJJOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 张元峰, 郝世勇, 司剑飞, 等.基于传输矩阵的电力变压器高频网络参数计算[J].电子设计工程, 2018, 26 (3) :84-88.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 于来行, 冯林, 张晶, 等.自适应融合目标和背景的图像特征提取方法[J].计算机辅助设计与图形学学报, 2016, 28 (8) :1250-1259.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGHW201604026&amp;v=MDk5NDU3cWZadVpuRnk3bVY3L0xMeXJEZWJHNEg5Zk1xNDlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 杨静, 李争.一种基于双边滤波的红外图像细节增强方法[J].激光与红外, 2016, 46 (4) :507-511.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSSS201602008&amp;v=MjQ1NDFUN1lmYkc0SDlmTXJZOUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeTdtVjcvTEk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 施丽红, 刘刚.基于改进蜂群优化的图像分割算法[J].电视技术, 2016, 40 (2) :37-44.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GLGX201602018&amp;v=MDUyOTNZOUViSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeTdtVjcvTElpSE1kckc0SDlmTXI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 卢献健, 晏红波, 梁月吉.小波分解层数及分量组合对滑坡预测的影响[J].桂林理工大学学报, 2016, 36 (2) :304-309.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGGA201604005&amp;v=MTQxMDBQeXJNYjdHNEg5Zk1xNDlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnk3bVY3L0w=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 郝志成, 吴川, 杨航, 等.基于双边纹理滤波的图像细节增强方法[J].中国光学, 2016, 9 (4) :423-431.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GZXB201612025&amp;v=MTEyNzN5N21WNy9MSWpmVGJMRzRIOWZOclk5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 巨刚, 袁亮, 刘小月, 等.多算法融合的自适应图像增强方法[J].光子学报, 2016, 45 (12) :136-144.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=LDKJ201703005&amp;v=MDczMjc0SDliTXJJOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeTdtVjcvTEtTbkFaTEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 谢洪森, 周鹏, 栾宝宽, 等.一种海杂波纹理分量提取方法研究[J].雷达科学与技术, 2017, 15 (3) :251-254.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201906089" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201906089&amp;v=Mjc4NjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N21WNy9MTHo3QmRMRzRIOWpNcVk5TmJZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
