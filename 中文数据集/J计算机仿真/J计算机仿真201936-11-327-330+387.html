<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139117252318750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJSJZ201911071%26RESULT%3d1%26SIGN%3d9KyTRvcEmcO32SDpUImyEUbwXGg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201911071&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201911071&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201911071&amp;v=MDkwMzMzenFxQnRHRnJDVVI3cWZadVpwRnl2Z1dyck1MejdCZExHNEg5ak5ybzlDWllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#23" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;2 模糊图像角点特征提取方法&lt;/b&gt; "><b>2 模糊图像角点特征提取方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#28" data-title="&lt;b&gt;2.1 图像角点检测&lt;/b&gt;"><b>2.1 图像角点检测</b></a></li>
                                                <li><a href="#64" data-title="&lt;b&gt;2.2 图像角点特征提取&lt;/b&gt;"><b>2.2 图像角点特征提取</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="&lt;b&gt;3 仿真证明及分析&lt;/b&gt; "><b>3 仿真证明及分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#100" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#56" data-title="&lt;b&gt;图1 方向模板示意图&lt;/b&gt;"><b>图1 方向模板示意图</b></a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;图2 多角点结合的图像角点提取方法流程图&lt;/b&gt;"><b>图2 多角点结合的图像角点提取方法流程图</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;表1 提取角点特征数目&lt;/b&gt;"><b>表1 提取角点特征数目</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;图3 特征提取所用时间对比图&lt;/b&gt;"><b>图3 特征提取所用时间对比图</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;表2 噪声干扰下各方法的效果比较&lt;/b&gt;"><b>表2 噪声干扰下各方法的效果比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="150">


                                    <a id="bibliography_1" title=" 刘桂华,陈林宇,肖得胜.基于FPGA的图像多尺度特征点提取及匹配[J].电视技术,2016,40(9):103-107." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSSS201609022&amp;v=MjE4OThyTUlUN1lmYkc0SDlmTXBvOUhab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXZnV3I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[1]</b>
                                         刘桂华,陈林宇,肖得胜.基于FPGA的图像多尺度特征点提取及匹配[J].电视技术,2016,40(9):103-107.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_2" title=" 查易艺,孙权森,罗楠,等.基于FAST和DAISY的遥感图像配准算法[J].计算机应用研究,2016,33(2):624-628." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201602071&amp;v=MTA1NzVDWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnl2Z1dyck1MejdTWkxHNEg5Zk1yWTk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[2]</b>
                                         查易艺,孙权森,罗楠,等.基于FAST和DAISY的遥感图像配准算法[J].计算机应用研究,2016,33(2):624-628.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_3" title=" 刘子腾.基于激光视觉的角焊缝图像特征点提取[J].焊接学报,2016,37(2):89-93." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HJXB201602022&amp;v=Mjk3ODFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnl2Z1dyck1MU2ZUYkxHNEg5Zk1yWTlIWm9RS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[3]</b>
                                         刘子腾.基于激光视觉的角焊缝图像特征点提取[J].焊接学报,2016,37(2):89-93.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_4" title=" 陈庄,杨峰,冯欣,等.多尺度积角点检测和视觉颜色特征的鲁棒车牌定位方法[J].重庆大学学报,2016,9(2):89-98." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=FIVE201602012&amp;v=MjgyNzNZOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXZnV3JyTUl5VGRhN0c0SDlmTXI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[4]</b>
                                         陈庄,杨峰,冯欣,等.多尺度积角点检测和视觉颜色特征的鲁棒车牌定位方法[J].重庆大学学报,2016,9(2):89-98.
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_5" title=" 任立胜,王立中.基于曲率尺度空间的角点检测图像匹配方法分析[J].电子技术应用,2016,42(12):112-114." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZJY201612038&amp;v=MDkyMTlHRnJDVVI3cWZadVpwRnl2Z1dyck1JVGZCZDdHNEg5Zk5yWTlHYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[5]</b>
                                         任立胜,王立中.基于曲率尺度空间的角点检测图像匹配方法分析[J].电子技术应用,2016,42(12):112-114.
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_6" title=" 张盛博,刘娜,霍宏,等.基于层次形状特征提取模型的图像分类[J].高技术通讯,2016,26(1):81-88." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GJSX201601012&amp;v=MTQxNjFpZllkckc0SDlmTXJvOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXZnV3JyTUk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[6]</b>
                                         张盛博,刘娜,霍宏,等.基于层次形状特征提取模型的图像分类[J].高技术通讯,2016,26(1):81-88.
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_7" title=" 李建华,刘柯.基于SURF特征提取的双目测距在铝锭垛定位中的应用研究[J].计算机工程与科学,2016,38(10):2121-2125." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201610024&amp;v=MTY5NzJGeXZnV3JyTUx6N0JaYkc0SDlmTnI0OUhZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnA=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[7]</b>
                                         李建华,刘柯.基于SURF特征提取的双目测距在铝锭垛定位中的应用研究[J].计算机工程与科学,2016,38(10):2121-2125.
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_8" title=" 王德胜,吴钟建,姚秀娟,等.检测图像角点自适应确定跟踪模板的方法[J].红外技术,2017,39(7):638-641." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWJS201707010&amp;v=Mjg2MzNJOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXZnV3JyTUxUckJmYkc0SDliTXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[8]</b>
                                         王德胜,吴钟建,姚秀娟,等.检测图像角点自适应确定跟踪模板的方法[J].红外技术,2017,39(7):638-641.
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_9" title=" 赵亚利,章为川,李云红.图像边缘轮廓自适应阈值的角点检测方法[J].中国图象图形学报,2016,21(11):1502-1514." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201611010&amp;v=MjU2MzZaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXZnV3JyTVB5cmZiTEc0SDlmTnJvOUU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[9]</b>
                                         赵亚利,章为川,李云红.图像边缘轮廓自适应阈值的角点检测方法[J].中国图象图形学报,2016,21(11):1502-1514.
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_10" title=" 曹艳玲,袁义宏.岭南古建筑图像特征优化提取仿真研究[J].计算机仿真,2017,34(9):354-357." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201709078&amp;v=MDU5MTdCdEdGckNVUjdxZlp1WnBGeXZnV3JyTUx6N0JkTEc0SDliTXBvOUNiSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[10]</b>
                                         曹艳玲,袁义宏.岭南古建筑图像特征优化提取仿真研究[J].计算机仿真,2017,34(9):354-357.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(11),327-330+387             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>大数据环境下异质模糊图像角点特征提取仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%BE%E5%BF%97%E5%AE%8F&amp;code=24182350&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">曾志宏</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%BE%99%E5%B2%A9%E5%AD%A6%E9%99%A2%E6%95%B0%E5%AD%A6%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0220226&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">龙岩学院数学与信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>运用传统方法在大数据环境下进行异质模糊图像角点特征提取时,存在角点遗漏、提取不精确等问题。为解决上述问题,提出一种基于改进SUSAN的异质图像角点特征提取方法。在大数据环境下,采用高斯滤波对异质模糊图像进行去噪处理,通过改进SUSAN角点检测方法建立圆形模板,采用圆形模板邻域内像素灰度值中值代替模板中心像素灰度值作为模板“核”来检测区域目标角点。对检测出的图像角点所在边界进行细化;采用多角点结合的提取方法对经过处理的异质模糊图像角点特征进行精确提取。仿真结果证明,所提方法对图像角点特征提取的精度较高,大大缩短了提取用时,并且不会对图像的内容及细节造成破坏;面对噪声及其它环境的干扰,该方法的运算效率没有受到太大的影响,说明该方法的抗噪性比较好,为图像处理工作提供了更好的依据。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BC%82%E8%B4%A8%E6%A8%A1%E7%B3%8A%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">异质模糊图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E8%A7%92%E7%82%B9%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">图像角点特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%92%E7%82%B9%E6%8F%90%E5%8F%96%E6%96%B9%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">角点提取方法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    曾志宏(1982-),男(汉族),福建永定人,硕士研究生,讲师,主研方向:图像处理、大数据。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-21</p>

                    <p>

                            <b>基金：</b>
                                                        <span>福建省教育厅中青年教师项目(JAT160487);</span>
                    </p>
            </div>
                    <h1><b>Simulation of Corner Feature Extraction in Heterogeneous Fuzzy Images in Big Data Environment</b></h1>
                    <h2>
                    <span>ZENG Zhi-hong</span>
            </h2>
                    <h2>
                    <span>College of Mathematics and Information Engineering,Longyan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Traditional method leads to the missing corner and inaccurate extraction during the extraction of corner features from heterogeneous fuzzy image in big data environment. Therefore, a method to extract corner features from heterogeneous images based on improved SUSAN was proposed. In big data environment, Gaussian filter was used to remove the noise from the heterogeneous fuzzy image, and the circular template was established by improving SUSAN corner detection method. Moreover, the median grayscale value of pixel in the neighborhood of circular template was used to replace the gray value of central pixel of template. As the "core" of the template, it was used to detect the corner points of regional target. After that, the boundary of the detected corner points was refined. The corner feature of the heterogeneous fuzzy image after the treatment was extracted accurately by the extraction method combining many corner points. Simulation results verify that the proposed method has high accuracy in extracting corner features. Meanwhile, this method greatly shortens the extraction time without damaging the content and details of image. Facing to noise and other environmental interference, the operation efficiency of the proposed method is not greatly affected. Consequently, the proposed method has better anti-noise performance, which provides a better basis for the image processing.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Heterogeneous%20fuzzy%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Heterogeneous fuzzy image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20corner%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Image corner feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Corner%20extraction%20method&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Corner extraction method;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-21</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="23" name="23" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="24">图像处理技术不断发展,使图像识别与图像故障点检测逐渐受到了重视,目前已广泛应用于模式识别、数据分析、图像处理等许多领域。针对异质模糊图像的角点特征提取是图像处理和计算机视觉领域中的一个基本而关键的问题,是实现异质模糊图像的配准拼接、场景分析以及故障检测的基础<citation id="170" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。近年来,许多研究人员对模糊图像角点提取方法进行了大量研究,目前的角点特征提取方法可分为三大类:第一类是边缘图像的角点特征提取方法,该方法通过检测图像的边缘特征,来计算曲率用于识别角点,这种识别方法并不完善;第二类是基于图像灰度差对角点特征进行提取,该方法是直接处理灰度图像,提取效果很差,稳定性不好;第三类是通过创建角点样本对角点进行识别,进而对角点特征进行提取,但是当角点样本量较大时,达到该方法的运行极限,提取效率会大大降低。由于图像角点特征提取对于计算机视觉领域意义重大,因此受该领域学者的重视,成为热点课题,同时学者们也得出了较好的研究结果。</p>
                </div>
                <div class="p1">
                    <p id="25">文献<citation id="171" type="reference">[<a class="sup">2</a>]</citation>提出基于灰度差阈值的图像角点特征提取方法,该方法首先采用高斯滤波对异质模糊图像进行去噪;然后根据灰度差的不同对角点进行选择;其次按照自适应阈值和灰度值对选择出的角点特征进行分类;最后选用检测模板对分类结果进行再次选择,获得最适合的角点特征。采用该方法对角点特征进行提取时存在提取的角点特征数量少,且不准确的问题。文献<citation id="172" type="reference">[<a class="sup">3</a>]</citation>提出了基于区域检测的模糊图像角点特征提取方法。该方法先利用区域检测方法创建异质模糊图像显著图,通过腐蚀膨胀操作获取目标区域,并将其视为待检测区域;采用多尺度结合非极大值抑制方法优化角点检测方法,检测模糊图像角点并提取。采用该方法进行角点特征提取时,图像受损严重,且提取角点特征数量巨大,其中掺杂大量无用的角点特征,存在提取效果不好的问题。</p>
                </div>
                <div class="p1">
                    <p id="26">就上述问题,提出一种基于改进SUSAN的异质图像角点特征提取方法。该方法结合了上述方法的优势,提出了更佳的提取方法。实验结果表明,该方法提高了角点提取数量,缩短了角点特征提取时间,具有较好的抗噪性。</p>
                </div>
                <h3 id="27" name="27" class="anchor-tag"><b>2 模糊图像角点特征提取方法</b></h3>
                <h4 class="anchor-tag" id="28" name="28"><b>2.1 图像角点检测</b></h4>
                <div class="p1">
                    <p id="29">图像在采集、传输过程中会受到采集设备和传输环境的影响,存在大量噪声,这些噪声的存在会使图像中掺杂大量的假角点,如果直接检测图像角点会影响提取结果,因此要先去除图像噪声。采用高斯滤波对图像做平滑处理,准备工作完成后,运用SUSAN方法对图像角点进行检测。</p>
                </div>
                <div class="p1">
                    <p id="30">图像去噪采用自适应高斯滤波方法,高斯滤波是一种低通滤波器,对图像的去噪效果较好,并且可以有效保留原图像更多细节<citation id="173" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。高斯滤波运算过程是一个加权求平均数的过程,异质模糊图像中每一个像素点的数值都是通过加权求平均后获得,以下给出二维高斯函数</p>
                </div>
                <div class="p1">
                    <p id="31"><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>π</mi><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>e</mi><msup><mrow></mrow><mrow><mrow><mo>(</mo><mrow><mfrac><mrow><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>y</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>)</mo></mrow></mrow></msup></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="32">式中:二维高斯函数均值为0,方差为<i>σ</i><sup>2</sup>。</p>
                </div>
                <div class="p1">
                    <p id="33">对二维高斯函数进行离散化处理,创建高斯模板,获得一个阶数为(2<i>k</i>+1)×(2<i>k</i>+1)的权值矩阵。</p>
                </div>
                <div class="p1">
                    <p id="34">异质模糊图像中每一个像素点都可用上式进行定值。其中方差对于高斯模板的权值有很大的影响,方差太小会使邻域操作简化成对图像的点运算,去噪效果不理想;而方差太大,会导致图像信息内容部分遗失。因此需要选用合适的方差对图像进行去噪,同时完整地保存图像原有的细节内容。在对模糊图像进行去噪之前要考虑待去噪部分是边缘还是平滑区域。假设,是边缘区域则像素点较为离散,方差较大;假设,是非边缘区域,则根据该特征计算出图像某部分的方差为<i>M</i>,即</p>
                </div>
                <div class="p1">
                    <p id="35"><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>A</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow></msub></mrow></munder><mrow><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>-</mo><mover accent="true"><mi>x</mi><mo>¯</mo></mover><mo stretchy="false">)</mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>i</mi><mo>×</mo><mi>j</mi></mrow></mfrac></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="36">式中:<i>A</i><sub>(</sub><sub><i>i</i></sub><sub>,</sub><sub><i>j</i></sub><sub>)</sub>是点(<i>i</i>,<i>j</i>)邻近(2<i>k</i>+1)×(2<i>k</i>+1)大小的区域,<mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>x</mi><mo>¯</mo></mover><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>A</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow></msub></mrow></munder><mi>x</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mrow><mi>i</mi><mo>×</mo><mi>j</mi></mrow></mfrac></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="37">对经过去噪处理后的图像采用SUSAN方法进行角点检测。SUSAN方法利用灰度值对图像角点进行计算,具有定位准确、运行效率快等特点<citation id="174" type="reference"><link href="158" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。SUSAN方法是利用一个圆形模板遍历图像,假设设定的模块内其余像素点的灰度值与中心位置像素点的灰度差比预设的阈值小,即可认定该点与中心像素点的灰度值一致,满足此条件的像素构成的区域可将其看作为核值近似区(USAN)。利用下式计算USAN部分的值</p>
                </div>
                <div class="p1">
                    <p id="38"><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>n</mi><mo stretchy="false">(</mo><mover accent="true"><mi>r</mi><mo>¯</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mover accent="true"><mi>r</mi><mo>¯</mo></mover><mo>∈</mo><mi>C</mi><mo stretchy="false">(</mo><mover accent="true"><mi>r</mi><mo>→</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">)</mo></mrow></munder><mi>C</mi></mstyle><mo stretchy="false">(</mo><mover accent="true"><mi>r</mi><mo>→</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo>,</mo><mover accent="true"><mi>r</mi><mo>→</mo></mover><mo stretchy="false">)</mo></mrow></math></mathml>      (3)</p>
                </div>
                <div class="p1">
                    <p id="39">式中,<mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>r</mi><mo>→</mo></mover><msub><mrow></mrow><mn>0</mn></msub></mrow></math></mathml>是核在图像中的位置,<mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>r</mi><mo>→</mo></mover></math></mathml>是圆形模板内某一点的位置,<mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mo stretchy="false">(</mo><mover accent="true"><mi>r</mi><mo>→</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">)</mo></mrow></math></mathml>是圆心为<mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>r</mi><mo>→</mo></mover><msub><mrow></mrow><mn>0</mn></msub></mrow></math></mathml>的圆形模板,<mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mo stretchy="false">(</mo><mover accent="true"><mi>r</mi><mo>→</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo>,</mo><mover accent="true"><mi>r</mi><mo>¯</mo></mover><mo stretchy="false">)</mo></mrow></math></mathml>是模板内属于<i>USAN</i>部分的判断函数,公式如下</p>
                </div>
                <div class="area_img" id="40">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201911071_04000.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="42">式中,<i>t</i>是亮度差,<i>I</i>(*)是*位置的灰度值。</p>
                </div>
                <div class="p1">
                    <p id="43">由此可知,把某点位置上USAN部分的范围视为该位置角点特征的度量,该部分点越小,角点特征越明显<citation id="175" type="reference"><link href="160" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="44">当圆形模板移动到任意像元时,圆心与像元重叠,便可计算出圆形模板其它像元和中心像元的亮度差,计算公式如下</p>
                </div>
                <div class="area_img" id="45">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201911071_04500.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="47">式中,<i>q</i>为阈值。</p>
                </div>
                <div class="p1">
                    <p id="48">假设,<i>n</i>是USAN部分的像元数量<citation id="176" type="reference"><link href="162" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。将求解获得的USAN部分面积和阈值之间的差作为反映准则,公式如下</p>
                </div>
                <div class="p1">
                    <p id="49"><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>R</mi><mo stretchy="false">(</mo><mover accent="true"><mi>r</mi><mo>¯</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mi>h</mi><mo>-</mo><mi>n</mi><mo stretchy="false">(</mo><mover accent="true"><mi>r</mi><mo>¯</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">)</mo><mo>,</mo><mi>n</mi><mo stretchy="false">(</mo><mover accent="true"><mi>r</mi><mo>¯</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>h</mi><mo>=</mo><mn>0</mn><mtext> </mtext><mi>e</mi><mi>l</mi><mi>s</mi><mi>e</mi></mrow></mrow></mrow></math></mathml>      (6)</p>
                </div>
                <div class="p1">
                    <p id="50">式中,<i>R</i>是反映准则;<i>h</i>是固定值,为像元数量的二分之一。</p>
                </div>
                <div class="p1">
                    <p id="51">当圆形模板遍历整个图像<i>f</i>(<i>x</i>,<i>y</i>)时,通过计算某点的USAN部分大小,可求出每个点的USAN反映图像<i>R</i>(<i>x</i>,<i>y</i>)</p>
                </div>
                <div class="area_img" id="52">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201911071_05200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="54">式中,<mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>n</mi><mo stretchy="false">(</mo><mover accent="true"><mi>r</mi><mo>→</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">)</mo></mrow></math></mathml>是USAN部分的大小,<i>g</i>是反映角点特征的几何门限,影响着角点特征的尖锐性,当该值最小时,检测出的角点较为尖锐<citation id="177" type="reference"><link href="164" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。当某部分的边界出现模糊时,SUSAN算子就会出现伪角点,可采用USAN的中心和不间断性排除伪角点的反映图像。</p>
                </div>
                <div class="p1">
                    <p id="55">假设核心位置的坐标是(<i>x</i><sub>0</sub>,<i>y</i><sub>0</sub>),圆形模板的半径是<i>r</i><sub>0</sub>,(<i>x</i>,<i>y</i>)是圆形模板中的一点,如图1所示。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201911071_056.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                    <img alt="图1 方向模板示意图" src="Detail/GetImg?filename=images/JSJZ201911071_056.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
                                </a>
                                <p class="img_tit"><b>图1 方向模板示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201911071_056.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="57">图1中Q是核心点(x<sub>0</sub>,y<sub>0</sub>)和点(x,y)的矢量与X轴的夹角,取值范围是0°～360°,令Q<sub>1</sub>是圆形模板的起始角,Q<sub>2</sub>是圆形模板的终止角,X轴为方向0°,逆时针方向为正方向,通过改变Q<sub>1</sub>、Q<sub>2</sub>值,可以改变模板的大小和方向,最后对图像角点进行提取。</p>
                </div>
                <div class="p1">
                    <p id="58">检测图像角点的具体方法如下:</p>
                </div>
                <div class="p1">
                    <p id="59">1)利用式(6)计算出核心点(x<sub>0</sub>,y<sub>0</sub>)和点(x,y)的间隔</p>
                </div>
                <div class="p1">
                    <p id="60">r(x,y)=(x-x<sub>0</sub>)<sup>2</sup>+(y-y<sub>0</sub>)<sup>2</sup>      (8)</p>
                </div>
                <div class="p1">
                    <p id="61">2)确定点(x,y)和X轴的夹角,根据图1可知,当y&lt;y<sub>0</sub>、x&gt;x<sub>0</sub>,有<mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Q</mtext><mo>=</mo><mrow><mi>a</mi><mi>r</mi><mi>c</mi><mi>t</mi><mi>a</mi><mi>n</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mfrac><mrow><mtext>y</mtext><mo>-</mo><mtext>y</mtext><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mtext>x</mtext><mo>-</mo><mtext>x</mtext><msub><mrow></mrow><mn>0</mn></msub></mrow></mfrac><mo stretchy="false">)</mo></mrow></math></mathml>;若(y&lt;y<sub>0</sub>、x&lt;x<sub>0</sub>)or(y&gt;y<sub>0</sub>、x&lt;x<sub>0</sub>),则有<mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Q</mtext><mo>=</mo><mn>1</mn><mn>8</mn><mn>0</mn><mo>+</mo><mrow><mi>a</mi><mi>r</mi><mi>c</mi><mi>t</mi><mi>a</mi><mi>n</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mfrac><mrow><mtext>y</mtext><mo>-</mo><mtext>y</mtext><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mtext>x</mtext><mo>-</mo><mtext>x</mtext><msub><mrow></mrow><mn>0</mn></msub></mrow></mfrac><mo stretchy="false">)</mo></mrow></math></mathml>;若y&gt;y<sub>0</sub>、x&gt;x<sub>0</sub>,则有<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Q</mtext><mo>=</mo><mn>3</mn><mn>6</mn><mn>0</mn><mo>+</mo><mrow><mi>a</mi><mi>r</mi><mi>c</mi><mi>t</mi><mi>a</mi><mi>n</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mfrac><mrow><mtext>y</mtext><mo>-</mo><mtext>y</mtext><msub><mrow></mrow><mn>0</mn></msub></mrow><mrow><mtext>x</mtext><mo>-</mo><mtext>x</mtext><msub><mrow></mrow><mn>0</mn></msub></mrow></mfrac><mo stretchy="false">)</mo></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="62">3)确定Q<sub>1</sub>≤Q≤Q<sub>2</sub>是否成立,将满足r(x,y)&lt;r<sub>0</sub>的点(x,y)加入2)计算。</p>
                </div>
                <div class="p1">
                    <p id="63">4)通过式(5)可以计算出反映图像R(x,y),就是在这部分ΔQ=Q<sub>2</sub>-Q<sub>1</sub>的图像角点可以提取。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64"><b>2.2 图像角点特征提取</b></h4>
                <div class="p1">
                    <p id="65">检测出的图像角点均为异质模糊图像的边界点,并且是两条以上边界线的交点。根据该几何特性,对图像边界进行细化处理<citation id="178" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="66">将图像边界集合A进行细化,用A、B表示</p>
                </div>
                <div class="p1">
                    <p id="67">A⨂B=A-(AΘB)=A∩(AΘB)      (9)</p>
                </div>
                <div class="p1">
                    <p id="68">对于对称细化图像边界A,表达式为</p>
                </div>
                <div class="p1">
                    <p id="69">{B}={B<sup>1</sup>,B<sup>2</sup>,...,B<sup>n</sup>}      (10)</p>
                </div>
                <div class="p1">
                    <p id="70">式中:B<sup>1</sup>是B<sup>n-1</sup>的旋转形式,图像边界A经过该元素序列的细化,可用下式进行表达</p>
                </div>
                <div class="p1">
                    <p id="71">A⨂{B}=((...((A⨂B<sup>1</sup>)⨂B<sup>2</sup>)...)⨂B<sup>n</sup>)      (11)</p>
                </div>
                <div class="p1">
                    <p id="72">该过程就是用B<sup>1</sup>细化A,然后对细化结果采用B<sup>2</sup>进一步细化,一直进行到A被B<sup>n</sup>细化。整个运行过程直到图像边界不发生任何变化为止。</p>
                </div>
                <div class="p1">
                    <p id="73">假设,灰阶图像I,采用<i>Harris</i>方法、<i>Shi</i>-<i>Tomasi</i>方法和<i>Fast</i>方法提取出的单个角点特征分别是P<mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>Η</mtext><mrow><mo stretchy="false">(</mo><mtext>n</mtext><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml>、P<mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>S</mtext><mrow><mo stretchy="false">(</mo><mtext>n</mtext><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml>、P<mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>F</mtext><mrow><mo stretchy="false">(</mo><mtext>n</mtext><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml>,角点特征集合分别是P<sub>H</sub>、P<sub>S</sub>、P<sub>F</sub><citation id="179" type="reference"><link href="168" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。即</p>
                </div>
                <div class="area_img" id="74">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201911071_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="76">把三个集合结合在一起,可以提取到由真正角点P<mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>C</mtext><mn>1</mn></msubsup></mrow></math></mathml>、普通角点P<mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>C</mtext><mn>2</mn></msubsup></mrow></math></mathml>和假角点P<mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>C</mtext><mn>3</mn></msubsup></mrow></math></mathml>组成的图像角点特征P<sub>C</sub>。基于多角点结合的图像角点提取方法流程图如图2。</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201911071_077.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                    <img alt="图2 多角点结合的图像角点提取方法流程图" src="Detail/GetImg?filename=images/JSJZ201911071_077.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
                                </a>
                                <p class="img_tit"><b>图2 多角点结合的图像角点提取方法流程图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201911071_077.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="78">多角点特征P<sub>C</sub>、真角点P<mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>C</mtext><mn>1</mn></msubsup></mrow></math></mathml>、普通角点P<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>C</mtext><mn>2</mn></msubsup></mrow></math></mathml>、假角点P<mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>C</mtext><mn>3</mn></msubsup></mrow></math></mathml>的描述公式如下</p>
                </div>
                <div class="area_img" id="79">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201911071_07900.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="81">按照多角点特征的优化提取方法可知,在采用公式进行计算时,需要保证下式成立</p>
                </div>
                <div class="area_img" id="82">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201911071_08200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="84">如果把计算方式理想化,那么多角点特征的优化提取过程为</p>
                </div>
                <div class="area_img" id="85">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201911071_08500.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="87">综上所述,在大数据环境下完成对异质模糊图像角点特征的提取。</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag"><b>3 仿真证明及分析</b></h3>
                <div class="p1">
                    <p id="89">实验平台选用Windows 7系统、主频为3.5GHz、8G内存的计算机,采用分辨率为220M、感光元件尺寸为1/1.6英寸、像素精度是0.0625mm的相机进行仿真,选用64×64像元、128×128像元、256×256像元和512×512像元的图像作为实验对象,实验中产生的代码全用MATLAB实现。</p>
                </div>
                <div class="p1">
                    <p id="90">为了证明所提角点特征提取方法的有效性和可行性,分别采用文献<citation id="180" type="reference">[<a class="sup">2</a>]</citation>方法、文献<citation id="181" type="reference">[<a class="sup">3</a>]</citation>方法和所提方法对实验对象进行对比实验。实验中,三种方法提取的角点特征数量统计结果如表1所示,所用的时间统计结果如图3所示:</p>
                </div>
                <div class="area_img" id="91">
                    <p class="img_tit"><b>表1 提取角点特征数目</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="91" border="1"><tr><td><br />像元数</td><td>文献[2]方法</td><td>文献[3]方法</td><td>所提方法</td></tr><tr><td><br />64×64</td><td>1.8×10<sup>3</sup>个</td><td>0.5×10<sup>3</sup>个</td><td>2.1×10<sup>3</sup>个</td></tr><tr><td><br />128×128</td><td>2.3×10<sup>3</sup>个</td><td>1.9×10<sup>3</sup>个</td><td>2.5×10<sup>3</sup>个</td></tr><tr><td><br />256×256</td><td>3.3×10<sup>3</sup>个</td><td>2.7×10<sup>3</sup>个</td><td>5.2×10<sup>3</sup>个</td></tr><tr><td><br />512×512</td><td>14.5×10<sup>3</sup>个</td><td>8.3×10<sup>3</sup>个</td><td>20.7×10<sup>3</sup>个</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="92">分析表1可知:当像元数为64×64时,三种方法中,文献<citation id="182" type="reference">[<a class="sup">3</a>]</citation>方法提取出的角点数量为最低,所提方法提取出的角点特征数量最高;当像元数为512×512时,三种方法中文献<citation id="183" type="reference">[<a class="sup">2</a>]</citation>方法和所提方法提取出的角点特征数量均高于10.0×10<sup>3</sup>个,其中所提方法的角点提取数量高达20.7×10<sup>3</sup>个,文献<citation id="184" type="reference">[<a class="sup">3</a>]</citation>提取的角点数量为8.3×10<sup>3</sup>个,低于另两种方法所提取的角点数量。通过上述实验数据可知,三种方法提取的角点数均随着像元数的增加而增加,并且对于相同的图像像元数,所提方法的角点特征提取数量比其它两种方法多。</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201911071_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                    <img alt="图3 特征提取所用时间对比图" src="Detail/GetImg?filename=images/JSJZ201911071_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
                                </a>
                                <p class="img_tit"><b>图3 特征提取所用时间对比图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201911071_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="94">由图3分析可知:三种方法提取所用时间都随着像元数的增加而增加,其中文献<citation id="185" type="reference">[<a class="sup">2</a>]</citation>方法所用的时间增加最多,文献<citation id="186" type="reference">[<a class="sup">3</a>]</citation>方法相对于文献<citation id="187" type="reference">[<a class="sup">2</a>]</citation>方法方法提取所用时间更短,但两种方法特征提取所用时间都高于所提方法。</p>
                </div>
                <div class="p1">
                    <p id="95">为进一步验证实验的可信度,对实验图像进行噪声干扰,在这种情况下,对比三种方法的提取结果,如表2所示:</p>
                </div>
                <div class="area_img" id="96">
                    <p class="img_tit"><b>表2 噪声干扰下各方法的效果比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="96" border="1"><tr><td rowspan="2"><br />图像像<br />元数</td><td rowspan="2">噪声<br />强度</td><td colspan="3"><br />各方法提取率/%</td></tr><tr><td><br />文献[2]方法</td><td>文献[3]方法</td><td>所提方法</td></tr><tr><td><br />64×64</td><td rowspan="4">10%</td><td><br />66.5</td><td>70.5</td><td>85.5</td></tr><tr><td><br />128×128</td><td><br />52.0</td><td>64.5</td><td>79.5</td></tr><tr><td><br />256×256</td><td><br />45.0</td><td>59.5</td><td>63.5</td></tr><tr><td><br />512×512</td><td><br />30.9</td><td>46.5</td><td>55.0</td></tr><tr><td><br />64×64</td><td rowspan="4">20%</td><td><br />51.5</td><td>68.5</td><td>77.5</td></tr><tr><td><br />128×128</td><td><br />42.0</td><td>50.0</td><td>64.5</td></tr><tr><td><br />256×256</td><td><br />30.5</td><td>39.5</td><td>50.0</td></tr><tr><td><br />512×512</td><td><br />20.5</td><td>31.5</td><td>42.0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="97">分析表2可知:在受噪声干扰的情况下,三种方法提取率都有不同程度的降低,其中文献<citation id="188" type="reference">[<a class="sup">2</a>]</citation>方法的提取率降低幅度较为明显,说明该方法抗噪性较差,应用于异质模糊图像的角点特征提取效果也较差;而文献<citation id="189" type="reference">[<a class="sup">3</a>]</citation>方法要明显优于文献<citation id="190" type="reference">[<a class="sup">2</a>]</citation>方法,噪声强度增大时,角点特征提取率降低幅度较小;相比之下,所提方法在噪声干扰下,图像角点提取结果优于其它两种方法,证明所提方法进行角点特征提取具有一定的抗噪性。</p>
                </div>
                <div class="p1">
                    <p id="98">通过分析实验数据可知,文献<citation id="191" type="reference">[<a class="sup">2</a>]</citation>方法对角点很敏感,且能够提取出较多的有效角点,但方法所用时间较长,角点特征提取的效率不高,且易受噪声影响;而文献<citation id="192" type="reference">[<a class="sup">3</a>]</citation>方法虽然角点提取数量不高,但该方法提取速度比较快。</p>
                </div>
                <div class="p1">
                    <p id="99">综上所述,所提方法无论是在提取效率还是抗噪性等方面都优于其它两种方法,具有可行性。</p>
                </div>
                <h3 id="100" name="100" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="101">为解决传统方法存在的角点遗漏、特征提取效率不高等问题,提出了基于改进SUSAN的异质图像角点特征提取方法。仿真验证明,实验中所选取的三种角点特征提取方法中,文献<citation id="193" type="reference">[<a class="sup">2</a>]</citation>方法和文献<citation id="194" type="reference">[<a class="sup">3</a>]</citation>方法相对来提取效果不够理想,而所提方法的总体提取性能最好,缩短了运算时间,具有较高的提取效率。但是实际应用中也发现了一些不足,所提方法虽然抗噪性比其它两种方法好,但是面对噪声干扰或其它的环境影响,提取精度还需进一步改进优化,进一步提升抗噪性能。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="196" type="formula" href="images/JSJZ201911071_19600.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">曾志宏</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="150">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSSS201609022&amp;v=MzEzODFUN1lmYkc0SDlmTXBvOUhab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXZnV3JyTUk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[1]</b> 刘桂华,陈林宇,肖得胜.基于FPGA的图像多尺度特征点提取及匹配[J].电视技术,2016,40(9):103-107.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201602071&amp;v=MDU5NDNTWkxHNEg5Zk1yWTlDWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnl2Z1dyck1Mejc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[2]</b> 查易艺,孙权森,罗楠,等.基于FAST和DAISY的遥感图像配准算法[J].计算机应用研究,2016,33(2):624-628.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HJXB201602022&amp;v=MzA2MjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnl2Z1dyck1MU2ZUYkxHNEg5Zk1yWTlIWm9RS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[3]</b> 刘子腾.基于激光视觉的角焊缝图像特征点提取[J].焊接学报,2016,37(2):89-93.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=FIVE201602012&amp;v=MjA3OTJPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5dmdXcnJNSXlUZGE3RzRIOWZNclk5RVpvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[4]</b> 陈庄,杨峰,冯欣,等.多尺度积角点检测和视觉颜色特征的鲁棒车牌定位方法[J].重庆大学学报,2016,9(2):89-98.
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZJY201612038&amp;v=MTUwODg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXZnV3JyTUlUZkJkN0c0SDlmTnJZOUdiSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[5]</b> 任立胜,王立中.基于曲率尺度空间的角点检测图像匹配方法分析[J].电子技术应用,2016,42(12):112-114.
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GJSX201601012&amp;v=MDk1NjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5dmdXcnJNSWlmWWRyRzRIOWZNcm85RVpvUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[6]</b> 张盛博,刘娜,霍宏,等.基于层次形状特征提取模型的图像分类[J].高技术通讯,2016,26(1):81-88.
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201610024&amp;v=MDM1MjZxZlp1WnBGeXZnV3JyTUx6N0JaYkc0SDlmTnI0OUhZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[7]</b> 李建华,刘柯.基于SURF特征提取的双目测距在铝锭垛定位中的应用研究[J].计算机工程与科学,2016,38(10):2121-2125.
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWJS201707010&amp;v=MTY5MzZaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXZnV3JyTUxUckJmYkc0SDliTXFJOUU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[8]</b> 王德胜,吴钟建,姚秀娟,等.检测图像角点自适应确定跟踪模板的方法[J].红外技术,2017,39(7):638-641.
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201611010&amp;v=MjgxOTN5dmdXcnJNUHlyZmJMRzRIOWZOcm85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[9]</b> 赵亚利,章为川,李云红.图像边缘轮廓自适应阈值的角点检测方法[J].中国图象图形学报,2016,21(11):1502-1514.
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201709078&amp;v=MDY0MTR2Z1dyck1MejdCZExHNEg5Yk1wbzlDYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[10]</b> 曹艳玲,袁义宏.岭南古建筑图像特征优化提取仿真研究[J].计算机仿真,2017,34(9):354-357.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201911071" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201911071&amp;v=MDkwMzMzenFxQnRHRnJDVVI3cWZadVpwRnl2Z1dyck1MejdCZExHNEg5ak5ybzlDWllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxVZHNtcXpnRzFUbGhJZnl1eVpDaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
