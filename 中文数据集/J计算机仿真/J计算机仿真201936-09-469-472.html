<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139897752603750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201909098%26RESULT%3d1%26SIGN%3d4RRk3QOQAA85%252bvYgYEACyzNB%252bhU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201909098&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201909098&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201909098&amp;v=MDU5NjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeW5tVzczQkx6N0JkTEc0SDlqTXBvOU1iSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#17" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#21" data-title="&lt;b&gt;2 基于图像识别的人体动作特征提取&lt;/b&gt; "><b>2 基于图像识别的人体动作特征提取</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="&lt;b&gt;3 人体动作图像目标检测&lt;/b&gt; "><b>3 人体动作图像目标检测</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#61" data-title="&lt;b&gt;4 基于图像识别的人体动作跟踪&lt;/b&gt; "><b>4 基于图像识别的人体动作跟踪</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#70" data-title="&lt;b&gt;5 实验分析&lt;/b&gt; "><b>5 实验分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#80" data-title="&lt;b&gt;6 结论&lt;/b&gt; "><b>6 结论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#73" data-title="&lt;b&gt;表1 形态学操作方法数据&lt;/b&gt;"><b>表1 形态学操作方法数据</b></a></li>
                                                <li><a href="#74" data-title="&lt;b&gt;表2 活动轮廓模型法数据&lt;/b&gt;"><b>表2 活动轮廓模型法数据</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;表3 图像识别方法数据&lt;/b&gt;"><b>表3 图像识别方法数据</b></a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;图1 人体动作识别成功率对比曲线&lt;/b&gt;"><b>图1 人体动作识别成功率对比曲线</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 李荣,徐燕华.基于视觉信息的图像特征提取算法研究[J].电子设计工程,2016,24(9):188-190." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201609057&amp;v=MjIzOTc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bm1XNzNBSWpyUGRMRzRIOWZNcG85QVk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         李荣,徐燕华.基于视觉信息的图像特征提取算法研究[J].电子设计工程,2016,24(9):188-190.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 许丽娟,刘大龙.公交车危险动作视觉图像识别仿真[J].计算机仿真,2015,32(6):150-153." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201506035&amp;v=MzIzODBGckNVUjdxZlp1Wm9GeW5tVzczQUx6N0JkTEc0SDlUTXFZOUdZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         许丽娟,刘大龙.公交车危险动作视觉图像识别仿真[J].计算机仿真,2015,32(6):150-153.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                     张炎炎,孟繁丽,张新程,等.TD-LED网络结构评估方法研究及预规划分析[C].中国移动通信集团设计院第十九届新技术论坛论文集,北京:中国移动通信集团设计院,2013:37-42.</a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 鲁艳玲,吴伟陵.智能天线在CDMA网络规划与优化中的应用[J].无线通信技术,2003,(1):36-38." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WYWT200301008&amp;v=MTc2NDJUY2VyRzRIdExNcm85RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bm1XNzNBTWo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         鲁艳玲,吴伟陵.智能天线在CDMA网络规划与优化中的应用[J].无线通信技术,2003,(1):36-38.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 肖莹,张新程.WCDMA系统的传播模型校准[J].电信科学,2005,(3):78-81." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DXKX200503023&amp;v=MTA0NDZHNEh0VE1ySTlIWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlubVc3M0FJVFhBZHI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         肖莹,张新程.WCDMA系统的传播模型校准[J].电信科学,2005,(3):78-81.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 詹煜欣,董文永.基于对极几何约束的动态北京下运动目标检测[J].计算机应用研究,2018,35(11):3462-3465." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201811064&amp;v=MjMzNzA1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlubVc3M0FMejdTWkxHNEg5bk5ybzlEWUlRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         詹煜欣,董文永.基于对极几何约束的动态北京下运动目标检测[J].计算机应用研究,2018,35(11):3462-3465.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 姚莉秀,王小念,杨杰,等.基于多面体时空梯度描述子的人体动作识别[J].华南理工大学学报(自然科学版),2012,40(6):56-62." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNLG201206012&amp;v=MjQxNDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bm1XNzNBTFNQSGFiRzRIOVBNcVk5RVpvUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         姚莉秀,王小念,杨杰,等.基于多面体时空梯度描述子的人体动作识别[J].华南理工大学学报(自然科学版),2012,40(6):56-62.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(09),469-472             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>高强度运动下的人体动作图像识别方法研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%BE%89&amp;code=42868465&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张辉</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8D%97%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E6%96%B0%E8%81%94%E5%AD%A6%E9%99%A2&amp;code=1749608&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河南师范大学新联学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对传统动作识别方法一直存在提取成功率较低、提取时间较长等问题,提出了一种基于图像识别的自动跟踪方法对高强度运动下的人体动作进行识别。首先,应用双重卷积理论对高强度下人体动作的原形图像进行阈值分割,对人体动作进行特征提取。然后,结合高斯分布模型对获得的人体动作图像目标、背景和前景信息进行处理,得到人体动作图像背景的高斯分布模型,并采用卡尔曼滤波获取人体动作图像的跟踪轨迹。最后,应用贝叶斯分类理论,对人体动作图像的灰度信息构建目标模型,求解出人体动作图像的最优峰值点,实现多个目标的分割与跟踪。实验结果表明,通过图像识别的自动跟踪方法对人体动作特征提取具有良好的精确,且提取速度显著提高。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E5%8A%A8%E8%B7%9F%E8%B8%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自动跟踪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高斯分布;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卡尔曼滤波;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张辉(1981-),男(汉族),河南洛阳人,硕士研究生,讲师,主要研究领域为体育教育训练学。&lt;image id="114" type="formula" href="images/JSJZ201909098_11400.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-11</p>

            </div>
                    <h1><b>Research on Human Motion Image Recognition Method under High Intensity Motion</b></h1>
                    <h2>
                    <span>Zhang Hui</span>
            </h2>
                    <h2>
                    <span>Xinlian College, Henan Normal University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problems of low extraction success rate and long extraction time in traditional motion recognition methods, an automatic tracking method based on image recognition was proposed to recognize human motion in high intensity motion. Firstly, double convolution theory was applied to threshold segmentation of the original image of human motion under high intensity, and feature extraction of human motion was carried out. Then, combined with the Gauss distribution model, the target, background and foreground information of human action image were processed, the Gauss distribution model of human action image background was obtained, and the tracking trajectory of human action image was obtained by Kalman filter. Finally, based on Bayesian classification theory, an object model was constructed for gray level information of human action image, and the optimal peak point of human action image was solved to realize segmentation and tracking of multiple targets. The experimental results show that the automatic tracking method of image recognition is accurate and the extraction speed is improved significantly.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Image recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Automatic%20tracking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Automatic tracking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gaussian%20distribution&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gaussian distribution;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Kalman%20filtering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Kalman filtering;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-11</p>
                            </div>


        <!--brief start-->
                        <h3 id="17" name="17" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="18">随着各种智能设备的生产和发展,人类除了对智能机器设备更加关注外,对人体动作的识别也越来越重视。目前,人体动作行为的研究,已经逐渐成为了机器视觉领域中重要研究的问题之一<citation id="109" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。随着科学技术的发展,人脸识别、手势识别和指纹识别等机器视觉技术已经广泛应用于学校和公司等环境中,这些技术为人体动作识别带来了巨大的动力<citation id="110" type="reference"><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="19">文献<citation id="111" type="reference">[<a class="sup">6</a>]</citation>针对动作目标的提取问题,提出了一种基于对极几何约束的检测方法。利用视屏序列中相继帧对应的背景角点来满足对极几何约束条件的原理,该方法先提取前一帧Harris 角点,再利用金字塔分层Lucas-Kanade光流法获得在下一帧的对应点;通过随机采样的算法预测出基础矩阵,来识别背景角点和前景角点,最后识别出运动目标区域。该方法能够在动态背景下高精度地完成多个运动目标去的检测,但每秒处理的图像帧数较低。文献<citation id="112" type="reference">[<a class="sup">7</a>]</citation>提出了一种新的时空兴趣点检测器,该方法以检测出的时空兴趣点为中心,建立基于多面体模型的时空梯度描述子来进一步刻画人体动作在时空上的视觉特征; 再利用词袋方法对看到的动作特征建立较为有效的码书;最后将特征描述子与高层次的人工定义的动作属性相结合,采用隐支持向量机结合坐标下降法求解最终识别模型的局部最优解。该方法识别率较高,但特征描述过于复杂。</p>
                </div>
                <div class="p1">
                    <p id="20">为了能更加精确的对高强度运动下的人体动作进行识别,本文提出一种基于图像识别的自动跟踪方法,通过高斯定理对人体动作图像进行建模,并采用卡尔曼滤波来获取人体动作的位置目标,最终获取人体动作图像跟踪轨迹。</p>
                </div>
                <h3 id="21" name="21" class="anchor-tag"><b>2 基于图像识别的人体动作特征提取</b></h3>
                <div class="p1">
                    <p id="22">在对人体动作图像自动跟踪过程中,本文应用双重卷积理论对高强度下人体动作的原形图像进行阈值分割。然后提取人体动作图像目标,从每个通道得出输出的人体运动图像,并对提取的动作图像进行滤波处理,来获得人体动作图像的归一化中心距。最后结合向量机理论对人体动作图像进行像素分类,获得待选的动作图像目标,并采用高斯定理对人体动作图像的目标和背景进行模型的建立。</p>
                </div>
                <div class="p1">
                    <p id="23">本文应用双重卷积理论对高强度下人体动作的原形图像进行阈值分割,提取人体动作图像目标,在此理论的基础上,需要对高强度下人体动作图像目标进行Gabor小波转换,可表示为</p>
                </div>
                <div class="p1">
                    <p id="24"><i>A</i><sub>(</sub><sub><i>i</i></sub><sub>,</sub><sub><i>j</i></sub><sub>)</sub>(<i>k</i>,<i>l</i>)=‖<i>B</i>(<i>i</i>,<i>j</i>)·<i>C</i>(<i>k</i>,<i>l</i>)‖      (1)</p>
                </div>
                <div class="p1">
                    <p id="25">式中,<i>A</i><sub>(</sub><sub><i>i</i></sub><sub>,</sub><sub><i>j</i></sub><sub>)</sub>(<i>k</i>,<i>l</i>) 为人体动作图像目标经过Gabor滤波器卷积处理之后得到的一组滤波结果;<i>B</i>(<i>i</i>,<i>j</i>)为动作图像目标;<i>C</i>(<i>k</i>,<i>l</i>)为Gabor小波滤波器组。除此之外,还需要对高强度运动下人体动作图像<i>D</i>(<i>x</i>,<i>y</i>)的<i>p</i>+<i>q</i>阶中心矩阵进行定义,可表示为</p>
                </div>
                <div class="p1">
                    <p id="26"><mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>q</mi></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>x</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>-</mo><mover accent="true"><mi>x</mi><mo>¯</mo></mover><mo stretchy="false">)</mo></mrow></mstyle></mrow></mstyle><msup><mrow></mrow><mi>p</mi></msup><mrow><mo stretchy="false">(</mo><mi>y</mi><mo>-</mo><mover accent="true"><mi>y</mi><mo>¯</mo></mover><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mi>q</mi></msup><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="27">式中,(<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>¯</mo></mover></math></mathml>,<mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>y</mi><mo>¯</mo></mover></math></mathml>)为人体动作图像的中心坐标。为了对动作图像进行更精确的分析,需要定义4个变换不变的矩,分别为平移、旋转和尺度不变的矩,表示如下</p>
                </div>
                <div class="p1">
                    <p id="28"><i>φ</i><sub>1</sub>=<i>η</i><sub>20</sub>+<i>η</i><sub>02</sub></p>
                </div>
                <div class="p1">
                    <p id="29"><i>φ</i><sub>2</sub>=(<i>η</i><sub>20</sub>-<i>η</i><sub>02</sub>)<sup>2</sup>+4<i>η</i><mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow><mn>2</mn></msubsup></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="30"><i>φ</i><sub>3</sub>=(<i>η</i><sub>30</sub>-<i>η</i><sub>12</sub>)<sup>2</sup>+(3<i>η</i><sub>21</sub>-<i>η</i><sub>03</sub>)<sup>2</sup></p>
                </div>
                <div class="p1">
                    <p id="31"><i>φ</i><sub>4</sub>=(<i>η</i><sub>30</sub>+<i>η</i><sub>12</sub>)<sup>2</sup>+(<i>η</i><sub>21</sub>+<i>η</i><sub>03</sub>)<sup>2</sup>      (3)</p>
                </div>
                <div class="p1">
                    <p id="32">式中,<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>η</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>q</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>E</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>q</mi></mrow></msub></mrow><mrow><mi>E</mi><msubsup><mrow></mrow><mrow><mn>0</mn><mn>0</mn></mrow><mi>γ</mi></msubsup></mrow></mfrac><mo>,</mo><mi>γ</mi><mo>=</mo><mfrac><mrow><mi>p</mi><mo>+</mo><mi>q</mi></mrow><mn>2</mn></mfrac><mo>+</mo><mn>1</mn><mo>,</mo><mi>p</mi><mo>+</mo><mi>q</mi><mo>=</mo><mn>2</mn><mo>,</mo><mn>3</mn><mo>,</mo><mn>4</mn></mrow></math></mathml>,···表示高强度下人体动作图像的归一化中心距离。本文通过向量机的分类方法对人体动作图像进行归一化中心矩的分析。假设在任意时刻<i>t</i>,人体动作图像中任何一个像素(<i>i</i>,<i>j</i>)的像素概率表示为</p>
                </div>
                <div class="p1">
                    <p id="33"><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>G</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>t</mi></msubsup><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mi>Κ</mi><mo>,</mo><mi>L</mi></mrow></munder><mi>p</mi></mstyle><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">(</mo><mi>G</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>t</mi></msubsup><mrow><mo stretchy="false">|</mo><mi>θ</mi></mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>,</mo><mi>s</mi></mrow><mi>t</mi></msubsup><mo stretchy="false">)</mo></mrow></math></mathml>      (4)</p>
                </div>
                <div class="p1">
                    <p id="34">式中,<i>G</i><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>为<i>t</i>时刻人体动作图像中的像素值;<i>p</i><sub><i>s</i></sub>(<i>G</i><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>|<i>θ</i><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>,</mo><mi>s</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>)为在任何时刻<i>t</i>时,人体动作图像的像素(<i>i</i>,<i>j</i>)是前景还是背景的概率。在任意时刻<i>t</i>时,人体动作图像中像素(<i>i</i>,<i>j</i>)的背景混合模型可表示为</p>
                </div>
                <div class="p1">
                    <p id="35"><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false">(</mo><mi>G</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>t</mi></msubsup><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi>w</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>×</mo><mi>η</mi><mo stretchy="false">(</mo><mi>G</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>t</mi></msubsup><mo>,</mo><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>,</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mi>j</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo stretchy="false">)</mo></mstyle></mrow></math></mathml>      (5)</p>
                </div>
                <div class="p1">
                    <p id="36">式中,<i>k</i>为混合模型中表达人体动作图像像素色彩特性的高斯分布模型的个数;<i>w</i><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>为任意时刻<i>t</i>时,人体动作图像背景混合模型中的权重,且满足<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi>w</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>k</mi></mrow><mi>t</mi></msubsup><mo>=</mo><mn>1</mn></mrow></math></mathml>;<i>μ</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>为<i>t</i>时刻下背景混合模型中的均值;∑<mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>为<i>t</i>时刻下背景混合模型模型中协方差矩阵。</p>
                </div>
                <div class="p1">
                    <p id="37">将权重和标准差之间的比作为适应度值,在人体动作图像的背景混合模型中寻找出最大适应度的子模型作为当前一帧背景分布模型,便可以求得在任意时刻<i>t</i>时,高强度运动下人体动作图像的背景混合模型中像素(<i>i</i>,<i>j</i>)的条件概率,可表示为</p>
                </div>
                <div class="p1">
                    <p id="38" class="code-formula">
                        <mathml id="38"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>η</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>,</mo><mi>μ</mi><mo>,</mo><mstyle displaystyle="true"><mo>∑</mo><mo stretchy="false">)</mo></mstyle><mo>=</mo><mfrac><mn>1</mn><mrow><mrow><mo stretchy="false">(</mo><mn>2</mn><mi>π</mi><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mrow><mfrac><mi>π</mi><mn>2</mn></mfrac></mrow></msup><mrow><mo stretchy="false">|</mo><mstyle displaystyle="true"><mo>∑</mo><mo stretchy="false">|</mo></mstyle></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mrow></mfrac><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo stretchy="false">(</mo><mi>Y</mi><mo>-</mo><mi>μ</mi><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mi>Τ</mi></msup></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><msup><mstyle mathsize="140%" displaystyle="true"><mo>∑</mo></mstyle><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mi>Y</mi><mo>-</mo><mi>μ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mspace width="0.25em" /><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="39">式中,<i>Y</i>和<i>η</i>分别为人体动作图像像素(<i>i</i>,<i>j</i>)的特征向量及特征向量的维数;<i>μ</i>为条件概率的均值;∑为条件概率的协方差矩阵。</p>
                </div>
                <div class="p1">
                    <p id="40">本文通过多次迭代的方法获取高强度运动下人体动作图像的背景,具体研究为:首先,设置最大的迭代次数为<i>α</i><sub>1</sub>,每次迭代过程中需要被修正的人体动作图像的最少像素数为<i>α</i><sub>2</sub>。然后,在人体动作图像中的任何一个像素中,从前景和背景混合模型中找到最大适应度值的子模型当作人体动作图像这一帧的前景和背景的分布模型。其次,通过式(6)计算出人体动作图像的像素5周围的背景像素个数<i>λ</i><sub><i>a</i></sub>。最后,应用获得的人体动作图像的像素先验率判断像素。可表示为</p>
                </div>
                <div class="p1">
                    <p id="41"><i>p</i>(<i>H</i><sub><i>B</i></sub>)=<i>λ</i><sub><i>a</i></sub>/5</p>
                </div>
                <div class="p1">
                    <p id="42"><i>p</i>(<i>H</i><sub><i>F</i></sub>)=1-<i>p</i>(<i>H</i><sub><i>B</i></sub>)      (7)</p>
                </div>
                <div class="p1">
                    <p id="43">式中,<i>p</i>(<i>H</i><sub><i>B</i></sub>)和<i>p</i>(<i>H</i><sub><i>F</i></sub>)分别为人体动作图像像素<i>H</i><sub><i>B</i></sub>和<i>H</i><sub><i>F</i></sub>的先验密度分布函数。如果<i>p</i>(<i>H</i><sub><i>B</i></sub>)≥<i>p</i>(<i>H</i><sub><i>F</i></sub>),那么将像素归类为背景;如果<i>p</i>(<i>H</i><sub><i>B</i></sub>)&lt;<i>p</i>(<i>H</i><sub><i>F</i></sub>),那么将像素归类为前景。</p>
                </div>
                <div class="p1">
                    <p id="44">在上述的迭代过程中,如果迭代次数大于<i>α</i><sub>1</sub>,或者在一次迭代中被修正的人体动作图像的像素像素小于<i>α</i><sub>2</sub>,迭代过程结束。否则在人体动作图像的背景和前景混合模型中继续寻找最大适应度值的子模型。</p>
                </div>
                <div class="p1">
                    <p id="45">得到动作图像背景后,将高强度运动下的人体动作图像当前帧与人体动作图像背景相做差值,求出人体动作图像目标,可表示为</p>
                </div>
                <div class="p1">
                    <p id="46"><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>Ι</mi><msub><mrow></mrow><mi>h</mi></msub><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>k</mi></mstyle><mrow><mo>(</mo><mrow><mrow><mo stretchy="false">∥</mo><mfrac><mrow><mi>y</mi><mo>-</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mi>h</mi></mfrac><mo stretchy="false">∥</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>)</mo></mrow><mi>δ</mi><mrow><mo>[</mo><mrow><mi>b</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mi>u</mi></mrow><mo>]</mo></mrow></mrow></math></mathml>      (8)</p>
                </div>
                <div class="p1">
                    <p id="47">式中,<i>I</i><sub><i>h</i></sub>为归一化因子;<i>u</i>为人体动作图像目标的特征值;<i>y</i>为人体动作图像(<i>i</i>,<i>j</i>)的中心像素;<i>h</i>为带宽,用其判定候选区域的尺度。应用式(8)获取人体动作图像的背景模型,因此为构建人体动作目标模型提供理论依据。</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag"><b>3 人体动作图像目标检测</b></h3>
                <div class="p1">
                    <p id="49">在上述对人体动作自动跟踪的基础上,结合高斯模型对获得的人体动作图像目标、背景和前景信息以图像灰度信息作为特征空间,进行信息处理,得到人体动作图像背景的高斯分布模型。并且采用卡尔曼滤波来获取人体动作的位置目标,最终获取人体动作图像跟踪轨迹。</p>
                </div>
                <div class="p1">
                    <p id="50">假设人体动作图像帧的全部图像灰度值都满足图像灰度值的期望值为<i>μ</i>,图像灰度值分布的方差为<i>σ</i>的正态分布,并且满足人体动作图像像素点的高斯分布是单变量。那么人体动作图像帧的所有像素点组成正态分布的目标和背景的概率模型可表示为</p>
                </div>
                <div class="p1">
                    <p id="51"><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">|</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mi>π</mi><mi>σ</mi></mrow></msqrt></mrow></mfrac><mrow><mi>exp</mi></mrow><mrow><mo>(</mo><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mrow><mo>(</mo><mrow><mfrac><mrow><mi>x</mi><mo>-</mo><mi>μ</mi></mrow><mi>σ</mi></mfrac></mrow><mo>)</mo></mrow></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>)</mo></mrow></mrow></math></mathml>      (9)</p>
                </div>
                <div class="p1">
                    <p id="52">式中:<i>p</i>(<i>x</i>|<i>w</i><sub><i>i</i></sub>)为单变量正态分布;<i>w</i><sub><i>i</i></sub>为人体动作图像的灰度信息特征值。在第<i>K</i>=2,3,···,<i>L</i>帧中,如果将人体动作图像目标和背景的均值和方差进行更新,则可表示为</p>
                </div>
                <div class="p1">
                    <p id="53" class="code-formula">
                        <mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>Κ</mi><mo>+</mo><mn>1</mn></mrow><mo>´</mo></msubsup><mo>=</mo><mfrac><mrow><mi>Κ</mi><mo>-</mo><mn>1</mn></mrow><mi>Κ</mi></mfrac><mi>μ</mi><msubsup><mrow></mrow><mi>Κ</mi><mo>´</mo></msubsup><mo>+</mo><mfrac><mn>1</mn><mi>Κ</mi></mfrac><mi>μ</mi><msub><mrow></mrow><mi>Κ</mi></msub></mtd></mtr><mtr><mtd><mi>σ</mi><msubsup><mrow></mrow><mrow><mi>Κ</mi><mo>+</mo><mn>1</mn></mrow><mrow><mn>2</mn><msup><mrow></mrow><mo>´</mo></msup></mrow></msubsup><mo>=</mo><mfrac><mrow><mi>Κ</mi><mo>-</mo><mn>1</mn></mrow><mi>Κ</mi></mfrac><mi>σ</mi><msubsup><mrow></mrow><mi>Κ</mi><mrow><mn>2</mn><msup><mrow></mrow><mo>´</mo></msup></mrow></msubsup><mo>+</mo><mfrac><mn>1</mn><mi>Κ</mi></mfrac><mi>σ</mi><msubsup><mrow></mrow><mi>Κ</mi><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="54">在第<i>K</i>=<i>L</i>+1帧中,如果将人体动作图像目标和背景的均值和方差进行更新,则可表示为</p>
                </div>
                <div class="p1">
                    <p id="55"><i>μ</i><sup>′</sup><sub><i>K</i></sub><sub>+1</sub>=(1-<i>ρ</i>)<i>μ</i><sup>′</sup><sub><i>K</i></sub>+<i>ρμ</i><sub><i>K</i></sub></p>
                </div>
                <div class="p1">
                    <p id="56"><i>σ</i><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Κ</mi><mo>+</mo><mn>1</mn></mrow><mrow><mn>2</mn><msup><mrow></mrow><mo>´</mo></msup></mrow></msubsup></mrow></math></mathml>=(1-<i>ρ</i>)<i>σ</i><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Κ</mi><mrow><mn>2</mn><msup><mrow></mrow><mo>´</mo></msup></mrow></msubsup></mrow></math></mathml>+<i>ρσ</i><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Κ</mi><mn>2</mn></msubsup></mrow></math></mathml>      (11)</p>
                </div>
                <div class="p1">
                    <p id="57">式中:<mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi><msub><mrow></mrow><mi>Κ</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Ν</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></munderover><mi>Ι</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>为第<i>K</i>帧人体动作图像中目标和背景点的统计均值;<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><msubsup><mrow></mrow><mi>Κ</mi><mn>2</mn></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Ν</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></munderover><mrow><mo stretchy="false">(</mo><mi>Ι</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mi>Κ</mi></msub><mo stretchy="false">)</mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>为第<i>K</i>帧人体动作图像中目标和背景点的方差;<i>μ</i><sup>′</sup><sub><i>K</i></sub>为第<i>K</i>帧人体动作图目标和背景样本点中采用高斯模型的均值;<i>σ</i><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Κ</mi><mrow><mn>2</mn><msup><mrow></mrow><mo>´</mo></msup></mrow></msubsup></mrow></math></mathml>为第<i>K</i>帧人体动作图目标和背景样本点中采用高斯模型的方差;<i>N</i><sub><i>K</i></sub>为人体动作图像目标和背景的样本点数;<i>I</i><sub><i>j</i></sub>为人体动作图像每个样本点的灰度值;<i>ρ</i>为更新率。</p>
                </div>
                <div class="p1">
                    <p id="58">在人体高强度动作的情况下,为了在以原目标位置为中心的附近区域快速地找到人体动作图像目标,采用卡尔曼滤波来估测人体动作图像的目标位置。将第1帧中的人体动作图像目标中心位置以及动作速度赋值给<i>X</i><sub>1</sub>,那么估测的人体动作协方差可表示为</p>
                </div>
                <div class="p1">
                    <p id="59"><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>X</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>Κ</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>Μ</mi><mi>X</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></math></mathml>      (12)</p>
                </div>
                <div class="p1">
                    <p id="60">式中,<i>M</i>为滤波器的结构参数;<i>X</i><sub><i>K</i></sub>为第<i>K</i>帧图像中人体动作图像的目标中心位置以及动作速度的估测协方差值。结合上式能够估测出人体动作图像的目标位置,并得到精确的中心位置以及人体动作图像目标的滤波方程。</p>
                </div>
                <h3 id="61" name="61" class="anchor-tag"><b>4 基于图像识别的人体动作跟踪</b></h3>
                <div class="p1">
                    <p id="62">对人体动作图像跟踪过程中,在以图像动作目标和背景模型为基础的前提下,应用贝叶斯分类理论,对人体动作图像的灰度信息构建目标模型,并判断第<i>K</i>帧中的所有人体动作图像的样本点,得到人体动作的置信图,然后利用均值漂移理论识别置信图的峰值点,求解出人体动作图像的最优峰值点,实现多个目标的分割与跟踪。</p>
                </div>
                <div class="p1">
                    <p id="63">对人体动作图像的多目标进行分类时,应用贝叶斯公式进行计算出人体动作图像的后验条件概率,可表示为</p>
                </div>
                <div class="p1">
                    <p id="64"><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">|</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>2</mn></munderover><mi>p</mi></mstyle><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">|</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>      (13)</p>
                </div>
                <div class="p1">
                    <p id="65">式中,<i>i</i>=1,2;<i>p</i>(<i>w</i><sub>1</sub>|<i>x</i>)和<i>p</i>(<i>w</i><sub>2</sub>|<i>x</i>)分别为人体动作图像的目标模型和背景模型。将式(9)和式(13)进行联立,得出人体动作图像目标的初始位置,并且应用灰度信息构建目标模型,对样本点进行后验条件概率判断,便能求出人体动作的置信图<i>R</i><sub><i>K</i></sub>,可表示为</p>
                </div>
                <div class="p1">
                    <p id="66"><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><msub><mrow></mrow><mi>Κ</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>      (14)</p>
                </div>
                <div class="p1">
                    <p id="67">将前一帧的人体动作图像的尺寸作为初值,通过均漂移算法求出人体动作的置信图峰值点,最终求出高强度运动下人体动作的自动跟踪目标函数,可表示为</p>
                </div>
                <div class="p1">
                    <p id="68"><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Y</mi><mo>=</mo><mover accent="true"><mi>ω</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>R</mi></mstyle><msub><mrow></mrow><mi>Κ</mi></msub><mo stretchy="false">(</mo><mi>Μ</mi><msup><mrow></mrow><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>,</mo><mi>Ν</mi><msup><mrow></mrow><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msup><mo stretchy="false">)</mo></mrow></math></mathml>      (15)</p>
                </div>
                <div class="p1">
                    <p id="69">因此,可以应用式(15)便可以完成人体动作图像识别的自动跟踪。</p>
                </div>
                <h3 id="70" name="70" class="anchor-tag"><b>5 实验分析</b></h3>
                <div class="p1">
                    <p id="71">为了验证本文基于图像识别方法的可行性与确定性,需要进行仿真。本文通过在MATLAB仿真环境下进行编程实现的,在人体处于高强度运动下,对人体动作进行自动识别。具体采用以下两种实验,对本文的识别方法进行验证:</p>
                </div>
                <div class="p1">
                    <p id="72">1)要求实验对象人处于某一个动作下,运用人体动作识别过程中常用的两种方法:形态学操作方法和活动轮廓模型法与本文的方法进行比较。通过对比,验证这三种方法图像提取时间的快慢和清晰度精确的情况,具体数据如下表所示。</p>
                </div>
                <div class="area_img" id="73">
                    <p class="img_tit"><b>表1 形态学操作方法数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="73" border="1"><tr><td><br />组数</td><td>图像提取时间/s</td><td>清晰度(%)</td></tr><tr><td><br />1</td><td>8.34</td><td>51.69</td></tr><tr><td><br />2</td><td>8.90</td><td>54.15</td></tr><tr><td><br />3</td><td>9.01</td><td>48.64</td></tr><tr><td><br />4</td><td>11.15</td><td>50.91</td></tr><tr><td><br />5</td><td>10.18</td><td>41.12</td></tr><tr><td><br />6</td><td>10.03</td><td>60.17</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="74">
                    <p class="img_tit"><b>表2 活动轮廓模型法数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="74" border="1"><tr><td><br />组数</td><td>图像提取时间/s</td><td>清晰度(%)</td></tr><tr><td><br />1</td><td>11.83</td><td>56.68</td></tr><tr><td><br />2</td><td>10.89</td><td>58.56</td></tr><tr><td><br />3</td><td>12.90</td><td>56.36</td></tr><tr><td><br />4</td><td>12.59</td><td>50.12</td></tr><tr><td><br />5</td><td>11.85</td><td>51.44</td></tr><tr><td><br />6</td><td>11.43</td><td>60.92</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="75">
                    <p class="img_tit"><b>表3 图像识别方法数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="75" border="1"><tr><td><br />组数</td><td>图像提取时间/s</td><td>清晰度(%)</td></tr><tr><td><br />1</td><td>1.81</td><td>96.48</td></tr><tr><td><br />2</td><td>1.39</td><td>98.36</td></tr><tr><td><br />3</td><td>2.06</td><td>96.27</td></tr><tr><td><br />4</td><td>2.91</td><td>96.12</td></tr><tr><td><br />5</td><td>1.57</td><td>97.44</td></tr><tr><td><br />6</td><td>1.63</td><td>96.99</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="76">从表中可以看出,采用形态学操作方法和活动轮廓模型法对6组图像进行处理,图像提取的时间平均约为10s,清晰度值平均约为55%;而采用本文图像识别自动跟踪方法对图像提取的时间平均值约1.5s,且清晰度平均值约为98%。通过对比可以看出,本文基于图像识别自动跟踪方法识别人体动作图像具有较高的清晰度,并且识别时间较短。</p>
                </div>
                <div class="p1">
                    <p id="77">2)要求实验对象人给出不同的动作,然后对其动作进行采样,将本文采用的方法与传统方法进行比较。在仿真环境下,对10组不同的人体动作分别进行图像识别,对比结果如图1所示。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201909098_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 人体动作识别成功率对比曲线" src="Detail/GetImg?filename=images/JSJZ201909098_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 人体动作识别成功率对比曲线</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201909098_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="79">从图中可以看出,采用对比方法图像识别的成功率均在70%以下,而采用本文动作识别方法的成功率在90%以上,说明本文采用的方法能够对人体动作进行精确地识别,对人体高强度下的动作图像识别具有重要的意义。</p>
                </div>
                <h3 id="80" name="80" class="anchor-tag"><b>6 结论</b></h3>
                <div class="p1">
                    <p id="81">本文提出了一种基于图像识别自动跟踪方法对高强度运动下的人体动作进行识别。首先,应用双重卷积理论对高强度下人体动作的原形图像进行阈值分割,实现基于图像识别的人体动作特征提取。然后,结合高斯模型对获得的人体动作图像目标、背景和前景信息进行处理,得到人体动作图像背景的高斯分布模型,采用卡尔曼滤波获取人体动作图像跟踪轨迹。最后,应用贝叶斯分类理论,对人体动作图像的灰度信息构建目标模型,求解出人体动作图像的最优峰值点,实现多个目标的分割与跟踪。</p>
                </div>
                <div class="p1">
                    <p id="82">在MATLAB仿真环境下进行实验,实验结果表明,通过图像识别自动跟踪方法对人体动作特征提取较为精确,提取速度较快,表明本文的方法可行性较高。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201609057&amp;v=MTAwMDNVUjdxZlp1Wm9GeW5tVzczQUlqclBkTEc0SDlmTXBvOUFZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 李荣,徐燕华.基于视觉信息的图像特征提取算法研究[J].电子设计工程,2016,24(9):188-190.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201506035&amp;v=MTMyNTgzQUx6N0JkTEc0SDlUTXFZOUdZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeW5tVzc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 许丽娟,刘大龙.公交车危险动作视觉图像识别仿真[J].计算机仿真,2015,32(6):150-153.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                 张炎炎,孟繁丽,张新程,等.TD-LED网络结构评估方法研究及预规划分析[C].中国移动通信集团设计院第十九届新技术论坛论文集,北京:中国移动通信集团设计院,2013:37-42.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WYWT200301008&amp;v=MDA4MTlHRnJDVVI3cWZadVpvRnlubVc3M0FNalRjZXJHNEh0TE1ybzlGYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 鲁艳玲,吴伟陵.智能天线在CDMA网络规划与优化中的应用[J].无线通信技术,2003,(1):36-38.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DXKX200503023&amp;v=Mjk3NTN5bm1XNzNBSVRYQWRyRzRIdFRNckk5SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 肖莹,张新程.WCDMA系统的传播模型校准[J].电信科学,2005,(3):78-81.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201811064&amp;v=MDA5MTNvOURZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeW5tVzczQUx6N1NaTEc0SDluTnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 詹煜欣,董文永.基于对极几何约束的动态北京下运动目标检测[J].计算机应用研究,2018,35(11):3462-3465.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNLG201206012&amp;v=MjgwOTVFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlubVc3M0FMU1BIYWJHNEg5UE1xWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 姚莉秀,王小念,杨杰,等.基于多面体时空梯度描述子的人体动作识别[J].华南理工大学学报(自然科学版),2012,40(6):56-62.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201909098" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201909098&amp;v=MDU5NjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeW5tVzczQkx6N0JkTEc0SDlqTXBvOU1iSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
