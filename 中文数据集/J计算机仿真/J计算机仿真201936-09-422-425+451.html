<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139888100103750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201909087%26RESULT%3d1%26SIGN%3didJxmGWdReGehBt49mJ6IniW1F8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201909087&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201909087&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201909087&amp;v=MjM4NjBGckNVUjdxZlp1Wm9GeW5sVWIzSUx6N0JkTEc0SDlqTXBvOU5ZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;2 基于大数据的人体行为特征方向估计模型&lt;/b&gt; "><b>2 基于大数据的人体行为特征方向估计模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#32" data-title="&lt;b&gt;2.1 人体行为特征提取&lt;/b&gt;"><b>2.1 人体行为特征提取</b></a></li>
                                                <li><a href="#52" data-title="&lt;b&gt;2.2 构建人体行为特征方向估计模型&lt;/b&gt;"><b>2.2 构建人体行为特征方向估计模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#94" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#97" data-title="1)不同人体行为特征方向估计模型的效果对比:">1)不同人体行为特征方向估计模型的效果对比:</a></li>
                                                <li><a href="#101" data-title="2)对比不同人体行为特征方向估计模型的准确率(%):">2)对比不同人体行为特征方向估计模型的准确率(%):</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#107" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#99" data-title="&lt;b&gt;图1 不同模型对应的实验效果&lt;/b&gt;"><b>图1 不同模型对应的实验效果</b></a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;图2 所提评估模型准确率&lt;/b&gt;"><b>图2 所提评估模型准确率</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;图3 文献&lt;/b&gt;&lt;b&gt;评估模型的准确率&lt;/b&gt;"><b>图3 文献</b><b>评估模型的准确率</b></a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;图4 文献&lt;/b&gt;&lt;b&gt;评估模型的准确率&lt;/b&gt;"><b>图4 文献</b><b>评估模型的准确率</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 余家林,孙季丰,李万益.基于多核稀疏编码的三维人体姿态估计[J].电子学报,2016,44(8):1899-1908." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201608019&amp;v=MDc2NDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmxVYjNJSVRmVGU3RzRIOWZNcDQ5RWJZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         余家林,孙季丰,李万益.基于多核稀疏编码的三维人体姿态估计[J].电子学报,2016,44(8):1899-1908.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 朱珏钰,曹亚微,周书仁,等.基于随机森林深度特征选择的人体姿态估计[J].计算机工程与应用,2017,53(2):172-176." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201702032&amp;v=MjUyNDl1Wm9GeW5sVWIzSUx6N01hYkc0SDliTXJZOUdab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         朱珏钰,曹亚微,周书仁,等.基于随机森林深度特征选择的人体姿态估计[J].计算机工程与应用,2017,53(2):172-176.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 马淼,李贻斌.基于多级动态模型的2维人体姿态估计[J].机器人,2016,38(5):578-587." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201605009&amp;v=MTMzMjRmTEc0SDlmTXFvOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeW5sVWIzSUx6elo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         马淼,李贻斌.基于多级动态模型的2维人体姿态估计[J].机器人,2016,38(5):578-587.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 李庆武,席淑雅,王恬,等.结合位姿约束与轨迹寻优的人体姿态估计[J].光学精密工程,2017,25(4):1060-1069." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201704030&amp;v=MDEyMjR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlubFViM0lJalhCWTdHNEg5Yk1xNDlHWklRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         李庆武,席淑雅,王恬,等.结合位姿约束与轨迹寻优的人体姿态估计[J].光学精密工程,2017,25(4):1060-1069.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 代钦,石祥滨,乔建忠,等.结合遮挡级别的人体姿态估计方法[J].计算机辅助设计与图形学学报,2017,29(2):279-289." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201702009&amp;v=MDU4OTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeW5sVWIzSUx6N0JhTEc0SDliTXJZOUZiWVE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         代钦,石祥滨,乔建忠,等.结合遮挡级别的人体姿态估计方法[J].计算机辅助设计与图形学学报,2017,29(2):279-289.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 李红波,李双生,孙舶源.基于Kinect骨骼数据的人体动作姿势识别方法[J].计算机工程与设计,2016,37(4):969-975." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201604025&amp;v=MDYyODhadVpvRnlubFViM0lOaWZZWkxHNEg5Zk1xNDlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         李红波,李双生,孙舶源.基于Kinect骨骼数据的人体动作姿势识别方法[J].计算机工程与设计,2016,37(4):969-975.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 温子星,徐欣,潘景文,等.预测性姿势调节对人体站立受扰后姿势响应影响的研究[J].中国康复医学杂志,2016,31(10):1104-1110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGKF201610010&amp;v=MjMwNDVMRzRIOWZOcjQ5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmxVYjNJUHlyQWE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         温子星,徐欣,潘景文,等.预测性姿势调节对人体站立受扰后姿势响应影响的研究[J].中国康复医学杂志,2016,31(10):1104-1110.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 杨建,刘述木,王晓林.投影深度向量分解融合 PEMS 的视角不变人体动作识别[J].计算机应用研究,2016,33(3):940-944." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201603070&amp;v=MTQwMjl1Wm9GeW5sVWIzSUx6N1NaTEc0SDlmTXJJOUNaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         杨建,刘述木,王晓林.投影深度向量分解融合 PEMS 的视角不变人体动作识别[J].计算机应用研究,2016,33(3):940-944.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 尹彦,罗冬梅,刘卉,等.功能性踝关节不稳者姿势稳定性的研究进展[J].体育科学,2016,36(4):61-67." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TYKX201604008&amp;v=MDkwNzM0OUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeW5sVWIzSU1UVEFkckc0SDlmTXE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         尹彦,罗冬梅,刘卉,等.功能性踝关节不稳者姿势稳定性的研究进展[J].体育科学,2016,36(4):61-67.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 王健,袁立伟,张芷,等.视觉预期和注意指向对姿势和动作肌肉预期和补偿姿势调节的影响[J].心理学报,2017,49(7):920-927." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XLXB201707007&amp;v=MjQ4OTgzSVBTSFRiTEc0SDliTXFJOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeW5sVWI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         王健,袁立伟,张芷,等.视觉预期和注意指向对姿势和动作肌肉预期和补偿姿势调节的影响[J].心理学报,2017,49(7):920-927.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 尹清松,廖前芳,周前祥,等.基于JACK的驾驶姿势的下肢关节受力及舒适度分析[J].航天医学与医学工程,2016,29(6):440-445." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HYXB201606010&amp;v=MTM5NTZxQnRHRnJDVVI3cWZadVpvRnlubFViM0lMVFRUYkxHNEg5Zk1xWTlFWklRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         尹清松,廖前芳,周前祥,等.基于JACK的驾驶姿势的下肢关节受力及舒适度分析[J].航天医学与医学工程,2016,29(6):440-445.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 刘桥.游泳运动员姿势识别校正方法研究与仿真[J].计算机仿真,2017,34(4):227-230." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201704048&amp;v=MzE5NDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlubFViM0lMejdCZExHNEg5Yk1xNDlCYklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         刘桥.游泳运动员姿势识别校正方法研究与仿真[J].计算机仿真,2017,34(4):227-230.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(09),422-425+451             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于大数据的人体行为特征方向估计模型仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E9%9D%99&amp;code=27158878&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘静</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%86%85%E8%92%99%E5%8F%A4%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E9%9D%92%E5%B9%B4%E6%94%BF%E6%B2%BB%E5%AD%A6%E9%99%A2&amp;code=0194487&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">内蒙古师范大学青年政治学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>由于人体运动过程中行为的多样性以及复杂性,导致人体行为特征方向估计模型的效果不理想、准确率偏低等问题。为此,构建基于大数据的人体行为特征方向估计模型。通过人体运动图像中的深度信息分别计算出不同像素点在水平方向和垂直方向的梯度值,再计算不同像素点与邻域像素点之间的差值,获取人体行为特征。对图像中的关键参数进行自适应处理,利用遗传算法对关键参数进行寻优,并构建基于大数据的人体行为特征方向估计模型。实验结果表明,与传统的人体行为特征方向估计模型相比,所提估计模型在人体行为特征方向估计效果以及准确率方面都有较大幅度的提升。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%A7%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大数据;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E4%BD%93%E8%A1%8C%E4%B8%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人体行为;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%96%B9%E5%90%91&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征方向;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BC%B0%E8%AE%A1%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">估计模型;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    刘静(1981-),女(满族),内蒙古乌兰察布人,硕士,讲师,研究方向:计算机应用。&lt;image id="153" type="formula" href="images/JSJZ201909087_15300.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-10</p>

            </div>
                    <h1><b>Simulation of Human Body Behavior Feature Direction Estimation Model Based on Big Data</b></h1>
                    <h2>
                    <span>LIU Jing</span>
            </h2>
                    <h2>
                    <span>Youth College of Politics Science of Inner Mongolia Normal University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Due to the diversity and complexity of behavior during human motion, the estimation model of human behavior features is not ideal and the accuracy is low. Therefore, a model to estimate human behavior feature direction based on big data was constructed. The gradient values of different pixel points on the horizontal direction and the vertical direction are respectively computed by the depth information in human motion image, and the difference between different pixel points and adjacent pixel points was calculated to obtain the human behavior feature. The key parameters in image were adaptively processed. Finally, the genetic algorithm was used to optimize key parameters, and the estimation model of human behavior feature direction based on big data was constructed. Following conclusion can be drawn from Simulation results show that, compared with the traditional estimation model of human behavior feature direction, the proposed estimation model has a great improvement in the estimation effect and accuracy of human behavior feature.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Big%20data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Big data;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Human%20behavior&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Human behavior;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Feature%20direction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Feature direction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Estimation%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Estimation model;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-10</p>
                            </div>


        <!--brief start-->
                        <h3 id="27" name="27" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="28">人体行为特征方向估计一直以来都是一项十分具有挑战的工作,主要是通过单一的图像来估计人体的姿势状态,提取人体主要关节的节点<citation id="135" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。但是,人体自身的遮挡、衣着的变化等多种情况,造成人体行为特征方向估计问题一直没有得到很好的解决。早期的人体行为特征方向估计模型主要用于普通的可见光图像<citation id="136" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。但是随着大数据时代的到来,传统的人体行为特征方向估计模型已经无法满足当前的需求。人体行为特征方向估计成为当前各界学者十分关注的问题<citation id="137" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。人体行为特征方向估计的应用前景十分广泛,研究人体行为特征方向估计模型具有重要意义以及实用价值。</p>
                </div>
                <div class="p1">
                    <p id="29">为了解决人体行为特征方向估计模型存在的一系列问题,有关学者给出了一些相关的研究成果。例如文献<citation id="138" type="reference">[<a class="sup">4</a>]</citation>构建基于轨迹寻优的人体行为特征方向估计模型。首先估计人体单一部件和对称部件在单帧图像中的多个合理位置,通过对称部件之间的位姿约束构建标识部件。然后根据单一部件、标识部件各自的目标优化函数,引用动态规划算法得到初始轨迹候选集。最后根据最优轨迹构建人体行为特征方向估计模型。由于该模型的计算步骤较为复杂,导致该模型的整体估计效果并不是十分理想。文献<citation id="139" type="reference">[<a class="sup">5</a>]</citation>构建基于部位形变的人体行为特征方向估计模型。根据遮挡级别以及遮挡程度,计算遮挡方位以及遮挡比例。通过构建所对应遮挡级别的部位检测器,形成人体行为特征方向估计模型。该模型的适用性较差,需要进一步进行深入研究。</p>
                </div>
                <div class="p1">
                    <p id="30">针对上述模型存在的一系列问题,构建基于大数据的人体行为特征方向估计模型。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>2 基于大数据的人体行为特征方向估计模型</b></h3>
                <h4 class="anchor-tag" id="32" name="32"><b>2.1 人体行为特征提取</b></h4>
                <div class="p1">
                    <p id="33">在初始图像中各个像素点的值为物体在深度z方向上的实际距离。在人体行为特征提取的过程中,要判断像素点是否属于人体,且需要在深度图上进行人体行为特征前景提取,分析出人体所在的区域范围。在以下的过程中,利用四叉树分裂——合并方法将图像按照从大到小的顺序进行划分,将人体划分多个不同的块。如果任意一个方块内的像素具有连续性,则证明该区域内的像素具有连续性;反之,如果该区域内的像素不连续,则继续将图像进行分块,直至图像足够小。将不同区域的方块与其邻近的方块进行比较,如果像素是连续性的,则将图像进行合并,将图像从大到小处理过一次后,就能够将人体的深度连续区域分割出来。以下给出具体的研究过程。</p>
                </div>
                <div class="p1">
                    <p id="34">在初步得到人体的各个区域后,分别对人体各个区域的像素进行提取,通过偏移量能够得到两个不同像素之间的深度值之差,将该差值作为提取到的人体特征<citation id="140" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。将人体上不同点的深度值看作是足够大的常数,此时,上述特征具有保持不变的特性,则有</p>
                </div>
                <div class="p1">
                    <p id="35"><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>Ι</mi><mo>,</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>d</mi><msub><mrow></mrow><mi>Ι</mi></msub><mrow><mo>(</mo><mrow><mi>x</mi><mo>+</mo><mfrac><mi>u</mi><mrow><mi>d</mi><msub><mrow></mrow><mi>Ι</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>)</mo></mrow><mo>-</mo><mi>d</mi><msub><mrow></mrow><mi>Ι</mi></msub><mrow><mo>(</mo><mrow><mi>x</mi><mo>+</mo><mfrac><mi>v</mi><mrow><mi>d</mi><msub><mrow></mrow><mi>Ι</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>)</mo></mrow></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="36">式中,,<i>d</i><sub><i>I</i></sub>(<i>x</i>)代表像素点<i>x</i>的深度值,<i>u</i>、<i>v</i>分别代表人体不同特征矢量<citation id="141" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="37">所提方法在传统方法的基础上,引入随机森林算法,对图像进行分割、提取等。通过对人体区域进行标定,能够提取相应的人体行为特征。在上述基础上,利用随机森林算法进行训练得到一个分类器。将未经过识别的人体行为特征图像放入至训练好的随机森林分类器中,能够得到不同的人体区域像素分类标签</p>
                </div>
                <div class="p1">
                    <p id="38"><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>Ι</mi><mo>,</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>Τ</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mi>Ρ</mi></mstyle><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">(</mo><mi>Ι</mi><mo>,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="39">利用Mean-Shift算法对图像的像素识别结果进行计算,能够得到初步的人体骨架识别结果。在实际的测试图片中,能够得到人体各个区域的骨架节点,但是人体手臂处的节点误差相对较大。例如,在一个人伸出手臂放置于人体的躯干前面时,由于遮挡关系,会造成各个关节叠加在一起,无法进行区分,产生较大的误差<citation id="142" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。针对以上情况,引用多视角后处理方法对误差进行改进,结合深度图估算出人体的身高以及人体所对应的标准节点模型。通过式(3)计算人体某个区域节点所对应的置信度</p>
                </div>
                <div class="p1">
                    <p id="40"><mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>f</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mrow><mi>exp</mi></mrow><mrow><mo>(</mo><mrow><mo>-</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>↔</mo><mi>j</mi></mrow></munder><mi>a</mi></mstyle><mi>b</mi><mi>s</mi><mo stretchy="false">(</mo><mi>log</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>/</mo><mo stretchy="false">)</mo><mi>D</mi><mo stretchy="false">(</mo><mi>i</mi><msub><mrow></mrow><mi>s</mi></msub><mo>,</mo><mi>j</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mo>)</mo></mrow></mrow></math></mathml>      (3)</p>
                </div>
                <div class="p1">
                    <p id="41">式中,<i>D</i>(<i>i</i><sub><i>s</i></sub>,<i>j</i><sub><i>s</i></sub>)代表人体模型中任意两个骨架节点之间的空间距离,<i>D</i>(<i>i</i>,<i>j</i>)代表计算结果中两个节点之间的空间距离。如果上述的两个距离值特别接近,则证明该值符合所估计的人体模型,且具有较高的置信度;反之,则说明该区域内的节点置信度特别低。</p>
                </div>
                <div class="p1">
                    <p id="42">对人体行为测试图进行深入分析,得到手臂上各个节点的位置信息<citation id="143" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,利用式(4)给出投影后的概率分布计算式</p>
                </div>
                <div class="p1">
                    <p id="43"><mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>y</mi><mi>z</mi></mrow></msub><mo stretchy="false">(</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><mo>∑</mo><mrow><mfrac><mn>1</mn><mi>Ν</mi></mfrac></mrow></mstyle><mi>Ρ</mi><mo stretchy="false">(</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>q</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (4)</p>
                </div>
                <div class="p1">
                    <p id="44">式中,<i>q</i>代表人体某个像素的识别分类结果。将所有<i>x</i>-<i>y</i>平面上全部像素的识别结果放置于测试图中,并重新计算投影后的概率分布值。在上述基础上,利用Mean-Shift算法进行计算,能够得到人体各个节点的位置信息</p>
                </div>
                <div class="p1">
                    <p id="45"><i>E</i>=((<i>I</i><sub><i>yz</i></sub>(<i>y</i>,<i>z</i>)=<i>q</i>))(<i>x</i>-<i>y</i>)(<i>y</i>-<i>z</i>)      (5)</p>
                </div>
                <div class="p1">
                    <p id="46">仅仅通过上述计算得到的关于<i>y</i>、<i>z</i>的信息是无法在三维空间内得到一个准确的节点位置,利用上述计算能够得到人体手臂上各个节点的相关信息,将得到的两个数据进行合并,获取人体区域内各个节点准确的三维位置信息</p>
                </div>
                <div class="p1">
                    <p id="47"><mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>y</mi><mi>z</mi></mrow></msub><mo stretchy="false">(</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>q</mi><mo stretchy="false">)</mo></mrow><mrow><mi>D</mi><mo stretchy="false">(</mo><mi>i</mi><msub><mrow></mrow><mi>s</mi></msub><mo>,</mo><mi>j</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>      (6)</p>
                </div>
                <div class="p1">
                    <p id="48">以下给出深度图经过增加处理后的人体骨架估计算法的计算流程:</p>
                </div>
                <div class="p1">
                    <p id="49">1)利用图像基本识别方法能够得到人体区域内各个节点的准确位置信息;</p>
                </div>
                <div class="p1">
                    <p id="50">2)通过人体模型来计算人体区域内各个节点的置信度,如果人体内某一个节点的置信度很高,则跳过该节点,减少整个算法的计算量;反之,针对节点置信度偏低,则在原始的深度图上形成新的测试图以及顶视图。</p>
                </div>
                <div class="p1">
                    <p id="51">3)在上述步骤的基础上,重新计算人体各个骨架节点的确切位置,将三维数据进行重新更新,得到的结果就是人体行为特征。</p>
                </div>
                <h4 class="anchor-tag" id="52" name="52"><b>2.2 构建人体行为特征方向估计模型</b></h4>
                <div class="p1">
                    <p id="53">在2.1小节的基础上,通过对关键参数的方式进行自适应处理,利用遗传优化算法进行寻优,并构建人体行为特征方向估计模型。以下给出具体的研究过程:</p>
                </div>
                <div class="p1">
                    <p id="54">通过三维物体投射到二维平面的过程可描述为</p>
                </div>
                <div class="p1">
                    <p id="55"><i>W</i>=<i>πS</i>      (7)</p>
                </div>
                <div class="p1">
                    <p id="56">式中,<i>S</i>代表未知的三维形状;<i>W</i>代表二维投影;假设∏代表摄像机校准矩阵,为了简化描述,采用弱透视投影模型,则∏能够简化为</p>
                </div>
                <div class="area_img" id="57">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201909087_05700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="59">式中,<i>α</i>代表一个决定摄像机焦距以及摄像机与物体远近的标量。</p>
                </div>
                <div class="p1">
                    <p id="60">为了增加人体行为特征方向的适用性,引用三维物体<i>S</i>设定主动模型,则有</p>
                </div>
                <div class="p1">
                    <p id="61"><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>c</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>R</mi><msub><mrow></mrow><mi>i</mi></msub><mi>B</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>      (9)</p>
                </div>
                <div class="p1">
                    <p id="62">式中,<i>R</i><sub><i>i</i></sub>代表旋转矩阵,<i>B</i><sub><i>i</i></sub>代表基础形状,<i>c</i><sub><i>i</i></sub>代表基础形状的权重值,<i>i</i>、<i>k</i>代表基础形状的数量,则能够将式(7)转换为</p>
                </div>
                <div class="p1">
                    <p id="63"><i>W</i>=<image href="images/JSJZ201909087_120.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>c</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>R</mi><msub><mrow></mrow><mi>i</mi></msub><mi>B</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>Μ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>B</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>      (10)</p>
                </div>
                <div class="p1">
                    <p id="64">其中</p>
                </div>
                <div class="p1">
                    <p id="65"><i>M</i><sub><i>i</i></sub>=<i>c</i><sub><i>i</i></sub>∏<i>R</i><sub><i>i</i></sub>      (11)</p>
                </div>
                <div class="p1">
                    <p id="66">式(11)满足如下约束条件</p>
                </div>
                <div class="p1">
                    <p id="67"><i>M</i><sub><i>i</i></sub><i>M</i><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup></mrow></math></mathml>=<i>c</i><sup>2</sup><sub><i>i</i></sub><i>l</i>      (12)</p>
                </div>
                <div class="p1">
                    <p id="68">式中,<i>l</i>代表单位矩阵。</p>
                </div>
                <div class="p1">
                    <p id="69">考虑实际应用中的噪声问题,则能够将凸规划式表示为</p>
                </div>
                <div class="p1">
                    <p id="70"><mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Q</mi><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>Μ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>Μ</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mi>W</mi><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow></munderover><mi>Μ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>B</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mo stretchy="false">|</mo><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false">|</mo></mstyle><mo stretchy="false">|</mo><mi>Μ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mo stretchy="false">|</mo><msub><mrow></mrow><mn>2</mn></msub></mrow></math></mathml>      (13)</p>
                </div>
                <div class="p1">
                    <p id="71">其中,||*||<sub><i>F</i></sub>代表矩阵的<i>F</i>-范数,<i>λ</i>代表一个常数<citation id="144" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。在上述基础上,引入辅助变量<i>Z</i>,则将式(13)转换为</p>
                </div>
                <div class="p1">
                    <p id="72"><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Q</mi><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mo>=</mo><mi>min</mi></mrow></mstyle><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>Μ</mi></mstyle><mo>∼</mo></mover><mi>Ζ</mi></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mi>W</mi><mo>-</mo><mi>Ζ</mi><mover><mstyle mathsize="140%" displaystyle="true"><mi>B</mi></mstyle><mo>∼</mo></mover><mo stretchy="false">|</mo><mo stretchy="false">|</mo><msubsup><mrow></mrow><mn>2</mn><mi>F</mi></msubsup><mo>+</mo><mi>λ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false">|</mo></mstyle><mo stretchy="false">|</mo><mi>Μ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mo stretchy="false">|</mo><msub><mrow></mrow><mn>2</mn></msub><mi>Ζ</mi></mrow></math></mathml>      (14)</p>
                </div>
                <div class="p1">
                    <p id="73">式中,<i>M</i><sub>1</sub>,…,<i>M</i><sub><i>k</i></sub>代表<mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>Μ</mi></mstyle><mo>∼</mo></mover></mrow></math></mathml>的列向量,<mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ζ</mi><mo>=</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>Μ</mi></mstyle><mo>∼</mo></mover><mo>,</mo><mi>B</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>B</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></math></mathml>代表<mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>B</mi></mstyle><mo>∼</mo></mover></mrow></math></mathml>的行向量。</p>
                </div>
                <div class="p1">
                    <p id="74">上式的增强拉格朗日形式为</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>Μ</mi></mstyle><mo>∼</mo></mover><mo>,</mo><mi>Ζ</mi><mo>,</mo><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mi>W</mi><mo>-</mo><mi>Ζ</mi><mover><mstyle mathsize="140%" displaystyle="true"><mi>B</mi></mstyle><mo>∼</mo></mover><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mo>+</mo><mo>〈</mo><mi>Y</mi><mo>,</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>Μ</mi></mstyle><mo>∼</mo></mover><mo>-</mo><mi>Ζ</mi><mo>〉</mo><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mfrac><mi>μ</mi><mn>2</mn></mfrac><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>Μ</mi></mstyle><mo>∼</mo></mover><mo>-</mo><mi>Ζ</mi><mo stretchy="false">|</mo><mo stretchy="false">|</mo><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">式中,<i>Y</i>代表人体中的节点对偶变量,<i>μ</i>代表控制优化步数的参数。在上述基础上,引用<i>ADMM</i>算法计算下列步骤,直至收敛,即</p>
                </div>
                <div class="p1">
                    <p id="77"><mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>Μ</mi></mstyle><mo>∼</mo></mover><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>Μ</mi></munder><mi>L</mi><msub><mrow></mrow><mi>μ</mi></msub><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>Μ</mi></mstyle><mo>∼</mo></mover><mo>,</mo><mi>Ζ</mi><mo>,</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (16)</p>
                </div>
                <div class="p1">
                    <p id="78"><mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Y</mi><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>Ζ</mi></munder><mi>L</mi><msub><mrow></mrow><mi>μ</mi></msub><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>Μ</mi></mstyle><mo>∼</mo></mover><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>,</mo><mi>Ζ</mi><mo>,</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (17)</p>
                </div>
                <div class="p1">
                    <p id="79"><mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ζ</mi><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mi>Y</mi><msup><mrow></mrow><mi>k</mi></msup><mo>+</mo><mi>μ</mi><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>Μ</mi></mstyle><mo>∼</mo></mover><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>,</mo><mo>-</mo><mi>Ζ</mi><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo stretchy="false">)</mo></mrow></math></mathml>      (18)</p>
                </div>
                <div class="p1">
                    <p id="80">在传统方法的基础上,利用基于遗传算法的自适应凸松弛人体姿势估计算法对传统凸松弛算法进行改进<citation id="145" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。在传统方法中,作为控制优化步数的变量<i>μ</i>是一个十分重要的参数,能够调节整个算法的迭代次数以及准确性,即</p>
                </div>
                <div class="p1">
                    <p id="81">Pr<mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>i</mtext><mtext>m</mtext><mtext>R</mtext><mtext>e</mtext><mtext>s</mtext><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mi>Μ</mi><mo>-</mo><mi>Ζ</mi><mo stretchy="false">|</mo><mo stretchy="false">|</mo><msub><mrow></mrow><mi>F</mi></msub></mrow><mrow><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mi>Ζ</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">|</mo><mo stretchy="false">|</mo><msub><mrow></mrow><mi>F</mi></msub></mrow></mfrac></mrow></math></mathml>      (19)</p>
                </div>
                <div class="p1">
                    <p id="82">式(19)就是误差评价函数PrimRes的表达式。其中,<i>M</i>代表算法的估计值。</p>
                </div>
                <div class="p1">
                    <p id="83">参数<i>μ</i>的更新方式会影响算法的迭代次数和准确度。以下给出<i>μ</i>的更新方式</p>
                </div>
                <div class="area_img" id="84">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201909087_08400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="86">DualRes是<i>Z</i>在前后两次迭代中的变化函数,则有</p>
                </div>
                <div class="p1">
                    <p id="87">DualRe<mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>s</mtext><mo>=</mo><mi>μ</mi><mfrac><mrow><mrow><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mtext>Ζ</mtext><mo>-</mo><mtext>Ζ</mtext></mrow><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">|</mo><mo stretchy="false">|</mo><msub><mrow></mrow><mi>F</mi></msub></mrow><mrow><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mi>Ζ</mi><msub><mrow></mrow><mn>0</mn></msub><mrow><mo stretchy="false">|</mo><mo stretchy="false">|</mo></mrow><msub><mrow></mrow><mi>F</mi></msub></mrow></mfrac></mrow></math></mathml>      (21)</p>
                </div>
                <div class="p1">
                    <p id="88">在式(20)中,根据变化函数取值的大小对关键参数进行调整,但是在很多的情况下无法获取最佳的调整效果。对于经过改进后的算法,在算法的初始运行阶段,误差评价函数PrimRes的值相对较大。利用式(22)进行计算能够得到如下结论,<i>μ</i>的值越大,则算法的调节能力越强,以下给出<i>μ</i>值调整的最佳变换策略</p>
                </div>
                <div class="p1">
                    <p id="89"><i>μ</i><sub><i>t</i></sub><sub>+1</sub>=<i>μ</i><sub><i>t</i></sub>×<i>e</i><sup>(</sup><sup><i>k</i></sup><sup>PrimRes)2</sup>      (22)</p>
                </div>
                <div class="p1">
                    <p id="90">参数初始值选取的好坏往往能决定一个算法的执行效果。在原始算法中,参数<i>μ</i>的改变对算法的迭代次数以及准确度有很大的影响。在上述基础上,引用遗传算法对参数<i>μ</i>进行优化,并构建人体行为特征方向估计模型<citation id="146" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>,实现人体行为特征方向估计</p>
                </div>
                <div class="p1">
                    <p id="91"><i>Z</i><sup><i>t</i></sup><sup>+1</sup>=(<i>μ</i><mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>G</mi><mi>A</mi></mrow><mi>n</mi></msubsup></mrow></math></mathml><i>WB</i><sup><i>T</i></sup>+<i>μM</i><sup><i>t</i></sup><sup>+1</sup>+<i>Y</i><sup><i>tt</i></sup>)      (23)</p>
                </div>
                <div class="p1">
                    <p id="92">式中,<i>μ</i><mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>G</mi><mi>A</mi></mrow><mi>n</mi></msubsup></mrow></math></mathml>代表经过优化的<i>μ</i>的初始值。</p>
                </div>
                <div class="p1">
                    <p id="93">综上所述,完成人体行为特征方向估计模型的构建。</p>
                </div>
                <h3 id="94" name="94" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="95">为了验证所构建基于大数据的人体行为特征方向估计模型的综合有效性,需要进行实验,实验环境为:Intel CPU E56302.66GHz,40g内存,模型利用MATLAB脚本和C++混编实现。</p>
                </div>
                <div class="p1">
                    <p id="96">实验选取RGBD-GroundT-ruth进行实验,样本库中有500幅分辨率为768×576像素的图像,按照不同的任务划分为3类,并且每一类图像中都含有同一个人所做的连续动作。以下给出具体的实验过程:</p>
                </div>
                <h4 class="anchor-tag" id="97" name="97">1)不同人体行为特征方向估计模型的效果对比:</h4>
                <div class="p1">
                    <p id="98">将所构建的人体行为特征方向估计模型与文献<citation id="147" type="reference">[<a class="sup">4</a>]</citation>构建的基于轨迹寻优的人体行为特征方向估计模型进行实验效果对比,对比结果如图1所示。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201909087_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 不同模型对应的实验效果" src="Detail/GetImg?filename=images/JSJZ201909087_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 不同模型对应的实验效果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201909087_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="100">分析图1可知,所构建的人体行为特征方向估计模型对参数μ进行自适应处理后,能够解决传统方法存在的大面积躯干识别错误的问题,取得了较为理想的实验结果。</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101">2)对比不同人体行为特征方向估计模型的准确率(%):</h4>
                <div class="p1">
                    <p id="102">为了验证所构建的人体行为特征方向估计模型在人体特征方向估计的准确率上的综合有效性,将所提模型与文献<citation id="148" type="reference">[<a class="sup">4</a>]</citation>构建的基于轨迹寻优的人体行为特征方向估计模型以及文献<citation id="149" type="reference">[<a class="sup">5</a>]</citation>构建的基于部位形变的人体行为特征方向估计模型,对样本库中的500幅图像的准确率进行对比,实验结果如图2至图4所示。</p>
                </div>
                <div class="area_img" id="103">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201909087_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 所提评估模型准确率" src="Detail/GetImg?filename=images/JSJZ201909087_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 所提评估模型准确率</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201909087_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="104">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201909087_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 文献[4]评估模型的准确率" src="Detail/GetImg?filename=images/JSJZ201909087_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 文献</b><citation id="150" type="reference">[<a class="sup">4</a>]</citation><b>评估模型的准确率</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201909087_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="105">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201909087_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 文献[5]评估模型的准确率" src="Detail/GetImg?filename=images/JSJZ201909087_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 文献</b><citation id="151" type="reference">[<a class="sup">5</a>]</citation><b>评估模型的准确率</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201909087_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="106">分析图2至图4可知,所提基于大数据的人体行为特征方向估计模型的准确率走势相对较稳定,一直高于其它两种人体行为特征方向估计模型,并且所提模型的准确率一直在93%-99%之内。通过具体的实验数据,充分验证了所提模型在准确率上,相比传统模型有了一定的提高,并且具有较好的鲁棒性。</p>
                </div>
                <h3 id="107" name="107" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="108">人体行为特征方向估计一直以来都是一个十分具有挑战的问题,虽然被广泛应用,但却一直未得到很好的解决。基于此,在传统模型的基础上,构建了基于大数据的人体行为特征方向估计模型。实验结果表明,所提模型适用性强,准确性高。</p>
                </div>
                <div class="p1">
                    <p id="109">所提模型针对大数据下的人体行为特征方向估计方面进行了深入研究,但是现阶段的人体行为特征方向估计模型无法满足实际的应用需求,该模型还有较大的提升空间。</p>
                </div>
                <div class="p1">
                    <p id="110">未来阶段,将主要针对以下几个方面展开研究:</p>
                </div>
                <div class="p1">
                    <p id="111">1)将独立输出层相结合,构建目标检测边框。</p>
                </div>
                <div class="p1">
                    <p id="112">2)如何将任务需求的相关参数智能化以及将参数加入到模型中,进行联合训练是今后研究的重要方向。</p>
                </div>
                <div class="p1">
                    <p id="113">3)如何利用深度神经网络进行无监督学习,提高深度神经网络的性能,也是一项十分有意义的研究。未来阶段,将会针对该方面展开深入研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201608019&amp;v=MTY3MDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlubFViM0lJVGZUZTdHNEg5Zk1wNDlFYllRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 余家林,孙季丰,李万益.基于多核稀疏编码的三维人体姿态估计[J].电子学报,2016,44(8):1899-1908.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201702032&amp;v=MTI3MDl1Wm9GeW5sVWIzSUx6N01hYkc0SDliTXJZOUdab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 朱珏钰,曹亚微,周书仁,等.基于随机森林深度特征选择的人体姿态估计[J].计算机工程与应用,2017,53(2):172-176.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201605009&amp;v=MjM1NzN5bmxVYjNJTHp6WmZMRzRIOWZNcW85RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 马淼,李贻斌.基于多级动态模型的2维人体姿态估计[J].机器人,2016,38(5):578-587.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201704030&amp;v=MDI4NjRSN3FmWnVab0Z5bmxVYjNJSWpYQlk3RzRIOWJNcTQ5R1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 李庆武,席淑雅,王恬,等.结合位姿约束与轨迹寻优的人体姿态估计[J].光学精密工程,2017,25(4):1060-1069.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201702009&amp;v=MjAyMzVGYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlubFViM0lMejdCYUxHNEg5Yk1yWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 代钦,石祥滨,乔建忠,等.结合遮挡级别的人体姿态估计方法[J].计算机辅助设计与图形学学报,2017,29(2):279-289.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201604025&amp;v=MTUwMTdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmxVYjNJTmlmWVpMRzRIOWZNcTQ5SFk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 李红波,李双生,孙舶源.基于Kinect骨骼数据的人体动作姿势识别方法[J].计算机工程与设计,2016,37(4):969-975.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGKF201610010&amp;v=MDQ2NTh0R0ZyQ1VSN3FmWnVab0Z5bmxVYjNJUHlyQWFMRzRIOWZOcjQ5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 温子星,徐欣,潘景文,等.预测性姿势调节对人体站立受扰后姿势响应影响的研究[J].中国康复医学杂志,2016,31(10):1104-1110.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201603070&amp;v=MTU1MjBGckNVUjdxZlp1Wm9GeW5sVWIzSUx6N1NaTEc0SDlmTXJJOUNaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 杨建,刘述木,王晓林.投影深度向量分解融合 PEMS 的视角不变人体动作识别[J].计算机应用研究,2016,33(3):940-944.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TYKX201604008&amp;v=MjcwNTFvRnlubFViM0lNVFRBZHJHNEg5Zk1xNDlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 尹彦,罗冬梅,刘卉,等.功能性踝关节不稳者姿势稳定性的研究进展[J].体育科学,2016,36(4):61-67.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XLXB201707007&amp;v=MjQzNzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeW5sVWIzSVBTSFRiTEc0SDliTXFJOUZZNFE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 王健,袁立伟,张芷,等.视觉预期和注意指向对姿势和动作肌肉预期和补偿姿势调节的影响[J].心理学报,2017,49(7):920-927.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HYXB201606010&amp;v=MTcyNTJPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmxVYjNJTFRUVGJMRzRIOWZNcVk5RVpJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 尹清松,廖前芳,周前祥,等.基于JACK的驾驶姿势的下肢关节受力及舒适度分析[J].航天医学与医学工程,2016,29(6):440-445.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201704048&amp;v=MjI0MTJPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmxVYjNJTHo3QmRMRzRIOWJNcTQ5QmJJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 刘桥.游泳运动员姿势识别校正方法研究与仿真[J].计算机仿真,2017,34(4):227-230.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201909087" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201909087&amp;v=MjM4NjBGckNVUjdxZlp1Wm9GeW5sVWIzSUx6N0JkTEc0SDlqTXBvOU5ZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
