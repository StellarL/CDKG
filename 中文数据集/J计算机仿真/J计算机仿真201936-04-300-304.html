<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141820971693750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201904063%26RESULT%3d1%26SIGN%3dvWCt%252fDuDZOJ87K%252bV8WK7xLA4Uco%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201904063&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201904063&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201904063&amp;v=MjQzNjRkTEc0SDlqTXE0OURaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXpoVnJ2UEx6N0I=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="&lt;b&gt;2 SRCNN算法的基本原理&lt;/b&gt; "><b>2 SRCNN算法的基本原理</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="&lt;b&gt;2.1 SRCNN算法模型&lt;/b&gt;"><b>2.1 SRCNN算法模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#64" data-title="&lt;b&gt;3 基于MC-ARCNN算法的熔体图像重建&lt;/b&gt; "><b>3 基于MC-ARCNN算法的熔体图像重建</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#66" data-title="&lt;b&gt;3.1 MC-ARCNN的模型结构&lt;/b&gt;"><b>3.1 MC-ARCNN的模型结构</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;3.2 MC-ARCNN的模型公式&lt;/b&gt;"><b>3.2 MC-ARCNN的模型公式</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#79" data-title="&lt;b&gt;4 实验结果与分析&lt;/b&gt; "><b>4 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#80" data-title="&lt;b&gt;4.1 实验参数选择&lt;/b&gt;"><b>4.1 实验参数选择</b></a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;4.2 综合性能量化评价&lt;/b&gt;"><b>4.2 综合性能量化评价</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#101" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="&lt;b&gt;图1 SRCNN模型结构示意图&lt;/b&gt;"><b>图1 SRCNN模型结构示意图</b></a></li>
                                                <li><a href="#68" data-title="&lt;b&gt;图2 MC-ARCNN模型结构示意图&lt;/b&gt;"><b>图2 MC-ARCNN模型结构示意图</b></a></li>
                                                <li><a href="#71" data-title="&lt;b&gt;图3 原始低分辨输入图像及其不同程度的锐化图集&lt;/b&gt;"><b>图3 原始低分辨输入图像及其不同程度的锐化图集</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;图4 引晶前样图及SRCNN、MC-SRCNN、MC-ARCNN处理结果对比图&lt;/b&gt;"><b>图4 引晶前样图及SRCNN、MC-SRCNN、MC-ARCNN处理结果对比图</b></a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;表1 引晶前重建图像 (100帧) 的均值Brenner函数、熵函数计算&lt;/b&gt;"><b>表1 引晶前重建图像 (100帧) 的均值Brenner函数、熵函数计算</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;图5 四种典型状态样图的重建结果&lt;/b&gt;"><b>图5 四种典型状态样图的重建结果</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;表2 四种典型状态样图重建图像的均值Brenner函数计算结果&lt;/b&gt;"><b>表2 四种典型状态样图重建图像的均值Brenner函数计算结果</b></a></li>
                                                <li><a href="#100" data-title="&lt;b&gt;表3 四种典型状态样图重建图像的均值熵函数计算结果&lt;/b&gt;"><b>表3 四种典型状态样图重建图像的均值熵函数计算结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 李真, 陈振强, 陈宝东.泡生法高质量蓝宝石晶体的研究[J].人工晶体学报, 2008, 37 (4) :877-880." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RGJT200804025&amp;v=MDI0ODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6aFZydk9OeXJCZXJHNEh0bk1xNDlIWVlRS0RIODQ=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[1]</b>
                                         李真, 陈振强, 陈宝东.泡生法高质量蓝宝石晶体的研究[J].人工晶体学报, 2008, 37 (4) :877-880.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 刘丽君, 徐家庆, 蔡兴民.泡生法蓝宝石晶体生长工艺的探讨[J].哈尔滨工业大学学报, 2011, 43 (3) :145-148." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBX201103031&amp;v=MTgyNzR6cXFCdEdGckNVUjdxZlp1Wm1GeXpoVnJ2T0xTakpkckc0SDlETXJJOUdaWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[2]</b>
                                         刘丽君, 徐家庆, 蔡兴民.泡生法蓝宝石晶体生长工艺的探讨[J].哈尔滨工业大学学报, 2011, 43 (3) :145-148.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 李留臣, 冯金生.我国蓝宝石晶体生长技术的现状与发展趋势[J].人工晶体学报, 2012, 41 (1) :221-226." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RGJT2012S1042&amp;v=MjE1NjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXpoVnJ2T055ckJlckc0SDlPdnJvOUJab1FLREg4NHY=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[3]</b>
                                         李留臣, 冯金生.我国蓝宝石晶体生长技术的现状与发展趋势[J].人工晶体学报, 2012, 41 (1) :221-226.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 周林, 杨鹏.蓝宝石材料的性能和应用研究[J].硅谷, 2014, 7 (21) :139-140." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GGYT201421115&amp;v=MDg5NDBJaXJTZXJHNEg5WE9ybzVFWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6aFZydk8=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[4]</b>
                                         周林, 杨鹏.蓝宝石材料的性能和应用研究[J].硅谷, 2014, 7 (21) :139-140.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" J L HARRIS.Diffraction and resolving power[J].JOSA, 1964, 54 (7) :931-933." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Diffraction and resolving power">
                                        <b>[5]</b>
                                         J L HARRIS.Diffraction and resolving power[J].JOSA, 1964, 54 (7) :931-933.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" R Y TSAI.Multiframe image restoration and registration[J].Adv.Comput.Vis.Image Process., JAI Press Inc, 1984, 1 (2) :317-339." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multipleframe image restoration and registration">
                                        <b>[6]</b>
                                         R Y TSAI.Multiframe image restoration and registration[J].Adv.Comput.Vis.Image Process., JAI Press Inc, 1984, 1 (2) :317-339.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" H SU, J ZHOU, Z H ZHANG.Survey of super-resolution image reconstruction methods[J].Acta Automatica Sinica, 2013, 39 (8) :1202-1213." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201308005&amp;v=MTY5NzJGeXpoVnJ2T0tDTGZZYkc0SDlMTXA0OUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm0=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[7]</b>
                                         H SU, J ZHOU, Z H ZHANG.Survey of super-resolution image reconstruction methods[J].Acta Automatica Sinica, 2013, 39 (8) :1202-1213.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" F ZHOU, W YANG, Q LIAO.Interpolation-based image super-resolution using multisurface fitting[J].IEEE Transactions on Image Processing, 2012, 21 (7) :3312-3318." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interpolation-Based Image Super-Resolution Using Multisurface Fitting">
                                        <b>[8]</b>
                                         F ZHOU, W YANG, Q LIAO.Interpolation-based image super-resolution using multisurface fitting[J].IEEE Transactions on Image Processing, 2012, 21 (7) :3312-3318.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Z LIN, H Y SHUM.Fundamental limits of reconstruction-based superresolution algorithms under local translation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26 (1) :83-97." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fundamental Limits of Reconstruction-Base Superresolution Algorithms under Local Translation">
                                        <b>[9]</b>
                                         Z LIN, H Y SHUM.Fundamental limits of reconstruction-based superresolution algorithms under local translation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26 (1) :83-97.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 潘宗序, 等.基于多尺度结构自相似性的单幅图像超分辨率算法[J].自动化学报, 2014, 40 (4) :594-603." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201404003&amp;v=MTY0NjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emhWcnZPS0NMZlliRzRIOVhNcTQ5Rlo0UUtESDg0dlI0VDY=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[10]</b>
                                         潘宗序, 等.基于多尺度结构自相似性的单幅图像超分辨率算法[J].自动化学报, 2014, 40 (4) :594-603.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" C DONG, et al.Image super-resolution using deep convolutional networks[J].IEEE transactions on pattern analysis and machine intelligence, 2016, 38 (2) :295-307." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image super-resolution using deep convolutional networks">
                                        <b>[11]</b>
                                         C DONG, et al.Image super-resolution using deep convolutional networks[J].IEEE transactions on pattern analysis and machine intelligence, 2016, 38 (2) :295-307.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" J KIM, L J KWON, L K MU.Accurate image super-resolution using very deep convolutional networks[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, 2016:1646-1654." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accurate image super-resolution using very deep convolutional networks">
                                        <b>[12]</b>
                                         J KIM, L J KWON, L K MU.Accurate image super-resolution using very deep convolutional networks[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, 2016:1646-1654.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" J JOHNSON, A ALAHI, F F LI.Perceptual Losses for Real-Time Style Transfer and Super-Resolution[J].ECCV, 2016:694-711." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Perceptual losses for real-time style transfer and super-resolution">
                                        <b>[13]</b>
                                         J JOHNSON, A ALAHI, F F LI.Perceptual Losses for Real-Time Style Transfer and Super-Resolution[J].ECCV, 2016:694-711.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" B LIM, et al.Enhanced deep residual networks for single image super-resolution[C].The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops.2017, 1 (2) :3." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Enhanced Deep Residual Networks for Single Image Super-Resolution">
                                        <b>[14]</b>
                                         B LIM, et al.Enhanced deep residual networks for single image super-resolution[C].The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops.2017, 1 (2) :3.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" G Y YOUM, S H BAE, M KIM.Image super-resolution based on convolution neural networks using multi-channel input[C].Image, Video, and Multidimensional Signal Processing Workshop.IEEE, Bordeaux, 2016:1-5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image super-resolution based on convolution neural networks using multi-channel input">
                                        <b>[15]</b>
                                         G Y YOUM, S H BAE, M KIM.Image super-resolution based on convolution neural networks using multi-channel input[C].Image, Video, and Multidimensional Signal Processing Workshop.IEEE, Bordeaux, 2016:1-5.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" C DONG, et al.Compression artifacts reduction by a deep convolutional network[C].Proceedings of the IEEE International Conference on Computer Vision, Santiago, 2015:576-584." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Compression artifacts reduction by a deep convolutional network &amp;quot;">
                                        <b>[16]</b>
                                         C DONG, et al.Compression artifacts reduction by a deep convolutional network[C].Proceedings of the IEEE International Conference on Computer Vision, Santiago, 2015:576-584.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" S Yazdanfar, et al.Simple and robust image-based autofocusing for digital microscopy[J].Optics express, 2008, 16, (12) :8670-8677." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Simple and robust image-based autofocusing for digital microscopy">
                                        <b>[17]</b>
                                         S Yazdanfar, et al.Simple and robust image-based autofocusing for digital microscopy[J].Optics express, 2008, 16, (12) :8670-8677.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" N R Pal, S K Pal.Entropy:A new definition and its applications[J].IEEE transactions on systems, man, and cybernetics, 1991, 21 (5) :1260-1270." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Entropy: a new definition and its applications">
                                        <b>[18]</b>
                                         N R Pal, S K Pal.Entropy:A new definition and its applications[J].IEEE transactions on systems, man, and cybernetics, 1991, 21 (5) :1260-1270.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(04),300-304             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于CNN的晶体生长状态图像重建与仿真研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%9D%A4&amp;code=24668270&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">王坤</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E9%92%B0&amp;code=17333302&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">李钰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%AF%9B%E9%A2%96%E6%9D%B0&amp;code=36993372&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">毛颖杰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%AE%B7%E5%A7%B8&amp;code=41614100&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">殷姸</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%9C%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0024290&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">华东理工大学信息科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对晶体生长过程中熔体状态图像对比度低、纹理细节不清晰的问题, 在分析基于卷积神经网络的图像超分辨率重建算法的基础上, 结合多通道输入以及去噪技术, 提出一种基于多通道输入-祛伪影卷积神经网络的图像重建算法, 用于提高熔体状态成像质量。以蓝宝石晶体为研究对象的重建仿真结果表明, 所提算法的重建结果在主观判断和客观评价上都优于传统重建算法, 对提高晶体生长设备的自动化水平具有十分重要的意义。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%86%94%E4%BD%93%E7%8A%B6%E6%80%81&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">熔体状态;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">图像重建;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E9%80%9A%E9%81%93%E8%BE%93%E5%85%A5&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">多通道输入;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9B%E4%BC%AA%E5%BD%B1&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">祛伪影;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王坤 (1993-) , 男 (汉族) , 江苏省江都市人, 硕士研究生, 主要研究领域为图像处理、模式识别。;
                                </span>
                                <span>
                                    李钰 (1973-) , 男 (汉族) , 浙江省诸暨市人, 副教授, 硕士研究生导师, 主要研究领域为信号与信息处理。;
                                </span>
                                <span>
                                    毛颖杰 (1994-) , 男 (汉族) , 浙江省奉化市人, 硕士研究生, 主要研究领域为图像处理、模式识别。;
                                </span>
                                <span>
                                    殷研 (1994-) , 女 (汉族) , 江苏省江都市人, 硕士研究生, 主要研究领域为图像处理、模式识别。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-03-07</p>

            </div>
                    <h1><b>Research on Image Reconstruction Algorithm and Simulation of Crystal Growth State Based on CNN</b></h1>
                    <h2>
                    <span>WANG Kun</span>
                    <span>LI Yu</span>
                    <span>MAO Ying-jie</span>
                    <span>YIN Yan</span>
            </h2>
                    <h2>
                    <span>College of Information Science and Engineering, East China University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In view of low contrast and unclear texture details problem of the melt state image during crystal growth, with analysis on super-resolution reconstruction algorithm of convolutional neural network, and combined with multi-channel input and denoising technique, an image reconstruction algorithm of multi-channel and artifacts-reduction based on convolutional neural network is proposed to improve the quality of melt state image. The reconstruction simulation results of sapphire crystal show that the reconstruction result of the proposed algorithm is superior to the traditional reconstruction algorithm in subjective judgment and objective evaluation, which is of great significance for improving the automation level of the crystal growth equipment.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Melt%20state&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Melt state;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20neural%20network&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20reconstruction&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Image reconstruction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-channel%20input&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Multi-channel input;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Artifacts%20reduction&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Artifacts reduction;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-03-07</p>
                            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="40">光学晶体在军事、航空航天、精密制造等领域具有广泛的应用, 由于自然界的天然晶体储量有限并且往往含有杂质, 因此需要通过人工结晶的方法来规模化生产。人工晶体的生产通常需要在高温晶体生长炉中经过化料、引晶、结晶等过程, 整个工艺过程依赖温度梯度的调节来完成, 特别是引晶时熔体界面的温度场分布状态对产品质量有着重要的影响。例如, 泡生法来生产蓝宝石晶体<citation id="103" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。由于原材料三氧化二铝的熔点高达2045度, 熔体界面的温度分布状态很难通过传感器直接测量, 通常是由操作人员通过观察界面的纹理状态来间接判断温度场的分布。这种方法主观性较大, 严重影响规模化生产效率的提高。随着世界各国对光学晶体需求的日益增长, 研究利用机器视觉代替人眼视觉, 通过熔体界面图像的纹理信息来自动识别状态, 提高晶体生长设备的自动化、智能化水平, 对实现晶体材料的规模化生产具有十分重要的意义<citation id="104" type="reference"><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="41">显然, 熔体界面的图像信息是实现晶体生长自动化的关键。然而, 在强热强光背景环境中, CCD摄像头采集到的熔体图像质量较低、对比度差、纹理细节不清晰, 对状态的判断带来了极大的困难。因此, 改善熔体界面纹理的成像质量, 使其能够准确地呈现炉内熔体状态, 是本文需要解决的关键问题。</p>
                </div>
                <div class="p1">
                    <p id="42">图像超分辨率 (Super-resolution, SR) 重建是图像复原领域的一个重要分支。早在20世纪60年代, Harris<citation id="105" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等以单张图像插值的方法首次提出“图像超分辨率重建”这一概念。20世纪80年代, Huang和Tsai<citation id="106" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>首次提出了基于频域并通过多张低分辨率 (Low-resolution, LR) 图像来重建一张高分辨率 (High-resolution, HR) 图像的超分辨率算法。在随后的30多年时间, 图像超分辨率重建技术以其广泛的应用价值和理论价值, 成为计算机视觉与图像处理领域的一个研究热点。</p>
                </div>
                <div class="p1">
                    <p id="43">目前, 主流的SR重建方法主要有三类:基于插值的方法、基于重建的方法和基于学习的方法<citation id="107" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。基于插值的方法是最早提出的图像重建方法<citation id="108" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, 最常见的方法有最近邻插值、线性插值、双三次插值等, 其优点是插值方法比较完善, 主流仿真软件中都有相对应的函数, 但是基于插值的方法在图像重建的同时也会产生混叠效应、块效应、模糊效应等问题, 复原效果并不理想。基于重建的超分辨率方法的基础是均衡及非均衡采样定理<citation id="109" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 强制约束了图像的平滑和下采样, 不能很好地重建一些高频细节。基于学习的方法是近年来图像超分辨率重建的主流算法<citation id="110" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 这类方法包含两个重要阶段, 一个是训练阶段, 另一个是重建阶段。其中, 训练阶段用于学习标准图像与LR图像间的对应关系, 重建阶段通过对应关系将训练样本库里的匹配图像块作为补充信息, 然后填充到原始LR图像中, 来丰富LR图像信息, 最后得到SR图像。</p>
                </div>
                <div class="p1">
                    <p id="44">近年来, 深度学习方法在计算机视觉领域有着优异的表现, 它可以通过建立强有力的模型和设计高效的学习策略来克服过度拟合, 并且神经网络可以灵活地通过改变网络结构或添加新的激活函数来更好地拟合训练数据。Dong等人结合卷积神经网络的方法用于图像超分辨率重建 (SRCNN) <citation id="111" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 以三层卷积网络结构, 建立了端到端图像超分辨率重建模型, 取得很好的效果;SRCNN的优势是网络结构比较简单, 易于收敛, 计算复杂度较低, 可以在保持高质量的情况下快速重建HR图像, 其缺陷是网络比较浅。Kim等提出了一种利用20层的残差卷积网络进行学习预测的方法<citation id="112" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 采用比较大的学习率参数大幅提高训练速度, 峰值信噪比 (Peak signal to noise ratio, PSNR) 实验结果接近历史最好效果;但是20层的大模型网络结构, 增加了更多的网络参数, 容易导致过拟合。Johnson等提出一种基于感知损失函数的修复低分辨率视频图像方法<citation id="113" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 从人类视觉感知角度出发, 取得很好的视觉效果;但是当采用较高层重建的时候, 保留了图像的内容和空间结构, 却改变了图像的颜色、纹理和精确的形状。Lim等提出了增强型深度残差网络结构, 去除了传统残差网络中的不必要模块, 加速了训练进程;但是拓展了基准模型, 不仅整体结构扩大, 也产生了梯度消失问题<citation id="114" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="45">本文针对采集晶体生长图像的细节信息不显著, 以及因高温高亮背景在图像处理过程中所产生的图像伪影现象, 结合实际应用的信号环境和算法的实时性, 以精简的卷积神经网络结构获得有效的图像超分辨率重建效果。在SRCNN算法的基础上, 结合细节增强和去噪算法, 提出了基于多通道-祛伪影卷积神经网络的图像超分辨率重建 (Multi-Channel and Artifacts-Reduction Super-Resolution based on Convolutional Neural Network, MC-ARCNN) 算法, 旨在主观视觉和客观数据上都获得比原算法有更好的效果。</p>
                </div>
                <div class="p1">
                    <p id="46">本文采用改进型四层卷积神经网络结构来学习HR图像和LR图像之间端到端的映射。首先, 引入多通道输入概念<citation id="115" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 对输入的LR图像进行细节增强的预处理, 将多幅原始LR图像与处理后的细节增强图像成对组合, 作为多通道输入图像组, 有助于提取更好的图像特征, 增强输出HR图像的细节信息;然后, 将高温高亮背景在图像处理过程中所产生的图像伪影现象, 类比于图像的压缩效应, 引入祛伪影算法<citation id="116" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 改进三层SRCNN结构, 在第一层与第二层之间, 加入一个祛伪影层, 去处理由第一个卷积层提取的含有因高光高亮背景引成的噪声特征空间。</p>
                </div>
                <div class="p1">
                    <p id="47">与传统的SRCNN、MC-SRCNN算法相比, 本文算法针对高温高亮的特殊信号背景, 在网络结构上加以优化, 并结合图像增强和去噪技术, 在保证重建图像纹理细节的同时, 有效抑制噪声的产生。</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag"><b>2 SRCNN算法的基本原理</b></h3>
                <div class="p1">
                    <p id="49">本文选取晶体生长过程中检测引晶温度时的熔体界面截图, 作为实验输入LR图像, 该图像背景纹路复杂, 具有代表性。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50"><b>2.1 SRCNN算法模型</b></h4>
                <div class="p1">
                    <p id="51">以单幅图像为例, SRCNN模型结构如图1所示。</p>
                </div>
                <div class="area_img" id="52">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904063_052.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图1 SRCNN模型结构示意图" src="Detail/GetImg?filename=images/JSJZ201904063_052.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图1 SRCNN模型结构示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904063_052.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="53">主要包含三个步骤:</p>
                </div>
                <div class="p1">
                    <p id="54"><b>1</b>) 输入图像块的特征提取:用训练过的一组基 (如<b>PCA, DCT, Haar</b>等) , 从输入的<b>LR</b>图像中提取图像块, 由一组高维向量表示, 并将这些向量组成一组特征图。第一层卷积层表示如下</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>max</mi><mo stretchy="false"> (</mo><mn>0</mn><mo>, </mo><mi>W</mi><msub><mrow></mrow><mn>1</mn></msub><mo>*</mo><mi>Y</mi><mo>+</mo><mi>B</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">式中, 选用<b>max (0, <i>W</i></b><sub><b>1</b></sub>*<b><i>Y</i>+<i>B</i></b><sub><b>1</b></sub>) 作为激励函数, <b><i>W</i></b><sub><b>1</b></sub>为滤波器, <b><i>B</i></b><sub><b>1</b></sub>为偏差, “*”号表示卷积操作, <b><i>W</i></b><sub><b>1</b></sub>的大小为<b><i>n</i></b><sub><b>1</b></sub>×<b><i>c</i>×<i>f</i></b><sub><b>1</b></sub>×<b><i>f</i></b><sub><b>1</b></sub>, 数量<b><i>n</i></b><sub><b>1</b></sub>与特征图个数保持一致, <b><i>c</i></b>是输入图像的通道数量, <b>SRCNN</b>模型中通道数值为<b>1, f</b><sub><b>1</b></sub>是滤波器尺寸。经过第一层卷积层后, 从<b>LR</b>图像中提取的每个图像块被表示为<b><i>n</i></b><sub><b>1</b></sub>维的特征图向量;</p>
                </div>
                <div class="p1">
                    <p id="57"><b>2</b>) 非线性映射:将首层处理后的<b><i>n</i></b><sub><b>1</b></sub>维特征图向量, 以非线性映射方式, 转化为<b><i>n</i></b><sub><b>2</b></sub>维特征向量。第二层卷积层表示如下</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false"> (</mo><mn>0</mn><mo>, </mo><mi>W</mi><msub><mrow></mrow><mn>2</mn></msub><mo>*</mo><mi>F</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">) </mo><mo>+</mo><mi>B</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">式中, <b><i>W</i></b><sub><b>2</b></sub>的大小为<b><i>n</i></b><sub><b>2</b></sub>×<b><i>n</i></b><sub><b>1</b></sub>×<b><i>f</i></b><sub><b>2</b></sub>×<b><i>f</i></b><sub><b>2</b></sub>;</p>
                </div>
                <div class="p1">
                    <p id="60"><b>3</b>) 图像重建:将卷积提取的<b><i>HR</i></b>特征块进行聚合, 以传统的叠加求平均的方法来产生最终的输出图。平均步骤可以由一个预先定义的滤波器来实现。最后的重建层表示如下</p>
                </div>
                <div class="p1">
                    <p id="61" class="code-formula">
                        <mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>W</mi><msub><mrow></mrow><mn>3</mn></msub><mo>*</mo><mi>F</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">) </mo><mo>+</mo><mi>B</mi><msub><mrow></mrow><mn>3</mn></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="62">式中, <b><i>W</i></b><sub><b>3</b></sub>的大小为<b><i>n</i></b><sub><b>2</b></sub>×<b><i>f</i></b><sub><b>3</b></sub>×<b><i>f</i></b><sub><b>3</b></sub>×<b><i>c</i>, <i>B</i></b><sub><b>3</b></sub>是维数为<b><i>c</i></b>的向量。</p>
                </div>
                <div class="p1">
                    <p id="63">由于整个网络都是卷积操作, 所以网络的输入、输出图像大小是一致的。</p>
                </div>
                <h3 id="64" name="64" class="anchor-tag"><b>3 基于MC-ARCNN算法的熔体图像重建</b></h3>
                <div class="p1">
                    <p id="65">本文针对高温高亮成像环境导致的图像降质问题, 引入多通道输入以增强输出图像的细节信息, 并改进卷积神经网络结构, 以减弱高亮产生的图像伪影现象。</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66"><b>3.1 MC-ARCNN的模型结构</b></h4>
                <div class="p1">
                    <p id="67">本文在<b><i>SRCNN</i></b>的模型基础上, 引入多通道输入以增强输出图像的细节信息;祛伪影网络结构的增加, 以减弱高温高亮背景在图像处理过程中产生的伪影现象。<b><i>MC</i>-<i>ARCNN</i></b>的模型结构如图<b>2</b>所示。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904063_068.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图2 MC-ARCNN模型结构示意图" src="Detail/GetImg?filename=images/JSJZ201904063_068.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图2 MC-ARCNN模型结构示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904063_068.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="69" name="69"><b>3.1.1</b> 多通道输入图像组的形成</h4>
                <div class="p1">
                    <p id="70">本文首先使用通过五种不同的强度值 (<b>Amount=0.4, 0.8, 1.2, 1.6, 2</b>) 对<b>LR</b>图像进行锐化, 利用<b>MATLAB</b>的内建函数以及‘<b>Amount</b>′参数进行设置;然后, 将锐化后的<b>LR</b>图像与原始<b>LR</b>图像一一配对, 构成多通道输入图像组如图<b>3</b>所示。</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904063_071.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图3 原始低分辨输入图像及其不同程度的锐化图集" src="Detail/GetImg?filename=images/JSJZ201904063_071.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图3 原始低分辨输入图像及其不同程度的锐化图集</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904063_071.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="72">在<b>SRCNN</b>结构中, 图<b>3</b>所示单幅<b>LR</b>图像的细节纹理模糊, 缺少高频信息成份。因此, <b>SRCNN</b>是利用缺少高频成份的<b>LR</b>图像去重构高频成份。作为对比, <b>MC-SRCNN</b>利用了高频成份加强的多通道图像组作为输入, 则会更好地恢复图像的高频信息。通过图<b>3</b>的局部细节放大图可以看出, 锐化后的图像在增强图像纹理信息的同时, 也不可避免地增强了由于炉内高温高亮背景带来的噪声点集与阴影集, 形成噪声块及伪影现象, 将会影响最终超分辨重建图像的效果。所以, 需要减弱伪影现象的干扰。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73"><b>3.1.2</b> 祛伪影结构的建立</h4>
                <div class="p1">
                    <p id="74">采集图像中因高温高亮背景在图像增强过程中导致的伪影现象, 使得<b>SRCNN</b>模型在特征提取时, 提取到具有噪声和模糊的特征图。针对此问题, 本文在<b>SRCNN</b>模型的特征提取层 (第一层) 之后, 引入祛伪影层, 构成新的模型结构<b>ARCNN</b>。祛伪影层的作用是将第一层的‘<b>noisy</b>’特征映射到‘<b>cleaner</b>’特征空间, 等同于去噪的特征映射。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>3.2 MC-ARCNN的模型公式</b></h4>
                <div class="p1">
                    <p id="76">在<b>MC-ARCNN</b>模型结构中, 除了新加入的祛伪影层, 其余三层与<b>SRCNN</b>结构保持不变。因此, <b>MC-ARCNN</b>模型结构共包含<b>4</b>层, 分别是特征提取层、祛伪影层、映射层和重建层。<b>MC-ARCNN</b>模型结构可由以下公式表示:</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>F</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false"> (</mo><mi>Y</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mo>=</mo><mi>Y</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">) </mo></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>F</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>R</mi><mi>e</mi><mspace width="0.25em" /><mi>L</mi><mi>U</mi><mo stretchy="false"> (</mo><mi>W</mi><msub><mrow></mrow><mi>i</mi></msub><mo>*</mo><mi>Y</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>B</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>, </mo><mi>i</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mn>3</mn><mo stretchy="false">}</mo><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>F</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>W</mi><msub><mrow></mrow><mn>4</mn></msub><mo>*</mo><mi>F</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">) </mo><mo>+</mo><mi>B</mi><msub><mrow></mrow><mn>4</mn></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">其中, <b><i>Y</i></b><sup> (<b><i>n</i></b>) </sup>表示多通道输入图像组, <b><i>W</i></b><sub><b><i>i</i></b></sub>和<b><i>B</i></b><sub><b><i>i</i></b></sub>分别代表第<b><i>i</i></b>层的滤波器和偏移, <b><i>F</i></b><sub><b><i>i</i></b></sub>是输出的特征向量组;第二层 (<b><i>W</i></b><sub><b>2</b></sub>, <b><i>B</i></b><sub><b>2</b></sub>) , 是添加的祛伪影层。</p>
                </div>
                <h3 id="79" name="79" class="anchor-tag"><b>4 实验结果与分析</b></h3>
                <h4 class="anchor-tag" id="80" name="80"><b>4.1 实验参数选择</b></h4>
                <div class="p1">
                    <p id="81">对于<b><i>MC</i>-<i>SRCNN</i></b>模型训练参数, 本文设置其通道数为<b>N</b><mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>D</mi><mrow><mo stretchy="false"> (</mo><mn>0</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>=<b>10, N</b><mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>D</mi><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>=<b>64, N</b><mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>D</mi><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>=<b>32, N</b><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>D</mi><mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>=<b>16, N</b><mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>D</mi><mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>=<b>1</b>;滤波器大小<b>f</b><sub><b>1</b></sub>=<b>9, f</b><sub><b>2</b></sub>=<b>7, f</b><sub><b>3</b></sub>=<b>1, f</b><sub><b>4</b></sub>=<b>5</b>;迭代<b>2.5×10</b><sup><b>5</b></sup>次。</p>
                </div>
                <div class="p1">
                    <p id="87">本文中使用的实验图例, 是从晶体生长过程中处于该状态的一段视频里随机获取的, 图样本身纹路复杂, 具有代表性。对于实验的客观数据评价, 本文抽取各引晶状态视频中的<b>100</b>帧状态样图进行运算, 得出均值结果。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88"><b>4.2 综合性能量化评价</b></h4>
                <div class="p1">
                    <p id="89">由于本文的原始图像为降质图像, 所以采用<b>Brenner</b>梯度函数<citation id="117" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>和熵函数<citation id="118" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>两个无参考模型量化指标来客观评价重建图像的清晰度和信息量, 其定义如下</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>B</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>y</mi></msub><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mi>x</mi></msub><mrow><mrow><mo>|</mo><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mn>2</mn><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow></mstyle></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>E</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>ln</mi><mo stretchy="false"> (</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">式中, <b>f (x, y</b>) 表示图像<b>f</b>对应像素点 (<b>x, y</b>) 的灰度值, <b>B (f</b>) 为图像清晰度的计算结果, 计算相邻两个像素灰度差的平方, 计算结果值越大, 代表重建图像成像质量越高;<b>p</b><sub><b>i</b></sub>表示图像中灰度值为<b>i</b>的像素出现的概率, <b>L</b>为灰度级总数 (通常取值<b>256) , E (f</b>) 为图像信息量的计算结果, 根据<b>Shannon</b>定理, 熵值越大, 代表重建图像包含的信息量越多。</p>
                </div>
                <div class="p1">
                    <p id="92">本文首先对熔体界面寻找引晶温度阶段的随机样图分别进行<b>SRCNN、MC-SRCNN</b><citation id="119" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、<b>MC-ARCNN</b>处理, 如图<b>4</b>所示, 其中右下角框内图像表示各图中黑框区域的二倍局部放大图。通过图<b>4</b>仿真结果可以看出, 原始<b>LR</b>图像的局部放大区域纹路信息平滑、清晰度较低, 整体图像信息的平面感强、层次感低, 不易于辨别熔体界面的波动状态;基础的<b>SRCNN</b>方法重建后的图像, 一定程度上增强了图像的清晰度与细节信息, 但用于熔体界面状态的判断, 效果仍不理想;<b>MC-SRCNN</b>方法, 由于锐化方法的引入, 在增强图像细节纹路信息的同时, 不可避免地引入了噪声点集与伪影集, 不利于熔体状态的判断;本文提出的<b>MC-ARCNN</b>算法, 在<b>MC-SRCNN</b>的基础上, 减弱了图像伪影对状态识别的干扰, 不仅在细节上更丰富, 也使重建图像更具层次感, 更利于判断熔体界面的状态。</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904063_093.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图4 引晶前样图及SRCNN、MC-SRCNN、MC-ARCNN处理结果对比图" src="Detail/GetImg?filename=images/JSJZ201904063_093.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图4 引晶前样图及SRCNN、MC-SRCNN、MC-ARCNN处理结果对比图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904063_093.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="94">对该理想状态视频中的<b>100</b>帧样图进行<b>Brenner</b>梯度函数、熵函数的指标测试, 均值结果如表<b>1</b>所示。以原始引晶前样图作为输入, 分别计算原始样图及其<b>SRCNN、MC-SRCNN、MC-ARCNN</b>的<b>Brnner</b>和<b>Entropy</b>, 再将<b>100</b>帧数据求和取均值, 由数据结果可知, <b>Brenner</b>梯度函数计算结果<b>MC-ARCNN &gt; MC-SRCNN &gt; SRCNN &gt;Original LR, Entropy</b>计算结果排序与<b>Brenner</b>相同, 说明改进型的<b>MC-ARCNN</b>算法重建图像具有更高的清晰度和更大的信息量, 在客观评价中具有更优异的性能表现。</p>
                </div>
                <div class="area_img" id="95">
                    <p class="img_tit"><b>表1 引晶前重建图像 (100帧) 的均值Brenner函数、熵函数计算</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="95" border="1"><tr><td><br /></td><td>Original LR</td><td>SRCNN</td><td>MC-SRCNN</td><td>MC-ARCNN</td></tr><tr><td><br />Brenner</td><td>873.5</td><td>1165.3</td><td>1816.4</td><td>2200.5</td></tr><tr><td><br />Entropy</td><td>5.845</td><td>5.924</td><td>6.095</td><td>6.124</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="96">最后, 本文增加熔体界面的四种典型状态随机样图进行MC-ARCNN处理, 处理结果如图5 (a) - (d) 所示, 分别代表下降籽晶、开始引晶、晶体生长和生长完毕四种状态, 各状态100帧样图的平均Brenner、Entropy值分别由表2、表3给出。仿真结果表明, MC-ARCNN算法使增强了图像的细节纹理, 使图像具有层次感, 提高了图像的成像质量, 利于判断熔体界面状态。</p>
                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904063_097.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图5 四种典型状态样图的重建结果" src="Detail/GetImg?filename=images/JSJZ201904063_097.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图5 四种典型状态样图的重建结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904063_097.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="98">进行数据分析, 表<b>2</b>中<b>MC-ARCNN</b>的平均<b>Brenner</b>和<b>Entropy</b>值皆为各类测试结果中最高, 客观说明<b>MC-ARCNN</b>的重建结果具有更高的清晰度和更大的信息量, 性能表现更好。</p>
                </div>
                <div class="area_img" id="99">
                    <p class="img_tit"><b>表2 四种典型状态样图重建图像的均值Brenner函数计算结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="99" border="1"><tr><td><br /></td><td>Original</td><td>SRCNN</td><td>MC-SRCNN</td><td>MC-ARCNN</td></tr><tr><td><br />下降籽晶</td><td>689.3</td><td>812.4</td><td>1073.9</td><td>1408.1</td></tr><tr><td><br />开始引晶</td><td>818.2</td><td>910.4</td><td>1325.4</td><td>1648.3</td></tr><tr><td><br />晶体生长</td><td>738.9</td><td>985.2</td><td>1692.9</td><td>1960.8</td></tr><tr><td><br />生长完毕</td><td>852.1</td><td>1021.8</td><td>1764.6</td><td>2169.3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="100">
                    <p class="img_tit"><b>表3 四种典型状态样图重建图像的均值熵函数计算结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="100" border="1"><tr><td><br /></td><td>Original</td><td>SRCNN</td><td>MC-SRCNN</td><td>MC-ARCNN</td></tr><tr><td><br />下降籽晶</td><td>5.356</td><td>5.472</td><td>5.631</td><td>5.673</td></tr><tr><td><br />开始引晶</td><td>4.878</td><td>4.927</td><td>5.175</td><td>5.250</td></tr><tr><td><br />晶体生长</td><td>4.397</td><td>4.449</td><td>4.657</td><td>4.762</td></tr><tr><td><br />生长完毕</td><td>4.783</td><td>4.861</td><td>5.013</td><td>5.188</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="101" name="101" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="102">本文提出了一种基于多通道-祛伪影卷积神经网络的图像超分辨率重建算法。利用多通道输入以增强重建图像的细节信息;加入祛伪影层以减弱高亮背景在图像增强过程中引起的伪影现象, 对SRCNN算法进行改进, 弥补了SRCNN算法对于高温高亮背景图像复原保真度较低的问题。实验结果表明:①针对晶体生长熔体状态图像测试集, 本文提出的算法比SRCNN算法的重建图像质量更高, 对细节信息的复原效果更强, 噪声抑制更明显;②针对晶体生长熔体状态视频测试集, 本文算法的重建结果在客观评价指标测试中, 梯度函数均值结果比原始图像增加100%～190%, 熵函数均值结果比原始图像增加了0.28～0.40, 皆为同组LR、SRCNN、MC-SRCNN中最高, 客观性能表现最佳。</p>
                </div>
                <div class="area_img" id="120">
                                <img alt="" src="Detail/GetImg?filename=images/JSJZ201904063_12000.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                            <p class="img_tit"></p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RGJT200804025&amp;v=MzAzMTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXpoVnJ2T055ckJlckc0SHRuTXE0OUhZWVE=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[1]</b> 李真, 陈振强, 陈宝东.泡生法高质量蓝宝石晶体的研究[J].人工晶体学报, 2008, 37 (4) :877-880.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBX201103031&amp;v=MTM2ODZHNEg5RE1ySTlHWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6aFZydk9MU2pKZHI=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[2]</b> 刘丽君, 徐家庆, 蔡兴民.泡生法蓝宝石晶体生长工艺的探讨[J].哈尔滨工业大学学报, 2011, 43 (3) :145-148.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RGJT2012S1042&amp;v=MTYwMTh2T055ckJlckc0SDlPdnJvOUJab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXpoVnI=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[3]</b> 李留臣, 冯金生.我国蓝宝石晶体生长技术的现状与发展趋势[J].人工晶体学报, 2012, 41 (1) :221-226.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GGYT201421115&amp;v=MjEwMTdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emhWcnZPSWlyU2VyRzRIOVhPcm81RVk=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[4]</b> 周林, 杨鹏.蓝宝石材料的性能和应用研究[J].硅谷, 2014, 7 (21) :139-140.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Diffraction and resolving power">

                                <b>[5]</b> J L HARRIS.Diffraction and resolving power[J].JOSA, 1964, 54 (7) :931-933.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multipleframe image restoration and registration">

                                <b>[6]</b> R Y TSAI.Multiframe image restoration and registration[J].Adv.Comput.Vis.Image Process., JAI Press Inc, 1984, 1 (2) :317-339.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201308005&amp;v=MTgwODBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emhWcnZPS0NMZlliRzRIOUxNcDQ5RllZUUs=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[7]</b> H SU, J ZHOU, Z H ZHANG.Survey of super-resolution image reconstruction methods[J].Acta Automatica Sinica, 2013, 39 (8) :1202-1213.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interpolation-Based Image Super-Resolution Using Multisurface Fitting">

                                <b>[8]</b> F ZHOU, W YANG, Q LIAO.Interpolation-based image super-resolution using multisurface fitting[J].IEEE Transactions on Image Processing, 2012, 21 (7) :3312-3318.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fundamental Limits of Reconstruction-Base Superresolution Algorithms under Local Translation">

                                <b>[9]</b> Z LIN, H Y SHUM.Fundamental limits of reconstruction-based superresolution algorithms under local translation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26 (1) :83-97.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201404003&amp;v=MjY3ODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6aFZydk9LQ0xmWWJHNEg5WE1xNDlGWjRRS0RIODQ=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[10]</b> 潘宗序, 等.基于多尺度结构自相似性的单幅图像超分辨率算法[J].自动化学报, 2014, 40 (4) :594-603.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image super-resolution using deep convolutional networks">

                                <b>[11]</b> C DONG, et al.Image super-resolution using deep convolutional networks[J].IEEE transactions on pattern analysis and machine intelligence, 2016, 38 (2) :295-307.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accurate image super-resolution using very deep convolutional networks">

                                <b>[12]</b> J KIM, L J KWON, L K MU.Accurate image super-resolution using very deep convolutional networks[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, 2016:1646-1654.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Perceptual losses for real-time style transfer and super-resolution">

                                <b>[13]</b> J JOHNSON, A ALAHI, F F LI.Perceptual Losses for Real-Time Style Transfer and Super-Resolution[J].ECCV, 2016:694-711.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Enhanced Deep Residual Networks for Single Image Super-Resolution">

                                <b>[14]</b> B LIM, et al.Enhanced deep residual networks for single image super-resolution[C].The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops.2017, 1 (2) :3.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image super-resolution based on convolution neural networks using multi-channel input">

                                <b>[15]</b> G Y YOUM, S H BAE, M KIM.Image super-resolution based on convolution neural networks using multi-channel input[C].Image, Video, and Multidimensional Signal Processing Workshop.IEEE, Bordeaux, 2016:1-5.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Compression artifacts reduction by a deep convolutional network &amp;quot;">

                                <b>[16]</b> C DONG, et al.Compression artifacts reduction by a deep convolutional network[C].Proceedings of the IEEE International Conference on Computer Vision, Santiago, 2015:576-584.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Simple and robust image-based autofocusing for digital microscopy">

                                <b>[17]</b> S Yazdanfar, et al.Simple and robust image-based autofocusing for digital microscopy[J].Optics express, 2008, 16, (12) :8670-8677.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Entropy: a new definition and its applications">

                                <b>[18]</b> N R Pal, S K Pal.Entropy:A new definition and its applications[J].IEEE transactions on systems, man, and cybernetics, 1991, 21 (5) :1260-1270.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201904063" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201904063&amp;v=MjQzNjRkTEc0SDlqTXE0OURaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXpoVnJ2UEx6N0I=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
