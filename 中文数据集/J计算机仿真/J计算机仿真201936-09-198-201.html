<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139882561353750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201909040%26RESULT%3d1%26SIGN%3dJWsx0DRBL4BUNw%252bcYApBleqpEKw%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201909040&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201909040&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201909040&amp;v=MDAzMTQ5QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmtWTHJJTHo3QmRMRzRIOWpNcG8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#23" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;2 虚拟现实的声场合成信息采集建模原理&lt;/b&gt; "><b>2 虚拟现实的声场合成信息采集建模原理</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#50" data-title="&lt;b&gt;3 虚拟现实的声场合成信息采集建模方法&lt;/b&gt; "><b>3 虚拟现实的声场合成信息采集建模方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="&lt;b&gt;3.1 基于MEMS和HRIR的声场合成信息采集&lt;/b&gt;"><b>3.1 基于MEMS和HRIR的声场合成信息采集</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;3.2 声场合成信息采集结果处理&lt;/b&gt;"><b>3.2 声场合成信息采集结果处理</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#89" data-title="&lt;b&gt;4 实验结果与分析&lt;/b&gt; "><b>4 实验结果与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#99" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#94" data-title="&lt;b&gt;图1 不同方法所得结果与实际情况拟合程度&lt;/b&gt;"><b>图1 不同方法所得结果与实际情况拟合程度</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;表1 不同方法信息采集耗时对比&lt;/b&gt;"><b>表1 不同方法信息采集耗时对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 常广晖,陈志敏.一种循环平稳声场的声源识别定位方法[&lt;i&gt;J&lt;/i&gt;].海军工程大学学报,2016,28(5):75-79." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HJGX201605016&amp;v=MDg4OTNvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeW5rVkxySUxTZk1kckc0SDlmTXE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         常广晖,陈志敏.一种循环平稳声场的声源识别定位方法[&lt;i&gt;J&lt;/i&gt;].海军工程大学学报,2016,28(5):75-79.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 胡珍,等.水下掩埋目标的散射声场计算与实验[&lt;i&gt;J&lt;/i&gt;].物理学报,2016 65(6):170-177." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WLXB201606023&amp;v=MTIwOTJPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmtWTHJJTWlIVGJMRzRIOWZNcVk5SFo0UUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         胡珍,等.水下掩埋目标的散射声场计算与实验[&lt;i&gt;J&lt;/i&gt;].物理学报,2016 65(6):170-177.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 胡代弟,董素鸽.远程实验信息数据采集方法研究仿真[&lt;i&gt;J&lt;/i&gt;].计算机仿真,2017,34(4):186-189." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201704039&amp;v=MTI4MjNVUjdxZlp1Wm9GeW5rVkxySUx6N0JkTEc0SDliTXE0OUdiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         胡代弟,董素鸽.远程实验信息数据采集方法研究仿真[&lt;i&gt;J&lt;/i&gt;].计算机仿真,2017,34(4):186-189.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 于晓林,等.一种基于波数积分方法的线源声场计算方法[&lt;i&gt;J&lt;/i&gt;].声学技术,2017,36(5):415-422." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SXJS201705004&amp;v=MzIzMDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlua1ZMcklOalhCZmJHNEg5Yk1xbzlGWUlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         于晓林,等.一种基于波数积分方法的线源声场计算方法[&lt;i&gt;J&lt;/i&gt;].声学技术,2017,36(5):415-422.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 邓英,陈浩,于其蛟.井孔中多极源在分层介质中的声场模拟方法[&lt;i&gt;J&lt;/i&gt;].应用声学,2017,36(6):555-558." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YYSN201706014&amp;v=Mjk0MDJUWVlMRzRIOWJNcVk5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmtWTHJJUEQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         邓英,陈浩,于其蛟.井孔中多极源在分层介质中的声场模拟方法[&lt;i&gt;J&lt;/i&gt;].应用声学,2017,36(6):555-558.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 于群,等.聚焦换能器声强和声功率测量方法研究[&lt;i&gt;J&lt;/i&gt;].中国测试,2017,43(1):27-32." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYCS201701006&amp;v=MTc3MDc0SDliTXJvOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeW5rVkxySU5qVElmYkc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         于群,等.聚焦换能器声强和声功率测量方法研究[&lt;i&gt;J&lt;/i&gt;].中国测试,2017,43(1):27-32.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 宁少武,史治宇.夹层结构中夹层声场的处理方法研究[&lt;i&gt;J&lt;/i&gt;].振动与冲击,2016,35(23):160-167." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDCJ201623025&amp;v=MTkzODNJWkxHNEg5Zk9ySTlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlua1ZMcklQeW4=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         宁少武,史治宇.夹层结构中夹层声场的处理方法研究[&lt;i&gt;J&lt;/i&gt;].振动与冲击,2016,35(23):160-167.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 俞孟萨,庞业珍.舰船辐射声场及声源特性测量方法研究综述[&lt;i&gt;J&lt;/i&gt;].船舶力学,2017,21(1):107-126." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CBLX201701013&amp;v=MjE1NzlHRnJDVVI3cWZadVpvRnlua1ZMcklKaS9IZHJHNEg5Yk1ybzlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         俞孟萨,庞业珍.舰船辐射声场及声源特性测量方法研究综述[&lt;i&gt;J&lt;/i&gt;].船舶力学,2017,21(1):107-126.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 闫秀丽,等.阶梯盘超声辐射声场指向性研究[&lt;i&gt;J&lt;/i&gt;].机械科学与技术,2017,36(10):1570-1574." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXKX201710014&amp;v=MjY1ODNBZHJHNEg5Yk5yNDlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlua1ZMcklMelg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         闫秀丽,等.阶梯盘超声辐射声场指向性研究[&lt;i&gt;J&lt;/i&gt;].机械科学与技术,2017,36(10):1570-1574.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 郭莹,闫美辰.基于镜像源方法的室内声场脉冲响应仿真[&lt;i&gt;J&lt;/i&gt;].沈阳工业大学学报,2017,39(1):55-60." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYGY201701011&amp;v=MjQ0NTdCdEdGckNVUjdxZlp1Wm9GeW5rVkxySU5qVE1kN0c0SDliTXJvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         郭莹,闫美辰.基于镜像源方法的室内声场脉冲响应仿真[&lt;i&gt;J&lt;/i&gt;].沈阳工业大学学报,2017,39(1):55-60.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(09),198-201             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>虚拟现实的声场合成信息采集建模仿真分析</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%9C%8D%E8%89%BA%E6%96%87&amp;code=42868441&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">霍艺文</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E6%AD%A6&amp;code=16874395&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐武</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E9%80%B8%E7%90%B3&amp;code=41584451&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李逸琳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%B6%E9%9D%99&amp;code=41584452&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陶静</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BA%91%E5%8D%97%E6%B0%91%E6%97%8F%E5%A4%A7%E5%AD%A6%E7%94%B5%E6%B0%94%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0068064&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">云南民族大学电气信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>目前声场合成信息采集方法存在采集结果与实际结果拟合程度低、采集耗时长的问题,提出基于MEMS和HRIR的虚拟现实声场合成信息采集建模方法。通过麦克风阵列体系得到声场原始信号,并利用欧拉角多数据融合获取人头部姿态信息。根据所得信息计算HRTF函数值,对函数值进行傅里叶变换,得到新生成的声音信号数据,对新生成的信号进行傅里叶逆变换,获得虚拟现实声场合成信息采集结果。利用最小方差模态滤波器能够高效消除期望模态之外模态的能力,结合声场各阶简正波加权系数,获取声场合成信息采集结果滤波后向量值。仿真结果表明,基于MEMS和HRIR的虚拟现实声场合成信息采集建模方法所得结果与实际结果拟合程度高,且信息采集耗时短。上述方法整体运行效率高,声场合成信息采集性能高。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%99%9A%E6%8B%9F%E7%8E%B0%E5%AE%9E&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">虚拟现实;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A3%B0%E5%9C%BA%E5%90%88%E6%88%90%E4%BF%A1%E6%81%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">声场合成信息;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%87%87%E9%9B%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">采集;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    霍艺文(1994-)，女(汉族)，山东滨州人，硕士研究生，研究方向:虚拟现实与智能算法研究;;
                                </span>
                                <span>
                                    *徐武(1974-)，男(汉族)，新疆克拉玛依人，硕士研究生，教授，研究方向:虚拟现实技术(通讯作者);;
                                </span>
                                <span>
                                    李逸琳(1993-)，女(汉族)，河北省石家庄市人，硕士研究生，研究方向:虚拟现实技术;;
                                </span>
                                <span>
                                    陶静(1994-)，女(汉族)，江苏省盐城市人，硕士研究生，研究方向:虚拟现实技术。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-05-02</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助(GRANT:61741206);</span>
                    </p>
            </div>
                    <h1><b>Virtual Reality Sound Field Synthesis Information Acquisition Modeling Simulation Analysis</b></h1>
                    <h2>
                    <span>HUO Yi-wen</span>
                    <span>XU Wu</span>
                    <span>Li Yi-lin</span>
                    <span>Tao Jing</span>
            </h2>
                    <h2>
                    <span>School of Electrical and Information Technolgy, Yunnan Minzu University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>This paper put forward a method for modeling and collecting virtual reality sound field synthesis information based on MEMS and HRIR. First of all, we obtained the original signal of sound field through microphone array system, and then used the multiple data fusion of Eulerian angle to obtain information of human head posture. Secondly, we calculated HRTF function value based on the obtained information and performed Fourier transform on the function value to obtain the new sound signal data. Moreover, we performed the inverse Fourier transform on the new signal to obtain the collection result of virtual reality sound field synthesis information. Through the minimum variance modal filter, we could efficiently eliminate the ability of modality except the excepted modality. Combined with the normal mode weighting coefficient of each order of sound field, we got the vector value after filtering the collection result of sound field synthesis information. Simulation results show that the result obtained by a method for modeling and collecting virtual reality sound field synthesis information based on MEMS and HRIR has high fitting degree with the actual result. The information acquisition usually takes a short time. The overall running efficiency of proposed method is high. Meanwhile, the performance of sound field synthesis information collection is high.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Virtual%20reality&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Virtual reality;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Sound%20field%20synthesis%20information&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Sound field synthesis information;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Collection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Collection;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-05-02</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="23" name="23" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="24">虚拟现实技术,即VR技术是当前最受关注的高端科技之一<citation id="116" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。该技术早在航空航天、教育以及影音娱乐等众多领域予以应用,其凭借自身的代入感与身临其境的体验感为目前相关产业带来了很大的便利以及新的发展机会,其中,沉浸感是它的核心<citation id="117" type="reference"><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。要对声场合成信息进行高精度地采集,才能更好地将虚拟现实的沉浸感呈现给大众。当前基于LabVIEW的声场合成信息采集建模方法,在声场全息重构分析下,通过LabVIEW软件平台,使用传声器阵列标定标准和数据采集等重构辅助方法完成声场信息采集模型的构建。该方法采集到的声场合成信息与实际情况吻合度较低。鉴于声场合成信息采集的现实意义,使得该方面的研究方法层出不穷。以下为当前运行较为广泛的一些方法。</p>
                </div>
                <div class="p1">
                    <p id="25">于晓林<citation id="118" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等人提出基于波数积分的声场信息采集方法。利用对深度格林函数的上行波以及下行波进行归一化,获取稳定性较高的系数矩阵,以得到格林函数解析值。模拟并展开深度格林函数,以此验证深度格林函数解析结果的精准性。与仿真实例相结合,所提方法获取的波数积分模型以及传统模型所得结果比较,实验结果表明,该方法所得结果与传统模型具有一定的拟合程度,但采集过程耗时较长。邓英<citation id="119" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等人提出基于多极源的声场信息采集方法。该方法针对水平层地质中声波的传播规律,提出能够动态获取研究区域信息的方式,以保障模拟结果有效性的情况下得到的计算区域最小。实验结果表明,该方法时效性较强,但计算结果与实际信息相符程度较低。于群<citation id="120" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等人提出基于近场测量的声场信息采集方法。利用声场测量体系对聚焦换能器的预聚焦区域中声压进行扫描测量,通过声强法获取聚焦换能器声强分布规律和辐射声功率。根据远场测量法以及近场测量法之间的比对,获取的声功率误差要低于12%。总体结果表明,该方法能够高效避免对测量设备的破坏,但测量结果与实际情况的拟合程度较低。</p>
                </div>
                <div class="p1">
                    <p id="26">依据上述分析,当前声场信息采集方法普遍存在采集结果与实际结果拟合程度低、采集过程存在延迟的问题,提出基于MEMS和HRIR的虚拟现实声场合成信息采集建模方法,以高效解决当前方法存在的问题。</p>
                </div>
                <h3 id="27" name="27" class="anchor-tag"><b>2 虚拟现实的声场合成信息采集建模原理</b></h3>
                <div class="p1">
                    <p id="28">在虚拟现实的声场合成信息采集建模原理中,首先采用傅里叶变换实现声场合成波函数的转换,然后依据转换结果计算声场合成波中的一个采集点至声场波信息的发射焦点之间的相位差,并利用相位差值获取发射声场信息和接收声场信息,最后基于所得信息获取虚拟现实的声场合成信息最终采集结果。详细步骤如下所示:</p>
                </div>
                <div class="p1">
                    <p id="29">利用傅里叶变换对声场合成波函数进行重新定义:将其表示为很多单频波叠加的状态。其中,声场合成波函数表达式为</p>
                </div>
                <div class="p1">
                    <p id="30"><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>x</mi></mstyle><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo>⋅</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mfrac><mrow><mn>2</mn><mi>π</mi></mrow><mi>Ν</mi></mfrac><mo stretchy="false">(</mo><mi>n</mi><mo>-</mo><mn>1</mn><mo stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mi>k</mi><mo>-</mo><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="31">式(1)中,<i>X</i>(<i>k</i>)代表声场合成波函数值,<i>N</i>代表声场合成信息数量,<i>n</i>代表声场合成信息时间序列数量,<i>x</i>(<i>n</i>)代表声场合成信息时间序列,<i>k</i>代表声场脉冲波函数中元素数量。</p>
                </div>
                <div class="p1">
                    <p id="32">对式(1)中的<i>x</i>(<i>n</i>)进行傅里叶变换</p>
                </div>
                <div class="p1">
                    <p id="33"><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><mi>X</mi><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo><mo>/</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><mo>/</mo><mn>2</mn></mrow></munderover><mrow><mrow><mo>[</mo><mrow><mi>cos</mi><mrow><mo>(</mo><mrow><mfrac><mrow><mn>2</mn><mi>π</mi><mo>⋅</mo><mi>k</mi></mrow><mrow><mi>Ν</mi><mo>⋅</mo><mi>d</mi><mi>t</mi></mrow></mfrac></mrow><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mstyle></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="34">式(2)中,<i>dt</i>代表声场合成波两点之间的时间间隔。</p>
                </div>
                <div class="p1">
                    <p id="35">假设<i>i</i>代表阵元,<i>A</i>(<i>x</i>,<i>y</i>)代表声场合成波中的一个采集点,<i>F</i><sub>1</sub>(0,<i>F</i><sub>1</sub>)代表声场波信息的发射焦点。其中,<i>A</i>(<i>x</i>,<i>y</i>)至<i>F</i><sub>1</sub>(0,<i>F</i><sub>1</sub>)的延迟为<i>Δt</i><sub><i>i</i></sub><sub>1</sub>,那么两者之间的相位差表达式为</p>
                </div>
                <div class="p1">
                    <p id="36"><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Δ</mi><mi>φ</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mi>π</mi><mo>⋅</mo><mi>k</mi></mrow><mrow><mi>Ν</mi><mo>⋅</mo><mi>d</mi><mi>t</mi></mrow></mfrac><mo>⋅</mo><mi>x</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (3)</p>
                </div>
                <div class="p1">
                    <p id="37">式(3)中,<i>Δφ</i><sub><i>i</i></sub><sub>1</sub>代表<i>A</i>(<i>x</i>,<i>y</i>)至<i>F</i><sub>1</sub>(0,<i>F</i><sub>1</sub>)两者之间的相位差。</p>
                </div>
                <div class="p1">
                    <p id="38">利用式(3)得到<i>x</i>(<i>n</i>)的<i>k</i>次谐波发射声场信息可表示为</p>
                </div>
                <div class="p1">
                    <p id="39"><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>k</mi><mo>,</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>(</mo><mrow><mfrac><mrow><mi>cos</mi><mi>Δ</mi><mi>φ</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>+</mo><mi>sin</mi><mi>Δ</mi><mi>φ</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub></mrow><mrow><mn>2</mn><mi>Ν</mi></mrow></mfrac></mrow><mo>)</mo></mrow></mrow></math></mathml>      (4)</p>
                </div>
                <div class="p1">
                    <p id="40">依据同样的方式能够得到接收声场信息</p>
                </div>
                <div class="p1">
                    <p id="41"><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>k</mi><mo>,</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>(</mo><mrow><mfrac><mrow><mi>cos</mi><mi>Δ</mi><mi>φ</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>+</mo><mi>sin</mi><mi>Δ</mi><mi>φ</mi><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub></mrow><mi>S</mi></mfrac></mrow><mo>)</mo></mrow></mrow></math></mathml>      (5)</p>
                </div>
                <div class="p1">
                    <p id="42">式(5)中,声场面积<i>S</i>的表达式为</p>
                </div>
                <div class="p1">
                    <p id="43"><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mi>Ν</mi></mrow><mi>Ν</mi></munderover><mi>A</mi></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (6)</p>
                </div>
                <div class="p1">
                    <p id="44">式(6)中,<i>A</i>(<i>i</i>)代表幅度加权函数值,如果<i>A</i>(<i>i</i>)=1,那么接收声场不加权;反之,接收声场实行幅度加权操作。</p>
                </div>
                <div class="p1">
                    <p id="45">因为声场合成波信息能够表示为很多单频波相互叠加的形式,由此虚拟现实的声场合成信息即为各单频波生成的声场相互叠加而成<citation id="121" type="reference"><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>。综上,将全部<i>d</i><sub>1</sub>(<i>k</i>,<i>x</i>)相加,则可获取总发射声场<i>D</i><sub>1</sub>(<i>x</i>)。将全部<i>d</i><sub>2</sub>(<i>k</i>,<i>x</i>)相加,则可获取总接收声场<i>D</i><sub>2</sub>(<i>x</i>)。</p>
                </div>
                <div class="p1">
                    <p id="46"><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>Κ</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><mo>/</mo><mn>2</mn></mrow></munderover><mi>d</mi></mstyle><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>k</mi><mo>,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="47"><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>Κ</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><mo>/</mo><mn>2</mn></mrow></munderover><mi>d</mi></mstyle><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>k</mi><mo>,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (8)</p>
                </div>
                <div class="p1">
                    <p id="48">其中,式(8)所得计算结果即为虚拟现实的声场合成信息采集结果。</p>
                </div>
                <div class="p1">
                    <p id="49">在虚拟现实的声场合成信息采集建模原理中,未对声场合成信息采集结果进行滤波,导致该方法所得结果与实际信息相符程度较低,且耗时长。提出基于MEMS和HRIR的虚拟现实声场合成信息采集建模方法。</p>
                </div>
                <h3 id="50" name="50" class="anchor-tag"><b>3 虚拟现实的声场合成信息采集建模方法</b></h3>
                <h4 class="anchor-tag" id="51" name="51"><b>3.1 基于MEMS和HRIR的声场合成信息采集</b></h4>
                <div class="p1">
                    <p id="52">在进行虚拟现实的声场合成信息采集时,通过麦克风阵列体系得到声场原始信号,并利用欧拉角多数据融合获取人头部姿态信息。根据所得信息计算<i>HRTF</i>函数值,对函数值进行傅里叶变换,得到新生成的声音信号数据,对新生成的信号进行傅里叶逆变换,获得虚拟现实声场合成信息采集结果。实现过程如下所示:</p>
                </div>
                <div class="p1">
                    <p id="53">麦克风阵列为能够应用在语音处理中,并按照一定的排列规则进行排列的麦克风体系<citation id="122" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。该体系具备空间选择性的特征,能够对周围环境中存在的噪音进行一定程度上地抑制。在此,利用麦克风阵列对声场合成信息进行采集,并将采集结果定义为<i>x</i><sup>′</sup>,对<i>x</i><sup>′</sup>实行快速傅里叶变换,并将<i>x</i><sup>′</sup>从时域转换至频域中,由此获取的频域声音信号为</p>
                </div>
                <div class="p1">
                    <p id="54"><i>X</i><sup>′</sup>=<i>FFT</i>(<i>x</i><sup>′</sup>)      (9)</p>
                </div>
                <div class="p1">
                    <p id="55">式(9)中,<i>FFT</i>代表傅里叶变换函数。</p>
                </div>
                <div class="p1">
                    <p id="56">在获取频域声音信号的同时,利用MEMS对人头部姿态进行定位。以达到头随声动效果为目的,采用MEMS技术对人体头部倾斜以及方向等姿态参数进行测量。根据MEMS中的加速计对被测者的头部三个坐标轴静态加速度进行测量,也就是重力加速度于三个坐标轴上的分量。假设<i>g</i><sup>′</sup>代表重力加速度,<i>g</i><sup>′</sup><sub><i>x</i></sub><sup>′</sup>代表轴分量,<i>θ</i><sup>′</sup>代表坐标轴静态加速度方向和重力加速度方向间存在的角度。其中,<i>θ</i><sup>′</sup>计算公式为</p>
                </div>
                <div class="p1">
                    <p id="57"><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>θ</mi><msup><mrow></mrow><mo>´</mo></msup><mo>=</mo><mrow><mi>sin</mi></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo>(</mo><mrow><mfrac><mrow><mi>g</mi><msubsup><mrow></mrow><mrow><mi>x</mi><msup><mrow></mrow><mo>´</mo></msup></mrow><mo>´</mo></msubsup></mrow><mrow><mi>g</mi><msup><mrow></mrow><mo>´</mo></msup></mrow></mfrac></mrow><mo>)</mo></mrow></mrow></math></mathml>      (10)</p>
                </div>
                <div class="p1">
                    <p id="58">根据式(10),对欧拉角速率ϕ<sup>′</sup>和载体角速率<i>φ</i><sup>′</sup>进行计算</p>
                </div>
                <div class="p1">
                    <p id="59"><mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>ϕ</mtext><msup><mrow></mrow><mo>´</mo></msup><mo>=</mo><mo stretchy="false">(</mo><mover accent="true"><mi>ω</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>y</mi></msub><mrow><mi>sin</mi></mrow><mtext>ϕ</mtext><msup><mrow></mrow><mo>´</mo></msup><mo>+</mo><mover accent="true"><mi>ω</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>z</mi></msub><mrow><mi>cos</mi></mrow><mtext>ϕ</mtext><msup><mrow></mrow><mo>´</mo></msup><mo stretchy="false">)</mo><mrow><mi>tan</mi></mrow><mi>θ</mi><msup><mrow></mrow><mo>´</mo></msup><mo>+</mo><mover accent="true"><mi>ω</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>x</mi></msub></mrow></math></mathml>      (11)</p>
                </div>
                <div class="p1">
                    <p id="60"><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>φ</mi><msup><mrow></mrow><mo>´</mo></msup><mo>=</mo><mo stretchy="false">(</mo><mover accent="true"><mi>ω</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>y</mi></msub><mrow><mi>sin</mi></mrow><mtext>ϕ</mtext><msup><mrow></mrow><mo>´</mo></msup><mo>+</mo><mover accent="true"><mi>ω</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>z</mi></msub><mrow><mi>sin</mi></mrow><mi>θ</mi><msup><mrow></mrow><mo>´</mo></msup><mo stretchy="false">)</mo><mrow><mi>sec</mi></mrow><mi>θ</mi><msup><mrow></mrow><mo>´</mo></msup></mrow></math></mathml>      (12)</p>
                </div>
                <div class="p1">
                    <p id="61">根据上述计算可知,<mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><msup><mrow></mrow><mo>´</mo></msup><mo>=</mo><mo stretchy="false">[</mo><mover accent="true"><mi>ω</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>x</mi></msub><mo>,</mo><mover accent="true"><mi>ω</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>y</mi></msub><mo>,</mo><mover accent="true"><mi>ω</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>z</mi></msub><mo stretchy="false">]</mo></mrow></math></mathml>为三轴角速度,其为载体坐标系和参考坐标系间转换结果<i>M</i>至参考坐标系在进行积分时获取的观测量<i>z</i><sub><i>k</i></sub>=[<i>θ</i><sup>′</sup><sub><i>k</i></sub>,ϕ<sup>′</sup><sub><i>k</i></sub>,<i>φ</i><sup>′</sup><sub><i>k</i></sub>],其中,<i>z</i><sub><i>k</i></sub>可表示为</p>
                </div>
                <div class="p1">
                    <p id="62"><i>z</i><sub><i>k</i></sub>=∫<i>M</i>·<i>W</i><sup>′</sup><i>dt</i>      (13)</p>
                </div>
                <div class="p1">
                    <p id="63">假设,要利用<i>z</i><sub><i>k</i></sub>=[<i>θ</i><sup>′</sup><sub><i>k</i></sub>,ϕ<sup>′</sup><sub><i>k</i></sub>,<i>φ</i><sup>′</sup><sub><i>k</i></sub>]来表征偏转角、俯仰角与翻滚角,采用方向余弦法对其进行计算,则能够从中获取<i>θ</i><sup>′</sup><sub><i>k</i></sub>、ϕ<sup>′</sup><sub><i>k</i></sub>、<i>φ</i><sup>′</sup><sub><i>k</i></sub>,以此得到的头部姿态信息为(<i>θ</i><sup>′</sup>,ϕ<sup>′</sup>)。</p>
                </div>
                <div class="p1">
                    <p id="64">综合以上计算,利用HRTF函数模拟虚拟现实的全景声场,依据上述得到的头部姿态定位信息实现声场合成信息的采集。HRTF函数为声波频率与声源方位函数,其中主要包括声源定位信息,也就是波达方向。于自由场条件下,可将HRTF函数表示为:</p>
                </div>
                <div class="area_img" id="65">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201909040_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="67">式(14)中,<i>P</i><sup>′</sup><sub><i>L</i></sub>、<i>P</i><sup>′</sup><sub><i>R</i></sub>代表仰角是ϕ<sup>′</sup>,夹角是<i>θ</i><sup>′</sup>,人头部中心距离是<i>r</i><sup>′</sup>,频率是<i>a</i><sup>′</sup>的信号在被测对象耳膜周围的复数声压,<i>P</i><sup>′</sup><sub>0</sub>代表信号于自由声场内原人头中心处的复数声压。其中,<i>HRTF</i>函数值<i>H</i><sup>′</sup>=<i>H</i><sub><i>L</i></sub>+<i>H</i><sub><i>R</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="68">对<i>H</i><sup>′</sup>进行傅里叶变换,使其从时域转换至频域,并以此定义频域中<i>HRTF</i>数据</p>
                </div>
                <div class="p1">
                    <p id="69"><i>H</i><sup>′′</sup>=<i>FFT</i>(<i>H</i><sup>′</sup>)      (15)</p>
                </div>
                <div class="p1">
                    <p id="70">根据<i>HRTF</i>数据对频域中的声音信号进行过滤,得到新生成的声音信号数据</p>
                </div>
                <div class="p1">
                    <p id="71"><i>Y</i><sup>′</sup>=<i>X</i><sup>′</sup>·<i>H</i><sup>′′</sup>      (16)</p>
                </div>
                <div class="p1">
                    <p id="72">对式(16)计算得到的声音信号实行傅里叶逆变换,该逆变换过程可降低声场合成信息采集复杂度,提高采集效率。其中,获取的虚拟现实声场合成信息采集结果可表示为</p>
                </div>
                <div class="p1">
                    <p id="73"><i>Y</i><sup>″</sup>=<i>IFFT</i>(<i>Y</i><sup>′</sup>)      (17)</p>
                </div>
                <div class="p1">
                    <p id="74">式(17)所得结果即为虚拟现实的声场合成信息采集结果。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>3.2 声场合成信息采集结果处理</b></h4>
                <div class="p1">
                    <p id="76">为使3.1得到的计算结果与实际信息相符程度更高,要对虚拟现实的声场合成信息采集结果进行进一步地处理。利用最小方差模态滤波器能够高效消除期望模态之外模态的能力,结合声场各阶简正波加权系数,获取声场合成信息采集结果处理后向量值。具体处理流程如下:</p>
                </div>
                <div class="p1">
                    <p id="77">最小方差滤波器可以高效消除期望信号之外的信号对期望信号产生的影响,其内部的约束基阵加权向量值能够使期望信号上形成单位幅度波束,并使基阵均方输出最小<citation id="123" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。根据简正波理念可了解到:接收基阵声场是利用若干简正波叠加形成的,且各个信号的简正波模态彼此正交,能够通过其正交性实现各简正波模态的滤波分离。最小方差模态滤波器能够高效消除期望模态之外的模态对滤波能力的影响,其中,约束权向量能够使其它干扰信号以及噪声的输出能量达到最小。</p>
                </div>
                <div class="p1">
                    <p id="78">综合以上分析和3.1的求解,得知虚拟现实的声场合成信息采集结果为<i>Y</i><sup>″</sup>,设采集结果的模态是第<i>m</i><sup>″</sup>号简正波,<i>w</i><sub><i>m</i></sub><sup>″</sup>代表与上述简正波相对应的加权系数,那么模态滤波器的输出可表示为<i>w</i><sub><i>m</i></sub><sup>″</sup><i>Y</i><sup>″</sup>。此时,最小方差模态的滤波器能够表示为</p>
                </div>
                <div class="p1">
                    <p id="79"><i>w</i><sub><i>m</i></sub><sup>″</sup>=min<i>E</i><sup>″</sup>[|<i>w</i><sub><i>m</i></sub><sup>″</sup><i>Y</i><sup>″</sup>|<sup>2</sup>]      (18)</p>
                </div>
                <div class="p1">
                    <p id="80">式(18)中,<i>E</i><sup>″</sup>代表方差模态滤波器。</p>
                </div>
                <div class="p1">
                    <p id="81">利用拉格朗日法对式(18)进行求解,能够获取最佳的加权系数</p>
                </div>
                <div class="p1">
                    <p id="82"><mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msubsup><mrow></mrow><mi>m</mi><mo>´</mo></msubsup><msup><mrow></mrow><mo>˝</mo></msup><mo>=</mo><mfrac><mrow><mi>R</mi><msubsup><mrow></mrow><mrow><mi>Y</mi><msup><mrow></mrow><mo>˝</mo></msup></mrow><mrow><mo>‴</mo><mo>-</mo><mn>1</mn></mrow></msubsup></mrow><mrow><mi>E</mi><msup><mrow></mrow><mo>˝</mo></msup></mrow></mfrac></mrow></math></mathml>      (19)</p>
                </div>
                <div class="p1">
                    <p id="83">其中,<i>R</i><sup></sup><sub><i>Y</i></sub><sub><sup>″</sup></sub>代表<i>Y</i><sup>″</sup>协方差矩阵。在实际中,<i>R</i><sup></sup><sub><i>Y</i></sub><sub><sup>″</sup></sub>是一个未知量,要利用<i>Y</i><sup>″</sup>有限个采样数据对其进行估计,则有</p>
                </div>
                <div class="p1">
                    <p id="84"><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><msubsup><mrow></mrow><mrow><mi>Y</mi><msup><mrow></mrow><mo>˝</mo></msup></mrow><mo>‴</mo></msubsup><mo>=</mo><mstyle displaystyle="true"><mo>∑</mo><mrow><mfrac><mrow><mi>w</mi><msub><mrow></mrow><mrow><mi>m</mi><msup><mrow></mrow><mo>˝</mo></msup></mrow></msub></mrow><mrow><mi>Y</mi><msup><mrow></mrow><mo>˝</mo></msup><mo stretchy="false">(</mo><mi>Τ</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></mstyle></mrow></math></mathml>      (20)</p>
                </div>
                <div class="p1">
                    <p id="85">式(20)中,<i>Y</i><sup>″</sup>(<i>T</i>)代表虚拟现实的声场合成信息时间序列。</p>
                </div>
                <div class="p1">
                    <p id="86">根据式(18)的方差模态滤波器和式(19)各阶简正波加权系数对虚拟现实声场合成信息采集结果进行滤波,得到的声场合成信息采集结果处理后向量值为</p>
                </div>
                <div class="p1">
                    <p id="87"><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><msup><mrow></mrow><mo>˝</mo></msup><mo>=</mo><mfrac><mrow><mi>w</mi><msubsup><mrow></mrow><mrow><mi>m</mi><msup><mrow></mrow><mo>˝</mo></msup></mrow><mo>´</mo></msubsup><mo>⋅</mo><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext><mi>E</mi><msup><mrow></mrow><mo>˝</mo></msup></mrow><mrow><mi>Y</mi><msup><mrow></mrow><mo>˝</mo></msup></mrow></mfrac></mrow></math></mathml>      (21)</p>
                </div>
                <div class="p1">
                    <p id="88">式(21)中,<i>h</i><sup>″</sup>代表声场合成信息采集结果处理后向量值。</p>
                </div>
                <h3 id="89" name="89" class="anchor-tag"><b>4 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="90">为验证基于MEMS和HRIR的虚拟现实的声场合成信息采集建模方法整体性能,需要进行一次实验。实验环境为:Microsoft Visual Studio C++下的OpenGI,实验数据来源于某族非物质文化遗产的“四季生产调”VR保护全景声场。实验指标为:</p>
                </div>
                <div class="p1">
                    <p id="91">1)信息采集结果与实际情况的拟合度</p>
                </div>
                <div class="p1">
                    <p id="92">2)信息采集耗时</p>
                </div>
                <div class="p1">
                    <p id="93">实验结果如图1所示。</p>
                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201909040_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 不同方法所得结果与实际情况拟合程度" src="Detail/GetImg?filename=images/JSJZ201909040_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 不同方法所得结果与实际情况拟合程度</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201909040_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="95">分析图1可知,基于多极源的声场信息采集结果与实际情况拟合程度最高约为60%,基于近场测量的声场信息采集结果与实际情况拟合程度最高约为70%,基于<i>MEMS</i>和<i>HRIR</i>的虚拟现实的声场合成信息采集结果与实际情况拟合程度最高约为99.8%。通过在数据上的对比发现,所提方法采集结果与实际声场合成信息情况拟合程度更高一些。</p>
                </div>
                <div class="p1">
                    <p id="96">表1中,<i>J</i>0代表待采集信息类型,单位为种。<i>J</i>1代表基于波数积分的声场信息采集方法采集耗时,单位为<i>h</i>。<i>J</i>2代表基于<i>MEMS</i>和<i>HRIR</i>的虚拟现实的声场合成信息采集方法采集耗时,单位为<i>h</i>。</p>
                </div>
                <div class="area_img" id="97">
                    <p class="img_tit"><b>表1 不同方法信息采集耗时对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="97" border="1"><tr><td><br /><i>J</i>0</td><td><i>J</i>1</td><td><i>J</i>2</td></tr><tr><td><br />10</td><td>0.3</td><td>0.1</td></tr><tr><td><br />20</td><td>1.5</td><td>0.2</td></tr><tr><td><br />30</td><td>2.6</td><td>0.3</td></tr><tr><td><br />40</td><td>3.9</td><td>0.5</td></tr><tr><td><br />50</td><td>4.5</td><td>0.6</td></tr><tr><td><br />60</td><td>5.8</td><td>0.7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="98">分析表1,基于波数积分的声场信息采集方法采集耗时平均为3.1<i>h</i>,基于<i>MEMS</i>和<i>HRIR</i>的虚拟现实的声场合成信息采集方法采集耗时平均为0.4<i>h</i>。所提方法利用傅里叶逆变换得到声场合成信息采集结果,降低了信息采集过程的复杂度,提高了采集效率。</p>
                </div>
                <h3 id="99" name="99" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="100">虚拟现实的声场合成信息采集对于科技的发展和大众接收新事物等方面均有着十分重要的意义。针对当前相关方法性能较差的问题,提出基于<i>MEMS</i>和<i>HRIR</i>的虚拟现实声场合成信息采集方法。通过<i>MEMS</i>和<i>HRIR</i>相结合的方式对声场合成信息进行采集,利用最小方差模态滤波器对采集结果进行滤波,提高信息纯度。实验结果表明,所提信息采集方法采集结果与实际情况拟合程度高、采集耗时短,是一种非常可行的虚拟现实声场合成信息采集方法。</p>
                </div>
                <div class="area_img" id="124">
                                <img alt="" src="Detail/GetImg?filename=images/JSJZ201909040_12400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HJGX201605016&amp;v=Mjk0MTFNcW85RVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmtWTHJJTFNmTWRyRzRIOWY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 常广晖,陈志敏.一种循环平稳声场的声源识别定位方法[<i>J</i>].海军工程大学学报,2016,28(5):75-79.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WLXB201606023&amp;v=MjE4MTR6cXFCdEdGckNVUjdxZlp1Wm9GeW5rVkxySU1pSFRiTEc0SDlmTXFZOUhaNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 胡珍,等.水下掩埋目标的散射声场计算与实验[<i>J</i>].物理学报,2016 65(6):170-177.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201704039&amp;v=MzAyMTMzenFxQnRHRnJDVVI3cWZadVpvRnlua1ZMcklMejdCZExHNEg5Yk1xNDlHYllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 胡代弟,董素鸽.远程实验信息数据采集方法研究仿真[<i>J</i>].计算机仿真,2017,34(4):186-189.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SXJS201705004&amp;v=MDk1ODRSN3FmWnVab0Z5bmtWTHJJTmpYQmZiRzRIOWJNcW85RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 于晓林,等.一种基于波数积分方法的线源声场计算方法[<i>J</i>].声学技术,2017,36(5):415-422.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YYSN201706014&amp;v=MjYxNDBGckNVUjdxZlp1Wm9GeW5rVkxySVBEVFlZTEc0SDliTXFZOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 邓英,陈浩,于其蛟.井孔中多极源在分层介质中的声场模拟方法[<i>J</i>].应用声学,2017,36(6):555-558.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYCS201701006&amp;v=MjcxMzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlua1ZMcklOalRJZmJHNEg5Yk1ybzlGWW8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 于群,等.聚焦换能器声强和声功率测量方法研究[<i>J</i>].中国测试,2017,43(1):27-32.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDCJ201623025&amp;v=MTM0NDNJWkxHNEg5Zk9ySTlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlua1ZMcklQeW4=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 宁少武,史治宇.夹层结构中夹层声场的处理方法研究[<i>J</i>].振动与冲击,2016,35(23):160-167.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CBLX201701013&amp;v=MDY4MDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlua1ZMcklKaS9IZHJHNEg5Yk1ybzlFWjRRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 俞孟萨,庞业珍.舰船辐射声场及声源特性测量方法研究综述[<i>J</i>].船舶力学,2017,21(1):107-126.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXKX201710014&amp;v=MzI1MzVFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlua1ZMcklMelhBZHJHNEg5Yk5yNDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 闫秀丽,等.阶梯盘超声辐射声场指向性研究[<i>J</i>].机械科学与技术,2017,36(10):1570-1574.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYGY201701011&amp;v=MDU5MTMzenFxQnRHRnJDVVI3cWZadVpvRnlua1ZMcklOalRNZDdHNEg5Yk1ybzlFWllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 郭莹,闫美辰.基于镜像源方法的室内声场脉冲响应仿真[<i>J</i>].沈阳工业大学学报,2017,39(1):55-60.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201909040" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201909040&amp;v=MDAzMTQ5QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmtWTHJJTHo3QmRMRzRIOWpNcG8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc1FTMHdYQkFCcm1KK2ZPTjlDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
