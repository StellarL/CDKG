<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139153893412500%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJSJZ201911094%26RESULT%3d1%26SIGN%3dDWU%252fd%252be8KDXn0aRu8RTcKGyXJRA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201911094&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201911094&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201911094&amp;v=MDc5NzJGeXJnVzdyQkx6N0JkTEc0SDlqTnJvOU1ZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnA=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;2 三维动态视景图像重建和块匹配处理&lt;/b&gt; "><b>2 三维动态视景图像重建和块匹配处理</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#32" data-title="&lt;b&gt;2.1 三维动态视景图像重建&lt;/b&gt;"><b>2.1 三维动态视景图像重建</b></a></li>
                                                <li><a href="#51" data-title="&lt;b&gt;2.2 三维动态视景的块匹配处理&lt;/b&gt;"><b>2.2 三维动态视景的块匹配处理</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="&lt;b&gt;3 三维动态视景自修正算法设计&lt;/b&gt; "><b>3 三维动态视景自修正算法设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="&lt;b&gt;3.1 多源信息融合&lt;/b&gt;"><b>3.1 多源信息融合</b></a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;3.2 三维动态视景自修正&lt;/b&gt;"><b>3.2 三维动态视景自修正</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#91" data-title="&lt;b&gt;4 仿真与结果分析&lt;/b&gt; "><b>4 仿真与结果分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#102" data-title="&lt;b&gt;5 结语&lt;/b&gt; "><b>5 结语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="&lt;b&gt;图1 三维动态视景图像块匹配处理网格模型&lt;/b&gt;"><b>图1 三维动态视景图像块匹配处理网格模型</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;图2 三维动态视景图像&lt;/b&gt;"><b>图2 三维动态视景图像</b></a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;图3 三维动态视景的多源信息融合输出&lt;/b&gt;"><b>图3 三维动态视景的多源信息融合输出</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;图4 三维动态视景自修正输出&lt;/b&gt;"><b>图4 三维动态视景自修正输出</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;图5 输出性能对比&lt;/b&gt;"><b>图5 输出性能对比</b></a></li>
                                                <li><a href="#101" data-title="&lt;b&gt;表1 时间开销对比(单位&lt;/b&gt;:ms)"><b>表1 时间开销对比(单位</b>:ms)</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="136">


                                    <a id="bibliography_1" title=" 陈炜耿,柴琳,赵雅涵.一类改进的红外无损检测技术热波图像序列处理方法[J].机械设计与制造工程,2018,(12):101-106." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXZZ201812023&amp;v=MTY4NzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXJnVzdyQUx6WFJkTEc0SDluTnJZOUhaNFE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[1]</b>
                                         陈炜耿,柴琳,赵雅涵.一类改进的红外无损检测技术热波图像序列处理方法[J].机械设计与制造工程,2018,(12):101-106.
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_2" title=" 李俊杰,高翠芳,黄芳.基于优化采样支持向量机的指纹二值化方法[J].东北师大学报(自然科学版),2018,50(4):59-65." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DBSZ201804012&amp;v=MjgwMDU3cWZadVpwRnlyZ1c3ckFJUy9ZZExHNEg5bk1xNDlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[2]</b>
                                         李俊杰,高翠芳,黄芳.基于优化采样支持向量机的指纹二值化方法[J].东北师大学报(自然科学版),2018,50(4):59-65.
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_3" title=" 郑乐乐,韩慧妍,韩燮.基于显著性与弱凸性的三维点云模型分割[J].计算机工程,2018,44(4):299-304." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201804048&amp;v=MjA2NTdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmdXN3JBTHo3QmJiRzRIOW5NcTQ5QmI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[3]</b>
                                         郑乐乐,韩慧妍,韩燮.基于显著性与弱凸性的三维点云模型分割[J].计算机工程,2018,44(4):299-304.
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_4" title=" RUI L L,ZHANG P,HUANG H Q,et al.Reputation-based incentive mechanisms in crowdsourcing[J].Journal of Electronics &amp;amp; Information Technology,2016,38(7):1808-1815." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201607033&amp;v=MjEwNDdmWnVacEZ5cmdXN3JBSVRmU2RyRzRIOWZNcUk5R1o0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[4]</b>
                                         RUI L L,ZHANG P,HUANG H Q,et al.Reputation-based incentive mechanisms in crowdsourcing[J].Journal of Electronics &amp;amp; Information Technology,2016,38(7):1808-1815.
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_5" title=" ZHANG Y,JIANG C,SONG L,et al.Incentive mechanism for mobile crowdsourcing using an optimized tournament model[J].IEEE Journal on Selected Areas in Communications,2017,35(4):880-892." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Incentive mechanism for mobile crowdsourcing using an optimized tournament model">
                                        <b>[5]</b>
                                         ZHANG Y,JIANG C,SONG L,et al.Incentive mechanism for mobile crowdsourcing using an optimized tournament model[J].IEEE Journal on Selected Areas in Communications,2017,35(4):880-892.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_6" title=" 王燕,王双印.基于卷积神经网络的人脸信息增强识别研究[J].计算机科学,2018,45(8):268-271." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201808050&amp;v=MzAyMjdmWnVacEZ5cmdXN3JBTHo3QmI3RzRIOW5NcDQ5QVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[6]</b>
                                         王燕,王双印.基于卷积神经网络的人脸信息增强识别研究[J].计算机科学,2018,45(8):268-271.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_7" title=" 杨伟,谢维成,蒋文波,等.基于自相似性车载采集城市街景图像的重建[J].计算机应用,2017,37(3):817-822." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201703037&amp;v=MjA3NzBiTXJJOUdZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXJnVzdyQUx6N0JkN0c0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[7]</b>
                                         杨伟,谢维成,蒋文波,等.基于自相似性车载采集城市街景图像的重建[J].计算机应用,2017,37(3):817-822.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_8" title=" 周雨薇,陈强,孙权森,等.结合暗通道原理和双边滤波的遥感图像增强[J].中国图象图形学报,2014,19(2):313-321." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201402018&amp;v=Mjc3MTBacEZ5cmdXN3JBUHlyZmJMRzRIOVhNclk5RWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[8]</b>
                                         周雨薇,陈强,孙权森,等.结合暗通道原理和双边滤波的遥感图像增强[J].中国图象图形学报,2014,19(2):313-321.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_9" title=" 郭佳,刘晓玉,吴冰,等.一种光照不均匀图像的二值化方法[J].计算机应用与软件,2014,31(3):183-186." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201403049&amp;v=MjE4ODZxZlp1WnBGeXJnVzdyQUx6VFpaTEc0SDlYTXJJOUJiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[9]</b>
                                         郭佳,刘晓玉,吴冰,等.一种光照不均匀图像的二值化方法[J].计算机应用与软件,2014,31(3):183-186.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_10" title=" 刘杰.基于分布式压缩感知的异源图像融合方法[J].舰船电子工程,2018,38(12):30-33." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JCGC201812007&amp;v=Mjc1NjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmdXN3JBTHk3TWJiRzRIOW5Oclk5Rlk0UUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[10]</b>
                                         刘杰.基于分布式压缩感知的异源图像融合方法[J].舰船电子工程,2018,38(12):30-33.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_11" title=" 卞乐,霍冠英,李庆武.基于Curvelet变换和多目标粒子群的混合熵MRI图像多阈值分割[J].计算机应用,2016,36(11):3188-3195." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201611046&amp;v=MjgyMDk5Zk5ybzlCWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlyZ1c3ckFMejdCZDdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[11]</b>
                                         卞乐,霍冠英,李庆武.基于Curvelet变换和多目标粒子群的混合熵MRI图像多阈值分割[J].计算机应用,2016,36(11):3188-3195.
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_12" title=" 杨旭,陈波,李小阳,等.远距离数字离轴全息中基于图像指标优化的相位误差校正方法[J].激光杂志,2017,38(4):96-100." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGZZ201704023&amp;v=MDk4NzZxQnRHRnJDVVI3cWZadVpwRnlyZ1c3ckFMeXJSZExHNEg5Yk1xNDlIWjRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                        <b>[12]</b>
                                         杨旭,陈波,李小阳,等.远距离数字离轴全息中基于图像指标优化的相位误差校正方法[J].激光杂志,2017,38(4):96-100.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(11),427-431             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>多源信息融合三维动态视景自修正仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%9B%BD%E5%8D%8E&amp;code=28181598&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">张国华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8C%85%E9%94%8B&amp;code=27279526&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">包锋</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BD%90%E5%8D%9A&amp;code=30381726&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">齐博</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%85%B0%E5%AE%87&amp;code=41786399&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">兰宇</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%9C%E5%8C%97%E7%9F%B3%E6%B2%B9%E5%A4%A7%E5%AD%A6&amp;code=1694099&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">东北石油大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>三维动态视景重构中受到边缘模糊特征集的干扰,导致图像输出失真。为了提高三维动态视景的自动修正能力,提出一种基于多源信息融合的三维动态视景自修正方法。采用局部边缘轮廓特征提取方法进行三维动态视景图像重构,结合模糊特征匹配方法进行三维动态视景的块匹配处理,构建三维动态视景图像的图像特征分割模型,采用小波多尺度分解进行三维动态视景图像的纹理分解和多源信息融合,根据三维动态视景的信息融合结果进行视景重构,结合模糊特征检测方法,实现三维动态视景图像的清晰化识别,采用纹理修正方法,在多源信息融合空间中实现三维动态视景自修正处理。仿真结果表明,采用上述方法进行三维动态视景重构的自修正能力较好,特征分辨能力较强,提高了图像的检测和信息融合能力。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E6%BA%90%E4%BF%A1%E6%81%AF%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">多源信息融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E5%8A%A8%E6%80%81%E8%A7%86%E6%99%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">三维动态视景;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E4%BF%AE%E6%AD%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">自修正;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%87%8D%E6%9E%84&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">重构;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张国华(1981-),男(汉族),吉林长春人,博士研究生,讲师,研究方向:计算机数值模拟,虚拟现实技术,人工智能;;
                                </span>
                                <span>
                                    包锋(1965-),男(汉族),山东蓬莱人,教授,研究方向:大数据及云计算,虚拟现实技术;;
                                </span>
                                <span>
                                    齐博(1981-),男(汉族),辽宁锦县人,讲师,研究方向:网络安全技术,虚拟现实技术;;
                                </span>
                                <span>
                                    兰宇(1981-),男(汉族),吉林四平人,讲师,研究方向:软件工程,计算机应用技术。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-02</p>

                    <p>

                            <b>基金：</b>
                                                        <span>虚拟现实技术背景下的海洋浮冰监测平台研究(KY12181103);</span>
                    </p>
            </div>
                    <h1>3<b>D Dynamic Scene Self-Correction Simulation Based on Multi-Source Information Fusion</b></h1>
                    <h2>
                    <span>ZHANG Guo-hua</span>
                    <span>BAO Feng</span>
                    <span>QI Bo</span>
                    <span>LAN Yu</span>
            </h2>
                    <h2>
                    <span>Northeast Petroleum University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In 3 D dynamic scene reconstruction, the image output is distorted due to the interference of edge fuzzy feature set. In order to improve capability of automatic correction for three-dimensional dynamic scene, a method to correct three-dimensional dynamic scene automatically based on multi-source information fusion. Firstly, the three-dimensional dynamic scene image was reconstructed by the method of local edge contour feature extraction. Combined with the fuzzy feature matching method, the blocks of three-dimensional dynamic scene were matched, and then the model of feature segmentation of three-dimensional dynamic scene image was constructed. Moreover, the wavelet multi-scale decomposition was used to fuse the texture decomposition and the multi-source information fusion of three-dimensional dynamic scene image. According to the information fusion result of three-dimensional dynamic scene, the visual scene was reconstructed. Based on fuzzy characteristic detection method, the clear identification of three-dimensional dynamic visual image was achieved. Finally, the texture correction method was used to realize the automatic correction for three-dimensional dynamic scene in multi-source information fusion space. Simulation results show that the proposed method has better auto correction ability of three-dimensional dynamic scene reconstruction and stronger feature resolving power. Thus, the ability of detection and information fusion of image is improved.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-source%20information%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Multi-source information fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Three-dimensional%20dynamic%20scene&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Three-dimensional dynamic scene;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Auto%20correction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Auto correction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Reconstruction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" target="_blank">Reconstruction;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-04-02</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="27" name="27" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="28">三维动态视景仿真技术不断发展,采用视景重构技术进行虚拟现实仿真,构建虚拟视景下的三维重构模型,提高三维建模和图像分析能力具有重要研究意义。在三维动态视景的重构过程中,受到图像的边缘像素集的模糊性影响,导致三维动态视景的信息丢失,需要对三维动态视景进行自修正处理<citation id="160" type="reference"><link href="136" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>,结合图像修复和自适应重建技术,实现三维动态视景重构和识别,提高三维动态视景的成像能力。研究三维动态视景的修正方法,在三维视景仿真和虚拟现实设计中具有重要意义,相关的三维动态视景修正技术研究受到人们的极大重视<citation id="161" type="reference"><link href="138" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="29">对三维动态视景的修正技术是建立在图像的边缘轮廓检测和信息融合基础上,结合对三维动态视景的纹理渲染结果,构建三维动态视景图像的特征分析模型,采用目标匹配方法进行三维动态视景纹理渲染,建立三维动态视景图像的均匀分布网格顶点模型<citation id="162" type="reference"><link href="140" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>,进行三维动态视景的自修正处理。传统方法中,对三维动态视景的自修正方法主要有基于自相关特征匹配的三维动态视景修正方法、模糊关联特征匹配方法和小波分析方法等,文献<citation id="163" type="reference">[<a class="sup">4</a>]</citation>中提出一种基于边缘轮廓检测的三维动态视景修正方法,进行色彩模式自动识别和颜色分类,提高视景的自修正能力,但该方法的模糊度较大,自适应性能不好<citation id="164" type="reference"><link href="142" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。文献<citation id="165" type="reference">[<a class="sup">5</a>]</citation>中提出一种基于人类视觉特征分辨性构造的三维动态视景修正方法,采用块匹配方法实现三维动态视景自动提取,有效避免了视觉刺激,提高视景自修正能力,但该方法的计算复杂度较高,自适应性能不好。</p>
                </div>
                <div class="p1">
                    <p id="30">针对上述问题,本文提出一种基于多源信息融合的三维动态视景自修正方法。采用局部边缘轮廓特征提取方法进行三维动态视景图像重构,构建三维动态视景图像的特征分割模型,采用小波多尺度分解进行三维动态视景图像的纹理分解和多源信息融合,根据三维动态视景的信息融合结果进行视景重构,结合模糊特征检测方法,实现三维动态视景图像的清晰化识别和自修正。最后进行仿真分析,展示了本文方法在提高三维动态视景自修正能力方面的优越性能。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>2 三维动态视景图像重建和块匹配处理</b></h3>
                <h4 class="anchor-tag" id="32" name="32"><b>2.1 三维动态视景图像重建</b></h4>
                <div class="p1">
                    <p id="33">为了实现对三维动态视景图像的自修正处理,结合色彩特征检测方法,构建三维动态视景图像的统计分析模型,结合三维动态视景仿真技术,进行视觉重构和特征分析,采用自适应的模板匹配方法进行三维动态视景的边缘轮廓检测和纹理渲染,构建三维动态视景图像的均匀分布模型<citation id="166" type="reference"><link href="146" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>,采用网格分割方法,实现三维动态视景的模糊网格划分,结合区域块特征分割方法,进行三维动态视景图像的纹理渲染和特征分解,设三维动态视景图像像素序列的分布矩阵描述为</p>
                </div>
                <div class="area_img" id="34">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201911094_03400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="36">采用边缘轮廓检测方法进行三维动态视景的动态分布特征检测,构建三维动态视景的颜色特征点分离模型,三维动态视景图像重建线性方程组为</p>
                </div>
                <div class="area_img" id="37">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201911094_03700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="39">采用自相关特征匹配方法,得到三维动态视景自动纹理分割的灰度像素集为<i>u</i><sup>(3)</sup>=(<i>u</i><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml>,<i>u</i><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml>,<i>u</i><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml>,<i>u</i><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml>),得到平滑函数为</p>
                </div>
                <div class="p1">
                    <p id="40"><i>D</i>(<i>x</i>,<i>y</i>,<i>σ</i>)=(<i>G</i>(<i>x</i>,<i>y</i>,<i>kσ</i>)-<i>G</i>(<i>x</i>,<i>y</i>,<i>σ</i>))*<i>I</i>(<i>x</i>,<i>y</i>)=<i>L</i>(<i>x</i>,<i>y</i>,<i>kσ</i>)-<i>L</i>(<i>x</i>,<i>y</i>,<i>σ</i>)      (3)</p>
                </div>
                <div class="p1">
                    <p id="42">其中</p>
                </div>
                <div class="p1">
                    <p id="43"><i>L</i>(<i>x</i>,<i>y</i>,<i>σ</i>)=<i>G</i>(<i>x</i>,<i>y</i>,<i>σ</i>)⨂<i>I</i>(<i>x</i>,<i>y</i>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="44">式中,<i>I</i>(<i>x</i>,<i>y</i>)表示三维动态视景图像在(<i>x</i>,<i>y</i>)处的灰度值,<i>L</i>(<i>x</i>,<i>y</i>,<i>σ</i>)表示三维动态视景的Taubin平滑算子,<i>G</i>(<i>x</i>,<i>y</i>,<i>σ</i>)表示为三维动态视景块匹配特征系数,计算式为</p>
                </div>
                <div class="p1">
                    <p id="45"><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>σ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>π</mi><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>e</mi><msup><mrow></mrow><mrow><mo>-</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>y</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow></msup></mrow></math></mathml>      (5)</p>
                </div>
                <div class="p1">
                    <p id="46">判断三维动态视景图像的边界纹理信息,结合主成分分析方法进行三维动态视景的动态跟踪识别,提取三维动态视景的相似度特征量<citation id="167" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>,构建三维动态视景图像的稀疏采样点集合为</p>
                </div>
                <div class="p1">
                    <p id="47"><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>Τ</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ν</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mo stretchy="false">∥</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>Τ</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>g</mi><msubsup><mrow></mrow><mi>i</mi><mo>´</mo></msubsup><mo stretchy="false">)</mo><mo stretchy="false">∥</mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>τ</mi><mo>⋅</mo><mtext>Φ</mtext><mo stretchy="false">(</mo><mi>Τ</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>      (6)</p>
                </div>
                <div class="p1">
                    <p id="48">采用模糊判断方法进行三维动态视景的自适应加权控制<citation id="168" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>,根据三维动态视景图像的模糊指向性分布进行视觉特征重建,得到三维动态视景图像的逆加权<i>f</i>(<i>g</i><sub><i>i</i></sub>)为</p>
                </div>
                <div class="p1">
                    <p id="49"><mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>g</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>c</mi><msub><mrow></mrow><mn>1</mn></msub><mover><mstyle mathsize="140%" displaystyle="true"><mi>λ</mi></mstyle><mo>∼</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mi>n</mi><mi>p</mi></mrow></msub></mrow></munderover><mrow><mfrac><mrow><mi>ρ</mi><msub><mrow></mrow><mi>j</mi></msub><mover accent="true"><mi>υ</mi><mo>→</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mrow><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mi>υ</mi><mo>→</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow><msup><mrow></mrow><mrow><mi>σ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msup><mo>+</mo><mi>ε</mi></mrow></mfrac></mrow></mstyle></mrow><mo>/</mo></mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mi>n</mi><mi>p</mi></mrow></msub></mrow></munderover><mrow><mfrac><mrow><mi>ρ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mrow><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mi>υ</mi><mo>→</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow><msup><mrow></mrow><mrow><mi>σ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msup><mo>+</mo><mi>ε</mi></mrow></mfrac></mrow></mstyle></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="50">构建三维动态视景图像的特征分析模型,采用局部边缘轮廓特征提取方法进行三维动态视景图像重构。</p>
                </div>
                <h4 class="anchor-tag" id="51" name="51"><b>2.2 三维动态视景的块匹配处理</b></h4>
                <div class="p1">
                    <p id="52">结合模糊特征匹配方法进行三维动态视景的块匹配处理,构建三维动态视景图像的图像特征分割模型,采用4×4的网格模型进行建三维动态视景的网格模型设计<citation id="169" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,如图1所示。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201911094_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                    <img alt="图1 三维动态视景图像块匹配处理网格模型" src="Detail/GetImg?filename=images/JSJZ201911094_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
                                </a>
                                <p class="img_tit"><b>图1 三维动态视景图像块匹配处理网格模型</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201911094_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="54">在图1所示的分块匹配模型中,采用三维动态平滑滤波方法,进行三维动态视景的稀疏点重构,得三维动态视景的色彩稀疏点重构输出的数学表述如下</p>
                </div>
                <div class="p1">
                    <p id="55">G<sub>new</sub>=(1+μT)(1+λT)G<sub>old</sub>      (8)</p>
                </div>
                <div class="p1">
                    <p id="56"><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Τ</mtext><mo stretchy="false">(</mo><mtext>g</mtext><msub><mrow></mrow><mtext>i</mtext></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mtext>k</mtext></msub><mtext>ω</mtext></mstyle><msub><mrow></mrow><mtext>k</mtext></msub></mrow></mfrac><mo>⋅</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mtext>k</mtext></msub><mtext>ω</mtext></mstyle><msub><mrow></mrow><mtext>k</mtext></msub><mo stretchy="false">(</mo><mtext>g</mtext><msub><mrow></mrow><mtext>k</mtext></msub><mo>-</mo><mtext>g</mtext><msub><mrow></mrow><mtext>i</mtext></msub><mo stretchy="false">)</mo></mrow></math></mathml>      (9)</p>
                </div>
                <div class="p1">
                    <p id="57">其中,G<sub>new</sub>和G<sub>old</sub>分别表示三维动态视景图像的统计特征分量和网格区域分块特征量。根据对三维动态视景图像的网格区域分割结果,采用块匹配方法实现三维动态视景的块区域匹配<citation id="170" type="reference"><link href="154" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>,得到三维动态视景图像的边界特征分割集表达式为</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext>f</mtext><mo stretchy="false">(</mo><mtext>G</mtext><msub><mrow></mrow><mtext>n</mtext></msub><mo stretchy="false">)</mo><mo>=</mo><mtext>a</mtext><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mtext>a</mtext><msub><mrow></mrow><mn>2</mn></msub><mtext>x</mtext><mo>+</mo><mtext>a</mtext><msub><mrow></mrow><mn>3</mn></msub><mtext>y</mtext><mo>+</mo><mtext>a</mtext><msub><mrow></mrow><mn>4</mn></msub><mtext>z</mtext><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mn>0</mn></mrow><mtext>n</mtext></munderover><mtext>γ</mtext></mstyle><msub><mrow></mrow><mtext>i</mtext></msub><mtext>U</mtext><mo stretchy="false">(</mo><mtext>g</mtext><msubsup><mrow></mrow><mtext>i</mtext><mo>´</mo></msubsup><mo>,</mo><mtext>p</mtext><msub><mrow></mrow><mtext>i</mtext></msub><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mtext>g</mtext><mo stretchy="false">(</mo><mtext>G</mtext><msub><mrow></mrow><mtext>n</mtext></msub><mo stretchy="false">)</mo><mo>=</mo><mtext>b</mtext><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mtext>b</mtext><msub><mrow></mrow><mn>2</mn></msub><mtext>x</mtext><mo>+</mo><mtext>b</mtext><msub><mrow></mrow><mn>3</mn></msub><mtext>y</mtext><mo>+</mo><mtext>b</mtext><msub><mrow></mrow><mn>4</mn></msub><mtext>z</mtext><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mn>0</mn></mrow><mtext>n</mtext></munderover><mtext>θ</mtext></mstyle><msub><mrow></mrow><mtext>i</mtext></msub><mtext>U</mtext><mo stretchy="false">(</mo><mtext>g</mtext><msubsup><mrow></mrow><mtext>i</mtext><mo>´</mo></msubsup><mo>,</mo><mtext>p</mtext><msub><mrow></mrow><mtext>i</mtext></msub><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mtext>h</mtext><mo stretchy="false">(</mo><mtext>G</mtext><msub><mrow></mrow><mtext>n</mtext></msub><mo stretchy="false">)</mo><mo>=</mo><mtext>c</mtext><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mtext>c</mtext><msub><mrow></mrow><mn>2</mn></msub><mtext>x</mtext><mo>+</mo><mtext>c</mtext><msub><mrow></mrow><mn>3</mn></msub><mtext>y</mtext><mo>+</mo><mtext>c</mtext><msub><mrow></mrow><mn>4</mn></msub><mtext>z</mtext><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mn>0</mn></mrow><mtext>n</mtext></munderover><mtext>ω</mtext></mstyle><msub><mrow></mrow><mtext>i</mtext></msub><mtext>U</mtext><mo stretchy="false">(</mo><mtext>g</mtext><msubsup><mrow></mrow><mtext>i</mtext><mo>´</mo></msubsup><mo>,</mo><mtext>p</mtext><msub><mrow></mrow><mtext>i</mtext></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">上式表示为对三维动态视景图像的颜色特征分解结果,根据RGB颜色特征分解方法,进行三维动态视景图像的多源信息融合和量化分析<citation id="171" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>,给出三维动态视景的边界特征识别结果<i>Φ</i>(T<sub>n</sub>)由下式给出</p>
                </div>
                <div class="p1">
                    <p id="60"><i>Φ</i>(T<sub>n</sub>)=γ<sup>T</sup>Hγ+θ<sup>T</sup>Hθ+ω<sup>T</sup>Hω      (11)</p>
                </div>
                <div class="p1">
                    <p id="61">根据上述模型构建,结合模糊特征匹配方法进行三维动态视景的块匹配处理,进行三维动态视景图像色彩特征自动提取,在灰度像素区域中进行边缘轮廓区域的像素重构,提高对三维动态视景图像的特征识别和颜色空间表达能力。</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag"><b>3 三维动态视景自修正算法设计</b></h3>
                <h4 class="anchor-tag" id="63" name="63"><b>3.1 多源信息融合</b></h4>
                <div class="p1">
                    <p id="64">在上述采用局部边缘轮廓特征提取方法进行三维动态视景图像重构,结合模糊特征匹配方法进行三维动态视景的块匹配处理的基础上,进行三维动态视景的自修正处理,本文提出一种基于多源信息融合的三维动态视景自修正技术,提取三维动态视景图像的局部边缘轮廓特征量,采用模糊特征检索方法进行三维动态视景图像的像素特征匹配<citation id="172" type="reference"><link href="158" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>,得到三维动态视景图像的细节特征量分布函数定义为</p>
                </div>
                <div class="p1">
                    <p id="65">fitness<mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">(</mo><mover accent="true"><mtext>x</mtext><mo>→</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mtext>f</mtext><mo stretchy="false">(</mo><mover accent="true"><mtext>x</mtext><mo>→</mo></mover><mo stretchy="false">)</mo><mo>+</mo><mrow><mo stretchy="false">(</mo><mtext>C</mtext><mtext>t</mtext><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mtext>α</mtext></msup><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mtext>j</mtext><mo>=</mo><mn>1</mn></mrow><mtext>p</mtext></msubsup><mtext>G</mtext></mstyle><msubsup><mrow></mrow><mtext>j</mtext><mtext>β</mtext></msubsup><mo stretchy="false">(</mo><mover accent="true"><mtext>x</mtext><mo>→</mo></mover><mo stretchy="false">)</mo></mrow></math></mathml>      (12)</p>
                </div>
                <div class="p1">
                    <p id="66">通过如上定义,生成三维动态视景图像分布特征量,采用交叉性的融合滤波方法,进行多源信息融合<sup><a class="sup">[13]</a></sup>,得到三维动态视景自修正的适应度函数为</p>
                </div>
                <div class="area_img" id="134">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201911094_13400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="70">构建三维动态视景图像的多维直方图修正模型,在多源信息融合下,得到三维动态视景融合的状态约束方程</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext> </mtext><mtext>W</mtext><msub><mrow></mrow><mtext>u</mtext></msub><mtext>u</mtext><mo stretchy="false">(</mo><mtext>a</mtext><mo>,</mo><mtext>b</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mtext>j</mtext><mn>2</mn><mtext>π</mtext><mtext>Κ</mtext><mi>l</mi><mi>n</mi><mtext>a</mtext></mrow></msup><mo>×</mo><mfrac><mtext>Κ</mtext><mrow><msqrt><mtext>a</mtext></msqrt></mrow></mfrac></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mrow><mo>{</mo><mrow><mrow><mo>[</mo><mrow><mfrac><mrow><mtext>a</mtext><mtext>e</mtext><msup><mrow></mrow><mrow><mfrac><mrow><mtext>j</mtext><mn>2</mn><mtext>π</mtext><mtext>f</mtext><msub><mrow></mrow><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><mtext>a</mtext></mfrac><mo stretchy="false">(</mo><mtext>b</mtext><mo>-</mo><mtext>b</mtext><msub><mrow></mrow><mtext>a</mtext></msub><mo stretchy="false">)</mo></mrow></msup></mrow><mrow><mtext>f</mtext><msub><mrow></mrow><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow></mfrac><mo>-</mo><mfrac><mrow><mtext>e</mtext><msup><mrow></mrow><mrow><mtext>j</mtext><mn>2</mn><mtext>π</mtext><mtext>f</mtext><msub><mrow></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo stretchy="false">(</mo><mtext>b</mtext><mo>-</mo><mtext>b</mtext><msub><mrow></mrow><mtext>a</mtext></msub><mo stretchy="false">)</mo></mrow></msup></mrow><mrow><mtext>f</mtext><msub><mrow></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow></mfrac></mrow><mo>]</mo></mrow></mrow></mrow><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext>j</mtext><mn>2</mn><mtext>π</mtext><mo stretchy="false">(</mo><mtext>b</mtext><mo>-</mo><mtext>b</mtext><msub><mrow></mrow><mtext>a</mtext></msub><mo stretchy="false">)</mo><mo stretchy="false">[</mo><mtext>E</mtext><mtext>i</mtext><mo stretchy="false">(</mo><mtext>j</mtext><mn>2</mn><mtext>π</mtext><mtext>f</mtext><msub><mrow></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo stretchy="false">(</mo><mtext>b</mtext><mo>-</mo><mtext>b</mtext><msub><mrow></mrow><mtext>a</mtext></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>-</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mrow><mrow><mrow><mrow><mtext>E</mtext><mtext>i</mtext><mrow><mo>(</mo><mrow><mfrac><mrow><mtext>j</mtext><mn>2</mn><mtext>π</mtext><mtext>f</mtext><msub><mrow></mrow><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><mtext>a</mtext></mfrac><mo stretchy="false">(</mo><mtext>b</mtext><mo>-</mo><mtext>b</mtext><msub><mrow></mrow><mtext>a</mtext></msub><mo stretchy="false">)</mo></mrow><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow><mo>}</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">其中,<mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>b</mtext><msub><mrow></mrow><mtext>a</mtext></msub><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mtext>a</mtext><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mfrac><mn>1</mn><mrow><mtext>a</mtext><mtext>f</mtext><msub><mrow></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow></mfrac><mo>-</mo><mfrac><mtext>Τ</mtext><mn>2</mn></mfrac><mo stretchy="false">)</mo><mo>,</mo><mtext>E</mtext><mtext>i</mtext><mo stretchy="false">(</mo><mo>•</mo><mo stretchy="false">)</mo></mrow></math></mathml>表示三维动态视景修正的指数函数。构建三维动态视景图像的多维直方图结构模型,采用模糊相关性特征检测方法实现三维动态视景图像的灰度特征提取,在分辨率调节下,得到多源信息融合输出为</p>
                </div>
                <div class="p1">
                    <p id="73"><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>u</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mtext>Τ</mtext></msqrt></mrow></mfrac><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>t</mtext><mrow><mo>(</mo><mrow><mfrac><mtext>t</mtext><mtext>Τ</mtext></mfrac></mrow><mo>)</mo></mrow><mrow><mi>e</mi><mi>x</mi><mi>p</mi></mrow><mo stretchy="false">{</mo><mo>-</mo><mtext>j</mtext><mo stretchy="false">[</mo><mn>2</mn><mtext>π</mtext><mtext>Κ</mtext><mrow><mi>l</mi><mi>n</mi></mrow><mrow><mo>(</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mtext>t</mtext><mrow><mtext>t</mtext><msub><mrow></mrow><mn>0</mn></msub></mrow></mfrac></mrow><mo>)</mo></mrow><mo stretchy="false">]</mo><mo stretchy="false">}</mo></mrow></math></mathml>      (15)</p>
                </div>
                <div class="p1">
                    <p id="74">式中rect(t)=1,|t|≤1/2。采用高分辨率图像滤波方法,得到三维动态视景的多源信息融合滤波方程</p>
                </div>
                <div class="p1">
                    <p id="75"><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>f</mtext><msub><mrow></mrow><mtext>i</mtext></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mtext>Κ</mtext><mrow><mtext>t</mtext><msub><mrow></mrow><mn>0</mn></msub><mo>-</mo><mtext>t</mtext></mrow></mfrac><mtext> </mtext><mo stretchy="false">|</mo><mtext>t</mtext><mo stretchy="false">|</mo><mo>≤</mo><mfrac><mtext>Τ</mtext><mn>2</mn></mfrac></mrow></math></mathml>      (16)</p>
                </div>
                <div class="p1">
                    <p id="76">其中,K=Tf<sub><i>max</i></sub>f<sub><i>min</i></sub>/B,t<sub>0</sub>=f<sub>0</sub>T/B,f<sub>0</sub>为三维动态视景自修正的正扩散权重,f<sub><i>min</i></sub>,f<sub><i>max</i></sub>分别为最低和最高采用频率。对三维动态视景进行多源信息融合处理后,结合模糊辨识方法,进行修正算法的优化设计<sup><a class="sup">[14]</a></sup>。</p>
                </div>
                <h4 class="anchor-tag" id="77" name="77"><b>3.2 三维动态视景自修正</b></h4>
                <div class="p1">
                    <p id="78">采用小波多尺度分解进行三维动态视景图像的纹理分解和多源信息融合,根据三维动态视景的信息融合结果进行视景重构,在特征尺度d(x)的约束下,得到三维动态视景图像的多重色差核系数c(X,Y)和边缘细节特征s(X,Y),小波多尺度分解模型为</p>
                </div>
                <div class="p1">
                    <p id="79">l(X,Y)=(2u<sub>x</sub>u<sub>y</sub>+C<sub>1</sub>)/(u<mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>x</mtext><mn>2</mn></msubsup></mrow></math></mathml>+u<mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>y</mtext><mn>2</mn></msubsup></mrow></math></mathml>+C<sub>1</sub>)      (17)</p>
                </div>
                <div class="p1">
                    <p id="80">构建三维动态视景图像的多维信息分布模型,采用模糊相关性特征检测方法实现三维动态视景的动态分割和模板匹配<sup><a class="sup">[15]</a></sup>,采用尺度分解方法,得到三维动态视景修正的动态特征分割输出分量U<sub>0</sub>(z<sup>Q</sup>)、U<sub>1</sub>(z<sup>Q</sup>),利用邻域灰度像素匹配的方法,得到三维动态视景自修正的模糊迭代式为</p>
                </div>
                <div class="p1">
                    <p id="81">g=k⨂f+n      (18)</p>
                </div>
                <div class="p1">
                    <p id="82">其中⨂表示卷积算子,设置h为三维动态视景的颜色特征量的边缘像素集,采用三维动态区域规划方法,得到三维动态视景修正的母小波表达式为</p>
                </div>
                <div class="p1">
                    <p id="83"><mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>s</mtext><msub><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>Ρ</mtext><mtext>Μ</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mo>-</mo><mi>∞</mi></mrow><mi>∞</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>j</mtext><mo>=</mo><mn>0</mn></mrow><mrow><mtext>Ν</mtext><msub><mrow></mrow><mtext>p</mtext></msub><mo>-</mo><mn>1</mn></mrow></munderover><mtext>p</mtext></mstyle></mrow></mstyle><mo stretchy="false">(</mo><mtext>t</mtext><mo>-</mo><mtext>i</mtext><mtext>Τ</mtext></mrow></math></mathml><sub>s</sub>-jT<sub>p</sub>-c<sub>j</sub>T<sub>c</sub>-a<sub>i</sub>ε)      (19)</p>
                </div>
                <div class="p1">
                    <p id="84"><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>s</mtext><msub><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>A</mtext><mtext>Μ</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>j</mtext><mo>=</mo><mo>-</mo><mi>∞</mi></mrow><mi>∞</mi></munderover><mtext>d</mtext></mstyle><msub><mrow></mrow><mtext>j</mtext></msub><mtext>p</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo>-</mo><mtext>j</mtext><mtext>Τ</mtext></mrow></math></mathml><sub>s</sub>)      (20)</p>
                </div>
                <div class="p1">
                    <p id="85">式中的T<sub>s</sub>是颜色特征点重构的阈值,在三维动态视景的模板像素集中,动态修正的输出为</p>
                </div>
                <div class="p1">
                    <p id="86"><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>x</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>m</mtext><mo>=</mo><mn>1</mn></mrow><mtext>Μ</mtext></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>k</mtext><mo>=</mo><mn>1</mn></mrow><mrow><mtext>Κ</mtext><mo stretchy="false">(</mo><mtext>m</mtext><mo stretchy="false">)</mo></mrow></munderover><mtext>w</mtext></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>k</mtext></mrow></msub><mtext>s</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo>-</mo><mtext>Τ</mtext><msub><mrow></mrow><mtext>m</mtext></msub><mo>-</mo><mtext>τ</mtext><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>k</mtext></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mtext>v</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></mathml>      (21)</p>
                </div>
                <div class="p1">
                    <p id="87">式中,w<sub>mk</sub>表示系数性的纹理特征分量,结合灰阶信息特征提取方法,在多源信息融合空间中,实现三维动态视景的信息融合和修正,根据自修正结果,得到视景重构输出为</p>
                </div>
                <div class="area_img" id="88">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201911094_08800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="90">其中,η表示三维动态视景的边缘亮度,φ表示三维动态视景稀疏特征分量,R表示三维动态视景的模板匹配系数,D表示边缘模糊像素集。根据对三维动态视景的自修正结果,提高对三维动态视景的辨识能力。</p>
                </div>
                <h3 id="91" name="91" class="anchor-tag"><b>4 仿真与结果分析</b></h3>
                <div class="p1">
                    <p id="92">为了测试本文方法在实现三维动态视景自修正中的应用性能,进行实验分析,结合Visual C++和Matlab R2010进行算法设计,采用Simulink工具读取三维动态视景图像信息,提取颜色特征分量,设定三维动态视景图像的边缘轮廓特征集分布为Hm=0.12,图像的区域分块模板匹配系数为0.27,三维视景的灰度像素集大小M<sub>s</sub>=12,x,y,z方向的边缘像素集为(12,25,60),对三维动态视景自修正的学习迭代次数为120次,仿真步长为20,根据上述仿真环境和参数设定,进行三维动态视景自修正仿真分析,得到待修正的三维动态视景图像如图2所示。</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201911094_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                    <img alt="图2 三维动态视景图像" src="Detail/GetImg?filename=images/JSJZ201911094_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
                                </a>
                                <p class="img_tit"><b>图2 三维动态视景图像</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201911094_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="94">以图2的三维动态视景为测试对象,构建三维动态视景图像的特征分割模型,采用小波多尺度分解进行三维动态视景图像的纹理分解和多源信息融合,得到信息融合输出如图3所示。分析图3得知,采用本文方法能有效实现三维动态视景的多源信息融合。</p>
                </div>
                <div class="area_img" id="95">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201911094_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                    <img alt="图3 三维动态视景的多源信息融合输出" src="Detail/GetImg?filename=images/JSJZ201911094_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
                                </a>
                                <p class="img_tit"><b>图3 三维动态视景的多源信息融合输出</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201911094_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="96">根据信息融合结果,结合模糊特征检测方法,实现三维动态视景图像的清晰化识别,采用纹理修正方法,在多源信息融合空间中实现三维动态视景自修正处理,得到修正输出如图4所示。</p>
                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201911094_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                    <img alt="图4 三维动态视景自修正输出" src="Detail/GetImg?filename=images/JSJZ201911094_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
                                </a>
                                <p class="img_tit"><b>图4 三维动态视景自修正输出</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201911094_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="98">分析图4得知,本文方法进行三维动态视景自修正处理,提高了图像的高分辨识别能力,测试不同方法进行三维动态视景自修正处理后的输出峰值信噪比,得到对比结果如图5所示,分析图5得知,本文方法进行三维动态视景自修正的输出峰值信噪比较高,说明修正的质量较好。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201911094_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">
                                    <img alt="图5 输出性能对比" src="Detail/GetImg?filename=images/JSJZ201911094_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
                                </a>
                                <p class="img_tit"><b>图5 输出性能对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201911094_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="100">测试时间开销,得到对比结果见表1,分析得知,本文方法进行三维动态视景自修正的时间开销较短,实时性较好。</p>
                </div>
                <div class="area_img" id="101">
                    <p class="img_tit"><b>表1 时间开销对比(单位</b>:ms) <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="101" border="1"><tr><td><br />图像样本集</td><td>本文方法</td><td>文献[4]</td><td>文献[5]</td></tr><tr><td><br />100</td><td>2.31</td><td>21.25</td><td>14.33</td></tr><tr><td><br />200</td><td>4.65</td><td>32.44</td><td>18.65</td></tr><tr><td><br />300</td><td>6.54</td><td>54.65</td><td>25.43</td></tr><tr><td><br />400</td><td>8.13</td><td>68.43</td><td>32.36</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="102" name="102" class="anchor-tag"><b>5 结语</b></h3>
                <div class="p1">
                    <p id="103">在三维动态视景的重构过程中,受到图像的边缘像素集的模糊性影响,导致三维动态视景的信息丢失,需要对三维动态视景进行自修正处理,结合图像修复和自适应重建技术,实现三维动态视景重构和识别,本文提出一种基于多源信息融合的三维动态视景自修正方法。采用模糊判断方法进行三维动态视景的自适应加权控制,根据三维动态视景图像的模糊指向性分布进行视觉特征重建,采用三维动态平滑滤波方法,进行三维动态视景的稀疏点重构,根据对三维动态视景图像的网格区域分割结果,采用块匹配方法实现三维动态视景的块区域匹配,采用小波多尺度分解进行三维动态视景图像的纹理分解和多源信息融,在多源信息融合空间中实现三维动态视景自修正处理。研究得知,采用该方法进行三维动态视景重构的自修正能力较好,三维视景的输出峰值信噪比较高。</p>
                </div>
                <div class="area_img" id="135">
                                <img alt="" src="Detail/GetImg?filename=images/JSJZ201911094_13500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
                            <p class="img_tit"></p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="136">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXZZ201812023&amp;v=MjA1MzJyWTlIWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlyZ1c3ckFMelhSZExHNEg5bk4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[1]</b> 陈炜耿,柴琳,赵雅涵.一类改进的红外无损检测技术热波图像序列处理方法[J].机械设计与制造工程,2018,(12):101-106.
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DBSZ201804012&amp;v=MjU1MDk5bk1xNDlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlyZ1c3ckFJUy9ZZExHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[2]</b> 李俊杰,高翠芳,黄芳.基于优化采样支持向量机的指纹二值化方法[J].东北师大学报(自然科学版),2018,50(4):59-65.
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201804048&amp;v=MDc3NjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlyZ1c3ckFMejdCYmJHNEg5bk1xNDlCYklRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[3]</b> 郑乐乐,韩慧妍,韩燮.基于显著性与弱凸性的三维点云模型分割[J].计算机工程,2018,44(4):299-304.
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201607033&amp;v=MjM5NDBJVGZTZHJHNEg5Zk1xSTlHWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlyZ1c3ckE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[4]</b> RUI L L,ZHANG P,HUANG H Q,et al.Reputation-based incentive mechanisms in crowdsourcing[J].Journal of Electronics &amp; Information Technology,2016,38(7):1808-1815.
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Incentive mechanism for mobile crowdsourcing using an optimized tournament model">

                                <b>[5]</b> ZHANG Y,JIANG C,SONG L,et al.Incentive mechanism for mobile crowdsourcing using an optimized tournament model[J].IEEE Journal on Selected Areas in Communications,2017,35(4):880-892.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201808050&amp;v=MTAxNjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmdXN3JBTHo3QmI3RzRIOW5NcDQ5QVpJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[6]</b> 王燕,王双印.基于卷积神经网络的人脸信息增强识别研究[J].计算机科学,2018,45(8):268-271.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201703037&amp;v=MjkwMzVnVzdyQUx6N0JkN0c0SDliTXJJOUdZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[7]</b> 杨伟,谢维成,蒋文波,等.基于自相似性车载采集城市街景图像的重建[J].计算机应用,2017,37(3):817-822.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201402018&amp;v=MDcyNTlBUHlyZmJMRzRIOVhNclk5RWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmdXN3I=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[8]</b> 周雨薇,陈强,孙权森,等.结合暗通道原理和双边滤波的遥感图像增强[J].中国图象图形学报,2014,19(2):313-321.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201403049&amp;v=MTY1MzE0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXJnVzdyQUx6VFpaTEc0SDlYTXJJOUJiWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[9]</b> 郭佳,刘晓玉,吴冰,等.一种光照不均匀图像的二值化方法[J].计算机应用与软件,2014,31(3):183-186.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JCGC201812007&amp;v=Mjc5NzFOclk5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmdXN3JBTHk3TWJiRzRIOW4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[10]</b> 刘杰.基于分布式压缩感知的异源图像融合方法[J].舰船电子工程,2018,38(12):30-33.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201611046&amp;v=MTY4NTVnVzdyQUx6N0JkN0c0SDlmTnJvOUJZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[11]</b> 卞乐,霍冠英,李庆武.基于Curvelet变换和多目标粒子群的混合熵MRI图像多阈值分割[J].计算机应用,2016,36(11):3188-3195.
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGZZ201704023&amp;v=MDAwMzZxQnRHRnJDVVI3cWZadVpwRnlyZ1c3ckFMeXJSZExHNEg5Yk1xNDlIWjRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">

                                <b>[12]</b> 杨旭,陈波,李小阳,等.远距离数字离轴全息中基于图像指标优化的相位误差校正方法[J].激光杂志,2017,38(4):96-100.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201911094" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201911094&amp;v=MDc5NzJGeXJnVzdyQkx6N0JkTEc0SDlqTnJvOU1ZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnA=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hOVEpzeWorTktOTStJV3FqdFBKWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
