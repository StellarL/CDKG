<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141938658100000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201903020%26RESULT%3d1%26SIGN%3dcD0xpWL%252bOn7NuSGYOpMmQHO88do%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201903020&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201903020&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201903020&amp;v=MjcyMzJGeURsVTc3TUx6N0JkTEc0SDlqTXJJOUhaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm0=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#29" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#32" data-title="&lt;b&gt;2 无人机飞行目标导航图像采集系统原理模型&lt;/b&gt; "><b>2 无人机飞行目标导航图像采集系统原理模型</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;2 融合FMS图像分割的无人机半全局立体匹配算法&lt;/b&gt; "><b>2 融合FMS图像分割的无人机半全局立体匹配算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#38" data-title="&lt;b&gt;2.1 SGM算法&lt;/b&gt;"><b>2.1 SGM算法</b></a></li>
                                                <li><a href="#71" data-title="&lt;b&gt;2.2 存在的问题&lt;/b&gt;"><b>2.2 存在的问题</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;2.3 FMS图像分割算法&lt;/b&gt;"><b>2.3 FMS图像分割算法</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;2.4 对SGM算法的改进&lt;/b&gt;"><b>2.4 对SGM算法的改进</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#111" data-title="&lt;b&gt;3.1 参数的确定&lt;/b&gt;"><b>3.1 参数的确定</b></a></li>
                                                <li><a href="#117" data-title="&lt;b&gt;3.2 Middleburry平台测试&lt;/b&gt;"><b>3.2 Middleburry平台测试</b></a></li>
                                                <li><a href="#127" data-title="&lt;b&gt;3.3 实景测试&lt;/b&gt;"><b>3.3 实景测试</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#130" data-title="&lt;b&gt;4 结论&lt;/b&gt; "><b>4 结论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#34" data-title="&lt;b&gt;图1 无人机飞行目标导航图像采集信息系统&lt;/b&gt;"><b>图1 无人机飞行目标导航图像采集信息系统</b></a></li>
                                                <li><a href="#36" data-title="&lt;b&gt;图2&lt;/b&gt; BT&lt;b&gt;插值计算原理&lt;/b&gt;"><b>图2</b> BT<b>插值计算原理</b></a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;图3 一个初始点的迭代过程示意图&lt;/b&gt;"><b>图3 一个初始点的迭代过程示意图</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;图4 不同参数情 况下的分割效果图&lt;/b&gt;"><b>图4 不同参数情 况下的分割效果图</b></a></li>
                                                <li><a href="#119" data-title="&lt;b&gt;图5&lt;/b&gt; m&lt;sub&gt;&lt;b&gt;2&lt;/b&gt;&lt;/sub&gt;&lt;b&gt;不同取值与匹配率的对应关系&lt;/b&gt;"><b>图5</b> m<sub><b>2</b></sub><b>不同取值与匹配率的对应关系</b></a></li>
                                                <li><a href="#123" data-title="&lt;b&gt;图6 视差对比图&lt;/b&gt;"><b>图6 视差对比图</b></a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;表1 匹配精度的实验评判对比 (单位为&lt;/b&gt;%) "><b>表1 匹配精度的实验评判对比 (单位为</b>%) </a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;表2 匹配时间的实验评判对比 (单位为&lt;/b&gt;ms) "><b>表2 匹配时间的实验评判对比 (单位为</b>ms) </a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;图7 实景测试结果&lt;/b&gt;"><b>图7 实景测试结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 顾苏杭, 陆兵, 马正华. 基于轮廓和ASIFT特征的目标检测与跟踪算法[J]. 计算机仿真, 2017, 34 (6) :266-271." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201706057&amp;v=MzAwOTE0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeURsVTc3TUx6N0JkTEc0SDliTXFZOUFZNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         顾苏杭, 陆兵, 马正华. 基于轮廓和ASIFT特征的目标检测与跟踪算法[J]. 计算机仿真, 2017, 34 (6) :266-271.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 张黎. 基于立体视觉的三维建筑物重建技术研究[D]. 上海师范大学, 2012." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1012454048.nh&amp;v=MDMwNzZQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeURsVTc3TVZGMjZITGU5R3RISXA1RWI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         张黎. 基于立体视觉的三维建筑物重建技术研究[D]. 上海师范大学, 2012.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" D Scharstein, R Szeliski. A Taxonomy and Evaluation of Dense Two-frame Stereo Correspondence Algorithms[J]. International Journal of Computer Vision, 2002, 47 (1) : 7-42." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830724&amp;v=MjM2NDFCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaURsVzcvSUlWbz1OajdCYXJPNEh0SE9wNHhGWStrTFkzazV6&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         D Scharstein, R Szeliski. A Taxonomy and Evaluation of Dense Two-frame Stereo Correspondence Algorithms[J]. International Journal of Computer Vision, 2002, 47 (1) : 7-42.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" H Hirschm&#252;ller. Accurate and Efficient Stereo Processing by Semi-global Matching and Mutual Information[J]. Computer Vision and Pattern Recognition, 2005, 2 (2) : 807-814." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accurate and efficient stereo processing by semi-global matching and mutual information">
                                        <b>[4]</b>
                                         H Hirschm&#252;ller. Accurate and Efficient Stereo Processing by Semi-global Matching and Mutual Information[J]. Computer Vision and Pattern Recognition, 2005, 2 (2) : 807-814.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 宁晓斐. 双目立体视觉中半全局立体匹配算法的研究[D]. 辽宁大学, 2014." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014372697.nh&amp;v=MTU2MzE0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeURsVTc3TVZGMjZHckMvSE5mRnFKRWJQSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         宁晓斐. 双目立体视觉中半全局立体匹配算法的研究[D]. 辽宁大学, 2014.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 葛忠孝, 等. 基于树形结构的半全局立体匹配算法[J]. 计算机工程, 2016, 42 (8) : 243-248." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201608044&amp;v=MTYxMjhadVptRnlEbFU3N01MejdCYmJHNEg5Zk1wNDlCWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         葛忠孝, 等. 基于树形结构的半全局立体匹配算法[J]. 计算机工程, 2016, 42 (8) : 243-248.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" S Birchfield, C Tomasi. Depth Discontinuities by Pixel-to-pixelStereo[C]. Proceedings of the 6th International Conference on Computer Vision.Washington D.C. USA: IEEE Press, 1998:1073-1080." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Depth discontinuities by pixel-to-pixel stereo">
                                        <b>[7]</b>
                                         S Birchfield, C Tomasi. Depth Discontinuities by Pixel-to-pixelStereo[C]. Proceedings of the 6th International Conference on Computer Vision.Washington D.C. USA: IEEE Press, 1998:1073-1080.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 高波, 马利庄. 加入结构约束的半全局立体匹配算法[J]. 计算机应用与软件, 2009, 26 (2) :244-247." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ200902085&amp;v=MTY3NDJUWlpMRzRIdGpNclk5TllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5RGxVNzdNTHo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         高波, 马利庄. 加入结构约束的半全局立体匹配算法[J]. 计算机应用与软件, 2009, 26 (2) :244-247.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 陈智君, 等. 区域生长的半全局密集匹配算法[J]. 测绘科学, 2017, 42 (5) :12-16." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHKD201705003&amp;v=MDEwODFpWEFhckc0SDliTXFvOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeURsVTc3TUo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         陈智君, 等. 区域生长的半全局密集匹配算法[J]. 测绘科学, 2017, 42 (5) :12-16.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 倪伟基, 等. 基于色彩分割和自适应窗口的快速立体匹配[J]. 仪器仪表学报, 2011, 32 (1) :194-200." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201101032&amp;v=MzAxMTFtRnlEbFU3N01QRHpUYkxHNEg5RE1ybzlHWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         倪伟基, 等. 基于色彩分割和自适应窗口的快速立体匹配[J]. 仪器仪表学报, 2011, 32 (1) :194-200.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 赵胜男, 王文剑. 一种快速均值漂移图像分割算法[J]. 数据采集与处理, 2015, 30 (1) :192-201." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJCJ201501019&amp;v=Mjc2NDU3cWZadVptRnlEbFU3N01OaWZJWkxHNEg5VE1ybzlFYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         赵胜男, 王文剑. 一种快速均值漂移图像分割算法[J]. 数据采集与处理, 2015, 30 (1) :192-201.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 殷虎. 基于图像分割的立体匹配算法研究[D]. 南京航空航天大学, 2010." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1011252374.nh&amp;v=MDAxNjZxZlp1Wm1GeURsVTc3TVZGMjZIN0c5SE5MTHE1RWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         殷虎. 基于图像分割的立体匹配算法研究[D]. 南京航空航天大学, 2010.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" 盛捷, 等. Mean Shift算法优化带宽的自动搜索[J]. 系统仿真学报, 2011, 23 (12) : 2744-2749." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTFZ201112032&amp;v=MDUzOTREbFU3N01QVG5OZExHNEg5RE5yWTlHWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         盛捷, 等. Mean Shift算法优化带宽的自动搜索[J]. 系统仿真学报, 2011, 23 (12) : 2744-2749.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(03),98-104+163             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>无人机飞行目标导航定位图像优化匹配仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%AD%A6%E5%BC%BA&amp;code=41438520&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武强</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%99%BA&amp;code=30486568&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李智</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%8B%87%E5%86%9B&amp;code=23850927&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王勇军</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E5%B7%A5%E7%A8%8B%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AD%A6%E9%99%A2&amp;code=0269119&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林电子科技大学电子工程与自动化学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E8%88%AA%E5%A4%A9%E5%B7%A5%E4%B8%9A%E5%AD%A6%E9%99%A2%E6%97%A0%E4%BA%BA%E6%9C%BA%E9%81%A5%E6%B5%8B%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=1698417&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林航天工业学院无人机遥测重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>传统的半全局立体匹配算法很好地兼顾了匹配算法的精确性和实时性, 但是算法在处理图像中深度不连续区域误匹配率偏高。针对以上问题, 提出了融合快速均值漂移 (Fast Mean Shift, FMS) 图像分割的无人机 (Unmanned Aerial Vehicle, UAV) 半全局立体匹配算法。将FMS图像分割算法融合到匹配算法的全局能量函数中, 重新构造出更加合理的全局能量函数, 解决了因为不同原因造成视差跳跃而赋值同一的惩罚系数的问题。该算法在Middleburry测试平台进行仿真测试以及基于算法进行无人机实景图像实验, 结果表明:该算法有效降低了图像在深度视差突变区域的误匹配率, 并且能够有效兼顾算法的匹配精度和匹配速度。由此, 改进后的算法满足无人机视觉辅助导航的需求。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%A0%E4%BA%BA%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">无人机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像分割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%8A%E5%85%A8%E5%B1%80%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">半全局匹配;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E5%B7%AE%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">视差图;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    武强 (1991-) , 男 (汉族) , 四川达州人, 硕士研究生, 主要研究方向为计算机视觉和无人机视觉导航;;
                                </span>
                                <span>
                                    李智 (1965-) , 男 (壮族) , 广西壮族自治区灵川县人, 2003年于电子科技大学获得博士学位, 现为桂林航天工业学院教授、西安电子科技大学博士生导师, 主要研究方向为智能仪器系统、现代测试理论与技术;;
                                </span>
                                <span>
                                    王勇军 (1985-) , 男 (汉族) , 山东聊城市人, 分别在2007年和2010年于桂林电子科技大学获得学士学位和硕士学位, 现为桂林航天工业学院讲师、桂林电子科技大学博士研究生, 主要研究方向为无人机组合导航技术。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2017-09-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61361006) ;广西自然科学基金项目 (2015GXNSFBA139251) ;广西自然科学基金重点项目 (2016GXNSFDA380031);</span>
                                <span>广西自动检测技术与仪器重点实验室基金项目 (YQ14203);</span>
                    </p>
            </div>
                    <h1><b>The Simulation on Optimization and Matching of Image for Navigation and Positioning of UAV Flight Target</b></h1>
                    <h2>
                    <span>WU Qiang</span>
                    <span>LI Zhi</span>
                    <span>WANG Yong-jun</span>
            </h2>
                    <h2>
                    <span>School of Electronic Engineering and Automation, Guilin University of Electronic Technology</span>
                    <span>Key Laboratory of Unmanned Aerial Vehicle Telemetry, Guilin University of Aerospace Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The traditional semi-global stereo matching algorithm well balances the accuracy and real-time performance of matching algorithm, however, which has a high mismatching rate of the depth discontinuity regions in the image processing. In view of the above problem, the unmanned aerial vehicle (UAV) Semi-global Matching Algorithm through Fusion of Fast Mean Shift (FMS) Image Segmentation is proposed. The FMS image segmentation algorithm was integrated into the global energy function of the matching algorithm to reconstruct a more reasonable global energy function, which solves the problem of assigning the same penalty coefficient for disparity mutations due to different reasons. The simulation test based on the algorithm was carried out on the Middle burry test platform. And based on the proposed algorithm, a real scene image filmed by UAV experiment was conducted. The results show that the algorithm effectively reduces the mismatching rate of the images in the depth disparity mutation regions and balances the matching accuracy and matching speed of the algorithm. Therefore, the improved algorithm can meet the requirements of UAV vision assisted navigation.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=UAVs&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">UAVs;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Image segmentation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Semi-global%20matching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Semi-global matching;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Disparity%20map&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Disparity map;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2017-09-25</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="29" name="29" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="30">复杂背景下的目标识别与三维重建一直是图像处理、模式识别以及计算机视觉等领域的研究热点, 有着重要的研究意义和应用价值, 尤其是近年来将其与无人机的导航与避障相结合, 成为无人机实现智能化的关键技术<citation id="132" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。计算机视觉技术中的双目立体匹配技术是利用双目摄像头在无人机飞行过程中, 获得同一目标物体在不同角度下拍摄的左右视图, 两视图在同一目标点上的位置偏差由三角测量原理计算所得, 从而获得目标物体的场景深度, 根据所获得的深度信息, 再结合三维重建技术重构出周围环境的3D立体景象<citation id="133" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 进而辅助无人机进行自主导航与避障。由于飞行器飞行速度快, 视角变换复杂, 提供一种同时兼顾实时性和准确性的立体匹配算法成为研究的关键。</p>
                </div>
                <div class="p1">
                    <p id="31">在众多的立体匹配算法中, 文献<citation id="134" type="reference">[<a class="sup">3</a>]</citation>将立体匹配算法分为2类: (1) 局部立体匹配算法, 该类算法方法简单, 匹配速度快, 实时性较好, 但是在遮挡区域的处理效果较差; (2) 全局立体匹配算法, 该类算法采用对整幅图像制定约束策略, 能够有效降低图像在遮挡和弱纹理区域的误匹配率, 但是处理时间较长, 实时性较差。全局算法中的半全局立体匹配算法 (Semi-Global Matching, SGM) , 本质上是一种对动态规划方法的改进, 在提高匹配精度的同时兼顾了算法的实时性。文献<citation id="135" type="reference">[<a class="sup">4</a>]</citation>中所提出的SGM算法, 很好地兼顾了算法的准确性和实时性, 但是该方法在视差深度跳跃区域的误匹配率较高。文献<citation id="136" type="reference">[<a class="sup">5</a>]</citation>中所提MS (Mean Shift) +SGM算法, 很好地解决了SGM算法的上述问题, 但是由于采用经典的MS图像分割算法, 迭代运算时间较长, 额外增加了立体匹配算法的运行时间开销, 进而难以达到无人机的实时性要求。针对以上问题, 在保留SGM算法整体框架和能够应用SIMD (Single Instruction Multiple Data) 能力的基础上, 提出了一种融合FMS图像分割的无人机半全局立体匹配算法。实验证明, 本文算法能够很好的兼顾双目匹配的匹配速度和匹配精度, 从而使其进一步应用于无人机的辅助导航与避障。</p>
                </div>
                <h3 id="32" name="32" class="anchor-tag"><b>2 无人机飞行目标导航图像采集系统原理模型</b></h3>
                <div class="p1">
                    <p id="33">无人机的导航一般由GPS和IMU (惯性测量单元) 的联合位姿导航系统完成, 但是由于在复杂低空环境下GPS信号微弱且不稳定, IMU系统容易产生累积误差, 这样就致使无人机难以获得可靠的导航数据。在联合位姿导航系统中融入双目视觉导航, 能够有效地解决无人机在上述环境下导航信息不足的问题。而且双目立体视觉技术是实现无人机进行自主导航与避障的一项关键技术。整个无人机飞行目标导航图像采集信息系统如图1所示。双目视觉系统一般由图像获取、摄像机标定、特征提取、立体匹配和三维重建这5个步骤构成, 其中立体匹配是双目视觉系统中最为关键的核心一步。</p>
                </div>
                <div class="area_img" id="34">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201903020_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 无人机飞行目标导航图像采集信息系统" src="Detail/GetImg?filename=images/JSJZ201903020_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 无人机飞行目标导航图像采集信息系统</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201903020_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="35">双目立体匹配就是在左右视图中寻找同一场景下的对应关系, 其算法的关键部分是先建立一个基于能量的代价评估函数, 然后再针对该函数进行最优化处理。在实际的无人机导航与避障的应用情况下, 需要有效的兼顾算法的匹配精度和匹配速度, 本文针对这个问题进行算法的改进。</p>
                </div>
                <div class="area_img" id="36">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201903020_036.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 BT插值计算原理" src="Detail/GetImg?filename=images/JSJZ201903020_036.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2</b> BT<b>插值计算原理</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201903020_036.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="37" name="37" class="anchor-tag"><b>2 融合FMS图像分割的无人机半全局立体匹配算法</b></h3>
                <h4 class="anchor-tag" id="38" name="38"><b>2.1 SGM算法</b></h4>
                <div class="p1">
                    <p id="39">SGM算法在求解全局能量函数最小值的问题上是一个NP (Non-Deterministic Polynomial) 完全问题。因此, 其解决办法的核心思想是利用动态规划的方法, 将多个方向的一维路径能量最优进行聚合, 从而达到近似一个二维全局最优的目的<citation id="137" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。其中基于点的匹配代价计算是SGM算法的基础。</p>
                </div>
                <h4 class="anchor-tag" id="40" name="40">2.1.1 基于点的匹配代价计算</h4>
                <div class="p1">
                    <p id="41">SGM算法中的匹配代价计算一般有两种方法。互信息 (Mutual Information, MI) 法和BT插值法。前者对光照变化有较好的鲁棒性, 但是MI方法中含有卷积运算, 运算效率较低。后者由Birchfield和Tomasi<citation id="138" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出的一种简称为“BT插值法”, 该方法不仅抗噪能力强而且仅含有单一的加减运算, 运算实现性相对较好。因此本文采用BT插值法。</p>
                </div>
                <div class="p1">
                    <p id="42">如图2所示, 示意图中的<i>x</i><sub><i>i</i></sub>和<i>y</i><sub><i>i</i></sub>分别表示左右视图中的待匹配点对, <i>IL</i>, <i>IR</i>分别表示左右视图上某一对应极线的灰度函数, 则有如下定义</p>
                </div>
                <div class="p1">
                    <p id="43"><mathml id="44"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msubsup><mrow></mrow><mi>R</mi><mo>-</mo></msubsup><mo>≡</mo><mi>Ι</mi><msubsup><mrow></mrow><mi>R</mi><mo>´</mo></msubsup><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>R</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi>Ι</mi><msub><mrow></mrow><mi>R</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="45"><mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msubsup><mrow></mrow><mi>R</mi><mo>+</mo></msubsup><mo>≡</mo><mi>Ι</mi><msubsup><mrow></mrow><mi>R</mi><mo>´</mo></msubsup><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>R</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi>Ι</mi><msub><mrow></mrow><mi>R</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="47"><i>I</i><sub>min</sub>=min (<i>I</i><sup>-</sup><sub><i>R</i></sub>, <i>I</i><sup>+</sup><sub><i>R</i></sub>, <i>I</i><sub><i>R</i></sub> (<i>y</i><sub><i>i</i></sub>) )       (3) </p>
                </div>
                <div class="p1">
                    <p id="48"><i>I</i><sub>max</sub>=max (<i>I</i><sup>-</sup><sub><i>R</i></sub>, <i>I</i><sup>+</sup><sub><i>R</i></sub>, <i>I</i><sub><i>R</i></sub> (<i>y</i><sub><i>i</i></sub>) )       (4) </p>
                </div>
                <div class="p1">
                    <p id="49">由此, 可以定义基于“<i>BT</i>插值法”的匹配代价为</p>
                </div>
                <div class="p1">
                    <p id="50"><i>C</i><sub><i>BT</i></sub> (<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>, <i>I</i><sub><i>L</i></sub>, <i>I</i><sub><i>R</i></sub>) =max{0, <i>I</i><sub><i>L</i></sub> (<i>x</i><sub><i>i</i></sub>) -<i>I</i><sub>max</sub>, </p>
                </div>
                <div class="p1">
                    <p id="51"><i>I</i><sub>min</sub>-<i>I</i><sub><i>L</i></sub> (<i>x</i><sub><i>i</i></sub>) }      (5) </p>
                </div>
                <h4 class="anchor-tag" id="52" name="52">2.1.2 匹配代价聚合和深度赋值</h4>
                <div class="p1">
                    <p id="53">在不考虑噪声、弱纹理、遮挡等问题的情况下, 根据上述基于点的匹配代价计算方法, 聚合左右视图所有匹配点对的代价, 能够得到一个最小的匹配代价之和。其能量计算公式如下</p>
                </div>
                <div class="p1">
                    <p id="54"><mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>p</mi></munder><mi>C</mi></mstyle><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>D</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="56">但是在实际情况下, 存在诸如噪声、弱纹理、遮挡等问题, 因为基于点的匹配计算, 考虑的是像素点或者像素点的领域特征, 在上述干扰环境下, 仅仅以基于点的匹配代价进行代价聚合的方式并不能够适用于所有的匹配区域, 这样往往就存在错误的匹配代价极有可能小于正确的匹配代价的情况。另一个更为严重的问题是, 如果采用动态规划的思想进行匹配代价聚合, 那么错误的匹配代价计算如同多米诺效应一般, 不断向周围进行扩散, 一旦出现该情况, 所生成的深度信息图不再具有应用于无人机视觉辅助导航与避障的价值。</p>
                </div>
                <div class="p1">
                    <p id="57">因此, 在<i>SGM</i>算法中, 对 (6) 式额外添加一个平滑约束对领域内不同程度的视差变化进行区别对待, 加以不同的惩罚。新构成的能量函数定义如下</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>p</mi></munder><mi>C</mi></mstyle><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>D</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>q</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>p</mi></msub></mrow></munder><mi>Ρ</mi></mstyle><msub><mrow></mrow><mn>1</mn></msub><mi>Τ</mi><mo stretchy="false">[</mo><mo stretchy="false">|</mo><mi>D</mi><msub><mrow></mrow><mi>p</mi></msub><mo>-</mo><mi>D</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">|</mo><mo>=</mo><mn>1</mn><mo stretchy="false">]</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mspace width="0.25em" /><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>q</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>Ρ</mi></msub></mrow></munder><mi>Ρ</mi></mstyle><msub><mrow></mrow><mn>2</mn></msub><mi>Τ</mi><mo stretchy="false">[</mo><mo stretchy="false">|</mo><mi>D</mi><msub><mrow></mrow><mi>p</mi></msub><mo>-</mo><mi>D</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">|</mo><mo>&gt;</mo><mn>1</mn><mo stretchy="false">]</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">其中 (7) 式右侧<mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>p</mi></munder><mi>C</mi></mstyle><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>D</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>项表示视图中所有像素点的匹配代价聚合。<i>T</i>[]为截断函数, 当且仅当其括号内的参数为真时其值为1, 否则为0。第二项和第三项即为所引入的平滑约束机制。<i>P</i><sub>1</sub>和<i>P</i><sub>2</sub>为约束项的惩罚系数<citation id="139" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。当视差变化量较小时, 赋值一个较小的惩罚系数<i>P</i><sub>1</sub>, 当视差变化量较大时, 赋值一个较大的惩罚系数<i>P</i><sub>2</sub>, 另外, 需要保证<i>p</i><sub>2</sub>&gt;<i>p</i><sub>1</sub>。 <i>P</i><sub>2</sub>的表达式通常由对应点的颜色强度值<i>I</i><sub><i>bp</i></sub>, <i>I</i><sub><i>bq</i></sub>确定, 如 (8) 式所示</p>
                </div>
                <div class="p1">
                    <p id="61"><mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mfrac><mrow><mi>p</mi><msubsup><mrow></mrow><mn>2</mn><mo>´</mo></msubsup></mrow><mrow><mo stretchy="false">|</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>p</mi></mrow></msub><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>q</mi></mrow></msub><mo stretchy="false">|</mo></mrow></mfrac></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="63">SGM算法在求解<i>E</i> (<i>D</i>) 最优解的过程中, 采用降维的思想, 将多个方向的一维路径能量最优进行聚合, 从而达到近似一个二维全局最优的目的<citation id="140" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。因此<i>SGM</i>算法是沿着8个或者16个一维路径聚合匹配代价</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo><mo>=</mo><mi>C</mi><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo><mo>+</mo><mrow><mi>min</mi></mrow><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mi>L</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>-</mo><mi>r</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>L</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>-</mo><mi>r</mi><mo>, </mo><mi>d</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo></mtd></mtr><mtr><mtd><mi>L</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>-</mo><mi>r</mi><mo>, </mo><mi>d</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo></mtd></mtr><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext><mi>L</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>-</mo><mi>r</mi><mo>, </mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mstyle><mi>i</mi></munder></mtd></mtr></mtable></mrow><mo>) </mo></mrow></mtd></mtr><mtr><mtd><mo>-</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>k</mi></munder><mi>L</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>-</mo><mi>r</mi><mo>, </mo><mi>k</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">上式表示的是像素点<i>p</i>在视差为<i>d</i>沿<i>r</i>方向的代价函数, 第1项<i>C</i> (<i>p</i>, <i>d</i>) 表示对像素点<i>p</i>赋值深度<i>d</i>的匹配代价;第2项表示当前路径上的上一个匹配点的最小匹配代价;第3项表示为了避免<i>L</i>过大, 所添加的一个约束项。</p>
                </div>
                <div class="p1">
                    <p id="66">最终, 将所有方向上的匹配代价进行聚合</p>
                </div>
                <div class="p1">
                    <p id="67"><mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>r</mi></munder><mi>L</mi></mstyle><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (10) </p>
                </div>
                <h4 class="anchor-tag" id="69" name="69">2.1.3 视差精化</h4>
                <div class="p1">
                    <p id="70">在得到所有像素点的匹配代价<i>S</i> (<i>p</i>, <i>d</i>) 之后, 所生成的是存在噪声点或者异常深度突变的原始视差图, 考虑到计算时间和滤波效果, 本文采用<i>median</i>滤波对原始视差图进行处理。由于半全局立体匹配算法采用了动态规划的思想, 这样就导致该算法对遮挡问题处理欠佳, 因此最后再对视差图进行左右一致性约束处理。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71"><b>2.2 存在的问题</b></h4>
                <div class="p1">
                    <p id="72">尽管<i>SGM</i>算法具有很多优点, 但是该算法在处理图像中深度不连续区域误匹配率偏高。因为在视差图中, 视差跳跃的地方可能是由遮挡、弱纹理和误匹配引起的, 但是也有可能是由物体本身的边界引起的, 因此, 如果在 (7) 式中继续采用统一的<i>P</i><sub>2</sub>进行惩罚, 会引起深度边界的模糊不清以及误匹配偏高的问题。根据视差图的先验知识可知, 视差在同一分割区域内是平滑变化的, 分割块的边界总是伴随着视差跳跃。因此, 利用图像分割信息能够提高图像在视差不连续和弱纹理区域的匹配精度<citation id="141" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。为解决这一问题, 本文提出了融合<i>FMS</i>图像分割的无人机半全局立体匹配算法。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73"><b>2.3 FMS图像分割算法</b></h4>
                <div class="p1">
                    <p id="74">FMS算法是一种对MS算法进行改进了的图像分割算法。给定<i>d</i>维空间<i>R</i><sup><i>d</i></sup>中的<i>n</i>个样本点<i>x</i><sub><i>i</i></sub>, <i>i</i>=1, 2, ..., <i>n</i>, 选择一个中心点<i>x</i>作为初始点, <i>h</i>为半径做一个高维球<citation id="142" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。由<i>MS</i>算法原理可知, 图像像素点的偏移向量为</p>
                </div>
                <div class="p1">
                    <p id="75"><mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>G</mi></mstyle><mo stretchy="false"> (</mo><mfrac><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>x</mi></mrow><mi>h</mi></mfrac><mo stretchy="false">) </mo><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>G</mi></mstyle><mo stretchy="false"> (</mo><mfrac><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>x</mi></mrow><mi>h</mi></mfrac><mo stretchy="false">) </mo><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>-</mo><mi>x</mi></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="77">式中<i>G</i> (<i>x</i>) 是核函数, <i>h</i>是带宽, <i>w</i> (<i>x</i>) 是样本点的权值<citation id="143" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 由 (11) 式进一步可以得出均值漂移量为</p>
                </div>
                <div class="p1">
                    <p id="78"><mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>m</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>G</mi></mstyle><mo stretchy="false"> (</mo><mfrac><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>x</mi></mrow><mi>h</mi></mfrac><mo stretchy="false">) </mo><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>G</mi></mstyle><mo stretchy="false"> (</mo><mfrac><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>x</mi></mrow><mi>h</mi></mfrac><mo stretchy="false">) </mo><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>      (12) </p>
                </div>
                <div class="p1">
                    <p id="80">由 (11) 和 (12) 可以得出图像像素点的均值漂移量为</p>
                </div>
                <div class="p1">
                    <p id="81"><i>m</i><sub><i>h</i></sub> (<i>x</i>) =<i>M</i><sub><i>h</i></sub> (<i>x</i>) +<i>x</i>      (13) </p>
                </div>
                <div class="p1">
                    <p id="82">上式表明均值漂移向量<i>m</i><sub><i>h</i></sub> (<i>x</i>) 总是指向概率密度增大的方向, MS算法是一种统计迭代算法, 为了获得较高的计算精度, 需要进行多次的迭代运算, 其计算代价相当大, 因此将MS算法融合到半全局立体匹配算法中, 会额外增加立体匹配算法的运行时间开销, 进而难以达到无人机的实时性要求。本文采用将FMS图像分割算法融合到半全局立体匹配算法中。</p>
                </div>
                <div class="p1">
                    <p id="83">FMS图像分割算法对图像进行分割时, 仅利用少量的像素点作为初始点进行迭代, 对于出现在高维球区域内的其它像素点根据其到已有类中心的距离进行归类因而减少了迭代次数, 缩短了分割时间。</p>
                </div>
                <div class="p1">
                    <p id="84">假设第<i>t</i>次迭代中, 高维球内的样本点集为<i>S</i><sup> (<i>t</i>) </sup>={<i>x</i><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>, <i>x</i><mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>, <i>x</i><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>, …, <i>x</i><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>}, 聚类中心集合为<i>T</i><sup> (<i>t</i>) </sup>={<i>y</i><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>, <i>y</i><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>, <i>y</i><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>, …, <i>y</i><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>}, 她们的初始值设置为<i>S</i><sup> (0) </sup>=<i>T</i><sup> (0) </sup>=<i>S</i>, 在第<i>t</i>次迭代时, 迭代公式为:</p>
                </div>
                <div class="p1">
                    <p id="93"><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>∈</mo><mi>S</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msup></mrow></munder><mi>Κ</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>-</mo><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>∈</mo><mi>S</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msup></mrow></munder><mi>Κ</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>-</mo><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mn>3</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi></mrow></math></mathml>      (14) </p>
                </div>
                <div class="p1">
                    <p id="95">产生新的聚类中心集合为<mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><mrow><mo>{</mo><mrow><mi>y</mi><msubsup><mrow></mrow><mn>1</mn><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>, </mo><mi>y</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>, </mo><mi>y</mi><msubsup><mrow></mrow><mn>3</mn><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>y</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>}</mo></mrow></mrow></math></mathml>, 并以此替代样本集<i>S</i><sup> (<i>t</i>+1) </sup>=<i>T</i><sup> (<i>T</i>+1) </sup>, 然后进行下一次迭代。整个迭代过程直至<i>S</i><sup> (<i>t</i>+1) </sup>=<i>S</i><sup> (<i>t</i>) </sup>或<i>T</i><sup> (<i>t</i>+1) </sup>=<i>T</i><sup> (<i>t</i>) </sup>结束。</p>
                </div>
                <div class="p1">
                    <p id="97">图3是该<i>FMS</i>图像分割一个初始点的迭代过程示意图。</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201903020_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 一个初始点的迭代过程示意图" src="Detail/GetImg?filename=images/JSJZ201903020_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 一个初始点的迭代过程示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201903020_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="99">在图<b>3</b>中, 小黑点表示图像中的像素点, 初始状态下, 所有的像素点都标记为<b>0</b>, 表示没有被迭代访问<citation id="144" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。图 (a) 中, 大圆圈表示以一个初始点为中心的高维球, 其半径为带宽<i>h</i>, 高维球内的所有点标记为<b>1</b>, 表示已经被访问过, 箭头所指的方向表示计算所得的MS向量的方向;图 (b) 中, 是进行均值漂移后的情况, 以新的位置作为中心点产生一个新的高维球, 计算均值漂移向量, 对高维球内的点做访问标记, 然后再根据计算的均值漂移向量进行重新漂移, 不断重复该过程;图 (c) 中, 实圆圈表示初始点进行迭代运算的最终结果, 初始点经过漂移, 收敛到像素点密度最大的地方。虚圆圈圈住的点表示迭代过程中被访问过的点, 这些点将不再作为初始点进行迭代<citation id="145" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="100">用<i>ρ</i>=<b>3</b>维向量的二维网格来表示彩色图像, 网格点所在的空间表示图像的空间域, 而颜色所在的空间表示图像的色彩域, 二者可以组成一个<i>ρ</i>+<b>2</b>维的向量<i>x</i>= (<i>x</i><sup><i>s</i></sup>, <i>x</i><sup><i>r</i></sup>) , <i>x</i><sup><i>s</i></sup>表示网格点的空间部分, <i>x</i><sup><i>r</i></sup>表示网格点的颜色部分, 由于二者完全不同, 要经过适当的归一化处理补偿<citation id="146" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 其表达式为</p>
                </div>
                <div class="p1">
                    <p id="101"><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><msub><mrow></mrow><mrow><mi>h</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi>h</mi><msub><mrow></mrow><mi>r</mi></msub></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mi>C</mi><mrow><mi>h</mi><msubsup><mrow></mrow><mi>s</mi><mn>2</mn></msubsup><mi>h</mi><msubsup><mrow></mrow><mi>r</mi><mi>ρ</mi></msubsup></mrow></mfrac><mi>k</mi><mrow><mo> (</mo><mrow><mrow><mrow><mo>|</mo><mrow><mfrac><mrow><mi>x</mi><msup><mrow></mrow><mi>s</mi></msup></mrow><mrow><mi>h</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></mfrac></mrow><mo>|</mo></mrow></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>) </mo></mrow><mi>k</mi><mrow><mo> (</mo><mrow><mrow><mrow><mo>|</mo><mrow><mfrac><mrow><mi>x</mi><msup><mrow></mrow><mi>r</mi></msup></mrow><mrow><mi>h</mi><msub><mrow></mrow><mi>r</mi></msub></mrow></mfrac></mrow><mo>|</mo></mrow></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>) </mo></mrow></mrow></math></mathml> (<b>15</b> ) </p>
                </div>
                <div class="p1">
                    <p id="103">其中<i>k</i> (<i>x</i>) 是用在两个域中的公共函数, <i>h</i><sub><i>s</i></sub>, <i>h</i><sub><i>r</i></sub>是核带宽, <i>C</i>是相应的归一化常数<citation id="147" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104"><b>2.4 对SGM算法的改进</b></h4>
                <div class="p1">
                    <p id="105">由视差图的先验知识可知, 视差在同一分割区域块内是平滑变化的, 分割块的边界总是伴随着视差跳跃<citation id="148" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。根据这样的一个先验知识, 本文结合图像分割算法能够对图像提供场景结构信息, 将FMS图像分割融合到半全局立体匹配算法中, 进而构造一个改进的全局能量函数, 如 (16) 、 (17) 式所示, 在原有的惩罚系数<i>P</i><sub>2</sub>的基础上, 对于不同分割区域块的视差跳跃给予不同的惩罚系数。当视差跳跃处于不同的分割区域块时, 赋值一个较小的惩罚系数<i>m</i><sub>1</sub>, 当视差跳跃处于同一分割区域块内时, 赋值一个较大惩罚系数<i>m</i><sub>2</sub>。其中<i>m</i>的取值由实验获得。</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>p</mi></munder><mi>C</mi></mstyle><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>D</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>q</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>p</mi></msub></mrow></munder><mi>Ρ</mi></mstyle><msub><mrow></mrow><mn>1</mn></msub><mi>Τ</mi><mo stretchy="false">[</mo><mo stretchy="false">|</mo><mi>D</mi><msub><mrow></mrow><mi>p</mi></msub><mo>-</mo><mi>D</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">|</mo><mo>=</mo><mn>1</mn><mo stretchy="false">]</mo><mo>+</mo></mtd></mtr><mtr><mtd><mspace width="0.25em" /><mspace width="0.25em" /><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>q</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>Ρ</mi></msub></mrow></munder><mi>m</mi></mstyle><mi>Ρ</mi><msub><mrow></mrow><mn>2</mn></msub><mi>Τ</mi><mo stretchy="false">[</mo><mo stretchy="false">|</mo><mi>D</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo>-</mo><mi>D</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">|</mo><mo>&gt;</mo><mn>1</mn><mo stretchy="false">]</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="107">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201903020_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h3 id="109" name="109" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="110">本文算法分两部分进行测试:一方面在Middleburry测试平台上进行实验测试, 另外一方面对搭建双目摄像头的无人机所拍摄的实景图像进行实验测试。本文实验在Intel (R) core (TM) i5-4590 CPU , 3.30GHz, 内存为4.0GHz的硬件平台下进行, 实验的运行环境为:vs2015和opencv2.4.9。</p>
                </div>
                <h4 class="anchor-tag" id="111" name="111"><b>3.1 参数的确定</b></h4>
                <h4 class="anchor-tag" id="112" name="112">3.1.1 确定FMS图像分割的参数</h4>
                <div class="p1">
                    <p id="113">FMS图像分割中主要需要确定两个参数的值, 分别是空间域带宽h<sub>s</sub>, 颜色域带宽h<sub>r</sub>。首先将M设置为25, 本文选用Middleburry标准图库里的teddy、cones、tsukuba、venus这四幅测试图进行参数的确定。从实验结果来看, h<sub>s</sub>和h<sub>r</sub>如果越大, 分割的区域块也偏大, 容易导致欠分割现象;反之, 则会出现过分割现象。这两种极端的图像分割现象都不利于对SGM算法进行改进。因此, 通过实验要选定合适的带宽参数。在实验程序中, 为了使颜色分割区域更加明显突出, 采用了漫水填充法, 通过对在不同参数下获得的分割图进行比较, 最终选定h<sub>s</sub>=10, h<sub>r</sub>=7, M=25。下图为四幅测试图不同参数情况下的分割效果图。</p>
                </div>
                <div class="area_img" id="114">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201903020_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同参数情 况下的分割效果图" src="Detail/GetImg?filename=images/JSJZ201903020_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 不同参数情 况下的分割效果图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201903020_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="115" name="115"><b>3.1.2</b> 确定惩罚系数m</h4>
                <div class="p1">
                    <p id="116">对于视差跳跃的区域本文采用了根据不同情况重新赋值惩罚系数的方法。当视差跳跃处于不同的分割区域块时, 赋值一个较小的惩罚系数m<sub><b>1</b></sub>, 为了承袭经典SGM算法里视差跳跃惩罚系数P<sub><b>2</b></sub>的功能, 将m<sub><b>1</b></sub>设为<b>1</b>。当视差跳跃处于同一分割区域块内时, 赋值一个较大惩罚系数m<sub><b>2</b></sub>。该实验对四幅标准图进行测试, 当m<sub><b>2</b></sub>取值为<b>5</b>时, tsukuba和teddy达到最高匹配率, 当m<sub><b>2</b></sub>取值为<b>6</b>的时, cones和venus达到最高匹配率。综合这两个情况, 将m<sub><b>2</b></sub>赋值为<b>5.5</b>。图<b>5</b>为m<sub><b>2</b></sub>的不同取值与匹配率的对应关系。</p>
                </div>
                <h4 class="anchor-tag" id="117" name="117"><b>3.2 Middleburry平台测试</b></h4>
                <div class="p1">
                    <p id="118">为了验证本文算法在视差跳跃区域的处理效果优于传统的半全局立体匹配算法, 对Middleburry标准图库里的四幅测试图分别在SGM算法, MS+SGM算法, FMS+SGM算法下进行对比分析。</p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201903020_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 m2不同取值与匹配率的对应关系" src="Detail/GetImg?filename=images/JSJZ201903020_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5</b> m<sub><b>2</b></sub><b>不同取值与匹配率的对应关系</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201903020_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="120">本文采用了误匹配率<i>B</i>作为评判依据, 对几种算法的性能进行客观地评价, 其表达式如 (<b>18</b>) 所示, 其中<i>N</i>为图像的大小, <i>d</i><sub><i>C</i></sub> (<i>x</i>, <i>y</i>) 为改进后算法所计算的视差值, <i>d</i><sub><i>T</i></sub> (<i>x</i>, <i>y</i>) 为数据集的标准视差值, <i>δ</i><sub><i>d</i></sub> (一般取值为<b>1</b>) 为视差误差的容差。</p>
                </div>
                <div class="p1">
                    <p id="121"><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>B</mi><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></munder><mo stretchy="false"> (</mo></mstyle><mo stretchy="false">|</mo><mi>d</mi><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>d</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mo>&gt;</mo><mi>δ</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml> (<b>18</b>) </p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201903020_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 视差对比图" src="Detail/GetImg?filename=images/JSJZ201903020_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 视差对比图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201903020_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="124">
                    <p class="img_tit"><b>表1 匹配精度的实验评判对比 (单位为</b>%)  <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="124" border="1"><tr><td rowspan="2"><br />方法</td><td colspan="3"><br />teddy</td><td colspan="3">cones</td><td colspan="3">tsukuba</td><td colspan="3">venus</td></tr><tr><td><br />nonocc</td><td>all</td><td>disc</td><td>nonocc</td><td>all</td><td>disc</td><td>nonocc</td><td>all</td><td>disc</td><td>nonocc</td><td>all</td><td>disc</td></tr><tr><td><br />SGM</td><td>6.02</td><td>12.2</td><td>16.3</td><td>3.06</td><td>9.75</td><td>8.90</td><td>3.26</td><td>3.96</td><td>12.8</td><td>1.0</td><td>1.57</td><td>11.3</td></tr><tr><td><br />MS+SGM</td><td>10.26</td><td>15.74</td><td>6.2</td><td>5.82</td><td>13.3</td><td>8.18</td><td>5.65</td><td>7.01</td><td>10.3</td><td>12.83</td><td>13.6</td><td>11.2</td></tr><tr><td><br />FMS+SGM</td><td>10.20</td><td>15.80</td><td>15.3</td><td>5.83</td><td>13.8</td><td>8.20</td><td>5.78</td><td>6.85</td><td>9.8</td><td>12.75</td><td>13.5</td><td>10.9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"> (上表中nonocc表示除遮挡外部分的误匹配百分比, all表示所有部分的误匹配百分比, disc表示视差深度不连续变化部分的误匹配百分比) </p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="125">
                    <p class="img_tit"><b>表2 匹配时间的实验评判对比 (单位为</b>ms)  <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="125" border="1"><tr><td><br />方法</td><td>teddy</td><td>cones</td><td>tsukuba</td><td>venus</td></tr><tr><td><br />SGM</td><td>665</td><td>667</td><td>362</td><td>494</td></tr><tr><td><br />MS+SGM</td><td>755</td><td>776</td><td>443</td><td>558</td></tr><tr><td><br />FMS+SGM</td><td>685</td><td>673</td><td>389</td><td>512</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="126">对比以上实验结果, 从匹配精度上看, 本文的FMS+SGM算法跟MS+SGM在nonocc, all, disc三项中的效果相当, 这是因为二者都属于融合图像分割的半全局立体匹配算法, 虽然二者在nonocc和all上的误匹配率高于SGM算法, 但是二者在disc的误匹配率都要低于SGM算法, 说明了本文的算法在深度视差跳跃区域的处理效果良好。从匹配时间上看, MS+SGM和FMS+SGM的耗时均比SGM算法用时多, 这是应为二者都融合了图像分割算法的缘故, 但是FMS+SGM算法比MS+SGM算法的用时少, 因为FMS并非采用图像中的所有像素点进行迭代运算, 所以迭代次数比MS少了很多, 因此前者相比后者耗时较少。</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127"><b>3.3 实景测试</b></h4>
                <div class="p1">
                    <p id="128">为了进一步验证本文算法在真实场景中的实际效果, 使用搭建有双目摄像头的无人机进行实景拍摄, 如图7中的 (a) 、 (b) , 图 (c) 为结果视差图。从图 (c) 中可以看出, 视差图中的三个物体边缘轮廓大体清晰, 算法的处理效果基本满意。但是由于双目摄像头标定精度及周围环境噪声的影响, 在一定程度上降低了匹配精度。</p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201903020_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 实景测试结果" src="Detail/GetImg?filename=images/JSJZ201903020_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 实景测试结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201903020_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="130" name="130" class="anchor-tag"><b>4 结论</b></h3>
                <div class="p1">
                    <p id="131">本文提出了融合FMS图像分割的无人机半全局立体匹配算法。将FMS图像分割算法融合到SGM算法的能量函数中, 该算法相比传统的SGM算法, 有效解降低了在深度不连续区域的误匹配率, 并且运行速度比MS+SGM算法要快。因此, 改进后的算法可以有效兼顾立体匹配算法的匹配精度和匹配速度, 能够很好的应用于无人机的视觉辅助导航中。</p>
                </div>
                <div class="area_img" id="149">
                                <img alt="" src="Detail/GetImg?filename=images/JSJZ201903020_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201706057&amp;v=Mjk1NzN5RGxVNzdNTHo3QmRMRzRIOWJNcVk5QVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 顾苏杭, 陆兵, 马正华. 基于轮廓和ASIFT特征的目标检测与跟踪算法[J]. 计算机仿真, 2017, 34 (6) :266-271.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1012454048.nh&amp;v=MDMxMjZlOUd0SElwNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnlEbFU3N01WRjI2SEw=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 张黎. 基于立体视觉的三维建筑物重建技术研究[D]. 上海师范大学, 2012.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830724&amp;v=MjA2MDNJSVZvPU5qN0Jhck80SHRIT3A0eEZZK2tMWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaURsVzcv&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> D Scharstein, R Szeliski. A Taxonomy and Evaluation of Dense Two-frame Stereo Correspondence Algorithms[J]. International Journal of Computer Vision, 2002, 47 (1) : 7-42.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accurate and efficient stereo processing by semi-global matching and mutual information">

                                <b>[4]</b> H Hirschmüller. Accurate and Efficient Stereo Processing by Semi-global Matching and Mutual Information[J]. Computer Vision and Pattern Recognition, 2005, 2 (2) : 807-814.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014372697.nh&amp;v=MDY0ODIyNkdyQy9ITmZGcUpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5RGxVNzdNVkY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 宁晓斐. 双目立体视觉中半全局立体匹配算法的研究[D]. 辽宁大学, 2014.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201608044&amp;v=MzE2OTBmTXA0OUJZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeURsVTc3TUx6N0JiYkc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 葛忠孝, 等. 基于树形结构的半全局立体匹配算法[J]. 计算机工程, 2016, 42 (8) : 243-248.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Depth discontinuities by pixel-to-pixel stereo">

                                <b>[7]</b> S Birchfield, C Tomasi. Depth Discontinuities by Pixel-to-pixelStereo[C]. Proceedings of the 6th International Conference on Computer Vision.Washington D.C. USA: IEEE Press, 1998:1073-1080.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ200902085&amp;v=MjU1MDJUWlpMRzRIdGpNclk5TllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5RGxVNzdNTHo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 高波, 马利庄. 加入结构约束的半全局立体匹配算法[J]. 计算机应用与软件, 2009, 26 (2) :244-247.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHKD201705003&amp;v=Mjc2MTFNcW85Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5RGxVNzdNSmlYQWFyRzRIOWI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 陈智君, 等. 区域生长的半全局密集匹配算法[J]. 测绘科学, 2017, 42 (5) :12-16.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201101032&amp;v=MDI5ODJDVVI3cWZadVptRnlEbFU3N01QRHpUYkxHNEg5RE1ybzlHWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 倪伟基, 等. 基于色彩分割和自适应窗口的快速立体匹配[J]. 仪器仪表学报, 2011, 32 (1) :194-200.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJCJ201501019&amp;v=MjM0NzNvOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeURsVTc3TU5pZklaTEc0SDlUTXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 赵胜男, 王文剑. 一种快速均值漂移图像分割算法[J]. 数据采集与处理, 2015, 30 (1) :192-201.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1011252374.nh&amp;v=MDQ3MzREbFU3N01WRjI2SDdHOUhOTExxNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 殷虎. 基于图像分割的立体匹配算法研究[D]. 南京航空航天大学, 2010.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTFZ201112032&amp;v=MDY1OTBabUZ5RGxVNzdNUFRuTmRMRzRIOUROclk5R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 盛捷, 等. Mean Shift算法优化带宽的自动搜索[J]. 系统仿真学报, 2011, 23 (12) : 2744-2749.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201903020" />
        <input id="dpi" type="hidden" value="400" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201903020&amp;v=MjcyMzJGeURsVTc3TUx6N0JkTEc0SDlqTXJJOUhaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm0=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVREcXYrcHRHTVovelQ5amowVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
