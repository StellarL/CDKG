<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141829383412500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201905077%26RESULT%3d1%26SIGN%3dmysr2JKZzHjStBeLDExzmMK0APM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201905077&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201905077&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201905077&amp;v=MTM5OTc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5L2xVNzNOTHo3QmRMRzRIOWpNcW85Q1k=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#29" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#34" data-title="&lt;b&gt;2 网络结构&lt;/b&gt; "><b>2 网络结构</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="&lt;b&gt;2.1  检测网络&lt;/b&gt;"><b>2.1  检测网络</b></a></li>
                                                <li><a href="#53" data-title="&lt;b&gt;2.2 评价网络&lt;/b&gt;"><b>2.2 评价网络</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#56" data-title="&lt;b&gt;3 训练&lt;/b&gt; "><b>3 训练</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#72" data-title="&lt;b&gt;4 实验&lt;/b&gt; "><b>4 实验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#73" data-title="&lt;b&gt;4.1 实验数据集&lt;/b&gt;"><b>4.1 实验数据集</b></a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;4.2 实验环境及评价指标&lt;/b&gt;"><b>4.2 实验环境及评价指标</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;4.3 基于城管数据集分类实验&lt;/b&gt;"><b>4.3 基于城管数据集分类实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#106" data-title="&lt;b&gt;5 结论&lt;/b&gt; "><b>5 结论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#36" data-title="&lt;b&gt;图1 分类架构图&lt;/b&gt;"><b>图1 分类架构图</b></a></li>
                                                <li><a href="#45" data-title="&lt;b&gt;图2 检测网络结构&lt;/b&gt;"><b>图2 检测网络结构</b></a></li>
                                                <li><a href="#48" data-title="&lt;b&gt;图3 线性卷积层 图4 多层感知卷积层&lt;/b&gt;"><b>图3 线性卷积层 图4 多层感知卷积层</b></a></li>
                                                <li><a href="#55" data-title="&lt;b&gt;图5 线性卷积层&lt;/b&gt;"><b>图5 线性卷积层</b></a></li>
                                                <li><a href="#58" data-title="&lt;b&gt;图6 训练流程图&lt;/b&gt;"><b>图6 训练流程图</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;表1 城管数据集信息&lt;/b&gt;"><b>表1 城管数据集信息</b></a></li>
                                                <li><a href="#76" data-title="&lt;b&gt;图7 实验数据样例图&lt;/b&gt;"><b>图7 实验数据样例图</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;表3 基于城管案件数据集的实验结果&lt;/b&gt;"><b>表3 基于城管案件数据集的实验结果</b></a></li>
                                                <li><a href="#101" data-title="&lt;b&gt;表4 本文方法与&lt;/b&gt;AlexNet&lt;b&gt;对比结果&lt;/b&gt;"><b>表4 本文方法与</b>AlexNet<b>对比结果</b></a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;表 5 本文方法与&lt;/b&gt;VGGNet&lt;b&gt;对比结果&lt;/b&gt;"><b>表 5 本文方法与</b>VGGNet<b>对比结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     李琦.A Digital City:Creating an Intelligent Service Platform for the 21th Century[J].Computer Science, 2002, 29 (7) :6-7.</a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 陈平.城市管理数字化看看北京东城区——解读万米单元网格城市管理新模式[J].城乡建设, 2005, (10) :10-13." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CXJS200510003&amp;v=MjExMTgzTUpqWEJmYkc0SHRUTnI0OUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeS9sVTc=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[2]</b>
                                         陈平.城市管理数字化看看北京东城区——解读万米单元网格城市管理新模式[J].城乡建设, 2005, (10) :10-13.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 丁世飞, 齐丙娟, 谭红艳.支持向量机理论与算法研究综述[J].电子科技大学学报, 2011, 40 (1) :2-10." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DKDX201101003&amp;v=Mjk0NTN5L2xVNzNNSVNiUGRyRzRIOURNcm85Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUY=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[3]</b>
                                         丁世飞, 齐丙娟, 谭红艳.支持向量机理论与算法研究综述[J].电子科技大学学报, 2011, 40 (1) :2-10.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" D H Hubel, T N Wiesel.Receptive fields, binocular interaction and functional architecture in the cat&#39;s visual cortex.[J].Journal of Physiology, 1962, 160 (1) :106." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Receptive fields, binocular interaction and functional architecture in the cat&amp;#39;s visual cortex">
                                        <b>[4]</b>
                                         D H Hubel, T N Wiesel.Receptive fields, binocular interaction and functional architecture in the cat&#39;s visual cortex.[J].Journal of Physiology, 1962, 160 (1) :106.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Y Lecun, et al.Backpropagation Applied to Handwritten Zip Code Recognition[J].Neural Computation, 1989, 1 (4) :541-551." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500012738&amp;v=MDkwMzJVcmZJSjE0VWFCWT1OaWZKWmJLOUh0ak1xbzlGWk9vTkMzOHhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubA==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[5]</b>
                                         Y Lecun, et al.Backpropagation Applied to Handwritten Zip Code Recognition[J].Neural Computation, 1989, 1 (4) :541-551.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" A Krizhevsky, I Sutskever, G E Hinton.ImageNet classification with deep convolutional neural networks[C].International Conference on Neural Information Processing Systems.Curran Associates Inc.2012:1097-1105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">
                                        <b>[6]</b>
                                         A Krizhevsky, I Sutskever, G E Hinton.ImageNet classification with deep convolutional neural networks[C].International Conference on Neural Information Processing Systems.Curran Associates Inc.2012:1097-1105.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" K Simonyan, A Zisserman.Very Deep Convolutional Networks for Large-Scale ImageRecognition[J].Computer Science, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">
                                        <b>[7]</b>
                                         K Simonyan, A Zisserman.Very Deep Convolutional Networks for Large-Scale ImageRecognition[J].Computer Science, 2014.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" C Szegedy, et al.Going Deeper withConvolutions[J].Computer Science, 2014:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">
                                        <b>[8]</b>
                                         C Szegedy, et al.Going Deeper withConvolutions[J].Computer Science, 2014:1-9.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" K He, et al.Deep Residual Learning for Image Recognition[C].Computer Vision and Pattern Recognition.IEEE, 2016:770-778." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">
                                        <b>[9]</b>
                                         K He, et al.Deep Residual Learning for Image Recognition[C].Computer Vision and Pattern Recognition.IEEE, 2016:770-778.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" S Ioffe, CSzegedy.Batch normalization:accelerating deep network training by reducing internal covariate shift[C].International Conference on International Conference on Machine Learning.JMLR.org, 2015:448-456." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Batch Normalization:Accelerating Deep Network Training by Reducing Internal Covariate Shift">
                                        <b>[10]</b>
                                         S Ioffe, CSzegedy.Batch normalization:accelerating deep network training by reducing internal covariate shift[C].International Conference on International Conference on Machine Learning.JMLR.org, 2015:448-456.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" M Lin, Q Chen, S Yan.Network In Network[J].Computer Science, 2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Network in network">
                                        <b>[11]</b>
                                         M Lin, Q Chen, S Yan.Network In Network[J].Computer Science, 2013.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" J Redmon, et al.You Only Look Once:Unified, Real-Time Object Detection[J].2015:779-788." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=You Only Look Once:Unified,Real-Time Object Detection">
                                        <b>[12]</b>
                                         J Redmon, et al.You Only Look Once:Unified, Real-Time Object Detection[J].2015:779-788.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" X Wang, H X Zhang.Application of Deep Learning Framework Caffe in Image Classification[J].Modern Computer, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDJS201605016&amp;v=MjEyNjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5L2xVNzNNUFNuQmZiRzRIOWZNcW85RVlvUUtESDg=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[13]</b>
                                         X Wang, H X Zhang.Application of Deep Learning Framework Caffe in Image Classification[J].Modern Computer, 2016.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(05),381-385+394             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>针对复杂背景的城管案件图像分类方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%81%E6%98%B1&amp;code=42021384&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">丁昱</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E7%81%B5%E5%B7%A7&amp;code=25928913&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">李灵巧</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E8%BE%89%E5%8D%8E&amp;code=10738412&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">杨辉华</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=0269119&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">桂林电子科技大学计算机与信息安全学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为解决智慧城市管理系统中复杂背景案件图片分类问题, 提出了一个卷积神经网络模型。不像其它深度学习网络模型, 所提方法在卷积网络中使用多层感知卷积层替代传统线性卷积层来提取城管图像特征, 然后再使用一个评价网络根据所提取的特征对图像中所含关键物体进行评分, 从而得出分类结果。基于实际运行的城市管理系统整理了一份包含8类案件、4996个注释对象共计4119张图片的城市管理案件图像的标准数据集来验证所提方法。实验结果表明, 所提方法在分类精度及速度上都优于AlexNet, VGG16Net, 和ResNet分类方法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%99%BA%E6%85%A7%E5%9F%8E%E7%AE%A1&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">智慧城管;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9F%8E%E5%B8%82%E7%AE%A1%E7%90%86&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">城市管理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">图像分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">卷积神经网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    丁昱 (1991-) , 男, 汉族, 湖南长沙人, 硕士研究生, 主要研究方向为机器学习, 图像处理;
                                </span>
                                <span>
                                    李灵巧 (1986-) , 男, 汉族, 广西桂林人, 博士研究生, 研究方向为人工智能;;
                                </span>
                                <span>
                                    杨辉华 (1972-) , 男, 汉族, 湖南人, 教授, 博士生导师, 主要研究方向为人工智能, 机器学习, 测量技术与仪器, 近红外光谱技术及其应用等。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-04</p>

                    <p>

                            <b>基金：</b>
                                                        <span>广西重点研发计划项目 (桂科AB16380293);</span>
                                <span>国家自然科学基金资助项目 (21365008, 61562013);</span>
                    </p>
            </div>
                    <h1><b>Image Classification Method of Urban Management Cases Based on Complex Background</b></h1>
                    <h2>
                    <span>DING Yu</span>
                    <span>LI Ling-qiao</span>
                    <span>YANG Hui-hua</span>
            </h2>
                    <h2>
                    <span>School of Computer and Information Security, Guilin University of Electronic Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In this paper, a novel deep convolution neural network is proposed to classify the images with complex background in the intelligent city management system. Unlike some existing deep neural networks, the algorithm used a multilayer perceptron instead of the commonly used linear convolution layer in convolution network to extract different characteristics of the urban management images. Then an evaluation network integrated the obtained characteristics to achieve the scores of all the urban management objects. To evaluate the algorithm, we also created a standard image database of city management cases that contains 8 categories and 4996 comment objects in total 4119 pictures. The comparison results demonstrate that the classification accuracy and computation speed of the algorithm exceed those of AlexNet, VGG16 Net, and ResNet.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Smart%20city&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Smart city;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Urban%20management&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Urban management;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20classification&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Image classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=CNN&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">CNN;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-04</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="29" name="29" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="30">信息化时代的来临使城市管理步入数字化的轨道, 现在智慧城市管理系统一般借助手机APP、微信客户端、电脑等客户端上传图片及表单来上报城市管理中所出现的问题<citation id="109" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。城管工作人员则依据其经验将各类案件分配到相应的个人处理。然而, 随着城市不断扩张以及人民对城市管理的要求不断提高, 导致问题案件数量不断增加, 人工分配案件已经不能满足日常工作需求<citation id="110" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。因此迫切需要一种针对城管案件进行快速分类的方法来协助城市管理工作, 以提高城管案件处理效率。</p>
                </div>
                <div class="p1">
                    <p id="31">目前, 图像分类方法可以分为以支持向量机 (Support Vector Machines, SVM) <citation id="111" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>方法和拉格朗日支持向量机 (LSVM) 方法为代表的传统方法和通过组合数据的低层特征形成更加抽象的高层特征表示的深度学习方法。使用传统方法进行图像分类之前, 一般需要提取图像的HOG特征等纹理特征, 所提取的特征会对最终的分类结果产生直接的影响, 这导致使用传统方法得到的分类结果不稳定。</p>
                </div>
                <div class="p1">
                    <p id="32">卷积神经网络 (Convolutional Neural Networks, CNN) <citation id="112" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>模型是受视觉神经机制的启发而设计的, 它是多层感知机的变种。1989年, LecunY et al<citation id="113" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出反向传播算法, 极大地推动了卷积神经网络的发展。在2012年至2015年间, 随着计算机硬件技术的进步及对卷积神经网络更深的研究, 层数更深、功能更完备的网络模型不断被提出, 如Krizhevsky et al提出的AlexNet<citation id="114" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、牛津大学的VGG<citation id="115" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、Google的GoogLeNet<citation id="116" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、微软的ResNet<citation id="117" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>接连刷新ImageNet上创造的记录。</p>
                </div>
                <div class="p1">
                    <p id="33">城市管理案件中的图像由市民或采集员在道路或社区用手机拍摄采集所得, 背景信息较复杂、图像质量较低, 采集质量参差不齐, 这让使用现有的深度学习方法进行案件图像分类的效果并不理想。但城管系统中的上报案件图像是人为采集的, 所以图片中必然含有代表案件分类的关键物体信息。如果能从图像的复杂背景中检测出这些关键物体, 就相当于提取出能表示图像进行分类的关键特征, 从而显著提升模型的分类性能。</p>
                </div>
                <h3 id="34" name="34" class="anchor-tag"><b>2 网络结构</b></h3>
                <div class="p1">
                    <p id="35">本文的网络结构分为2个部分, 如图1所示, 分别是使用卷积神经网络进行物体信息提取的检测网络和使用反向传播网络根据提取的信息进行案件分类的评价网络。其中卷积神经网络包含24个卷积层, 4个池化层, 在最后再连接了2个全连接层;反向传播网络采用4个输入的3层网络结构的反向传播网络。</p>
                </div>
                <div class="area_img" id="36">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905077_036.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图1 分类架构图" src="Detail/GetImg?filename=images/JSJZ201905077_036.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图1 分类架构图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905077_036.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="37">本文针对复杂背景的案件图像提出的分类算法思想 (图1) , 将案件图片输入到一个卷积神经网络, 预测图像中可能出现的城管物体的类别、可能出现的位置和物体相对大小等信息, 然后综合以上信息计算各类案件得分, 从而预测出该幅图像所属的案件类别。</p>
                </div>
                <div class="p1">
                    <p id="38">本文提出的分类算法流程:</p>
                </div>
                <div class="p1">
                    <p id="39">1) 将图像调整448*448;</p>
                </div>
                <div class="p1">
                    <p id="40">2) 放入卷积神经网络中提取特征;</p>
                </div>
                <div class="p1">
                    <p id="41">3) 设置阀值过滤得出可能出现关键物体的信息;</p>
                </div>
                <div class="p1">
                    <p id="42">4) 根据所有物体信息得出分类结果。</p>
                </div>
                <h4 class="anchor-tag" id="43" name="43"><b>2.1  检测网络</b></h4>
                <div class="p1">
                    <p id="44">检测网络使用的网络模型包含24个卷积层, 4个池化层, 在最后再连接了2个全连接层, 网络结构如图2所示。用卷积层来提取图像特征, 该层用设定的卷积核对一幅图像进行卷积, 将卷积值加权并加偏置, 然后作用于一个激活函数上。因为本文所使用的卷积核比较小, 实现该操作时使用的是最直接的遍历矩阵的方式计算卷积运算。</p>
                </div>
                <div class="area_img" id="45">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905077_045.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图2 检测网络结构" src="Detail/GetImg?filename=images/JSJZ201905077_045.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图2 检测网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905077_045.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="46">在卷积神经网络模型的训练过程中, 每一层网络的输入都会因为前一层网络参数的变化导致其分布发生改变, 造成整个网络模型的不稳定, 这就要求必须使用一个很小的学习率和对参数很好的初始化, 但是这么做会让训练过程变得慢而且复杂。所以为了解决这个问题, 本文在每个卷积层前都加上Batch Normalization层<citation id="118" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 其不仅能加速模型收敛还能提供一定的正则化。</p>
                </div>
                <div class="p1">
                    <p id="47">为了能让网络提取到更加抽象和有效的非线性特征, 本网络将一部分传统卷积层用多感知卷积层代替<citation id="119" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。卷积层一般通过线性滤波器进行线性卷积运算随后接个非线性激活函数从而生成特征图, 如图3所示, 但是如果用超完备的滤波器将所有可能的特征都提取出来, 网络过于庞大。但在神经网络中卷积提取的高层特征其实是底层特征通过某种运算的组合, 所以本文的网络对卷积计算中在每个局部感受野中加上一个微型多层网络, 如图4所示, 以优化卷积层算法。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905077_048.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图3 线性卷积层 图4 多层感知卷积层" src="Detail/GetImg?filename=images/JSJZ201905077_048.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图3 线性卷积层 图4 多层感知卷积层</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905077_048.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="49">本文应用多感知卷积层时, 相当于对2个卷积层之间添加一个额外的1×1卷积层, 后面接一个修正的线性激活 (rectified linear activation) , 如式 (1) 所示, 这个核函数简单地把小于零的输入乘以0.1, 对于其它输入则原样输出。该1×1卷积具有双重目的:最重要的一点是, 它们被主要用于降维模块以打破计算瓶颈, 否则网络规模会受到限制。这使得不仅可以加深网络, 同时还可以加宽, 而不造成严重的性能下降。</p>
                </div>
                <div class="area_img" id="50">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905077_05000.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="52">池化层利用图像局部相关性原理, 对图像进行子抽样, 以此减少数据处理, 同时保留有用信息, 以保持图像的旋转不变性。其常见的算法有在图像区域的每个分区取平均值的平均池化 (Mean Pooling) 和在每个区域寻找最大值的最大池化 (Max Pooling) 。在本网络结构中, 使用几层卷积层过后对其输出的特征向量采用最大池化方法防止过拟合, 以此来改善结果。</p>
                </div>
                <h4 class="anchor-tag" id="53" name="53"><b>2.2 评价网络</b></h4>
                <div class="p1">
                    <p id="54">本文使用<i>BP</i>网络作为评价网络, 网络结构如图5所示, 其属于多层前馈的人工神经网络, 由若干神经元组成, 且每个神经元都对应着一个激活函数和阀值。本文使用每幅图片中所含唯一关键物体的宽高<i>w</i>、<i>h</i>和其中心相对偏移量<i>x</i>、<i>y</i>作为网络的输入向量, 通过交替输入的正向传播和误差的反向传播, 用函数梯度下降法动态迭代搜索权重向量使网络误差函数达到最小值。</p>
                </div>
                <div class="area_img" id="55">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905077_055.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图5 线性卷积层" src="Detail/GetImg?filename=images/JSJZ201905077_055.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图5 线性卷积层</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905077_055.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="56" name="56" class="anchor-tag"><b>3 训练</b></h3>
                <div class="p1">
                    <p id="57">本文采用带注释对象的数据集图像来训练检测网络使其提取其中所含城管物体信息, 同时使用图像的类别与其所含注释对象的关系训练评价网络使其能根据图像所含注释对象信息得到案件的正确分类, 进而实现整个网络的训练阶段。</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905077_058.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图6 训练流程图" src="Detail/GetImg?filename=images/JSJZ201905077_058.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图6 训练流程图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905077_058.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="59">在训练检测模型时, 由于训练集样本数量较少, 容易导致过拟合问题。为了解决此类问题, 人为对数据集进行了扩充, 通过对原始图片的旋转角度、曝光度、饱和度、色调进行微调产生临时训练样本, 实现训练样本数量的扩充, 促使网络学习到更多图像不变性特征。</p>
                </div>
                <div class="p1">
                    <p id="60">本文的检测模型使用均方和误差作为损失函数来优化模型参数, 即网络输出向量与真实图像对应向量的均方和作为误差, 如式 (2) 所示, 其中y<sub>i</sub>和<mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mtext>y</mtext><mo>^</mo></mover></math></mathml><sub>i</sub>代表预测数据与标定数据之间的坐标、<i>IOU</i>和分类结果的值及误差。</p>
                </div>
                <div class="p1">
                    <p id="62"><mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>S</mtext><mtext>S</mtext><mtext>E</mtext><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mn>0</mn></mrow><mtext>n</mtext></munderover><mtext>λ</mtext></mstyle><msub><mrow></mrow><mtext>i</mtext></msub><mrow><mo stretchy="false"> (</mo><mtext>y</mtext><msub><mrow></mrow><mtext>i</mtext></msub><mo>-</mo><mover accent="true"><mtext>y</mtext><mo>^</mo></mover><msub><mrow></mrow><mtext>i</mtext></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="64">本网络中位置相关误差与类别误差对网络loss的贡献值是不同的, 因此在计算loss时, 使用λ<sub>coord</sub>=6.2增大位置贡献, 使用λ<sub>noob</sub>=0.4降低不包含物体的网格对网络的影响, 如式 (3) 所示, 其中x、y代表<i>bounding box</i>的中心离开其所在网格边界的偏移;w、h代表<i>bounding box</i>的宽和高相对图片的比例;p (C) 表示预测类别为 C的精度 (C在本文中是8, 数据集有8类) 。检测网络将图片分为了i块, ∏<mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>i</mtext><mo>, </mo><mtext>j</mtext></mrow><mrow><mtext>o</mtext><mtext>b</mtext><mtext>j</mtext></mrow></msubsup></mrow></math></mathml>表示第i个网格的第j个<i>bounding box</i>对obj目标负责是式子的值<citation id="120" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="122">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905077_12200.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="122">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905077_12201.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="71">在训练分类网络时使用的是三层反向传播神经网络, 用图片中带标注物体的<i>bounding box</i>的宽高w、h和其中心相对图片左上角的偏移x、y作为网络的输入向量, 以图片影响案件分类的物体为正样本、无关物体为负样本。通过交替输入的正向传播和误差的反向传播, 用函数梯度下降法动态迭代搜索权重向量使网络误差函数达到最小值。</p>
                </div>
                <h3 id="72" name="72" class="anchor-tag"><b>4 实验</b></h3>
                <h4 class="anchor-tag" id="73" name="73"><b>4.1 实验数据集</b></h4>
                <div class="p1">
                    <p id="74">本文实验数据来源于某市的城市管理系统中上报案件所附带的图片, 具体样例图像如图7所示, 主要选取系统中数据较齐全的4个大类中的8个小类, 分别为:乱涂写乱张贴、雨水算子破损、井盖破损、交通护栏破损、共享单车乱停、非机动车乱停、机动车乱停、暴露性垃圾为样本。数据集中共有尺度大小不一的4119张图片, 格式皆为jpg, 其中训练集和测试集的比例为3:2, 具体的数据集信息如表1所示。</p>
                </div>
                <div class="area_img" id="75">
                    <p class="img_tit"><b>表1 城管数据集信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="75" border="1"><tr><td><br /></td><td>训练集</td><td>测试集</td><td>合计</td></tr><tr><td><br />乱涂写乱张贴</td><td>375</td><td>174</td><td>549</td></tr><tr><td><br />雨水算子破损</td><td>292</td><td>260</td><td>552</td></tr><tr><td><br />井盖破损</td><td>390</td><td>186</td><td>567</td></tr><tr><td><br />交通护栏破损</td><td>318</td><td>152</td><td>470</td></tr><tr><td><br />共享单车乱停</td><td>226</td><td>181</td><td>407</td></tr><tr><td><br />非机动车乱停</td><td>321</td><td>204</td><td>525</td></tr><tr><td><br />机动车乱停</td><td>300</td><td>245</td><td>545</td></tr><tr><td><br />暴露性垃圾</td><td>296</td><td>208</td><td>504</td></tr><tr><td><br />合计</td><td>2518</td><td>1610</td><td>4119</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905077_076.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图7 实验数据样例图" src="Detail/GetImg?filename=images/JSJZ201905077_076.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图7 实验数据样例图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905077_076.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="77" name="77"><b>4.2 实验环境及评价指标</b></h4>
                <div class="p1">
                    <p id="78">本文实验均在配置为<i>Ubuntu</i>14.04的操作系统、显卡为<i>M</i>40、<i>CPU</i>为<i>Intel Xeon E</i>5的硬件环境下, 基于深度学习框架<i>Caffe</i><citation id="121" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>实现。</p>
                </div>
                <div class="p1">
                    <p id="79">实验采用<i>Precision</i>、<i>Recall</i>及<i>F</i>1_<i>Score</i>为单类案件分类效果的评价标准。其计算公式分别如下</p>
                </div>
                <div class="p1">
                    <p id="80"><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ρ</mtext><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>i</mtext><mtext>s</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext><mo>=</mo><mfrac><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext><mo>+</mo><mtext>F</mtext><mtext>Ρ</mtext></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="82"><mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>R</mtext><mtext>e</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>l</mtext><mo>=</mo><mfrac><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext><mo>+</mo><mtext>F</mtext><mtext>Ν</mtext></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="84"><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>F</mtext><mn>1</mn><mo>_</mo><mtext>S</mtext><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>e</mtext><mo>=</mo><mfrac><mrow><mn>2</mn><mo>×</mo><mtext>Ρ</mtext><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>i</mtext><mtext>s</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext><mo>×</mo><mtext>R</mtext><mtext>e</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>l</mtext></mrow><mrow><mtext>Ρ</mtext><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>i</mtext><mtext>s</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext><mo>+</mo><mtext>R</mtext><mtext>e</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>l</mtext></mrow></mfrac></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="86">上式中TP表示当前类原本是正类并且也被预测为正类的个数, FP表示当前类原本是负类且被预测为正类的个数, FN表示当前类原本是正类且被预测为负类的个数。</p>
                </div>
                <div class="p1">
                    <p id="87">本文评判模型对案件的分类性能是根据Mean_Pre, Mean_Recall 和Mean_F1, 其计算方式如式 (7) (8) (9) 所示。其中n表示数据集中城管案件总类别数。</p>
                </div>
                <div class="p1">
                    <p id="88">Mean<mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>_</mo><mtext>p</mtext><mtext>r</mtext><mtext>e</mtext><mo>=</mo><mfrac><mn>1</mn><mtext>n</mtext></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mn>1</mn></mrow><mtext>n</mtext></munderover><mtext>Ρ</mtext></mstyle><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>i</mtext><mtext>s</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext><msub><mrow></mrow><mtext>i</mtext></msub></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="90">Mean<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>_</mo><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>l</mtext><mo>=</mo><mfrac><mn>1</mn><mtext>n</mtext></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mn>1</mn></mrow><mtext>n</mtext></munderover><mtext>R</mtext></mstyle><mtext>e</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>l</mtext><msub><mrow></mrow><mtext>i</mtext></msub></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="92">Mean<mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>_</mo><mtext>F</mtext><mn>1</mn><mo>=</mo><mfrac><mn>1</mn><mtext>n</mtext></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mn>1</mn></mrow><mtext>n</mtext></munderover><mtext>F</mtext></mstyle><mn>1</mn><mo>_</mo><mtext>S</mtext><mtext>c</mtext><mtext>o</mtext><mtext>r</mtext><mtext>e</mtext><msub><mrow></mrow><mtext>i</mtext></msub></mrow></math></mathml>      (9) </p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>4.3 基于城管数据集分类实验</b></h4>
                <div class="p1">
                    <p id="95">实验应用上文提出的城管案件图像作为数据集, 计算分类模型的平均精度Mean_pre、平均召回率Mean_recall以及F1_Score值, 并与AlexNet, VGG16Net, ResNet模型做对比, 实验结果如表3所示。</p>
                </div>
                <div class="area_img" id="96">
                    <p class="img_tit"><b>表3 基于城管案件数据集的实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="96" border="1"><tr><td><br />模型名称</td><td>训练时长</td><td>训练集</td><td>测试集</td><td>合计</td></tr><tr><td><br />AlexNet</td><td>6 h</td><td>89.91%</td><td>90.83%</td><td>0.899</td></tr><tr><td><br />VGG16Net</td><td>7 h</td><td>96.22%</td><td>97.30%</td><td>0.970</td></tr><tr><td><br />ResNet</td><td>20 h</td><td>92.00%</td><td>92.61%</td><td>0.922</td></tr><tr><td><br />BCCNet</td><td>6 h</td><td>97.22%</td><td>98.42%</td><td>0.973</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="97">以上实验结果表明, 网络在测试集分类平均准确率达97.22%, 其中分类准确率最高的类别“乱涂写乱张贴”, 最低的“雨水算子破损”。可以看出本文设计的分类模型在城管案件分类问题上在检测速度和分类精度上均优于AlexNet, VGG16Net, ResNet分类模型。</p>
                </div>
                <div class="p1">
                    <p id="98">为了验证本模型对复杂背景环境下的案件图像分类优于其它分类器, 将详细分析各分类模型对于城管案件数据集的分类结果, 并在下文中会将本文方法分别于与之训练时间相近的AlexNet分类网络和与之分类精度相近的VGG16Net分类网络分别进行比较。</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99">4.3.1 比较AlexNet和本文方法</h4>
                <div class="p1">
                    <p id="100">在几乎相近的训练时间下, AlexNet分类模型在部分案件类别的分类结果上与本文方法相差不大, 但在“雨水算子破损”、“机动车乱停”、“非机动车乱停”, “井盖破损”四个案件类别的分类结果精度上有相当大的差距, 对比结果表4所示。</p>
                </div>
                <div class="area_img" id="101">
                    <p class="img_tit"><b>表4 本文方法与</b>AlexNet<b>对比结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="101" border="1"><tr><td><br />类别</td><td>方法</td><td>Pre</td><td>Recall</td><td>F1_Score</td></tr><tr><td><br />乱涂写乱张贴</td><td>本文方法</td><td>100.0%</td><td>98.85%</td><td>0.994</td></tr><tr><td><br /> (event-0201) </td><td>AlexNet</td><td>95.05%</td><td>98.85%</td><td>0.969</td></tr><tr><td><br />雨水算子破损</td><td>本文方法</td><td>99.21%</td><td>96.94%</td><td>0.980</td></tr><tr><td><br /> (unite -0104) </td><td>AlexNet</td><td>90.16%</td><td>83.96%</td><td>0.869</td></tr><tr><td><br />井盖破损</td><td>本文方法</td><td>87.61%</td><td>97.87%</td><td>0.893</td></tr><tr><td><br /> (unite -0100) </td><td>AlexNet</td><td>69.91%</td><td>91.48%</td><td>0.792</td></tr><tr><td><br />交通护栏破损</td><td>本文方法</td><td>95.52%</td><td>97.70%</td><td>0.966</td></tr><tr><td><br /> (unite -0211) </td><td>AlexNet</td><td>94.73%</td><td>93.50%</td><td>0.941</td></tr><tr><td><br />共享单</td><td>本文方法</td><td>98.84%</td><td>99.41%</td><td>0.991</td></tr><tr><td><br />车乱停</td><td>AlexNet</td><td>93.92%</td><td>98.83%</td><td>0.963</td></tr><tr><td><br />非机动车乱停</td><td>本文方法</td><td>98.85%</td><td>100.0%</td><td>0.994</td></tr><tr><td><br /> (event-0551) </td><td>AlexNet</td><td>79.65%</td><td>89.75%</td><td>0.844</td></tr><tr><td><br />机动车乱停</td><td>本文方法</td><td>99.16%</td><td>97.13%</td><td>0.981</td></tr><tr><td><br /> (event-0550) </td><td>AlexNet</td><td>98.48%</td><td>79.91%</td><td>0.882</td></tr><tr><td><br />暴露性垃圾</td><td>本文方法</td><td>98.57%</td><td>99.52%</td><td>0.990</td></tr><tr><td><br /> (event-0102) </td><td>AlexNet</td><td>97.42%</td><td>90.43%</td><td>0.937</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="102">在上表中可以看出, AlexNet分类模型所得到的最好结果的类别为“雨水算子破损”, 而分类最差的案件类别为“非机动车乱停”其精度低于80%。而在本文提供的数据集中, 在位于街道上拍摄的案件类别“非机动车乱停”, 因为街道背景的复杂性使得案件图像的背景复杂度远大于在单一颜色墙面所拍摄的案件类别“乱涂写乱张贴”。因此AlexNet分类模型的分类结果受背景的复杂性的影响很大, 而本文方法无论对于复杂背景下的图像或单一背景下的图像的分类效果都不错。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103">4.3.2 比较VGG16Net和本文方法</h4>
                <div class="p1">
                    <p id="104">比较每个案件类别的VGG16分类模型和本文方法分类结果, 如表5所示, 发现2类方法的分类结果本文方法稍好但相差不大。在背景复杂度较大的“机动车乱停”、“非机动车乱停”两个案件类别中本文方法的分类结果明显优于VGG16分类结果, 但在背景简单的案件类别如的“乱涂写乱张贴”、“交通护栏破损”上VGG16的分类结果优于本文方法。</p>
                </div>
                <div class="area_img" id="105">
                    <p class="img_tit"><b>表 5 本文方法与</b>VGGNet<b>对比结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="105" border="1"><tr><td><br />类别</td><td>方法</td><td>Pre</td><td>Recall</td><td>F1_Score</td></tr><tr><td><br />乱涂写乱张贴</td><td>本文方法</td><td>100.0%</td><td>98.85%</td><td>0.994</td></tr><tr><td><br /> (event-0201) </td><td>VGGNet</td><td>91.70%</td><td>99.42%</td><td>0.980</td></tr><tr><td><br />雨水算子破损</td><td>本文方法</td><td>99.21%</td><td>96.94%</td><td>0.980</td></tr><tr><td><br /> (unite-0104) </td><td>VGGNet</td><td>97.70%</td><td>97.70%</td><td>0.977</td></tr><tr><td><br />井盖破损</td><td>本文方法</td><td>87.61%</td><td>97.87%</td><td>0.893</td></tr><tr><td><br /> (unite-0100) </td><td>VGGNet</td><td>94.50%</td><td>91.48%</td><td>0.929</td></tr><tr><td><br />交通护栏破损</td><td>本文方法</td><td>95.52%</td><td>97.70%</td><td>0.966</td></tr><tr><td><br /> (unite-0211) </td><td>VGGNet</td><td>92.77%</td><td>100.0%</td><td>0.962</td></tr><tr><td><br />共享单</td><td>本文方法</td><td>98.84%</td><td>99.41%</td><td>0.991</td></tr><tr><td><br />车乱停</td><td>VGGNet</td><td>98.84%</td><td>99.41%</td><td>0.991</td></tr><tr><td><br />非机动车乱停</td><td>本文方法</td><td>98.85%</td><td>100.0%</td><td>0.994</td></tr><tr><td><br /> (event-0551) </td><td>VGGNet</td><td>96.13%</td><td>97.07%</td><td>0.966</td></tr><tr><td><br />机动车乱停</td><td>本文方法</td><td>99.16%</td><td>97.13%</td><td>0.981</td></tr><tr><td><br /> (event-0550) </td><td>VGGNet</td><td>99.15%</td><td>96.72%</td><td>0.979</td></tr><tr><td><br />暴露性垃圾</td><td>本文方法</td><td>98.57%</td><td>99.52%</td><td>0.990</td></tr><tr><td><br /> (event-0102) </td><td>VGGNet</td><td>99.01%</td><td>96.66%</td><td>0.978</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="106" name="106" class="anchor-tag"><b>5 结论</b></h3>
                <div class="p1">
                    <p id="107">本文为解决日益增加的城市管理案件数量, 所带来的案件处理不及时的问题, 提出了一种基于关键物体信息提取的背景复杂城市管理案件图像分类方法, 依据城管案件图像进行案件自动分类, 以提升城管案件处理效率。</p>
                </div>
                <div class="p1">
                    <p id="108">该方法通过检测图像所包含的关键物体信息对案件进行归类, 弥补现行图像分类算法对复杂背景下的案件图像分类精度的不足。使用实际运行的城市管理系统中产生的上报案件图片从多个方面测试该模型的分类性能。实验数据表明, 该方法能解决城管图像自动分类问题, 并且分类准确率达到了97.22%。本文方法在相同硬件环境下相比AlexNet、VGGNet、ResNet等分类网络在保证训练速度的同时依然能兼顾较好的分类精度。</p>
                </div>
                <div class="area_img" id="123">
                                <img alt="" src="Detail/GetImg?filename=images/JSJZ201905077_12300.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                            <p class="img_tit"></p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 李琦.A Digital City:Creating an Intelligent Service Platform for the 21th Century[J].Computer Science, 2002, 29 (7) :6-7.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CXJS200510003&amp;v=MjQ1MTJPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5L2xVNzNNSmpYQmZiRzRIdFROcjQ5Rlo0UUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[2]</b> 陈平.城市管理数字化看看北京东城区——解读万米单元网格城市管理新模式[J].城乡建设, 2005, (10) :10-13.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DKDX201101003&amp;v=MDM0MDNVUjdxZlp1Wm1GeS9sVTczTUlTYlBkckc0SDlETXJvOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[3]</b> 丁世飞, 齐丙娟, 谭红艳.支持向量机理论与算法研究综述[J].电子科技大学学报, 2011, 40 (1) :2-10.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Receptive fields, binocular interaction and functional architecture in the cat&amp;#39;s visual cortex">

                                <b>[4]</b> D H Hubel, T N Wiesel.Receptive fields, binocular interaction and functional architecture in the cat's visual cortex.[J].Journal of Physiology, 1962, 160 (1) :106.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500012738&amp;v=MjExODdHZXJxUVRNbndaZVp0RmlubFVyZklKMTRVYUJZPU5pZkpaYks5SHRqTXFvOUZaT29OQzM4eG9CTVQ2VDRQUUgvaXJSZA==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[5]</b> Y Lecun, et al.Backpropagation Applied to Handwritten Zip Code Recognition[J].Neural Computation, 1989, 1 (4) :541-551.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">

                                <b>[6]</b> A Krizhevsky, I Sutskever, G E Hinton.ImageNet classification with deep convolutional neural networks[C].International Conference on Neural Information Processing Systems.Curran Associates Inc.2012:1097-1105.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">

                                <b>[7]</b> K Simonyan, A Zisserman.Very Deep Convolutional Networks for Large-Scale ImageRecognition[J].Computer Science, 2014.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">

                                <b>[8]</b> C Szegedy, et al.Going Deeper withConvolutions[J].Computer Science, 2014:1-9.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">

                                <b>[9]</b> K He, et al.Deep Residual Learning for Image Recognition[C].Computer Vision and Pattern Recognition.IEEE, 2016:770-778.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Batch Normalization:Accelerating Deep Network Training by Reducing Internal Covariate Shift">

                                <b>[10]</b> S Ioffe, CSzegedy.Batch normalization:accelerating deep network training by reducing internal covariate shift[C].International Conference on International Conference on Machine Learning.JMLR.org, 2015:448-456.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Network in network">

                                <b>[11]</b> M Lin, Q Chen, S Yan.Network In Network[J].Computer Science, 2013.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=You Only Look Once:Unified,Real-Time Object Detection">

                                <b>[12]</b> J Redmon, et al.You Only Look Once:Unified, Real-Time Object Detection[J].2015:779-788.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDJS201605016&amp;v=MzIwNjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5L2xVNzNNUFNuQmZiRzRIOWZNcW85RVlvUUtESDg0dlI0VDY=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[13]</b> X Wang, H X Zhang.Application of Deep Learning Framework Caffe in Image Classification[J].Modern Computer, 2016.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201905077" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201905077&amp;v=MTM5OTc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5L2xVNzNOTHo3QmRMRzRIOWpNcW85Q1k=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
