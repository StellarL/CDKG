<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141826561537500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201904097%26RESULT%3d1%26SIGN%3d9awi9EXrVtPvjgTtXvGD0%252bHHnUw%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201904097&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201904097&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201904097&amp;v=MTk4ODFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnkva1ZyL1BMejdCZExHNEg5ak1xNDlNWTRRS0Q=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#19" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#23" data-title="&lt;b&gt;2 破损图像子区域自适应划分标注&lt;/b&gt; "><b>2 破损图像子区域自适应划分标注</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#24" data-title="&lt;b&gt;2.1 破损图像增强&lt;/b&gt;"><b>2.1 破损图像增强</b></a></li>
                                                <li><a href="#39" data-title="&lt;b&gt;2.2 破损图像细节增强&lt;/b&gt;"><b>2.2 破损图像细节增强</b></a></li>
                                                <li><a href="#53" data-title="&lt;b&gt;2.3 图像分割&lt;/b&gt;"><b>2.3 图像分割</b></a></li>
                                                <li><a href="#70" data-title="&lt;b&gt;2.4 破损图像子区域自适应划分标注实现&lt;/b&gt;"><b>2.4 破损图像子区域自适应划分标注实现</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#80" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#90" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#85" data-title="&lt;b&gt;图1 不同方法标注准确率对比&lt;/b&gt;"><b>图1 不同方法标注准确率对比</b></a></li>
                                                <li><a href="#87" data-title="&lt;b&gt;图2 不同方法标注召回率对比&lt;/b&gt;"><b>图2 不同方法标注召回率对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 柯逍, 周铭柯, 牛玉贞.融合深度特征和语义邻域的自动图像标注[J].模式识别与人工智能, 2017, 30 (3) :193-203." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201703001&amp;v=MDc0MzQva1ZyL1BLRDdZYkxHNEg5Yk1ySTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnk=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[1]</b>
                                         柯逍, 周铭柯, 牛玉贞.融合深度特征和语义邻域的自动图像标注[J].模式识别与人工智能, 2017, 30 (3) :193-203.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 李冰锋, 唐延东, 韩志.基于超图直推非负矩阵分解的图像标注法研究[J].计算机仿真, 2017, 34 (2) :380-384." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201702085&amp;v=MDI0NDBGckNVUjdxZlp1Wm1GeS9rVnIvUEx6N0JkTEc0SDliTXJZOU5ZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[2]</b>
                                         李冰锋, 唐延东, 韩志.基于超图直推非负矩阵分解的图像标注法研究[J].计算机仿真, 2017, 34 (2) :380-384.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 高耀东, 侯凌燕, 杨大利.基于多标签学习的卷积神经网络的图像标注方法[J].计算机应用, 2017, 37 (1) :228-232." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201701041&amp;v=MDM5OTdCdEdGckNVUjdxZlp1Wm1GeS9rVnIvUEx6N0JkN0c0SDliTXJvOUJaWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[3]</b>
                                         高耀东, 侯凌燕, 杨大利.基于多标签学习的卷积神经网络的图像标注方法[J].计算机应用, 2017, 37 (1) :228-232.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 王建文, 林劼.基于颜色直方图金字塔的图像自动标注方法[J].计算机工程, 2016, 42 (6) :235-240." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201606043&amp;v=MTg1MjhadVptRnkva1ZyL1BMejdCYmJHNEg5Zk1xWTlCWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[4]</b>
                                         王建文, 林劼.基于颜色直方图金字塔的图像自动标注方法[J].计算机工程, 2016, 42 (6) :235-240.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 张博, 郝杰, 马刚, 等.基于弱匹配概率典型相关性分析的图像自动标注[J].软件学报, 2017, 28 (2) :292-309." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201702008&amp;v=Mjk2OTlQTnlmVGJMRzRIOWJNclk5RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5L2tWci8=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[5]</b>
                                         张博, 郝杰, 马刚, 等.基于弱匹配概率典型相关性分析的图像自动标注[J].软件学报, 2017, 28 (2) :292-309.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 张奎, 陈兆学.一种基于游程码的二值图像孔洞标记和表达方法[J].光学技术, 2017, 43 (4) :364-368." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJS201704016&amp;v=MDI2OTN5L2tWci9QSWpYQmZiRzRIOWJNcTQ5RVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUY=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[6]</b>
                                         张奎, 陈兆学.一种基于游程码的二值图像孔洞标记和表达方法[J].光学技术, 2017, 43 (4) :364-368.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 黄冬梅, 许琼琼, 杜艳玲, 等.基于DBNMI模型的海洋遥感影像自动标注方法[J].中国科学技术大学学报, 2017, 47 (7) :541-546." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKJD201707001&amp;v=MjY5MzFtRnkva1ZyL1BQeWJCYXJHNEg5Yk1xSTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[7]</b>
                                         黄冬梅, 许琼琼, 杜艳玲, 等.基于DBNMI模型的海洋遥感影像自动标注方法[J].中国科学技术大学学报, 2017, 47 (7) :541-546.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 秦煜, 吴静静, 安伟.基于RANSAC的激光网格标记图像特征提取[J].计算机工程与科学, 2017, 39 (8) :1495-1501." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201708018&amp;v=MjMzNTJwNDlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnkva1ZyL1BMejdCWmJHNEg5Yk0=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[8]</b>
                                         秦煜, 吴静静, 安伟.基于RANSAC的激光网格标记图像特征提取[J].计算机工程与科学, 2017, 39 (8) :1495-1501.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(04),461-464             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>破损图像子区域自适应划分标注方法仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E6%9F%B3&amp;code=29594295&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">杨柳</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8D%97%E8%B4%A2%E7%BB%8F%E6%94%BF%E6%B3%95%E5%A4%A7%E5%AD%A6%E6%96%87%E5%8C%96%E4%BC%A0%E6%92%AD%E5%AD%A6%E9%99%A2&amp;code=0885939&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">河南财经政法大学文化传播学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对当前图像标注方法中存在准确率与召回率低的问题, 提出基于多示例学习的破损图像子区域自适应划分标注方法。利用模糊增强算法计算图像模糊隶属度, 对得到的图像隶属度进行非线性变换增强图像对比度, 通过隶属度的逆变换获取整体得到增强的破损图像。在对数域上分离整体增强后图像中大特征和小细节, 并采用二次函数分解图像中的大特征, 得到增强细节后的破损图像。将增强后图像代入图像分割中, 利用相邻像素之间差分计算得到图像中具有梯度突变的点, 利用形态学处理突变点, 并确定初始分割阈值。将互信息量当作目标函数, 通过计算分割图像和原始图像互信息量, 得到最佳分割阈值, 实现破损图像分割。经图像分割, 利用多示例学习法与多样性密度法相结合的方式将训练图像集合中图像划分成正包、负包, 利用计算图像各分割块有关各标注自身多样性密度的得分值实现图像子区域自适应划分标注。实验结果表明, 该方法标注准确率与召回率均较高。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A0%B4%E6%8D%9F%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">破损图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AD%90%E5%8C%BA%E5%9F%9F&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">子区域;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%92%E5%88%86%E6%A0%87%E6%B3%A8&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">划分标注;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    杨柳 (1981-) , 女 (汉族) , 河南南阳人, 实验师, 主要研究方向为网络与新媒体。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-04</p>

            </div>
                    <h1><b>Simulation of adaptive segmentation method for broken image sub-region</b></h1>
                    <h2>
                    <span>YANG Liu</span>
            </h2>
                    <h2>
                    <span>School of culture and communication, Henan University of Economics and Law</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Because the current image annotation method has low correct rate and recall rate, this article puts forward a method of adaptive partition annotation for subregion in damaged image based on multi-instance learning method. The fuzzy enhancement algorithm was used to calculate the fuzzy membership degree of image, and then obtained image membership degree was nonlinearly transformed to enhance the image contrast. After that, the inverse transform of membership degree was used to obtain the overall enhanced damaged image. The big features and small details in the overall enhanced image were separated on the logarithmic domain. Meanwhile, the quadratic function was used to decompose the big features in image, so as to obtain the damaged image with enhanced detail. Then, the enhanced image was introduced into the image segmentation, and the difference calculation between adjacent pixels was used to get the point with gradient mutation in image. The mutation point was processed by morphology and the initial segmentation threshold was determined. In addition, the mutual information was used as the objective function. By calculating the mutual information between the segmented image and the original image, the optimal segmentation threshold was obtained and the damaged image segmentation was achieved. Through image segmentation, the multi-instance learning method and the diverse density method were used to divide the image in the training image set into positive packet and negative packet. Finally, the score of diversity density of each image segment was calculated to achieve the adaptive partition annotation of subregion in image. Experimental results show that the method has higher tagging accuracy and recall rate.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Damaged%20image&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Damaged image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Subregion&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Subregion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Partition%20annotation&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Partition annotation;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-04</p>
                            </div>


        <!--brief start-->
                        <h3 id="19" name="19" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="20">互联网高科技迅猛发展, 视频和图像等信息数据以海量形式增长, 其中包含部分破损图像<citation id="92" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。子区域标注作为破损图像修复的首要环节, 对于图像再利用来说十分重要, 已经成为图像处理领域的研究热点<citation id="93" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="21">高耀东<citation id="94" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等人提出基于多标签学习与卷积神经网络结合的图像标注方法。采用IAPR TC-12标准图像集进行实验。实验结果表明, 该方法具有简单易实现的优点, 但存在标注准确率低的问题。王建文<citation id="95" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等人提出基于PKM的图像特征标注方法。利用corel5k数据集进行实验, 实验结果表明, 所提方法具有一定标注稳定性, 但存在召回率低的问题。张博<citation id="96" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等人提出基于弱匹配概率相关性的图像标注方法。所提方法也叫作SemiPCCA, 其关注模态内部各个结构。实验结果表明, 该方法标注效率较高, 但存在标注精度低的问题。</p>
                </div>
                <div class="p1">
                    <p id="22">上述关于图像标注的方法可靠性较差, 在此, 以破损图像为研究对象, 提出基于多示例学习的破损图像子区域自适应划分标注方法。</p>
                </div>
                <h3 id="23" name="23" class="anchor-tag"><b>2 破损图像子区域自适应划分标注</b></h3>
                <h4 class="anchor-tag" id="24" name="24"><b>2.1 破损图像增强</b></h4>
                <div class="p1">
                    <p id="25">为了提升破损图像子区域自适应划分标注精确度, 需要先对破损图像进行整体处理, 实现图像的模糊增强。详细过程如下:</p>
                </div>
                <div class="p1">
                    <p id="26">1) 计算图像模糊隶属度值。依据模糊集相关概念, 一幅图像<i>I</i>灰度级设置为<i>L</i>, 大小为<i>M</i>×<i>N</i>, 该图像能够当作模糊点集矩阵, 表现形式为:</p>
                </div>
                <div class="p1">
                    <p id="27" class="code-formula">
                        <mathml id="27"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>μ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mn>1</mn><mo>, </mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd><mtd><mi>μ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>μ</mi><msub><mrow></mrow><mrow><mn>1</mn><mi>Ν</mi></mrow></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mn>1</mn><mo>, </mo><mi>Ν</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>μ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mn>2</mn><mo>, </mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd><mtd><mi>μ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>2</mn></mrow></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mn>2</mn><mo>, </mo><mn>2</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>μ</mi><msub><mrow></mrow><mrow><mn>2</mn><mi>Ν</mi></mrow></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mn>2</mn><mo>, </mo><mi>Ν</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>⋯</mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mo>⋯</mo></mtd></mtr><mtr><mtd><mi>μ</mi><msub><mrow></mrow><mrow><mi>Μ</mi><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>Μ</mi><mo>, </mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd><mtd><mi>μ</mi><msub><mrow></mrow><mrow><mi>Μ</mi><mn>2</mn></mrow></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>Μ</mi><mo>, </mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>μ</mi><msub><mrow></mrow><mrow><mi>Μ</mi><mi>Ν</mi></mrow></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>Μ</mi><mo>, </mo><mi>Ν</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="28">其中, <i>μ</i><sub><i>ij</i></sub> (<i>I</i> (<i>i</i>, <i>j</i>) ) (0≤<i>μ</i><sub><i>ij</i></sub> (<i>I</i> (<i>i</i>, <i>j</i>) ) ≤1) 代表图像像素点<i>I</i> (<i>i</i>, <i>j</i>) 存在某种特点的程度, 通常情况下将其称作模糊隶属度。<i>μ</i><sub><i>ij</i></sub> (<i>I</i> (<i>i</i>, <i>j</i>) ) 经模糊隶属度函数获取, 不同隶属度函数对图像检测产生的影响效果不同。根据式 (1) 的计算, 可将隶属度函数定义为:</p>
                </div>
                <div class="p1">
                    <p id="29" class="code-formula">
                        <mathml id="29"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo><mi>Τ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>[</mo><mrow><mn>1</mn><mo>+</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>L</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>-</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow><mrow><mi>F</mi><msub><mrow></mrow><mi>d</mi></msub></mrow></mfrac></mrow><mo>]</mo></mrow><msup><mrow></mrow><mrow><mo>-</mo><mi>F</mi><msub><mrow></mrow><mi>e</mi></msub></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="30">式 (2) 中, <i>F</i><sub><i>d</i></sub>代表倒数模糊因子, <i>F</i><sub><i>e</i></sub>代表指数模糊因子, 通常<i>F</i><sub><i>e</i></sub>值为2, 选择可以满足<i>μ</i><sub><i>ij</i></sub> (<i>I</i> (<i>i</i>, <i>j</i>) ) =<i>μ</i><sub><i>c</i></sub> (<i>I</i> (<i>i</i>, <i>j</i>) ) =<i>T</i> (<i>I</i><sub><i>c</i></sub>) =0.5的<i>I</i><sub><i>c</i></sub>当作渡越点。其中渡越点通常通过<i>OTSU</i>法获取, 得到<i>I</i><sub><i>c</i></sub>与<i>F</i><sub><i>e</i></sub>, 就能够得到<i>F</i><sub><i>d</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="31">2) 破损图像模糊隶属度转换。基于模糊隶属度<i>μ</i><sub><i>ij</i></sub> (<i>I</i> (<i>i</i>, <i>j</i>) ) 与渡越点<i>I</i><sub><i>c</i></sub>, 通过模糊增强函数实现模糊隶属度非线性转换, 实现图像对比度增强。其中, 增强函数如式 (3) 所示:</p>
                </div>
                <div class="p1">
                    <p id="32" class="code-formula">
                        <mathml id="32"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>´</mo></msubsup><mo>=</mo><mi>E</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>μ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mi>E</mi><mo stretchy="false"> (</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>r</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>μ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>, </mo><mi>r</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mn>3</mn><mo>⋯</mo><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="33">式 (3) 中:</p>
                </div>
                <div class="p1">
                    <p id="34" class="code-formula">
                        <mathml id="34"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false"> (</mo><mi>μ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup><mo>, </mo><mn>0</mn><mo>≤</mo><mi>μ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>≤</mo><mn>0</mn><mo>.</mo><mn>5</mn></mtd></mtr><mtr><mtd><mn>1</mn><mo>-</mo><mn>2</mn><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>, </mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>≤</mo><mi>μ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>≤</mo><mn>1</mn></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="35">根据式 (4) 可知, 增强实质上即为对比渡越点<i>I</i><sub><i>c</i></sub>小的图像灰度值区域实行衰减计算, 针对比渡越点<i>I</i><sub><i>c</i></sub>大的图像灰度值区域实行增强计算。从理论上来讲, 利用迭代计算, 可以生成二值化图像<citation id="97" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="36">3) 模糊隶属度函数逆变换。综合上述计算与分析, 将非线性转换之后的<i>μ</i><sup>′</sup><sub><i>ij</i></sub>实行逆变换, 获取增强之后的图像。其中, 逆变换公式可表示为:</p>
                </div>
                <div class="p1">
                    <p id="37" class="code-formula">
                        <mathml id="37"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>Ι</mi><mo>′</mo></msup><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Τ</mi><mspace width="0.25em" /><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false"> (</mo><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>´</mo></msubsup><mo stretchy="false">) </mo><mo>=</mo><mi>L</mi><mo>-</mo><mn>1</mn><mo>+</mo><mi>F</mi><msub><mrow></mrow><mi>d</mi></msub><mrow><mo>[</mo><mrow><mn>1</mn><mo>-</mo><mo stretchy="false"> (</mo><mi>μ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo></mrow><mo>]</mo></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn><mo>/</mo><mi>F</mi><msub><mrow></mrow><mi>e</mi></msub></mrow></msup><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="38">式 (5) 中, <i>I</i>′代表增强后的图像。</p>
                </div>
                <h4 class="anchor-tag" id="39" name="39"><b>2.2 破损图像细节增强</b></h4>
                <div class="p1">
                    <p id="40">经2.1节图像整体增强后, 增强提取图像细节, 以提升子区域标注召回率。</p>
                </div>
                <div class="p1">
                    <p id="41">假设已经构建了梯度场, 期望包含输出破损图像中全部细节的辅助图像I″ (i, j) , 能够通过式 (6) 最优化问题得到:</p>
                </div>
                <div class="area_img" id="102">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201904097_10200.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="43">式 (6) 中, SymbolQCpI″ (i, j) 代表辅助图像在 (i, j) 位置灰度梯度, SymbolQCpY (i, j) 代表图像总梯度值。</p>
                </div>
                <div class="p1">
                    <p id="44">因为2.2节所用的方法使用在增强破损图像细节, 而不是增强轮廓信息, 所以I″中比较小的细节和比较大的特征要分离开。以降低运算复杂度为目的, 在对数域实现上述提到的分离<citation id="98" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。则有:</p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mi>G</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>+</mo><mi>G</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">式 (7) 中, G (i, j) 、G<sub>d</sub> (i, j) 和G<sub>b</sub> (i, j) 分别和<i>log</i> (I″) 、<i>log</i> (I″<sub>d</sub>) 和<i>log</i> (I″<sub>b</sub>) 相等, 其中I″<sub>b</sub>代表图像中的大特征, I″<sub>d</sub>代表图像中的小细节。</p>
                </div>
                <div class="p1">
                    <p id="47">据以上计算, 利用式 (8) 的二次函数分解G (i, j) :</p>
                </div>
                <div class="area_img" id="48">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201904097_04800.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="49">式 (8) 中, λ代表权重因子, 其功能为平衡G<sub>b</sub> (i, j) 相对于G (i, j) 存在的平滑性以及保真度, 将该值确定为0.7。</p>
                </div>
                <div class="p1">
                    <p id="50">经过上述分解, 可得到增强的细节层:</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>Ι</mi><mo>″</mo></msup><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mi>exp</mi><mo stretchy="false"> (</mo><mi>G</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mi>G</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">式 (9) 中, I″<sub>d</sub>代表增强细节后的破损图像。</p>
                </div>
                <h4 class="anchor-tag" id="53" name="53"><b>2.3 图像分割</b></h4>
                <div class="p1">
                    <p id="54">图像分割过程如下:</p>
                </div>
                <div class="p1">
                    <p id="55">1) 针对2.2节得到的增强细节后的破损图像I″<sub>d</sub>, 分别在I″<sub>d</sub>的x轴与y轴实行相邻像素差分计算, 并标记出梯度的突变像素点。差分计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><msup><mi>Ι</mi><mo>‴</mo></msup><msub><mrow></mrow><mrow><mi>d</mi><mi>x</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><msup><mi>Ι</mi><mo>″</mo></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><msup><mi>Ι</mi><mo>″</mo></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><msup><mi>Ι</mi><mo>‴</mo></msup><msub><mrow></mrow><mrow><mi>d</mi><mi>y</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><msup><mi>Ι</mi><mo>″</mo></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><msup><mi>Ι</mi><mo>″</mo></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">根据类间最大距离方式判断I″<sub>x</sub> (x, y) 、I″<sub>y</sub> (x, y) 为梯度突变点与否。假设在水平方向上I″<sub>dx</sub> (x, y) ≤Th, 那么该像素点不为灰度突变点, 将不对其进行改变;假设I″<sub>dx</sub> (x, y) &gt;Th, 那么该像素点是灰度突变点, 对该像素点作标记, 并转至步骤2) , 其中Th代表预设阈值。</p>
                </div>
                <div class="p1">
                    <p id="58">2) 针对步骤1) 中已经标记成梯度突变的像素点实行全面结构元素形态学中的腐蚀操作, 判断其中的像素点是否为噪声点, 假设为噪声点即滤除, 假设为目标边缘即保留, 进一步增强图像, 进而提升破损图像子区域自适应划分标注精度<citation id="99" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="59">在与x轴平行的方向上, 假设A代表将I″ (x, y) 当作中心的区域, 将其和图像结构元素矩阵B<sub>i</sub>分别实施多结构元素腐蚀操作后获取并集。假设AΘB<sub>1</sub>∪AΘB<sub>2</sub>∪AΘB<sub>3</sub>∪AΘB<sub>4</sub>≠Ø代表能够将B<sub>i</sub>中至少一个结构填充至待检测图像中, 那么该结构相对应破损图像区域范围内像素点中心位置是破损边缘像素点, 设定I″<sub>x</sub> (x, y) =255, 并返回至步骤1) 对下个像素点进行判断。假设AΘB<sub>1</sub>∪AΘB<sub>2</sub>∪AΘB<sub>3</sub>∪AΘB<sub>4</sub>=Ø代表B<sub>i</sub>中四个方向的结构都无法填充至待检测图像中, 那么该结构相对应破损图像区域范围内像素点中心位置是噪声点, 设定I″<sub>x</sub> (x, y) =0, 返回至步骤1) 对下个像素点进行判断。经过上述分析, 最后能够获取水平方向上二值化边缘的检测结果, 其中, 取值结果如下所示:</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>Ι</mi><mo>″</mo></msup><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>2</mn><mn>5</mn><mn>5</mn><mo>, </mo><msup><mi>Ι</mi><mo>″</mo></msup><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mtext>是</mtext><mtext>目</mtext><mtext>标</mtext><mtext>区</mtext><mtext>域</mtext><mtext>边</mtext><mtext>缘</mtext><mtext>的</mtext><mtext>像</mtext><mtext>素</mtext><mtext>点</mtext></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><msup><mi>Ι</mi><mo>″</mo></msup><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mtext>是</mtext><mtext>噪</mtext><mtext>声</mtext><mtext>像</mtext><mtext>素</mtext><mtext>点</mtext></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">利用相同的方式得到的与y轴平行方向上边缘检测图像为:</p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>Ι</mi><mo>″</mo></msup><msub><mrow></mrow><mi>y</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>2</mn><mn>5</mn><mn>5</mn><mo>, </mo><msup><mi>Ι</mi><mo>″</mo></msup><msub><mrow></mrow><mi>y</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mtext>是</mtext><mtext>目</mtext><mtext>标</mtext><mtext>区</mtext><mtext>域</mtext><mtext>边</mtext><mtext>缘</mtext><mtext>的</mtext><mtext>像</mtext><mtext>素</mtext><mtext>点</mtext></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><msup><mi>Ι</mi><mo>″</mo></msup><msub><mrow></mrow><mi>y</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mtext>是</mtext><mtext>噪</mtext><mtext>声</mtext><mtext>像</mtext><mtext>素</mtext><mtext>点</mtext></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63">3) 综合步骤2) 平行于横纵轴方向上图像二值化分割结果, 通过棋盘距离得到初始边缘分割的破损图像和分割阈值T′。其中初始边缘分割的破损图像J (x, y) 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>max</mi><mo stretchy="false"> (</mo><msup><mi>Ι</mi><mo>″</mo></msup><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>, </mo><msup><mi>Ι</mi><mo>″</mo></msup><msub><mrow></mrow><mi>y</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">4) 通过改进最大互信息量法计算最优分割图像。假设图像分割影响参量δ=15, 按照步骤3) 获取初始的阈值T′, 则可在区间<mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><msup><mi>Τ</mi><mo>′</mo></msup><mo>-</mo><mi>δ</mi><mo>, </mo><msup><mi>Τ</mi><mo>′</mo></msup><mo>+</mo><mi>δ</mi></mrow><mo>]</mo></mrow></mrow></math></mathml>范围内循环调节分割阈值, 则有:</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>Τ</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi></mrow></msub><mo>=</mo><mi>arg</mi><mspace width="0.25em" /><mi>max</mi><mo stretchy="false"> (</mo><mi>Μ</mi><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>Ι</mi><mo>″</mo></msup><mo>, </mo><mi>J</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">式 (15) 中, T′<sub>op</sub>代表最优分割阈值, MI (I″, J) 代表I″和J间的互信息。利用该分割阈值得到分割之后的图像集D′为:</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>D</mi><mo>′</mo></msup><mo>=</mo><msup><mi>Τ</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>o</mi><mi>p</mi></mrow></msub><mo>⋅</mo><mrow><mo>[</mo><mrow><mi>Μ</mi><mi>Ι</mi><mo stretchy="false"> (</mo><msup><mi>Ι</mi><mo>″</mo></msup><mo>, </mo><mi>J</mi><mo stretchy="false">) </mo><mo>⋅</mo><msup><mi>Ι</mi><mo>″</mo></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="70" name="70"><b>2.4 破损图像子区域自适应划分标注实现</b></h4>
                <div class="p1">
                    <p id="71">基于2.1节至2.3节图像处理, 利用多示例学习法实现破损图像子区域自适应划分标注。</p>
                </div>
                <div class="p1">
                    <p id="72">根据多样性密度运行思想可知, 要在破损图像中确定一个最优标注, 将每幅图像当作一个包, 经分割之后, 每幅图像块当作包中一个示例。针对标注集合是K的图像F而言, 将其当作一个包, 那么图像块z<sub>i</sub>∈F就是包中一个示例, 针对图像集合D′来说, 在多示例学习中可表示为:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>D</mi><mo>′</mo></msup><mo>=</mo><mrow><mo>{</mo><mrow><mi>S</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>Κ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>}</mo></mrow><mo>⋅</mo><mi>V</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">其中, K<sub>i</sub>代表S<sub>i</sub>相应的标注集合, V代表D′中图像的数量, 将D′当作学习样本。针对标注k∈K来说, 假设图像S<sub>i</sub>中有此标注则可将其标记为正包, 相反的则标记为负包。利用计算z<sub>i</sub>和正包、负包间距离, 能够获取z<sub>i</sub>不同标注k之下的得分Sc值, 选择Sc值最大时的标注当作破损图像块示例z<sub>i</sub>最佳标注。其中Sc计算表达式为:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mi>c</mi><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mi>k</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mo>∑</mo><mtext>m</mtext></mstyle><mtext>i</mtext><mtext>n</mtext><mi>S</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mstyle displaystyle="true"><mo>∑</mo><mrow><mrow><mo>[</mo><mrow><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext><mi>S</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi>Ο</mi><mi>t</mi></mrow><mo>]</mo></mrow></mrow></mstyle></mrow><mi>V</mi></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">式 (18) 中:</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><mi>t</mi><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext><mi>S</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext><mi>S</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">上式中, Sc (m, k) 代表标注k时图像块m得分值Sc, <i>min</i>S<sub>i</sub>代表图像特征空间范围内假设示例m近邻中存在来源于包S<sub>i</sub>中任意一个示例或者S<sub>i</sub>中任意一个示例近邻范围内存在示例m, 那么将示例m和包S<sub>i</sub>称作近邻关系, 并将值定义为1, 反之将值定义为0。<i>max</i>S<sub>i</sub>代表在破损图像特征空间范围内, 除了和示例m是近邻关系的包, 假设距离示例m最远的若干个示例中存在来源于包S<sub>i</sub>的任意一个示例或者S<sub>i</sub>中任意一个示例的远邻中存在示例m, 那么取值定义为1, 反之将值定义为0。</p>
                </div>
                <div class="p1">
                    <p id="79">综上, 可利用式 (18) 选择<i>Sc</i>值最大时的标注当作破损图像块示例最佳标注, 以此完成破损图像子区域自适应划分标注。</p>
                </div>
                <h3 id="80" name="80" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="81">为验证基于多示例学习的破损图像子区域自适应划分标注方法可行性, 进行一次仿真。实验过程中使用Visual C++6.0实现所提方法, 用到的PC机主频是2.0GHz, 显存是1GB。实验图像来自于real-vorld图像集合。所提方法性能验证通过不同方法在以下方面对比实现:</p>
                </div>
                <div class="p1">
                    <p id="82">①图像标注准确率</p>
                </div>
                <div class="p1">
                    <p id="83">②图像标注召回率</p>
                </div>
                <div class="p1">
                    <p id="84">实验结果如下所示:</p>
                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904097_085.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图1 不同方法标注准确率对比" src="Detail/GetImg?filename=images/JSJZ201904097_085.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图1 不同方法标注准确率对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904097_085.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="86">分析图<b>1</b>可知, 基于多示例学习的破损图像子区域自适应划分标注方法标注准确率高于文献方法。所提方法为了提升破损图像子区域自适应划分标注准确率, 先对破损图像进行了整体处理, 实现图像的模糊增强, 初步提升了图像子区域自适应划分标注准确率。在图像分割中对于已经标记成梯度突变的像素点, 实行全面结构元素形态学中的腐蚀操作, 判断其中的像素点是否为噪声点, 不仅进一步增强了图像, 也进一步提高了破损图像子区域自适应划分标注精度。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904097_087.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图2 不同方法标注召回率对比" src="Detail/GetImg?filename=images/JSJZ201904097_087.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图2 不同方法标注召回率对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904097_087.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="88">分析图<b>2</b>可知, 所提方法召回率, 即图像子区域自适应划分标注查全率更高。该方法在对图像进行整体增强后, 在对数域上分离图像中大特征和小细节, 由采用二次函数分解图像中的大特征, 由此得到破损图像细节, 在很大程度上有效增强了方法的查全性能, 也就是提高了图像标注召回率。</p>
                </div>
                <div class="p1">
                    <p id="89">从上述两个实验中可以看出, 基于多示例学习的破损图像子区域自适应划分标注方法具有很强标注性能, 可为该领域发展提供十分可靠的依据。</p>
                </div>
                <h3 id="90" name="90" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="91">图像标注作为图像处理技术中的一种, 其研究价值不言而喻。当前相关研究方法性能待完善, 提出基于多示例学习的破损图像子区域自适应划分标注方法。分别利用增强图像整体和细节及分割图像为子区域标注奠定基础, 最后结合多样性密度法运行理念, 利用多示例学习法实现破损图像子区域自适应划分标注。通过实验证明了所提方法标注性能优越, 具有可实践性和实用性。下一步可针对抽象类别的图像标注进行研究, 以拓宽图像标注研究范围。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="101" type="formula" href="images/JSJZ201904097_10100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">杨柳</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201703001&amp;v=MTU1OTVrVnIvUEtEN1liTEc0SDliTXJJOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeS8=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[1]</b> 柯逍, 周铭柯, 牛玉贞.融合深度特征和语义邻域的自动图像标注[J].模式识别与人工智能, 2017, 30 (3) :193-203.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201702085&amp;v=MDI3NTFtRnkva1ZyL1BMejdCZExHNEg5Yk1yWTlOWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[2]</b> 李冰锋, 唐延东, 韩志.基于超图直推非负矩阵分解的图像标注法研究[J].计算机仿真, 2017, 34 (2) :380-384.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201701041&amp;v=MTQ4Mjc0SDliTXJvOUJaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeS9rVnIvUEx6N0JkN0c=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[3]</b> 高耀东, 侯凌燕, 杨大利.基于多标签学习的卷积神经网络的图像标注方法[J].计算机应用, 2017, 37 (1) :228-232.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201606043&amp;v=MjAwMDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeS9rVnIvUEx6N0JiYkc0SDlmTXFZOUJaNFFLREg=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[4]</b> 王建文, 林劼.基于颜色直方图金字塔的图像自动标注方法[J].计算机工程, 2016, 42 (6) :235-240.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201702008&amp;v=MTA1NTdyL1BOeWZUYkxHNEg5Yk1yWTlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnkva1Y=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[5]</b> 张博, 郝杰, 马刚, 等.基于弱匹配概率典型相关性分析的图像自动标注[J].软件学报, 2017, 28 (2) :292-309.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJS201704016&amp;v=MDY2MTdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5L2tWci9QSWpYQmZiRzRIOWJNcTQ5RVk=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[6]</b> 张奎, 陈兆学.一种基于游程码的二值图像孔洞标记和表达方法[J].光学技术, 2017, 43 (4) :364-368.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKJD201707001&amp;v=MDk4OTlQUHliQmFyRzRIOWJNcUk5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5L2tWci8=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[7]</b> 黄冬梅, 许琼琼, 杜艳玲, 等.基于DBNMI模型的海洋遥感影像自动标注方法[J].中国科学技术大学学报, 2017, 47 (7) :541-546.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201708018&amp;v=MzA0NTR6cXFCdEdGckNVUjdxZlp1Wm1GeS9rVnIvUEx6N0JaYkc0SDliTXA0OUViSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[8]</b> 秦煜, 吴静静, 安伟.基于RANSAC的激光网格标记图像特征提取[J].计算机工程与科学, 2017, 39 (8) :1495-1501.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201904097" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201904097&amp;v=MTk4ODFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnkva1ZyL1BMejdCZExHNEg5ak1xNDlNWTRRS0Q=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
