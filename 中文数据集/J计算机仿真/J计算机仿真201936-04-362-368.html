<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141821374975000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201904076%26RESULT%3d1%26SIGN%3dswAwY8O2e0TtpZ22h%252fD70lQSadE%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201904076&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201904076&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201904076&amp;v=MzEwNzFtRnl6aFY3ckpMejdCZExHNEg5ak1xNDlDWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#39" data-title="&lt;b&gt;2 计算模型&lt;/b&gt; "><b>2 计算模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="&lt;b&gt;2.1 轮廓信息的二值化提取&lt;/b&gt;"><b>2.1 轮廓信息的二值化提取</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;2.2 多尺度轮廓信息融合方法&lt;/b&gt;"><b>2.2 多尺度轮廓信息融合方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#69" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="&lt;b&gt;3.1 基于RuG数据库的实验&lt;/b&gt;"><b>3.1 基于RuG数据库的实验</b></a></li>
                                                <li><a href="#83" data-title="&lt;b&gt;3.2 基于BSDS300数据库的实验&lt;/b&gt;"><b>3.2 基于BSDS300数据库的实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#93" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#41" data-title="&lt;b&gt;图1 多尺度轮廓融合方法&lt;/b&gt;"><b>图1 多尺度轮廓融合方法</b></a></li>
                                                <li><a href="#58" data-title="&lt;b&gt;图2 不同尺度下的轮廓图&lt;/b&gt;"><b>图2 不同尺度下的轮廓图</b></a></li>
                                                <li><a href="#60" data-title="&lt;b&gt;图3 不同尺度下的邻域判断及权重选取&lt;/b&gt;"><b>图3 不同尺度下的邻域判断及权重选取</b></a></li>
                                                <li><a href="#76" data-title="&lt;b&gt;表1 实验参数设置&lt;/b&gt;"><b>表1 实验参数设置</b></a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;图4 各方法在RuG数据库下的实验结果对比&lt;/b&gt;"><b>图4 各方法在RuG数据库下的实验结果对比</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;图5 各个方法的平均P值&lt;/b&gt;"><b>图5 各个方法的平均P值</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;图6 各方法在RuG数据库实验结果对比&lt;/b&gt;"><b>图6 各方法在RuG数据库实验结果对比</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;图7 各种轮廓检测方法的PR曲线和F值&lt;/b&gt;"><b>图7 各种轮廓检测方法的PR曲线和F值</b></a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;图8 各方法在BSDS300数据库实验结果对比&lt;/b&gt;"><b>图8 各方法在BSDS300数据库实验结果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     J Canny.A Computational Approach to Edge Detection[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 1986, 8 (6) :679.</a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" D H Hubel, T N Weisel.T N Wiesel.Receptive fields, binocular interaction and functional architecture in cat&#39;s visual cortex[J].J.Physiol. (London) 160, 106-154.1962, 160." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Receptive fields, binocular interaction and functional architecture in the cat&amp;#39;s visual cortex">
                                        <b>[2]</b>
                                         D H Hubel, T N Weisel.T N Wiesel.Receptive fields, binocular interaction and functional architecture in cat&#39;s visual cortex[J].J.Physiol. (London) 160, 106-154.1962, 160.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" N Petkov, M A Westenberg.Suppression of contour perception by band-limited noise and its relation to nonclassical receptive field inhibition[J].Biological Cybernetics, 2003, 88 (3) :236-246." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003245619&amp;v=MzA2ODc5U1hxUnJ4b3hjTUg3UjdxZForWnVGaURsVjd2TUpWOD1OajdCYXJPNEh0SFByWXRBWXVvR1kzazV6QmRoNGo5&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[3]</b>
                                         N Petkov, M A Westenberg.Suppression of contour perception by band-limited noise and its relation to nonclassical receptive field inhibition[J].Biological Cybernetics, 2003, 88 (3) :236-246.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" C Grigorescu, N Petkov, M A Westenberg.Contour detection based on nonclassical receptive field inhibition[M].IEEE Press, 2003." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contour detection based on nonclassical receptive field inhibition">
                                        <b>[4]</b>
                                         C Grigorescu, N Petkov, M A Westenberg.Contour detection based on nonclassical receptive field inhibition[M].IEEE Press, 2003.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Q Tang, N Sang, T Zhang.Extraction of salient contours from cluttered scenes[J].Pattern Recognition, 2007, 40 (11) :3100-3109." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739413&amp;v=Mjc1MjJadEZpbmxVcmZJSkZvUWJ4TT1OaWZPZmJLN0h0RE5xWTlGWStnR0NIMDZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZQ==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[5]</b>
                                         Q Tang, N Sang, T Zhang.Extraction of salient contours from cluttered scenes[J].Pattern Recognition, 2007, 40 (11) :3100-3109.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 杜晓凤, 李翠华, 李晶.基于复合感受野的轮廓检测方法[J].电子与信息学报, 2009, 31 (7) :1630-1634." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX200907022&amp;v=Mjc5MzlHRnJDVVI3cWZadVptRnl6aFY3ckpJVGZTZHJHNEh0ak1xSTlIWm9RS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[6]</b>
                                         杜晓凤, 李翠华, 李晶.基于复合感受野的轮廓检测方法[J].电子与信息学报, 2009, 31 (7) :1630-1634.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" C Zeng, et al.Contour detection based on a non-classical receptive field model with butterfly-shaped inhibition subregions[J].Neurocomputing, 2011, 74 (10) :1527-1534." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501911359&amp;v=MDUzMjd3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmZJSkZvUWJ4TT1OaWZPZmJLN0h0RE5xbzlFYmVvT0Qzaw==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[7]</b>
                                         C Zeng, et al.Contour detection based on a non-classical receptive field model with butterfly-shaped inhibition subregions[J].Neurocomputing, 2011, 74 (10) :1527-1534.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" G Papari, N Petkov.An improved model for surround suppression by steerable filters and multilevel inhibition with application to contour detection[J].Pattern Recognition, 2011, 44 (9) :1999-2007." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738161&amp;v=MDQ0OTNiSzdIdEROcVk5RlkrZ0hEWG80b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmZJSkZvUWJ4TT1OaWZPZg==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[8]</b>
                                         G Papari, N Petkov.An improved model for surround suppression by steerable filters and multilevel inhibition with application to contour detection[J].Pattern Recognition, 2011, 44 (9) :1999-2007.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 林川, 李亚, 曹以隽.考虑微动机制与感受野特性的轮廓检测模型[J].计算机工程与应用, 2016, 52 (24) :210-216." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201624039&amp;v=MDUwNTZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXpoVjdySkx6N01hYkc0SDlmT3E0OUc=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[9]</b>
                                         林川, 李亚, 曹以隽.考虑微动机制与感受野特性的轮廓检测模型[J].计算机工程与应用, 2016, 52 (24) :210-216.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" K F Yang, C Y Li, Y J Li.Multifeature-based surround inhibition improves contour detection in natural images[J].IEEE Transactions on Image Processing, 2014, 23 (12) :5020-5032." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multifeature-based surround inhibition improves contour detection in natural images">
                                        <b>[10]</b>
                                         K F Yang, C Y Li, Y J Li.Multifeature-based surround inhibition improves contour detection in natural images[J].IEEE Transactions on Image Processing, 2014, 23 (12) :5020-5032.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" S G Mallat.A Theory for Multiresolution Signal Decomposition:The Wavelet Representation[M].IEEE Computer Society, 1989." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A theory for multi-resolution signal decomposition: The wavelet representation">
                                        <b>[11]</b>
                                         S G Mallat.A Theory for Multiresolution Signal Decomposition:The Wavelet Representation[M].IEEE Computer Society, 1989.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" R L D Valois, D G Albrecht, L G Thorell.Spatial frequency selectivity of cells in macaque visual cortex[J].Vision Research, 1982, 22 (5) :545-559." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatial frequency selectivity of cells in macaque visual cortex">
                                        <b>[12]</b>
                                         R L D Valois, D G Albrecht, L G Thorell.Spatial frequency selectivity of cells in macaque visual cortex[J].Vision Research, 1982, 22 (5) :545-559.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" T Lindeberg.Edge detection and ridge detection with automatic scale selection[J].International Journal of Computer Vision, 1998, 30 (2) :117-156." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830520&amp;v=MjY4MzRrUFkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1RmlEbFY3dk1KVjg9Tmo3QmFyTzRIdEhPcDR4Rlll&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[13]</b>
                                         T Lindeberg.Edge detection and ridge detection with automatic scale selection[J].International Journal of Computer Vision, 1998, 30 (2) :117-156.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" X Ren.Multi-scale Improves Boundary Detection in Natural Images[C].European Conference on Computer Vision.Springer-Verlag, 2008:533-545." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-scale improves boundary detection in natural images">
                                        <b>[14]</b>
                                         X Ren.Multi-scale Improves Boundary Detection in Natural Images[C].European Conference on Computer Vision.Springer-Verlag, 2008:533-545.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 寿天德.视觉信息处理的脑机制[M].合肥:中国科学技术大学出版社, 2010:152-158." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787312027031001&amp;v=MTgzODFJOUdaZXNQRFJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW50VTd2TUpGc1ZYRnF6R2JDNUhOSE9x&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[15]</b>
                                         寿天德.视觉信息处理的脑机制[M].合肥:中国科学技术大学出版社, 2010:152-158.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" 刘曙, 罗予频, 杨士元.基于多尺度的轮廓匹配方法[J].计算机工程, 2008, 34 (1) :201-203." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC200801071&amp;v=MzE5MzBuTXJvOUNaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXpoVjdySkx6N0JiYkc0SHQ=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[16]</b>
                                         刘曙, 罗予频, 杨士元.基于多尺度的轮廓匹配方法[J].计算机工程, 2008, 34 (1) :201-203.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(04),362-368             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>视觉仿生轮廓检测中多尺度融合方法研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9E%97%E5%B7%9D&amp;code=33176360&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">林川</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E8%B6%8A&amp;code=34656484&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">郭越</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%9F%A6%E6%B1%9F%E5%8D%8E&amp;code=33177890&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">韦江华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%B9%E4%BB%A5%E9%9A%BD&amp;code=33177575&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">曹以隽</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E8%A5%BF%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E7%94%B5%E6%B0%94%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1698713&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">广西科技大学电气与信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>从复杂自然场景中检测目标轮廓是计算机视觉的重要任务之一。研究表明, 初级视皮层 (V1区) 中神经元对外界刺激的响应是经典感受野 (CRF) 和非经典感受野 (nCRF) 共同作用的结果, 机制可有效用于消除背景纹理。结合多尺度分析, 研究基于该机制的轮廓检测, 提出一种多尺度融合方法。首先通过仿非经典感受野的周边抑制特性, 获得不同尺度下的多幅轮廓信息二值图;接着以最小尺度轮廓信息二值图为基准, 判断各像素最优方向两侧相应范围内是否存在其它尺度的下的轮廓信息, 同时利用高斯函数对相关信息进行加权融合, 获得图像的权重图;最后对权重图进行非极大值抑制和二值化, 得到最终轮廓检测融合结果。实验结果表明, 与原轮廓检测方法相比, 上述方法可以有效提升轮廓检测的效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BD%AE%E5%BB%93%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">轮廓检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E7%BB%8F%E5%85%B8%E6%84%9F%E5%8F%97%E9%87%8E&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">非经典感受野;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%B0%BA%E5%BA%A6&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">多尺度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">融合;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    林川 (1979-) , 男 (汉族) , 湖北人, 教授, 硕士生导师, 研究领域为仿生智能计算、模式识别。;
                                </span>
                                <span>
                                    郭越 (1992-) , 男 (汉族) , 山西省孝义人, 硕士研究生, 研究领域为图像处理、模式识别。;
                                </span>
                                <span>
                                    韦江华 (1982-) , 男 (汉族) , 广西人, 实验师, 研究领域为模式识别。;
                                </span>
                                <span>
                                    曹以隽 (1992-) , 男 (汉族) , 广西桂林人, 硕士研究生, 研究领域为机器学习、模式识别。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2017-12-06</p>

                    <p>

                            <b>基金：</b>
                                                        <span>广西自然科学基金资助 (2015GXNSFAA139293);</span>
                                <span>广西教育厅科研项目 (YB2014207);</span>
                                <span>广西科技大学研究生教育创新计划项目 (GKYC201706);</span>
                    </p>
            </div>
                    <h1><b>Research on Visual Bionic Contour Detection Via Multi-Scale Fusion</b></h1>
                    <h2>
                    <span>LIN Chuan</span>
                    <span>GUO Yue</span>
                    <span>WEI Jiang-hua</span>
                    <span>CAO Yi-jun</span>
            </h2>
                    <h2>
                    <span>College of Electric and Information Engineering, Guangxi University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In computer vision, contour detection from complex scene is one of the most important tasks. Research suggests that the response of neurons in primary visual cortex (V1 area) is not only related to its Classical Receptive Field (CRF) , but also modulated by its non-Classical Receptive Field (nCRF) . This interaction is useful for eliminating background textures. Based on this perception mechanism and multi-resolution analysis, a multi-scale contour fusion method is proposed. At first, based on the physiological characteristics of the non-Classical Receptive Field, multi-scale contours with surround inhibition were obtained. Based on the minimum scale contour binary map, the current pixels with the optimal direction on both sides were used to determine whether there are pixels on other contour maps. After that, the Gaussian function was used to weight the relevant information and obtain the weight graph of the image. Finally, the weight graph was subjected to non-maximum suppression and binarization to obtain the final results. Comparied with original method, the proposed model can improve the performance effectively in contour detection.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Contour%20detection&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Contour detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Non-classical%20reptive%20field&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Non-classical reptive field;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-scale&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Multi-scale;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Fusion&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Fusion;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2017-12-06</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="36">轮廓检测是从含有大量噪声和背景纹理的图像中提取人类感兴趣的目标轮廓的过程。轮廓检测的关键是在提取目标轮廓的同时减少背景纹理的干扰。传统的边缘检测方法, 如Canny边缘检测算子<citation id="96" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>只能检测图像灰度的变化, 不能区分检测到的边缘是轮廓还是背景, 检测结果中存在大量纹理。Hubel和Wiesel<citation id="97" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>发现人类视觉系统中有大量用于轮廓检测的细胞, 通过不同神经元间的相互作用可以有效提取轮廓, 奠定了轮廓检测、目标识别等方面的生理学基础。研究显示, 人类初级视皮层中的神经细胞存在周边抑制的神经机制, 即神经元经典感受野的响应会被其周边的非经典感受野响应所调制, 这对于轮廓检测消除背景噪声是至关重要的<citation id="98" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。现有的模拟感受野特性的轮廓检测方法, 其核心方法是采用圆环形或蝶形的抑制模板模拟纹理抑制的权重。Grigorescu等人于2003年最先提出采用圆环形的高斯差分算子模型模拟距离权值, 提出两种抑制模型:各向同性抑制和各向异性抑制<citation id="99" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 比传统的边缘检测方法可以更好地区分纹理和轮廓, 为之后的研究奠定了基础。文献<citation id="100" type="reference">[<a class="sup">5</a>]</citation>针对文献<citation id="101" type="reference">[<a class="sup">4</a>]</citation>方法中自抑制的缺点, 提出在非经典感受野的抑制区两侧加入两个去抑制区, 采用蝶形的抑制模型取代圆环形抑制模型, 减少了自抑制的影响。文献<citation id="102" type="reference">[<a class="sup">6</a>]</citation>在此基础上加入了与距离和角度这两个特征信息有关的函数作为抑制区和易化区的权重, 考虑了轮廓上下文间的相互作用。文献<citation id="103" type="reference">[<a class="sup">7</a>]</citation>认为非经典感受野抑制通常是空间不对称的, 据此提出一种新的蝶形抑制模型。文献<citation id="104" type="reference">[<a class="sup">8</a>]</citation>通过采用方向可变的滤波器避免了自抑制现象, 提出的多层抑制方法使得非经典感受野抑制等级无需人工设定。近年来, 文献<citation id="105" type="reference">[<a class="sup">9</a>]</citation>考虑微动机制, 将圆环形模板按等间隔角度生成八方向DoG子模板, 使其更符合人眼的生理特性。文献<citation id="106" type="reference">[<a class="sup">10</a>]</citation>把方向、亮度、对比度三个特征整合起来调制周边抑制强度, 与单特征调制相比取得了更好的效果。</p>
                </div>
                <div class="p1">
                    <p id="37">上述模型从非经典感受野的角度进行了改进, 取得了一定的效果。而多分辨率小波分析显示<citation id="107" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 在大尺度下, 图像细节消失只保留大致的轮廓。这说明纹理只在小尺度出现, 选取合适的尺度可以实现轮廓的保留和纹理的消除。通过模拟不同尺度下神经元细胞响应的相互抑制特性<citation id="108" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 有助于融合不同尺度下的轮廓信息。如何将不同尺度下的信息进行有效整合已经成为轮廓检测的新热点, 大多数研究从抑制模板的角度出发, 将不同尺度下得到的轮廓纹理信息进行分类整合。</p>
                </div>
                <div class="p1">
                    <p id="38">本文的主要贡献是在传统的周边抑制模型中加入多尺度下轮廓信息的融合。针对获得的多尺度下轮廓信息二值图, 以保留图像信息最多的最小尺度下的轮廓点为基准点, 通过其它尺度下轮廓点与基准点的比较处理得到最后的权重矩阵, 对权重矩阵进行非极大值抑制和二值化处理获得最终轮廓。为了验证本文方法的有效性, 分别将本文提出的多尺度融合方法与文献<citation id="109" type="reference">[<a class="sup">4</a>,<a class="sup">9</a>,<a class="sup">10</a>]</citation>有效整合, 与原轮廓检测结果进行对比表明, 本文所提出的方法不仅改进了原有方法, 也具有较好的检测效果。</p>
                </div>
                <h3 id="39" name="39" class="anchor-tag"><b>2 计算模型</b></h3>
                <div class="p1">
                    <p id="40">本章提出了多个尺度下二值化轮廓图的融合方法用于轮廓检测。首先得到多尺度处理后的一系列二值化图像;接着以尺度最小的图像为基准, 利用邻域对其它尺度下图像中的像素点的偏移进行判断;对判断信息进行高斯函数加权融合得到权重矩阵;最后对权重矩阵进行非极大值抑制和二值化处理得到最终输出。该模型的总体框架如图1所示。</p>
                </div>
                <div class="area_img" id="41">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904076_041.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图1 多尺度轮廓融合方法" src="Detail/GetImg?filename=images/JSJZ201904076_041.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图1 多尺度轮廓融合方法</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904076_041.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="42" name="42"><b>2.1 轮廓信息的二值化提取</b></h4>
                <div class="p1">
                    <p id="43">对于初级视皮层中具有方向选择性的简单细胞, 文献<citation id="110" type="reference">[<a class="sup">4</a>]</citation>提出采用一族二维<b>Gabor</b>函数模拟其经典感受野, 其公式如下</p>
                </div>
                <div class="p1">
                    <p id="44" class="code-formula">
                        <mathml id="44"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mi>φ</mi><mo stretchy="false">) </mo><mo>=</mo><mi>exp</mi><mo stretchy="false"> (</mo><mfrac><mrow><mover accent="true"><mi>X</mi><mo>˜</mo></mover><mo>+</mo><mi>γ</mi><mover accent="true"><mi>Y</mi><mo>˜</mo></mover><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">) </mo><mi>cos</mi><mo stretchy="false"> (</mo><mn>2</mn><mtext>π</mtext><mfrac><mover accent="true"><mi>X</mi><mo>˜</mo></mover><mi>λ</mi></mfrac><mo>+</mo><mi>φ</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mover accent="true"><mi>X</mi><mo>˜</mo></mover><mo>=</mo><mi>x</mi><mtext>c</mtext><mtext>o</mtext><mtext>s</mtext><mspace width="0.25em" /><mi>θ</mi><mo>+</mo><mi>y</mi><mtext>s</mtext><mtext>i</mtext><mtext>n</mtext><mspace width="0.25em" /><mi>θ</mi><mo>, </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mover accent="true"><mi>Y</mi><mo>˜</mo></mover><mo>=</mo><mo>-</mo><mi>x</mi><mtext>s</mtext><mtext>i</mtext><mtext>n</mtext><mspace width="0.25em" /><mi>θ</mi><mo>+</mo><mi>y</mi><mtext>c</mtext><mtext>o</mtext><mtext>s</mtext><mspace width="0.25em" /><mi>θ</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="45">其中<i>γ</i>=<b>0.5</b>, 决定了感受野的椭圆度;标准差<i>σ</i>决定了感受野的大小, 也就是本文中提到的尺度;参数<i>λ</i>是波长, <b>1</b>/<i>λ</i>是余弦函数的空间频率;<i>δ</i>/<i>λ</i>=<b>0.56</b>是空间频率带宽;<i>φ</i>是相角参数 (<i>φ</i>∈ (-π, π]) ;<i>θ</i>为<b>Gabor</b>函数的方向参数 (<i>θ</i>∈[<b>0</b>, π) ) 。</p>
                </div>
                <div class="p1">
                    <p id="46">简单细胞感受野函数与输入图像<b><i>f</i> (<i>x</i>, <i>y</i></b>) 的响应<b><i>r</i> (<i>x</i>, <i>y</i></b>, <i>λ</i>, <i>σ</i>, <i>θ</i>, <i>φ</i>) 是二者的卷积:</p>
                </div>
                <div class="p1">
                    <p id="47" class="code-formula">
                        <mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mi>φ</mi><mo stretchy="false">) </mo><mo>=</mo><mi>f</mi><mo>*</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mi>φ</mi><mo stretchy="false">) </mo><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="48">*为卷积符号。</p>
                </div>
                <div class="p1">
                    <p id="49">复杂细胞的感受野模型是一对相位差为π/<b>2</b>简单细胞响应的平方和再开方, 叫<b><i>Gabor</i></b>能量</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>e</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><msqrt><mrow><mi>r</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mn>0</mn><mo stretchy="false">) </mo><mo>+</mo><mi>r</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>λ</mi><mo>, </mo><mi>σ</mi><mo>, </mo><mi>θ</mi><mo>, </mo><mo>-</mo><mfrac><mtext>π</mtext><mn>2</mn></mfrac><mo stretchy="false">) </mo></mrow></msqrt><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51"><i>θ</i><sub><b><i>N</i></b></sub>表示方向参数的个数, <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mtext>π</mtext></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>θ</mi></msub></mrow></mfrac><mo>, </mo><mtext> </mtext><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ν</mi><msub><mrow></mrow><mi>θ</mi></msub></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="53">非经典感受野采用如下二维高斯差分函数 (<b>DoG</b>) 作为模板</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>D</mi><mi>o</mi><mi>G</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mtext>π</mtext><mo stretchy="false"> (</mo><mn>4</mn><mi>σ</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mfrac><mrow><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>y</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mo stretchy="false"> (</mo><mn>4</mn><mi>σ</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>-</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mtext>π</mtext><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mfrac><mrow><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>y</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">通过标准化的<b>DoG</b>函数和<b>Gabor</b>能量做卷积得到抑制项。感受野的最终响应为经典感受野响应减去非经典感受野的响应。最后采用非极大值抑制和双阈值处理得到二值化的轮廓图。后续的轮廓检测方法都是在此基础上进行研究的。</p>
                </div>
                <h4 class="anchor-tag" id="56" name="56"><b>2.2 多尺度轮廓信息融合方法</b></h4>
                <div class="p1">
                    <p id="57">生理研究表明<citation id="111" type="reference"><link href="27" rel="bibliography" /><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>, 到达人眼视觉系统的图像信息不仅依靠物理场景的光强度分布, 也取决于其到眼睛的距离。图像信息的分辨率与感受野的半径大小成反比。物理场景的多尺度呈现是通过细胞感受野的尺度变化来体现的。多尺度分析在仿生视觉研究中的作用越来越重要。如图<b>2</b>所示, 图<b>2 (a</b>) 到图<b>2 (c</b>) 分别是从小到大尺度下按照<b>2.1</b>节方法获得的二值化轮廓图, 在小尺度下轮廓信息虽然比较完整, 但也包含了很多纹理;在大尺度下虽然有部分纹理被移除, 但是原有轮廓也被破坏。现有的很多轮廓检测方法只考虑视神经元单一尺度下非经典感受野模板的改进, 或者视神经元间的上下文整合。对于同一幅图像, 在保留轮廓信息的同时尽可能的去除背景纹理是互相矛盾的, 但是采用合理的多尺度信息融合可以在两者之间达到一种平衡。</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904076_058.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图2 不同尺度下的轮廓图" src="Detail/GetImg?filename=images/JSJZ201904076_058.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图2 不同尺度下的轮廓图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904076_058.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="59">多尺度下二值化轮廓图的融合需要考虑以下两个问题:由于使用高斯函数进行滤波, 随着滤波参数的增大, 轮廓会变的越来越平滑, 与小尺度时相比轮廓会产生一定的偏移<citation id="112" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 这对于最终轮廓的确定会产生一定的影响;另外, 每个尺度下的二值图中所包含的轮廓纹理信息不尽相同, 其在最终的融合过程中所起的作用也有所区别, 如何确定其所占的权重也是要考虑的。针对上述问题, 本文提出了如下的解决方法:对于尺度变化所导致的轮廓形变, 其变化并不是没有规律的, 像素点的偏移总是以其最优方向为基准, 向两侧进行平行移动, 且尺度越大, 像素偏移越多。根据该规律, 本文以尺度最小轮廓图中的像素点为基准, 采用大小变化的邻域去判断这些偏移是否是属于轮廓点的偏移。选择尺度最小的轮廓图作为基准是因为尺度最小轮廓图中像素点位置最为精准, 且尺度最小图像中的轮廓和纹理信息最多。构造以尺度最小的轮廓图中像素点为中心, 大小不断扩大的邻域, 判断该像素点最优方向两侧区域内是否发生原像素点的偏移。这里选取是因为要尽量避免非偏移像素点对判断的干扰。对于不同尺度下得到的轮廓信息, 接着通过加权以区分其在确定最终轮廓中所占的比重, 对加权后的矩阵进行求和得到最后的权重矩阵。最终对权重矩阵进行非极大值抑制和二值化得到最终的轮廓图。</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904076_060.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图3 不同尺度下的邻域判断及权重选取" src="Detail/GetImg?filename=images/JSJZ201904076_060.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图3 不同尺度下的邻域判断及权重选取</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904076_060.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="61">邻域内是否存在像素点偏移的判断方法如图<b>3</b>所示。图<b>3 (1</b>) 到图<b>3 (8</b>) 是<b>2.1</b>节方法分别在尺度<b>1</b>到<b>8</b>下得到的二值图。图<b>3 (1</b>) 作为尺度最小的基准图像, 从中选取了<b>4</b>个具有代表性的像素点<b>A、B、C、D</b>对整个的方法进行说明, 它们分别代表了轮廓像素点、类似轮廓的像素点、类似纹理的像素点、背景纹理像素点。图<b>3 (1</b>) 右侧四幅图像分别是每个点的放大图像, 其最优方向如箭头所示;每幅图像下面的一列图像是该点在不同尺度下进行偏移判断的放大图像, 图中的两个三角形区域即为判断像素点是否偏移的搜索邻域, 其范围是该像素点最优方向左右两侧<b>45</b>°区域以内, 红色方框表示检测到偏移, 蓝色虚线方框表示没有检测到偏移。点<b>A</b>作为轮廓像素点, 虽然随着尺度变大发生了偏移, 但不断扩大的邻域仍然可以检测到这种偏移, 即这种偏移极有可能是轮廓点产生的偏移;点<b>B</b>作为类似轮廓的像素点, 从其对应的一列可以看出, 在尺度较大时已经检测不到偏移, 但在尺度较小的时候多次检测成功, 说明其为轮廓像素点的可能性较大;点<b>C</b>作为类似纹理的像素点, 检测到其偏移的次数较少, 说明其为纹理像素点的可能性较大;点<b>D</b>作为纹理像素点, 在其它尺度的图像中已经检测不出像素点的偏移, 即该点很可能为纹理像素点。</p>
                </div>
                <div class="p1">
                    <p id="62">设<b><i>c</i></b><sub><b><i>i</i></b></sub> (<b><i>x</i>, <i>y</i>) , <i>i</i>=1, …, 8</b>代表尺度<b>1</b>到<b>8</b>下的轮廓图, 采用邻域<b><i>D</i></b><sub><b><i>j</i></b></sub>, <b><i>j</i>=2, …, 8</b>去组合这些不同尺度下的信息</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>c</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>h</mi><mi>i</mi><mi>t</mi></mrow></msub><mo>=</mo><mi>c</mi><msub><mrow></mrow><mn>1</mn></msub><mo>⊕</mo><mi>D</mi><msub><mrow></mrow><mi>j</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">邻域的大小与尺度大小有关, 采用当前尺度与最小尺度之差大小作为搜索邻域的范围<b><i>L</i></b><sub><b><i>D</i></b><sub><b><i>j</i></b></sub></sub></p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mi>D</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>=</mo><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>σ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>i</mi><mo>=</mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mn>8</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66"><b><i>c</i></b><sub><b><i>j</i>, <i>hit</i></b></sub>为不同尺度下像素点的偏移信息, 经实验确定, 其在最终的融合中服从正态分布。权重越大, 说明在对应尺度下获得轮廓偏移信息越重要。如图<b>3</b>所示, 黑色箭头所指向的高斯函数值即为该尺度下偏移判断的权重, 检测到偏移的红色方框加权, 没有检测到的蓝色虚线方框不加权。随着尺度的变大, 偏移信息的权重不断减小。对加权后的偏移信息求和得到最终的权重矩阵</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>2</mn></mrow><mn>8</mn></munderover><mrow><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mtext>π</mtext></mrow></msqrt><mi>γ</mi></mrow></mfrac></mrow></mstyle><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo>-</mo><mi>μ</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>γ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">) </mo><mi>c</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>h</mi><mi>i</mi><mi>t</mi></mrow></msub><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">对权重矩阵采用非极大值抑制和二值化处理, 获得最终的轮廓检测结果<b><i>F</i> (<i>x</i>, <i>y</i></b>) 。</p>
                </div>
                <h3 id="69" name="69" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <h4 class="anchor-tag" id="70" name="70"><b>3.1 基于RuG数据库的实验</b></h4>
                <div class="p1">
                    <p id="71">本文采用<b><i>Grigorescu</i></b>在文献<citation id="113" type="reference">[<a class="sup">4</a>]</citation>中所用的性能评价方法。其轮廓数据库<citation id="114" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>中包含总共<b>40</b>幅<b>512×512</b>像素大小的图像。有其对应的真实轮廓图用于评估检测模型的性能。</p>
                </div>
                <div class="p1">
                    <p id="72">设<b>E</b><sub><b>GT</b></sub>和<b>B</b><sub><b>GT</b></sub>分别是真实轮廓图中的轮廓像素集合和背景像素集合。<b>E</b><sub><b>D</b></sub>和<b>B</b><sub><b>D</b></sub>分别是轮廓检测方法检测出轮廓的轮廓像素集合和背景像素集合。<b>E=E</b><sub><b>D</b></sub>∩<b>E</b><sub><b>GT</b></sub>是正确检测到的轮廓像素。<b>E</b><sub><b>FN</b></sub>=<b>E</b><sub><b>GT</b></sub>∩<b>B</b><sub><b>D</b></sub>指的是漏检, 即轮廓检测方法中没有检测到的真实轮廓中的轮廓像素, <b>E</b><sub><b>FP</b></sub>=<b>E</b><sub><b>D</b></sub>∩<b>B</b><sub><b>GT</b></sub>指的是错检, 即轮廓检测方法检测为轮廓但是真实轮廓中不是轮廓的部分。轮廓检测的性能评价标准定义如下:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ρ</mtext><mo>=</mo><mfrac><mrow><mi>c</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>E</mi><mo stretchy="false">) </mo></mrow><mrow><mi>c</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>E</mi><mo stretchy="false">) </mo><mo>+</mo><mi>c</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>F</mi><mi>Ρ</mi></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mi>c</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>F</mi><mi>Ν</mi></mrow></msub><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">这里<b>card (X</b>) 表示集合<b>X</b>中元素的数量, 评价标准<b>P</b>在[<b>0, 1</b>]之间。如果检测到的轮廓与真实轮廓完全一致, 并且没有背景纹理被检测成轮廓像素, 则<b>P=1</b>;错检和漏检越多, <b>P</b>越接近于<b>0</b>。当<b>P</b>值较高时, 轮廓检测效果较好。</p>
                </div>
                <div class="p1">
                    <p id="75">为了验证本文提出方法的性能, 选取<b>P</b>值作为性能评价标准。分别基于文献<citation id="115" type="reference">[<a class="sup">4</a>]</citation>的各向同性抑制模型、各向异性模型;文献<citation id="116" type="reference">[<a class="sup">9</a>]</citation>考虑微动机制与感受野特性的轮廓检测模型;文献<citation id="117" type="reference">[<a class="sup">10</a>]</citation>基于多特征周边抑制轮廓检测模型进行多尺度的二值化轮廓图融合, 并与原方法进行比较。</p>
                </div>
                <div class="area_img" id="76">
                    <p class="img_tit"><b>表1 实验参数设置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="76" border="1"><tr><td><br /></td><td>Σ多尺度融合所选尺度</td><td>Μ高斯加权函数期望</td><td>γ<sup>2</sup>高斯加权函数方差</td></tr><tr><td><br />文献[4]的各向同性方法</td><td>[1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5]</td><td>1.5</td><td>0.5</td></tr><tr><td><br />盏文献[4]的各向异性方法</td><td>[1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5]</td><td>1.5</td><td>0.5</td></tr><tr><td><br />盏文献[9]方法</td><td>[1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5]</td><td>1.5</td><td>0.5</td></tr><tr><td><br />盏文献[10]方法</td><td>[1, 2, 3, 4, 5, 6, 7, 8]</td><td>2</td><td>4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="77">
                                <img alt="" src="Detail/GetImg?filename=images/JSJZ201904076_077.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904076_078.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图4 各方法在RuG数据库下的实验结果对比" src="Detail/GetImg?filename=images/JSJZ201904076_078.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图4 各方法在RuG数据库下的实验结果对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904076_078.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904076_079.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图5 各个方法的平均P值" src="Detail/GetImg?filename=images/JSJZ201904076_079.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图5 各个方法的平均P值</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904076_079.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="80">表<b>1</b>列出了文献<citation id="119" type="reference">[<a class="sup">4</a>,<a class="sup">9</a>,<a class="sup">10</a>]</citation>多尺度融合时的参数。图<b>4</b>是<b>RuG</b>数据库中每幅图像<b>P</b>值所对应的实验结果。图<b>5</b>是原方法和加上多尺度融合后总体平均<b>P</b>值的比较。图<b>6</b>为各种轮廓检测模型的定性结果比较。图中第一列是原始输入自然场景图像, 第二列是<b>RuG</b>数据库中提供的自然图像所对应的真实轮廓图, 第三列和第四列分别为文献<citation id="118" type="reference">[<a class="sup">4</a>]</citation>中各向同性抑制和本文多尺度融合下的各向同性抑制模型的检测结果, 第五列和第六列分别是各向异性抑制和本文多尺度融合下的检测结果, 第七列和第八列分别是文献<citation id="120" type="reference">[<a class="sup">9</a>]</citation>模型和本文多尺度融合下得到的轮廓图, 第九列和第十列分别是文献<citation id="121" type="reference">[<a class="sup">10</a>]</citation>和本文多尺度融合下得到的轮廓图。由图<b>4</b>和图<b>5</b>可知:本文所提方法的评测值大于其它方法的评测值, 说明所提出的多尺度二值化图片融合方法检测到的轮廓更接近于真实轮廓, 可以有效提升轮廓检测效果。如图<b>6</b>所示:本文方法明显的抑制了纹理边缘, 减少了轮廓破坏, 检测结果更接近于真实轮廓。</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904076_081.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图6 各方法在RuG数据库实验结果对比" src="Detail/GetImg?filename=images/JSJZ201904076_081.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图6 各方法在RuG数据库实验结果对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904076_081.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="83" name="83"><b>3.2 基于BSDS300数据库的实验</b></h4>
                <div class="p1">
                    <p id="84">伯克利分割数据库 (<b>BSDS300</b>) 包含<b>300</b>张图片和其对应的<b>5-10</b>幅人工手绘边界, 其中有<b>200</b>幅训练图新盘和<b>100</b>幅测试图片。采用精确度-覆盖度框架来评价轮廓检测方法的好坏。</p>
                </div>
                <div class="p1">
                    <p id="85">设<b>TP</b>表示轮廓正确检测特征数;<b>FP</b>表示轮廓检测方法检测为轮廓, 实际为背景的特征数;<b>TN</b>表示背景正确检测特征数;<b>FN</b>表示检测出来为背景点实际上是轮廓的特征数。伯克利数据库采用精确度-覆盖度 (<b>PR</b>) 曲线和其调和平均数<b>F</b>作为性能评价指标。其中精确度表示正样本预测正确率, 覆盖度表示轮廓覆盖率</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mi>Τ</mi><mi>Ρ</mi><mo>/</mo><mo stretchy="false"> (</mo><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mi>Τ</mi><mi>Ρ</mi><mo>/</mo><mo stretchy="false"> (</mo><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87"><b>F</b>值代表着方法的检测结果与人类观察轮廓的相似度, <b>F</b>值越大, 轮廓检测方法性能越好</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo>=</mo><mn>2</mn><mi>Ρ</mi><mi>R</mi><mo>/</mo><mo stretchy="false"> (</mo><mi>Ρ</mi><mo>+</mo><mi>R</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">图<b>7</b>分别展示了文献<citation id="122" type="reference">[<a class="sup">4</a>,<a class="sup">9</a>,<a class="sup">10</a>]</citation>以及经过本文多尺度融合方法处理后的检测结果。从各个方法的<b>PR</b>曲线和<b>F</b>值可以看出本文所提出的基于多尺度下二值化轮廓图的融合方法有效提升了原有方法的性能。</p>
                </div>
                <div class="p1">
                    <p id="90">图<b>8</b>选取了一部分数据库中的图像做定性比较。图中第一列是<b>BSDS300</b>数据库中的原始图像, 第二列是所对应的真实轮廓图, 第三列和第四列分别为文献<citation id="123" type="reference">[<a class="sup">4</a>]</citation>中各向同性方法和本文多尺度融合方法下的检测结果, 第五列和第六列分别是各向异性方法和本文多尺度融合方法下的检测结果, 第七列和第八列分别是文献<citation id="124" type="reference">[<a class="sup">9</a>]</citation>方法和本文多尺度融合方法下得到的轮廓图, 第九列和第十列分别是文献<citation id="125" type="reference">[<a class="sup">10</a>]</citation>方法和本文多尺度融合方法下得到的轮廓图。可以看出, 经过多尺度融合方法处理后的轮廓检测效果更好。</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904076_091.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图7 各种轮廓检测方法的PR曲线和F值" src="Detail/GetImg?filename=images/JSJZ201904076_091.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图7 各种轮廓检测方法的PR曲线和F值</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904076_091.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904076_092.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图8 各方法在BSDS300数据库实验结果对比" src="Detail/GetImg?filename=images/JSJZ201904076_092.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图8 各方法在BSDS300数据库实验结果对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904076_092.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="93" name="93" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="94">轮廓检测的目的是从复杂的背景中提取目标的轮廓, 是图像处理及计算机视觉中非常重要且困难的任务之一。纹理抑制是轮廓检测中的关键步骤, 初级视皮层中存在具有方向选择性的神经元细胞, 其周边抑制特性可以较好的分辨轮廓和纹理部分, 为仿生视觉研究提供了思路。然而现有的基于周边抑制特性的检测方法大多数是单个尺度下对检测模板的改进, 没有考虑多尺度下图像信息的应用。多分辨率分析显示, 在大尺度下, 纹理消失的同时一些轮廓细节也会丢失, 轮廓也会发生位移和破坏。通过组合不同尺度下的信息可以在抑制纹理的同时得到好的轮廓。</p>
                </div>
                <div class="p1">
                    <p id="95">本文在传统方法使用周边抑制特性的基础上, 结合多尺度下像素点的偏移特性, 对最终生成的二值化图片进行融合。通过将本文方法加在其它轮廓检测方法上并于原方法进行比较, 表明本文所提出的方法可以有效减少虚假轮廓, 避免轮廓缺失, 保留轮廓细节的同时更好的抑制了背景纹理。本文方法还有很多可以提升的地方, 比如判断像素点的偏移是否有更好、更准确的方法;能否在考虑多尺度的情况上加入其它的图像线索, 如对比度、方向、亮度等以充分利用图像的所有信息。这些问题都有待后续地进一步研究。</p>
                </div>
                <div class="area_img" id="126">
                                <img alt="" src="Detail/GetImg?filename=images/JSJZ201904076_12600.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                            <p class="img_tit"></p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 J Canny.A Computational Approach to Edge Detection[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 1986, 8 (6) :679.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Receptive fields, binocular interaction and functional architecture in the cat&amp;#39;s visual cortex">

                                <b>[2]</b> D H Hubel, T N Weisel.T N Wiesel.Receptive fields, binocular interaction and functional architecture in cat's visual cortex[J].J.Physiol. (London) 160, 106-154.1962, 160.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003245619&amp;v=MjUzNTBPNEh0SFByWXRBWXVvR1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1RmlEbFY3dk1KVjg9Tmo3QmFy&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[3]</b> N Petkov, M A Westenberg.Suppression of contour perception by band-limited noise and its relation to nonclassical receptive field inhibition[J].Biological Cybernetics, 2003, 88 (3) :236-246.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contour detection based on nonclassical receptive field inhibition">

                                <b>[4]</b> C Grigorescu, N Petkov, M A Westenberg.Contour detection based on nonclassical receptive field inhibition[M].IEEE Press, 2003.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739413&amp;v=Mjg4OTBmSUpGb1FieE09TmlmT2ZiSzdIdEROcVk5RlkrZ0dDSDA2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcg==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[5]</b> Q Tang, N Sang, T Zhang.Extraction of salient contours from cluttered scenes[J].Pattern Recognition, 2007, 40 (11) :3100-3109.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX200907022&amp;v=MjE4NjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emhWN3JKSVRmU2RyRzRIdGpNcUk5SFpvUUtESDg0dlI=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[6]</b> 杜晓凤, 李翠华, 李晶.基于复合感受野的轮廓检测方法[J].电子与信息学报, 2009, 31 (7) :1630-1634.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501911359&amp;v=MTk3MTZieE09TmlmT2ZiSzdIdEROcW85RWJlb09EM2t3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmZJSkZvUQ==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[7]</b> C Zeng, et al.Contour detection based on a non-classical receptive field model with butterfly-shaped inhibition subregions[J].Neurocomputing, 2011, 74 (10) :1527-1534.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738161&amp;v=MTg0NDNGWStnSERYbzRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyZklKRm9RYnhNPU5pZk9mYks3SHRETnFZOQ==&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[8]</b> G Papari, N Petkov.An improved model for surround suppression by steerable filters and multilevel inhibition with application to contour detection[J].Pattern Recognition, 2011, 44 (9) :1999-2007.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201624039&amp;v=MzE4NDNVUjdxZlp1Wm1GeXpoVjdySkx6N01hYkc0SDlmT3E0OUdiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[9]</b> 林川, 李亚, 曹以隽.考虑微动机制与感受野特性的轮廓检测模型[J].计算机工程与应用, 2016, 52 (24) :210-216.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multifeature-based surround inhibition improves contour detection in natural images">

                                <b>[10]</b> K F Yang, C Y Li, Y J Li.Multifeature-based surround inhibition improves contour detection in natural images[J].IEEE Transactions on Image Processing, 2014, 23 (12) :5020-5032.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A theory for multi-resolution signal decomposition: The wavelet representation">

                                <b>[11]</b> S G Mallat.A Theory for Multiresolution Signal Decomposition:The Wavelet Representation[M].IEEE Computer Society, 1989.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatial frequency selectivity of cells in macaque visual cortex">

                                <b>[12]</b> R L D Valois, D G Albrecht, L G Thorell.Spatial frequency selectivity of cells in macaque visual cortex[J].Vision Research, 1982, 22 (5) :545-559.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830520&amp;v=MjAwMzQ3QmFyTzRIdEhPcDR4Rllla1BZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FkWitadUZpRGxWN3ZNSlY4PU5q&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[13]</b> T Lindeberg.Edge detection and ridge detection with automatic scale selection[J].International Journal of Computer Vision, 1998, 30 (2) :117-156.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-scale improves boundary detection in natural images">

                                <b>[14]</b> X Ren.Multi-scale Improves Boundary Detection in Natural Images[C].European Conference on Computer Vision.Springer-Verlag, 2008:533-545.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787312027031001&amp;v=MTE4NzQ3bjN4RTlmYnZuS3JpZlplWnZGeW50VTd2TUpGc1ZYRnF6R2JDNUhOSE9xSTlHWmVzUERSTTh6eFVTbURkOVNI&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[15]</b> 寿天德.视觉信息处理的脑机制[M].合肥:中国科学技术大学出版社, 2010:152-158.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC200801071&amp;v=MjU5NzZWN3JKTHo3QmJiRzRIdG5Ncm85Q1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emg=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[16]</b> 刘曙, 罗予频, 杨士元.基于多尺度的轮廓匹配方法[J].计算机工程, 2008, 34 (1) :201-203.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201904076" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201904076&amp;v=MzEwNzFtRnl6aFY3ckpMejdCZExHNEg5ak1xNDlDWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
