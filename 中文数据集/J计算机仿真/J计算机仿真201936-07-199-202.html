<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637140807953232500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201907042%26RESULT%3d1%26SIGN%3d6v5fVsnbCCTTgCbo%252fYrIDS8SxS4%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201907042&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201907042&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201907042&amp;v=MzEwNzFuRnlqZ1ZMM09MejdCZExHNEg5ak1xSTlCWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;2 双目立体视觉图像多目标处理精确匹配方法&lt;/b&gt; "><b>2 双目立体视觉图像多目标处理精确匹配方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#32" data-title="&lt;b&gt;2.1 图像目标区域初步分割与跟踪&lt;/b&gt;"><b>2.1 图像目标区域初步分割与跟踪</b></a></li>
                                                <li><a href="#49" data-title="&lt;b&gt;2.2 图像目标区域特征点分离&lt;/b&gt;"><b>2.2 图像目标区域特征点分离</b></a></li>
                                                <li><a href="#71" data-title="&lt;b&gt;2.3 图像目标区域特征点精确匹配&lt;/b&gt;"><b>2.3 图像目标区域特征点精确匹配</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#94" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#97" data-title="1) 3种方法的匹配精度对比实验">1) 3种方法的匹配精度对比实验</a></li>
                                                <li><a href="#106" data-title="2) 3种方法的匹配时间对比实验">2) 3种方法的匹配时间对比实验</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#110" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#102" data-title="&lt;b&gt;图1 实验对象&lt;/b&gt;"><b>图1 实验对象</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;表1 3种方法的匹配精度对比&lt;/b&gt;"><b>表1 3种方法的匹配精度对比</b></a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;图2 3种方法的目标匹配时间对比&lt;/b&gt;"><b>图2 3种方法的目标匹配时间对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="122">


                                    <a id="bibliography_1" title=" 邹辉, 黄福珍.基于改进FAsT-Match算法的电力设备红外图像多目标定位[J].中国电机工程学报, 2017, 37 (2) :591-598." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGDC201702027&amp;v=MDUxMDNQYmJHNEg5Yk1yWTlIWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnlqZ1ZMM09QeXI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         邹辉, 黄福珍.基于改进FAsT-Match算法的电力设备红外图像多目标定位[J].中国电机工程学报, 2017, 37 (2) :591-598.
                                    </a>
                                </li>
                                <li id="124">


                                    <a id="bibliography_2" title=" 齐美彬, 岳周龙, 疏坤, 等.基于广义关联聚类图的分层关联多目标跟踪[J].自动化学报, 2017, 43 (1) :152-160." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201701014&amp;v=MDk0NTE0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeWpnVkwzT0tDTGZZYkc0SDliTXJvOUVZSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         齐美彬, 岳周龙, 疏坤, 等.基于广义关联聚类图的分层关联多目标跟踪[J].自动化学报, 2017, 43 (1) :152-160.
                                    </a>
                                </li>
                                <li id="126">


                                    <a id="bibliography_3" title=" 王云舒, 刘建业, 曾庆化, 等.惯性信息辅助的快速大视角图像匹配方法[J].中国惯性技术学报, 2016, 24 (4) :504-510." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGXJ201604015&amp;v=Mjk0MTBmTXE0OUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeWpnVkwzT1B5clRaTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         王云舒, 刘建业, 曾庆化, 等.惯性信息辅助的快速大视角图像匹配方法[J].中国惯性技术学报, 2016, 24 (4) :504-510.
                                    </a>
                                </li>
                                <li id="128">


                                    <a id="bibliography_4" title=" Xu W, Chen Y T, Piao Y J, et al.Target fast matching recognition of on-board system based on Jilin-1 satellite image[J].Optics &amp;amp; Precision Engineering, 2017, 25 (1) :255-262." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201701032&amp;v=MjM5MTMzenFxQnRHRnJDVVI3cWZadVpuRnlqZ1ZMM09JalhCWTdHNEg5Yk1ybzlHWm9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Xu W, Chen Y T, Piao Y J, et al.Target fast matching recognition of on-board system based on Jilin-1 satellite image[J].Optics &amp;amp; Precision Engineering, 2017, 25 (1) :255-262.
                                    </a>
                                </li>
                                <li id="130">


                                    <a id="bibliography_5" title=" 张敬丽, 张会清, 代汝勇.基于MIC-SURF的快速图像匹配算法[J].计算机工程, 2016, 42 (1) :210-214." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201601037&amp;v=MjMyOTc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amdWTDNPTHo3QmJiRzRIOWZNcm85R1k=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         张敬丽, 张会清, 代汝勇.基于MIC-SURF的快速图像匹配算法[J].计算机工程, 2016, 42 (1) :210-214.
                                    </a>
                                </li>
                                <li id="132">


                                    <a id="bibliography_6" title=" 向程谕, 王冬丽, 李建勋, 等.基于改进SIFT特征的深度图像匹配[J].计算机应用, 2016, 36 (s2) :135-138." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY2016S2035&amp;v=MTUyMDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amdWTDNPTHo3QmQ3RzRIOWV2clk5R1lZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         向程谕, 王冬丽, 李建勋, 等.基于改进SIFT特征的深度图像匹配[J].计算机应用, 2016, 36 (s2) :135-138.
                                    </a>
                                </li>
                                <li id="134">


                                    <a id="bibliography_7" title=" 付偲, 邓丽, 卢根, 等.基于快速视网膜关键点算法改进的图像匹配方法[J].计算机工程与应用, 2016, 52 (19) :208-212." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201619038&amp;v=MDczNDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeWpnVkwzT0x6N01hYkc0SDlmTnBvOUdiSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         付偲, 邓丽, 卢根, 等.基于快速视网膜关键点算法改进的图像匹配方法[J].计算机工程与应用, 2016, 52 (19) :208-212.
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_8" title=" 朱奇光, 张朋珍, 李昊立, 等.基于全局和局部特征融合的图像匹配算法研究[J].仪器仪表学报, 2016, 37 (1) :170-176." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201601023&amp;v=MDE5NjRSN3FmWnVabkZ5amdWTDNPUER6VGJMRzRIOWZNcm85SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         朱奇光, 张朋珍, 李昊立, 等.基于全局和局部特征融合的图像匹配算法研究[J].仪器仪表学报, 2016, 37 (1) :170-176.
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_9" title=" 戴宪策, 谢奇.基于傅里叶-梅林变换的图像匹配方法研究[J].红外技术, 2016, 38 (10) :860-863." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWJS201610009&amp;v=MDYwMTdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amdWTDNPTFRyQmZiRzRIOWZOcjQ5RmI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         戴宪策, 谢奇.基于傅里叶-梅林变换的图像匹配方法研究[J].红外技术, 2016, 38 (10) :860-863.
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_10" title=" Hui Z, Wang B, Sarkar V, et al.Comparison of surface matching and target matching for image‐guided pelvic radiation therapy for both supine and prone patient positions[J].Journal of Applied Clinical Medical Physics, 2016, 17 (3) :14-24." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Comparison of surface matching and target matching for image‐guided pelvic radiation therapy for both supine and prone patient positions">
                                        <b>[10]</b>
                                         Hui Z, Wang B, Sarkar V, et al.Comparison of surface matching and target matching for image‐guided pelvic radiation therapy for both supine and prone patient positions[J].Journal of Applied Clinical Medical Physics, 2016, 17 (3) :14-24.
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_11" title=" 李金明.多视觉动画图像三维重建特征点匹配优化仿真[J].计算机仿真, 2017, 34 (9) :341-344." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201709075&amp;v=MTU2ODdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnlqZ1ZMM09MejdCZExHNEg5Yk1wbzlDWVlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         李金明.多视觉动画图像三维重建特征点匹配优化仿真[J].计算机仿真, 2017, 34 (9) :341-344.
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_12" title=" 杨进, 高飞, 马良.基于改进并行粒子群算法的彩色图像匹配[J].计算机应用研究, 2016, 33 (8) :2543-2546." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201608068&amp;v=MTM1ODlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amdWTDNPTHo3U1pMRzRIOWZNcDQ5RGJJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         杨进, 高飞, 马良.基于改进并行粒子群算法的彩色图像匹配[J].计算机应用研究, 2016, 33 (8) :2543-2546.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(07),199-202             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>双目立体视觉图像多目标处理精确匹配仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B9%8C%E5%85%B0&amp;code=07992807&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">乌兰</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%86%85%E8%92%99%E5%8F%A4%E6%B0%91%E6%97%8F%E5%A4%A7%E5%AD%A6%E4%BC%A0%E5%AA%92%E5%AD%A6%E9%99%A2&amp;code=0183133&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">内蒙古民族大学传媒学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对当前双目立体视觉图像多目标处理方法中存在的匹配精度较低、匹配过程耗时较长等问题, 提出基于小波变换的双目立体视觉图像多目标处理精确匹配方法。采用背景差分法初步检测并分割双目立体视觉图像的目标区域, 通过粒子滤波算法跟踪并确定最终的目标区域;对确定的目标区域图像, 利用模板图像与聚类分析算法结合的方式, 提取并分离双目立体视觉左、右两侧图像目标区域的特征匹配点, 同时剔除错误匹配点;根据双目立体视觉理论基础与小波理论, 对于所得到的图像特征匹配点, 采用小波变换特征点配准方法进行目标匹配, 实现目标匹配精度与速度间的平衡。实验结果表明, 相比于当前方法, 所提方法的目标匹配精度较高, 且运行时间更短, 具有较好的鲁棒性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%8C%E7%9B%AE%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">双目立体视觉;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E7%9B%AE%E6%A0%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多目标;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">匹配;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    乌兰 (1965-) , 女 (蒙古族) , 内蒙古兴安盟人, 中级实验师。研究方向:教育技术学、计算机应用与管理。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-07</p>

            </div>
                    <h1><b>Binocular Stereo Vision Image Multi-objective Processing Exact Matching Simulation</b></h1>
                    <h2>
                    <span>WU Lan</span>
            </h2>
                    <h2>
                    <span>College of media, National University Of The Inner Mongol</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Due to low matching precision and long matching process of current method, this paper proposed a method to accurately match the multi-objective processing of binocular stereo vision image based on wavelet transform. Firstly, we used the background difference method to detect and segment the target region of binocular stereo vision image. Secondly, we tracked and determined the final target region by the particle filter algorithm. For the image of determined target region, we combined the template image with the cluster analysis algorithm to extract and separate the feature matching points in target region of left image and right image of binocular stereoscopic image. Meanwhile, we eliminated the false matching points. According to the binocular stereoscopic vision theory and wavelet theory, we used the registration method of wavelet transform feature point to match the obtained image feature matching points. Finally, we achieved the balance between target matching accuracy and speed. Experimental results show that the proposed method has higher target matching precision and shorter running time than that of current method. Meanwhile, this method has better robustness.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Binocular%20stereo%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Binocular stereo vision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-objective&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multi-objective;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Matching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Matching;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-07</p>
                            </div>


        <!--brief start-->
                        <h3 id="27" name="27" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="28">视觉传感与图像处理技术迅速发展, 带动了机器视觉的智能化发展, 通过视觉技术能够实现目标识别与定位。机器视觉包括单目、双目和多目三种类型, 相比其他两种类型, 双目视觉技术获取信息的方式更简单<citation id="146" type="reference"><link href="122" rel="bibliography" /><link href="124" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。双目立体视觉技术在工业检测、机器人导航、建筑设计、虚拟现实等多领域应用广泛。双目立体视觉图像多目标处理匹配是当前该技术领域的研究要点, 受到很多专家与学者的关注, 现已出现一些较好的图像目标匹配方法<citation id="147" type="reference"><link href="126" rel="bibliography" /><link href="128" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="29">张敬丽等人提出基于MIC-SURF算子的双目立体视觉图像多目标处理匹配方法<citation id="148" type="reference"><link href="130" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。采用自适应平滑算法进行图像滤波, 运用自然邻域像素法检测非平滑区域的几何角点, 结合改进MIC算法及SURF算子提取目标区域特征点, 根据所得图像特征描述子进行多目标匹配。该方法所需匹配时间较短, 但存在角点漏检等问题, 图像多目标匹配精度较低。向程谕等人提出基于改进SIFT算法的双目立体视觉图像多目标处理匹配方法<citation id="149" type="reference"><link href="132" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。利用SIFT算法提取图像目标区域特征点, 通过Harris角点检测算子剔除所得特征点中的伪特征点;对于得到的特征点描述子, 利用统计抽样法降维后, 运用近邻搜索方法实现图像目标区域特征匹配。该方法的匹配精度较高, 且对图像的适应性较强, 但运算量大, 匹配过程的时间成本较高。付偲等人提出基于视网膜关键点算法的双目立体视觉图像多目标处理匹配方法<citation id="150" type="reference"><link href="134" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。在原有ASIFT算法的基础上, 引入视网膜关键点算法与Lanczos-4插值操作, 综合随机样本已知性算法进行目标区域匹配点筛选, 采用暴力匹配方式进行图像目标区域匹配, 提高匹配效率。该方法目标区域匹配过程耗时较短, 但匹配精度较低。</p>
                </div>
                <div class="p1">
                    <p id="30">针对上述方法中的不足之处, 提出基于小波变换的双目立体视觉图像多目标处理精确匹配方法, 通过仿真实验与当前方法进行比较, 验证了所提匹配方法的性能。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>2 双目立体视觉图像多目标处理精确匹配方法</b></h3>
                <h4 class="anchor-tag" id="32" name="32"><b>2.1 图像目标区域初步分割与跟踪</b></h4>
                <div class="p1">
                    <p id="33">利用背景差分法对双目立体视觉图像进行前后景分离, 获取图像目标区域, 通过粒子滤波进行目标跟踪, 并确定图像目标区域。</p>
                </div>
                <div class="p1">
                    <p id="34">背景差分方法是常用的图像目标区域分离方法, 主要的背景建模方法包括:中值法背景建模、均值法背景建模、卡尔曼滤波器模型、高斯分布模型与高级背景模型等。背景分离常用的方法有:时间差分法、中值滤波法及高斯法等<citation id="151" type="reference"><link href="136" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="35">综合考虑图像中目标范围与背景噪声干扰, 通过中值滤波法实现双目立体视觉图像的前后景分离。构建一个视觉缓冲区域用于缓存L帧图像, 并以L帧图像的同位像素中值作为图像背景的对应位置像素值</p>
                </div>
                <div class="p1">
                    <p id="36"><i>B</i><sub><i>t</i>+1</sub> (<i>x</i>, <i>y</i>) =<i>med</i> (<i>I</i><sub><i>t</i></sub> (<i>x</i>, <i>y</i>) , …, <i>I</i><sub><i>t</i>-<i>L</i></sub> (<i>x</i>, <i>y</i>) )      (1) </p>
                </div>
                <div class="p1">
                    <p id="37">上式中, <i>B</i><sub><i>t</i>+1</sub> (<i>x</i>, <i>y</i>) 代表当前图像背景在像素点 (<i>x</i>, <i>y</i>) 位置的灰度值, <i>I</i><sub><i>t</i></sub> (<i>x</i>, <i>y</i>) 、<i>I</i><sub><i>t</i>-<i>L</i></sub> (<i>x</i>, <i>y</i>) 代表缓存图像中对应帧图像在像素点 (<i>x</i>, <i>y</i>) 位置的灰度值。</p>
                </div>
                <div class="p1">
                    <p id="38">为了简化计算过程, 降低计算量, 引入样本学习参数<i>λ</i>, 以此映射图像背景变化对目标变化的敏感度, <i>λ</i>取值越小, 图像前景目标变化对图像背景的影响越小。则有:</p>
                </div>
                <div class="p1">
                    <p id="39">1) 当<i>I</i><sub><i>t</i></sub> (<i>x</i>, <i>y</i>) 为图像前景目标时:</p>
                </div>
                <div class="p1">
                    <p id="40"><i>B</i><sub><i>t</i>+1</sub> (<i>x</i>, <i>y</i>) =<i>B</i><sub><i>t</i></sub> (<i>x</i>, <i>y</i>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="41">2) 当<i>I</i><sub><i>t</i></sub> (<i>x</i>, <i>y</i>) 为图像背景时:</p>
                </div>
                <div class="p1">
                    <p id="42"><i>B</i><sub><i>t</i>+1</sub> (<i>x</i>, <i>y</i>) =<i>λI</i><sub><i>t</i></sub> (<i>x</i>, <i>y</i>) + (1-<i>λ</i>) <i>B</i><sub><i>t</i></sub> (<i>x</i>, <i>y</i>)      (3) </p>
                </div>
                <div class="p1">
                    <p id="43">根据以往研究结果, <i>λ</i>一般取值为0.05。通过上述计算过程, 初步完成图像目标区域分割。</p>
                </div>
                <div class="p1">
                    <p id="44">利用隐马尔可夫统计模型进行目标跟踪预测, 以图像中的像素点数据为观测值, 目标位置及区域为隐匿状态, 对应的描述式如下</p>
                </div>
                <div class="p1">
                    <p id="45"><i>p</i> (<i>x</i><sub><i>t</i></sub>|<i>y</i><sub>1:<i>t</i></sub>) =<i>αp</i> (<i>y</i><sub><i>t</i></sub>|<i>x</i><sub><i>t</i></sub>) ×</p>
                </div>
                <div class="p1">
                    <p id="46">∫<sub><i>x</i><sub><i>t</i>-1</sub></sub><i>p</i> (<i>x</i><sub><i>t</i></sub>|<i>x</i><sub><i>t</i>-1</sub>) <i>p</i> (<i>x</i><sub><i>t</i>-1</sub>|<i>y</i><sub>1:<i>t</i>-1</sub>) <i>dx</i><sub><i>t</i>-1</sub>      (4) </p>
                </div>
                <div class="p1">
                    <p id="47">其中, <i>p</i> (<i>x</i><sub><i>t</i></sub>|<i>y</i><sub>1:<i>t</i></sub>) 为预估目标状态;<i>p</i> (<i>y</i><sub><i>t</i></sub>|<i>x</i><sub><i>t</i></sub>) 为观察模型, 用于描述目标所处状态的近似程度, 此处采用基于图像色彩直方图的观察模型;<i>p</i> (<i>x</i><sub><i>t</i></sub>|<i>x</i><sub><i>t</i>-1</sub>) 为转移模型, 用于描述相邻帧图像间目标的变化;<i>p</i> (<i>x</i><sub><i>t</i>-1</sub>|<i>y</i><sub>1:<i>t</i>-1</sub>) 为前一时刻目标状态。初始状态为<i>p</i> (<i>x</i><sub>0</sub>) , 用于描述初步分割结果, 包括目标位置和区域。</p>
                </div>
                <div class="p1">
                    <p id="48">通过以上计算完成图像目标区域的初步分割与跟踪, 结合相关技术操作, 对比不同帧图像内目标区域的差异与关联, 确定最终的图像目标区域。</p>
                </div>
                <h4 class="anchor-tag" id="49" name="49"><b>2.2 图像目标区域特征点分离</b></h4>
                <div class="p1">
                    <p id="50">确定图像目标区域后, 结合双目立体视觉图像模板图进行目标区域的特征点分离, 获取图像目标区域特征匹配点。</p>
                </div>
                <div class="p1">
                    <p id="51">以模板图像几何中心点作为模板中心, 记作<i>c</i>, 将模板图特征点集合记作<i>T</i>, 双目立体视觉图像目标区域的特征点集合记作<i>S</i>, 设模板图与目标区域图像的某一特征匹配点对为 (<i>t</i>, <i>s</i>) (<i>t</i><sub><i>i</i></sub>∈<i>T</i>, <i>s</i><sub><i>i</i></sub>∈<i>S</i>) 。模板图特征点<i>t</i><sub><i>i</i></sub>到中心点的相对向量<i>r</i><sub><i>i</i></sub> (<i>t</i><sub><i>i</i></sub>) 的描述式如公式 (5) 所示</p>
                </div>
                <div class="p1">
                    <p id="52"><i>r</i><sub><i>i</i></sub> (<i>t</i><sub><i>i</i></sub>) =<i>p</i> (<i>c</i>) -<i>p</i> (<i>t</i><sub><i>i</i></sub>)      (5) </p>
                </div>
                <div class="p1">
                    <p id="53">上式中, <i>p</i> (<i>c</i>) 代表模板图中心点的坐标, <i>p</i> (<i>t</i><sub><i>i</i></sub>) 代表模板图对应特征点的坐标。对于模板图与双目立体视觉图像目标区域的正确匹配点对 (<i>t</i><sub><i>i</i></sub>, <i>s</i><sub><i>i</i></sub>) , 可根据特征点<i>t</i>和<i>s</i>的点坐标及方向近似估计图像目标区域特征点集的中心点, 对应的计算式为</p>
                </div>
                <div class="area_img" id="54">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201907042_05400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="56"><i>θ</i>=<i>θ</i><sub><i>s</i></sub>-<i>θ</i><sub><i>t</i></sub>      (7) </p>
                </div>
                <div class="p1">
                    <p id="57">其中, <i>θ</i><sub><i>s</i></sub>、<i>θ</i><sub><i>t</i></sub>分别代表图像目标区域与相应模板图的特征点角度方向, <i>p</i> (<i>s</i><sub><i>i</i></sub>) 代表图像目标区域对应特征点的坐标。各目标区域图像都有对应的匹配对特征点与估计中心点。</p>
                </div>
                <div class="p1">
                    <p id="58">利用基于搜索密度峰值的快速聚类算法<citation id="152" type="reference"><link href="138" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>进行图像特征点及中心点分离, 设采集得到的图像特征点与中心点集合为数据点集合, 记作<i>C</i><sub><i>s</i></sub>={<i>P</i><sub><i>i</i></sub>}<mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup></mrow></math></mathml>, <i>P</i><sub><i>i</i></sub>∈<i>C</i><sub><i>s</i></sub>对应的局部密度为<i>ρ</i><sub><i>i</i></sub>, 密度值大于点<i>i</i>处密度<i>ρ</i><sub><i>i</i></sub>的最小距离为<i>δ</i><sub><i>i</i></sub>, <i>ρ</i><sub><i>i</i></sub>的计算公式如下</p>
                </div>
                <div class="p1">
                    <p id="60"><mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>S</mi><mo>, </mo><mi>j</mi><mo>≠</mo><mi>i</mi></mrow></munder><mi>e</mi></mstyle><msup><mrow></mrow><mrow><mo>-</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mi>d</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mrow><mi>d</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></msup></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="62"><i>d</i><sub><i>ij</i></sub>=<i>dist</i> (<i>p</i> (<i>i</i>) , <i>p</i> (<i>j</i>) )      (9) </p>
                </div>
                <div class="p1">
                    <p id="63">其中, <i>j</i>为不同于<i>i</i>的点, <i>d</i><sub><i>c</i></sub>代表搜索终止距离, <i>d</i><sub><i>ij</i></sub>代表点<i>i</i>与<i>j</i>间的欧式距离。</p>
                </div>
                <div class="p1">
                    <p id="64"><i>δ</i><sub><i>i</i></sub>=min (<i>d</i><sub><i>ij</i></sub>) <i>j</i>:<i>ρ</i><sub><i>j</i></sub>&gt;<i>ρ</i><sub><i>i</i></sub>      (10) </p>
                </div>
                <div class="p1">
                    <p id="65">点<i>i</i>处的密度<i>ρ</i><sub><i>i</i></sub>为局部最大密度时, <i>δ</i><sub><i>i</i></sub>=max (<i>d</i><sub><i>ij</i></sub>) 。</p>
                </div>
                <div class="p1">
                    <p id="66">对于集合<i>C</i><sub><i>s</i></sub>={<i>P</i><sub><i>i</i></sub>}<mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup></mrow></math></mathml>中的各点<i>P</i><sub><i>i</i></sub>, 计算相对的 (<i>ρ</i><sub><i>i</i></sub>, <i>δ</i><sub><i>i</i></sub>) , 据此生成的决策图中, 具备较大的<i>ρ</i>和<i>δ</i>的点看作聚类中心点。确定聚类中心后, 将其余各点分配到密度更大、距离更近的数据簇内。求算各簇的距离均值<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>δ</mi><mo>¯</mo></mover><mo>, </mo></mrow></math></mathml>以距离值大于<mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>δ</mi><mo>¯</mo></mover></math></mathml>的点为作为光晕点, 距离小于<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>δ</mi><mo>¯</mo></mover></math></mathml>的点作为核心点。重复进行以上步骤, 获取各点集的差异化目标特征点, 距离特征点较远的点即为错误特征匹配点。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71"><b>2.3 图像目标区域特征点精确匹配</b></h4>
                <div class="p1">
                    <p id="72">确定并匹配特征点线段的端点, 将小波变换模最大值位置对应的像素点看作匹配基元, 结合由粗而细的配准策略, 匹配对应的像素点, 同时记录两侧模最大值处的相关信息;联合左右两侧图像像素点投影的顺序一致约束, 利用以上所得信息调控小尺度层次的匹配空间, 匹配小尺度小波系数模最大值处的像素点, 实现图像目标精确匹配。</p>
                </div>
                <div class="p1">
                    <p id="73">图像信号<i>f</i> (<i>x</i>') 在任意空间尺度与像素点处的小波变换计算描述式如下</p>
                </div>
                <div class="p1">
                    <p id="74"><i>W</i><sub><i>S</i><sup>′</sup></sub><i>f</i> (<i>x</i><sup>′</sup>) =<i>f</i>*<i>ψ</i><sub><i>S</i><sup>′</sup></sub> (<i>x</i><sup>′</sup>)      (11) </p>
                </div>
                <div class="p1">
                    <p id="75"><i>ψ</i><sub><i>S</i><sup>′</sup></sub>= (1/<i>S</i><sup>′</sup>) <i>ψ</i> (<i>x</i><sup>′</sup>/<i>S</i><sup>′</sup>)      (12) </p>
                </div>
                <div class="p1">
                    <p id="76">其中, <i>ψ</i><sub><i>S</i><sup>′</sup></sub>代表小波, 为母小波<i>ψ</i> (<i>x</i><sup>′</sup>) 通过空间尺度因子<i>S</i><sup>′</sup>伸缩后所得, 需要满足以下约束条件</p>
                </div>
                <div class="p1">
                    <p id="77">∫<sup>∞</sup><sub>-∞</sub><i>ψ</i> (<i>x</i><sup>′</sup>) <i>dx</i><sup>′</sup>=0      (13) </p>
                </div>
                <div class="p1">
                    <p id="78">以<i>ψ</i> (<i>x</i>') 作为图像平滑函数<i>φ</i> (<i>x</i>') 的一次导数函数, 该函数积分值等于1, 随着距离增加逐渐趋近于0, 该平滑函数可看作低通滤波算子, 对应的计算式为</p>
                </div>
                <div class="p1">
                    <p id="79"><i>dφ</i> (<i>x</i><sup>′</sup>) =<i>ψ</i> (<i>x</i><sup>′</sup>) <i>dx</i><sup>′</sup>      (14) </p>
                </div>
                <div class="p1">
                    <p id="80">结合以上计算, 可得:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>W</mi><msub><mrow></mrow><mrow><mi>S</mi><mo>'</mo></mrow></msub><mi>f</mi><mo stretchy="false"> (</mo><mn>2</mn><msup><mrow></mrow><mi>j</mi></msup><mo>⋅</mo><mi>x</mi><mo>'</mo><mo stretchy="false">) </mo><mo>=</mo><mi>f</mi><mo>*</mo><mi>ψ</mi><msub><mrow></mrow><mrow><mn>2</mn><msup><mrow></mrow><mi>j</mi></msup></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>'</mo><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mo>=</mo><mi>f</mi><mo>*</mo><mrow><mo> (</mo><mrow><mn>2</mn><msup><mrow></mrow><mi>j</mi></msup><mfrac><mrow><mi>d</mi><mi>φ</mi><msub><mrow></mrow><mrow><mn>2</mn><msup><mrow></mrow><mi>j</mi></msup></mrow></msub></mrow><mrow><mi>d</mi><mi>x</mi><msup><mrow></mrow><mo>´</mo></msup></mrow></mfrac></mrow><mo>) </mo></mrow><mo stretchy="false"> (</mo><mi>x</mi><msup><mrow></mrow><mo>´</mo></msup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mo>=</mo><mo stretchy="false"> (</mo><mn>2</mn><msup><mrow></mrow><mi>j</mi></msup><mo>, </mo><mi>x</mi><msup><mrow></mrow><mo>´</mo></msup><mo stretchy="false">) </mo><mfrac><mi>d</mi><mrow><mi>d</mi><mi>x</mi><msup><mrow></mrow><mo>´</mo></msup></mrow></mfrac><mrow><mo> (</mo><mrow><mi>f</mi><mo>*</mo><mi>φ</mi><msub><mrow></mrow><mrow><mn>2</mn><msup><mrow></mrow><mi>j</mi></msup></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msup><mrow></mrow><mo>´</mo></msup><mo stretchy="false">) </mo></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">上式中, <i>W</i><sub><i>S</i>'</sub><i>f</i> (2<sup><i>j</i></sup>·<i>x</i>') 与<i>f</i> (<i>x</i>') 经<i>φ</i><sub>2<sup><i>j</i></sup></sub>平滑处理后的一次导数为正相关关系, <i>W</i><sub><i>S</i>'</sub><i>f</i> (2<sup><i>j</i></sup>·<i>x</i>') 的模最大值代表<i>f</i> (<i>x</i>') *<i>φ</i><sub>2<sup><i>j</i></sup></sub> (<i>x</i>') 的剧烈变动像素点, 将该点作为图像匹配的特征线段端点。</p>
                </div>
                <div class="p1">
                    <p id="83">以双目立体视觉图像中一侧视觉图像中某点作为中心的窗口区域为基本标准<citation id="153" type="reference"><link href="144" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 结合互相关函数对另一幅视觉图像对应区域进行相似性度量。设双目立体视觉图像的左侧视觉图像为<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false"> (</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>x</mi></mstyle><mo>∼</mo></mover><mo>, </mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mo>∼</mo></mover><mo stretchy="false">) </mo></mrow></math></mathml>, 右侧视觉图像为<mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mi>R</mi></msub><mo stretchy="false"> (</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>x</mi></mstyle><mo>∼</mo></mover><mo>, </mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mo>∼</mo></mover><mo stretchy="false">) </mo></mrow></math></mathml>, 选择中心点为 (<i>i</i><sub>1</sub>, <i>j</i>') 的窗口作为图像配准模板<i>T</i>, 该模板对应的区域规模为 (2<i>k</i>+1) × (2<i>l</i>+1) 。在右侧视觉图像水平空间内沿<i>x</i>轴方向移动该窗口, 平移距离为△<i>x</i>, 将其在右侧视觉图像中覆盖形成区域中的第<i>k</i>个子图记作<i>S</i><sub><i>k</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="86">设左侧视觉图像像素点 (<i>i</i><sub>1</sub>, <i>j</i>') 的灰度值为<i>T</i> (<i>i</i><sub>1</sub>, <i>j</i>') , 右侧视觉图像像素点 (<i>i</i><sub>2</sub>, <i>j</i>') 的灰度值为<i>S</i><sub><i>k</i></sub> (<i>i</i><sub>1</sub>, <i>j</i>') 。利用公式 (16) 给出对应的归一化函数式</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mo>-</mo><mi>k</mi></mrow><mi>k</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mo>-</mo><mi>l</mi></mrow><mi>l</mi></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>S</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>m</mi><mo>+</mo><mi>i</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>n</mi><mo>+</mo><mi>j</mi><mo>'</mo><mo stretchy="false">) </mo><mi>Τ</mi><mo stretchy="false"> (</mo><mi>m</mi><mo>+</mo><mi>i</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>n</mi><mo>+</mo><mi>j</mi><mo>'</mo><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88"><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><mo> (</mo><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mo>-</mo><mi>k</mi></mrow><mi>k</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mo>-</mo><mi>l</mi></mrow><mi>l</mi></munderover><mrow><mo stretchy="false">[</mo><mi>S</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>m</mi><mo>+</mo><mi>i</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>n</mi><mo>+</mo><mi>j</mi><mo>'</mo><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow></mstyle></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mo>-</mo><mi>k</mi></mrow><mi>k</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mo>-</mo><mi>l</mi></mrow><mi>l</mi></munderover><mrow><mo stretchy="false">[</mo><mi>Τ</mi><mo stretchy="false"> (</mo><mi>m</mi><mo>+</mo><mi>i</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>n</mi><mo>+</mo><mi>j</mi><mo>'</mo><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow></mstyle></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow><mo>) </mo></mrow></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math></mathml>      (16) </p>
                </div>
                <div class="p1">
                    <p id="90"><i>C</i>值最大时, 左侧视觉图像中的像素点 (<i>x</i><sub><i>l</i></sub>, <i>y</i><sub><i>l</i></sub>) 与右侧视觉图像中的对应像素点相匹配。为了削弱图像中的噪声影响, 利用下式计算归一化过程的协方差关联系数:</p>
                </div>
                <div class="p1">
                    <p id="91"><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><msup><mrow></mrow><mo>´</mo></msup><mo>=</mo><mfrac><mrow><mi>cov</mi><mo stretchy="false"> (</mo><mi>i</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>i</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>j</mi><msup><mrow></mrow><mo>´</mo></msup><mo stretchy="false">) </mo></mrow><mrow><msqrt><mrow><mi>var</mi><mo stretchy="false"> (</mo><mi>i</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>j</mi><msup><mrow></mrow><mo>´</mo></msup><mo>, </mo><mi>Τ</mi><mo stretchy="false">) </mo><mi>var</mi><mo stretchy="false"> (</mo><mi>i</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>j</mi><msup><mrow></mrow><mo>´</mo></msup><mo>, </mo><mi>S</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo></mrow></msqrt></mrow></mfrac></mrow></math></mathml>      (17) </p>
                </div>
                <div class="p1">
                    <p id="93">综上所述, 通过双目立体视觉图像的多目标区域检测, 提取并分离左侧视觉图像与右侧视觉图像中各目标区域特征点, 结合小波变换与盒过滤技术, 实现双目立体视觉图像多目标快速、精确匹配。</p>
                </div>
                <h3 id="94" name="94" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="95">为了验证所提基于小波变换的双目立体视觉图像多目标处理精确匹配方法的综合有效性, 需要进行一次仿真, 仿真环境如下:Windows7, 32位操作系统;MATLAB 2016A软件平台;仿真所用计算机主要参数为:处理器为Intel酷睿i5-6200U型号处理器, 主频为2.30GHz, 内存为4GB。</p>
                </div>
                <div class="p1">
                    <p id="96">实验结果的图、表中, MEA代表所提基于小波变换的双目立体视觉图像多目标处理精确匹配方法, MEB代表基于MIC-SURF算子的双目立体视觉图像多目标处理匹配方法, MEC代表基于改进SIFT算法的双目立体视觉图像多目标处理匹配方法。</p>
                </div>
                <h4 class="anchor-tag" id="97" name="97">1) 3种方法的匹配精度对比实验</h4>
                <div class="p1">
                    <p id="98">双目立体视觉图像多目标配准过程中, 对于左侧与右侧图像的m'对目标特征匹配点集合, 以其对应的均方根误差RMSE来判断匹配效果, RMSE的计算公式为</p>
                </div>
                <div class="p1">
                    <p id="99"><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>Μ</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>m</mi><msup><mrow></mrow><mo>´</mo></msup></mrow></mfrac><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi><msup><mrow></mrow><mo>´</mo></msup></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mrow><mo stretchy="false"> (</mo><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mo>´</mo></msubsup><mo>-</mo><mi>x</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mo>´</mo></msubsup><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo></mrow></msqrt></mrow></math></mathml>      (18) </p>
                </div>
                <div class="p1">
                    <p id="101">其中, (<i>x</i><sup>′</sup><sub><i>i</i></sub>, <i>y</i><sup>′</sup><sub><i>i</i></sub>) 、 (<i>x</i><sub><i>h</i></sub>, <i>y</i><sub><i>h</i></sub>) 分别代表待配准图像特征点对的坐标集与基准图像特征点的坐标点集。均方根误差值越小, 图像目标匹配精度越高。实验选取的实验图像对象如下图:</p>
                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201907042_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 实验对象" src="Detail/GetImg?filename=images/JSJZ201907042_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 实验对象</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201907042_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="103">对比各方法的图像目标匹配精度, 实验结果如表1所示。表1中, ME代表匹配方法;IM代表实验样本图像, 所选3组实验图像分别记作IM1、IM2和IM3, 如图1;RMSE代表图像匹配精度, 单位%;NS代表算法对应的特征匹配对数量, 单位为对, 用g表示。</p>
                </div>
                <div class="area_img" id="104">
                    <p class="img_tit"><b>表1 3种方法的匹配精度对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="104" border="1"><tr><td><br />ME</td><td>IM</td><td>RMSE</td><td>NS/g</td></tr><tr><td><br />MEA</td><td>IM1</td><td>97.55</td><td>75</td></tr><tr><td><br />MEB</td><td></td><td>92.33</td><td>52</td></tr><tr><td><br />MEC</td><td></td><td>95.08</td><td>60</td></tr><tr><td><br />MEA</td><td>IM2</td><td>98.16</td><td>72</td></tr><tr><td><br />MEB</td><td></td><td>91.05</td><td>45</td></tr><tr><td><br />MEC</td><td></td><td>95.98</td><td>55</td></tr><tr><td><br />MEA</td><td>IM3</td><td>97.86</td><td>78</td></tr><tr><td><br />MEB</td><td></td><td>93.47</td><td>60</td></tr><tr><td><br />MEC</td><td></td><td>94.52</td><td>62</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="105">分析表1数据可知, 对于不同的实验样本, 各方法的匹配精度不同, 但所提方法的匹配精度及特征点对数量的变化较小, 说明所提方法的图像适应性更好;对于相同组实验样本, 所提方法的匹配精度高于实验对比方法, 且特征点对数量多于另外两种方法, 说明所提方法的图像目标匹配效果更好。</p>
                </div>
                <h4 class="anchor-tag" id="106" name="106">2) 3种方法的匹配时间对比实验</h4>
                <div class="p1">
                    <p id="107">分别记录实验中, 目标数量不同时, 各目标匹配方法运行过程所消耗的匹配时间, 实验结果如图1所示。</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201907042_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 3种方法的目标匹配时间对比" src="Detail/GetImg?filename=images/JSJZ201907042_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 3种方法的目标匹配时间对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201907042_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="109">由图1可知, 目标数量不同时, 3种方法的目标匹配时间都随着图像中目标数量的增加而延长, 但所提方法的时间增长量较少, 运行稳定性更好;图像中目标数量相同时, 3种方法中, 所提方法的目标匹配时间明显短于实验对比方法, 运行效率更高。</p>
                </div>
                <h3 id="110" name="110" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="111">双目立体视觉图像间存在一定的视觉差, 为提高图像融合的准确性, 提出基于小波变换的双目立体视觉图像多目标处理精确匹配方法, 仿真结果表明, 所提方法性能较当前方法有一定提升。下一阶段, 将对双目立体图像进行深层分解, 进一步提高特征点提取准确性, 简化匹配计算, 提升匹配精度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="121" type="formula" href="images/JSJZ201907042_12100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">乌兰</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="122">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGDC201702027&amp;v=MDYwMTJyWTlIWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnlqZ1ZMM09QeXJQYmJHNEg5Yk0=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 邹辉, 黄福珍.基于改进FAsT-Match算法的电力设备红外图像多目标定位[J].中国电机工程学报, 2017, 37 (2) :591-598.
                            </a>
                        </p>
                        <p id="124">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201701014&amp;v=MTcyMTlPS0NMZlliRzRIOWJNcm85RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amdWTDM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 齐美彬, 岳周龙, 疏坤, 等.基于广义关联聚类图的分层关联多目标跟踪[J].自动化学报, 2017, 43 (1) :152-160.
                            </a>
                        </p>
                        <p id="126">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGXJ201604015&amp;v=MzAxMjF5clRaTEc0SDlmTXE0OUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeWpnVkwzT1A=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 王云舒, 刘建业, 曾庆化, 等.惯性信息辅助的快速大视角图像匹配方法[J].中国惯性技术学报, 2016, 24 (4) :504-510.
                            </a>
                        </p>
                        <p id="128">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201701032&amp;v=Mjg5NzlPSWpYQlk3RzRIOWJNcm85R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amdWTDM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Xu W, Chen Y T, Piao Y J, et al.Target fast matching recognition of on-board system based on Jilin-1 satellite image[J].Optics &amp; Precision Engineering, 2017, 25 (1) :255-262.
                            </a>
                        </p>
                        <p id="130">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201601037&amp;v=MjcyODU3cWZadVpuRnlqZ1ZMM09MejdCYmJHNEg5Zk1ybzlHWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 张敬丽, 张会清, 代汝勇.基于MIC-SURF的快速图像匹配算法[J].计算机工程, 2016, 42 (1) :210-214.
                            </a>
                        </p>
                        <p id="132">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY2016S2035&amp;v=MDM1NTZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeWpnVkwzT0x6N0JkN0c0SDlldnJZOUc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 向程谕, 王冬丽, 李建勋, 等.基于改进SIFT特征的深度图像匹配[J].计算机应用, 2016, 36 (s2) :135-138.
                            </a>
                        </p>
                        <p id="134">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201619038&amp;v=MTUxNzN5amdWTDNPTHo3TWFiRzRIOWZOcG85R2JJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 付偲, 邓丽, 卢根, 等.基于快速视网膜关键点算法改进的图像匹配方法[J].计算机工程与应用, 2016, 52 (19) :208-212.
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201601023&amp;v=MjM1ODhIOWZNcm85SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5amdWTDNPUER6VGJMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 朱奇光, 张朋珍, 李昊立, 等.基于全局和局部特征融合的图像匹配算法研究[J].仪器仪表学报, 2016, 37 (1) :170-176.
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWJS201610009&amp;v=MjkxMDNCZmJHNEg5Zk5yNDlGYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnlqZ1ZMM09MVHI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 戴宪策, 谢奇.基于傅里叶-梅林变换的图像匹配方法研究[J].红外技术, 2016, 38 (10) :860-863.
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Comparison of surface matching and target matching for image‐guided pelvic radiation therapy for both supine and prone patient positions">

                                <b>[10]</b> Hui Z, Wang B, Sarkar V, et al.Comparison of surface matching and target matching for image‐guided pelvic radiation therapy for both supine and prone patient positions[J].Journal of Applied Clinical Medical Physics, 2016, 17 (3) :14-24.
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201709075&amp;v=MTIwNDJDVVI3cWZadVpuRnlqZ1ZMM09MejdCZExHNEg5Yk1wbzlDWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 李金明.多视觉动画图像三维重建特征点匹配优化仿真[J].计算机仿真, 2017, 34 (9) :341-344.
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201608068&amp;v=MDI0ODVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeWpnVkwzT0x6N1NaTEc0SDlmTXA0OURiSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 杨进, 高飞, 马良.基于改进并行粒子群算法的彩色图像匹配[J].计算机应用研究, 2016, 33 (8) :2543-2546.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201907042" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201907042&amp;v=MzEwNzFuRnlqZ1ZMM09MejdCZExHNEg5ak1xSTlCWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRsbWkycFBkejk2L1VObmUxUWpzZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
