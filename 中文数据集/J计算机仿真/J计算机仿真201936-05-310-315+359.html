<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141790727631250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201905062%26RESULT%3d1%26SIGN%3dBXXy8dG0G0PYlS16C5ohZpCMOOI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201905062&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201905062&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201905062&amp;v=MTI0MzNvOURab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXprVnIzTEx6N0JkTEc0SDlqTXE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;2 图上数据多分类问题的离散非局部变分&lt;/b&gt;Potts&lt;b&gt;模型&lt;/b&gt; "><b>2 图上数据多分类问题的离散非局部变分</b>Potts<b>模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="&lt;b&gt;2.1 数据多分类问题的集合描述&lt;/b&gt;"><b>2.1 数据多分类问题的集合描述</b></a></li>
                                                <li><a href="#64" data-title="&lt;b&gt;2.2 稀疏无向加权图及其上定义的非局部离散算子&lt;/b&gt;"><b>2.2 稀疏无向加权图及其上定义的非局部离散算子</b></a></li>
                                                <li><a href="#101" data-title="&lt;b&gt;2.3 多分类问题的非局部离散变分Potts模型&lt;/b&gt;"><b>2.3 多分类问题的非局部离散变分Potts模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#116" data-title="&lt;b&gt;3 改进多分类问题的非局部离散变分Potts模型及其ADMM算法&lt;/b&gt; "><b>3 改进多分类问题的非局部离散变分Potts模型及其ADMM算法</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#197" data-title="&lt;b&gt;4 数值实验&lt;/b&gt; "><b>4 数值实验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#204" data-title="&lt;b&gt;4.1&lt;/b&gt; “&lt;b&gt;三月”人工数据集&lt;/b&gt;"><b>4.1</b> “<b>三月”人工数据集</b></a></li>
                                                <li><a href="#217" data-title="&lt;b&gt;4.2&lt;/b&gt; “&lt;b&gt;四月”人工数据集&lt;/b&gt;"><b>4.2</b> “<b>四月”人工数据集</b></a></li>
                                                <li><a href="#231" data-title="&lt;b&gt;4.3 Waveform数据集&lt;/b&gt;"><b>4.3 Waveform数据集</b></a></li>
                                                <li><a href="#234" data-title="&lt;b&gt;4.4 MNIST数据集&lt;/b&gt;"><b>4.4 MNIST数据集</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#241" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#200" data-title="&lt;b&gt;图1 无向图的部分顶点&lt;/b&gt;"><b>图1 无向图的部分顶点</b></a></li>
                                                <li><a href="#202" data-title="&lt;b&gt;图2 图与标记&lt;/b&gt;"><b>图2 图与标记</b></a></li>
                                                <li><a href="#216" data-title="&lt;b&gt;图3&lt;/b&gt; “&lt;b&gt;三月”实验结果&lt;/b&gt;"><b>图3</b> “<b>三月”实验结果</b></a></li>
                                                <li><a href="#230" data-title="&lt;b&gt;图4&lt;/b&gt; “&lt;b&gt;四月”实验结果&lt;/b&gt;"><b>图4</b> “<b>四月”实验结果</b></a></li>
                                                <li><a href="#233" data-title="&lt;b&gt;图5&lt;/b&gt; waveform&lt;b&gt;数据集实验结果&lt;/b&gt;"><b>图5</b> waveform<b>数据集实验结果</b></a></li>
                                                <li><a href="#236" data-title="&lt;b&gt;图6&lt;/b&gt; MNIST&lt;b&gt;手写数字数据集&lt;/b&gt;"><b>图6</b> MNIST<b>手写数字数据集</b></a></li>
                                                <li><a href="#238" data-title="&lt;b&gt;图7&lt;/b&gt; MNIST&lt;b&gt;数据集实验结果&lt;/b&gt;"><b>图7</b> MNIST<b>数据集实验结果</b></a></li>
                                                <li><a href="#240" data-title="&lt;b&gt;表1 经典算法和改进算法在三种数据集上的分类结果比较&lt;/b&gt;"><b>表1 经典算法和改进算法在三种数据集上的分类结果比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" M Mohammed, K M B han, E B M Bashier.Machine Learning:Algorithms and Applications[M].Boca Raton:CPR Press, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Machine Learning:Algorithms and Applications">
                                        <b>[1]</b>
                                         M Mohammed, K M B han, E B M Bashier.Machine Learning:Algorithms and Applications[M].Boca Raton:CPR Press, 2016.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" X Kong, M K Ng, Z H Zhou.Transductive Multi-Label Learning via Label Set Propagation[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering, 2013, 25 (3) :704-719." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Transductive Multilabel Learning via Label Set Propagation">
                                        <b>[2]</b>
                                         X Kong, M K Ng, Z H Zhou.Transductive Multi-Label Learning via Label Set Propagation[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering, 2013, 25 (3) :704-719.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 刘建伟, 刘媛, 罗雄麟.半监督学习方法与研究综述[J].计算机学报, 2015, 38 (8) :2592-1617." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201508008&amp;v=MDUxMjg2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXprVnIzTEx6N0Jkckc0SDlUTXA0OUZiSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         刘建伟, 刘媛, 罗雄麟.半监督学习方法与研究综述[J].计算机学报, 2015, 38 (8) :2592-1617.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" C Samson, et al.A Level Set Model for Image Classification[J].International Journal of Computer Vision, 2000, 40 (3) :187-197." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830653&amp;v=MTQxOTJaK1p1RmlEbFY3N05JbDA9Tmo3QmFyTzRIdEhPcDR4Rll1NE1ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3Fk&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         C Samson, et al.A Level Set Model for Image Classification[J].International Journal of Computer Vision, 2000, 40 (3) :187-197.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" C H Q Ding, et al.A Min-max Cut Algorithm for Graph Partitioning and Data Clustering[C].IEEE International Conference on Data Mining.IEEE Computer Society, 2001:107-114." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A min-max cut algorithm for graph partitioning and data clustering">
                                        <b>[5]</b>
                                         C H Q Ding, et al.A Min-max Cut Algorithm for Graph Partitioning and Data Clustering[C].IEEE International Conference on Data Mining.IEEE Computer Society, 2001:107-114.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" U V Luxburg.A tutorial on spectral clustering[J].Statistics and Computing, 2007, 17 (4) :395-416." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002792420&amp;v=MzA1Mjc9Tmo3QmFyTzRIdEhPcUlaSFlPa1BZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FkWitadUZpRGxWNzdOSWww&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         U V Luxburg.A tutorial on spectral clustering[J].Statistics and Computing, 2007, 17 (4) :395-416.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" B Xavier, et al.Multi-class Transductive Learning Based on ?偨b1 Relaxations of Cheeger Cut and Mumford-Shah-Potts Model[J].Journal of Mathematical Imaging &amp;amp; Vision, 2014, 49 (1) :191-201." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14032600015418&amp;v=MTYyNDFyZklKRjhSYUJFPU5qN0Jhcks4SHRMT3FZOUZaT29LQ0gweG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         B Xavier, et al.Multi-class Transductive Learning Based on ?偨b1 Relaxations of Cheeger Cut and Mumford-Shah-Potts Model[J].Journal of Mathematical Imaging &amp;amp; Vision, 2014, 49 (1) :191-201.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" C Garcia-Cardona, et al.Fast Multiclass Segmentation using Diffuse Interface Methods on Graphs[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2013, 36 (8) :1600-1613." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast Multiclass Segmentation using Diffuse Interface Methods on Graphs">
                                        <b>[8]</b>
                                         C Garcia-Cardona, et al.Fast Multiclass Segmentation using Diffuse Interface Methods on Graphs[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2013, 36 (8) :1600-1613.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" M Maier, M Hein, U Von Luxburg.Optimal Construction of K-nearest Neighbor Graphs for Identifying Noisy Clusters[J].Theoretical Computer Science, 2009, 410 (19) :1749-1764." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100980298&amp;v=MzI0OTRmSUpGOFJhQkU9TmlmT2ZiSzdIdERPcm85RmJlTVBEblV4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         M Maier, M Hein, U Von Luxburg.Optimal Construction of K-nearest Neighbor Graphs for Identifying Noisy Clusters[J].Theoretical Computer Science, 2009, 410 (19) :1749-1764.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" X Bresson, et al.Multiclass Total Variation Clustering[J].Advances in Neural Information Processing Systems, 2013, 1 (13) :1421-1429." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiclass total variation clustering">
                                        <b>[10]</b>
                                         X Bresson, et al.Multiclass Total Variation Clustering[J].Advances in Neural Information Processing Systems, 2013, 1 (13) :1421-1429.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" L Rudin, S Osher, F Fatemi.Nonlinear Total Variation Based Noise Removal Algorithms[J].1992, 60 (1-4) :259-268." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinear total variation based noise removal algorithms">
                                        <b>[11]</b>
                                         L Rudin, S Osher, F Fatemi.Nonlinear Total Variation Based Noise Removal Algorithms[J].1992, 60 (1-4) :259-268.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" M Belkin, I Matveeva, P Niyogi.Regularization and Semi-supervised Learning on Large Graphs[M].Berlin :Springer Berlin Heidelberg, 2004." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Regularization and Semi-supervised Learning on Large Graphs">
                                        <b>[12]</b>
                                         M Belkin, I Matveeva, P Niyogi.Regularization and Semi-supervised Learning on Large Graphs[M].Berlin :Springer Berlin Heidelberg, 2004.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" G Gilboa, S Osher.Nonlocal Operators with Applications to Image Processing[J].Siam Journal on Multiscale Modeling &amp;amp; Simulation, 2008, 7 (3) :1005-1028." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlocal operators with applications to image processing">
                                        <b>[13]</b>
                                         G Gilboa, S Osher.Nonlocal Operators with Applications to Image Processing[J].Siam Journal on Multiscale Modeling &amp;amp; Simulation, 2008, 7 (3) :1005-1028.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" A Elmoataz, O Lezoray, S Bougleux.Nonlocal Discrete Regularization on Weighted Graphs:A Framework for Image and Manifold Processing[J].IEEE Trans Image Process, 2008, 17 (7) :1047-1060." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlocal Discrete Regularization on Weighted Graphs: A Framework for Image and Manifold Processing">
                                        <b>[14]</b>
                                         A Elmoataz, O Lezoray, S Bougleux.Nonlocal Discrete Regularization on Weighted Graphs:A Framework for Image and Manifold Processing[J].IEEE Trans Image Process, 2008, 17 (7) :1047-1060.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" E Bae, E Merkurjev.Convex Variational Methods for Multiclass Data Segmentation on Graphs[J].Journal of Mathematical Imaging and Vision, 2017, 58 (3) :468-493." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJDA59E31856DB943E492CF10E8ABE0385D&amp;v=MTExMTdMVTA1dEJod0xtNndxcz1OajdCYXNLOUY2VFByb2RBWXA5OUJYZzZ1aElhNkV3TFNYK1hwR05IRExLWFRiL3JDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         E Bae, E Merkurjev.Convex Variational Methods for Multiclass Data Segmentation on Graphs[J].Journal of Mathematical Imaging and Vision, 2017, 58 (3) :468-493.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" X Luo, A L Bertozzi.Convergence Analysis of the Graph Allen-Cahn Scheme[J].Journal of Statistical Physics, 2017, 167 (3) :934-958." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD72A465715B8F22D5B5C3F4BEEABD74E2&amp;v=MDI5Mzk2d3FzPU5qN0JhclM2YjlYS3FvaEVZWmtIZW40N3V4Tmg3MHgrUG51UTJXZEVDOGFUUWMrZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRCaHdMbQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         X Luo, A L Bertozzi.Convergence Analysis of the Graph Allen-Cahn Scheme[J].Journal of Statistical Physics, 2017, 167 (3) :934-958.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" L Condat.Fast projection onto the Simplex and the l1 Ball[J].Mathematical Programming, 2016, 158 (1-2) :575-585." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast projection onto the Simplex and the l1 Ball">
                                        <b>[17]</b>
                                         L Condat.Fast projection onto the Simplex and the l1 Ball[J].Mathematical Programming, 2016, 158 (1-2) :575-585.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" 潘振宽, 等.三维图像多相分割的变分水平集方法[J].计算机学报, 2009, 32 (12) :2464-2474." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX200912020&amp;v=MDE4ODdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6a1ZyM0xMejdCZHJHNEh0ak5yWTlIWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         潘振宽, 等.三维图像多相分割的变分水平集方法[J].计算机学报, 2009, 32 (12) :2464-2474.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" R Glowinski, T W Pan, X C Tai.Some Facts About Operator-Splitting and Alternating Direction Methods[J].Springer International Publishing, 2016, 103 (9) :19-94." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Some Facts About Operator-Splitting and Alternating Direction Methods">
                                        <b>[19]</b>
                                         R Glowinski, T W Pan, X C Tai.Some Facts About Operator-Splitting and Alternating Direction Methods[J].Springer International Publishing, 2016, 103 (9) :19-94.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(05),310-315+359             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>改进的POTTS模型及其数据多分类直推学习算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E6%96%B9%E4%B8%BD&amp;code=42021381&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵方丽</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%BD%98%E6%8C%AF%E5%AE%BD&amp;code=08142590&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">潘振宽</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E6%AD%A2%E7%A3%8A&amp;code=38196285&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐止磊</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%91%E4%B8%96%E7%A7%80&amp;code=08143508&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郑世秀</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%9D%92%E5%B2%9B%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0201790&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">青岛大学计算机科学技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>借助于图上离散非局部算子, 计算机视觉领域图像分割的Potts模型可直接应用于数据多分类直推学习, 但为受多种约束的能量泛函极值问题。采用传统的惩罚函数方法将受约束优化问题转化为无约束优化问题的求解涉及多个难以设定的惩罚参数。通过用较少的标记函数设计每类数据的特征函数自然满足原有的Simplex约束避免了对这类约束的惩罚。通过直接投影方法保证了直推学习中预设标记点精确约束进一步减少了能量泛函中惩罚项及惩罚参数的数量。对平衡分类约束和变量分裂引起的约束通过设计ADMM (Alternating Direction Method of Multipliers) 方法降低了对惩罚参数的过分依赖。通过对多个标准数据集进行数值实验验证了所提出模型和算法的有效性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A6%BB%E6%95%A3%E9%9D%9E%E5%B1%80%E9%83%A8%E7%AE%97%E5%AD%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">离散非局部算子;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E6%8D%AE%E5%A4%9A%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数据多分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%AE%97%E6%B3%95%E7%BA%A6%E6%9D%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">算法约束;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    赵方丽 (1993-) , 女 (回族) , 山东菏泽人, 硕士研究生, 主要研究领域为图像处理与机器学习;
                                </span>
                                <span>
                                    潘振宽 (1966-) , 男 (汉族) , 山东青岛人, 青岛大学计算机科学技术学院院长, 教授, 主要研究邻域图像处理与机器学习;;
                                </span>
                                <span>
                                    徐止磊 (1992-) , 男 (汉族) , 山东临沂人, 硕士研究生, 主要研究领域为图像处理与机器学习;;
                                </span>
                                <span>
                                    郑世秀 (1972-) , 女 (汉族) , 山东青岛人, 讲师, 主要研究领域为图像处理与机器学习。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-03-23</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61772294);</span>
                    </p>
            </div>
                    <h1><b>Improved POTTS Model and its Data Multi-classification Direct Learning Algorithm</b></h1>
                    <h2>
                    <span>ZHAO Fang-li</span>
                    <span>PAN Zhen-kuan</span>
                    <span>XU Zhi-lei</span>
                    <span>ZHENG Shi-xiu</span>
            </h2>
                    <h2>
                    <span>College of Computer Science and Technology, Qingdao University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The Potts model for image segmentation in computer vision can be extended to multi-class data classification/transductive learning via discrete non-local operators on graph, but it leads to a constrained energy minimization problem with multiple constraints. Traditionally, this problem is solved through transformation of a constrained problem into an unconstrained one by penalty function methods with some parameters which are hard to tune. This paper proposed a modified Potts model and ADMM (Alternating Direction Method of Multipliers) to avoid the selections of multiple parameters for easy implementation. This paper designed a new scheme for characteristic functions for different sub-datasets using fewer label functions to fulfill naturally the simplex constraint of original Potts model. This paper used a simple projection method to ensure the predefined labels exactly, avoiding the data terms due to penalty. In order to overcome the problems of dependences of penalty parameters, this paper designed the ADMM method to enforce the balance classification constraints and the constraints due to linear splitting variables. Finally, numerous experiments on standard datasets are presented to demonstrate the efficiency of the proposed model and algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Graph&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Graph;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Discrete%20non-local%20operators&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Discrete non-local operators;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-class%20data%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multi-class data classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Constraint&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Constraint;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-03-23</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="42">在机器学习领域, 监督学习、半监督学习的精度和效率依赖于标注样本数量, 标注样本数量越大其精度和效率越高<citation id="244" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。但大量样本的手工标注耗时、费力、枯燥, 且易出错, 直推学习<citation id="245" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>即基于少量标注样本通过建立数学模型和算法对大量未标注样本进行自动标注。在数据挖掘领域, 直推学习又称半监督分类<citation id="246" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 且与计算机视觉领域的半监督图像分割极其类似<citation id="247" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。对高效直推学习模型与算法研究可分为两个方面。一是提升模型与算法的分类正确率。最初的最小割模型<citation id="248" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>分类正确率较低, 为提升分类正确率, 研究者提出Ratio Cut、Normalized Cut、Cheeger Cut<citation id="249" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等模型, 为进一步提升分类正确率, 研究者在原先的算法的基础上引入均衡分类约束, 并从两类分类问题推广到多分类问题中<citation id="250" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。二是通过降低模型维数或复杂度提高分类效率, 但相关研究较少<citation id="251" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="43">数据分类可在稀疏无向加权图上实现<citation id="252" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。即将分类数据抽象为无向图上的顶点, 根据顶点间的广义距离或相似度建立每个顶点及其临近顶点的关联, 依据相似度对关联顶点间的边赋予权, 其最小割方法即通过边赋予权, 通过优化方法将相似的顶点分为一类, 从而对应类间的最小权。当用离散标注函数标记每个顶点时, 上述最小割问题对应标注函数的最小离散非局部总变差<citation id="253" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="44">离散非局部总变差源于计算机视觉中有界变差函数的总变差<citation id="254" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>及机器学习中的离散规则化研究<citation id="255" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。文献<citation id="256" type="reference">[<a class="sup">13</a>]</citation>基于连续图像空间的非局部均值概念抽象出计算机视觉中的非局部导数、梯度、散度等概念, 并提出了连续空间中的非局部变分模型, 文献<citation id="257" type="reference">[<a class="sup">14</a>]</citation>将其推广到其离散形式, 可自然处理离散图上数据分类, 大大拓展了图上数据规则化数据分类方法。该类方法通过对基于图的能量泛函取极小值得到分类结果, 并将原本对离散变量的优化通过凸松弛技术<citation id="258" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>转化为连续问题求解, 最终通过阈值化得到原问题解。</p>
                </div>
                <div class="p1">
                    <p id="45">在二类分类问题研究基础上, 文献<citation id="265" type="reference">[<a class="sup">7</a>,<a class="sup">8</a>]</citation>、<citation id="259" type="reference">[<a class="sup">16</a>]</citation>分别基于离散非局部总变差和Ginzburg-Landau近似提出了图上数据多分类的Potts类变分模型, 其分类方案是为每类数据设定1个标记函数, 且为保证每个顶点仅属于1个类, 在每个顶点, 所有标记函数必须满足Simplex约束。在求解时或通过惩罚函数方法将这些约束增广到原能量泛函<citation id="260" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 或通过约束投影方法处理<citation id="261" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>, 计算复杂且影响收敛效率。在计算机视觉领域, 对于n类分割问题, 文献<citation id="262" type="reference">[<a class="sup">18</a>]</citation>等提出了用n-1个标记函数设计n个特征函数方案, 自动满足了Simplex约束, 大大简化了模型的求解。本文拟将文献<citation id="263" type="reference">[<a class="sup">17</a>]</citation>的特征函数设计方案推广到多数据分类的离散非局部总变差模型。此外, 对于直推学习或半监督分类问题, 均将预先标注的顶点以惩罚函数的形式作为数据项增广到能量泛函中, 其惩罚参数人为设定, 在优化计算过程中很难保证这些约束精确满足, 为此, 本文提出简单投影方法以确保在优化计算过程中预先标注顶点的标记严格满足, 既能提高收敛效率, 又能提高计算精度。此外, 为了避免对总变差项的变分导致的非局部曲率项的计算困难, 本文通过引入辅助变量替代非局部离散梯度, 即引入了新的变量分裂线性约束。对变量分类约束连同平衡分类约束, 本文设计了相应的ADMM (Alternating Direction Method of Multipliers) <citation id="264" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>以避免对固定惩罚参数的依赖。</p>
                </div>
                <div class="p1">
                    <p id="46">本文分5个部分。第2部分首先给出了数据多分类问题的集合描述, 并给出了无向加权稀疏图及其上定义的离散非局部导数、梯度、散度等概念, 在此基础上建立了与最小割对应的图上数据多分类问题的离散非局部变分Potts模型。第3部分在直推多数据分类的定义基础上提出了改进的Potts分类方案, 并基于该设计方案提出了图上数据多分类的离散非局部变分模型及ADMM投影算法。第4部分针对“三月”、“四月”人工数据集, waveform数据集及MNIST10类数据标准手写体数据集对本文提出的模型和算法的有效性进行了数值实验验证。第5部分为总结和展望。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag"><b>2 图上数据多分类问题的离散非局部变分</b>Potts<b>模型</b></h3>
                <h4 class="anchor-tag" id="48" name="48"><b>2.1 数据多分类问题的集合描述</b></h4>
                <div class="p1">
                    <p id="49">多分类问题是根据数据间的相似性将给定的数据集<i>V</i>划分为彼此邻接互补重叠的多个子集<i>V</i><sub>1</sub>, <i>V</i><sub>2</sub>, ...<i>V</i><sub><i>n</i></sub>, 即</p>
                </div>
                <div class="area_img" id="50">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905062_05000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="52">其中, ∅为空集。其分类最小割问题可表达为</p>
                </div>
                <div class="p1">
                    <p id="53"><mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mi>i</mi><mi>n</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow><mi>n</mi></munderover><mi>C</mi></mstyle><mo stretchy="false"> (</mo><mi>V</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>V</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="55">但易陷于无效解。基于平衡分类概念的Ratio Cut、Normalized Cut、Cheeger Cut等方法可以避免无效解, 但本质为NP Hard问题。尽管可通过凸松弛方法克服NP Hard问题, 但其凸松弛后的模型是非凸的。本文采用广义的平衡分类约束克服无效解, 即</p>
                </div>
                <div class="p1">
                    <p id="56"><mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>V</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mo>=</mo><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="58">其中, |<i>V</i><sub><i>i</i></sub>|表示第<i>i</i>类数据的个数, |<i>V</i>|表示所有数据的个数。</p>
                </div>
                <div class="p1">
                    <p id="59">直推学习或半监督分类, 是在已知少部分数据类属的情况下的分类, 即</p>
                </div>
                <div class="p1">
                    <p id="60"><i>V</i><mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mn>0</mn></msubsup></mrow></math></mathml>⊂<i>V</i><sub><i>i</i></sub>, <i>α</i><mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mn>0</mn></msubsup></mrow></math></mathml>=|<i>V</i><mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mn>0</mn></msubsup></mrow></math></mathml>|≪|<i>V</i><sub><i>i</i></sub>|=<i>α</i><sub><i>i</i></sub>      (4) </p>
                </div>
                <h4 class="anchor-tag" id="64" name="64"><b>2.2 稀疏无向加权图及其上定义的非局部离散算子</b></h4>
                <div class="p1">
                    <p id="65">稀疏无向加权图可用三元组<i>G</i> (<i>V</i>, <i>E</i>, <i>W</i>) 描述, 其中, <i>V</i>= (<i>x</i><sub><i>i</i></sub>) , (<i>i</i>=1, 2, …, <i>m</i>) 为图上顶点的集合, <i>x</i><sub><i>i</i></sub>表示第<i>i</i>个顶点。对其中任意一个顶点, 有时用<i>x</i>或<i>y</i>表示。<i>E</i>= (<i>e</i><sub><i>ij</i></sub>) 为图上顶点<i>x</i><sub><i>i</i></sub>、<i>x</i><sub><i>j</i></sub>关联的边<i>e</i><sub><i>ij</i></sub>的集合。<i>W</i>= (<i>w</i><sub><i>ij</i></sub>) (<i>x</i><sub><i>i</i></sub>∈<i>V</i>, <i>x</i><sub><i>j</i></sub>∈<i>V</i>, <i>i</i>≠<i>j</i>) 为边<i>e</i><sub><i>ij</i></sub>上权的集合, 有时表示为<i>w</i> (<i>x</i>, <i>y</i>) , 用以表示顶点间的相似度。|<i>V</i><sub><i>i</i></sub>|、|<i>V</i>|仍分别表示第<i>i</i>类数据 (顶点) 、所有数据 (顶点) 的个数。<mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mi>w</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></math></mathml>表示顶点<i>x</i>的度, 其中<i>N</i> (<i>x</i>) 表示与<i>x</i>邻接的顶点的集合。图<i>G</i> (<i>V</i>, <i>E</i>, <i>W</i>) 的度为<mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><mi>o</mi><mi>l</mi><mo stretchy="false"> (</mo><mi>V</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>V</mi></mrow></munder><mi>d</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>, 子集<i>V</i><sub><i>i</i></sub>的度为<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><mi>o</mi><mi>l</mi><mo stretchy="false"> (</mo><mi>V</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>V</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>d</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>。通常将加权图中的权<i>w</i> (<i>x</i>, <i>y</i>) 表示为</p>
                </div>
                <div class="p1">
                    <p id="69"><mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>exp</mi></mrow><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mi>d</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="71">以使得<i>w</i> (<i>x</i>, <i>y</i>) =<i>w</i> (<i>y</i>, <i>x</i>) , 且<i>w</i> (<i>x</i>, <i>y</i>) ∈ (0, 1]。其中, <i>σ</i>为控制邻域范围的参数。与广义距离<i>d</i> (<i>x</i>, <i>y</i>) 相反, <i>w</i> (<i>x</i>, <i>y</i>) 越大表示对应的两个顶点越相似。以加权图为基础的数据聚类或分类是将相似的顶点划分在一起, 将不相似的顶点划分在不同类。稀疏的含义是每个顶点仅与自己相似或相近的少量顶点关联, 从而避免了完全连通图导致的复杂计算。</p>
                </div>
                <div class="p1">
                    <p id="72">类似于连续空间上定义的非局部算子, 可定义<i>e</i> (<i>x</i>, <i>y</i>) 上的离散非局部导数<citation id="266" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="73">∂<sub><i>y</i></sub><i>u</i> (<i>x</i>) :<mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>u</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msqrt><mrow><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></msqrt><mspace width="0.25em" /><mtext> </mtext><mi>y</mi><mo>∈</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="75">同样定义顶点<i>x</i>邻域上的离散非局部梯度。</p>
                </div>
                <div class="p1">
                    <p id="76"><mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>u</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msqrt><mrow><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></msqrt><mtext> </mtext><mtext> </mtext><mi>y</mi><mo>∈</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="78">顶点<i>x</i>, <i>y</i>间的非局部矢量<mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>v</mi><mo>→</mo></mover><mo>=</mo><mi>v</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></math></mathml>的离散非局部散度</p>
                </div>
                <div class="p1">
                    <p id="80"><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mo>⋅</mo><mover accent="true"><mi>v</mi><mo>→</mo></mover><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>:<mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mo stretchy="false"> (</mo></mstyle><mi>v</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>v</mi><mo stretchy="false"> (</mo><mi>y</mi><mo>, </mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msqrt><mrow><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></msqrt></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="83">非局部矢量<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>v</mi><mo>→</mo></mover><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mover accent="true"><mi>v</mi><mo>→</mo></mover><msub><mrow></mrow><mn>2</mn></msub></mrow></math></mathml>的点积</p>
                </div>
                <div class="p1">
                    <p id="85"><mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>〈</mo><mover accent="true"><mi>v</mi><mo>→</mo></mover><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mover accent="true"><mi>v</mi><mo>→</mo></mover><msub><mrow></mrow><mn>2</mn></msub><mo>〉</mo><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>:<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mi>v</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="88">则有非局部矢量的模</p>
                </div>
                <div class="p1">
                    <p id="89"><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mover accent="true"><mi>v</mi><mo>→</mo></mover><mo stretchy="false">|</mo><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>:<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mi>v</mi></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></msqrt></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="92">离散非局部梯度的模</p>
                </div>
                <div class="p1">
                    <p id="93"><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><mo stretchy="false">|</mo><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mrow><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>u</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></msqrt></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="95">离散非局部拉普拉斯算子Laplacian</p>
                </div>
                <div class="p1">
                    <p id="96"><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mo>⋅</mo><mo stretchy="false"> (</mo><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mn>2</mn><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mo stretchy="false"> (</mo></mstyle><mi>u</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>u</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (12) </p>
                </div>
                <div class="p1">
                    <p id="98">离散非局部曲率</p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>k</mi><msub><mrow></mrow><mi>w</mi></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>y</mi><mo>∈</mo><mi>Ν</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mrow><mrow><mo> (</mo><mrow><mfrac><mn>1</mn><mrow><mo stretchy="false">|</mo><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><mo stretchy="false">|</mo><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mo stretchy="false">|</mo><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><mo stretchy="false">|</mo><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></mstyle><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100"><i>u</i> (<i>x</i>) ) <i>w</i> (<i>x</i>, <i>y</i>)      (13) </p>
                </div>
                <h4 class="anchor-tag" id="101" name="101"><b>2.3 多分类问题的非局部离散变分Potts模型</b></h4>
                <div class="p1">
                    <p id="102">多分类问题的<i>Potts</i>模型为每个数据类指定1个标记函数, 即定义</p>
                </div>
                <div class="area_img" id="103">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905062_10300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="105">为满足<i>Simplex</i>约束 (14) , 在每个顶点上, 这些标记函数应满足</p>
                </div>
                <div class="p1">
                    <p id="106"><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>u</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn></mrow></math></mathml>      (15) </p>
                </div>
                <div class="p1">
                    <p id="108">引入多个标记函数后, 借助于上述离散非局部算子, 最小割问题 (2) 可改写为离散非局部总变差表达</p>
                </div>
                <div class="p1">
                    <p id="109" class="code-formula">
                        <mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Μ</mi><mi>i</mi><mi>n</mi><mi>C</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtable><mtr><mtd><mi>i</mi><mo>, </mo><mi>j</mi></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mi>i</mi><mo>≠</mo><mi>j</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mi>n</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>V</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>V</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>Μ</mi><mi>i</mi><mi>n</mi><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mtable><mtr><mtd><mi>x</mi><mo>∈</mo><mi>V</mi><mo>;</mo><mi>y</mi><mo>∈</mo><mi>V</mi><msub><mrow></mrow><mi>j</mi></msub></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mi>x</mi><mo>≠</mo><mi>y</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></munder><mi>w</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>Μ</mi><mi>i</mi><mi>n</mi></mrow></mstyle><mrow><mi>u</mi><mo>∈</mo><mrow><mo stretchy="false">{</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">}</mo></mrow><msup><mrow></mrow><mi>n</mi></msup></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>V</mi></mrow></munder><mo stretchy="false">|</mo></mstyle></mrow></mstyle><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="110">其平衡分类约束 (3) 可改写为</p>
                </div>
                <div class="p1">
                    <p id="111"><mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>V</mi></mrow></munder><mi>u</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>      (17) </p>
                </div>
                <div class="p1">
                    <p id="113">其已知标注样本可表达为如下约束</p>
                </div>
                <div class="area_img" id="114">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905062_11400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h3 id="116" name="116" class="anchor-tag"><b>3 改进多分类问题的非局部离散变分Potts模型及其ADMM算法</b></h3>
                <div class="p1">
                    <p id="117">上述多分类问题的非局部离散变分Potts模型可综合为如下受约束凸松弛模型, 将<i>u</i><sub><i>i</i></sub>∈{0, 1}凸松弛为<i>u</i><sub><i>i</i></sub>∈[0, 1], 即</p>
                </div>
                <div class="p1">
                    <p id="118"><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>Μ</mi><mi>i</mi><mi>n</mi></mrow></mstyle><mrow><mi>u</mi><mo>∈</mo><mrow><mo stretchy="false">[</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mi>n</mi></msup></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>V</mi></mrow></munder><mo stretchy="false">|</mo></mstyle></mrow></mstyle><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (19) </p>
                </div>
                <div class="area_img" id="120">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905062_12000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="122">其经典的计算方法是引入多个惩罚参数将上述约束优化问题转化为无约束优化问题, 即</p>
                </div>
                <div class="area_img" id="123">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905062_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="125">其中, </p>
                </div>
                <div class="p1">
                    <p id="126" class="code-formula">
                        <mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>η</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mi>x</mi><mo>∈</mo><mi>V</mi><msup><mrow></mrow><mn>0</mn></msup></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>w</mi><mi>i</mi><mi>s</mi><mi>e</mi></mtd></mtr></mtable></mrow></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="127">为已知标定顶点的掩模函数, <i>μ</i><sub>0</sub>、<i>μ</i><sub>1</sub>、<i>μ</i><sub>2</sub>为惩罚参数。理论上, 惩罚参数为较大的正数时上述约束能够较好满足, 但数值过大会导致数值病态, 而数值较小则约束近似满足。为避免之, 本文对约束 (20<i>c</i>) 采用投影方法处理, 使得每步迭代均严格满足;对约束 (20<i>b</i>) 采用增广Lagrange方法处理;对约束 (20<i>a</i>) 的处理, 考虑到该约束方程可表示为<mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mi>i</mi><mo>≠</mo><mi>j</mi></mrow><mi>n</mi></munderover><mi>u</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>, 即完全可以用<i>n</i>-1个二值标记函数<i>u</i><sub><i>i</i></sub> (<i>x</i>) , (<i>i</i>=1, 2, ..., <i>n</i>-1) 设计<i>n</i>个类别的特征函数</p>
                </div>
                <div class="p1">
                    <p id="129" class="code-formula">
                        <mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>χ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>u</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>, </mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>, </mo><mi>u</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mi>x</mi><mo>∈</mo><mi>V</mi><msub><mrow></mrow><mi>i</mi></msub></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>w</mi><mi>i</mi><mi>s</mi><mi>e</mi></mtd></mtr></mtable></mrow></mrow><mo>, </mo><mo stretchy="false"> (</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>, </mo><mi>n</mi><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="130">且自然满足<mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>χ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn></mrow></math></mathml>, 参照文献[21]提出的方案, 各类别数据的特征函数设计如下</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>χ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>u</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mi>u</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>χ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>u</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>u</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mi>u</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>.</mo><mo>.</mo><mo>.</mo></mtd></mtr><mtr><mtd><mi>χ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mn>1</mn><mo>-</mo><mi>u</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>.</mo><mo>.</mo><mo>.</mo></mtd></mtr><mtr><mtd><mi>χ</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mn>1</mn><mo>-</mo><mi>u</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mi>u</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">其中, 引入<i>u</i><sub>0</sub> (<i>x</i>) =0, <i>u</i><sub>1</sub> (<i>x</i>) =1为表达方便。可以证明<mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>χ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn></mrow></math></mathml>自然满足。这样, 平衡约束条件 (17) 可改写为</p>
                </div>
                <div class="p1">
                    <p id="135"><mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>V</mi></mrow></munder><mi>χ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>V</mi></mrow></munder><mo stretchy="false"> (</mo></mstyle><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mn>1</mn><mo>-</mo><mi>u</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>      (23) </p>
                </div>
                <div class="p1">
                    <p id="137">从而, 受约束优化问题 (19, 20) 转化为</p>
                </div>
                <div class="p1">
                    <p id="138"><mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>Μ</mi><mi>i</mi><mi>n</mi></mrow></mstyle><mrow><mi>u</mi><mo>∈</mo><mrow><mo stretchy="false">[</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mi>n</mi></msup></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>V</mi></mrow></munder><mo stretchy="false">|</mo></mstyle></mrow></mstyle><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (24) </p>
                </div>
                <div class="p1">
                    <p id="140">s.t.</p>
                </div>
                <div class="area_img" id="141">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905062_14100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="143">为避免出现复杂的非局部曲率, 本文引进非局部辅助变量<mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>v</mi><mo>→</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>, 并引入<i>Lagrange</i>乘子<i>λ</i><sub>1<i>i</i></sub>, (<i>i</i>=1, 2, ..., <i>n</i>-1) 、<mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>λ</mi><mo>→</mo></mover><msub><mrow></mrow><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>, </mo><mo stretchy="false"> (</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>, </mo><mi>n</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>和惩罚参数<i>μ</i><sub>1</sub>、<i>μ</i><sub>2</sub>设计 (24, 25) 的ADMM投影方法如下</p>
                </div>
                <div class="area_img" id="146">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905062_14600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="148" class="code-formula">
                        <mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>λ</mi><msubsup><mrow></mrow><mrow><mn>1</mn><mi>i</mi></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mi>λ</mi><msubsup><mrow></mrow><mrow><mn>1</mn><mi>i</mi></mrow><mi>k</mi></msubsup><mo>+</mo><mi>μ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>V</mi></mrow></munder><mi>χ</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mover accent="true"><mi>λ</mi><mo>→</mo></mover><msubsup><mrow></mrow><mrow><mn>2</mn><mi>i</mi></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mover accent="true"><mi>λ</mi><mo>→</mo></mover><msubsup><mrow></mrow><mrow><mn>2</mn><mi>i</mi></mrow><mi>k</mi></msubsup><mo>+</mo><mi>μ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mover accent="true"><mi>v</mi><mo>→</mo></mover><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>7</mn><mi>a</mi><mo>, </mo><mn>2</mn><mn>7</mn><mi>b</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="149">在迭代每一步, <i>u</i><mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml> (<i>x</i>) 采用简单投影公式</p>
                </div>
                <div class="p1">
                    <p id="151" class="code-formula">
                        <mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>η</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></msub><mo stretchy="false"> (</mo><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mn>0</mn></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>, </mo><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mn>0</mn></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mtd><mtd><mi>i</mi><mi>f</mi><mi>η</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn></mtd></mtr><mtr><mtd><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mtd><mtd><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>w</mi><mi>i</mi><mi>s</mi><mi>e</mi></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="152">使得约束 (20<i>c</i>) 严格满足。</p>
                </div>
                <div class="p1">
                    <p id="153">在<i>k</i>-&gt;<i>k</i>+1的优化中, 固定<mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>v</mi><mo>→</mo></mover><msup><mrow></mrow><mi>k</mi></msup></mrow></math></mathml>求关于<i>u</i>的优化问题</p>
                </div>
                <div class="p1">
                    <p id="155"><mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>a</mi><mi>r</mi><mi>g</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>Μ</mi><mi>i</mi><mi>n</mi></mrow></mstyle><mrow><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">]</mo></mrow></munder><mi>E</mi><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mover accent="true"><mi>v</mi><mo>→</mo></mover><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">) </mo></mrow></math></mathml>      (29) </p>
                </div>
                <div class="p1">
                    <p id="157">然后固定<i>u</i><sup><i>k</i>+1</sup>求关于<mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>v</mi><mo>→</mo></mover></math></mathml>的优化问题</p>
                </div>
                <div class="p1">
                    <p id="159"><mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mover accent="true"><mi>v</mi><mo>→</mo></mover><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>Μ</mi><mi>i</mi><mi>n</mi></mrow></mstyle><mover accent="true"><mi>v</mi><mo>→</mo></mover></munder><mi>E</mi><mo stretchy="false"> (</mo><mi>u</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>, </mo><mover accent="true"><mi>v</mi><mo>→</mo></mover><mo stretchy="false">) </mo></mrow></math></mathml>      (30) </p>
                </div>
                <div class="p1">
                    <p id="161">对 (29) 采用标准变分方法得到关于<i>u</i><sub><i>i</i></sub>的非局部Euler-Lagrange方程</p>
                </div>
                <div class="p1">
                    <p id="162" class="code-formula">
                        <mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mo>⋅</mo><mover accent="true"><mi>λ</mi><mo>→</mo></mover><msubsup><mrow></mrow><mrow><mn>2</mn><mi>i</mi></mrow><mi>k</mi></msubsup><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mo>⋅</mo><mo stretchy="false"> (</mo><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi>μ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mo>⋅</mo><mover accent="true"><mi>v</mi><mo>→</mo></mover><msubsup><mrow></mrow><mi>i</mi><mi>k</mi></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>λ</mi></mstyle><msubsup><mrow></mrow><mrow><mn>1</mn><mi>j</mi></mrow><mi>k</mi></msubsup><mfrac><mrow><mo>∂</mo><mi>χ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mrow><mo>∂</mo><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mo>+</mo><mi>μ</mi><msub><mrow></mrow><mn>1</mn></msub><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>V</mi></mrow></munder><mi>χ</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mfrac><mrow><mo>∂</mo><mi>χ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mrow><mo>∂</mo><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mo>=</mo><mn>0</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo stretchy="false"> (</mo><mn>3</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="163">与约束<i>u</i><sub><i>i</i></sub>∈[0, 1]对应的投影公式为</p>
                </div>
                <div class="p1">
                    <p id="164"><i>u</i><mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>=<i>Max</i> (<i>Min</i> (<i>u</i><mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>, 1) , 0)       (32) </p>
                </div>
                <div class="p1">
                    <p id="167">在 (31) 中, 特征函数<i>χ</i><sub><i>j</i></sub> (<i>x</i>) 关于二值标记函数<i>u</i><sub><i>i</i></sub> (<i>x</i>) 的偏导数<mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi>χ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mrow><mo>∂</mo><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac></mrow></math></mathml>可写成如下解析形式 (33) 。</p>
                </div>
                <div class="area_img" id="169">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905062_16900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="171">同样对 (30) 采用标准变分方法可得到关于<mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>v</mi><mo>→</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>的解析形式的广义软阈值式 (34) 。</p>
                </div>
                <div class="p1">
                    <p id="173" class="code-formula">
                        <mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi>v</mi><mo>→</mo></mover><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo></mtd></mtr><mtr><mtd><mi>Μ</mi><mi>a</mi><mi>x</mi><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mfrac><mrow><mover accent="true"><mi>λ</mi><mo>→</mo></mover><msubsup><mrow></mrow><mrow><mn>2</mn><mi>i</mi></mrow><mi>k</mi></msubsup></mrow><mrow><mi>μ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac></mrow><mo>|</mo></mrow><mo>-</mo><mfrac><mn>1</mn><mrow><mi>μ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>, </mo><mn>0</mn><mo stretchy="false">) </mo><mfrac><mrow><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mfrac><mrow><mover accent="true"><mi>λ</mi><mo>→</mo></mover><msubsup><mrow></mrow><mrow><mn>2</mn><mi>i</mi></mrow><mi>k</mi></msubsup></mrow><mrow><mi>μ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac></mrow><mrow><mrow><mo>|</mo><mrow><mo>∇</mo><msub><mrow></mrow><mi>w</mi></msub><mi>u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mfrac><mrow><mover accent="true"><mi>λ</mi><mo>→</mo></mover><msubsup><mrow></mrow><mrow><mn>2</mn><mi>i</mi></mrow><mi>k</mi></msubsup></mrow><mrow><mi>μ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac></mrow><mo>|</mo></mrow></mrow></mfrac><mo>, </mo><mn>0</mn><mfrac><mover accent="true"><mn>0</mn><mo>→</mo></mover><mrow><mrow><mo>|</mo><mover accent="true"><mn>0</mn><mo>→</mo></mover><mo>|</mo></mrow></mrow></mfrac><mo>=</mo><mover accent="true"><mn>0</mn><mo>→</mo></mover><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="174">当能量泛函极小时, 停止迭代, 并采用如下阈值公式将凸松弛后的标记函数恢复为二值标记函数, 然后由不同的特征函数确定不同数据点的类属。</p>
                </div>
                <div class="area_img" id="175">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201905062_17500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="177">停止迭代的条件为</p>
                </div>
                <div class="p1">
                    <p id="178"><mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>E</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><mi>E</mi><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">|</mo></mrow><mrow><mi>E</mi><msup><mrow></mrow><mi>k</mi></msup></mrow></mfrac><mo>≤</mo><mi>ζ</mi></mrow></math></mathml>      (36) </p>
                </div>
                <div class="p1">
                    <p id="180">其中, <i>E</i><sup><i>k</i></sup>为第<i>k</i>步能量泛函的离散值, <i>ζ</i>为迭代误差容限值。改进算法中, 惩罚参数<i>μ</i><sub>0</sub>不存在, 经典算法中<i>μ</i><sub>0</sub>=10。其它参数<i>μ</i><sub>1</sub>=<i>M</i>/<i>N</i>, <i>M</i>是数据类总数目, <i>N</i>为数据集样本的总个数, <i>μ</i><sub>2</sub>=20。上述方法的计算步骤总结如下:</p>
                </div>
                <div class="p1">
                    <p id="181">1) 用<i>K</i>-<i>NN</i>等方法构建稀疏无向加权图</p>
                </div>
                <div class="p1">
                    <p id="182">2) 设定少量已知标注顶点</p>
                </div>
                <div class="p1">
                    <p id="183">3) 对所有顶点任意随机初始化, 给定辅助变量初值</p>
                </div>
                <div class="p1">
                    <p id="184">4) 设定最大迭代次数、误差容限、惩罚参数及<i>Lagrange</i>乘子初值</p>
                </div>
                <div class="p1">
                    <p id="185">5) <i>For k</i>=1, ..., <i>k</i></p>
                </div>
                <div class="p1">
                    <p id="186">●由 (31) 、 (32) 计算<i>u</i><mathml id="187"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="188">●由 (34) 计算<mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>v</mi><mo>→</mo></mover><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="190">●由 (27) 计算<i>λ</i><mathml id="191"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mi>i</mi></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>、<mathml id="192"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>λ</mi><mo>→</mo></mover><msubsup><mrow></mrow><mrow><mn>2</mn><mi>i</mi></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="193">If<i>ε</i><sup><i>k</i>+1</sup>&gt;<i>ζ</i>, <i>break</i></p>
                </div>
                <div class="p1">
                    <p id="194"><i>End</i></p>
                </div>
                <div class="p1">
                    <p id="195">6) 由 (35) 恢复二值标记函数</p>
                </div>
                <div class="p1">
                    <p id="196">7) 由 (22) 计算计算各类数据集特征函数</p>
                </div>
                <h3 id="197" name="197" class="anchor-tag"><b>4 数值实验</b></h3>
                <div class="p1">
                    <p id="198">本节以“三月”、“四月”人工数据集、waveform真实数据集及MNIST10类数据标准手写体数据集为研究对象, 验证上文提出的改进多分类和分类准确率, 并和上文提到的依赖于多个惩罚参数的经典算法进行对比分析。实验环境为:3.3GHz Inter i5 双核 CPU, 4G 内存, Matlab 2016b。</p>
                </div>
                <div class="p1">
                    <p id="199">首先, 需要将数据集抽象为无向图, 无向图的部分顶点结构如图1, 图中红色点为预标记数据。</p>
                </div>
                <div class="area_img" id="200">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905062_200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 无向图的部分顶点" src="Detail/GetImg?filename=images/JSJZ201905062_200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 无向图的部分顶点</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905062_200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="201">任意初始化的图和带有预标记的图如图2。</p>
                </div>
                <div class="area_img" id="202">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905062_202.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 图与标记" src="Detail/GetImg?filename=images/JSJZ201905062_202.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 图与标记</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905062_202.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="203">无向图中两个顶点之间的相似度由数据点之间的权值决定, 权值越大, 相似度越大。相似度由 (5) 确定。其中, 定义广义距离<i>d</i><sup>2</sup> (<i>x</i>, <i>y</i>) =∫<i>G</i><sub><i>α</i></sub>* (<i>f</i> (<i>x</i>+<i>t</i>) -<i>f</i> (<i>y</i>+<i>t</i>) ) <sup>2</sup><i>dt</i>, 加上高斯卷积<i>G</i><sub><i>α</i></sub>为了保证距离顶点近的数据点权值大, 每个顶点采用与它最邻近的<i>K</i>个邻居顶点代表, 顶点的<i>K</i>个最相邻的顶点的大多数属于某一个类别, 则该顶点也属于这个类别, 即<i>K</i>-<i>NN</i>算法。实验中, 取9个最近的邻接数据点来计算这个图, 即<i>K</i>=9。</p>
                </div>
                <h4 class="anchor-tag" id="204" name="204"><b>4.1</b> “<b>三月”人工数据集</b></h4>
                <div class="p1">
                    <p id="205">交叉形状的三月人工数据集 (<i>n</i>=3) 在<i>Matlab</i>生成算法如下:</p>
                </div>
                <div class="p1">
                    <p id="206"><i>tn</i>=3000;</p>
                </div>
                <div class="p1">
                    <p id="207"><i>dim</i>=100;</p>
                </div>
                <div class="p1">
                    <p id="208"><i>x</i>=<i>linspace</i> (0, <i>pi</i>, <i>tn</i>/3) ';</p>
                </div>
                <div class="p1">
                    <p id="209"><i>T</i>=[1.5*cos (<i>x</i>) sin (<i>x</i>) ];</p>
                </div>
                <div class="p1">
                    <p id="210"><i>T</i>=<i>cat</i> (1, <i>T</i>, [1.5*cos (<i>x</i>) +20.35-sin (<i>x</i>) ]) ;</p>
                </div>
                <div class="p1">
                    <p id="211"><i>T</i>=<i>cat</i> (1, <i>T</i>, [1.5*cos (<i>x</i>) -20.35-sin (<i>x</i>) ]) ;</p>
                </div>
                <div class="p1">
                    <p id="212"><i>sig</i>=0.015;</p>
                </div>
                <div class="p1">
                    <p id="213"><i>T</i> (:, 3:<i>dim</i>) =0;</p>
                </div>
                <div class="p1">
                    <p id="214"><i>T</i>=<i>T</i>+<i>sqrt</i> (<i>sig</i>) *<i>randn</i> (<i>tn</i>, <i>dim</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="215">这样得到3000个数据点, 每个数据点扩展为100维。采用给每组数据 (1000个数据点) 定义不同的颜色, 数据集可视化如图3中<i>a</i>所示。图3中<i>b</i>是对数据集的任意初始化, <i>c</i>和<i>d</i>分别为在原始算法和本文提出的改进算法的结果图。结果图上深蓝色的点为分类出错的数据点。</p>
                </div>
                <div class="area_img" id="216">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905062_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 “三月”实验结果" src="Detail/GetImg?filename=images/JSJZ201905062_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3</b> “<b>三月”实验结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905062_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="217" name="217"><b>4.2</b> “<b>四月”人工数据集</b></h4>
                <div class="p1">
                    <p id="218">“四月”人工数据集 (<i>n</i>=4) 由4000个数据点组成, 每个数据点同样扩展为100维。其在<i>Matlab</i>上的生成算法如下:</p>
                </div>
                <div class="p1">
                    <p id="219"><i>tn</i>=4000;</p>
                </div>
                <div class="p1">
                    <p id="220"><i>dim</i>=100;</p>
                </div>
                <div class="p1">
                    <p id="221"><i>x</i>=<i>linspace</i> (0, <i>pi</i>, <i>tn</i>/4) ';</p>
                </div>
                <div class="p1">
                    <p id="222"><i>T</i>=[1.5*<i>cos</i> (<i>x</i>)  <i>sin</i> (<i>x</i>) ];</p>
                </div>
                <div class="p1">
                    <p id="223"><i>T</i>=<i>cat</i> (1, <i>T</i>, [1.5*<i>cos</i> (<i>x</i>) +2  0.35-<i>sin</i> (<i>x</i>) ]) ;</p>
                </div>
                <div class="p1">
                    <p id="224"><i>T</i>=<i>cat</i> (1, <i>T</i>, [1.5*<i>cos</i> (<i>x</i>) -2  0.35-<i>sin</i> (<i>x</i>) ]) ;</p>
                </div>
                <div class="p1">
                    <p id="225"><i>T</i>=<i>cat</i> (1, <i>T</i>, [1.5*<i>cos</i> (<i>x</i>) +4  <i>sin</i> (<i>x</i>) ]) ;</p>
                </div>
                <div class="p1">
                    <p id="226"><i>sig</i>=0.015;</p>
                </div>
                <div class="p1">
                    <p id="227"><i>T</i> (:, 3:<i>dim</i>) =0;</p>
                </div>
                <div class="p1">
                    <p id="228"><i>T</i>=<i>T</i>+<i>sqrt</i> (<i>sig</i>) *<i>randn</i> (<i>tn</i>, <i>dim</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="229">‘四月’人工数据集的实验结果如图4所示。</p>
                </div>
                <div class="area_img" id="230">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905062_230.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 “四月”实验结果" src="Detail/GetImg?filename=images/JSJZ201905062_230.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4</b> “<b>四月”实验结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905062_230.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="231" name="231"><b>4.3 Waveform数据集</b></h4>
                <div class="p1">
                    <p id="232">Waveform数据集可以在http://archive.ics.uci.edu/ml/machine-learning-databases/Waveform网站获取, 是一个由5000个声音波形样本, 包括三种不同的波形, 每个样本有21个属性的真实数据集。该数据集是机器学习中进行分类算法测试的经典数据集。由于数据集结构本身的复杂性, 两种算法的分类精度较其它三种数据集均有所下降, 相比经典算法, 改进后的算法效率更高。将其可视化后的实验结果如图5。</p>
                </div>
                <div class="area_img" id="233">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905062_233.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 waveform数据集实验结果" src="Detail/GetImg?filename=images/JSJZ201905062_233.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5</b> waveform<b>数据集实验结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905062_233.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="234" name="234"><b>4.4 MNIST数据集</b></h4>
                <div class="p1">
                    <p id="235">MNIST数据集可以在http://yann.lecun.com/exdb/mnist/网站获取, 是一个由手写数字0-9组成的70000幅28*28像素的标准数据集。每一个像素点通过一个灰度值描述, 将28*28展开为一个一维的行向量, 用来表示图片数组中的行。MNIST有60000个训练样本集和10000个测试样本集, 是NIST数据库中的一个子集。该数据集被广泛应用于多类分类算法的测试中。手写效果如图6。</p>
                </div>
                <div class="area_img" id="236">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905062_236.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 MNIST手写数字数据集" src="Detail/GetImg?filename=images/JSJZ201905062_236.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6</b> MNIST<b>手写数字数据集</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905062_236.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="237">一种可视化数据集 (如MNIST) 分类的方法由一系列图像组成, 在给定的分割中使用颜色区分类, 即将MNIST数据集进行可视化处理, 并对MNIST数据集 (n=10) 进行了实验验证。实验结果如图7。</p>
                </div>
                <div class="area_img" id="238">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201905062_238.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 MNIST数据集实验结果" src="Detail/GetImg?filename=images/JSJZ201905062_238.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7</b> MNIST<b>数据集实验结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201905062_238.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="239">表1给出经典算法和改进算法在本文提到的四种数据集的分类结果比较。由于数据量大, 很难对每个数据点的标记函数逐一初始化, 本文采用随机任意初始化的方法, 对于相同的数据进行分类很难得到完全相同的分类结果, 表1中的数值均为任意初始化运行10次所取得结果的平均值。从实验结果可以看出, 改进算法在运行效率上明显优于原始算法, 正确率也有提升。</p>
                </div>
                <div class="area_img" id="240">
                    <p class="img_tit"><b>表1 经典算法和改进算法在三种数据集上的分类结果比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="240" border="1"><tr><td><br />数据集</td><td>改进算法<br />错误率</td><td>经典算法<br />错误率</td><td>改进算法<br />迭代次数</td><td>经典算法<br />迭代次数</td><td>改进算法运<br />行时间 (秒) </td><td>经典算法运<br />行时间 (秒) </td><td>改进算法每<br />步时间 (秒) </td><td>经典算法每<br />步时间 (秒) </td></tr><tr><td><br />三月数据集</td><td>1.31%</td><td>1.46%</td><td>30</td><td>29</td><td>16.550</td><td>20.462</td><td>0.551</td><td>0.705</td></tr><tr><td><br />四月数据集</td><td>1.27%</td><td>1.36%</td><td>30</td><td>29</td><td>23.854</td><td>30.925</td><td>0.795</td><td>1.066</td></tr><tr><td><br />Waveform数据集</td><td>18.87%</td><td>19.27%</td><td>52</td><td>52</td><td>37.388</td><td>46.696</td><td>0.719</td><td>0.898</td></tr><tr><td><br />MNIST数据集</td><td>2.49%</td><td>2.59%</td><td>27</td><td>28</td><td>814.244</td><td>1085.492</td><td>30.157</td><td>38.768</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="241" name="241" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="242">数据多分类直推式学习问题可抽象为稀疏无向加权图上的非局部离散Potts模型, 但包含多类约束, 经典的惩罚函数方法须引入多个难以调节的惩罚参数, 且影响收敛精度和效率。本文基于较少的标记函数设计每类数据的特征函数自然消除了经典模型中的Simplex约束;对直推学习中预设标记点的精确约束采用直接投影方法精确满足, 避免了惩罚数据项和相应惩罚参数的引入;对于分裂变量约束及分类平衡约束, 本文通过ADMM方法避免了对惩罚参数的依赖。数值实验证明了本文方法的有效性。</p>
                </div>
                <div class="p1">
                    <p id="243">本文后续工作将研究采用更少的标记函数设计不同数据类的特征函数, 进一步降低求解规模, 以提高计算效率。</p>
                </div>
                <div class="area_img" id="267">
                                <img alt="" src="Detail/GetImg?filename=images/JSJZ201905062_26700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Machine Learning:Algorithms and Applications">

                                <b>[1]</b> M Mohammed, K M B han, E B M Bashier.Machine Learning:Algorithms and Applications[M].Boca Raton:CPR Press, 2016.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Transductive Multilabel Learning via Label Set Propagation">

                                <b>[2]</b> X Kong, M K Ng, Z H Zhou.Transductive Multi-Label Learning via Label Set Propagation[J].IEEE Transactions on Knowledge &amp; Data Engineering, 2013, 25 (3) :704-719.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201508008&amp;v=MDY1MjFyQ1VSN3FmWnVabUZ5emtWcjNMTHo3QmRyRzRIOVRNcDQ5RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 刘建伟, 刘媛, 罗雄麟.半监督学习方法与研究综述[J].计算机学报, 2015, 38 (8) :2592-1617.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830653&amp;v=MDEwMzE0SHRIT3A0eEZZdTRNWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaURsVjc3TklsMD1OajdCYXJP&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> C Samson, et al.A Level Set Model for Image Classification[J].International Journal of Computer Vision, 2000, 40 (3) :187-197.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A min-max cut algorithm for graph partitioning and data clustering">

                                <b>[5]</b> C H Q Ding, et al.A Min-max Cut Algorithm for Graph Partitioning and Data Clustering[C].IEEE International Conference on Data Mining.IEEE Computer Society, 2001:107-114.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002792420&amp;v=MDI4NzVOSWwwPU5qN0Jhck80SHRIT3FJWkhZT2tQWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaURsVjc3&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> U V Luxburg.A tutorial on spectral clustering[J].Statistics and Computing, 2007, 17 (4) :395-416.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14032600015418&amp;v=MjU3ODRxWTlGWk9vS0NIMHhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyZklKRjhSYUJFPU5qN0Jhcks4SHRMTw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> B Xavier, et al.Multi-class Transductive Learning Based on ?偨b1 Relaxations of Cheeger Cut and Mumford-Shah-Potts Model[J].Journal of Mathematical Imaging &amp; Vision, 2014, 49 (1) :191-201.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast Multiclass Segmentation using Diffuse Interface Methods on Graphs">

                                <b>[8]</b> C Garcia-Cardona, et al.Fast Multiclass Segmentation using Diffuse Interface Methods on Graphs[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2013, 36 (8) :1600-1613.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100980298&amp;v=MzI3NDIvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJmSUpGOFJhQkU9TmlmT2ZiSzdIdERPcm85RmJlTVBEblV4b0JNVDZUNFBRSA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> M Maier, M Hein, U Von Luxburg.Optimal Construction of K-nearest Neighbor Graphs for Identifying Noisy Clusters[J].Theoretical Computer Science, 2009, 410 (19) :1749-1764.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiclass total variation clustering">

                                <b>[10]</b> X Bresson, et al.Multiclass Total Variation Clustering[J].Advances in Neural Information Processing Systems, 2013, 1 (13) :1421-1429.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinear total variation based noise removal algorithms">

                                <b>[11]</b> L Rudin, S Osher, F Fatemi.Nonlinear Total Variation Based Noise Removal Algorithms[J].1992, 60 (1-4) :259-268.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Regularization and Semi-supervised Learning on Large Graphs">

                                <b>[12]</b> M Belkin, I Matveeva, P Niyogi.Regularization and Semi-supervised Learning on Large Graphs[M].Berlin :Springer Berlin Heidelberg, 2004.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlocal operators with applications to image processing">

                                <b>[13]</b> G Gilboa, S Osher.Nonlocal Operators with Applications to Image Processing[J].Siam Journal on Multiscale Modeling &amp; Simulation, 2008, 7 (3) :1005-1028.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlocal Discrete Regularization on Weighted Graphs: A Framework for Image and Manifold Processing">

                                <b>[14]</b> A Elmoataz, O Lezoray, S Bougleux.Nonlocal Discrete Regularization on Weighted Graphs:A Framework for Image and Manifold Processing[J].IEEE Trans Image Process, 2008, 17 (7) :1047-1060.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJDA59E31856DB943E492CF10E8ABE0385D&amp;v=MDYyOThLWFRiL3JDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0Qmh3TG02d3FzPU5qN0Jhc0s5RjZUUHJvZEFZcDk5QlhnNnVoSWE2RXdMU1grWHBHTkhETA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> E Bae, E Merkurjev.Convex Variational Methods for Multiclass Data Segmentation on Graphs[J].Journal of Mathematical Imaging and Vision, 2017, 58 (3) :468-493.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD72A465715B8F22D5B5C3F4BEEABD74E2&amp;v=MTEzMjBhclM2YjlYS3FvaEVZWmtIZW40N3V4Tmg3MHgrUG51UTJXZEVDOGFUUWMrZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXRCaHdMbTZ3cXM9Tmo3Qg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> X Luo, A L Bertozzi.Convergence Analysis of the Graph Allen-Cahn Scheme[J].Journal of Statistical Physics, 2017, 167 (3) :934-958.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast projection onto the Simplex and the l1 Ball">

                                <b>[17]</b> L Condat.Fast projection onto the Simplex and the l1 Ball[J].Mathematical Programming, 2016, 158 (1-2) :575-585.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX200912020&amp;v=MTcxMThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6a1ZyM0xMejdCZHJHNEh0ak5yWTlIWkk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 潘振宽, 等.三维图像多相分割的变分水平集方法[J].计算机学报, 2009, 32 (12) :2464-2474.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Some Facts About Operator-Splitting and Alternating Direction Methods">

                                <b>[19]</b> R Glowinski, T W Pan, X C Tai.Some Facts About Operator-Splitting and Alternating Direction Methods[J].Springer International Publishing, 2016, 103 (9) :19-94.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201905062" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201905062&amp;v=MTI0MzNvOURab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXprVnIzTEx6N0JkTEc0SDlqTXE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZDMVR6N0NyWFRURWhvQ21Icm4vdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
