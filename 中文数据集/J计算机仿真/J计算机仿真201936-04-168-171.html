<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141813075287500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201904036%26RESULT%3d1%26SIGN%3dn9dPLImL9m1n7wUDOUPYBJui3bo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201904036&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201904036&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201904036&amp;v=MjY0NzM0OUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXpnVTd2T0x6N0JkTEc0SDlqTXE=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#23" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;2 特征点对齐度优化原理&lt;/b&gt; "><b>2 特征点对齐度优化原理</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#56" data-title="&lt;b&gt;3 特征点对齐度优化方法&lt;/b&gt; "><b>3 特征点对齐度优化方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#57" data-title="&lt;b&gt;3.1 基于SURF算法的特征点提取方法&lt;/b&gt;"><b>3.1 基于SURF算法的特征点提取方法</b></a></li>
                                                <li><a href="#66" data-title="&lt;b&gt;3.2 稀疏降维&lt;/b&gt;"><b>3.2 稀疏降维</b></a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;3.3 特征点对齐度优化&lt;/b&gt;"><b>3.3 特征点对齐度优化</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#86" data-title="&lt;b&gt;4 实验结果与分析&lt;/b&gt; "><b>4 实验结果与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#96" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#88" data-title="&lt;b&gt;表1 三种不同方法的补偿参数&lt;/b&gt;"><b>表1 三种不同方法的补偿参数</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;图1 三种不同方法的均方根误差对比&lt;/b&gt;"><b>图1 三种不同方法的均方根误差对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 曹鹏, 宗文婷.运动员膝关节软骨挫伤图像特征点匹配仿真[J].计算机仿真, 2017, 34 (10) :225-228." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201710050&amp;v=MTAzNjBGckNVUjdxZlp1Wm1GeXpnVTd2Qkx6N0JkTEc0SDliTnI0OUFaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[1]</b>
                                         曹鹏, 宗文婷.运动员膝关节软骨挫伤图像特征点匹配仿真[J].计算机仿真, 2017, 34 (10) :225-228.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 孙增友, 段玉帅, 李亚.基于中心环绕滤波器检测的图像特征点匹配算法[J].计算机应用, 2017, 37 (12) :3547-3553." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201712034&amp;v=MDIwNDRkN0c0SDliTnJZOUdZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXpnVTd2Qkx6N0I=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[2]</b>
                                         孙增友, 段玉帅, 李亚.基于中心环绕滤波器检测的图像特征点匹配算法[J].计算机应用, 2017, 37 (12) :3547-3553.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 董本志, 龙建勇, 景维鹏.POKD-tree:一种有效的SIFT图像特征点匹配方法[J].计算机工程与应用, 2017, 53 (16) :182-186." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201716030&amp;v=MTI3NDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emdVN3ZCTHo3TWFiRzRIOWJOcVk5R1pJUUtESDg0dlI=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[3]</b>
                                         董本志, 龙建勇, 景维鹏.POKD-tree:一种有效的SIFT图像特征点匹配方法[J].计算机工程与应用, 2017, 53 (16) :182-186.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 张勇, 王志锋, 马文.基于改进SIFT特征点匹配的图像拼接算法研究[J].微电子学与计算机, 2016, 33 (3) :60-64." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201603013&amp;v=MDI1NTdCdEdGckNVUjdxZlp1Wm1GeXpnVTd2Qk1qWFNaTEc0SDlmTXJJOUVaNFFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[4]</b>
                                         张勇, 王志锋, 马文.基于改进SIFT特征点匹配的图像拼接算法研究[J].微电子学与计算机, 2016, 33 (3) :60-64.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 戴雪梅, 郎朗, 陈孟元.基于改进ORB的图像特征点匹配研究[J].电子测量与仪器学报, 2016, 30 (2) :233-240." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201602009&amp;v=MTM0NDBJVGZDZDdHNEg5Zk1yWTlGYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6Z1U3dkI=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[5]</b>
                                         戴雪梅, 郎朗, 陈孟元.基于改进ORB的图像特征点匹配研究[J].电子测量与仪器学报, 2016, 30 (2) :233-240.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 马丽丽, 等.基于RANSAC的特征点匹配算法[J].计算机工程与设计, 2016, 37 (7) :1794-1797." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201607018&amp;v=MTYzNDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emdVN3ZCTmlmWVpMRzRIOWZNcUk5RWJJUUs=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[6]</b>
                                         马丽丽, 等.基于RANSAC的特征点匹配算法[J].计算机工程与设计, 2016, 37 (7) :1794-1797.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 张勇, 耿国华.基于条件数约束的秦俑图像特征点匹配[J].云南大学学报:自然科学版, 2017, 39 (4) :547-553." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YNDZ201704007&amp;v=MjA2NTVGWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6Z1U3dkJQQ1BQZExHNEg5Yk1xNDk=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[7]</b>
                                         张勇, 耿国华.基于条件数约束的秦俑图像特征点匹配[J].云南大学学报:自然科学版, 2017, 39 (4) :547-553.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 朱力强, 等.基于特征点集距离描述的裂缝图像匹配算法研究[J].仪器仪表学报, 2016, 37 (12) :2851-2858." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201612027&amp;v=MTkyNzZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXpnVTd2QlBEelRiTEc0SDlmTnJZOUg=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[8]</b>
                                         朱力强, 等.基于特征点集距离描述的裂缝图像匹配算法研究[J].仪器仪表学报, 2016, 37 (12) :2851-2858.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 陈天华, 王福龙.实时鲁棒的特征点匹配算法[J].中国图象图形学报, 2016, 21 (9) :1213-1220." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201609010&amp;v=MTcxMTFNcG85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emdVN3ZCUHlyZmJMRzRIOWY=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[9]</b>
                                         陈天华, 王福龙.实时鲁棒的特征点匹配算法[J].中国图象图形学报, 2016, 21 (9) :1213-1220.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 邵春艳, 丁庆海, 罗海波.基于空间纹理相似性的图像角点特征匹配算法[J].计算机应用研究, 2016, 33 (12) :3868-3871." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201612078&amp;v=MDY0NjJDVVI3cWZadVptRnl6Z1U3dkJMejdTWkxHNEg5Zk5yWTlDYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                        <b>[10]</b>
                                         邵春艳, 丁庆海, 罗海波.基于空间纹理相似性的图像角点特征匹配算法[J].计算机应用研究, 2016, 33 (12) :3868-3871.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(04),168-171             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>视频图像区域形状特征点对齐度优化方法仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E5%8F%91%E8%BE%89&amp;code=39902545&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">吴发辉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E7%8E%B2&amp;code=37283408&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">张玲</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%99%E6%96%87%E6%A3%AE&amp;code=15091186&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">余文森</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E5%A4%B7%E5%AD%A6%E9%99%A2%E5%AE%9E%E9%AA%8C%E5%AE%A4%E7%AE%A1%E7%90%86%E4%B8%AD%E5%BF%83&amp;code=0140481&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">武夷学院实验室管理中心</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E5%A4%B7%E5%AD%A6%E9%99%A2%E6%95%B0%E5%AD%A6%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">武夷学院数学与计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了提高视频图像配准的精准度, 需要对视频图像中的特征点对齐度进行优化。采用当前特征点对齐度优化方法对视频图像区域形状特征点的对齐度进行优化时, 存在特征点提取准确度低和特征点对坐标均方根误差大的问题。提出一种视频图像区域形状特征点对齐度优化方法, 在尺度空间的基础上采用SURF算法构建Hessian矩阵, 通过Hessian矩阵提取视频图像区域形状特征点。通过SIFT算法生成特征点描述符参数和特征点方向参数对视频图像区域形状特征点做降维处理。在相似性度量算法的基础上采用双向匹配方法完成降维处理后特征点的对齐度优化。仿真结果表明, 所提方法特征提取准确度高、特征点对坐标均方根误差小。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E9%A2%91%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">视频图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E7%82%B9&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">特征点;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AF%B9%E9%BD%90%E5%BA%A6%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">对齐度优化;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    吴发辉 (1975-) , 男 (汉族) , 福建南平人, 硕士研究生, 工程师, 主要研究领域为:数字图像处理技术。;
                                </span>
                                <span>
                                    张玲 (1983-) , 女 (汉族) , 福建南平人, 硕士研究生, 实验师, 主要研究方向:计算机应用。;
                                </span>
                                <span>
                                    余文森 (1973-) , 男 (汉族) , 福建南平人, 博士研究生, 教授, 研究方向:数字图像处理技术。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-05-05</p>

                    <p>

                            <b>基金：</b>
                                                        <span>福建省自然科学基金面上项目 (2015J01669);</span>
                    </p>
            </div>
                    <h1><b>Video Image Region Shape Feature Alignment Degree Optimization Method Simulation</b></h1>
                    <h2>
                    <span>WU Fa-hui</span>
                    <span>ZHANG Ling</span>
                    <span>YU Wen-sen</span>
            </h2>
                    <h2>
                    <span>Laboratory Management Center, Wuyi University</span>
                    <span>College of Mathematics and Computer Science, Wuyi University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to improve the accuracy of video image registration, this paper proposed a method to optimize the alignment metric of shape feature points in video image region. On the basis of scale space, SURF algorithm was used to construct Hessian matrix, and then the shape feature points of video image region were extracted by Hessian matrix. Moreover, SIFT algorithm was used to generate the descriptor parameter of feature point and the direction parameter of feature point to reduce the dimension of shape feature points in video image region. Based on the similarity measurement algorithm, the bidirectional matching method was used to optimize the alignment metric of feature points after dimension reduction. Simulation results show that the proposed method has high accuracy in feature extraction. Meanwhile, the feature point has small error for root mean square of coordinate.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Video%20image&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Video image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Feature%20point&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Feature point;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Alignment%20metric%20optimization&amp;code=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" target="_blank">Alignment metric optimization;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-05-05</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="23" name="23" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="24">随着人工智能计算的不断发展, 计算机视觉与图像处理工作也得到了长足的进步<citation id="101" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。在进行相关视觉识别中, 图像配准技术的应用较为频繁, 因此, 对特定图像的特征点进行配准, 对后期的相关处理工作至关重要<citation id="102" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="25">在图像配准工作中, 需要找到参考图像和变换图像之间的对应关系, 在对应关系的寻找过程中, 特征点匹配是图像配准中较为重要的一步, 特征点对齐度准则是特征点匹配中常用的方法, 利用图像的交互方差完成图像特征点的匹配, 特征点对齐度准则不受图像灰度属性的影响, 也不需要图像之间存在线性关系, 实用性强<citation id="103" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。当前特征点对齐度优化方法存在特征点提取准确度低和特征点对坐标均方根误差大的问题, 需要对特征点对齐度优化方法进行研究<citation id="104" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。也有相关学者对这一问题进行研究, 提出一些较好的方法。但是, 缺都存在一定的问题。</p>
                </div>
                <div class="p1">
                    <p id="26">文献<citation id="105" type="reference">[<a class="sup">5</a>]</citation>提出了一种基于ORB的特征点对齐度优化方法:该方法对尺度不变性的图像特征点进行提取, 构建描述子, 对等待处理的图像进行划分, 通过汉明距离完成图像特征点的匹配, 采用PROSAC算法检测特征匹配点, 完成特征点对齐度的优化, 但是, 该方法提取得到的视频图像中的特征点无法标定关键特征, 为后期匹配带来较大困难。文献<citation id="106" type="reference">[<a class="sup">6</a>]</citation>提出了一种基于RANSAC的特征点对齐度优化方法, 该方法通过RANSAC算法获取视频图像中的初步特征匹配点对, 并对其进行纵坐标、横坐标的排序, 去除序号不同的匹配点, 对两幅图像中的质心进行计算, 根据计算结果选择最终的特征匹配点, 完成特征点对齐度的优化。但是, 该方法计算得到的特征点对坐标的均方根误差较大。文献<citation id="107" type="reference">[<a class="sup">7</a>]</citation>提出了一种基于条件数约束的特征点对齐度优化方法, 该方法在SIFT算子的基础上得到视频图像初始的特征匹配对, 并对视频图像中的特征点进行剖分操作, 将特征点对匹配问题转化为特征点对齐度优化问题, 通过迭代重加权算法完成特征点对齐度的优化, 该方法对视频图像中的特征点进行提取时的准确度低。</p>
                </div>
                <h3 id="27" name="27" class="anchor-tag"><b>2 特征点对齐度优化原理</b></h3>
                <div class="p1">
                    <p id="28">采用当前方法对特征点对齐度进行优化时, 基于视频图像角度信息和特征点信息, 以特征点为中心提取等待处理的视频图像中的特征子图, 通过角度直方图得到视频图像的旋转角度, 计算等待处理的视频图像中特征子图的对齐度, 并将结果与设置的阈值进行对比, 选取符合条件的匹配点, 完成视频图像中特征点对齐度的优化, 具体步骤如下。</p>
                </div>
                <div class="p1">
                    <p id="29">设<i>f</i><sub>1</sub> (<i>x</i>, <i>y</i>) 、<i>f</i><sub>2</sub> (<i>x</i>, <i>y</i>) 代表的是等待处理的视频图像;<i>P</i><sub><i>f</i><sub>1</sub></sub>、<i>P</i><sub><i>f</i><sub>2</sub></sub>代表的是在视频图像中提取得到的特征点集。待处理视频图像中的任何特征点对 (<i>p</i><sub><i>i</i></sub>, <i>q</i><sub><i>i</i></sub>) 在视频图像中提取得到的特征子图为<i>I</i><sub>1</sub> (<i>x</i>, <i>y</i>) 、<i>I</i><sub>2</sub> (<i>x</i>, <i>y</i>) 。设<i>H</i><sub>1</sub> (<i>n</i>) 、<i>H</i><sub>2</sub> (<i>n</i>) 为特征子图中灰度值是<i>i</i>的像素总数;<i>p</i><sub>1</sub> (<i>i</i>) 、<i>p</i><sub>2</sub> (<i>i</i>) 代表的是灰度值<i>i</i>在视频图像中出现的比率, 计算公式为</p>
                </div>
                <div class="p1">
                    <p id="30" class="code-formula">
                        <mathml id="30"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Η</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>/</mo><mi>Μ</mi><mo>×</mo><mi>Ν</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>p</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Η</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>/</mo><mi>Μ</mi><mo>×</mo><mi>Ν</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="31">设<image id="112" type="formula" href="images/JSJZ201904036_11200.jpg" display="inline" placement="inline"><alt></alt></image>代表的是特征子图<i>I</i><sub>2</sub> (<i>x</i>, <i>y</i>) 对于特征子图<i>I</i><sub>1</sub> (<i>x</i>, <i>y</i>) 灰度值是<i>n</i>的像素集合的灰度均值, <image id="113" type="formula" href="images/JSJZ201904036_11300.jpg" display="inline" placement="inline"><alt></alt></image>的计算公式为</p>
                </div>
                <div class="p1">
                    <p id="32" class="code-formula">
                        <mathml id="32"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow></msub><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Η</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>n</mi></mrow></munder><mi>Ι</mi></mstyle><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="33">设<i>σ</i><mathml id="34"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow><mn>2</mn></msubsup></mrow></math></mathml> (<i>n</i>) 代表的是特征子图<i>I</i><sub>2</sub> (<i>x</i>, <i>y</i>) 对于特征子图<i>I</i><sub>1</sub> (<i>x</i>, <i>y</i>) 灰度值是<i>n</i>的像素集合的方差, <i>σ</i><mathml id="35"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow><mn>2</mn></msubsup></mrow></math></mathml> (<i>n</i>) 的计算公式为</p>
                </div>
                <div class="p1">
                    <p id="36" class="code-formula">
                        <mathml id="36"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><msubsup><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow><mn>2</mn></msubsup><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Η</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>n</mi></mrow></munder><mo stretchy="false">[</mo></mstyle><mi>Ι</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mover accent="true"><mi>E</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow></msub><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="37">同理, 可以得到特征子图<i>I</i><sub>1</sub> (<i>x</i>, <i>y</i>) 对于特征子图<i>I</i><sub>2</sub> (<i>x</i>, <i>y</i>) 灰度值是<i>n</i>的像素集合的方差<i>σ</i><mathml id="38"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>2</mn><mo>, </mo><mn>1</mn></mrow><mn>2</mn></msubsup></mrow></math></mathml> (<i>n</i>) 和灰度均值<image id="114" type="formula" href="images/JSJZ201904036_11400.jpg" display="inline" placement="inline"><alt></alt></image>。</p>
                </div>
                <div class="p1">
                    <p id="39">在灰度值<i>n</i>出现比率<i>p</i><sub>1</sub> (<i>n</i>) 的基础上对方差<i>σ</i><mathml id="40"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow><mn>2</mn></msubsup></mrow></math></mathml> (<i>n</i>) 进行加权, 得到特征子图<i>I</i><sub>1</sub> (<i>x</i>, <i>y</i>) 的期望方差<image id="115" type="formula" href="images/JSJZ201904036_11500.jpg" display="inline" placement="inline"><alt></alt></image></p>
                </div>
                <div class="p1">
                    <p id="42" class="code-formula">
                        <mathml id="42"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>σ</mi><mo>¯</mo></mover><msubsup><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow><mn>2</mn></msubsup><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>n</mi></munder><mi>p</mi></mstyle><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">) </mo><mi>σ</mi><msubsup><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow><mn>2</mn></msubsup><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="43">同理, 在灰度值<i>n</i>出现比率<i>p</i><sub>2</sub> (<i>n</i>) 的基础上对方差<i>σ</i><mathml id="44"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>2</mn><mo>, </mo><mn>1</mn></mrow><mn>2</mn></msubsup></mrow></math></mathml> (<i>n</i>) 进行加权, 得到特征子图<i>I</i><sub>2</sub> (<i>x</i>, <i>y</i>) 的期望方差<image id="116" type="formula" href="images/JSJZ201904036_11600.jpg" display="inline" placement="inline"><alt></alt></image></p>
                </div>
                <div class="p1">
                    <p id="46" class="code-formula">
                        <mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>σ</mi><mo>¯</mo></mover><msubsup><mrow></mrow><mrow><mn>2</mn><mo>, </mo><mn>1</mn></mrow><mn>2</mn></msubsup><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>n</mi></munder><mi>p</mi></mstyle><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">) </mo><mi>σ</mi><msubsup><mrow></mrow><mrow><mn>2</mn><mo>, </mo><mn>1</mn></mrow><mn>2</mn></msubsup><mo stretchy="false"> (</mo><mi>n</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="47">通过特征子图的期望方差得到两幅视频图像的交互方差<i>CI</i></p>
                </div>
                <div class="p1">
                    <p id="48" class="code-formula">
                        <mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>Ι</mi><mo>=</mo><mover accent="true"><mi>σ</mi><mo>¯</mo></mover><msubsup><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow><mn>2</mn></msubsup><mo>/</mo><mi>σ</mi><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mover accent="true"><mi>σ</mi><mo>¯</mo></mover><msubsup><mrow></mrow><mrow><mn>2</mn><mo>, </mo><mn>1</mn></mrow><mn>2</mn></msubsup><mo>/</mo><mi>σ</mi><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="49">式中, <i>σ</i><mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup></mrow></math></mathml>、<i>σ</i><mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>为视频图像的方差。两幅图像灰度对应的稳定度可以通两幅图像的交互方差反映<citation id="108" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。通过式 (7) 可知, 两幅图像的交互方差越小, 两幅图像中的内容相似度越高;两幅图像的交互方差越大, 两幅图像中的内容相似度越低。通过上述公式得到特征点对 (<i>p</i><sub><i>i</i></sub>, <i>q</i><sub><i>i</i></sub>) 的对齐度<i>FPAM</i></p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mi>Ρ</mi><mi>A</mi><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>q</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mi>σ</mi><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup><mi>σ</mi><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>/</mo><mo stretchy="false"> (</mo><mover accent="true"><mi>σ</mi><mo>¯</mo></mover><msubsup><mrow></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow><mn>2</mn></msubsup><mi>σ</mi><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup><mo>+</mo><mover accent="true"><mi>σ</mi><mo>¯</mo></mover><msubsup><mrow></mrow><mrow><mn>2</mn><mo>, </mo><mn>1</mn></mrow><mn>2</mn></msubsup><mi>σ</mi><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">式中, <image id="117" type="formula" href="images/JSJZ201904036_11700.jpg" display="inline" placement="inline"><alt></alt></image>代表的是视频图像的旋转角度。在等待处理的视频图像<i>f</i><sub>1</sub> (<i>x</i>, <i>y</i>) 的特征点集合<i>P</i><sub><i>f</i><sub>1</sub></sub>中找到与等待处理的视频图像<i>f</i><sub>2</sub> (<i>x</i>, <i>y</i>) 中特征点<i>q</i><sub><i>j</i></sub>相对应的特征点<i>p</i>。当特征点<i>q</i><sub><i>j</i></sub>与<i>p</i>满足下式时, 得到正确的匹配点, 完成特征点对齐度的优化</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mi>Ρ</mi><mi>A</mi><mi>Μ</mi><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>&gt;</mo><mi>Τ</mi><msub><mrow></mrow><mi>a</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">式中, <i>T</i><sub><i>a</i></sub>为阈值。</p>
                </div>
                <h3 id="56" name="56" class="anchor-tag"><b>3 特征点对齐度优化方法</b></h3>
                <h4 class="anchor-tag" id="57" name="57"><b>3.1 基于SURF算法的特征点提取方法</b></h4>
                <div class="p1">
                    <p id="58">在高斯金字塔构建的尺度空间的基础上采用<i>SURF</i>算法对视频图像区域形状特征点进行检测, 通过盒式滤波器构建<i>Hessian</i>矩阵, 采用<i>Hessian</i>矩阵提取视频图像区域形状特征点<citation id="109" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="59">设I (x, y) 代表的是视频图像中尺度为σ的点, 该点处<i>Hessian</i>矩阵的表达式为</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo></mtd><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo></mtd><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>y</mi><mi>y</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">式中, L<sub>xx</sub> (x, y, σ) 、L<sub>xy</sub> (x, y, σ) 、L<sub>yy</sub> (x, y, σ) 代表的是视频图像I (x, y) 与高斯二阶偏导数∂<sup>2</sup>/∂x<sup>2</sup>G (x, y, σ) 、∂<sup>2</sup>/∂x∂yG (x, y, σ) 、∂<sup>2</sup>/∂y<sup>2</sup>G (x, y, σ) 在点 (x, y) 处的卷积。其中, G (x, y, σ) 代表的是二维高斯函数, 表达式为</p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mtext>π</mtext><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>e</mi><msup><mrow></mrow><mrow><mo>-</mo><mo stretchy="false"> (</mo><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>y</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo><mo>/</mo><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63">对盒式滤波器的大小进行更改, 将其变为尺寸不同的视频图像金字塔, 尺寸不同的滤波和视频图像的卷积分别用D<sub>xx</sub>、D<sub>xy</sub>、D<sub>yy</sub>表示, 通过积分视频图像加快卷积运算, 得到<i>Hessian</i>矩阵行列式Det (H) 的表达式</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mi>e</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>Η</mi><mo stretchy="false">) </mo><mo>=</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msub><mi>D</mi><msub><mrow></mrow><mrow><mi>y</mi><mi>y</mi></mrow></msub><mo>-</mo><mo stretchy="false"> (</mo><mi>ω</mi><mi>D</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">式中, ω代表的是补偿参数, 当参数在区间[2, 4]内取值时, 选取的特征点精准度较高<citation id="110" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。在<i>Hessian</i>矩阵行列式内进行非极大值抑制, 选取比其它邻域内点的值都小或都大的点作为视频图像的特征点。</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66"><b>3.2 稀疏降维</b></h4>
                <div class="p1">
                    <p id="67">视频图像区域形状特征点对齐度优化方法通过SIFT算法的生成描述符参数方法和分配方向参数方法分别生成视频图像的特征点描述符参数和特征点方向参数, 对提取得到的特征点进行降维处理。</p>
                </div>
                <div class="p1">
                    <p id="68">设<i>K</i>代表的是视频图像的特征点描述符参数向量;<i>R</i><sup>128</sup>空间中的列向量可以用参数向量<i>K</i>进行表示。视频图像区域形状特征点对齐度优化方法将小波变换基矩阵<i>ψ</i>作为规范正交基, 列向量用向量{<i>ψ</i><sub><i>i</i></sub>}<mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mn>1</mn><mn>2</mn><mn>8</mn></mrow></msubsup></mrow></math></mathml>进行表示。在小波基变换矩阵<i>ψ</i>的基础上对描述符参数向量<i>K</i>进行表示, 将其表示为<i>X</i>, <i>X</i>代表的是稀疏的128维列向量, 其表达式为</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><mo>=</mo><mi>Κ</mi><mi>ψ</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71">通过式 (13) 可知, 在<i>ψ</i>域描述符参数列向量<i>K</i>的其它表示形式可以用<i>X</i>代替。在以上变换域中, 列向量<i>X</i>为稀疏的, 消除了列向量<i>K</i>中存在的冗余, 通过小波基变换去除系数小的参数, 保留系数大的参数。</p>
                </div>
                <div class="p1">
                    <p id="72">如果在小波正交基<i>ψ</i>下向量<i>X</i>∈<i>R</i><sup>128</sup>为稀疏的, 在<i>ψ</i>域稀疏向量<i>K</i>的逼近或等价表示为<i>K</i>=<i>ψ</i><sup><i>T</i></sup><i>X</i>, 设ϕ∈<i>R</i><sup>32×128</sup>代表的是随机投影矩阵, 为32×128维;<i>Y</i>代表的是测量向量, 通过在随机投影矩阵ϕ上投影稀疏信号<i>X</i>得到, 测量向量<i>Y</i>的表达式为</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Y</mi><mo>=</mo><mtext>ϕ</mtext><mi>X</mi><mo>=</mo><mtext>ϕ</mtext><mi>ψ</mi><mi>Κ</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">式中, ϕ代表的是随机的32×128维的投影矩阵;<i>X</i>代表的是128维的稀疏列向量;<i>ψ</i>代表的是小波正交变换的128×128维的基矩阵;<i>K</i>代表的是特征点描述符的128维的列向量。</p>
                </div>
                <div class="p1">
                    <p id="75">128维的<i>K</i>列向量降到32维受随机投影矩阵ϕ的影响。设<i>Θ</i>代表的是列向量<i>X</i>进行稀疏变换的条件, 下式为有限等距约束</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>1</mn><mo>-</mo><mi>ε</mi><mo>≤</mo><mrow><mo>|</mo><mrow><mi>Θ</mi><mi>Κ</mi></mrow><mo>|</mo></mrow><mo>/</mo><mrow><mo>|</mo><mi>Κ</mi><mo>|</mo></mrow><mo>≤</mo><mn>1</mn><mo>+</mo><mi>ε</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">式中, <i>ε</i>代表的是常数。选择高度不相关的ϕ和<i>ψ</i>可以保证列向量<i>K</i>进行稀疏变化, 在变换条件<i>Θ</i>满足式 (15) 时确定小波正交变换基<i>ψ</i>, 利用随机投影矩阵ϕ和小波正交变换基<i>ψ</i>对特征点描述符向量进行降维处理, 从128维降到32维。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78"><b>3.3 特征点对齐度优化</b></h4>
                <div class="p1">
                    <p id="79">通过双向匹配方法在相似性度量算法的基础上对降维处理后的视频图像区域形状特征点进行对齐度优化处理。</p>
                </div>
                <div class="p1">
                    <p id="80">将视频图像甲和视频图像乙作为目标优化图像对。设U<sub>i</sub>代表的是视频图像甲中存在的特征点描述符;V<sub>j</sub>代表的是视频图像乙中存在的特征点描述符;d (U<sub>i</sub>, V<sub>j</sub>) 代表的是视频图像甲和视频图像乙中特征点之间的距离相似度</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo stretchy="false"> (</mo><mi>U</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>V</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mrow><mn>3</mn><mn>2</mn></mrow></munderover><mo stretchy="false">|</mo></mstyle><mi>x</mi><msub><mrow></mrow><mi>m</mi></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">|</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">式中, x<sub>m</sub>代表的是视频图像甲中存在的特征点描述符的元素;y<sub>m</sub>代表的是视频图像乙中存在的特征点描述符元素。</p>
                </div>
                <div class="p1">
                    <p id="83">采用基于双向匹配的相似度度量算法对视频区域形状特征点对齐度进行优化时, 将视频图像甲中的特征点作为视频图像乙的参考点U<sub>i</sub>, 通过式 (16) 对视频图像乙中的特征点与视频图像甲中特征点之间距离的相似度进行计算, 根据计算结果得到最近邻特征点V<sub>1j</sub>以及次最近邻特征点V<sub>2j</sub>。当V<sub>1j</sub>和V<sub>2j</sub>满足式 (17) 时, 最近邻特征点V<sub>1j</sub>为视频图像甲中参考点U<sub>i</sub>的匹配点, 同理, 得到视频图像甲中特征点的匹配点对集A。再以视频图像乙中存在的特征点作为视频图像甲中特征点的参考点V<sub>i</sub>, 通过式 (16) 对视频图像甲中的特征点与视频图像甲中特征点之间距离的相似度进行计算, 根据计算结果得到最近邻特征点U<sub>1j</sub>以及次最近邻特征点U<sub>2j</sub>。当U<sub>1j</sub>、U<sub>2j</sub>满足式 (17) 时, 最近邻特征点U<sub>1j</sub>为视频图像乙中参考点V<sub>i</sub>的匹配点。同理, 得到视频图像乙中特征点的匹配点对集B。当匹配点对集A、B中的特征点完全相同时, 得到有效的匹配点对, 完成特征点对齐度的优化。</p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo stretchy="false"> (</mo><mi>U</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>V</mi><msub><mrow></mrow><mrow><mn>1</mn><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>/</mo><mi>d</mi><mo stretchy="false"> (</mo><mi>U</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>V</mi><msub><mrow></mrow><mrow><mn>2</mn><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>&lt;</mo><mi>Τ</mi><msub><mrow></mrow><mi>h</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="85">式中, d (U<sub>i</sub>, V<sub>1j</sub>) 代表的是视频图像甲中存在的特征点与视频图像乙中存在特征点的最近邻特征点距离相似度;d (U<sub>i</sub>, V<sub>2j</sub>) 代表的是视频图像甲中存在的特征点与视频图像乙中存在特征点的次最近邻特征点距离相似度;T<sub>h</sub>为设置的阈值。</p>
                </div>
                <h3 id="86" name="86" class="anchor-tag"><b>4 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="87">为了验证视频图像区域形状特征点对齐度优化方法的整体有效性, 需要对视频图像区域形状特征点对齐度优化方法进行测试, 本次测试的实验平台为<i>Matlab</i>, 显存容量为5<i>GB</i>、内存容量为8<i>GB</i>。<i>ω</i>代表的是补偿参数, 当参数在区间[2, 4]内取值时, 选取的特征点准确度较高。分别采用视频图像区域形状特征点对齐度优化方法、基于<i>ORB</i>的特征点对齐度优化方法、基于<i>RANSAC</i>的特征点对齐度优化方法通过补偿参数进行测试, 根据测试结果对比三种不同方法提取特征点的准确度, 测试结果如表1所示。</p>
                </div>
                <div class="area_img" id="88">
                    <p class="img_tit"><b>表1 三种不同方法的补偿参数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="88" border="1"><tr><td rowspan="2"><br />DD</td><td colspan="3"><br />W</td></tr><tr><td><br />SP</td><td>OR</td><td>RA</td></tr><tr><td><br />1</td><td>2.364</td><td>2.517</td><td>1.055</td></tr><tr><td><br />2</td><td>3.527</td><td>1.924</td><td>3.254</td></tr><tr><td><br />3</td><td>2.067</td><td>1.527</td><td>3.116</td></tr><tr><td><br />4</td><td>3.021</td><td>4.319</td><td>4.281</td></tr><tr><td><br />5</td><td>3.657</td><td>1.958</td><td>4.024</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="89">式中, W代表的是补偿参数;SP代表的是视频图像区域形状特征点对齐度优化方法;OR代表的是基于ORB的特征点对齐度优化方法;RA代表的是基于RANSAC的特征点对齐度优化方法;DD代表的是三种不同方法的迭代次数。</p>
                </div>
                <div class="p1">
                    <p id="90">分析表1中的数据可知, 采用视频图像区域形状特征点对齐度优化方法进行测试时, 得到的补偿参数均在区间[2, 4]内, 概率为100%;采用基于ORB的特征点对齐度优化方法进行测试时, 得到的补偿参数中有一个在区间[2, 4]内, 概率为20%;采用基于RANSAC的特征点对齐度优化方法进行测试时, 得到的补偿参数中有两个在区间[2, 4]内, 概率为40%。当补偿参数在区间[2, 4]内取值时, 特征点提取的准确度较高, 对比三种不同方法的测试结果可知, 视频图像区域形状特征点对齐度优化方法提取特征点的准确度较高。</p>
                </div>
                <div class="p1">
                    <p id="91">为了进一步验证视频图像区域形状特征点对齐度优化方法的整体有效性, 通过两幅图像中特征点对坐标的均方根误差RMSE验证视频图像区域形状特征点对齐度优化方法 (方法1) 、基于ORB的特征点对齐度优化方法 (方法2) 、基于RANSAC的特征点对齐度优化方法 (方法3) 的对齐度优化效果, 测试结果如图1所示。均方根误差越小特征点对齐度优化的效果越好;均方根误差越大特征点对齐度优化的效果越差, 均方根误差的计算公式为</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>Μ</mi><mi>S</mi><mi>E</mi><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mrow><mo>|</mo><mrow><mo stretchy="false"> (</mo><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">式中, (<i>x</i>′<sub><i>i</i></sub>, <i>y</i>′<sub><i>i</i></sub>) 代表的是参考视频图像中的特征点坐标; (<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>) 代表的是等待处理的视频图像中的特征点坐标;<i>f</i>代表的是变换关系;<i>n</i>代表的是特征点的总数。</p>
                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201904036_094.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">
                                    <img alt="图1 三种不同方法的均方根误差对比" src="Detail/GetImg?filename=images/JSJZ201904036_094.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                                </a>
                                <p class="img_tit"><b>图1 三种不同方法的均方根误差对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201904036_094.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="95">图<b>1 (a</b>) 为视频图像区域形状特征点对齐度优化方法的测试结果, 分析图<b>1 (a</b>) 可知, 采用视频图像区域形状特征点对齐度优化方法得到的特征点对坐标的均方根误差均在<b>0.3</b>以下;图<b>1 (b</b>) 为基于<b>ORB</b>的特征点对齐度优化方法的测试结果, 图<b>1 (c</b>) 为基于<b>RANSAC</b>的特征点对齐度优化方法的测试结果, 分析图<b>1 (b</b>) 和图<b>1 (c</b>) 可知, 采用以上两种方法得到的特征点对坐标的均方根误差分别高达<b>0.7</b>和<b>0.8</b>。对比三种不同方法的测试结果可知, 视频图像区域形状特征点对齐度优化方法得到的特征点对坐标的均方根误差小, 对特征点对齐度优化效果好。</p>
                </div>
                <h3 id="96" name="96" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="97">图像中的特征点匹配是图像配准的基础, 对特征点对齐度进行优化, 可准确的完成图像的配准。当前特征点对齐度优化方法不能准确的提取图像中的特征点、计算得到的特征点对坐标的均方跟误差高。提出一种视频图像区域形状特征点对齐度优化方法, 可准确的提取出图像中的特征点, 特征点对齐度的优化效果好, 为图像配准技术的发展奠定了基础。取得如下成果</p>
                </div>
                <div class="p1">
                    <p id="98"><b>1</b>) 本文方法的测试结果可知, 采用视频图像区域形状特征点对齐度优化方法得到的特征点对坐标的均方根误差均在<b>0.3</b>以下;符合应用要求。</p>
                </div>
                <div class="p1">
                    <p id="99"><b>2</b>) 对本文方法进行测试时, 得到的补偿参数均在区间[<b>2, 4</b>]内, 概率为<b>100</b>%, 取得较好成果。</p>
                </div>
                <div class="p1">
                    <p id="100"><b>3</b>) 但是, 本文方法在图像模糊的前提下, 无法准确获取特征点, 影响后期应用, 这是需要进一步解决的问题。</p>
                </div>
                <div class="area_img" id="111">
                                <img alt="" src="Detail/GetImg?filename=images/JSJZ201904036_11100.jpg&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
                            <p class="img_tit"></p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201710050&amp;v=MTc3NjNCZExHNEg5Yk5yNDlBWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6Z1U3dkJMejc=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[1]</b> 曹鹏, 宗文婷.运动员膝关节软骨挫伤图像特征点匹配仿真[J].计算机仿真, 2017, 34 (10) :225-228.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201712034&amp;v=MTYyNzQ5R1lJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emdVN3ZCTHo3QmQ3RzRIOWJOclk=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[2]</b> 孙增友, 段玉帅, 李亚.基于中心环绕滤波器检测的图像特征点匹配算法[J].计算机应用, 2017, 37 (12) :3547-3553.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201716030&amp;v=Mjg0NDZHNEg5Yk5xWTlHWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6Z1U3dkJMejdNYWI=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[3]</b> 董本志, 龙建勇, 景维鹏.POKD-tree:一种有效的SIFT图像特征点匹配方法[J].计算机工程与应用, 2017, 53 (16) :182-186.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201603013&amp;v=MzA4MjBGckNVUjdxZlp1Wm1GeXpnVTd2Qk1qWFNaTEc0SDlmTXJJOUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[4]</b> 张勇, 王志锋, 马文.基于改进SIFT特征点匹配的图像拼接算法研究[J].微电子学与计算机, 2016, 33 (3) :60-64.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201602009&amp;v=MzIzMTlHRnJDVVI3cWZadVptRnl6Z1U3dkJJVGZDZDdHNEg5Zk1yWTlGYllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[5]</b> 戴雪梅, 郎朗, 陈孟元.基于改进ORB的图像特征点匹配研究[J].电子测量与仪器学报, 2016, 30 (2) :233-240.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201607018&amp;v=MDI5MDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnl6Z1U3dkJOaWZZWkxHNEg5Zk1xSTlFYklRS0RIODQ=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[6]</b> 马丽丽, 等.基于RANSAC的特征点匹配算法[J].计算机工程与设计, 2016, 37 (7) :1794-1797.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YNDZ201704007&amp;v=MTU2MTc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emdVN3ZCUENQUGRMRzRIOWJNcTQ5Rlk=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[7]</b> 张勇, 耿国华.基于条件数约束的秦俑图像特征点匹配[J].云南大学学报:自然科学版, 2017, 39 (4) :547-553.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201612027&amp;v=MTU5NTVnVTd2QlBEelRiTEc0SDlmTnJZOUhZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXo=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[8]</b> 朱力强, 等.基于特征点集距离描述的裂缝图像匹配算法研究[J].仪器仪表学报, 2016, 37 (12) :2851-2858.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201609010&amp;v=MjE0ODJyZmJMRzRIOWZNcG85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emdVN3ZCUHk=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[9]</b> 陈天华, 王福龙.实时鲁棒的特征点匹配算法[J].中国图象图形学报, 2016, 21 (9) :1213-1220.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201612078&amp;v=Mjg5NzlCTHo3U1pMRzRIOWZOclk5Q2JJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5emdVN3Y=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">

                                <b>[10]</b> 邵春艳, 丁庆海, 罗海波.基于空间纹理相似性的图像角点特征匹配算法[J].计算机应用研究, 2016, 33 (12) :3868-3871.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201904036" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201904036&amp;v=MjY0NzM0OUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeXpnVTd2T0x6N0JkTEc0SDlqTXE=&amp;uid=WEEvREdxOWJmbC9oM1NjYkZCcDMwV0J4bGdLbWpqYS9tZVBuZ3FmMU1ESmg=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
