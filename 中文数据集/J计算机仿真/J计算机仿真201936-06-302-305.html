<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141007009947500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201906062%26RESULT%3d1%26SIGN%3djtIaBRhnZeBrQQIrpOM4AMsfJ5k%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201906062&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201906062&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201906062&amp;v=MTY0NzR6cXFCdEdGckNVUjdxZlp1Wm5GeTdsV3J6S0x6N0JkTEc0SDlqTXFZOURab1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;2 机器人仿生视觉路标多模式匹配定位方法&lt;/b&gt; "><b>2 机器人仿生视觉路标多模式匹配定位方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#32" data-title="&lt;b&gt;2.1 基于路标分层匹配的航向姿态信息校正&lt;/b&gt;"><b>2.1 基于路标分层匹配的航向姿态信息校正</b></a></li>
                                                <li><a href="#44" data-title="&lt;b&gt;2.2 基于稳定姿态输出的路标匹配定位&lt;/b&gt;"><b>2.2 基于稳定姿态输出的路标匹配定位</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#53" data-title="&lt;b&gt;3 实验与仿真证明&lt;/b&gt; "><b>3 实验与仿真证明</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#66" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#56" data-title="&lt;b&gt;表1 不同方法定位运行时间对比&lt;/b&gt;"><b>表1 不同方法定位运行时间对比</b></a></li>
                                                <li><a href="#61" data-title="&lt;b&gt;图1 不同方法定位准确度对比&lt;/b&gt;"><b>图1 不同方法定位准确度对比</b></a></li>
                                                <li><a href="#64" data-title="&lt;b&gt;表2 不同方法定位成本消耗对比&lt;/b&gt;"><b>表2 不同方法定位成本消耗对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="75">


                                    <a id="bibliography_1" title=" 王映知, 周翕, 王永, 等.并联机器人运动目标精确优化定位仿真研究[J].计算机仿真, 2017, 34 (10) :320-324." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201710071&amp;v=MDUzNTQ5Q1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N2xXcnpOTHo3QmRMRzRIOWJOcjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         王映知, 周翕, 王永, 等.并联机器人运动目标精确优化定位仿真研究[J].计算机仿真, 2017, 34 (10) :320-324.
                                    </a>
                                </li>
                                <li id="77">


                                    <a id="bibliography_2" title=" 张智, 张磊, 苏丽, 等.基于人工离线特征库的室内机器人双目定位[J].哈尔滨工程大学学报, 2017, 38 (12) :1906-1914." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBG201712014&amp;v=MzEyNzdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N2xXcnpOTFNqSmFiRzRIOWJOclk5RVk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         张智, 张磊, 苏丽, 等.基于人工离线特征库的室内机器人双目定位[J].哈尔滨工程大学学报, 2017, 38 (12) :1906-1914.
                                    </a>
                                </li>
                                <li id="79">


                                    <a id="bibliography_3" title=" 李珣, 刘丽, 洪良, 等.移动机器人室内无源RFID定位方法及实现[J].计算机工程与应用, 2017, 53 (16) :230-236." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201716039&amp;v=MjM2NzlHRnJDVVI3cWZadVpuRnk3bFdyek5MejdNYWJHNEg5Yk5xWTlHYllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         李珣, 刘丽, 洪良, 等.移动机器人室内无源RFID定位方法及实现[J].计算机工程与应用, 2017, 53 (16) :230-236.
                                    </a>
                                </li>
                                <li id="81">


                                    <a id="bibliography_4" title=" 张涛, 马磊, 梅玲玉.基于单目视觉的仓储物流机器人定位方法[J].计算机应用, 2017, 37 (9) :2491-2495." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201709012&amp;v=MDM2OTE0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeTdsV3J6Tkx6N0JkN0c0SDliTXBvOUVab1FLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         张涛, 马磊, 梅玲玉.基于单目视觉的仓储物流机器人定位方法[J].计算机应用, 2017, 37 (9) :2491-2495.
                                    </a>
                                </li>
                                <li id="83">


                                    <a id="bibliography_5" title=" 陈英.工业机器人交流伺服驱动系统研究[J].电子设计工程, 2017, 25 (16) :80-83." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201716019&amp;v=MDAxMTJGeTdsV3J6TklqclBkTEc0SDliTnFZOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm4=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         陈英.工业机器人交流伺服驱动系统研究[J].电子设计工程, 2017, 25 (16) :80-83.
                                    </a>
                                </li>
                                <li id="85">


                                    <a id="bibliography_6" title=" 冯晟, 吴成东, 张云洲.基于改进APIT的移动机器人动态定位[J].北京邮电大学学报, 2016 (5) :178-182." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJYD201605014&amp;v=MDcwOTJxbzlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnk3bFdyek5KeWZTYXJHNEg5Zk0=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         冯晟, 吴成东, 张云洲.基于改进APIT的移动机器人动态定位[J].北京邮电大学学报, 2016 (5) :178-182.
                                    </a>
                                </li>
                                <li id="87">


                                    <a id="bibliography_7" title=" 温熙, 郭杭.室内移动机器人自定位方法[J].测绘科学, 2016, 41 (6) :97-101." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHKD201606021&amp;v=MDcxNDJYQWFyRzRIOWZNcVk5SFpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N2xXcnpOSmk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         温熙, 郭杭.室内移动机器人自定位方法[J].测绘科学, 2016, 41 (6) :97-101.
                                    </a>
                                </li>
                                <li id="89">


                                    <a id="bibliography_8" title=" 李朕阳, 郎朗, 陈孟元.基于SR-CKF的相对方位多机器人协同定位算法[J].电子测量与仪器学报, 2016, 30 (7) :1107-1113." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201607021&amp;v=Mjk1NzQ3bFdyek5JVGZDZDdHNEg5Zk1xSTlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         李朕阳, 郎朗, 陈孟元.基于SR-CKF的相对方位多机器人协同定位算法[J].电子测量与仪器学报, 2016, 30 (7) :1107-1113.
                                    </a>
                                </li>
                                <li id="91">


                                    <a id="bibliography_9" title=" 任红格, 刘伟民, 李福进.一种记忆可修剪型仿生机器人的速度跟踪算法研究[J].现代电子技术, 2017, 40 (15) :149-153." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201715040&amp;v=MTQ3MDVMRzRIOWJOcW85QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N2xXcnpOUFNuUFo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         任红格, 刘伟民, 李福进.一种记忆可修剪型仿生机器人的速度跟踪算法研究[J].现代电子技术, 2017, 40 (15) :149-153.
                                    </a>
                                </li>
                                <li id="93">


                                    <a id="bibliography_10" title=" 林辉灿, 吕强, 王国胜, 等.基于VSLAM的自主移动机器人三维同时定位与地图构建[J].计算机应用, 2017, 37 (10) :2884-2887." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201710027&amp;v=MTY2Mzc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N2xXcnpOTHo3QmQ3RzRIOWJOcjQ5SFk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         林辉灿, 吕强, 王国胜, 等.基于VSLAM的自主移动机器人三维同时定位与地图构建[J].计算机应用, 2017, 37 (10) :2884-2887.
                                    </a>
                                </li>
                                <li id="95">


                                    <a id="bibliography_11" title=" 陈晓飞, 凌有铸, 陈孟元.WSNs环境下基于高斯混合容积卡尔曼滤波的移动机器人定位算法?[J].传感技术学报, 2017, 30 (1) :133-138." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGJS201701024&amp;v=MDgwMzh6TkppckJmYkc0SDliTXJvOUhZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeTdsV3I=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         陈晓飞, 凌有铸, 陈孟元.WSNs环境下基于高斯混合容积卡尔曼滤波的移动机器人定位算法?[J].传感技术学报, 2017, 30 (1) :133-138.
                                    </a>
                                </li>
                                <li id="97">


                                    <a id="bibliography_12" title=" 黄显良, 郁建芳, 戚浩, 等.安徽霍山窗中小地震活动与精定位研究[J].地震工程学报, 2016, 38 (2) :236-241." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZBDZ201602010&amp;v=MjUxMzZXcnpOUHkvUGRMRzRIOWZNclk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N2w=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         黄显良, 郁建芳, 戚浩, 等.安徽霍山窗中小地震活动与精定位研究[J].地震工程学报, 2016, 38 (2) :236-241.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(06),302-305             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于机器人仿生视觉路标多模式匹配定位仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%95%E5%A5%87%E6%96%87&amp;code=11597181&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">何奇文</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E6%B1%A0%E5%AD%A6%E9%99%A2%E7%89%A9%E7%90%86%E4%B8%8E%E6%9C%BA%E7%94%B5%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0021064&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河池学院物理与机电工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对传统机器人仿生视觉路标多模式匹配定位过程中, 普遍存在着定位运行时间较长、准确度较低、成本消耗较大等问题。提出一种新型机器人仿生视觉路标多模式匹配定位方法。通过对机器人仿生视觉路标进行分析, 同时考虑到机器人定位时的实际方向与视觉路标指示的方向存在一定的偏差, 对方向偏差进一步修正, 得到当前位置较为准确的机器人姿态信息;采用双目视觉传感器采集路标图像中的匹配点对, 获取视觉路标图像三维坐标, 构建双目立体视觉定位模型, 根据该模型获得机器人与路标的相对位置关系, 实现机器人视觉路标多模式匹配定位。实验结果表明, 所提方法定位运行时间较短、准确度较高、成本消耗较低。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%BB%BF%E7%94%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器人仿生;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E8%A7%89%E8%B7%AF%E6%A0%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">视觉路标;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多模式匹配;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E8%A7%89%E5%AE%9A%E4%BD%8D%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">视觉定位模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E5%9D%90%E6%A0%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维坐标;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%81%8F%E5%B7%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">偏差;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    何奇文 (1973-) , 男 (汉族) , 湖北蕲春人, 硕士, 副教授, 高级工程师, 主要研究方向:嵌入式系统开发与应用研究以及电子信息类专业建设研究等方面工作。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-26</p>

            </div>
                    <h1><b>Research on Multi-pattern Matching Positioning Simulation Based on Robot Bionic Vision Road Sign</b></h1>
                    <h2>
                    <span>HE Qi-wen</span>
            </h2>
                    <h2>
                    <span>College of Physics and Mechanical and Electronic Engineering, Hechi University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Due to long running time, low accuracy and high cost in the traditional multi-pattern matching and positioning of robot bionic visual guidepost, this paper puts forward a new method of multi-pattern matching and positioning for robot bionic visual guidepost. Based on the analysis of robot bionic visual guidepost and the consideration for the deviation between the actual direction of the robot and the direction indicated by visual guidepost, the deviation was further corrected to obtain the more accurate attitude information of robot at the current position. After that, the binocular vision sensor was used to collect the matching pairs in guidepost image, so as to obtain the three-dimensional coordinate of visual guidepost image. Finally, the binocular stereo vision positioning model was built. According to this model, the relative position relationship between robot and guidepost was obtained. Thus, the multi-pattern matching positioning of robot vision guidepost was achieved. Simulation results show that the proposed method has shorter operation time, higher accuracy and lower cost during the location.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Robot%20bionics&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Robot bionics;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Visual%20guidepost&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Visual guidepost;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-pattern%20matching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multi-pattern matching;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Visual%20positioning%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Visual positioning model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Three-dimensional%20coordinate&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Three-dimensional coordinate;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deviation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deviation;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-26</p>
                            </div>


        <!--brief start-->
                        <h3 id="27" name="27" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="28">机器人作为高科技发展的产物, 已经逐渐的走进人们的生活和工作中。定位导航是智能机器人最基本、最重要的基础功能之一, 这要求机器人对其邻近区域有较强的环境理解能力。近几年, 视觉传感器因其能精确感知环境信息及合理成本而受到了广泛关注, 很多视觉定位方法均采用人工设定路标的方式, 并取得了很多好的成果<citation id="99" type="reference"><link href="75" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。但是在一些给定场合中, 并不适合放置人工路标, 而且场景复杂, 要求机器人具备较强的环境理解能力, 选择自然场景特征作为机器人导航定位是一种较好的方法。基于自然路标进行机器人自主导航的方法有很多, 但多数使用场景中具有显著特征的区域作为路标, 并获取路标结构中的一些点特征作为导航信息, 这种方法多数对机器人移动环境有着较好要求, 无法在复杂环境中应用。针对这种情况, 能够提出一种具有较高定位精度的方法成为当今社会亟待解决的问题<citation id="100" type="reference"><link href="81" rel="bibliography" /><link href="83" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="29">文献<citation id="101" type="reference">[<a class="sup">6</a>]</citation>提出一种基于改进APIT的机器人动态定位方法。该方法利用接收信号强度指标实现机器人测距, 采用改进的APIT算法来完成机器人动态定位, 并利用卡尔曼滤波对定位结果进行修正。该方法具有较好的定位精度, 但是定位时间过长。文献<citation id="102" type="reference">[<a class="sup">7</a>]</citation>提出一种基于Kinect传感器的室内移动机器人自定位方法。该方法利用Kinect传感器对机器人运动过程中连续的深度信息进行采集, 采用尺度不变特征变换方法匹配场景图像中的特征点对, 并根据随机抽样一致性方法去除错误匹配点, 利用传感器的深度信息将可用匹配点的二维坐标变换到相机坐标系下, 实现对机器人定位。该方法具有一定的可行性, 但是在定位过程中成本消耗过大。文献<citation id="103" type="reference">[<a class="sup">8</a>]</citation>提出一种基于SR-CKF的相对方位多机器人协同定位方法。该方法构建机器人运动方程和观测方程, 将机器人相对方位当作测量值, 得到多机器人协同定位模型, 完成定位。该方法定位运行时间较短, 但是定位过程中容易出现偏差, 造成定位准确度较低。</p>
                </div>
                <div class="p1">
                    <p id="30">针对上述问题, 提出一种基于双目视觉的机器人视觉路标匹配定位方法。实验结果表明, 所提方法定位运行时间较短、准确度较高、成本消耗较低。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>2 机器人仿生视觉路标多模式匹配定位方法</b></h3>
                <h4 class="anchor-tag" id="32" name="32"><b>2.1 基于路标分层匹配的航向姿态信息校正</b></h4>
                <div class="p1">
                    <p id="33">通过对机器人仿生视觉路标进行分析, 考虑到机器人定位时的实际方向和视觉路标指示的方向存在一定的偏差, 需要对较小的方向偏差进一步修正, 得到当前位置较为准确的机器人姿态信息, 具体过程如下:</p>
                </div>
                <div class="p1">
                    <p id="34">将机器人采集区域内的多个场景图像视为视觉路标, 提取场景图像中的显著特征并获取采集视觉路标过程中相机的方向和机体姿态, 用于创建机器人仿生视觉路标库。视觉路标图像全局特征信息和局部特征信息两者有各自的优点和不足之处, 将两者进行有效结合可以充分的发挥各自的优势, 利用视觉路标图像全局特征进行初步的过滤, 在此基础上, 使用快速鲁棒算子局部特征进行精确匹配。</p>
                </div>
                <div class="p1">
                    <p id="35">机器人与视觉路标位置越近, 投票分数会逐渐增加, 当超过视觉路标位置时, 投票分数会逐渐下降, 得票数最高者, 它所对应的路标位置信息上升和下降的趋势就越明显, 越容易判定和匹配峰值位置, 定位误差也就较小。</p>
                </div>
                <div class="p1">
                    <p id="36">机器人进行定位时的实际航向可能和视觉路标指示的方向存在一定的偏差, 需要对较小的方向偏差进行进一步修正, 机器人当前位置获得的新图像和视觉路标图像进行匹配后, 利用运动估计方法, 求出两幅图像之间的方向和姿态偏差。</p>
                </div>
                <div class="p1">
                    <p id="37">利用机器人双目相机对路标进行标定, 提取双目相机采集到的图像局部特征并与路标图像特征进行匹配, 结合最小二乘准则, 求解出本质矩阵, 然后对该矩阵进行奇异值分解:</p>
                </div>
                <div class="p1">
                    <p id="38" class="code-formula">
                        <mathml id="38"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo>=</mo><mi>U</mi><mstyle displaystyle="true"><mo>∑</mo><mi>V</mi></mstyle><msup><mrow></mrow><mi>Τ</mi></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="39">式中, <i>U</i>代表<i>m</i>×<i>m</i>阶酉矩阵;<i>V</i><sup><i>T</i></sup>代表<i>n</i>×<i>n</i>阶酉矩阵。根据2个路标图像之间本质矩阵和旋转矩阵之间的关系, 可获得2个路标图像之间旋转矩阵的求解公式:</p>
                </div>
                <div class="p1">
                    <p id="40" class="code-formula">
                        <mathml id="40"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>R</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mi>U</mi><mi>W</mi><msup><mrow></mrow><mi>Τ</mi></msup><mi>V</mi><msup><mrow></mrow><mi>Τ</mi></msup></mtd></mtr><mtr><mtd><mi>R</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mi>U</mi><mi>W</mi><mi>V</mi><msup><mrow></mrow><mi>Τ</mi></msup></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>W</mi><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>}</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="41">根据被测点前方必定处于相机前方的事实和相机位置之间的关系选取出一个<i>R</i>的正确解, 根据旋转矩阵<i>R</i>和姿态角之间的关系, 获取2个路标图像之间的3个姿态角的偏差:</p>
                </div>
                <div class="p1">
                    <p id="42" class="code-formula">
                        <mathml id="42"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mtext>Δ</mtext><mi>φ</mi><mo>=</mo><mi>arctan</mi><mo stretchy="false"> (</mo><mi>R</mi><mo stretchy="false"> (</mo><mn>2</mn><mo>, </mo><mn>3</mn><mo stretchy="false">) </mo><mo>/</mo><mi>R</mi><mo stretchy="false"> (</mo><mn>3</mn><mo>, </mo><mn>3</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext>Δ</mtext><mi>θ</mi><mo>=</mo><mi>arcsin</mi><mo stretchy="false"> (</mo><mi>R</mi><mo stretchy="false"> (</mo><mn>1</mn><mo>, </mo><mn>3</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext>Δ</mtext><mi>ψ</mi><mo>=</mo><mi>arctan</mi><mo stretchy="false"> (</mo><mi>R</mi><mo stretchy="false"> (</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo stretchy="false">) </mo><mo>/</mo><mi>R</mi><mo stretchy="false"> (</mo><mn>1</mn><mo>, </mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="43">式中, Δ<i>φ</i>、Δ<i>θ</i>、Δ<i>ψ</i>分别代表2个路标图像间的横滚角、俯仰角、方向角之差;结合路标已知方向和姿态, 则可获得当前位置较为准确的姿态信息, 通过确定姿态角的偏差, 可以对航向姿态信息进行校正, 通过校正后的姿态信息, 对路标进行匹配定位分析, 完成机器人仿生视觉路标的匹配定位。</p>
                </div>
                <h4 class="anchor-tag" id="44" name="44"><b>2.2 基于稳定姿态输出的路标匹配定位</b></h4>
                <div class="p1">
                    <p id="45">在融合机器人惯导和双目立体视觉理论基础上, 以2.1节得到的较为稳定的姿态输出为基础, 采集图像中的匹配点对, 获取视觉路标图像三维坐标, 构建双目立体视觉定位模型, 根据该模型获得机器人与路标的相对位置关系, 实现机器人视觉路标多模式匹配定位。具体过程如下:</p>
                </div>
                <div class="p1">
                    <p id="46">给定机器人双目视觉传感器获得的路标图像时, 假设能找到所对应的匹配点对, 则可确定视觉路标图像的三维坐标。假设, 机器人左视觉传感器的坐标系为<i>o</i><sub><i>l</i></sub>-<i>x</i><sub><i>l</i></sub><i>y</i><sub><i>l</i></sub><i>z</i><sub><i>l</i></sub>, 路标图像坐标系为<i>O</i><sub><i>l</i></sub>-<i>X</i><sub><i>l</i></sub><i>Y</i><sub><i>l</i></sub>, 有效焦距为<i>f</i><sub><i>l</i></sub>表示, 右视觉传感器的坐标系为<i>o</i><sub><i>r</i></sub>-<i>x</i><sub><i>r</i></sub><i>y</i><sub><i>r</i></sub><i>z</i><sub><i>r</i></sub>, 路标图像坐标系为<i>O</i><sub><i>r</i></sub>-<i>X</i><sub><i>r</i></sub><i>Y</i><sub><i>r</i></sub>, 有效焦距用<i>f</i><sub><i>r</i></sub>表示, 为了统一视觉传感器的坐标系, 把机器人左视觉传感器看作机器人坐标系原点, 利用下式给出, 其与右视觉传感器的坐标系之间的空间位置关系:</p>
                </div>
                <div class="p1">
                    <p id="47" class="code-formula">
                        <mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi><msub><mrow></mrow><mi>r</mi></msub></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mi>r</mi></msub></mtd></mtr><mtr><mtd><mi>z</mi><msub><mrow></mrow><mi>r</mi></msub></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mi>R</mi><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi><msub><mrow></mrow><mi>l</mi></msub></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mi>l</mi></msub></mtd></mtr><mtr><mtd><mi>z</mi><msub><mrow></mrow><mi>l</mi></msub></mtd></mtr></mtable><mo>]</mo></mrow><mo>+</mo><mi>Τ</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="48">式中, <i>R</i>和<i>T</i>分别为机器人右视觉传感器坐标系对应于机器人左视觉传感器坐标系的旋转矩阵和偏移向量;在实际情况下, 路标在机器人坐标系下的三维坐标表达式为:</p>
                </div>
                <div class="p1">
                    <p id="49" class="code-formula">
                        <mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>x</mi><mo>=</mo><mfrac><mrow><mi>z</mi><mi>X</mi><msub><mrow></mrow><mi>l</mi></msub></mrow><mrow><mi>f</mi><msub><mrow></mrow><mi>l</mi></msub></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>y</mi><mo>=</mo><mfrac><mrow><mi>z</mi><mi>Y</mi><msub><mrow></mrow><mi>l</mi></msub></mrow><mrow><mi>f</mi><msub><mrow></mrow><mi>l</mi></msub></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>z</mi><mo>=</mo><mfrac><mrow><mi>f</mi><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false"> (</mo><mi>f</mi><msub><mrow></mrow><mi>r</mi></msub><mi>t</mi><msub><mrow></mrow><mi>x</mi></msub><mo>-</mo><mi>X</mi><msub><mrow></mrow><mi>r</mi></msub><mi>t</mi><msub><mrow></mrow><mi>z</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>X</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msub><mrow></mrow><mn>7</mn></msub><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>8</mn></msub><mi>Y</mi><msub><mrow></mrow><mi>l</mi></msub><mo>+</mo><mi>f</mi><msub><mrow></mrow><mi>l</mi></msub><mi>r</mi><msub><mrow></mrow><mn>9</mn></msub><mo stretchy="false">) </mo><mo>-</mo><mi>f</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mi>X</mi><msub><mrow></mrow><mi>l</mi></msub><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub><mi>Y</mi><msub><mrow></mrow><mi>l</mi></msub><mo>+</mo><mi>f</mi><msub><mrow></mrow><mi>l</mi></msub><mi>r</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="50">由于机器人一般工作环境都较为平坦, 所以只需知道机器人二维位置坐标和路标坐标之间的角度, 则可以根据视觉路标的全局坐标, 来确定机器人全局坐标下的三维坐标:</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi><msub><mrow></mrow><mi>R</mi></msub></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mi>R</mi></msub></mtd></mtr><mtr><mtd><mi>θ</mi><msub><mrow></mrow><mi>R</mi></msub></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi><msub><mrow></mrow><mrow><mi>L</mi><mi>W</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mrow><mi>L</mi><mi>W</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>θ</mi><msub><mrow></mrow><mrow><mi>L</mi><mi>W</mi></mrow></msub></mtd></mtr></mtable><mo>]</mo></mrow><mspace width="0.25em" /><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>cos</mi><mspace width="0.25em" /><mi>θ</mi><msub><mrow></mrow><mi>R</mi></msub><mspace width="0.25em" /></mtd><mtd><mo>-</mo><mi>sin</mi><mspace width="0.25em" /><mi>θ</mi><msub><mrow></mrow><mi>R</mi></msub></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mi>sin</mi><mspace width="0.25em" /><mi>θ</mi><msub><mrow></mrow><mi>R</mi></msub></mtd><mtd><mi>cos</mi><mspace width="0.25em" /><mi>θ</mi><msub><mrow></mrow><mi>R</mi></msub></mtd><mtd><mn>0</mn><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mspace width="0.25em" /><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi><msub><mrow></mrow><mrow><mi>L</mi><mi>R</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mrow><mi>L</mi><mi>R</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>θ</mi><msub><mrow></mrow><mrow><mi>L</mi><mi>R</mi></mrow></msub></mtd></mtr></mtable><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">当机器人双目视野中出现多个路标时, 根据上述的方法对每个路标进行多模式匹配定位, 得到多个位置坐标, 在多个位置坐标基础上, 采用最小方差法, 进行筛选, 得到机器人的最终最优位置, 实现机器人视觉路标多模式匹配定位的最终目标。</p>
                </div>
                <h3 id="53" name="53" class="anchor-tag"><b>3 实验与仿真证明</b></h3>
                <div class="p1">
                    <p id="54">为了验证所提基于双目视觉的机器人视觉路标匹配定位方法的综合有效性, 需要进行一次仿真实验, 实验环境为:ntelCore5-1.6Hz 48G内存, 操作系统为Windows7, 将所提方法与基于改进APIT的机器人动态定位方法、基于SR-CKF的相对方位多机器人协同定位方法进行对比实验, 实验结果如下所示。</p>
                </div>
                <div class="p1">
                    <p id="55">将所提方法与基于改进APIT的机器人动态定位方法、基于SR-CKF的相对方位多机器人协同定位方法进行定位时间 (s) 对比实, 实验结果如表1所示, 表1中, 方法1代表所提方法;方法2代表基于改进APIT的机器人动态定位方法;方法3代表基于SR-CKF的相对方位多机器人协同定位方法。</p>
                </div>
                <div class="area_img" id="56">
                    <p class="img_tit"><b>表1 不同方法定位运行时间对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="56" border="1"><tr><td rowspan="2"><br />样本数量/个</td><td colspan="3"><br />定位运行时间/秒</td></tr><tr><td><br />方法1</td><td>方法2</td><td>方法3</td></tr><tr><td><br />10</td><td>6</td><td>13</td><td>42</td></tr><tr><td><br />20</td><td>12</td><td>16</td><td>57</td></tr><tr><td><br />30</td><td>18</td><td>24</td><td>79</td></tr><tr><td><br />40</td><td>21</td><td>33</td><td>102</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="57">分析表1可知, 随着样本数量的不断增加, 3种方法相应的定位时间也随之增加, 当样本数量从10个增加到40个时, 所提方法定位运行时间增加了15秒;基于改进APIT的机器人动态定位方法定位运行时间增加了20秒;基于SR-CKF的相对方位多机器人协同定位方法定位运行时间增加了60秒;通过数据可知, 本文方法具有较高的优势, 具体分析可知:</p>
                </div>
                <div class="p1">
                    <p id="58">样本数量为10个时, 所提方法定位运行时间与基于改进APIT的机器人动态定位方法和基于SR-CKF的相对方位多机器人协同定位方法定位运行时间之间分别相差7秒和36秒。</p>
                </div>
                <div class="p1">
                    <p id="59">样本数量为40个时, 所提方法定位运行时间与基于改进APIT的机器人动态定位方法和基于SR-CKF的相对方位多机器人协同定位方法定位运行时间之间分别相差12秒和81秒。</p>
                </div>
                <div class="p1">
                    <p id="60">将所提方法与基于改进APIT的机器人动态定位方法和基于SR-CKF的相对方位多机器人协同定位方法进行定位准确度 (%) 对比实验, 实验结果如图1所示。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201906062_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 不同方法定位准确度对比" src="Detail/GetImg?filename=images/JSJZ201906062_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 不同方法定位准确度对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201906062_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="62">分析图1可知, 随着样本数量的不断增加, 3种方法的定位准确度都有不同程度的降低。当样本数量从0个增加到200个时, 基于改进APIT的机器人动态定位方法定位准确度大约在35%～20%区间范围内发生浮动, 且变化幅度较为稳定, 当样本数量到达150个后定位时间急速下降;基于SR-CKF的相对方位多机器人协同定位方法定位准确度大约在55%～40%区间范围内发生浮动, 且波动有小幅变化;所提方法定位准确度大约在75%～70%区间范围内发生浮动, 且波动较为平缓;通过对比可知, 所提方法定位准确度最高, 优于其它两种方法, 具有较好的应用性能。</p>
                </div>
                <div class="p1">
                    <p id="63">将所提方法与基于改进APIT的机器人动态定位方法和基于SR-CKF的相对方位多机器人协同定位方法进行定位成本消耗 (元) 对比实验, 对比不同方法定位消耗的成本, 实验结果如表2所示, 表2中, 方法1代表所提方法;方法2代表基于改进APIT的机器人动态定位方法;方法3代表基于SR-CKF的相对方位多机器人协同定位方法。</p>
                </div>
                <div class="area_img" id="64">
                    <p class="img_tit"><b>表2 不同方法定位成本消耗对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="64" border="1"><tr><td rowspan="2"><br />样本数量/个</td><td colspan="3"><br />定位成本消耗/ (元) </td></tr><tr><td><br />方法1</td><td>方法2</td><td>方法3</td></tr><tr><td><br />15</td><td>12</td><td>32</td><td>87</td></tr><tr><td><br />25</td><td>25</td><td>68</td><td>134</td></tr><tr><td><br />35</td><td>38</td><td>89</td><td>175</td></tr><tr><td><br />45</td><td>46</td><td>106</td><td>197</td></tr><tr><td><br />55</td><td>66</td><td>144</td><td>222</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="65">分析表2可知, 随着样本数量的不断增加, 定位成本消耗也随着增加, 当样本数量为15个时, 所提方法定位成本消耗与基于改进APIT的机器人动态定位方法和基于SR-CKF的相对方位多机器人协同定位方法定位成本消耗之间分别相差20元和75元;当样本数量为35个时, 所提方法定位成本消耗与基于改进APIT的机器人动态定位方法和基于SR-CKF的相对方位多机器人协同定位方法定位成本消耗之间分别相差51元和137元;当样本数量为55个时, 所提方法定位成本消耗与基于改进APIT的机器人动态定位方法和基于SR-CKF的相对方位多机器人协同定位方法定位成本消耗之间分别相差78元和156元;通过对比可知, 所提方法定位成本消耗最低, 其次为基于改进APIT的机器人动态定位方法;基于SR-CKF的相对方位多机器人协同定位方法定位成本消耗最高, 证明了本文方法具有较高的实际应用性。</p>
                </div>
                <h3 id="66" name="66" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="67">针对传统的机器人仿生视觉路标多模式匹配定位方法中, 存在着各种问题。针对所存在的问题, 提出一种基于双目视觉的机器人视觉路标匹配定位方法。该方法利用路标图像全局特征和局部特征相结合进行匹配, 并利用运动估计法对视觉路标指示的方向的偏差进行修正, 在姿态偏差修正的基础上构建路标双目立体视觉定位模型, 实现机器人仿生视觉路标多模式匹配定位。该方法定位运行时间较短、成本消耗较低、准确度较高。适合广泛应用于各个领域。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="74" type="" href="images/JSJZ201906062_07400.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">何奇文</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="75">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201710071&amp;v=MDIwOTJGeTdsV3J6Tkx6N0JkTEc0SDliTnI0OUNaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm4=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 王映知, 周翕, 王永, 等.并联机器人运动目标精确优化定位仿真研究[J].计算机仿真, 2017, 34 (10) :320-324.
                            </a>
                        </p>
                        <p id="77">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBG201712014&amp;v=MjkxNDdmWnVabkZ5N2xXcnpOTFNqSmFiRzRIOWJOclk5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 张智, 张磊, 苏丽, 等.基于人工离线特征库的室内机器人双目定位[J].哈尔滨工程大学学报, 2017, 38 (12) :1906-1914.
                            </a>
                        </p>
                        <p id="79">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201716039&amp;v=MjgxMTlHRnJDVVI3cWZadVpuRnk3bFdyek5MejdNYWJHNEg5Yk5xWTlHYllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 李珣, 刘丽, 洪良, 等.移动机器人室内无源RFID定位方法及实现[J].计算机工程与应用, 2017, 53 (16) :230-236.
                            </a>
                        </p>
                        <p id="81">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201709012&amp;v=MTEwMDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N2xXcnpOTHo3QmQ3RzRIOWJNcG85RVpvUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 张涛, 马磊, 梅玲玉.基于单目视觉的仓储物流机器人定位方法[J].计算机应用, 2017, 37 (9) :2491-2495.
                            </a>
                        </p>
                        <p id="83">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201716019&amp;v=MDMwMTZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeTdsV3J6TklqclBkTEc0SDliTnFZOUU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 陈英.工业机器人交流伺服驱动系统研究[J].电子设计工程, 2017, 25 (16) :80-83.
                            </a>
                        </p>
                        <p id="85">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJYD201605014&amp;v=MjQxNzN5N2xXcnpOSnlmU2FyRzRIOWZNcW85RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 冯晟, 吴成东, 张云洲.基于改进APIT的移动机器人动态定位[J].北京邮电大学学报, 2016 (5) :178-182.
                            </a>
                        </p>
                        <p id="87">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHKD201606021&amp;v=MDM2MzE0TzN6cXFCdEdGckNVUjdxZlp1Wm5GeTdsV3J6TkppWEFhckc0SDlmTXFZOUhaWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 温熙, 郭杭.室内移动机器人自定位方法[J].测绘科学, 2016, 41 (6) :97-101.
                            </a>
                        </p>
                        <p id="89">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201607021&amp;v=MTMwNjRSN3FmWnVabkZ5N2xXcnpOSVRmQ2Q3RzRIOWZNcUk5SFpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 李朕阳, 郎朗, 陈孟元.基于SR-CKF的相对方位多机器人协同定位算法[J].电子测量与仪器学报, 2016, 30 (7) :1107-1113.
                            </a>
                        </p>
                        <p id="91">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201715040&amp;v=MjYyNjJDVVI3cWZadVpuRnk3bFdyek5QU25QWkxHNEg5Yk5xbzlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 任红格, 刘伟民, 李福进.一种记忆可修剪型仿生机器人的速度跟踪算法研究[J].现代电子技术, 2017, 40 (15) :149-153.
                            </a>
                        </p>
                        <p id="93">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201710027&amp;v=MjcyMTR6cXFCdEdGckNVUjdxZlp1Wm5GeTdsV3J6Tkx6N0JkN0c0SDliTnI0OUhZNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 林辉灿, 吕强, 王国胜, 等.基于VSLAM的自主移动机器人三维同时定位与地图构建[J].计算机应用, 2017, 37 (10) :2884-2887.
                            </a>
                        </p>
                        <p id="95">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGJS201701024&amp;v=MTM4MDJyQmZiRzRIOWJNcm85SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZ5N2xXcnpOSmk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 陈晓飞, 凌有铸, 陈孟元.WSNs环境下基于高斯混合容积卡尔曼滤波的移动机器人定位算法?[J].传感技术学报, 2017, 30 (1) :133-138.
                            </a>
                        </p>
                        <p id="97">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZBDZ201602010&amp;v=MzA5Njk5Zk1yWTlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRnk3bFdyek5QeS9QZExHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 黄显良, 郁建芳, 戚浩, 等.安徽霍山窗中小地震活动与精定位研究[J].地震工程学报, 2016, 38 (2) :236-241.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201906062" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201906062&amp;v=MTY0NzR6cXFCdEdGckNVUjdxZlp1Wm5GeTdsV3J6S0x6N0JkTEc0SDlqTXFZOURab1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V09TVFE2TFgybGV6bTlmY29MQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
