<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139253225756250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201910084%26RESULT%3d1%26SIGN%3dnQ5GZ9Nr7eDKcsw9Dc87ClE%252bH4E%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201910084&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201910084&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201910084&amp;v=MzA2OTJPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25WN3pMTHo3QmRMRzRIOWpOcjQ5TllJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;2 基于特征提取的图像邻域跟踪方法&lt;/b&gt; "><b>2 基于特征提取的图像邻域跟踪方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#34" data-title="&lt;b&gt;2.1 多帧图像的分块处理与匹配&lt;/b&gt;"><b>2.1 多帧图像的分块处理与匹配</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#50" data-title="&lt;b&gt;3 显著性加权最小二乘图像匹配跟踪方法&lt;/b&gt; "><b>3 显著性加权最小二乘图像匹配跟踪方法</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#64" data-title="&lt;b&gt;4 实验结果及分析&lt;/b&gt; "><b>4 实验结果及分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#82" data-title="&lt;b&gt;5 结论&lt;/b&gt; "><b>5 结论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#49" data-title="&lt;b&gt;图1 待匹配图像叠加分块示意图与去除冗余特征点示意图&lt;/b&gt;"><b>图1 待匹配图像叠加分块示意图与去除冗余特征点示意图</b></a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;表1 多帧视频图像序列信息&lt;/b&gt;"><b>表1 多帧视频图像序列信息</b></a></li>
                                                <li><a href="#69" data-title="&lt;b&gt;图2 多帧视频图像的邻域跟踪结果&lt;/b&gt;"><b>图2 多帧视频图像的邻域跟踪结果</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;表2 不同方法跟踪实验结果对比&lt;/b&gt;"><b>表2 不同方法跟踪实验结果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 王猛,翟东海,聂洪玉,等.邻域窗口权重变分的图像修复[J].中国图象图形学报,2018,20(8):1000-1007." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201508002&amp;v=MjEyODZxZlp1WnBGeS9uVjd6TFB5cmZiTEc0SDlUTXA0OUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         王猛,翟东海,聂洪玉,等.邻域窗口权重变分的图像修复[J].中国图象图形学报,2018,20(8):1000-1007.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 代蕾.基于视觉传达要素的电视画面优化设计方法研究[J].电视技术,2018,42(8):26-29+34." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSSS201808005&amp;v=MTAyMjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25WN3pMSVQ3WWZiRzRIOW5NcDQ5RllZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         代蕾.基于视觉传达要素的电视画面优化设计方法研究[J].电视技术,2018,42(8):26-29+34.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 王卓.基于视觉传达效果的三维图像虚拟重建[J].现代电子技术,2019,42(1):70-72." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201901015&amp;v=MjE3MzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkvblY3ekxQU25QWkxHNEg5ak1ybzlFWVk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         王卓.基于视觉传达效果的三维图像虚拟重建[J].现代电子技术,2019,42(1):70-72.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 魏本征,尹义龙.基于局部特征约束的TEM图像分割算法[J].数据采集与处理,2018,33(3):16-24." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJCJ201803002&amp;v=Mjg0NjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25WN3pMTmlmSVpMRzRIOW5Nckk5RlpvUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         魏本征,尹义龙.基于局部特征约束的TEM图像分割算法[J].数据采集与处理,2018,33(3):16-24.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 孙赫赫,尚晓清,王冲.基于区域对比的图像显著性检测方法[J].计算机工程与应用,2018,54(10):197-200,208." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201810031&amp;v=MDQ4NjZHNEg5bk5yNDlHWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkvblY3ekxMejdNYWI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         孙赫赫,尚晓清,王冲.基于区域对比的图像显著性检测方法[J].计算机工程与应用,2018,54(10):197-200,208.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 汪亚明.基于神经网络的图象序列特征点匹配[J].中国图象图形学报,2018,7(4):313-318." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB200204000&amp;v=MDMxNDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkvblY3ekxQeXJmYkxHNEh0UE1xNDlGWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         汪亚明.基于神经网络的图象序列特征点匹配[J].中国图象图形学报,2018,7(4):313-318.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 杨勇,闫钧华,井庆丰.融合图像显著性与特征点匹配的形变目标跟踪[J].中国图象图形学报,2018,23(3):86-100." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201803007&amp;v=MzE3OTN5L25WN3pMUHlyZmJMRzRIOW5Nckk5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         杨勇,闫钧华,井庆丰.融合图像显著性与特征点匹配的形变目标跟踪[J].中国图象图形学报,2018,23(3):86-100.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 温洪波.大型视频多帧图像信息处理系统设计[J].现代电子技术,2018,41(20):61-64." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201820014&amp;v=MTUyMDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkvblY3ekxQU25QWkxHNEg5bk9yNDlFWUlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         温洪波.大型视频多帧图像信息处理系统设计[J].现代电子技术,2018,41(20):61-64.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 陈守文,马姝婧,刘春昊,et al.三维图像特征点匹配与拼接[J].化工进展,2018,37(S1):228-233." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HGJZ2018S1032&amp;v=MTA4NzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9uVjd6TExTckJkTEc0SDltdnJvOUdab1E=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         陈守文,马姝婧,刘春昊,et al.三维图像特征点匹配与拼接[J].化工进展,2018,37(S1):228-233.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 师春艳.基于三维视觉的室内设计虚拟现实方法研究[J].现代电子技术,2018,41(5):78-82." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201805020&amp;v=MDI3NDdmWnVacEZ5L25WN3pMUFNuUFpMRzRIOW5NcW85SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         师春艳.基于三维视觉的室内设计虚拟现实方法研究[J].现代电子技术,2018,41(5):78-82.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 牛畅,黄银和,尹奎英.基于分块SURF特征提取的图像目标跟踪算法[J].激光与红外,2017,47(12):1541-1547." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGHW201712017&amp;v=MDE2NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9uVjd6TEx5ckRlYkc0SDliTnJZOUVZNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         牛畅,黄银和,尹奎英.基于分块SURF特征提取的图像目标跟踪算法[J].激光与红外,2017,47(12):1541-1547.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" >
                                        <b>[12]</b>
                                     杨勇,闫钧华,井庆丰.融合图像显著性与特征点匹配的形变目标跟踪[J].中国图象图形学报,2018,23(3):86-100.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(10),405-408             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于视觉传达的多帧视频图像邻域跟踪仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%86%89%E5%90%AF%E6%AD%A6&amp;code=35856316&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">冉启武</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%99%95%E8%A5%BF%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E7%94%B5%E6%B0%94%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1699848&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陕西理工大学电气工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在处理复杂多帧视频图像时,传统的基于SURF特征的图像邻域跟踪方法暴露出目标邻域精度不高、边界不够平滑且无法满足实时处理要求的情况。针对上述情况提出了一种基于视觉传达的多帧视频图像邻域跟踪方法。方法首先通过选取适当的叠加尺度,将邻域特征描述的向量与适当的叠加尺度进行完全叠加,完成去除冗余特征点和离散点处理,再对叠加区域中出现的目标给予权值,最后将权值与显著性加权最小二乘图像匹配方法结合完成多帧视频图像的邻域跟踪。实验表明:提出的方法不仅可以提高多帧视频图像的特征提取与匹配的精准率,而且降低了在匹配过程中出现的噪声问题,证明了上述方法相对于现有的邻域跟踪方法有很大的优越性,为下一步的多帧视频图像领域跟踪提供了精确的方法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%82%BB%E5%9F%9F%E8%B7%9F%E8%B8%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邻域跟踪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E8%B7%9F%E8%B8%AA%E6%96%B9%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像跟踪方法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B8%8E%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征提取与匹配;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    冉启武(1973-),男(汉族),陕西镇巴人,博士,讲师,研究方向:自动化技术,智能图像处理技术。&lt;image id="109" type="formula" href="images/JSJZ201910084_10900.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>陕西省教育厅(17JK0139);</span>
                    </p>
            </div>
                    <h1><b>Multi-frame Video Image Neighborhood Tracking Simulation Based on Visual Communication</b></h1>
                    <h2>
                    <span>RAN Qi-wu</span>
            </h2>
                    <h2>
                    <span>School of Electrical Engineering, Shaanxi University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>When processing complex multi-frame video images, the traditional image neighborhood tracking method based on SURF feature leads to low accuracy of target neighborhood, and the boundary is not smooth enough, so that the image cannot be processed in real time. Therefore, a multi-frame video image neighborhood tracking method based on visual communication was presented. Firstly, this method selected appropriate superimposed scales, and then vectors described by neighborhood features were completely superimposed with appropriate superimposed scales, and thus to remove the redundant feature points and discrete points. Secondly, our method gave the weights to the targets appearing in the superimposed region. Finally, the method combined the weights with the saliency weighted least squares image matching tracking method to track neighborhood of multi-frame video image. Simulation results show that the proposed method not only improves the accuracy of feature extraction and matching precision of multi-frame video images, but also reduces the noise in matching process. Compared with the existing neighborhood tracking methods, the proposed method has great advantages, which provides an accurate method for next neighborhood tracking.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Neighborhood%20tracking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Neighborhood tracking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Least%20squares%20image%20tracking%20method%20based%20on%20saliency%20weighted&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Least squares image tracking method based on saliency weighted;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Feature%20extraction%20and%20matching%20of%20multi-frame%20video%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Feature extraction and matching of multi-frame video image;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-03</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="27" name="27" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="28">在多媒体技术的快速发展下,视觉传达技术在图像邻域跟踪领域的表现尤其突出<citation id="102" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。多帧视频图像邻域跟踪的难点取决于如何将多帧视频图像中的目标准确地提取出来。在当前的图像邻域跟踪领域中,主要依赖邻域点序列来获取图像的尺度和邻域特征点来进行跟踪<citation id="99" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。邻域跟踪算法在图像特征识别中能够更准确的提取邻域点序列,且根据特征识别提取的邻域特征点和加性噪声对后续的特征点提取和后期的匹配有很大的帮助。常见的邻域跟踪算法有两种,一种是基于区域的邻域跟踪算法<citation id="100" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>,另一种是基于特征的邻域跟踪算法<citation id="101" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。在处理多帧视频图像时,多帧视频图像的特征匹配和边界点搜索操作非常复杂,容易造成视频邻域的特征点误匹配和加性噪声增强,而且传统的方法在进行搜索时的范围比较大。</p>
                </div>
                <div class="p1">
                    <p id="29">SURF作为一种图像特征提取方法,其原理是通过对金字塔结构进行深入分析,精细化视频图像的特征提取过程<citation id="103" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>,并结合金字塔空间结构生成过程进行简单化描述,和基于SIFT特征提取方法相比,SURF可以有效提高提取效率,但将其应用于多帧视频图像跟踪过程中仍然无法满足实时性需求。</p>
                </div>
                <div class="p1">
                    <p id="30">本文提出的基于视觉传达的多帧视频图像邻域跟踪算法从实时性要求的情况出发进行实时性的目标跟踪,提出了一种新的多帧视频图像邻域跟踪方法。该方法根据多帧视频图像序列来对感兴趣区域模板与下一帧图像特征点之间的连续匹配完成对其邻域跟踪,为多帧视频图像邻域跟踪提供了基础。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>2 基于特征提取的图像邻域跟踪方法</b></h3>
                <div class="p1">
                    <p id="32">在本文提出的邻域跟踪方法中,SURF特征提取算法的处理过程等同于对多帧视频图像的预处理操作<citation id="104" type="reference"><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>。在进行特征提取过程中,引入视频图像去噪方法,根据特征点在视频图像中的位置进行分类,最后通过匹配模版实现对匹配过程转换成对感兴趣邻域的跟踪。在特征点提取与匹配过程中引入了图像分块处理,提高了实时性。下面介绍本文方法的具体思路。</p>
                </div>
                <div class="p1">
                    <p id="33">针对多帧视频图像邻域跟踪,首先对多帧图像的序列进行分割,并对图像中心像素集进行定位分析,获得兴趣目标模版,并根据目标模版进行多帧图像特征提取,实现图像邻域跟踪。</p>
                </div>
                <h4 class="anchor-tag" id="34" name="34"><b>2.1 多帧图像的分块处理与匹配</b></h4>
                <div class="p1">
                    <p id="35">多帧视频图像的邻域进行跟踪,首次需要获得多帧视频图像的目标邻域,并在此邻域内通过特征提取实现特征匹配过程,采用SURF特征提取算法对大小为800×600px图片进行特征点检测的处理时间己经达到了最快,但是用这种方法来处理多帧视频图像的目标邻域进行跟踪是不太合适的。这是因为采用SURF特征提取算法对多帧视频图像进行特征点检测时,特征描述的生成时间与特征点的具体个数具有相关性<citation id="105" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。但是实际上视频图像的特征点与兴趣目标邻域的大小成正相关。因此,可以对食品图像目标进行分块处理,特征描述子特征点的匹配可以同时进行,这样就大大减少了计算时间,提升了效率。但是,由于特征描述向量的动态变化,很可能会造成多帧视频的失真<citation id="106" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>,因此需要对视频图像重叠宽度进行设定,确保多帧视频图像边界信息的无损保留,有效减少特征点的冗余信息。具体过程如下:</p>
                </div>
                <h4 class="anchor-tag" id="36" name="36">1)特征点的邻域</h4>
                <div class="p1">
                    <p id="37">对于需要提取的多帧视频图像边缘特征点,一般情况下设定金字塔结构为3层。在确定多帧视频图像特征点位置的大致区域需取邻域需区间是4<i>σ</i>(<i>σ</i>是特征点所在区域的尺度值),由此区间形成的特征向量所涵盖的邻域区间为20<i>σ</i>,为了便于后续研究,设定滤波器尺度为<i>L</i>,金字塔各层索引<i>s</i>及尺度值<i>σ</i>之间的关系可表示为</p>
                </div>
                <div class="p1">
                    <p id="38" class="code-formula">
                        <mathml id="38"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><mo>=</mo><mn>3</mn><mo>×</mo><mrow><mo>[</mo><mrow><mn>2</mn><msup><mrow></mrow><mrow><mn>0</mn><mo>+</mo><mn>1</mn></mrow></msup><mo>×</mo><mo stretchy="false">(</mo><mi>s</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mn>1</mn></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>σ</mi><mo>=</mo><mn>1</mn><mo>.</mo><mn>2</mn><mo>×</mo><mrow><mi>L</mi><mo>/</mo><mn>9</mn></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="39">考虑特殊情况的存在:当金字塔滤波器尺寸为最大值88时,特征点所在区域值<i>σ</i>约为13,此时20<i>σ</i>为260像素。为了实现特征向量的准确提取,叠加尺度必须调整为720像素。而如果提取的重叠尺度过大,则失去了分块意义<citation id="107" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。考虑到多帧视频图像特征提取过程中,为了凸显目标邻域对特征点的影响,需要对不同位置进行加权处理,可将重叠尺度<i>l</i><sub>1</sub>调整为90,将保留的边缘特征点作为中心,3.3<i>σ</i>(3.3<i>σ</i>的值为43个像素)为半径的圆内的主要邻域信息。</p>
                </div>
                <h4 class="anchor-tag" id="40" name="40">2)感兴趣邻域的尺度大小</h4>
                <div class="p1">
                    <p id="41">为了确保多帧视频图像跟踪目标在越过感兴趣邻域时的稳定性,应当确保目标始终存在于某一分块中。前提条件是必须保证叠加尺度和待匹配模板有一定的联系:在本文方法的待匹配模板中(设尺寸为<i>H</i>×<i>W</i>),选取叠加尺度等同于待匹配模板对角线<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><msqrt><mrow><mi>Η</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>W</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>,结合上文的结论设定最终的叠加尺度<i>l</i>为</p>
                </div>
                <div class="p1">
                    <p id="42" class="code-formula">
                        <mathml id="42"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mo>=</mo><mi>max</mi><mo stretchy="false">(</mo><mi>l</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>l</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="43" name="43">3)去除边界冗余特征点</h4>
                <div class="p1">
                    <p id="44">当观测到多帧视频图像叠加区域后,所处于分块边界周围的特征点在提取过程中会受到分割边界的影响:多帧视频图像的邻域特征提取会受到边界特征点的影响,产生冗余特征点。因此,为了减轻冗余特征对多帧视频图像的影响,需要对边界相关特征点进行去除。</p>
                </div>
                <h4 class="anchor-tag" id="45" name="45">4)明确分块数目</h4>
                <div class="p1">
                    <p id="46">由于多帧视频图像特征向量生成时需要以其邻域信息为基础,所以不可分块过大,且确保分割边界较短。综上分析,确定多帧视频图像分块数量为4,通过最简洁的十字分块形式。具体分块形式如图所示。</p>
                </div>
                <div class="p1">
                    <p id="47">通过上述过程可确定多帧视频图像分块的具体方式,以下结合图1进行详细说明:图1右边表示特征提取的分块情况,灰度大小表示重叠的部分,宽度为<i>l</i>′,获取特征点之后将黑色<i>L</i>型虚线外的区域(尺度为43个像素)的冗余特征点进行去除。其余的分块用上述方法进行推算。</p>
                </div>
                <div class="p1">
                    <p id="48">在分块操作完成之后,将待匹配图像的各子块输入到相应的通道中进行特征提取,获得各子块的待匹配模板后进入匹配阶段,完成目标模板和基准图的匹配。</p>
                </div>
                <div class="area_img" id="49">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910084_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 待匹配图像叠加分块示意图与去除冗余特征点示意图" src="Detail/GetImg?filename=images/JSJZ201910084_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 待匹配图像叠加分块示意图与去除冗余特征点示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910084_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="50" name="50" class="anchor-tag"><b>3 显著性加权最小二乘图像匹配跟踪方法</b></h3>
                <div class="p1">
                    <p id="51">在多帧视频图像目标邻域跟踪过程中,通常选取理想目标模板当作目前图像邻域跟踪匹配的基准图。由于目标相对于相机的运行,在视频图像上的目标与基准图之间存在随机误差。利用仿射变换来描述当前视频图像与基准图之间的几何畸变,即</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>r</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub><mi>y</mi><msub><mrow></mrow><mi>t</mi></msub></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>r</mi><msub><mrow></mrow><mn>3</mn></msub><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>4</mn></msub><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>5</mn></msub><mi>y</mi><msub><mrow></mrow><mi>t</mi></msub></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">其中:(<b>x</b><sub><b>t+1</b></sub>,<b>y</b><sub><b>t+1</b></sub>)、(<b>x</b><sub><b>t</b></sub>,<b>y</b><sub><b>t</b></sub>)是当前视频图像与基准图的坐标,<b>r</b><sub><b>0</b></sub>,<b>r</b><sub><b>1</b></sub>,<b>r</b><sub><b>2</b></sub>,<b>r</b><sub><b>3</b></sub>,<b>r</b><sub><b>4</b></sub>,<b>r</b><sub><b>5</b></sub>是几何畸变参数。在忽略噪声所带来的影响后当前视频图像与基准图的灰度分布关系利用下式来表示:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>≈</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>r</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mi>x</mi><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub><mi>y</mi><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>3</mn></msub><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>4</mn></msub><mi>x</mi><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>5</mn></msub><mi>y</mi><mo stretchy="false">)</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">上式中:<b>I</b><sub><b>t</b></sub>、<b>I</b><sub><b>t+1</b></sub>是当前视频图像与基准图的灰度分布函数。</p>
                </div>
                <div class="p1">
                    <p id="56">对于多帧视频图像目标邻域跟踪的情况,窗口区域内同时具有目标点和背景点,而只有目标点满足上式要求。在这种情况下,多帧视频图像中目标邻域内的任意一点(<b>x,y</b>)灰度误差为</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>v</mi><mo>=</mo><mi>W</mi><mo>×</mo><mo stretchy="false">(</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mi>W</mi><mo>×</mo><mrow><mo>[</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>r</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mi>x</mi><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub><mi>y</mi><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>3</mn></msub><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>4</mn></msub><mi>x</mi><mo>+</mo><mi>r</mi><msub><mrow></mrow><mn>5</mn></msub><mi>y</mi><mo stretchy="false">)</mo></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">式中的<b>W</b>为上一节计算获得的权值,对上式进行线性化后得出</p>
                </div>
                <div class="p1">
                    <p id="59"><b>v</b>=<b>W×[(I</b><sub><b>t+1</b></sub>-<b>I</b><sub><b>t</b></sub>)<sub><b>x</b></sub><b>dr</b><sub><b>0</b></sub>+<b>x(I</b><sub><b>t+1</b></sub>)<sub><b>x</b></sub><b>dr</b><sub><b>1</b></sub>+<b>y(I</b><sub><b>t+1</b></sub>)<sub><b>x</b></sub><b>dr</b><sub><b>2</b></sub>+(<b>I</b><sub><b>t+1</b></sub>)<sub><b>y</b></sub><b>dr</b><sub><b>3</b></sub>+<b>x(I</b><sub><b>t+1</b></sub>)<sub><b>y</b></sub><b>dr</b><sub><b>4</b></sub>+<b>y(I</b><sub><b>t+1</b></sub>)<sub><b>y</b></sub><b>dr</b><sub><b>5</b></sub>-<i>Δ</i><b>I</b>](<b>7</b>)</p>
                </div>
                <div class="p1">
                    <p id="62">其中:<b>dr</b><sub><b>0</b></sub>,…,<b>dr</b><sub><b>5</b></sub>表示待定的参数修正值,<i>Δ</i><b>I=I</b><sub><b>t+1</b></sub>(<b>x,y)-I</b><sub><b>t</b></sub>(<b>x,y</b>)为灰度差。在第二帧的视频图像中参数的初始值选择<mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>0</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>3</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>4</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>5</mn></msub></mrow><mo>]</mo></mrow><mo>=</mo><mrow><mo>[</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo>,</mo><mn>1</mn></mrow><mo>]</mo></mrow></mrow></math></mathml>,而后续多帧图像<b>I</b><sub><b>t+1</b></sub>(<b>t≥1</b>)的参数初始值应当为[<b>r</b><mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>0</mn><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>,<b>r</b><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>,<b>r</b><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>,<b>r</b><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>,<b>r</b><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>,<b>r</b><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>5</mn><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>]=[<b>r</b><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>0</mn><mi>t</mi></msubsup></mrow></math></mathml>,<b>r</b><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>t</mi></msubsup></mrow></math></mathml>,<b>r</b><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>t</mi></msubsup></mrow></math></mathml>,<b>r</b><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mi>t</mi></msubsup></mrow></math></mathml>,<b>r</b><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mi>t</mi></msubsup></mrow></math></mathml>,<b>r</b><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>5</mn><mi>t</mi></msubsup></mrow></math></mathml>],上标<b>t</b>的含义是<b>t</b>时刻的目标相对于初始阶段视频序列帧的仿射变换参数。在邻近的两个视频序列帧中目标位置和尺度改变较大时,尤其是目标平移活动大时,即<b>r</b><sub><b>0</b></sub>和<b>r</b><sub><b>3</b></sub>改变较大时,假设没有较满意的仿射变换参数估计值时,则无法满足泰勒展开的基础条件,依然会利用式(<b>6</b>)对灰度误差进行线性化求解来获取目标的当前位置,这样就导致目标邻域跟踪失败。在这种情况下本文采用上一时段图像目标相对于初始帧的仿射变换参数作为当前帧目标的仿射变换参数的初值。</p>
                </div>
                <div class="p1">
                    <p id="63">对视频图像目标邻域内全部像素点统计灰度误差,依据最小二乘匹配原则:∑<b>vv=</b><i><b>min</b></i>,获得参数修正值<b>dr</b><sub><b>0</b></sub>,…,<b>dr</b><sub><b>5</b></sub>相应的线性方程组,通过该方程求解出<b>dr</b><sub><b>0</b></sub>,…,<b>dr</b><sub><b>5</b></sub>,获得<b>r</b><sub><b>0</b></sub>,<b>r</b><sub><b>1</b></sub>,<b>r</b><sub><b>2</b></sub>,<b>r</b><sub><b>3</b></sub>,<b>r</b><sub><b>4</b></sub>,<b>r</b><sub><b>5</b></sub>的最终解。利用式(<b>7</b>)获取当前视频图像中目标的位置,完成多帧视频图像邻域跟踪。</p>
                </div>
                <h3 id="64" name="64" class="anchor-tag"><b>4 实验结果及分析</b></h3>
                <div class="p1">
                    <p id="65">仿真环境为<i>AMD A</i><b>10-5750</b><i>M</i><b>2.50</b><i>GHz CPU</i>,<b>4</b><i>GB</i>内存,<i>Win</i><b>10</b>操作系统,<i>Visual Studio</i><b>2013</b>+<i>OpenCV</i><b>3.0</b>,<i>Matlab</i><b>2013</b>软件。</p>
                </div>
                <div class="p1">
                    <p id="66">选取某视频序列中第<b>1</b>帧、第<b>10</b>帧、第<b>53</b>帧图像对跟踪算法的性能进行测试。表<b>1</b>给出第<b>1</b>帧、第<b>10</b>帧、第<b>53</b>帧图像的属性信息,这些属性信息可概括邻域跟踪阶段遇到的场景变化情况。</p>
                </div>
                <div class="area_img" id="67">
                    <p class="img_tit"><b>表1 多帧视频图像序列信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="67" border="1"><tr><td><br />帧数</td><td>光照变化</td><td>尺度变化</td><td>近似目标</td><td>部分遮挡</td><td>完全遮挡</td></tr><tr><td><br />第1帧</td><td>否</td><td>否</td><td>是</td><td>是</td><td>是</td></tr><tr><td><br />第20帧</td><td>是</td><td>否</td><td>是</td><td>是</td><td>否</td></tr><tr><td><br />第53帧</td><td>否</td><td>否</td><td>是</td><td>是</td><td>否</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="68">本文选用了多帧视频图像作为实验对象,与文中方法相结合运用到图2中,尺寸为720*480的多帧视频图像的序列中,多帧视频图像中的目标用白色方框标记,右上角的截取的小图像为匹配模板。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910084_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 多帧视频图像的邻域跟踪结果" src="Detail/GetImg?filename=images/JSJZ201910084_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 多帧视频图像的邻域跟踪结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910084_069.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="70">观测多帧视频图像可知:多帧视频图像序列背景较为复杂,目标和背景的差异不明显,无法有效实现目标和背景分离。即使在第1帧和第53帧中目标的位置及拍摄角度发生了一些变化,但根据本文方法依然可以对目标进行实时跟踪。该实验表明多帧视频图像的邻域跟踪算法可应用于复杂背景,有具有较好的抗干扰能力。</p>
                </div>
                <div class="p1">
                    <p id="71">实验过程中选取目标重叠率、综合评价指标F、平均误差作为评价指标,测试不同跟踪方法的跟踪精度。将多帧视频图像序列的总帧数以及跟踪所需时间的比值视为不同跟踪方法处理视频图像的运算速度,计算式如下</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>l</mi><mi>a</mi><mi>p</mi><mo>=</mo><mfrac><mrow><mi>a</mi><mi>r</mi><mi>e</mi><mi>a</mi><mo stretchy="false">(</mo><mi>R</mi><msub><mrow></mrow><mi>Τ</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>R</mi></mstyle><msub><mrow></mrow><mi>G</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>a</mi><mi>r</mi><mi>e</mi><mi>a</mi><mo stretchy="false">(</mo><mi>R</mi><msub><mrow></mrow><mi>Τ</mi></msub><mstyle displaystyle="true"><mo>∪</mo><mi>R</mi></mstyle><msub><mrow></mrow><mi>G</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">式(8)中,<i>R</i><sub><i>T</i></sub>代表追踪窗口,<i>R</i><sub><i>G</i></sub>代表追踪目标实际所在的窗口,<i>area</i>是指窗口的面积。选取目标的重叠率高于0.5时,<i>F</i>满足</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo>=</mo><mfrac><mrow><mn>2</mn><mi>Ρ</mi><mi>R</mi></mrow><mrow><mi>Ρ</mi><mo>+</mo><mi>R</mi></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">式(9)中,<i>P</i>代表选取目标的准确率,算法正确跟踪的样本数目和总样本数目的比率等于选取目标的准确率。<i>R</i>代表选取目标的召回率,算法正确跟踪的样本数目和总正确样本数目的比率等于选取目标的召回率,是衡量算法查全率的标准。<i>P</i>和<i>R</i>的计算公式如下</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>Ν</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>k</mi></mrow><mrow><mi>r</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi></mrow></msubsup></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>k</mi></mrow></msub></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>Ν</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mi>t</mi><mi>a</mi><mi>c</mi><mi>k</mi></mrow><mrow><mi>r</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi></mrow></msubsup></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>l</mi><mi>l</mi></mrow></msub></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">式(10)和式(11)中的<i>N</i><sub><i>all</i></sub>是指追踪目标的帧数,<i>N</i><sub><i>track</i></sub>是指算法进行目标追踪所获得的帧数,<i>N</i><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>k</mi></mrow><mrow><mi>r</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi></mrow></msubsup></mrow></math></mathml>是指算法进行目标追踪获得的正确帧数。</p>
                </div>
                <div class="p1">
                    <p id="78">算法估计得到的目标框架和现实环境下目标框架之间的中心距离为平均误差。表2为实验追踪结果。</p>
                </div>
                <div class="area_img" id="79">
                    <p class="img_tit"><b>表2 不同方法跟踪实验结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="79" border="1"><tr><td rowspan="2"><br />帧数</td><td colspan="3"><br />基于区域的邻域跟踪方法</td><td colspan="3">本文方法</td></tr><tr><td><br />P</td><td>R</td><td>F</td><td>P</td><td>R</td><td>F</td></tr><tr><td><br />第1帧</td><td>0.92</td><td>0.97</td><td>0.94</td><td>0.97</td><td>0.99</td><td>0.98</td></tr><tr><td><br />第20帧</td><td>0.89</td><td>0.77</td><td>0.83</td><td>0.94</td><td>0.84</td><td>0.89</td></tr><tr><td><br />第53帧</td><td>0.86</td><td>0.70</td><td>0.77</td><td>0.87</td><td>0.84</td><td>0.85</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="80">据上所述视频帧序列的部分截图中都有目标区域出现遮挡的情况,所以不能得到跟踪目标的连续踪迹。</p>
                </div>
                <div class="p1">
                    <p id="81">本文方法利用金字塔结构对目标框架的中心位置和追踪目标的运动方向进行预测,相对于传统算法的全局检测来说,本文方法加快了检测速度,且有效去除了目标邻域其它冗余特征点的干扰。传统跟踪算法在目标邻域随机选择邻域特征点进行跟踪,所选取的特征点并非都能描述邻域范围内的目标对象,并且存在冗余特征点,导致与目标中心之间的距离相差较远,误差越来越大。本文方法将特征点匹配和特征点跟踪的两种方法结合,得到准确描述跟踪目标的邻域点,避免了因随机选取邻域点,受到冗余邻域点干扰,造成的追踪位置出现偏差的情况,特别是在目标进行加速运动时,本文方法相比基于区域的邻域跟踪方法具有较低的错误率。</p>
                </div>
                <h3 id="82" name="82" class="anchor-tag"><b>5 结论</b></h3>
                <div class="p1">
                    <p id="83">本文提出的方法与传统的方法相比,根据多帧视频图像的特征点搜索进行匹配和权值的确定等方法的改进,在扫描过程中获得特征信息的基础上使邻域跟踪更好的进行图像匹配,且在匹配过程中有效的过滤掉邻域噪声的问题。实验表明,本文提出的基于多帧视频图像的邻域跟踪方法相对于传统的邻域跟踪方法具有一定的优越性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201508002&amp;v=MDM5NDFyQ1VSN3FmWnVacEZ5L25WN3pMUHlyZmJMRzRIOVRNcDQ5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 王猛,翟东海,聂洪玉,等.邻域窗口权重变分的图像修复[J].中国图象图形学报,2018,20(8):1000-1007.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSSS201808005&amp;v=MTk2NjBGckNVUjdxZlp1WnBGeS9uVjd6TElUN1lmYkc0SDluTXA0OUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 代蕾.基于视觉传达要素的电视画面优化设计方法研究[J].电视技术,2018,42(8):26-29+34.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201901015&amp;v=MjYxNzdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25WN3pMUFNuUFpMRzRIOWpNcm85RVk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 王卓.基于视觉传达效果的三维图像虚拟重建[J].现代电子技术,2019,42(1):70-72.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJCJ201803002&amp;v=MjE3MTQvblY3ekxOaWZJWkxHNEg5bk1ySTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 魏本征,尹义龙.基于局部特征约束的TEM图像分割算法[J].数据采集与处理,2018,33(3):16-24.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201810031&amp;v=MDIxODBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25WN3pMTHo3TWFiRzRIOW5OcjQ5R1pZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 孙赫赫,尚晓清,王冲.基于区域对比的图像显著性检测方法[J].计算机工程与应用,2018,54(10):197-200,208.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB200204000&amp;v=MDc4NTQvblY3ekxQeXJmYkxHNEh0UE1xNDlGWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 汪亚明.基于神经网络的图象序列特征点匹配[J].中国图象图形学报,2018,7(4):313-318.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201803007&amp;v=MzEyNjF5cmZiTEc0SDluTXJJOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9uVjd6TFA=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 杨勇,闫钧华,井庆丰.融合图像显著性与特征点匹配的形变目标跟踪[J].中国图象图形学报,2018,23(3):86-100.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201820014&amp;v=MTQ1ODJuUFpMRzRIOW5PcjQ5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25WN3pMUFM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 温洪波.大型视频多帧图像信息处理系统设计[J].现代电子技术,2018,41(20):61-64.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HGJZ2018S1032&amp;v=MTg0NzQvblY3ekxMU3JCZExHNEg5bXZybzlHWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 陈守文,马姝婧,刘春昊,et al.三维图像特征点匹配与拼接[J].化工进展,2018,37(S1):228-233.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201805020&amp;v=MTQ3ODlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25WN3pMUFNuUFpMRzRIOW5NcW85SFpJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 师春艳.基于三维视觉的室内设计虚拟现实方法研究[J].现代电子技术,2018,41(5):78-82.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGHW201712017&amp;v=MTYzODNEZWJHNEg5Yk5yWTlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkvblY3ekxMeXI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 牛畅,黄银和,尹奎英.基于分块SURF特征提取的图像目标跟踪算法[J].激光与红外,2017,47(12):1541-1547.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" >
                                    <b>[12]</b>
                                 杨勇,闫钧华,井庆丰.融合图像显著性与特征点匹配的形变目标跟踪[J].中国图象图形学报,2018,23(3):86-100.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201910084" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201910084&amp;v=MzA2OTJPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25WN3pMTHo3QmRMRzRIOWpOcjQ5TllJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
