<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139251006850000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJZ201910075%26RESULT%3d1%26SIGN%3doBBPv6142KzJT5iR7MbCW11B8rc%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201910075&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJZ201910075&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201910075&amp;v=MjQwMjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9uVTdySkx6N0JkTEc0SDlqTnI0OUNZWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;2 多核学习下多带抗噪声语音识别方法&lt;/b&gt; "><b>2 多核学习下多带抗噪声语音识别方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#32" data-title="&lt;b&gt;2.1 多核学习组合算法&lt;/b&gt;"><b>2.1 多核学习组合算法</b></a></li>
                                                <li><a href="#53" data-title="&lt;b&gt;2.2 基于组合算法的多带抗噪声语音识别方法&lt;/b&gt;"><b>2.2 基于组合算法的多带抗噪声语音识别方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#71" data-title="&lt;b&gt;3 仿真结果分析&lt;/b&gt; "><b>3 仿真结果分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="&lt;b&gt;4 结论&lt;/b&gt; "><b>4 结论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="&lt;b&gt;图1 MFCC提取流程图&lt;/b&gt;"><b>图1 MFCC提取流程图</b></a></li>
                                                <li><a href="#68" data-title="&lt;b&gt;图2 隐性马尔可夫模型&lt;/b&gt;"><b>图2 隐性马尔可夫模型</b></a></li>
                                                <li><a href="#70" data-title="&lt;b&gt;图3 语音识别方法整体流程图&lt;/b&gt;"><b>图3 语音识别方法整体流程图</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;表1 语音识别方法参数表&lt;/b&gt;"><b>表1 语音识别方法参数表</b></a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;表2 实验室环境中识别方法运算精度&lt;/b&gt;"><b>表2 实验室环境中识别方法运算精度</b></a></li>
                                                <li><a href="#80" data-title="&lt;b&gt;图4 汽车噪声环境下识别率&lt;/b&gt;"><b>图4 汽车噪声环境下识别率</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;图5 人群噪声环境下识别率&lt;/b&gt;"><b>图5 人群噪声环境下识别率</b></a></li>
                                                <li><a href="#82" data-title="&lt;b&gt;图6 图书馆噪声环境下识别率&lt;/b&gt;"><b>图6 图书馆噪声环境下识别率</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 李伟林,文剑,马文凯.基于深度神经网络的语音识别系统研究[J].计算机科学,2016,43(S2):45-49." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2016S2010&amp;v=MDQ4MjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25VN3JKTHo3QmI3RzRIOWV2clk5RVpJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         李伟林,文剑,马文凯.基于深度神经网络的语音识别系统研究[J].计算机科学,2016,43(S2):45-49.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 曹晶晶,许洁萍,邵聖淇.多噪声环境下的层级语音识别模型[J].计算机应用,2018,38(06):1790-1794." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201806045&amp;v=MDA3MzZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9uVTdySkx6N0JkN0c0SDluTXFZOUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         曹晶晶,许洁萍,邵聖淇.多噪声环境下的层级语音识别模型[J].计算机应用,2018,38(06):1790-1794.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 孙涛,冯婕.快速随机多核学习分类算法[J].西安电子科技大学学报,2016,43(1):36-40." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDKD201601007&amp;v=MTA4MDJuQWFyRzRIOWZNcm85Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25VN3JKUFM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         孙涛,冯婕.快速随机多核学习分类算法[J].西安电子科技大学学报,2016,43(1):36-40.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 张桂梅,孙晓旭,刘建新.基于自适应投影算法的分数阶全变分去噪模型[J].模式识别与人工智能,2016,29(11):1009-1018." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201611006&amp;v=MDgzMzN5L25VN3JKS0Q3WWJMRzRIOWZOcm85RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         张桂梅,孙晓旭,刘建新.基于自适应投影算法的分数阶全变分去噪模型[J].模式识别与人工智能,2016,29(11):1009-1018.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 张晓丹,黄丽霞,张雪英.关于在噪声环境下语音识别优化研究[J].计算机仿真,2016,33(8):172-176,291." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201608036&amp;v=MTY1MDRkTEc0SDlmTXA0OUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9uVTdySkx6N0I=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         张晓丹,黄丽霞,张雪英.关于在噪声环境下语音识别优化研究[J].计算机仿真,2016,33(8):172-176,291.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 张毅,谢延义,罗元,席兵.一种语音特征提取中Mel倒谱系数的后处理算法[J].智能系统学报,2016,11(2):208-215." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZNXT201602010&amp;v=MTYzNzBacEZ5L25VN3JKUHlQVGVyRzRIOWZNclk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         张毅,谢延义,罗元,席兵.一种语音特征提取中Mel倒谱系数的后处理算法[J].智能系统学报,2016,11(2):208-215.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 蓝阳,谢俊法,杨志鹏,崔保生.基于鲁棒自适应最小方差信号无畸变响应波束形成的高密度数据室内组合方法研究[J].石油物探,2018,57(1):104-112." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYWT201801015&amp;v=MTEwNzR6cXFCdEdGckNVUjdxZlp1WnBGeS9uVTdySk5qVGNlckc0SDluTXJvOUVZWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         蓝阳,谢俊法,杨志鹏,崔保生.基于鲁棒自适应最小方差信号无畸变响应波束形成的高密度数据室内组合方法研究[J].石油物探,2018,57(1):104-112.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 樊炳辉,卢凤,王鑫,刘圭圭.智能上假肢特定人语音识别系统实现[J].计算机工程与设计,2017,38(6):1630-1634." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201706042&amp;v=MjE5NThySk5pZllaTEc0SDliTXFZOUJab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9uVTc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         樊炳辉,卢凤,王鑫,刘圭圭.智能上假肢特定人语音识别系统实现[J].计算机工程与设计,2017,38(6):1630-1634.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 李方伟,李骐,朱江.改进的基于隐马尔可夫模型的态势评估方法[J].计算机应用,2017,37(5):1331-1334,1340." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201705020&amp;v=MjE0NTZxQnRHRnJDVVI3cWZadVpwRnkvblU3ckpMejdCZDdHNEg5Yk1xbzlIWklRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         李方伟,李骐,朱江.改进的基于隐马尔可夫模型的态势评估方法[J].计算机应用,2017,37(5):1331-1334,1340.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 胡丹,曾庆宁,龙超.调制域谱减法用于鲁棒性语音识别[J].科学技术与工程,2016,16(4):216-220." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201604041&amp;v=MjI1NjZHNEg5Zk1xNDlCWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkvblU3ckpMalhCZmI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         胡丹,曾庆宁,龙超.调制域谱减法用于鲁棒性语音识别[J].科学技术与工程,2016,16(4):216-220.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" E Buss,L J Leibold,C Lorenzi.Speech recognition for school-age children and adults tested in multi-tone vs multi-noise-band maskers[J].Journal of the Acoustical Society of America,2018,143(3):1458-1480." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Speech recognition for school-age children and adults tested in multi-tone vs multi-noise-band maskers">
                                        <b>[11]</b>
                                         E Buss,L J Leibold,C Lorenzi.Speech recognition for school-age children and adults tested in multi-tone vs multi-noise-band maskers[J].Journal of the Acoustical Society of America,2018,143(3):1458-1480.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" >
                                        <b>[12]</b>
                                     李伟林,文剑,马文凯.基于深度神经网络的语音识别系统研究[J].计算机科学,2016,43(Z11):45-49.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJZ" target="_blank">计算机仿真</a>
                2019,36(10),364-367+395             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于多核学习的多带抗噪声语音识别方法仿真</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A1%BE%E9%B8%BF%E8%99%B9&amp;code=42765942&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">顾鸿虹</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E5%A4%A9%E6%B4%A5%E5%AD%A6%E9%99%A2&amp;code=1749031&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京科技大学天津学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>由于传统语音识别方法在安静环境下语音识别较为准确,可在现实环境下,噪声干扰语音特征提取,导致测量数据不可信,语音识别方法正确率低。提出一种基于多核学习的多带抗噪声语音识别方法,构建多核学习组合算法。算法是多核学习与投影算法的融合,根据不同频带带宽,可以将多带噪声有效地分类,并加强语音特征级,与CHMM模型共同完成多带抗噪声语音识别方法,计算得出各模型条件概率,数值最大的即是语音识别结果。根据仿真结果分析,基于多核学习的多带抗噪声语音识别方法,相比传统方法可以减少运算量,提高语音识别正确率,有效地识别出现实噪声环境下正常语音。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E6%A0%B8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多核学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%B8%A6%E6%8A%97%E5%99%AA%E5%A3%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多带抗噪声;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">语音识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8A%95%E5%BD%B1%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">投影算法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    顾鸿虹(1982-),女(汉族),天津人,硕士,讲师,研究方向:计算机应用技术,软件工程,人工智能,语音识别。&lt;image id="108" type="formula" href="images/JSJZ201910075_10800.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-29</p>

            </div>
                    <h1><b>Multi-band Anti-Noise Speech Recognition Method Simulation Based on Multi-Core Learning</b></h1>
                    <h2>
                    <span>GU Hong-hong</span>
            </h2>
                    <h2>
                    <span>Tianjin College, University of Science &amp; Technology Beijing</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In quiet environment, the traditional speech recognition method is more accurate. In real environment, the speech feature extraction is influenced by noise interference, resulting in unreliable measurement data and low accuracy of speech recognition. Therefore, this article proposed a multi-band anti-noise speech recognition method based on multi-core learning. Firstly, the multi-core learning combination algorithm was constructed. This algorithm is the fusion of multi-core learning and projection algorithm. According to different bandwidths, the multi-band noise could be classified effectively and the speech feature level could be strengthened. After that, the multi-band anti-noise speech recognition system was completed with CHMM model. Then, conditional probability of each model was calculated. Thus, the maximum value was the speech recognition result. According to the analysis of simulation result, the multi-band anti-noise speech recognition method based on multi-core learning can effectively reduce the computational complexity and improve the accuracy of speech recognition. Thus, this method can effectively recognize the normal speech in real noise environment.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-core%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multi-core learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-band%20anti-noise&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multi-band anti-noise;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Speech%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Speech recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=CHMM%20model%20Projection%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">CHMM model Projection algorithm;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-29</p>
                            </div>


        <!--brief start-->
                        <h3 id="27" name="27" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="28">核学习作为实现噪声识别和分类的有效手段被研究者广泛关注。传统语音识别方法可以较好地分辨出安静环境下纯净语音,识别率较高,且错误率低。但是在现实生活中,需要进行语音识别的环境很难做到完全安静,都存在一定的多带噪声。因此,传统识别方法很难在现实环境中提取正常语音特征,语音识别率较低,不能满足实际情境的需要。在设计语音识别方法时,这种实际测量条件和实验室训练条件不一致,导致测量数据不可信,语音识别失败的现象,一直是研究的热点课题。</p>
                </div>
                <div class="p1">
                    <p id="29">针对上述问题,李伟林等人<citation id="89" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>设计出一种神经网络下语音识别方法,利用均值归一化提高模型性能和拟合度,并使用多模态函数进一步优化模型,减轻实验拟合状态,实现提高噪声环境下语音识别效率和减少错误率的目的。曹晶晶等人<citation id="90" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>将现实噪声环境分为上下层级,分别设立语音识别模型,由此来减少实验训练数据与样本测试数据间的不同,实现在噪声环境下语音正常识别。</p>
                </div>
                <div class="p1">
                    <p id="30">上述两种方法都存在假设噪声分类条件有限的问题,当实验数据中混有多带噪声时,无法有效的识别出正常语音,甚至在实验结果中还会产生其它形式的噪声,增加运算量,降低语音识别正确率。针对这种情况,提出一种基于多核学习的多带抗噪声语音识别方法,利用多核学习来加强识别方法的抗噪声能力,使得该方法能够不受噪声分类条件的限定,减少运算量,极大程度上降低识别错误率,完成语音正常识别。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>2 多核学习下多带抗噪声语音识别方法</b></h3>
                <h4 class="anchor-tag" id="32" name="32"><b>2.1 多核学习组合算法</b></h4>
                <div class="p1">
                    <p id="33">多核学习组合算法是多核学习<citation id="91" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>与投影算法<citation id="92" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>的融合,其在各种分类识别领域都被广泛应用,抗噪声语音识别方法中该算法的基本形式为:</p>
                </div>
                <div class="p1">
                    <p id="34" class="code-formula">
                        <mathml id="34"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">(</mo><mo>⋅</mo><mo>,</mo><mi>u</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi>Κ</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></munderover><mi>β</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mo>⋅</mo><mi>k</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mo>⋅</mo><mo>,</mo><mi>u</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mo>,</mo><mi>β</mi><msub><mrow></mrow><mi>k</mi></msub><mo>≥</mo><mn>0</mn><mo>;</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi>Κ</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></munderover><mi>β</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mn>1</mn><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="35">其中,<i>K</i><sub>0</sub>表示多核学习组合算法的总核数,<i>k</i><sub>0</sub>(·,<i>u</i><sub><i>n</i></sub>)为<i>K</i><sub>0</sub>中第<i>k</i>个基本核,<i>β</i><sub><i>k</i></sub>是<i>k</i>的加权系数。分类识别问题中多核算法的加权系数优化方式有许多,可是该算法在多带抗噪声语音识别中等同于多个单核算法同时运行,最终实验结果是各单核输出结果的加权均值。虽然这样该算法就拥有较为优秀的稳定性,但是对运行方法的储存空间和运算性能就有着较高要求,为此提出的多核学习组合算法,不需要对加权系数<i>β</i><sub><i>k</i></sub>进行优化处理,以减小运算量。</p>
                </div>
                <div class="p1">
                    <p id="36">根据式(1)中给出的初始限定条件,首先将<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi>Κ</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></munderover><mi>Μ</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub></mrow></math></mathml>模型引入,再使用<i>K</i><sub>0</sub>个基本核对算法进行拟合,并融入投影算法。根据不同领域分类需求或具体情境设定输入信息,基本核内可以包涵种类相同或者不同的单核函数。为了降低方法复杂性,现只针对核带宽参数<i>ξ</i>不同的单核函数,数学公式如式(2)所示</p>
                </div>
                <div class="area_img" id="37">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201910075_03700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="38">其中,当<i>M</i><sub><i>k</i></sub>&lt;<i>n</i>时,其投影函数为</p>
                </div>
                <div class="p1">
                    <p id="39" class="code-formula">
                        <mathml id="39"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ψ</mi><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi>Κ</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munderover><mi>a</mi></mstyle></mrow></mstyle><msubsup><mrow></mrow><mrow><mi>n</mi><mo>-</mo><mi>m</mi></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>⋅</mo><mi>k</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mo>⋅</mo><mo>,</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>w</mi><msub><mrow></mrow><mi>m</mi></msub></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi>Κ</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></munderover><mrow><mrow><mo>{</mo><mrow><mi>h</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><mo>}</mo></mrow></mrow></mstyle><msup><mrow></mrow><mi>Τ</mi></msup><mi>a</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="40">式(3)中</p>
                </div>
                <div class="p1">
                    <p id="41" class="code-formula">
                        <mathml id="41"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>h</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><mrow><mo>[</mo><mrow><mi>k</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mo>⋅</mo><mo>,</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo stretchy="false">)</mo><mo>,</mo><mi>k</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mo>⋅</mo><mo>,</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo stretchy="false">)</mo><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>k</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mo>⋅</mo><mo>,</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>w</mi><msub><mrow></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></msub></mrow></msub><mo stretchy="false">)</mo></mrow><mo>]</mo></mrow><msup><mrow></mrow><mi>Τ</mi></msup></mtd></mtr><mtr><mtd><mo>∈</mo><mi>R</mi><msup><mrow></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mi>k</mi></msub><mo>×</mo><mn>1</mn></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>a</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><mrow><mo>[</mo><mrow><mi>a</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mo>,</mo><mn>1</mn></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>,</mo><mi>a</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mo>,</mo><mn>2</mn></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>a</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mo>,</mo><mi>Μ</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><mo>]</mo></mrow><msup><mrow></mrow><mi>Τ</mi></msup><mo>∈</mo><mi>R</mi><msup><mrow></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mi>k</mi></msub><mo>×</mo><mn>1</mn></mrow></msup><mspace width="0.25em" /><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="42">因为任意<i>M</i><sub><i>k</i></sub>(<i>k</i>=1,2,…,<i>K</i><sub>0</sub>)数量相同,则式(3)可以进一步简写如下</p>
                </div>
                <div class="p1">
                    <p id="43" class="code-formula">
                        <mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ψ</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo><mo>=</mo><mi>v</mi><mi>e</mi><mi>c</mi><mo stretchy="false">(</mo><mover accent="true"><mi>h</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mi>Τ</mi></msup><mo>⋅</mo><mi>v</mi><mi>e</mi><mi>c</mi><mo stretchy="false">(</mo><mover accent="true"><mi>a</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="44">然后对函数进行拉直处理,且</p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi>h</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mrow><mo>[</mo><mrow><mi>h</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>,</mo><mi>h</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>h</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">(</mo><mi>Κ</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">)</mo></mrow></msubsup></mrow><mo>]</mo></mrow><mo>∈</mo><mi>R</mi><msup><mrow></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mi>k</mi></msub><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mover accent="true"><mi>a</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mrow><mo>[</mo><mrow><mi>a</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>,</mo><mi>a</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>a</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">(</mo><mi>Κ</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">)</mo></mrow></msubsup></mrow><mo>]</mo></mrow><mo>∈</mo><mi>R</mi><msup><mrow></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mi>k</mi></msub><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">通过式(7)与式(8)的不同投影向量堆叠运算,使单核最小均值函数转换为不同种类多核最小均值函数。这时<i>vec</i>(<sub><i>n</i></sub>)=<i>h</i><sub><i>n</i></sub>,并且<i>vec</i>(<sub><i>n</i></sub>)=<i>a</i><sub><i>n</i></sub>,因此式(6)可得</p>
                </div>
                <div class="p1">
                    <p id="47" class="code-formula">
                        <mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ψ</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo><mo>=</mo><mi>h</mi><msubsup><mrow></mrow><mi>n</mi><mi>Τ</mi></msubsup><mo>⋅</mo><mi>a</mi><msub><mrow></mrow><mi>n</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="48">在第<i>n</i>时,根据最近<i>P</i>个时间段内输入信息{<i>d</i><sub><i>n</i></sub><sub>-</sub><sub><i>P</i></sub><sub>+1</sub>,…,<i>d</i><sub><i>n</i></sub>}和期望数据{<i>u</i><sub><i>n</i></sub><sub>-</sub><sub><i>P</i></sub><sub>+1</sub>,…,<i>u</i><sub><i>n</i></sub>},得出式(9)中<i>h</i><sub><i>n</i></sub>的定义函数为</p>
                </div>
                <div class="p1">
                    <p id="49" class="code-formula">
                        <mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mrow><mo>[</mo><mrow><mi>h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>-</mo><mi>Ρ</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>,</mo><mi>h</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>-</mo><mi>Ρ</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>h</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>]</mo></mrow><mo>∈</mo><mi>R</mi><msup><mrow></mrow><mrow><mi>Μ</mi><msub><mrow></mrow><mi>k</mi></msub><mi>Κ</mi><msub><mrow></mrow><mn>0</mn></msub><mo>×</mo><mi>Ρ</mi></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="50">其中,函数<i>H</i><sub><i>n</i></sub>的任意第((<i>k</i>-1)<i>M</i><sub><i>k</i></sub>+<i>m</i>,<i>p</i>)项是<i>k</i><sup>(</sup><sup><i>k</i></sup><sup>)</sup>,式(11)中参数<i>m</i>=1,2,…,<i>M</i><sub><i>k</i></sub>;<i>k</i>=1,2,…,<i>K</i><sub>0</sub>;<i>p</i>=1,2,…,<i>P</i>。这时将<i>P</i>投影维度向量<i>d</i><sub><i>n</i></sub>引入,则第<i>p</i>个元素是<i>d</i><sub><i>n</i></sub><sub>-</sub><sub><i>P</i></sub><sub>+1</sub>。投影算法可以求出多核学习同最小维度向量问题的解,第<i>n</i>个时刻的多核建模是</p>
                </div>
                <div class="area_img" id="51">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJZ201910075_05100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="52">利用拉格朗日函数,对所有多带核矩阵变量目标向量求偏导,并使其等于0,证明多核学习组合算法可以使识别方法不受噪声分类条件的限定,并降低方法复杂性,实现减少运算量的目的。</p>
                </div>
                <h4 class="anchor-tag" id="53" name="53"><b>2.2 基于组合算法的多带抗噪声语音识别方法</b></h4>
                <h4 class="anchor-tag" id="54" name="54">2.2.1 噪声语音特征级提取</h4>
                <div class="p1">
                    <p id="55">对声音特征进行分辨和提取<citation id="93" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>是语音识别方法的关键环节,组合算法下多带抗噪声语音识别方法使用的是MFCC(Mel-Frequency Cepstrum Coefficient),是一种频率倒谱系数,用来提取人耳听觉特性下语音的MFCC。一般情况下,人耳对低频声音较为敏感,而在高频声音中,人耳对频率高低变化较为迟钝,无法敏锐地识别声频变化。这就可以和Mel<citation id="94" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>标度频率形成较为稳定的非线性关系,并且和Hz频率建立对应的非线性函数。这时利用MFCC计算二者之间的关系函数,得到Hz声频谱特征级。Mel声频和现实环境声频的表达公式为</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mi>e</mi><mi>l</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn><mn>5</mn><mn>9</mn><mn>5</mn><mi>lg</mi><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mfrac><mi>f</mi><mrow><mn>7</mn><mn>0</mn><mn>0</mn></mrow></mfrac><mo stretchy="false">)</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">其中,现实环境声频f的单位是Hz,该公式已被广泛应用在各类声频特征级提取领域中。</p>
                </div>
                <div class="p1">
                    <p id="58">MFCC的运行框架如图1所示,首先将传声器收集的环境声音进行声频加重,突出语音特征级,随后将其分帧转换为数字信号,并加窗Mamming<citation id="95" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>,其次对预处理后的数据信息进行傅里叶转变,并做取模平方运算,得出结果在Mel滤波器<citation id="96" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>组上进行刻度分布,使用卷积神经网络对每个滤波器输入信息取对数量能量,并进行离散余弦转换,得出多维度系数,将前6维向量系数声频倒谱加权,得到MCFF,然后在对其中任意一阶段进行差分变换,这样使每帧声音的特征级可以在一个12维度向量上表示。使现实环境中收集的MFCC和任意一阶段差分处理的<i>Δ</i>MFCC相融合,形成12维度向量MCFF的特征级作为识别特征的声频。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910075_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 MFCC提取流程图" src="Detail/GetImg?filename=images/JSJZ201910075_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 MFCC提取流程图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910075_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="60" name="60">2.2.2 隐性马尔可夫模型</h4>
                <div class="p1">
                    <p id="61">语音识别方法使用模型是连续混合CHMM,也称为隐性马尔可夫模型<citation id="97" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,通常使用λ=(A,B,<i>π</i>)来进行描述,对其中任意的一个模态,可以用多个正态Continuous概率密度矩阵的线性组合来体现,同时,任意一个正态Continuous都有各自的矢量函数和协同方差矩阵,这样就可以通过大量的MFCC计算得出Continuous。模型中每个语音识别单元中都会使用六种模态的HMM,分别从<i>S</i><sub>1</sub>到<i>S</i><sub>6</sub>,其中<i>S</i><sub>1</sub>为HMM的起始模态,并会有一定概率跳转至别的模态上,以此类推,而<i>S</i><sub>6</sub>为一种吸收模态,同时模态之间或者模态自身的跳转概率用<i>a</i><sub><i>ij</i></sub>表示,跳转概率使用的是一个6×6的矩阵,表示为<i>A</i>。除了起始模态和终止模态外,任意一个模态<i>j</i>都拥有一个函数<i>b</i><sub><i>j</i></sub>(<i>o</i><sub><i>t</i></sub>)来表示,它用来描述模态<i>j</i>在<i>t</i>时刻所产生的维度向量<i>o</i><sub><i>t</i></sub>,并计算其概率密度,则<i>b</i><sub><i>j</i></sub>(<i>o</i><sub><i>t</i></sub>)的函数表达式</p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>b</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">(</mo><mi>o</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi>τ</mi></mstyle><msub><mrow></mrow><mrow><mi>j</mi><mi>m</mi></mrow></msub><mi>Ν</mi><mo stretchy="false">(</mo><mi>o</mi><msub><mrow></mrow><mi>t</mi></msub><mo>;</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>j</mi><mi>m</mi></mrow></msub><mo>,</mo><mi>δ</mi><msub><mrow></mrow><mrow><mi>j</mi><mi>m</mi></mrow></msub><mo stretchy="false">)</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63">其中,<i>N</i>(<i>o</i><sub><i>t</i></sub>;<i>u</i><sub><i>jm</i></sub>,<i>δ</i><sub><i>jm</i></sub>)描述的是正态Continuous概率密度;<i>M</i>表示<i>HMM</i>的混合函数阶段数量;<i>u</i><sub><i>jm</i></sub>是模态<i>j</i>在第<i>m</i>个分布函数的矢量;<i>δ</i><sub><i>jm</i></sub>是协同方差矩阵;在语音识别中<i>o</i><sub><i>t</i></sub>是12维度向量,同时也是12维度MFCC的特征级;<i>τ</i><sub><i>jm</i></sub>描述的是<i>j</i>模态下第<i>m</i>个分布函数的混合参数,并且参数符合条件</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi>τ</mi></mstyle><msub><mrow></mrow><mrow><mi>j</mi><mi>m</mi></mrow></msub><mo>=</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>Ν</mi></mtd></mtr><mtr><mtd><mi>τ</mi><msub><mrow></mrow><mrow><mi>j</mi><mi>m</mi></mrow></msub><mo>≥</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>≤</mo><mi>m</mi><mo>≤</mo><mi>Μ</mi><mtext>且</mtext><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>Ν</mi></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">其中,N表示HMM的模态数。</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66">2.2.3 多带抗噪声语音识别方法流程</h4>
                <div class="p1">
                    <p id="67">语音识别就是将语音中各项特征分别对比分析的的过程,同时也是声频不同模态的识别过程。根据模态分配原则,并参照一定的相似性规则,提取现实噪声环境下语音特征级,并和样本库中各数据做比较,寻找相似结果,最高相似性的语音模态可以作为识别结论<citation id="98" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。传统单核语音识别方法,抗噪性不高,很难实现在嘈杂环境中语音正常识别,导致识别率低于实验环境。针对该问题,使用多核学习组合算法来加强运算能力,并加入语音特征级增强环节,提高语音频率信号比,同时提升方法鲁棒性,进而强化方法的抗噪声能力,提高识别正确率<citation id="99" type="reference"><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>。该方法的整体框架流程如图2所示。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910075_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 隐性马尔可夫模型" src="Detail/GetImg?filename=images/JSJZ201910075_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 隐性马尔可夫模型</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910075_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="69">其中,多带噪声语音<i>y</i>(<i>n</i>)使用特征级加强模块处理,增加语音可识别向量,得到<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>s</mi><mo>^</mo></mover></math></mathml>(<i>n</i>),再提取MFCC参数,使特征达到最大矢量量化,同时利用均值算法对MFCC处理后的特征数据做归一化处理,得到最大最小向量的MFCC特征级,即式(13)中的维度向量o<sub>t</sub>。在实验模型中,利用Baum-Welch函数对HMM进行更新训练,直到运算产生所有语音特征级HMM参数。在语音对比识别阶段,通过上述过程处理得到可识别语音的MFCC,最后只要运算出各模型限定条件概率,选取概率值最大的就是多带抗噪声语音识别方法的结果。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910075_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 语音识别方法整体流程图" src="Detail/GetImg?filename=images/JSJZ201910075_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 语音识别方法整体流程图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910075_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="71" name="71" class="anchor-tag"><b>3 仿真结果分析</b></h3>
                <div class="p1">
                    <p id="72">实验用到的现实环境噪声有汽车噪声、人群噪声以及图书馆噪声。语音识别方法使用的信息库数据,是在训练环境中录制的语音,使用常见声卡和传声器完成记录,实验样本采集率是<b>32kHz</b>,精确度为<b>16bit</b>。语音识别样本数据人数共<b>7</b>人(<b>4</b>男<b>3</b>女),语音内容为<b>0～9</b>,共十个数字,每个数字发音<b>10</b>次,共<b>700</b>个对比样本,其中每人前<b>8</b>次发音设定为训练集(共<b>560</b>个),剩余为测试集(共<b>140</b>个)。在多带噪声中,子带越宽,频带中含有的数据就越多,虽然方便计算,但是过宽的子带难以捕语音特征,同理,子带越窄,频带中丢失信息越多,残留的有效数据越少,不方便进行运算,但较容易捕捉,考虑到上述问题,采用孤立词语音识别,在测试集数据中融入不同种类和不同信噪比的现实环境噪声,运算得出信噪比-<b>15dB～45dB</b>可识别声频数据。<b>CHMM</b>下多带抗噪声语音识别方法参数设定如表<b>1</b>。</p>
                </div>
                <div class="area_img" id="73">
                    <p class="img_tit"><b>表1 语音识别方法参数表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="73" border="1"><tr><td colspan="2"><br />语音特征提取</td><td colspan="2">语音识别模型</td></tr><tr><td><br />特征级参数</td><td>MFCC</td><td>模型</td><td>HMM</td></tr><tr><td><br />增强系数</td><td>0.8526</td><td>模态数</td><td>6</td></tr><tr><td><br />窗</td><td>Hamming</td><td>混合数</td><td>8</td></tr><tr><td><br />窗长、折叠率</td><td>25ms50%</td><td>最大迭代数</td><td>100</td></tr><tr><td><br />特征维度系数</td><td>12维度</td><td>终止迭代门限</td><td>5×10<sup>-8</sup></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="74">仿真使用文献<citation id="100" type="reference">[<a class="sup">1</a>]</citation>、文献<citation id="101" type="reference">[<a class="sup">2</a>]</citation>以及基于多核学习的多带抗噪声语音识别方法(CHMM),三种方法进行仿真对比实验。方法性能评判规则:常规情况下,识别率和运算速度是传统语音识别方法评判优劣的通用标准,基于文章侧重点,在现实多带噪声环境中有效识别正常语音,提高方法的抗噪声能力,因此仿真选取语音识别正确率来作为评判三种方法性能优劣的标准。设定未识别语音信息数量为T,其中已完成识别的信息正确数量为S,则正确率运算公式为</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>a</mi><mi>t</mi><mo>=</mo><mrow><mo>(</mo><mrow><mfrac><mi>S</mi><mi>Τ</mi></mfrac></mrow><mo>)</mo></mrow><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">表2是实验室环境中未加入多带噪声的测试集,根据不用方法运算得出的语音识别数据。</p>
                </div>
                <div class="area_img" id="77">
                    <p class="img_tit"><b>表2 实验室环境中识别方法运算精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="77" border="1"><tr><td><br />识别方法</td><td>识别率/%</td></tr><tr><td><br />文献[1]</td><td>90.43</td></tr><tr><td><br />文献[2]</td><td>90.69</td></tr><tr><td><br />CHMM</td><td>90.72</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="78">仿真结果分析:根据表2数据得出,文献<citation id="102" type="reference">[<a class="sup">2</a>]</citation>和CHMM,在未加入多带噪声的训练集中,语音识别率相近,说明CHMM在语音特征增强环节损失数据极少,没有使方法在常规环境下识别性能下降。</p>
                </div>
                <div class="p1">
                    <p id="79">通过图4到图6的对比分析,三种不同种类多带噪声中,当信噪比是45dB时,没有经过处理的文献<citation id="103" type="reference">[<a class="sup">1</a>]</citation>、文献<citation id="104" type="reference">[<a class="sup">2</a>]</citation>和做过加强语音特征处理的CHMM,都没有达到在实验室环境中的识别率,研究发现,在45dB时提取的语音特征中混有少量噪声声频,导致两种仿真环境实验参数不同,识别率下降。</p>
                </div>
                <div class="area_img" id="80">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910075_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 汽车噪声环境下识别率" src="Detail/GetImg?filename=images/JSJZ201910075_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 汽车噪声环境下识别率</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910075_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910075_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 人群噪声环境下识别率" src="Detail/GetImg?filename=images/JSJZ201910075_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 人群噪声环境下识别率</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910075_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJZ201910075_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 图书馆噪声环境下识别率" src="Detail/GetImg?filename=images/JSJZ201910075_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 图书馆噪声环境下识别率</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJZ201910075_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="83">同时三种方法中,CHMM在不同信噪比的环境中都能有效识别正常语音,并且识别率最高。这表示,利用多核学习组合算法能够改善实际测量条件和实验室训练条件不一致情况,使CHMM拥有能好的抗噪声能力,并且语音增强模块可以更好的提升方法在各类环境中适应性,符合现实需求。</p>
                </div>
                <div class="p1">
                    <p id="84">在低信噪比阶段中,多核学习下CHMM方法拥有较强的鲁棒性。在-15dB阶段图书馆噪声环境仿真中,CHMM与文献<citation id="105" type="reference">[<a class="sup">2</a>]</citation>和文献<citation id="106" type="reference">[<a class="sup">3</a>]</citation>比较,语音识别率分别提高了17%和13%。</p>
                </div>
                <h3 id="85" name="85" class="anchor-tag"><b>4 结论</b></h3>
                <div class="p1">
                    <p id="86">根据实际测量条件和实验室训练条件不一致,导致测量数据不可信问题,提出一种多核学习下多带抗噪声语音识别方法,通过多核学习组合算法使识别方法不受噪声分类条件的限定,并降低方法复杂性,随后利用语音特征加强技术,强化正常语音,减少实际环境和样本环境参数不一致现象,最终完成增强方法识别率,提高方法性能的目的。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2016S2010&amp;v=MTA4MDhIOWV2clk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25VN3JKTHo3QmI3RzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 李伟林,文剑,马文凯.基于深度神经网络的语音识别系统研究[J].计算机科学,2016,43(S2):45-49.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201806045&amp;v=MTgyOTJGeS9uVTdySkx6N0JkN0c0SDluTXFZOUJZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnA=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 曹晶晶,许洁萍,邵聖淇.多噪声环境下的层级语音识别模型[J].计算机应用,2018,38(06):1790-1794.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDKD201601007&amp;v=MjU0MzN5L25VN3JKUFNuQWFyRzRIOWZNcm85Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 孙涛,冯婕.快速随机多核学习分类算法[J].西安电子科技大学学报,2016,43(1):36-40.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201611006&amp;v=Mjc0MTBacEZ5L25VN3JKS0Q3WWJMRzRIOWZOcm85RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 张桂梅,孙晓旭,刘建新.基于自适应投影算法的分数阶全变分去噪模型[J].模式识别与人工智能,2016,29(11):1009-1018.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201608036&amp;v=MjQzNDl1WnBGeS9uVTdySkx6N0JkTEc0SDlmTXA0OUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 张晓丹,黄丽霞,张雪英.关于在噪声环境下语音识别优化研究[J].计算机仿真,2016,33(8):172-176,291.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZNXT201602010&amp;v=MTg2OTh0R0ZyQ1VSN3FmWnVacEZ5L25VN3JKUHlQVGVyRzRIOWZNclk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 张毅,谢延义,罗元,席兵.一种语音特征提取中Mel倒谱系数的后处理算法[J].智能系统学报,2016,11(2):208-215.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYWT201801015&amp;v=MTY5MDZxZlp1WnBGeS9uVTdySk5qVGNlckc0SDluTXJvOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 蓝阳,谢俊法,杨志鹏,崔保生.基于鲁棒自适应最小方差信号无畸变响应波束形成的高密度数据室内组合方法研究[J].石油物探,2018,57(1):104-112.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201706042&amp;v=MjI0OTlKTmlmWVpMRzRIOWJNcVk5QlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25VN3I=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 樊炳辉,卢凤,王鑫,刘圭圭.智能上假肢特定人语音识别系统实现[J].计算机工程与设计,2017,38(6):1630-1634.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201705020&amp;v=MjU2NjFyQ1VSN3FmWnVacEZ5L25VN3JKTHo3QmQ3RzRIOWJNcW85SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 李方伟,李骐,朱江.改进的基于隐马尔可夫模型的态势评估方法[J].计算机应用,2017,37(5):1331-1334,1340.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201604041&amp;v=MDkyNjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L25VN3JKTGpYQmZiRzRIOWZNcTQ5QlpZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 胡丹,曾庆宁,龙超.调制域谱减法用于鲁棒性语音识别[J].科学技术与工程,2016,16(4):216-220.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Speech recognition for school-age children and adults tested in multi-tone vs multi-noise-band maskers">

                                <b>[11]</b> E Buss,L J Leibold,C Lorenzi.Speech recognition for school-age children and adults tested in multi-tone vs multi-noise-band maskers[J].Journal of the Acoustical Society of America,2018,143(3):1458-1480.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" >
                                    <b>[12]</b>
                                 李伟林,文剑,马文凯.基于深度神经网络的语音识别系统研究[J].计算机科学,2016,43(Z11):45-49.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJZ201910075" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201910075&amp;v=MjQwMjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9uVTdySkx6N0JkTEc0SDlqTnI0OUNZWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRyNFB2YmhVNFRrV0FxZi9KeHFTZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
