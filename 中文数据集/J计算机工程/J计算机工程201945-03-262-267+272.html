<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130639992775000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201903044%26RESULT%3d1%26SIGN%3dDWH5Swe9RNhfVJIGgty1A0nqCGg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903044&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903044&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903044&amp;v=MTI4NDBMejdCYmJHNEg5ak1ySTlCWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk3bFc3dk4=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#40" data-title="1 小样本声纹识别算法 ">1 小样本声纹识别算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="1.1 原始语音信号预处理">1.1 原始语音信号预处理</a></li>
                                                <li><a href="#46" data-title="1.2 基于凸透镜成像的图像增多算法">1.2 基于凸透镜成像的图像增多算法</a></li>
                                                <li><a href="#54" data-title="1.3 FBN-Alexnet网络">1.3 FBN-Alexnet网络</a></li>
                                                <li><a href="#99" data-title="1.4 声纹识别">1.4 声纹识别</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="2 实验与结果分析 ">2 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#104" data-title="2.1 实验平台">2.1 实验平台</a></li>
                                                <li><a href="#113" data-title="2.2 实验训练集与测试集">2.2 实验训练集与测试集</a></li>
                                                <li><a href="#115" data-title="2.3 实验测量参数">2.3 实验测量参数</a></li>
                                                <li><a href="#119" data-title="2.4 声纹识别方法对比实验">2.4 声纹识别方法对比实验</a></li>
                                                <li><a href="#123" data-title="2.5 训练样本数对识别率的影响">2.5 训练样本数对识别率的影响</a></li>
                                                <li><a href="#127" data-title="2.6 迭代次数对识别率的影响">2.6 迭代次数对识别率的影响</a></li>
                                                <li><a href="#133" data-title="2.7 网络训练时间的对比实验">2.7 网络训练时间的对比实验</a></li>
                                                <li><a href="#137" data-title="2.8 结果分析">2.8 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#140" data-title="3 结束语 ">3 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="&lt;b&gt;图1 基于深度模型的小样本声纹识别流程&lt;/b&gt;"><b>图1 基于深度模型的小样本声纹识别流程</b></a></li>
                                                <li><a href="#45" data-title="&lt;b&gt;图2 语音信号-语谱图转换&lt;/b&gt;"><b>图2 语音信号-语谱图转换</b></a></li>
                                                <li><a href="#52" data-title="&lt;b&gt;图3 凸透镜成像原理&lt;/b&gt;"><b>图3 凸透镜成像原理</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;图4 Alexnet网络结构&lt;/b&gt;"><b>图4 Alexnet网络结构</b></a></li>
                                                <li><a href="#57" data-title="&lt;b&gt;图5 FBN-Alexnet网络结构&lt;/b&gt;"><b>图5 FBN-Alexnet网络结构</b></a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;图6 声纹识别软件操作界面截图&lt;/b&gt;"><b>图6 声纹识别软件操作界面截图</b></a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;图7 智能声纹信报箱实物图&lt;/b&gt;"><b>图7 智能声纹信报箱实物图</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;图8 智能声纹信报箱的实物连接图&lt;/b&gt;"><b>图8 智能声纹信报箱的实物连接图</b></a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;图9 智能声纹信报箱的原理图&lt;/b&gt;"><b>图9 智能声纹信报箱的原理图</b></a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;表1 4种方法识别率的比较&lt;/b&gt; %"><b>表1 4种方法识别率的比较</b> %</a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;图10 不同训练样本容量的声纹识别率&lt;/b&gt;"><b>图10 不同训练样本容量的声纹识别率</b></a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;表2 迭代次数对识别率的影响&lt;/b&gt;"><b>表2 迭代次数对识别率的影响</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;图11 迭代次数对Loss值变化的影响&lt;/b&gt;"><b>图11 迭代次数对Loss值变化的影响</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;表3 2种模型训练时间的比较&lt;/b&gt; h"><b>表3 2种模型训练时间的比较</b> h</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" SALEEM M M, HANSEN J H L.A discriminative unsupervised method for speaker recognition using deep learning[C]//Proceedings of IEEE International Workshop on Machine Learning for Signal Processing.Washington D.C., USA:IEEE Press, 2016:1-5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A discriminative unsupervised method for speaker recognition using deep learning">
                                        <b>[1]</b>
                                         SALEEM M M, HANSEN J H L.A discriminative unsupervised method for speaker recognition using deep learning[C]//Proceedings of IEEE International Workshop on Machine Learning for Signal Processing.Washington D.C., USA:IEEE Press, 2016:1-5.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 陈锦飞, 徐欣.基于梅尔频率倒谱系数与动态时间规整的安卓声纹解锁系统[J].计算机工程, 2017, 43 (2) :201-205." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201702033&amp;v=MTUwODVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdsVzd2TUx6N0JiYkc0SDliTXJZOUdaNFFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         陈锦飞, 徐欣.基于梅尔频率倒谱系数与动态时间规整的安卓声纹解锁系统[J].计算机工程, 2017, 43 (2) :201-205.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" BAE H S, LEE H J, LEE S G.Voice recognition based on adaptive MFCC and deep learning[C]//Proceedings of IEEE Conference on Industrial Electronics and Applications.Washington D.C., USA:IEEE Press, 2016:1542-1546." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Voice recognition based on adaptive MFCC and deep learning">
                                        <b>[3]</b>
                                         BAE H S, LEE H J, LEE S G.Voice recognition based on adaptive MFCC and deep learning[C]//Proceedings of IEEE Conference on Industrial Electronics and Applications.Washington D.C., USA:IEEE Press, 2016:1542-1546.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" AZMY M M.Classification of lung sounds based on linear prediction cepstral coefficients and support vector machine[C]//Proceedings of Applied Electrical Engineering and Computing Technologies.Washington D.C., USA:IEEE Press, 2015:1-5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classification of lung sounds based on linear prediction cepstral coefficients and support vector machine">
                                        <b>[4]</b>
                                         AZMY M M.Classification of lung sounds based on linear prediction cepstral coefficients and support vector machine[C]//Proceedings of Applied Electrical Engineering and Computing Technologies.Washington D.C., USA:IEEE Press, 2015:1-5.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 林舒都, 邵曦.基于i-vector和深度学习的说话人识别[J].计算机技术与发展, 2017, 27 (6) :66-71." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WJFZ201706015&amp;v=MDkxOTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdsVzd2TU1pZk5kTEc0SDliTXFZOUVZWVE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         林舒都, 邵曦.基于i-vector和深度学习的说话人识别[J].计算机技术与发展, 2017, 27 (6) :66-71.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" CIRESAN D D, MEIER U, MASCI J, et al.Flexible, high performance convolutional neural networks for image classification[C]//Proceedings of the International Joint Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2011:1237-1242." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Flexible,high performance convolutional neural networks for image classification">
                                        <b>[6]</b>
                                         CIRESAN D D, MEIER U, MASCI J, et al.Flexible, high performance convolutional neural networks for image classification[C]//Proceedings of the International Joint Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2011:1237-1242.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" ABDEL-HAMID O, MOHAMED A R, JIANG H, et al.Convolutional neural networks for speech recognition[J].IEEE/ACM Transactions on Audio Speech and Language Processing, 2014, 22 (10) :1533-1545." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for speech recognition">
                                        <b>[7]</b>
                                         ABDEL-HAMID O, MOHAMED A R, JIANG H, et al.Convolutional neural networks for speech recognition[J].IEEE/ACM Transactions on Audio Speech and Language Processing, 2014, 22 (10) :1533-1545.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" HUANG J T, LI J, GONG Y.An analysis of convolutional neural networks for speech recognition[C]//Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing.Washington D.C., USA:IEEE Press, 2015:4989-4993." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An analysis of convolutional neural networks for speech recognition">
                                        <b>[8]</b>
                                         HUANG J T, LI J, GONG Y.An analysis of convolutional neural networks for speech recognition[C]//Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing.Washington D.C., USA:IEEE Press, 2015:4989-4993.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" ZHANG Y, PEZESHKI M, BRAKEL P, et al.Towards end-to-end speech recognition with deep convolutional neural networks[EB/OL].[2017-11-12].https://arxiv.org/abs/1701.02720." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Towards end-to-end speech recognition with deep convolutional neural networks">
                                        <b>[9]</b>
                                         ZHANG Y, PEZESHKI M, BRAKEL P, et al.Towards end-to-end speech recognition with deep convolutional neural networks[EB/OL].[2017-11-12].https://arxiv.org/abs/1701.02720.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" OQUAB M, BOTTOU L, LAPTEV I, et al.Learning and transferring mid-level image representations using convolutional neural networks[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2014:1717-1724." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks">
                                        <b>[10]</b>
                                         OQUAB M, BOTTOU L, LAPTEV I, et al.Learning and transferring mid-level image representations using convolutional neural networks[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2014:1717-1724.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" KRIZHEVSKY A, SUTSKEVER I, HINTON G E.ImageNet classification with deep convolutional neural networks[C]//Proceedings of International Conference on Neural Information Processing Systems.Red Hook, USA:Curran Associates Inc., 2012:1097-1105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">
                                        <b>[11]</b>
                                         KRIZHEVSKY A, SUTSKEVER I, HINTON G E.ImageNet classification with deep convolutional neural networks[C]//Proceedings of International Conference on Neural Information Processing Systems.Red Hook, USA:Curran Associates Inc., 2012:1097-1105.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" LIU X, KAN M, WU W.et al.VIPLFaceNet:an open source deep face recognition SDK[J].Frontiers of Computer Science, 2017, 11 (2) :208-218." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=VIPLFace Net:an open source deep face recognition SDK">
                                        <b>[12]</b>
                                         LIU X, KAN M, WU W.et al.VIPLFaceNet:an open source deep face recognition SDK[J].Frontiers of Computer Science, 2017, 11 (2) :208-218.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" BEIGY H, MEYBODI M R.Adaptation of parameters of BP algorithm using learning automata[C]//Proceedings of Brazilian Symposium on Neural Networks.Washington D.C., USA:IEEE Press, 2000:24-31." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptation of parameters of BP algorithm using learning automata">
                                        <b>[13]</b>
                                         BEIGY H, MEYBODI M R.Adaptation of parameters of BP algorithm using learning automata[C]//Proceedings of Brazilian Symposium on Neural Networks.Washington D.C., USA:IEEE Press, 2000:24-31.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" KLINE D M, BERARDI V L.Revisiting squared-error and cross-entropy functions for training neural network classifiers[J].Neural Computing and Applications, 2005, 14 (4) :310-318." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001641790&amp;v=MDg2MTRveGNNSDdSN3FlYnVkdEZDN2xWYi9BSkZvPU5qN0Jhck80SHRITnFZdEVZK0lQWTNrNXpCZGg0ajk5U1hxUnJ4&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         KLINE D M, BERARDI V L.Revisiting squared-error and cross-entropy functions for training neural network classifiers[J].Neural Computing and Applications, 2005, 14 (4) :310-318.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 赵立辉, 毛竹, 霍春宝, 等.基于GMM-SVM的说话人识别系统研究[J].工矿自动化, 2014, 40 (5) :49-53." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MKZD201405013&amp;v=MzAyNjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N2xXN3ZNS0NiUmFyRzRIOVhNcW85RVo0UUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         赵立辉, 毛竹, 霍春宝, 等.基于GMM-SVM的说话人识别系统研究[J].工矿自动化, 2014, 40 (5) :49-53.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" 周国鑫, 高勇.基于GMM-UBM模型的说话人辨识研究[J].无线电工程, 2014, 44 (12) :14-17." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXDG201412005&amp;v=MjY1MDBGckNVUkxPZVplUm9GeTdsVzd2TU1qWFBhYkc0SDlYTnJZOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         周国鑫, 高勇.基于GMM-UBM模型的说话人辨识研究[J].无线电工程, 2014, 44 (12) :14-17.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(03),262-267+272 DOI:10.19678/j.issn.1000-3428.0049975            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于深度学习的小样本声纹识别方法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E9%9D%93&amp;code=37988081&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李靓</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%99%E5%AD%98%E5%A8%81&amp;code=38080186&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孙存威</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B0%A2%E5%87%AF&amp;code=24384852&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">谢凯</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B4%BA%E5%BB%BA%E9%A3%9A&amp;code=10472956&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贺建飚</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E6%B1%9F%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0112354&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长江大学电子信息学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E6%B1%9F%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0193746&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长江大学计算机科学学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%8D%97%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中南大学信息科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>利用小样本声纹作为训练集训练卷积神经网络 (CNN) 时, 网络不能达到较好的收敛状态, 从而导致识别率较低。为此, 提出一种新的声纹识别方法。利用深度CNN提取潜在的声纹特征, 在CNN训练过程中采用基于凸透镜成像原理的图像增多算法解决小样本训练样本不足的问题, 并在卷积过程中引入快速批量归一化 (FBN) 方法以提高网络收敛速度、缩短训练时间。在包含630人的TIMIT语音数据库中进行训练、验证和测试, 结果表明, FBN-Alexnet网络比Alexnet网络训练时间缩短48.2%, 与GMM、GMM-UBM及GMM-SVM方法相比, 该方法识别率分别提高7.3%、2.2%、2.8%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A3%B0%E7%BA%B9%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">声纹识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=FBN-Alexnet%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">FBN-Alexnet网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B0%8F%E6%A0%B7%E6%9C%AC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">小样本;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BF%AB%E9%80%9F%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">快速批量归一化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%A4%9A%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像增多算法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李靓 (1996—) , 男, 硕士研究生, 主研方向为语音信号处理、图像处理;;
                                </span>
                                <span>
                                    *孙存威 (通信作者) , 硕士研究生;;
                                </span>
                                <span>
                                    谢凯, 教授、博士生导师;;
                                </span>
                                <span>
                                    贺建飚, 副教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-04</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61272147);</span>
                                <span>湖北省教育厅项目 (B2015446);</span>
                                <span>长江大学青年基金 (2016cqn10);</span>
                                <span>大学生创新创业计划基金 (2017009);</span>
                    </p>
            </div>
                    <h1><b>Small Sample Voiceprint Recognition Method Based on Deep Learning</b></h1>
                    <h2>
                    <span>LI Jing</span>
                    <span>SUN Cunwei</span>
                    <span>XIE Kai</span>
                    <span>HE Jianbiao</span>
            </h2>
                    <h2>
                    <span>School of Electronic and Information, Yangtze University</span>
                    <span>School of Computer Science, Yangtze University</span>
                    <span>College of Information Science and Engineering, Central South University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>When training Convolutional Neural NetWork (CNN) with small sample voiceprints as training set, the network cannot reach a good convergence state, which results in low recognition rate.So, this paper proposes a new voiceprint recognition method.The proposed method uses deep CNN to extract the rich and latent features of voiceprint, which improves the voiceprint recognition rate.In order to solve the problem that small sample cannot train the CNN, this paper proposes an image increasing algorithm based on the principle of convex lens imaging.At the same time, the Fast Batch Normalization (FBN) is introduced in the convolutional process, which improves the speed of the network convergence and shortens the training time.Select a TIMIT speech database containing voices of 630 speakers for training, validating and testing.Experimental results show that, compared with the GMM, GMM-UBM, and GMM-SVM algorithms, the proposed method improves the recognition rate by 7.3%, 2.2%, and 2.8% and compared with the original network, the training time of the FBN-Alexnet network is reduced by 48.2%.It means that it is an effective method for voiceprint recognition of small samples.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=voiceprint%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">voiceprint recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=FBN-Alexnet%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">FBN-Alexnet network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=small%20sample&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">small sample;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Fast%20Batch%20Normalization%20(FBN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Fast Batch Normalization (FBN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20increasing%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image increasing algorithm;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-04</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="36">声纹识别是根据人特有的语音特征识别说话人身份的一种生物特征识别技术<citation id="145" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。在传统机器学习方法中, 特征选择是识别精度的关键。目前常见的特征提取包括Mel频率倒谱系数<citation id="142" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、线性预测倒谱系数<citation id="143" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、i-supervector<citation id="144" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>, 机器学习方法则主要有HMM-UBM、GMM、GMM-SVM。这些方法提取的特征具有单一性, 导致识别精度低, 尤其在噪音背景下的识别效果较差。</p>
                </div>
                <div class="p1">
                    <p id="37">随着深度学习时代的到来, 卷积神经网络 (Convolutional Neural Network, CNN) 在图片识别领域取得了较大的进展<citation id="146" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。相较于传统方法, CNN避免了手工提取特征表征能力不足的问题。近年来语音识别领域也引入了CNN<citation id="147" type="reference"><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>, 用CNN直接学习语谱图, 相比传统提取语音特征方式, 减少了在时域和频域上的信息损失。同时, 由于CNN局部连接和权值共享的特点, 使得CNN具有平移不变性, 因此能够克服语音信号本身多样性的问题。</p>
                </div>
                <div class="p1">
                    <p id="38">基于深度学习的声纹识别模型通过大量语音数据训练时, 可自动学习丰富的声学特征 (频谱、基音、共振峰等) , 提高了声纹识别率, 但是对小样本的声纹识别并不理想。因为训练好一个深层的CNN需要大量的训练样本, 学习数百万个网络参数<citation id="148" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 仅用小样本声纹作为训练集训练CNN, 网络并不能达到较好的收敛状态, 从而导致声纹识别率低。</p>
                </div>
                <div class="p1">
                    <p id="39">针对目前研究人员较少利用深度学习解决小样本声纹识别率低的问题, 本文提出一种深度模型下的小样本声纹识别方法。由于在实际工作中很难获得大量的声纹数据, 本文给出一种基于凸透镜成像的图像增多算法。此外, 在网络训练过程中, 由于存在网络层数较多、网络参数巨大、训练耗时以及网络拟合问题, 本文引入快速批量归一化 (Fast Batch Normalization, FBN) 方法, 以在训练FBN-Alexnet网络时加速网络收敛。</p>
                </div>
                <h3 id="40" name="40" class="anchor-tag">1 小样本声纹识别算法</h3>
                <div class="p1">
                    <p id="41">本文算法流程如图1所示。</p>
                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903044_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于深度模型的小样本声纹识别流程" src="Detail/GetImg?filename=images/JSJC201903044_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 基于深度模型的小样本声纹识别流程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903044_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="43" name="43">1.1 原始语音信号预处理</h4>
                <div class="p1">
                    <p id="44">在使用音频训练或测试模型之前, 由于语音信号具有短时不变性的特点, 本文对一段语音信号<i>x</i> (<i>t</i>) 进行分帧, 转化为<i>x</i> (<i>m</i>, <i>n</i>) (<i>m</i>为帧的个数, <i>n</i>为帧长) , 通过短时傅里叶变换得<i>X</i> (<i>m</i>, <i>n</i>) , 将<i>X</i> (<i>m</i>, <i>n</i>) 经<i>Y</i> (<i>m</i>, <i>n</i>) (<i>Y</i> (<i>m</i>, <i>n</i>) = <i>X</i> (<i>m</i>, <i>n</i>) ×<i>X</i> (<i>m</i>, <i>n</i>) ′) 变换得到周期图。根据时间将<i>m</i>变换为刻度<i>M</i>, 根据频率将<i>n</i>变换为刻度<i>N</i>, 将 (<i>M</i>, <i>N</i>, 10×lb 10<i>Y</i> (<i>m</i>, <i>n</i>) ) 画成二维图 (即语谱图) 。由原始语音信号生成的语谱图如图2所示。</p>
                </div>
                <div class="area_img" id="45">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903044_045.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 语音信号-语谱图转换" src="Detail/GetImg?filename=images/JSJC201903044_045.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 语音信号-语谱图转换</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903044_045.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="46" name="46">1.2 基于凸透镜成像的图像增多算法</h4>
                <div class="p1">
                    <p id="47">本文提出的图像增多算法采用凸透镜成像原理, 通过改变光谱图的大小获得更多的训练数据。</p>
                </div>
                <div class="p1">
                    <p id="48">将预处理得到的语谱图放在<i>P</i>点位置, 根据凸透镜成像原理:</p>
                </div>
                <div class="p1">
                    <p id="49">1) 当<i>P</i>点离透镜的距离大于<i>F</i>小于2<i>F</i> (<i>F</i>为透镜焦距) 时, 获得的图像比原始图像大, 如图3 (a) 所示。</p>
                </div>
                <div class="p1">
                    <p id="50">2) 当<i>P</i>点离透镜的距离为2<i>F</i>时, 获得的图像与原始图像一样大, 如图3 (b) 所示。</p>
                </div>
                <div class="p1">
                    <p id="51">3) 当<i>P</i>点离透镜的距离大于2<i>F</i>时, 获得的图像比原始图像小, 如图3 (c) 所示。</p>
                </div>
                <div class="area_img" id="52">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903044_052.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 凸透镜成像原理" src="Detail/GetImg?filename=images/JSJC201903044_052.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 凸透镜成像原理</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903044_052.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="53">通过3种变换可获得多张图像, 并将所有图像尺度归一化为227×227作为CNN的输入。</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54">1.3 FBN-Alexnet网络</h4>
                <div class="p1">
                    <p id="55">Alexnet<citation id="149" type="reference"><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>网络结构和FBN-Alexnet网络结构分别如图4、如图5所示。在图5中, S表示步幅, Pad表示补白。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903044_056.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 Alexnet网络结构" src="Detail/GetImg?filename=images/JSJC201903044_056.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 Alexnet网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903044_056.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="57">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903044_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 FBN-Alexnet网络结构" src="Detail/GetImg?filename=images/JSJC201903044_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 FBN-Alexnet网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903044_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="58">本文使用的FBN-Alexnet网络相比Alexnet有以下改进:</p>
                </div>
                <div class="p1">
                    <p id="59">1) 通过改变卷积核的数量和大小, 减少全连接层的节点数, FBN-Alexnet网络相比Alexnet网络降低了计算消耗。具体改变为:</p>
                </div>
                <div class="p1">
                    <p id="60"> (1) 用大小为9×9的卷积核替换11×11的卷积核 (CONV1→Conv1) 。</p>
                </div>
                <div class="p1">
                    <p id="61"> (2) 将大小为 5×5的卷积核分解为2层3×3的卷积核 (CONV2→Conv2和Conv3) 。</p>
                </div>
                <div class="p1">
                    <p id="62"> (3) 减少每一层网络的特征图数。</p>
                </div>
                <div class="p1">
                    <p id="63"> (4) 增加一层卷积层 (Conv7) 。</p>
                </div>
                <div class="p1">
                    <p id="64"> (5) 将第2层全连接层的节点数减半。</p>
                </div>
                <div class="p1">
                    <p id="65">2) 在实验过程中, 笔者发现通过Alexnet网络中的局部响应归一化进行参数初始化, 对网络训练效果较小, 于是去除局部响应归一化并且在ReLU激活函数之前加入FBN层, 对数据进行归一化, 加快网络的收敛速度。</p>
                </div>
                <div class="p1">
                    <p id="66">整个网络的训练过程如下:</p>
                </div>
                <h4 class="anchor-tag" id="67" name="67"> (1) 正向传播学习网络</h4>
                <div class="p1">
                    <p id="68">输入特征在每层中的神经元计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="69"><i>net</i><sup> (<i>l</i>+1) </sup>=<b><i>W</i></b><sup> (<i>l</i>+1) </sup><b><i>x</i></b><sup> (<i>l</i>) </sup>+<b><i>b</i></b><sup> (<i>l</i>+1) </sup>      (1) </p>
                </div>
                <div class="p1">
                    <p id="70"><b><i>x</i></b><sup> (<i>l</i>+1) </sup>=<i>s</i> (<i>FBN</i> (<i>net</i><sup> (<i>l</i>+1) </sup>) )      (2) </p>
                </div>
                <div class="p1">
                    <p id="71">其中, <b><i>x</i></b><sup> (<i>l</i>) </sup>是第<i>l</i>层的向量输出, <b><i>x</i></b><sup> (<i>l</i>+1) </sup>是第<i>l</i>+1层的向量输出, <b><i>W</i></b><sup> (<i>l</i>+1) </sup>是层间线性系数组成的矩阵, <b><i>b</i></b><sup> (<i>l</i>+1) </sup>是第 (<i>l</i>+1) 层的偏差组成的向量, <i>s</i> (·) 是激活函数, <i>FBN</i> (·) 为本文引入的FBN算法。</p>
                </div>
                <div class="p1">
                    <p id="72">设某层神经元的输出包含<i>t</i>维数据, <i>net</i>={<i>e</i><sup> (1) </sup>, <i>e</i><sup> (2) </sup>, …, <i>e</i><sup> (</sup><sup><i>t</i></sup><sup>) </sup>}, 在每个维度中, 独立应用归一化算法。样本容量为<i>s</i>的小批量数据样本, 表示为:<i>B</i><sub><i>e</i></sub>={<i>e</i><sub>1</sub>, <i>e</i><sub>2</sub>, …, <i>e</i><sub><i>s</i></sub>}, 样本数据归一化后的结果为:<i>B</i><sub><i>g</i></sub>={<i>g</i><sub>1</sub>, <i>g</i><sub>2</sub>, …, <i>g</i><sub><i>s</i></sub>}, <i>g</i><sub><i>i</i></sub> (<i>i</i>∈[1, <i>s</i>]) 服从<i>N</i> (0, 1) 分布, FBN算法具体执行见算法1。</p>
                </div>
                <div class="p1">
                    <p id="73"><b>算法1</b> FBN算法</p>
                </div>
                <div class="p1">
                    <p id="74"><b>输入</b> 小批量数据样本<i>B</i><sub><i>e</i></sub></p>
                </div>
                <div class="p1">
                    <p id="75"><b>输出</b> 归一化后的样本数据<i>B</i><sub><i>g</i></sub></p>
                </div>
                <div class="p1">
                    <p id="76">1.小批量均值为:<mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>μ</mtext><mo>=</mo><mfrac><mn>1</mn><mtext>s</mtext></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mn>1</mn></mrow><mtext>s</mtext></munderover><mtext>e</mtext></mstyle><msub><mrow></mrow><mtext>i</mtext></msub></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="78">2.样本方差为:<mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>σ</mtext><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mfrac><mn>1</mn><mtext>s</mtext></mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>i</mtext><mo>=</mo><mn>1</mn></mrow><mtext>s</mtext></munderover><mo stretchy="false"> (</mo></mstyle><mtext>e</mtext><msub><mrow></mrow><mtext>i</mtext></msub><mo>-</mo><mtext>μ</mtext><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="80">3.归一化后的样本值为:<mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>g</mtext><msub><mrow></mrow><mtext>i</mtext></msub><mo>=</mo><mfrac><mrow><mtext>e</mtext><msub><mrow></mrow><mtext>i</mtext></msub><mo>-</mo><mtext>μ</mtext></mrow><mtext>σ</mtext></mfrac></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="82">4.更新全局平均值为:μ<sub>B</sub>= (1-γ) μ<sub>B</sub>+γμ</p>
                </div>
                <div class="p1">
                    <p id="83">5.更新全局方差为:σ<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>B</mtext><mn>2</mn></msubsup></mrow></math></mathml>= (1-γ) σ<mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>B</mtext><mn>2</mn></msubsup></mrow></math></mathml>+γσ<sup>2</sup></p>
                </div>
                <div class="p1">
                    <p id="86">在算法1中, 初始化参数值<i>μ</i><sub><i>B</i></sub>=0, <i>σ</i><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>B</mi><mn>2</mn></msubsup></mrow></math></mathml>=1, γ=0.01。通过引入动量γ实现全局均值和方差的更新, 在测试阶段μ<sub>B</sub>及σ<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>B</mi><mn>2</mn></msubsup></mrow></math></mathml>取最后训练得到的值。</p>
                </div>
                <div class="p1">
                    <p id="89">在反向传播过程中, 对于损失函数L, 应用链式规则, 归一化层的反向传播梯度由式 (3) ～式 (5) 决定。</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mrow><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>g</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac></mrow></mstyle><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>μ</mi><mo stretchy="false">) </mo><mrow><mo stretchy="false"> (</mo><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mrow><mo>-</mo><mfrac><mn>3</mn><mn>2</mn></mfrac></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>μ</mi></mrow></mfrac><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mrow><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mtext>g</mtext><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac></mrow></mstyle><mspace width="0.25em" /><mo>⋅</mo><mfrac><mrow><mo>-</mo><mn>1</mn></mrow><mi>σ</mi></mfrac><mo>+</mo><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mspace width="0.25em" /><mo>⋅</mo><mfrac><mrow><mo>-</mo><mn>2</mn><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>μ</mi><mo stretchy="false">) </mo></mrow><mi>s</mi></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>g</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mspace width="0.25em" /><mo>⋅</mo><mfrac><mn>1</mn><mi>σ</mi></mfrac><mo>+</mo><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mspace width="0.25em" /><mo>⋅</mo><mfrac><mrow><mn>2</mn><mo stretchy="false"> (</mo><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>μ</mi><mo stretchy="false">) </mo></mrow><mi>s</mi></mfrac><mo>+</mo><mfrac><mn>1</mn><mi>s</mi></mfrac><mo>⋅</mo><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>μ</mi></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">在网络训练过程中任一层网络的参数变化都会引起后续神经网络各层输入的分布变化, 导致神经网络必须不断地适应新的数据分布, 这就要求更细致地调整参数、使用更小的学习率去训练, 并且由于在激活操作中存在非线性饱和问题, 使得网络训练更加困难。在算法1中, 将神经网络各层输入数据归一化为标准正态分布, 能够有效解决上述问题, 进而降低网络训练时间、加速网络收敛。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92"> (2) <i>BP</i>算法反向传播调整网络</h4>
                <div class="p1">
                    <p id="93">为了提高网络的自适应性, 利用<i>BP</i>算法<citation id="150" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>反向调整参数。由于方差损失函数权重更新过慢, 本文采用交叉熵代价函数<citation id="151" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 其优点是:误差大, 网络参数更新快;误差小, 网络参数更新慢。对于含N个声纹的样本集x={ (x<sup> (1) </sup>, y<sup> (1) </sup>) , (x<sup> (2) </sup>, y<sup> (2) </sup>) , …, (x<sup> (</sup><sup>N</sup><sup>) </sup>, y<sup> (</sup><sup>N</sup><sup>) </sup>) }, 交叉熵代价函数定义为:</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Γ</mi><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">[</mo></mstyle><mi>y</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mtext>l</mtext><mtext>b</mtext><mo stretchy="false"> (</mo><mi>o</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>y</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mtext>l</mtext><mtext>b</mtext><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>o</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">其中, N表示声纹训练样本容量, o<sup> (</sup><sup>i</sup><sup>) </sup>表示输入x<sup> (</sup><sup>i</sup><sup>) </sup>对应的实际输出, y<sup> (</sup><sup>i</sup><sup>) </sup>表示第i组数据对应的类别标记, y<sup> (</sup><sup>i</sup><sup>) </sup>∈{1, 2, …, k}, k是声纹类别的数目, 卷积层参数w和b的反向传播梯度由式 (7) 、式 (8) 决定。</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mo>∂</mo><mrow><mo>∂</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup></mrow></mfrac><mi>Γ</mi><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>x</mi></mstyle><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>o</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo>-</mo><mi>y</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mfrac><mo>∂</mo><mrow><mo>∂</mo><mi>b</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup></mrow></mfrac><mi>Γ</mi><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>o</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo>-</mo><mi>y</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">采用梯度下降法更新<i>CNN</i>网络参数, 使得网络输出层误差函数值达到最小。ρ为学习率, 每层参数w<sup> (</sup><sup>i</sup><sup>) </sup>和b<sup> (</sup><sup>i</sup><sup>) </sup>更新计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo>-</mo><mi>ρ</mi><mfrac><mo>∂</mo><mrow><mo>∂</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup></mrow></mfrac><mi>Γ</mi><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>b</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><mi>b</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo>-</mo><mi>ρ</mi><mfrac><mo>∂</mo><mrow><mo>∂</mo><mi>b</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup></mrow></mfrac><mi>Γ</mi><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="99" name="99">1.4 声纹识别</h4>
                <div class="p1">
                    <p id="100">对于输入<i>x</i>= (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>k</i></sub>) , 在第<i>i</i>类的概率<i>P</i><sub><i>i</i></sub>计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi>Ζ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi>Ζ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>k</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">其中, <i>Z</i><sub><i>i</i></sub>是Softmax层的输入, <i>P</i><sub><i>i</i></sub>是Softmax层的输出。最大<i>P</i><sub><i>i</i></sub>对应的声纹类别即为识别结果。</p>
                </div>
                <h3 id="103" name="103" class="anchor-tag">2 实验与结果分析</h3>
                <h4 class="anchor-tag" id="104" name="104">2.1 实验平台</h4>
                <div class="p1">
                    <p id="105">本文实验是在操作系统为UBUNTU1404, GPU为NVIDIA GEFORCE GTX 1050, 内存大小为16 GB, 软件平台为PYTHON3.5、TENSORFLOW1.2.1, 界面软件为跨平台的Qt的机器上实现的。图6所示为应用本文算法开发的一款小样本声纹识别软件操作界面。</p>
                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903044_106.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 声纹识别软件操作界面截图" src="Detail/GetImg?filename=images/JSJC201903044_106.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 声纹识别软件操作界面截图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903044_106.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="107">此外, 笔者还开发了一款基于声纹开锁的智能信报箱, 如图7所示。</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903044_108.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 智能声纹信报箱实物图" src="Detail/GetImg?filename=images/JSJC201903044_108.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 智能声纹信报箱实物图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903044_108.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="109">智能信报箱的实物连接如图8所示, 主要由1-树莓派 (自带WiFi模块) 、2-电子锁、3-电源适配器、4-继电器组成。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903044_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 智能声纹信报箱的实物连接图" src="Detail/GetImg?filename=images/JSJC201903044_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图8 智能声纹信报箱的实物连接图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903044_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="111">智能信报箱的原理图如图9所示, 在移动设备上采集语音信号, 并在服务器上执行特征提取和识别。通过服务器和移动端之间的通信以及服务器和树莓派之间的通信, 打开智能声纹信报箱, 用户可以在手机上完成整个过程。</p>
                </div>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903044_112.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 智能声纹信报箱的原理图" src="Detail/GetImg?filename=images/JSJC201903044_112.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图9 智能声纹信报箱的原理图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903044_112.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="113" name="113">2.2 实验训练集与测试集</h4>
                <div class="p1">
                    <p id="114">本文实验数据集来源于美国国家标准技术局的TIMIT数据库, 其中包括了630个来自美国不同区域的人 (每人10句话) 。在630人中任选430人构成训练集, 剩余200人作为验证集和测试集。截取每人10个2 s的wav格式语音片段, 对每个语音片段对应生成一张语谱图, 并将每张语谱图根据图像增多算法生成50张, 即训练集包括430×50张语谱图, 在剩余200×50张语谱图中, 验证集∶测试集=7∶3。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115">2.3 实验测量参数</h4>
                <div class="p1">
                    <p id="116">记识别正确的声纹数为<i>N</i><sub><i>r</i></sub>, 测试总声纹数为<i>N</i><sub><i>n</i></sub>, 声纹识别率<i>R</i>计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mi>r</mi></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">此外, 实验还需要测量网络训练时间、Loss函数值。</p>
                </div>
                <h4 class="anchor-tag" id="119" name="119">2.4 声纹识别方法对比实验</h4>
                <div class="p1">
                    <p id="120">本文方法与常用于语音识别的GMM<citation id="152" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、GMM-SVM<sup></sup><citation id="153" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、GMM-UBM<citation id="154" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>方法进行对比实验, 声纹识别结果如表1所示。</p>
                </div>
                <div class="area_img" id="121">
                    <p class="img_tit"><b>表1 4种方法识别率的比较</b> % <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="121" border="1"><tr><td><br />识别方法</td><td>识别率</td></tr><tr><td><br />GMM方法</td><td>91.3</td></tr><tr><td><br />GMM-SVM方法</td><td>95.8</td></tr><tr><td><br />GMM-UBM方法</td><td>96.4</td></tr><tr><td><br />FBN-Alexnet方法</td><td>98.6</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="122">从实验结果可以看出, 基于深度学习的声纹识别率高于传统识别模型。现阶段基于深度学习的声纹识别, 模型通过对大量数据训练, 自动学习数据的潜在特征, 包括MFCC特征、解剖学声学特征 (倒频谱、共振峰) 、韵律特征、通道信息等。而传统的识别模型学习语音的单一特征, 很难保证提取的语音特征的质量, 甚至可能会丢失一些重要特征。与传统识别模型相比, 深度模型能提取更多潜在的声学特征, 从而提高了声纹识别率。</p>
                </div>
                <h4 class="anchor-tag" id="123" name="123">2.5 训练样本数对识别率的影响</h4>
                <div class="p1">
                    <p id="124">在实验中, 采用FBN-Alexnet网络模型来测试训练样本数对识别率产生的影响, 将上述430人的声纹数据 (人均10、20、30、40、50个语谱图) 分别作为训练集, 将剩余200人的声纹数据 (人均10、20、30、40、50个语谱图) 作为验证和测试样本, 验证集∶测试集=7∶3。不同训练样本容量的识别率结果如图10所示。</p>
                </div>
                <div class="area_img" id="125">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903044_125.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 不同训练样本容量的声纹识别率" src="Detail/GetImg?filename=images/JSJC201903044_125.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图10 不同训练样本容量的声纹识别率</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903044_125.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="126">实验结果表明, 随着训练样本容量的增加, FBN-Alexnet网络模型的识别率呈现上升趋势, 结果符合模式识别的规律。训练样本越少, 识别率越低, 原因在于网络并没有达到收敛状态。当样本容量达到一定数目时, 网络到达收敛状态, 识别率可达98%以上。</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127">2.6 迭代次数对识别率的影响</h4>
                <div class="p1">
                    <p id="128">本文实验采用上述430×50张语谱图训练Alexnet网络和FBN-Alexnet网络, 在相同的训练集下比较FBN对网络收敛速度的影响。FBN-Alexnet网络的训练迭代次数不可避免地会对识别率有一定影响, 不同迭代次数条件下的识别率结果如表2所示。</p>
                </div>
                <div class="area_img" id="129">
                    <p class="img_tit"><b>表2 迭代次数对识别率的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="129" border="1"><tr><td><br />迭代次数</td><td>识别率/%</td></tr><tr><td><br />50</td><td>90.8</td></tr><tr><td><br />100</td><td>96.1</td></tr><tr><td><br />150</td><td>98.1</td></tr><tr><td><br />200</td><td>98.6</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="130">由表2可知, 随着迭代次数的增加, 声纹识别率逐渐提高。当网络达到收敛状态时, 随着迭代次数增加, 识别率趋于稳定。</p>
                </div>
                <div class="p1">
                    <p id="131">图11是训练过程中网络的损失函数输出值 (Loss值) 的变化, 反映了网络是否正确收敛。从图11可以看出, 随着网络训练的进行, Loss值越来越小;刚开始训练时, Loss值下降的速度快, 但随着训练迭代的进行, Loss值下降的速度趋于平稳, 并且波动性也较小。</p>
                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903044_132.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 迭代次数对Loss值变化的影响" src="Detail/GetImg?filename=images/JSJC201903044_132.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图11 迭代次数对Loss值变化的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903044_132.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="133" name="133">2.7 网络训练时间的对比实验</h4>
                <div class="p1">
                    <p id="134">本文实验设定Alexnet基础学习率为0.01, FBN-Alexnet的学习率为0.05, 网络整体代价误差 (Loss) 为0.01。5次网络训练时间的平均值如表3所示。</p>
                </div>
                <div class="area_img" id="135">
                    <p class="img_tit"><b>表3 2种模型训练时间的比较</b> h <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="135" border="1"><tr><td><br />模型</td><td>训练时间</td></tr><tr><td><br />Alexnet</td><td>4.27</td></tr><tr><td><br />FBN-Alexnet</td><td>2.21</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="136">实验结果表明, 在网络训练过程中, FBN发挥了良好的作用。FBN-Alexnet的网络训练时间比原Alexnet网络减少48.2%。这是由于FBN操作将数据归一化到零均值和单位方差, 能够加速收敛, 并用小批量的样本方差和均值代替总的样本方差和均值, 降低了计算量, 而且通过改进网络结构模型 (改变卷积核的大小和数量, 减少第2层全连接层的节点数) , 进一步减少了网络的运算消耗, 缩短了网络的训练时间。</p>
                </div>
                <h4 class="anchor-tag" id="137" name="137">2.8 结果分析</h4>
                <div class="p1">
                    <p id="138">本文方法摒弃了传统的语音识别框架, 采用基于语谱图和FBN-Alexnet神经网络的声纹识别方法。该方法的优势是语谱图充分包含了说话人的语音特点和FBN-Alexnet神经网络能够自动提取潜在的声纹特征, 相比传统的声纹识别方法只能获取单一特征, 能够显著提高声纹识别率。</p>
                </div>
                <div class="p1">
                    <p id="139">本文采用CNN架构以提升网络收敛速度。由于网络参数变化通常会导致网络各层的输入数据分布发生变化, 造成网络不同层的不同维度间的数据所需要的学习率不一样。在训练网络时, 通常需要选取最小的学习率来进行训练, 从而防止网络过拟合, 保证梯度的正常下降。FBN操作将数据归一化到零均值和单位方差, 即使用较大的学习率也能保证梯度的正常下降。此外, 通过改进网络模型, 进一步缩短了网络训练时间。</p>
                </div>
                <h3 id="140" name="140" class="anchor-tag">3 结束语</h3>
                <div class="p1">
                    <p id="141">本文提出一种深度模型下的小样本声纹识别方法, 将小样本语谱图通过图像增多算法生成多张语谱图, 解决在实际应用中声纹数据不足的问题。利用声纹数据训练FBN-Alexnet神经网络, 并在卷积过程中加入FBN, 加快网络收敛速度, 缩短网络训练时间。该方法利用深度FBN-Alexnet神经网络提取声纹潜在的特征, 提高了声纹识别率。在此基础上, 通过采用交叉熵损失函数自适应地调整网络参数, 使网络模型更适用于小样本声纹数据集, 进一步提高声纹识别率, 解决了传统语音识别模型和小样本声纹识别率低的问题。实验结果表明, 该方法比Alexnet网络训练时间缩短了48.2%, 识别率超过98%。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A discriminative unsupervised method for speaker recognition using deep learning">

                                <b>[1]</b> SALEEM M M, HANSEN J H L.A discriminative unsupervised method for speaker recognition using deep learning[C]//Proceedings of IEEE International Workshop on Machine Learning for Signal Processing.Washington D.C., USA:IEEE Press, 2016:1-5.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201702033&amp;v=MzIyNTh0R0ZyQ1VSTE9lWmVSb0Z5N2xXN3ZNTHo3QmJiRzRIOWJNclk5R1o0UUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 陈锦飞, 徐欣.基于梅尔频率倒谱系数与动态时间规整的安卓声纹解锁系统[J].计算机工程, 2017, 43 (2) :201-205.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Voice recognition based on adaptive MFCC and deep learning">

                                <b>[3]</b> BAE H S, LEE H J, LEE S G.Voice recognition based on adaptive MFCC and deep learning[C]//Proceedings of IEEE Conference on Industrial Electronics and Applications.Washington D.C., USA:IEEE Press, 2016:1542-1546.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classification of lung sounds based on linear prediction cepstral coefficients and support vector machine">

                                <b>[4]</b> AZMY M M.Classification of lung sounds based on linear prediction cepstral coefficients and support vector machine[C]//Proceedings of Applied Electrical Engineering and Computing Technologies.Washington D.C., USA:IEEE Press, 2015:1-5.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WJFZ201706015&amp;v=MDU0MTZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdsVzd2TU1pZk5kTEc0SDliTXFZOUU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 林舒都, 邵曦.基于i-vector和深度学习的说话人识别[J].计算机技术与发展, 2017, 27 (6) :66-71.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Flexible,high performance convolutional neural networks for image classification">

                                <b>[6]</b> CIRESAN D D, MEIER U, MASCI J, et al.Flexible, high performance convolutional neural networks for image classification[C]//Proceedings of the International Joint Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2011:1237-1242.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for speech recognition">

                                <b>[7]</b> ABDEL-HAMID O, MOHAMED A R, JIANG H, et al.Convolutional neural networks for speech recognition[J].IEEE/ACM Transactions on Audio Speech and Language Processing, 2014, 22 (10) :1533-1545.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An analysis of convolutional neural networks for speech recognition">

                                <b>[8]</b> HUANG J T, LI J, GONG Y.An analysis of convolutional neural networks for speech recognition[C]//Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing.Washington D.C., USA:IEEE Press, 2015:4989-4993.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Towards end-to-end speech recognition with deep convolutional neural networks">

                                <b>[9]</b> ZHANG Y, PEZESHKI M, BRAKEL P, et al.Towards end-to-end speech recognition with deep convolutional neural networks[EB/OL].[2017-11-12].https://arxiv.org/abs/1701.02720.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks">

                                <b>[10]</b> OQUAB M, BOTTOU L, LAPTEV I, et al.Learning and transferring mid-level image representations using convolutional neural networks[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2014:1717-1724.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">

                                <b>[11]</b> KRIZHEVSKY A, SUTSKEVER I, HINTON G E.ImageNet classification with deep convolutional neural networks[C]//Proceedings of International Conference on Neural Information Processing Systems.Red Hook, USA:Curran Associates Inc., 2012:1097-1105.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=VIPLFace Net:an open source deep face recognition SDK">

                                <b>[12]</b> LIU X, KAN M, WU W.et al.VIPLFaceNet:an open source deep face recognition SDK[J].Frontiers of Computer Science, 2017, 11 (2) :208-218.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptation of parameters of BP algorithm using learning automata">

                                <b>[13]</b> BEIGY H, MEYBODI M R.Adaptation of parameters of BP algorithm using learning automata[C]//Proceedings of Brazilian Symposium on Neural Networks.Washington D.C., USA:IEEE Press, 2000:24-31.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001641790&amp;v=MTI5OTdyTzRIdEhOcVl0RVkrSVBZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZDN2xWYi9BSkZvPU5qN0Jh&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> KLINE D M, BERARDI V L.Revisiting squared-error and cross-entropy functions for training neural network classifiers[J].Neural Computing and Applications, 2005, 14 (4) :310-318.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MKZD201405013&amp;v=MDYxMjc0SDlYTXFvOUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdsVzd2TUtDYlJhckc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 赵立辉, 毛竹, 霍春宝, 等.基于GMM-SVM的说话人识别系统研究[J].工矿自动化, 2014, 40 (5) :49-53.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXDG201412005&amp;v=MTQ1NjBGckNVUkxPZVplUm9GeTdsVzd2TU1qWFBhYkc0SDlYTnJZOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 周国鑫, 高勇.基于GMM-UBM模型的说话人辨识研究[J].无线电工程, 2014, 44 (12) :14-17.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201903044" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903044&amp;v=MTI4NDBMejdCYmJHNEg5ak1ySTlCWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk3bFc3dk4=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
