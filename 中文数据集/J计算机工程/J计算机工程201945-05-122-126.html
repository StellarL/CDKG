<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130530047686250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201905020%26RESULT%3d1%26SIGN%3dNq22bR0yzkUpBxC%252b0gbDFACouRc%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201905020&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201905020&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201905020&amp;v=MTAwNTR6cXFCdEdGckNVUkxPZVplUm9GeTNsV3JyUEx6N0JiYkc0SDlqTXFvOUhaSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#37" data-title="1 高斯混合模型 ">1 高斯混合模型</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#63" data-title="2 因子分解机 ">2 因子分解机</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#107" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#108" data-title="3.1 数据介绍">3.1 数据介绍</a></li>
                                                <li><a href="#120" data-title="3.2 性能分析">3.2 性能分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#129" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="&lt;b&gt;图1 GMM预测框架&lt;/b&gt;"><b>图1 GMM预测框架</b></a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;图2 training.txt文件数据格式&lt;/b&gt;"><b>图2 training.txt文件数据格式</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;表1 文件列名说明&lt;/b&gt;"><b>表1 文件列名说明</b></a></li>
                                                <li><a href="#123" data-title="&lt;b&gt;图3 不同因子分解维度下的AUC值对比&lt;/b&gt;"><b>图3 不同因子分解维度下的AUC值对比</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;图4 不同聚类数下的AUC值对比&lt;/b&gt;"><b>图4 不同聚类数下的AUC值对比</b></a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;图5 不同模型的AUC值对比&lt;/b&gt;"><b>图5 不同模型的AUC值对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" HE Xinran, PAN J F, JIN O, et al.Practical lessons from predicting clicks on ads at Facebook[C]//Proceedings of the 8th International Workshop on Data Mining for Online Advertising.New York, USA:ACM Press, 2014:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Practical lessons from predicting clicks on ads at facebook &amp;quot;">
                                        <b>[1]</b>
                                         HE Xinran, PAN J F, JIN O, et al.Practical lessons from predicting clicks on ads at Facebook[C]//Proceedings of the 8th International Workshop on Data Mining for Online Advertising.New York, USA:ACM Press, 2014:1-9.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 张志强, 周永, 谢晓芹, 等.基于特征学习的广告点击率预估技术研究[J].计算机学报, 2016, 39 (4) :780-794." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201604010&amp;v=MjU3ODNVUkxPZVplUm9GeTNsV3JyUEx6N0Jkckc0SDlmTXE0OUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         张志强, 周永, 谢晓芹, 等.基于特征学习的广告点击率预估技术研究[J].计算机学报, 2016, 39 (4) :780-794.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" WU Wei, LI Hang, XU Jun.Learning query and document similarities from click-through bipartite graph with metadata[C]//Proceedings of the 6th ACM International Conference on Web Search and Data Mining.New York, USA:ACM Press, 2013:687-696." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning query and document similarities from click-through bipartite graph with metadata">
                                        <b>[3]</b>
                                         WU Wei, LI Hang, XU Jun.Learning query and document similarities from click-through bipartite graph with metadata[C]//Proceedings of the 6th ACM International Conference on Web Search and Data Mining.New York, USA:ACM Press, 2013:687-696.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" XIONG Chenyan, WANG Taifeng, DING Wenkui, et al.Relational click prediction for sponsored search[C]//Proceedings of the 5th ACM International Conference on Web Search and Data Mining.New York, USA:ACM Press, 2012:493-502." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Relational click prediction for sponsored search">
                                        <b>[4]</b>
                                         XIONG Chenyan, WANG Taifeng, DING Wenkui, et al.Relational click prediction for sponsored search[C]//Proceedings of the 5th ACM International Conference on Web Search and Data Mining.New York, USA:ACM Press, 2012:493-502.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" KUMAR R, NAIK S M, NAIK V D, et al.Predicting clicks:CTR estimation of advertisements using Logistic regression classifier[C]//Proceedings of Advance Computing Conference.Washington D.C., USA:IEEE Press, 2015:13-16." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Predicting clicks:CTR estimation of advertisements using logistic regression classifier">
                                        <b>[5]</b>
                                         KUMAR R, NAIK S M, NAIK V D, et al.Predicting clicks:CTR estimation of advertisements using Logistic regression classifier[C]//Proceedings of Advance Computing Conference.Washington D.C., USA:IEEE Press, 2015:13-16.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" CHEN Qiaoheng, YU S M, GUO Zixuan, et al.Estimating ads’ click through rate with recurrent neural network[EB/OL].[2018-01-20].https://www.itm-conferences.org/articles/ itmconf/pdf/2016/02/itmconf_ita2016_04 001.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Estimating ads&amp;#39;&amp;#39; click through rate with recurrent neural network">
                                        <b>[6]</b>
                                         CHEN Qiaoheng, YU S M, GUO Zixuan, et al.Estimating ads’ click through rate with recurrent neural network[EB/OL].[2018-01-20].https://www.itm-conferences.org/articles/ itmconf/pdf/2016/02/itmconf_ita2016_04 001.pdf.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" LEE J, SHI Yong, WANG Fang, et al.Advertisement clicking prediction by using multiple criteria mathematical programming[J].World Wide Web, 2016, 19 (4) :707-724." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Advertisement clicking prediction by using multiple criteria mathematical programming">
                                        <b>[7]</b>
                                         LEE J, SHI Yong, WANG Fang, et al.Advertisement clicking prediction by using multiple criteria mathematical programming[J].World Wide Web, 2016, 19 (4) :707-724.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" FANG Z P, YUE K, ZHANG J X, et al.Predicting click-through rates of new advertisements based on the Bayesian network[EB/OL].[2018-01-20].https://www.hindawi.com/journals/mpe/2014/818203/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Predicting click-through rates of new advertisements based on the Bayesian network">
                                        <b>[8]</b>
                                         FANG Z P, YUE K, ZHANG J X, et al.Predicting click-through rates of new advertisements based on the Bayesian network[EB/OL].[2018-01-20].https://www.hindawi.com/journals/mpe/2014/818203/.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" WANG Xuerui, LI Wei, CUI Ying, et al.Click-through rate estimation for rare events in online advertising[EB/OL].[2018-01-20].http://www.cs.cmu.edu/～xuerui/papers/ctr.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Click-through rate estimation for rare events in online advertising">
                                        <b>[9]</b>
                                         WANG Xuerui, LI Wei, CUI Ying, et al.Click-through rate estimation for rare events in online advertising[EB/OL].[2018-01-20].http://www.cs.cmu.edu/～xuerui/papers/ctr.pdf.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 涂丹丹, 舒承椿, 余海燕.基于联合概率矩阵分解的上下文广告推荐算法[J].软件学报, 2013, 24 (3) :454-464." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201303002&amp;v=MjYzMjhaZVJvRnkzbFdyclBOeWZUYkxHNEg5TE1ySTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         涂丹丹, 舒承椿, 余海燕.基于联合概率矩阵分解的上下文广告推荐算法[J].软件学报, 2013, 24 (3) :454-464.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 朱志北, 李斌, 刘学军, 等.基于LDA的互联网广告点击率预测研究[J].计算机应用研究, 2016, 33 (4) :979-982." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201604004&amp;v=MTc2NzMzenFxQnRHRnJDVVJMT2VaZVJvRnkzbFdyclBMejdTWkxHNEg5Zk1xNDlGWUlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         朱志北, 李斌, 刘学军, 等.基于LDA的互联网广告点击率预测研究[J].计算机应用研究, 2016, 33 (4) :979-982.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 潘书敏, 颜娜, 谢瑾奎.基于用户相似度和特征分化的广告点击率预测研究[J].计算机科学, 2017, 44 (2) :283-289." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201702049&amp;v=MDAyMzVsV3JyUEx6N0JiN0c0SDliTXJZOUJiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTM=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         潘书敏, 颜娜, 谢瑾奎.基于用户相似度和特征分化的广告点击率预测研究[J].计算机科学, 2017, 44 (2) :283-289.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" 张宇.张宇带你学概率论与数理统计:浙大四版[M].北京:北京理工大学出版社, 2015." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787568209502000&amp;v=MzIwODREQk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWnU5dUZDdmpVN3JJS1ZzVFhGcXpHYmErRnRQTXBvcEZadXNQ&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         张宇.张宇带你学概率论与数理统计:浙大四版[M].北京:北京理工大学出版社, 2015.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" RENDLE S.Factorization machines[C]//Proceedings of IEEE International Conference on Data Mining.Washington D.C., USA:IEEE Press, 2011:995-1000." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Factorization machines">
                                        <b>[14]</b>
                                         RENDLE S.Factorization machines[C]//Proceedings of IEEE International Conference on Data Mining.Washington D.C., USA:IEEE Press, 2011:995-1000.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 纪文迪, 王晓玲, 周傲英.广告点击率估算技术综述[J].华东师范大学学报 (自然科学版) , 2013 (3) :2-14." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDSZ201303005&amp;v=MDc1ODM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5M2xXcnJQTFNuWWRMRzRIOUxNckk5RllZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         纪文迪, 王晓玲, 周傲英.广告点击率估算技术综述[J].华东师范大学学报 (自然科学版) , 2013 (3) :2-14.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(05),122-126 DOI:10.19678/j.issn.1000-3428.0050466            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于GMM-FMs的广告点击率预测研究</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%93%E8%B7%AF%E4%BD%B3&amp;code=39214480&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邓路佳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%B9%B3%E5%B1%B1&amp;code=29432266&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘平山</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=0269119&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林电子科技大学计算机与信息安全学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E5%95%86%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林电子科技大学商学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>传统单一模型对广告点击率 (CTR) 的预测效果较片面, 且广告日志数据存在稀疏性问题。为此, 将高斯混合模型 (GMM) 与因子分解机 (FM) 相结合, 建立一种广告点击率预测模型GMM-FMs。对原始数据集进行高斯聚类, 在聚类后得到的数据子集上分别建立CTR预测模型, 将多个预测模型的结果进行有效加权得到最终结果。实验结果表明, 相比传统逻辑回归与FM模型, 该模型在训练集与测试集比例不同时均能取得较高的AUC值。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广告点击率;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高斯混合模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%A0%E5%AD%90%E5%88%86%E8%A7%A3%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">因子分解机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E6%8D%AE%E7%A8%80%E7%96%8F%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数据稀疏性;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">逻辑回归模型;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    邓路佳 (1990—) , 男, 硕士, 主研方向为大数据、机器学习;;
                                </span>
                                <span>
                                    刘平山, 副教授、博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-02-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金“对等网络辅助的HTTP自适应流媒体视频点播云平台内容分发关键技术研究” (61762029);</span>
                                <span>广西自然科学基金面上项目 (2016GXNSFAA380011);</span>
                    </p>
            </div>
                    <h1><b>Research on Click-Through Rate Prediction of Advertisement Based on GMM-FMs</b></h1>
                    <h2>
                    <span>DENG Lujia</span>
                    <span>LIU Pingshan</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Information Security, Guilin University of Electronic Technology</span>
                    <span>School of Business, Guilin University of Electronic Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The traditional single model is one-sided in predicting the Click-Through Rate (CTR) of advertisement, and the data of advertisement log is sparse.To solve this problem, a GMM-FMs model for predicting advertisement CTR is established by combining the Gaussian Mixture Model (GMM) with Factorization Machine (FM) .The original data set is clustered based on the Gaussian mixture model, and the CTR prediction models are built on the clustered data subset.The results of multiple prediction models are weighted effectively to get the final results.Experimental results show that compared with the traditional Logistic Regression (LR) model and FM model, the proposed model achieves higher AUC values regardless of the training-set to test-set ratio.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=advertisement%20Click-Through%20Rate%20(CTR)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">advertisement Click-Through Rate (CTR) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gaussian%20Mixture%20Model%20(GMM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gaussian Mixture Model (GMM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Factorization%20Machine%20(FM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Factorization Machine (FM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=data%20sparsity&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">data sparsity;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Logistic%20Regression%20(LR)%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Logistic Regression (LR) model;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-02-09</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="34">目前, 搜索广告成为互联网的重要经济来源之一, 其对广告媒体的收益 (<i>Revenue</i><sub>ad</sub>) 等于广告真实点击率 (Click-Through Rate, CTR) 乘以广告每次被点击的费用 (Cost Per Click, CPC) 。为使收益最大化, 需要将广告按照<i>Revenue</i><sub>ad</sub>值从大到小的顺序进行展示。因此, 准确预测广告点击率, 将广告按照收益进行排序, 有助于提高广告媒体的收益, 给广告商的广告投放方向进行指导, 同时给用户推荐较感兴趣的广告, 以提高用户体验。</p>
                </div>
                <div class="p1">
                    <p id="35">近年来, 国内外学者对广告点击率的预测进行了较多研究。文献<citation id="131" type="reference">[<a class="sup">1</a>]</citation>通过梯度提升回归树挖掘广告特征之间的非线性关系, 以提高广告点击率的预测效果。文献<citation id="132" type="reference">[<a class="sup">2</a>]</citation>使用张量分解来解决广告数据的稀疏性问题, 并使用神经网络挖掘广告特征之间的非线性关系, 其取得了较好的效果, 但是整个计算过程过于复杂。文献<citation id="133" type="reference">[<a class="sup">3</a>]</citation>通过构建广告转移向量对点击率进行预测。文献<citation id="134" type="reference">[<a class="sup">4</a>]</citation>认为广告的点击率预测不局限于一个模型, 而应该由多个模型的预测结果整合而成。文献<citation id="135" type="reference">[<a class="sup">5</a>]</citation>采用逻辑回归 (Logistic Regression, LR) 模型进行广告点击率预测, 该模型受到业界较广泛的接受。文献<citation id="136" type="reference">[<a class="sup">6</a>]</citation>采用递归神经网络 (Recurrent Neural Networks, RNN) 对广告特征进行非线性分析与优化, 以提高广告点击率的预测效果。文献<citation id="137" type="reference">[<a class="sup">7</a>]</citation>采用多种模型来对广告点击率进行预测, 其中, MCLR (Multi-Criteria Linear Regression) 和KMCR (Kernel-based Multiple Criteria Regression) 方法在KDD 2012数据集上分别表现出了比SVR (Support Vector Regression) 与LR更好的预测效果, 且这2种方法的稳定性得到了验证。文献<citation id="138" type="reference">[<a class="sup">8</a>]</citation>分析展示次数较低的广告, 采用贝叶斯网络对这些广告进行点击率预测, 并取得了较好的效果。文献<citation id="139" type="reference">[<a class="sup">9</a>]</citation>对广告日志数据进行分层聚类, 以提高广告的点击率预测效果。文献<citation id="140" type="reference">[<a class="sup">10</a>]</citation>使用矩阵分解解决广告数据的稀疏性问题。文献<citation id="141" type="reference">[<a class="sup">11</a>]</citation>采用隐狄利克雷分配 (Latent Dirichlet Allocation, LDA) 模型对广告日志进行主题分割, 以提高广告点击率的预测效果。文献<citation id="142" type="reference">[<a class="sup">12</a>]</citation>将GMM与LR法相结合, 对广告点击率进行预测, 并取得了较好的效果。</p>
                </div>
                <div class="p1">
                    <p id="36">但上述研究在广告点击率预测过程中多数只使用单一方法, 即使使用到多个模型, 其相互之间也没有产生交互, 使得预测结果还是由单一方法决定, 最终使结果过于片面。针对该问题, 本文建立一种GMM-FMs (Gaussian Mixed Model-Factorization Machines) 点击率预测模型。该模型将广告日志数据使用GMM进行聚类, 使得每个聚类中的数据具有较高的相似度, 不同聚类的数据之间具有较低的相似度。在进行广告点击率预测的过程中, 采用因子分解机 (Factorization Machine, FM) 方法解决聚类簇中广告数据的稀疏性问题, 最终结合多个模型的结果获得整合预测结果。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag">1 高斯混合模型</h3>
                <div class="p1">
                    <p id="38">一条广告的点击率预估结果表示为:</p>
                </div>
                <div class="p1">
                    <p id="39" class="code-formula">
                        <mathml id="39"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>b</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mi>i</mi></msup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="40">其中, <b><i>x</i></b><sup><i>i</i></sup>表示第<i>i</i>条广告日志数据的特征向量, <i>K</i>表示聚类个数, <i>w</i><sub><i>ij</i></sub>表示<b><i>x</i></b><sup><i>i</i></sup>属于第<i>j</i>个聚类的概率值, 且<mathml id="41"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn><mo>, </mo><mi>b</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mi>i</mi></msup><mo stretchy="false">) </mo></mrow></math></mathml>表示<b><i>x</i></b><sup><i>i</i></sup>在第<i>j</i>个模型上的点击率预测值, <i>y</i>表示<b><i>x</i></b><sup><i>i</i></sup>最终的点击率预测值。图1所示为广告点击率的GMM预测框架。</p>
                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905020_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 GMM预测框架" src="Detail/GetImg?filename=images/JSJC201905020_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 GMM预测框架</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905020_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="43">从图1可以看出, 首先使用GMM对广告日志进行聚类, 然后在每个簇上学习点击率预测模型FM, 最后将从每个FM上获得的预测结果进行加权得到最终点击率预测结果。</p>
                </div>
                <div class="p1">
                    <p id="44">GMM能够模拟多数事物的分布, 其属于软聚类模型, 与K-means硬聚类方法不同的是:采用K-means聚类之后会将原始数据分成<i>K</i>个子集, 原始数据中的每一条数据只属于<i>K</i>个子聚类中的一个子聚类 (簇) , 而GMM将原始数据中的每条数据按照一定的比例分类到不同的簇, 因此, 一条广告将会按照一定的比例被归属于不同的广告子集, 该广告最终被预测出的点击率是由多个广告子集上的预测模型分别得到的预测结果整合而成。由于每个广告的特征向量之间相互独立, 为求得最终点击率, 首先要获知其分布律, 分布律表示为:</p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>β</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>, </mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">其中, <mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>β</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mn>1</mn><mo>, </mo><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>表示<b><i>x</i></b><sup><i>i</i></sup>对应的第<i>j</i>个高斯分布的概率密度<citation id="143" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 其公式如下:</p>
                </div>
                <div class="p1">
                    <p id="48" class="code-formula">
                        <mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mtext>π</mtext><mi>σ</mi><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></msqrt></mrow></mfrac><mrow><mi>exp</mi></mrow><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></mfrac></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mi>μ</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mi>σ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">}</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="49">其中, <i>μ</i><sub><i>j</i></sub>为均值, <i>σ</i><sub><i>j</i></sub>为方差。为求出所有的<i>β</i><sub><i>j</i></sub>、<i>θ</i><sub><i>j</i></sub>, 需要计算关于所有广告日志对应的特征向量<b><i>X</i></b>的似然函数。假设特征向量的个数为<i>s</i>, 则<b><i>X</i></b>={<i>x</i><sup>1</sup>, <i>x</i><sup>2</sup>, …, <i>x</i><sup><i>s</i></sup>}, 其似然函数为:</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><mo stretchy="false"> (</mo><mi>β</mi><mo>, </mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mi>p</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>β</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>j</mi></msub><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>β</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>j</mi></msub><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mtext>π</mtext><mi>σ</mi><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></msqrt></mrow></mfrac><mrow><mi>exp</mi></mrow><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></mfrac></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51">当<i>L</i> (<i>β</i>, <i>θ</i>) 为极大值时, 就可以获得<i>β</i>与<i>θ</i>的解。<i>L</i> (<i>β</i>, <i>θ</i>) 与其对数似然函数在相同的点达到极大值, 对对数似然函数进行计算往往更方便, 因此, 取<i>L</i> (<i>β</i>, <i>θ</i>) 在其似然函数的极大值情况下的所有参数取值, 如式 (5) 所示。</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false"> (</mo><mi>β</mi><mo>, </mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mtext>l</mtext></mstyle><mtext>b</mtext><mtext> </mtext><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>β</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mtext>π</mtext><mi>σ</mi><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></msqrt></mrow></mfrac><mrow><mi>exp</mi></mrow><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></mfrac></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">本文使用EM算法来估计所有的参数值。E步计算特征向量<b><i>x</i></b><sup><i>i</i></sup>属于第<i>j</i>个高斯分量的贝叶斯后验概率, 计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>β</mi><msub><mrow></mrow><mi>j</mi></msub><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>L</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>β</mi></mstyle><msub><mrow></mrow><mi>l</mi></msub><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>θ</mi><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">M步对参数<i>μ</i>、<i>σ</i>、<i>β</i>进行极大似然估计与更新:</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>μ</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mi>i</mi></msup></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>β</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>s</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">参数估计的具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="58"><b>步骤1</b> 随机初始化参数<i>μ</i>、<i>σ</i>、<i>β</i>。</p>
                </div>
                <div class="p1">
                    <p id="59"><b>步骤2</b> 计算式 (6) 的后验概率。</p>
                </div>
                <div class="p1">
                    <p id="60"><b>步骤3</b> 通过式 (7) ～式 (9) 更新参数。</p>
                </div>
                <div class="p1">
                    <p id="61"><b>步骤4</b> 比较更新后与更新前参数是否相同或者两者之差是否小于一定的阈值。如果结果相同或两者差值小于阈值, 则停止参数更新;否则, 返回步骤2。</p>
                </div>
                <div class="p1">
                    <p id="62">当EM算法结束后, 即可用式 (6) 计算广告日志的特征向量属于每个高斯分量的概率值<i>w</i><sub><i>ij</i></sub>。</p>
                </div>
                <h3 id="63" name="63" class="anchor-tag">2 因子分解机</h3>
                <div class="p1">
                    <p id="64">广告日志中存在连续型数据和离散型数据2种类型。其中, 离散型数据往往占据整个数据集中较大的比例, 因此, 其是广告预测中比较重要的部分。为使用离散数据, 需对其进行独热编码, 但这样需要巨大的矩阵来表示原始的数据空间, 最终使得矩阵的维度过高且矩阵中的大部分元素值为0, 这就是数据的稀疏现象。在面对稀疏数据时, 使用传统的模型 (如LR) 进行预测, 往往无法取得较好的预测效果, 原因是该类模型很难从稀疏的数据中获得特征之间的相关性。本文采用FM方法对稀疏性数据进行点击率预测。</p>
                </div>
                <div class="p1">
                    <p id="65">FM是在多项式的公式上演变而来。多元一次多项式的表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>y</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>w</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>+</mo><mo>⋯</mo><mo>+</mo><mi>w</mi><msub><mrow></mrow><mi>n</mi></msub><mi>x</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>w</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>n</mi><mo>∈</mo><msup><mrow></mrow><mo>+</mo></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">其中, <b><i>x</i></b>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>n</i></sub>}表示数据集中任意一条广告的特征向量, 其特征分量为<i>x</i><sub><i>N</i></sub> (<i>N</i>=1, 2, …, <i>n</i>) 。式 (10) 表示多个特征分量与<i>y</i> (<b><i>x</i></b>) 之间的关系, 但是其中的特征分量之间并没有关联, 因此, 采取该方法进行建模会使得预测结果过于简单, 不够全面。针对上述方法的不足, 文献<citation id="144" type="reference">[<a class="sup">14</a>]</citation>将式 (10) 改为式 (11) 。</p>
                </div>
                <div class="p1">
                    <p id="68"><mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">) </mo><mrow><mo>=</mo><mi>w</mi></mrow><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>w</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mi>n</mi><mo>∈</mo></mrow></math></mathml><image href="images/JSJC201905020_070.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup>+</sup>      (11) </p>
                </div>
                <div class="p1">
                    <p id="71">与式 (10) 相比, 式 (11) 增加了交叉项, 这样就体现出了特征分量之间的相互关系。但是, 直接在交叉项前增加一个系数, 并不能很好地体现出交叉项之间的关系<citation id="145" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。因此, 文献<citation id="146" type="reference">[<a class="sup">14</a>]</citation>对式 (11) 中的交叉项系数使用隐向量的内积进行表示, 以解决数据稀疏问题, 如下:</p>
                </div>
                <div class="p1">
                    <p id="72"><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>v</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>l</mi></mrow></msub><mi>v</mi><msub><mrow></mrow><mrow><mi>j</mi><mi>l</mi></mrow></msub><mo>, </mo><mi>k</mi><mo>∈</mo></mrow></math></mathml><image href="images/JSJC201905020_074.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup>+</sup>      (12) </p>
                </div>
                <div class="p1">
                    <p id="75">将式 (12) 中所有隐向量表示成矩阵的形式, 如下:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>×</mo><mi>k</mi></mrow></msub><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>v</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub><mo>, </mo><mi>v</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>v</mi><msub><mrow></mrow><mrow><mn>1</mn><mi>k</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mi>v</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>1</mn></mrow></msub><mo>, </mo><mi>v</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>v</mi><msub><mrow></mrow><mrow><mn>2</mn><mi>k</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mo>⋮</mo><mtext> </mtext><mo>⋮</mo><mtext> </mtext><mtext> </mtext><mo>⋮</mo></mtd></mtr><mtr><mtd columnalign="left"><mi>v</mi><msub><mrow></mrow><mrow><mi>n</mi><mn>1</mn></mrow></msub><mo>, </mo><mi>v</mi><msub><mrow></mrow><mrow><mi>n</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>v</mi><msub><mrow></mrow><mrow><mi>n</mi><mi>k</mi></mrow></msub></mtd></mtr></mtable></mrow><mo>}</mo></mrow><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mn>1</mn><mtext>Τ</mtext></msubsup></mtd></mtr><mtr><mtd columnalign="left"><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mn>2</mn><mtext>Τ</mtext></msubsup></mtd></mtr><mtr><mtd columnalign="left"><mo>⋮</mo></mtd></mtr><mtr><mtd columnalign="left"><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mi>n</mi><mtext>Τ</mtext></msubsup></mtd></mtr></mtable></mrow><mo>}</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">如果将所有的<b><i>x</i></b>表示为一个<b><i>X</i></b><sub><i>s</i>×<i>n</i></sub>的矩阵, 其中, <i>s</i>为广告数据的条数, <i>n</i>为数据的维度, 则矩阵的每一列对应一个隐向量, 即矩阵的第<i>i</i>列对应<b><i>V</i></b><sub><i>n</i>×<i>k</i></sub>中的第<i>i</i>行, 其中, <i>k</i>表示因子分解维度, 该值是使用函数时指定的初始值, 但是其大小往往远小于<i>n</i>, 这是由稀疏数据的特性所决定的。由于最终要使用FM作为分类器, 因此首先要计算模型中的参数, 包括<i>θ</i>={<i>w</i><sub>0</sub>, <i>w</i><sub><i>i</i></sub>, <i>v</i><sub><i>ij</i></sub>} (<i>i</i>∈<image href="images/JSJC201905020_078.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup>+</sup>, <i>j</i>∈<image href="images/JSJC201905020_079.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup>+</sup>) 。任意一条数据的观测值与预测值之差表示为:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula"><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mo stretchy="false"> (</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mrow><mspace width="0.25em" /><mo>—</mo></mrow></mover><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">|</mo><mi>θ</mi><mo stretchy="false">) </mo><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mtext>l</mtext><mtext>b</mtext></mrow></math></mathml><mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mrow><mspace width="0.25em" /><mo>—</mo></mrow></mover><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">|</mo><mi>θ</mi><mo stretchy="false">) </mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="83">其中, <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mrow><mspace width="0.25em" /><mo>—</mo></mrow></mover><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">|</mo><mi>θ</mi><mo stretchy="false">) </mo></mrow></math></mathml>为预测值, y为<b><i>x</i></b>对应的真实值。求取每条数据的观测值与预测值之差然后将这些差相加, 得到最小值后就可以获得参数<i>θ</i>的最终估计, 表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>θ</mi><mo>=</mo><mrow><mi>arg</mi></mrow><mrow><mi>min</mi></mrow><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mi>l</mi></mstyle><mo stretchy="false"> (</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mrow><mspace width="0.25em" /><mo>—</mo></mrow></mover><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mi>i</mi></msup><mo stretchy="false">|</mo><mi>θ</mi><mo stretchy="false">) </mo><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>θ</mi><msub><mrow></mrow><mi>p</mi></msub><mo>∈</mo><mi>θ</mi></mrow></munder><mi>λ</mi></mstyle><mi>θ</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">式 (15) 的最后一项表示引入的正则化项, 其目的是预防得到的模型过拟合。通过解式 (15) 可获得参数<i>θ</i>。以下为FM算法的具体过程:</p>
                </div>
                <div class="p1">
                    <p id="87"><b>算法1</b> FM算法</p>
                </div>
                <div class="area_img" id="148">
                                <img alt="" src="Detail/GetImg?filename=images/JSJC201905020_14800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="102">当算法1运行结束之后, FM模型就已经确定, 该模型对应式 (1) 中的<i>b</i> (<b><i>x</i></b>) 。</p>
                </div>
                <div class="p1">
                    <p id="103">此时, 训练模型中的参数已经被全部求出, 要用该模型对一条广告的点击率进行预测, 需要进行以下3个步骤:</p>
                </div>
                <div class="p1">
                    <p id="104">1) 将广告数据对应的广告特征向量直接带入式 (6) , 计算该广告属于每个高斯分布的概率。</p>
                </div>
                <div class="p1">
                    <p id="105">2) 将该广告带入每个高斯分布对应的FM进行点击率预测。</p>
                </div>
                <div class="p1">
                    <p id="106">3) 将每一个FM预测出的该广告的点击率结果对应乘以其属于高斯分布的概率, 然后求和, 得到的结果就为该广告的点击率预测值, 即式 (1) 的结果。</p>
                </div>
                <h3 id="107" name="107" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="108" name="108">3.1 数据介绍</h4>
                <div class="p1">
                    <p id="109">本文采用<i>KDD Cup</i> 2012 <i>track</i>2的数据 (<i>https</i>://<i>www</i>.<i>kaggle</i>.<i>com</i>/<i>c</i>/<i>kddcup</i>2012-<i>track</i>2/<i>data</i>) 进行实验。获得数据后进行解压, 数据集中包含6个文件, 训练数据在文件<i>training</i>.<i>txt</i>中, 其大小为9.87 <i>GB</i>, 一共有149 639 105条广告, 但其中包含很多非法数据, 如一些无法确定用户性别的数据, 因为性别对点击率的影响很大, 所以本文将不符合条件的数据删除, 并从中随机抽取100万条数据作为点击率预测的实验数据。点击率计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="110">点击率<mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mfrac><mrow><mtext>点</mtext><mtext>击</mtext><mtext>次</mtext><mtext>数</mtext></mrow><mrow><mtext>展</mtext><mtext>示</mtext><mtext>次</mtext><mtext>数</mtext></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="112">经计算, 抽取到的数据集点击率与总体数据集点击率分别为0.040 68与0.040 33, 可以看出, 抽取到的数据能够近似地完全体现原始数据的特征。<i>training</i>.<i>txt</i>文件的数据格式如图2所示。<i>training</i>.<i>txt</i>文件包含12列, 表1对每列列名进行说明。</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905020_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 training.txt文件数据格式" src="Detail/GetImg?filename=images/JSJC201905020_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 training.txt文件数据格式</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905020_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="114">
                    <p class="img_tit"><b>表1 文件列名说明</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="114" border="1"><tr><td>列号</td><td>英文列名</td><td>中文列名</td></tr><tr><td><br />1</td><td>Click</td><td>点击次数</td></tr><tr><td><br />2</td><td>Impression</td><td>展示次数</td></tr><tr><td><br />3</td><td>DisplayURL</td><td>展示URL</td></tr><tr><td><br />4</td><td>AdID</td><td>广告ID</td></tr><tr><td><br />5</td><td>AdvertiserID</td><td>广告商ID</td></tr><tr><td><br />6</td><td>Depth</td><td>广告深度</td></tr><tr><td><br />7</td><td>Position</td><td>广告位置</td></tr><tr><td><br />8</td><td>QueryID</td><td>查询词ID</td></tr><tr><td><br />9</td><td>KeywordID</td><td>关键词ID</td></tr><tr><td><br />10</td><td>TitleID</td><td>标题ID</td></tr><tr><td><br />11</td><td>DescriptionID</td><td>描述词ID</td></tr><tr><td><br />12</td><td>UserID</td><td>用户ID</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="115">在图2中, 除了第1列、第2列, 其他列都使用hash索引来替代。在解压的文件中还有其余5个文件, 分别为queryid_tokensid.txt、purchasedkeywordid_tokensid.txt、titleid_tokensid.txt、descriptionid_tokensid.txt、userid_profile.txt, 这些文件的内容分别与表1中第8行～第12行的数据一一对应, 即图2中的hash表示都可以从这5个文件中找到相应的hash表示的内容。最后将这5个文件的内容与trainning.txt文件的内容进行合并, 对合并得到的文件中由连续型数据表示的列进行归一化, 对由离散型数据表示的列进行独热编码处理, 即可获得训练用的数据的特征向量。</p>
                </div>
                <div class="p1">
                    <p id="116">数据归一化方法如下:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mo>=</mo><mfrac><mrow><mi>c</mi><mo>-</mo><mi>Μ</mi><mi>i</mi><mi>n</mi><mi>V</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi></mrow><mrow><mi>Μ</mi><mi>a</mi><mi>x</mi><mi>V</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo>-</mo><mi>Μ</mi><mi>i</mi><mi>n</mi><mi>V</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">其中, <i>c</i>为待归一化的输入数据, <i>MinValue</i>为一列数据中所有<i>c</i>中的最小值, <i>MaxValue</i>为所有<i>c</i>中的最大值。</p>
                </div>
                <div class="p1">
                    <p id="119">独热编码处理方法过程为:设有一列数据, 其特征名为“动物”, 且该列中有3行, 每行的列值分别为“老鼠”“狮子”“豹子”, 进行独热编码处理即用该列中的所有列值构建一个向量&lt;老鼠, 狮子, 豹子&gt;, 则每一行经过独热编码分别表示为:&lt;1, 0, 0&gt;, &lt;0, 1, 0&gt;, &lt;0, 0, 1&gt;。</p>
                </div>
                <h4 class="anchor-tag" id="120" name="120">3.2 性能分析</h4>
                <div class="p1">
                    <p id="121">本次实验的目的是提高广告点击率预测的准确度, 使用曲线下面积 (Area Under Cureve, AUC) <citation id="147" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>作为衡量指标, 该指标不受数据集正负比例不平衡的影响, 其值越高, 说明预测效果越好。</p>
                </div>
                <div class="p1">
                    <p id="122">FM的因子分解维度对预测结果有较大影响, 即<b><i>V</i></b><sub><i>n</i>×<i>k</i></sub>中<i>k</i>值的大小会影响预测效果。将数据集按照9∶1、8∶2、7∶3的比例分为训练集与测试集, 在不同因子分解维度下得到广告点击率预测的AUC值, 结果如图3所示。</p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905020_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同因子分解维度下的AUC值对比" src="Detail/GetImg?filename=images/JSJC201905020_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 不同因子分解维度下的AUC值对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905020_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="124">从图3可以看出, 随着因子分解维度的增加, AUC值会逐渐增加, 当因子分解维度达到4以后, AUC值开始保持一定幅度的上下波动, 说明其达到稳定状态。在图3中, 训练集与测试集的比例为9∶1、8∶2、7∶3时点击率的AUC值范围分别为 0.658～0.669、0.664～0.677、0.660～0.673。当因子分解维度为8时AUC值结果较好, 因此, 本文选择在该维度下使用GMM-FMs模型测试不同聚类数下的点击率预测情况, 结果如图4所示。</p>
                </div>
                <div class="area_img" id="125">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905020_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同聚类数下的AUC值对比" src="Detail/GetImg?filename=images/JSJC201905020_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 不同聚类数下的AUC值对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905020_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="126">从图4可以看出, 随着聚类数的增加, AUC值逐渐降低, 在聚类数为2时, AUC值最佳, 主要原因在于, 随着聚类数的增加, 每个簇中的数据逐渐减少, 导致在对每个簇进行模型训练时得不到足够的数据, 因此, 无法训练出良好的模型。在聚类数为2、训练集与测试集比例分别为9∶1、8∶2、7∶3时AUC值分别为0.695、0.697、0.690, 比FM模型相应最高值分别提高0.026、0.020、0.017。由此可以看出, 相比FM模型, GMM-FMs模型有较大的性能改进。</p>
                </div>
                <div class="p1">
                    <p id="127">本文将传统LR、FM、GMM-FMs模型进行性能比较, 结果如图5所示。从图5可以看出, 相比FM模型与传统LR模型, 本文GMM-FMs模型均有较高改进, 其AUC值比FM分别提升0.026、0.020、0.017, 比LR分别提升0.058、0.056、0.051。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905020_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同模型的AUC值对比" src="Detail/GetImg?filename=images/JSJC201905020_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 不同模型的AUC值对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905020_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="129" name="129" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="130">为提高广告点击率的预测效果, 本文建立一种GMM-FMs模型。将广告日志进行聚类, 使得在每个簇上训练出的点击率预测模型更具有针对性, 以此提高预测结果的准确度。对各模型的预测结果按照权重大小排序并进行整合, 以解决单一模型预测效果较片面的问题。实验结果验证了该模型的高效性与可行性。但本文未考虑广告特征之间的非线性因素对广告点击率预测结果的影响, 因此, 下一步将引入特征之间非线性关系的挖掘方法, 以提高广告点击率的预测效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Practical lessons from predicting clicks on ads at facebook &amp;quot;">

                                <b>[1]</b> HE Xinran, PAN J F, JIN O, et al.Practical lessons from predicting clicks on ads at Facebook[C]//Proceedings of the 8th International Workshop on Data Mining for Online Advertising.New York, USA:ACM Press, 2014:1-9.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201604010&amp;v=MTkyMjVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTNsV3JyUEx6N0Jkckc0SDlmTXE0OUVaSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 张志强, 周永, 谢晓芹, 等.基于特征学习的广告点击率预估技术研究[J].计算机学报, 2016, 39 (4) :780-794.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning query and document similarities from click-through bipartite graph with metadata">

                                <b>[3]</b> WU Wei, LI Hang, XU Jun.Learning query and document similarities from click-through bipartite graph with metadata[C]//Proceedings of the 6th ACM International Conference on Web Search and Data Mining.New York, USA:ACM Press, 2013:687-696.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Relational click prediction for sponsored search">

                                <b>[4]</b> XIONG Chenyan, WANG Taifeng, DING Wenkui, et al.Relational click prediction for sponsored search[C]//Proceedings of the 5th ACM International Conference on Web Search and Data Mining.New York, USA:ACM Press, 2012:493-502.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Predicting clicks:CTR estimation of advertisements using logistic regression classifier">

                                <b>[5]</b> KUMAR R, NAIK S M, NAIK V D, et al.Predicting clicks:CTR estimation of advertisements using Logistic regression classifier[C]//Proceedings of Advance Computing Conference.Washington D.C., USA:IEEE Press, 2015:13-16.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Estimating ads&amp;#39;&amp;#39; click through rate with recurrent neural network">

                                <b>[6]</b> CHEN Qiaoheng, YU S M, GUO Zixuan, et al.Estimating ads’ click through rate with recurrent neural network[EB/OL].[2018-01-20].https://www.itm-conferences.org/articles/ itmconf/pdf/2016/02/itmconf_ita2016_04 001.pdf.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Advertisement clicking prediction by using multiple criteria mathematical programming">

                                <b>[7]</b> LEE J, SHI Yong, WANG Fang, et al.Advertisement clicking prediction by using multiple criteria mathematical programming[J].World Wide Web, 2016, 19 (4) :707-724.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Predicting click-through rates of new advertisements based on the Bayesian network">

                                <b>[8]</b> FANG Z P, YUE K, ZHANG J X, et al.Predicting click-through rates of new advertisements based on the Bayesian network[EB/OL].[2018-01-20].https://www.hindawi.com/journals/mpe/2014/818203/.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Click-through rate estimation for rare events in online advertising">

                                <b>[9]</b> WANG Xuerui, LI Wei, CUI Ying, et al.Click-through rate estimation for rare events in online advertising[EB/OL].[2018-01-20].http://www.cs.cmu.edu/～xuerui/papers/ctr.pdf.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201303002&amp;v=MjczMzdCdEdGckNVUkxPZVplUm9GeTNsV3JyUE55ZlRiTEc0SDlMTXJJOUZab1FLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 涂丹丹, 舒承椿, 余海燕.基于联合概率矩阵分解的上下文广告推荐算法[J].软件学报, 2013, 24 (3) :454-464.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201604004&amp;v=MjI5ODk5Zk1xNDlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkzbFdyclBMejdTWkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 朱志北, 李斌, 刘学军, 等.基于LDA的互联网广告点击率预测研究[J].计算机应用研究, 2016, 33 (4) :979-982.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201702049&amp;v=MDM4OTQzbFdyclBMejdCYjdHNEg5Yk1yWTlCYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 潘书敏, 颜娜, 谢瑾奎.基于用户相似度和特征分化的广告点击率预测研究[J].计算机科学, 2017, 44 (2) :283-289.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787568209502000&amp;v=MjQ5NzBQTXBvcEZadXNQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3ZqVTdySUtWc1RYRnF6R2JhK0Z0&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 张宇.张宇带你学概率论与数理统计:浙大四版[M].北京:北京理工大学出版社, 2015.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Factorization machines">

                                <b>[14]</b> RENDLE S.Factorization machines[C]//Proceedings of IEEE International Conference on Data Mining.Washington D.C., USA:IEEE Press, 2011:995-1000.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDSZ201303005&amp;v=MjU4NzNJOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTNsV3JyUExTbllkTEc0SDlMTXI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 纪文迪, 王晓玲, 周傲英.广告点击率估算技术综述[J].华东师范大学学报 (自然科学版) , 2013 (3) :2-14.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201905020" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201905020&amp;v=MTAwNTR6cXFCdEdGckNVUkxPZVplUm9GeTNsV3JyUEx6N0JiYkc0SDlqTXFvOUhaSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
