<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130639897931250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201903041%26RESULT%3d1%26SIGN%3dhxuVhw%252fMmkSoaqDfhRWUxiiivq8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903041&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903041&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903041&amp;v=MjcwOTMzenFxQnRHRnJDVVJMT2VaZVJvRnk3bFc3ck1MejdCYmJHNEg5ak1ySTlCWllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="1 ACO算法 ">1 ACO算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="1.1 光流估计和图形构建">1.1 光流估计和图形构建</a></li>
                                                <li><a href="#63" data-title="1.2 前景分布和背景分布的初始概率估计">1.2 前景分布和背景分布的初始概率估计</a></li>
                                                <li><a href="#88" data-title="1.3 视频对象分割的前向传递">1.3 视频对象分割的前向传递</a></li>
                                                <li><a href="#139" data-title="1.4 ACO算法步骤">1.4 ACO算法步骤</a></li>
                                                <li><a href="#176" data-title="1.5 前景和背景的标签确定">1.5 前景和背景的标签确定</a></li>
                                                <li><a href="#191" data-title="1.6 视频对象分割的反向传递">1.6 视频对象分割的反向传递</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#193" data-title="2 仿真结果分析 ">2 仿真结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#194" data-title="2.1 数据集和评价指标">2.1 数据集和评价指标</a></li>
                                                <li><a href="#198" data-title="2.2 结果评估">2.2 结果评估</a></li>
                                                <li><a href="#205" data-title="2.3 步骤分析">2.3 步骤分析</a></li>
                                                <li><a href="#208" data-title="2.4 能量项分析">2.4 能量项分析</a></li>
                                                <li><a href="#211" data-title="2.5 多个重要对象的分割">2.5 多个重要对象的分割</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#215" data-title="3 结束语 ">3 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="&lt;b&gt;图1 ACO算法总体框架&lt;/b&gt;"><b>图1 ACO算法总体框架</b></a></li>
                                                <li><a href="#80" data-title="&lt;b&gt;图2 初始概率分布&lt;/b&gt;"><b>图2 初始概率分布</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;图3 平稳分布的聚类属性分析示意图&lt;/b&gt;"><b>图3 平稳分布的聚类属性分析示意图</b></a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;图4 基于时空分布的前景估计示意图&lt;/b&gt;"><b>图4 基于时空分布的前景估计示意图</b></a></li>
                                                <li><a href="#175" data-title="&lt;b&gt;图5&lt;/b&gt; “&lt;b&gt;跳水”视频各种能量组合最小化时获得的分布&lt;/b&gt;"><b>图5</b> “<b>跳水”视频各种能量组合最小化时获得的分布</b></a></li>
                                                <li><a href="#200" data-title="&lt;b&gt;表1 SegTrack数据集上各算法被错误标记像素的平均数量&lt;/b&gt;"><b>表1 SegTrack数据集上各算法被错误标记像素的平均数量</b></a></li>
                                                <li><a href="#202" data-title="&lt;b&gt;表2 不同算法的IoU得分比较&lt;/b&gt;"><b>表2 不同算法的IoU得分比较</b></a></li>
                                                <li><a href="#204" data-title="&lt;b&gt;图6 不同算法的视频对象分割结果比较&lt;/b&gt;"><b>图6 不同算法的视频对象分割结果比较</b></a></li>
                                                <li><a href="#207" data-title="&lt;b&gt;表3 各步骤后的IoU平均得分&lt;/b&gt;"><b>表3 各步骤后的IoU平均得分</b></a></li>
                                                <li><a href="#210" data-title="&lt;b&gt;表4 ACO算法采用不同能量组合时获得的IoU平均得分&lt;/b&gt;"><b>表4 ACO算法采用不同能量组合时获得的IoU平均得分</b></a></li>
                                                <li><a href="#213" data-title="&lt;b&gt;表5 SegTrack v2数据集上不同算法的IoU得分&lt;/b&gt;"><b>表5 SegTrack v2数据集上不同算法的IoU得分</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" WANG W, SHEN J, YANG R, et al.Saliency-aware video object segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018, 40 (1) :20-33." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Saliency-aware video object segmentation">
                                        <b>[1]</b>
                                         WANG W, SHEN J, YANG R, et al.Saliency-aware video object segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018, 40 (1) :20-33.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 苏亮亮, 唐俊, 梁栋, 等.基于最大化子模和RRWM的视频协同分割[J].自动化学报, 2016, 42 (10) :1532-1541." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201610007&amp;v=MTUwODlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N2xXN3JNS0NMZlliRzRIOWZOcjQ5Rlk0UUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         苏亮亮, 唐俊, 梁栋, 等.基于最大化子模和RRWM的视频协同分割[J].自动化学报, 2016, 42 (10) :1532-1541.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" SPAMPINATO C, PALAZZO S, GIORDANO D.Gamifying video object segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (10) :1942-1958." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gamifying video object segmentation">
                                        <b>[3]</b>
                                         SPAMPINATO C, PALAZZO S, GIORDANO D.Gamifying video object segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (10) :1942-1958.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" ENDRES I, HOIEM D.Category independent object proposals[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2010:575-588." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Category Independent Object Proposals">
                                        <b>[4]</b>
                                         ENDRES I, HOIEM D.Category independent object proposals[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2010:575-588.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" CHOCKALINGAM P, PRADEEP N, BIRCHFIELD S.Adaptive fragments-based tracking of non-rigid objects using level sets[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2009:1530-1537." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive Fragments-Based Tracking of Non-Rigid Objects Using Level Sets">
                                        <b>[5]</b>
                                         CHOCKALINGAM P, PRADEEP N, BIRCHFIELD S.Adaptive fragments-based tracking of non-rigid objects using level sets[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2009:1530-1537.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Barnich O, DROOGENBROECK M V.ViBe:a universal background subtraction algorithm for video sequences [J].IEEE Transactions on Image Processing, 2011, 20 (6) :1709-1724." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ViBe: A universal background subtraction algorithm for video sequences">
                                        <b>[6]</b>
                                         Barnich O, DROOGENBROECK M V.ViBe:a universal background subtraction algorithm for video sequences [J].IEEE Transactions on Image Processing, 2011, 20 (6) :1709-1724.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" BROX T, MALIK J.Object segmentation by long term analysis of point trajectories[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2010:282-295." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object segmentation by long term analysis of point trajectories">
                                        <b>[7]</b>
                                         BROX T, MALIK J.Object segmentation by long term analysis of point trajectories[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2010:282-295.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" GIORDANO D, MURABITO F, PALAZZO S, et al.Superpixel-based video object segmentation using perceptual organization and location prior [C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:4814-4822." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Superpixel-Based Video Object Segmentation Using Perceptual Organization and Location Prior">
                                        <b>[8]</b>
                                         GIORDANO D, MURABITO F, PALAZZO S, et al.Superpixel-based video object segmentation using perceptual organization and location prior [C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:4814-4822.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" OCHS P, BROX T.Higher order motion models and spectral clustering[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:614-621." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Higher order motion models and spectral clustering">
                                        <b>[9]</b>
                                         OCHS P, BROX T.Higher order motion models and spectral clustering[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:614-621.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" WANG W, SHEN J, PORIKLI F.Saliency-aware geodesic video object segmentation[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:3395-3402." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Saliency-aware geodesic video object segmentation">
                                        <b>[10]</b>
                                         WANG W, SHEN J, PORIKLI F.Saliency-aware geodesic video object segmentation[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:3395-3402.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" LEE Y J, KIM J, GRAUMAN K.Key-segments for video object segmentation[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEE Press, 2011:1995-2002." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Key-segments for video object segmentation">
                                        <b>[11]</b>
                                         LEE Y J, KIM J, GRAUMAN K.Key-segments for video object segmentation[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEE Press, 2011:1995-2002.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" MA T, LATECKI L J.Maximum weight cliques with mutex constraints for video object segmentation[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:670-677." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Maximum weight cliques with mutex constraints for video object segmentation">
                                        <b>[12]</b>
                                         MA T, LATECKI L J.Maximum weight cliques with mutex constraints for video object segmentation[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:670-677.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" PAPAZOGLOU A, FERRARI V.Fast object segmentation in unconstrained video[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2013:1777-1784." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast object segmentation in unconstrained video">
                                        <b>[13]</b>
                                         PAPAZOGLOU A, FERRARI V.Fast object segmentation in unconstrained video[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2013:1777-1784.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" ACHANTA R, SHAJI A, SMITH K, et al.SLIC superpixels compared to state-of-the-art superpixel methods[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (11) :2274-2282." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SLIC Superpixels Compared to State-of-the-Art Superpixel Methods">
                                        <b>[14]</b>
                                         ACHANTA R, SHAJI A, SMITH K, et al.SLIC superpixels compared to state-of-the-art superpixel methods[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (11) :2274-2282.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" ZHANG D, JAVED O, SHAH M.Video object segmentation through spatially accurate and temporally dense extraction of primary object regions[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2013:628-635." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Video object segmentation through spatially accurate and temporally dense extraction of primary object regions">
                                        <b>[15]</b>
                                         ZHANG D, JAVED O, SHAH M.Video object segmentation through spatially accurate and temporally dense extraction of primary object regions[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2013:628-635.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" BAMPIS C G, MARAGOS P, BOVIK A C.Graph-driven diffusion and random walk schemes for image segmentation[J].IEEE Transactions on Image Processing, 2017, 26 (1) :35-50." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Graph-driven diffusion and random walk schemes for image segmentation">
                                        <b>[16]</b>
                                         BAMPIS C G, MARAGOS P, BOVIK A C.Graph-driven diffusion and random walk schemes for image segmentation[J].IEEE Transactions on Image Processing, 2017, 26 (1) :35-50.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" BANJAC G, GOULART P, STELLATO B, et al.Infeasibility detection in the alternating direction method of multipliers for convex optimization[J].IEEE Transactions on Power Electronics, 2017, 32 (5) :4007-4020." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Infeasibility detection in the alternating direction method of multipliers for convex optimization">
                                        <b>[17]</b>
                                         BANJAC G, GOULART P, STELLATO B, et al.Infeasibility detection in the alternating direction method of multipliers for convex optimization[J].IEEE Transactions on Power Electronics, 2017, 32 (5) :4007-4020.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" GRANT M, BOYD S, YE Y.CVX:Matlab software for disciplined convex programming[M].Berlin, Germany:Springer, 2008:109-120." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CVX:Matlab software for disciplined convex programming">
                                        <b>[18]</b>
                                         GRANT M, BOYD S, YE Y.CVX:Matlab software for disciplined convex programming[M].Berlin, Germany:Springer, 2008:109-120.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" KANDA N, LU X, KAWAI H.Maximum-a-posteriori- based decoding for end-to-end acoustic models[J].IEEE/ACM Transactions on Audio, Speech, and Language Proessing, 2017, 25 (5) :1023-1034." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Maximum-a-posteriori- based decoding for end-to-end acoustic models">
                                        <b>[19]</b>
                                         KANDA N, LU X, KAWAI H.Maximum-a-posteriori- based decoding for end-to-end acoustic models[J].IEEE/ACM Transactions on Audio, Speech, and Language Proessing, 2017, 25 (5) :1023-1034.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(03),242-249 DOI:10.19678/j.issn.1000-3428.0050381            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种基于交替凸优化的视频对象分割算法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%99%E5%A9%B7&amp;code=23431332&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孙婷</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E8%89%BA%E6%9C%AF%E4%B8%8E%E4%BC%A0%E5%AA%92%E5%AD%A6%E9%99%A2&amp;code=0201951&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安工业大学艺术与传媒学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>现有视频对象分割方案多数存在应用场景受限、运动背景过分割等问题, 为此, 提出一种可从视频序列中自动检测重要对象的无监督视频对象分割算法。从前景和背景概率分布的角度引入马尔可夫能量、时空能量和对抗能量。将视频对象分割问题建模为基于3种混合能量最小化的非凸优化问题, 利用基于交替凸优化的方法将其分解为2个二次规划问题。采用前向-反向传递策略, 以充分利用时域相关性从而提高对象分割的可靠性。结合多种视频数据集进行仿真, 结果表明, 与其他最新的视频对象分割算法相比, 该算法的分割性能有明显提高。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E9%A2%91%E5%AF%B9%E8%B1%A1%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">视频对象分割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%A0%E7%9B%91%E7%9D%A3%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">无监督算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%BD%E9%87%8F%E6%9C%80%E5%B0%8F%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">能量最小化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%A4%E6%9B%BF%E5%87%B8%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">交替凸优化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">二次规划问题;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%89%8D%E5%90%91-%E5%8F%8D%E5%90%91%E7%AD%96%E7%95%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">前向-反向策略;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    孙婷 (1980—) , 女, 讲师、硕士, 主研方向为视觉传达设计、图像处理。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-02-01</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金面上项目 (61273072);</span>
                    </p>
            </div>
                    <h1><b>A Video Object Segmentation Algorithm Based on Alternation Convex Optimization</b></h1>
                    <h2>
                    <span>SUN Ting</span>
            </h2>
                    <h2>
                    <span>School of Art and Media, Xi'an Technological University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>There are some deficiencies while using existing schemes, such as limited application scenes and over segmentation of motion background.An unsupervised video object segmentation algorithm is proposed, which can automatically detect important objects from video sequences.Markov energy, time and space energy, as well as antagonism energy are introduced from the view of the foreground and background probability distribution.Then, the problem of detecting important objects from the background is modeled as a non convex optimization problem based on the mixed energy minimization, and a method based on Alternation Convex Optimization (ACO) is proposed to decompose the problem into two kinds of two quadratic programming problems.In order to make full use of time-domain correlation to improve the reliability of object segmentation, a forward-backward deliver strategy is also adopted.A comprehensive simulation is carried out based on a variety of video datasets.Experimental results show that the performance of the algorithm in this paper is significantly better than the other latest video object segmentation algorithms.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=video%20object%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">video object segmentation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=unsupervised%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">unsupervised algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=energy%20minimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">energy minimization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Alternation%20Convex%20Optimization%20(ACO)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Alternation Convex Optimization (ACO) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=quadratic%20programming%20problem&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">quadratic programming problem;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=forward-backward%20strategy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">forward-backward strategy;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-02-01</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="42">视频对象分割<citation id="217" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>从视频序列的背景中提取重要对象, 它是动作识别、视频检索、对象替换和视频融合等多种计算机视觉技术的基础。因此, 研究稳健的视频对象分割技术具有重要意义。然而, 视频背景带噪、对象遮挡及非刚性对象变形等因素使得视频对象分割的难度较大<citation id="218" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。研究者针对视频对象分割问题进行大量研究, 现有的视频对象分割算法主要分为有监督算法和无监督算法2种<citation id="219" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="43">有监督分割算法需要用户对重要对象进行标注, 具体包括非刚性对象跟踪算法<citation id="220" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>和交互式视频分割算法<citation id="221" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。非刚性对象跟踪算法采用人工方式标注出首帧中的重要对象, 然后在后续视频帧中对该对象进行跟踪。交互式视频分割算法先选择部分视频帧, 然后对其进行标注并从视频背景中检测出对</p>
                </div>
                <div class="p1">
                    <p id="44">象。然而, 这类算法的人工标注过程耗时耗力, 局限性较大。</p>
                </div>
                <div class="p1">
                    <p id="45">无监督分割算法不需要人工标注, 可从视频序列中自动提取对象, 该算法是目前研究的热点。文献<citation id="222" type="reference">[<a class="sup">6</a>]</citation>结合多种特征训练支持向量机 (Support Vector Machine, SVM) , 构建基于帧间时域一致性的背景模型, 并提出一种背景减除算法用于视频对象分割。然而, 背景减除技术假设相机位置固定或者移动缓慢, 因此, 该算法只适用于少部分场景。文献<citation id="223" type="reference">[<a class="sup">7</a>]</citation>通过对长时间点迹进行分组实现对象分割。该方法假设同一对象的关键点位于严格的仿射子空间上, 这在许多实际应用中尤其是出现非刚性对象时并不成立。文献<citation id="224" type="reference">[<a class="sup">8</a>]</citation>通过利用相邻视频帧的连续超级像素实现运动对象检测。该方法分割出的每一块区域必须对应一个独一无二的运动, 因此混合运动 (比如水流、树木) 条件下的背景将出现过分割的情况。文献<citation id="225" type="reference">[<a class="sup">9</a>]</citation>通过对点迹进行谱聚类算法处理实现对象分割。该算法的缺点是它只基于运动, 因此无法分割静止的对象。文献<citation id="226" type="reference">[<a class="sup">10</a>]</citation>提出一种基于显著性驱动和短程距的视频对象分割算法。该方法假设环境中各部位比较平坦, 因此不适用于背景或前景具有复杂动态外观的场景。</p>
                </div>
                <div class="p1">
                    <p id="46">针对上述不足, 本文从前景和背景概率分布角度引入马尔可夫能量、时空能量和对抗能量3种能量, 基于3种混合能量最小化对视频对象分割问题进行建模, 进而提出一种基于交替凸优化 (Alternation Convex Optimization, ACO) 的视频对象分割算法, 并与当前其他最新视频对象分割算法<citation id="227" type="reference"><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>进行对比分析。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag">1 ACO算法</h3>
                <div class="p1">
                    <p id="48">ACO算法的输入是一组连续的视频帧<mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>Ι</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup><mo>, </mo><mi>Ι</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ι</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msup></mrow><mo>}</mo></mrow></mrow></math></mathml>, 输出是一组可区分前景重要对象和背景的像素级二元标签图。图1给出ACO算法的框架。首先, 根据输入的视频帧进行光流估计和图形构建, 并利用各视频帧边界的先验信息进行流形排序, 估计前景分布和背景分布的初始概率。然后, 对前景分布和背景分布进行交替凸优化处理, 并得到前景和背景的二分分割标签 (即确定标签图) 。该过程逐帧完成, 利用前一个帧的标签图获取当前帧的标签图。具体来说, 采用前向-反向传递策略, 依次获得首个视频帧到最后一个视频帧的标签图, 并反向进行, 以提升其精度。最后, 对超级像素级的分割结果进行精炼, 获得最终的像素级对象分割结果。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903041_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 ACO算法总体框架" src="Detail/GetImg?filename=images/JSJC201903041_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 ACO算法总体框架</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903041_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="51" name="51">1.1 光流估计和图形构建</h4>
                <div class="p1">
                    <p id="52">首先对各个帧<i>τ</i>利用文献<citation id="228" type="reference">[<a class="sup">14</a>]</citation>中的SLIC算法分别估计从<mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msup><mrow></mrow><mrow><mrow><mo> (</mo><mi>τ</mi><mo>) </mo></mrow></mrow></msup></mrow></math></mathml>到<mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msup><mrow></mrow><mrow><mrow><mo> (</mo><mrow><mi>τ</mi><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow></mrow></msup></mrow></math></mathml>和<mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msup><mrow></mrow><mrow><mrow><mo> (</mo><mrow><mi>τ</mi><mo>-</mo><mn>2</mn></mrow><mo>) </mo></mrow></mrow></msup></mrow></math></mathml>的光流。然后根据估计得到的流形进行如下的图形构建:设<mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo>=</mo><mrow><mo> (</mo><mrow><mi>V</mi><mo>, </mo><mi>E</mi></mrow><mo>) </mo></mrow></mrow></math></mathml>表示一个图形, 其中, <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><mo>=</mo><mrow><mo>{</mo><mrow><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>Ν</mi></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>表示节点集合, <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo>=</mo><mrow><mo>{</mo><mrow><mi>e</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>表示边集合。为连接x<sub>i</sub>和x<sub>j</sub>的每条边e<sub>ij</sub>分配权重 (或者仿射性) w<sub>ij</sub>:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>exp</mi><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mi>d</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow><mo>, </mo><mi>e</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>∈</mo><mi>E</mi></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">其中, d表示特征空间中x<sub>i</sub>和x<sub>j</sub>间的距离, σ<sup>2</sup>表示尺度参数。此外, 为便于描述, 给出文中k环图的定义, 即当k增加时, k环图中的节点与更多其他节点相连。</p>
                </div>
                <div class="p1">
                    <p id="61"><b>定义1</b> 在<i>k</i>环图中, 如果对于任意的<i>n</i>≤<i>k</i>+1, 存在序列<mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>g</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mrow><mi>g</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>x</mi><msub><mrow></mrow><mrow><mi>g</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></msub><mo>=</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>) </mo></mrow></mrow></math></mathml>且序列中的每一对连续节点 (或者超级像素) 存在共同的边界, 则节点x<sub>i</sub>和x<sub>j</sub>存在一条边相连。</p>
                </div>
                <h4 class="anchor-tag" id="63" name="63">1.2 前景分布和背景分布的初始概率估计</h4>
                <div class="p1">
                    <p id="64">因为前景对象有可能出现在视频帧的中心附近, 所以边界区域往往属于背景<citation id="229" type="reference"><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。已知该边界先验知识后, 执行流形排序过程。首先, 计算仿射矩阵<mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">W</mi><mo>=</mo><mrow><mo>[</mo><mrow><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mo>]</mo></mrow></mrow></math></mathml>, 并定义一个查询向量<b><i>y</i></b>。例如, 若节点<i>i</i>表示一次查询, 则<b><i>y</i></b><sub><i>i</i></sub>=1;否则, <b><i>y</i></b><sub><i>i</i></sub>=0。然后, 通过公式<i>Π</i>=<b><i>D</i></b><sup>-1/2</sup><b><i>WD</i></b><sup>-1/2</sup>对仿射矩阵<b><i>W</i></b>进行对称正规化。其中, <b><i>D</i></b>表示对角矩阵, 其元素<i>d</i><sub><i>ii</i></sub>等于<b><i>W</i></b>第<i>i</i>行元素之和。然后, 排序向量<b><i>r</i></b>可表示为:</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">r</mi><mo>=</mo><mrow><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Ι</mi><mo>-</mo><mi>α</mi><mi mathvariant="bold-italic">Π</mi></mrow><mo>) </mo></mrow></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">y</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">其中, <i>α</i>表示[0, 1]间的参数。<b><i>r</i></b>中的元素<i>r</i><sub><i>i</i></sub>表示第<i>i</i>个节点相对查询节点的排序, 即第<i>i</i>个节点与图中查询节点的相似度。在本文中, 为确定第<i>τ</i>帧的初始前景分布和背景分布, 构建4-环图。同时, 结合Lab空间的平均色差以及<i>x</i><sub><i>i</i></sub>和<i>x</i><sub><i>j</i></sub>间的平均光流差异, 计算仿射矩阵<b><i>W</i></b><sup> (<i>τ</i>) </sup>的各个元素<i>w</i><mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="69">对于背景分布, 本文根据边界先验知识设置一个查询向量<b><i>y</i></b><mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">b</mi><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>。具体来说, 如果节点<b>j</b>位于图像边界, 则设置节点<b>j</b>的查询量<b><i>y</i></b><mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">b</mi><mo>, </mo><mi mathvariant="bold-italic">j</mi></mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>与<mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>1</mn><mo>/</mo><mrow><mi mathvariant="bold">m</mi><mi mathvariant="bold">a</mi><mi mathvariant="bold">x</mi></mrow><msub><mrow></mrow><mi mathvariant="bold-italic">i</mi></msub><mrow><mo>{</mo><mrow><mi mathvariant="bold-italic">π</mi><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">j</mi></mrow><mrow><mrow><mo> (</mo><mi mathvariant="bold-italic">τ</mi><mo>) </mo></mrow></mrow></msubsup></mrow><mo>}</mo></mrow></mrow></math></mathml>成正比, 否则为0, 如图2 (<b><i>b</i></b>) 所示。<mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">π</mi><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">j</mi></mrow><mrow><mrow><mo> (</mo><mi mathvariant="bold-italic">τ</mi><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>表示正规化仿射矩阵<mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Π</mi><msup><mrow></mrow><mrow><mrow><mo> (</mo><mi>τ</mi><mo>) </mo></mrow></mrow></msup></mrow></math></mathml>的元素。于是, 对于与大量类似节点相连的高拓展性节点, 为其分配较大的查询量。然后, 将<mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">y</mi><msubsup><mrow></mrow><mi>b</mi><mrow><mrow><mo> (</mo><mi>τ</mi><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>看作式 (2) 中的查询向量, 可获得排序向量<mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">r</mi><msubsup><mrow></mrow><mi>b</mi><mrow><mrow><mo> (</mo><mi>τ</mi><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>, 如图2 (<b>c</b>) 所示, 其中的<b><i>r</i></b><mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">b</mi><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>和图2 (<b><i>f</i></b>) 中的<mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">r</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mrow><mo> (</mo><mi>τ</mi><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>分别表示初始背景分布和前景分布。此外, 如果为所有边界节点分配相同的查询量, 则背景分布<mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">r</mi><msubsup><mrow></mrow><mrow><mi>b</mi><mo>, </mo><mtext>u</mtext><mtext>n</mtext><mtext>i</mtext><mtext>f</mtext><mtext>o</mtext><mtext>r</mtext><mtext>m</mtext></mrow><mrow><mrow><mo> (</mo><mi>τ</mi><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>可能只局限于边界内, 如图2 (<b><i>d</i></b>) 所示。</p>
                </div>
                <div class="area_img" id="80">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903041_080.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 初始概率分布" src="Detail/GetImg?filename=images/JSJC201903041_080.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 初始概率分布</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903041_080.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="81">另一方面, 对于前景分布, 通过<b><i>y</i></b><mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>f</mi><mo>, </mo><mi>i</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>∝exp (-<b><i>r</i></b><mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">b</mi><mo>, </mo><mi mathvariant="bold-italic">i</mi></mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>) 将背景分布<b><i>r</i></b><mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">b</mi><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>转化为前景查询向量<b><i>y</i></b><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>。然后, 计算相应的排序向量及初始前景分布<b><i>r</i></b><mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">f</mi><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>。从图2 (<b><i>f</i></b>) 可以看出, <b><i>r</i></b><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>可基本表示前景对象的形状。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88">1.3 视频对象分割的前向传递</h4>
                <div class="p1">
                    <p id="89">按照从首帧到末帧的顺序, 依次描述各个视频帧的主要对象。利用先前帧的分割结果来处理当前帧。出于简便考虑, 主要从前景分布<b><i>p</i></b><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>角度对算法进行描述 (可按照对称方式来处理背景分布<b><i>p</i></b><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>) 。设p<mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>f</mi><mo>, </mo><mi>i</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>表示在帧τ内第i个节点处发现前景对象的概率, 对于视频对象分割, 定义一个能量函数, 该函数由马尔可夫能量、时空能量及对抗能量构成, 下面依次描述这3种能量。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93">1) 马尔可夫能量</h4>
                <div class="p1">
                    <p id="94">马尔可夫随机游走过程模拟对象在图形上的运动<citation id="230" type="reference"><link href="31" rel="bibliography" /><link href="33" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>, 2个节点的特征越相似, 节点之间发生运动的概率就越大。根据马尔可夫理论可知, 视频对象从节点j运动到节点i的转移概率为:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>a</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>w</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>/</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">对象的运动可建模为:</p>
                </div>
                <div class="p1">
                    <p id="97"><b><i>p</i></b><sup> (<i>θ</i>+1) </sup>=<b><i>Ap</i></b><sup> (<i>θ</i>) </sup>      (4) </p>
                </div>
                <div class="p1">
                    <p id="98">其中, <i>θ</i>表示一个时间实例, <b><i>A</i></b>=[<i>a</i><sub><i>ij</i></sub>]表示转移矩阵。当平方距离‖<b><i>Ap</i></b><sup> (∞) </sup>-<b><i>p</i></b><sup> (∞) </sup>‖<sup>2</sup>最小化为0时可获得平稳分布<b><i>p</i></b><sup> (∞) </sup>。图3给出平稳分布的一个例子。从图3可以看出2个理想的聚类属性:首先, 平稳分布出现在聚类中心 (点密度较高的区域) 周围的概率较高, 出现在聚类边界 (点密度较低的区域) 上的概率较低。其次, 周围点的概率非常接近, 便于将这些点分配给相同的聚类。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903041_099.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 平稳分布的聚类属性分析示意图" src="Detail/GetImg?filename=images/JSJC201903041_099.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 平稳分布的聚类属性分析示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903041_099.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="100">为满足以上2个聚类属性, 定义如下的马尔可夫能量<i>ε</i><sub>M</sub>:</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><msub><mrow></mrow><mtext>Μ</mtext></msub><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>) </mo></mrow><mo>=</mo><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msup><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">∥</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">其中, <b><i>A</i></b><sup> (<i>τ</i>) </sup>表示可由仿射矩阵<b><i>W</i></b><sup> (<i>τ</i>) </sup>确定的帧<i>τ</i>的转移矩阵。当对象在图3 (c) 或图3 (d) 中的单个聚类内移动时, 马尔可夫能量也很少, 且满足前面描述的2个属性。对于某一特征空间, 图3 (c) 中的左侧聚类和图3 (d) 中的右侧聚类可分别对应于前景和背景。相反, 图3 (e) 和图3 (f) 中的均匀、随机分布导致能量较大。因此, 除马尔可夫能量<i>ε</i><sub>M</sub>外, 本文进一步考虑时空能量<i>ε</i><sub>S</sub>和对抗能量<i>ε</i><sub>A</sub>, 以便充分利用这些相互分离的聚类获得可靠的前景分布和背景分布。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103">2) 时空能量</h4>
                <div class="p1">
                    <p id="104">对各个视频帧, 第1.2节中的初始分布<b><i>r</i></b><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>是前景分布的粗略估计。然而, 逐帧估计缺乏时域一致性, 还不足以进行视频对象分割。于是, 将初始分布与先前帧的分割结果结合起来, 生成空域精准、时域相干的分割结果。对于视频帧τ, 要首先获得时域前景置信图<i>φ</i><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>。为此, 计算将帧<mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>τ</mi></mstyle><mo>∼</mo></mover></mrow></math></mathml>的前景标签传递给帧τ的传播矩阵<mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">C</mi><msup><mrow></mrow><mrow><mrow><mo> (</mo><mrow><mi>τ</mi><mo>, </mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>τ</mi></mstyle><mo>∼</mo></mover></mrow><mo>) </mo></mrow></mrow></msup></mrow></math></mathml>。如果光流显示在帧τ内第i个节点处至少有一个像素与帧<mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>τ</mi></mstyle><mo>∼</mo></mover></mrow></math></mathml>内第j个节点的像素相匹配, 则<mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">C</mi><msup><mrow></mrow><mrow><mrow><mo> (</mo><mrow><mi>τ</mi><mo>, </mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>τ</mi></mstyle><mo>∼</mo></mover></mrow><mo>) </mo></mrow></mrow></msup></mrow></math></mathml>中的元素<mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>c</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mrow><mo> (</mo><mrow><mi>τ</mi><mo>, </mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>τ</mi></mstyle><mo>∼</mo></mover></mrow><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>为1;否则为0。然后, 将先前2个帧的分割结果传输给当前帧τ, 获得时域置信图<i>φ</i><mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>:</p>
                </div>
                <div class="p1">
                    <p id="113"><i>φ</i><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>=<b><i>C</i></b><sup> (<i>τ</i>, <i>τ</i>-1) </sup><b><i>l</i></b><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>+<b><i>C</i></b><sup> (<i>τ</i>, <i>τ</i>-2) </sup><b><i>l</i></b><mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo>-</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="117">其中, <b><i>l</i></b><mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>和<b><i>l</i></b><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo>-</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>分别表示帧τ-1和τ-2的前景二元标签向量。然后计算时空分布:</p>
                </div>
                <div class="p1">
                    <p id="120"><b><i>s</i></b><mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>=<i>β</i>×<i>φ</i><sup> (<i>τ</i>) </sup><sub>f</sub>⨂<b><i>r</i></b><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="123">其中, ⨂表示逐个元素相乘, <i>β</i>表示对<b><i>s</i></b><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>进行正规化的常数。将时域估计<i>φ</i><mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>和空域估计<b><i>r</i></b><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>相乘, 得到的时空分布<b><i>s</i></b><mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>便是前景的准确分布, 如图4 (<i>f</i>) 所示。因此, 为保证前景分布与时空分布的相似性, 本文将时空能量ε<sub>s</sub>定义为:</p>
                </div>
                <div class="p1">
                    <p id="128" class="code-formula">
                        <mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><msub><mrow></mrow><mtext>s</mtext></msub><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>) </mo></mrow><mo>=</mo><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">s</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">∥</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903041_129.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 基于时空分布的前景估计示意图" src="Detail/GetImg?filename=images/JSJC201903041_129.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 基于时空分布的前景估计示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903041_129.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="130" name="130">3) 对抗能量</h4>
                <div class="p1">
                    <p id="131">对前景分布<b><i>p</i></b><mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>和背景分布<b><i>p</i></b><mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>进行比较后, 便可从背景中分割出前景对象。为保证分割的可靠性和准确性, 这2个分布应尽量为互斥区域, 即它们应该避免出现在同一区域中。为表述<b><i>p</i></b><mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>和<b><i>p</i></b><mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>间的这种互斥性, 本文将对抗能量定义为:</p>
                </div>
                <div class="p1">
                    <p id="136" class="code-formula">
                        <mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><msub><mrow></mrow><mtext>A</mtext></msub><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>, </mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>) </mo></mrow><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>Μ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>w</mi></mstyle></mrow></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mrow><mo> (</mo><mi>τ</mi><mo>) </mo></mrow></mrow></msubsup><mi>p</mi><msubsup><mrow></mrow><mrow><mi>f</mi><mo>, </mo><mi>i</mi></mrow><mrow><mrow><mo> (</mo><mi>τ</mi><mo>) </mo></mrow></mrow></msubsup><mi>p</mi><msubsup><mrow></mrow><mrow><mi>b</mi><mo>, </mo><mi>j</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="137">其中, M<sub>i</sub>表示节点i的邻居节点集合, <mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mrow><mo> (</mo><mi>τ</mi><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>表示帧<i>τ</i>内节点<i>i</i>和<i>j</i>间的仿射性。如果高概率前景节点被低概率背景相邻节点包围, 则对抗能量将会下降。因此, 当对抗能量较小时, 前景和背景将各自形成其支配区域。</p>
                </div>
                <h4 class="anchor-tag" id="139" name="139">1.4 ACO算法步骤</h4>
                <div class="p1">
                    <p id="140">将3个能量项综合起来, 形成1个混合能量项。为使标记更加简洁, 省略帧数上标。为获得最优的前景分布<b><i>p</i></b><sub><i>f</i></sub>和背景分布<b><i>p</i></b><sub><i>b</i></sub>, 使混合能量最小化:</p>
                </div>
                <div class="p1">
                    <p id="141"><i>ε</i> (<b><i>p</i></b><sub><i>f</i></sub>, <b><i>p</i></b><sub><i>b</i></sub>) =<i>ε</i><sub><i>M</i></sub> (<b><i>p</i></b><sub><i>f</i></sub>) +<i>ε</i><sub><i>M</i></sub> (<b><i>p</i></b><sub><i>b</i></sub>) +<i>γ</i>·<i>ε</i><sub><i>S</i></sub> (<b><i>p</i></b><sub><i>f</i></sub>) +</p>
                </div>
                <div class="p1">
                    <p id="142"><i>γ</i>·<i>ε</i><sub><i>S</i></sub> (<b><i>p</i></b><sub><i>b</i></sub>) +<i>δ</i>·<i>ε</i><sub><i>A</i></sub> (<b><i>p</i></b><sub><i>f</i></sub>, <b><i>p</i></b><sub><i>b</i></sub>)      (10) </p>
                </div>
                <div class="p1">
                    <p id="143">约束:</p>
                </div>
                <div class="p1">
                    <p id="144" class="code-formula">
                        <mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mn>0</mn><mo>≤</mo><mi>p</mi><msub><mrow></mrow><mrow><mi>f</mi><mo>, </mo><mi>i</mi></mrow></msub><mo>≤</mo><mn>1</mn><mo>, </mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mrow><mi>f</mi><mo>, </mo><mi>i</mi></mrow></msub><mo>=</mo><mn>1</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mn>0</mn><mo>≤</mo><mi>p</mi><msub><mrow></mrow><mrow><mi>b</mi><mo>, </mo><mi>i</mi></mrow></msub><mo>≤</mo><mn>1</mn><mo>, </mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mrow><mi>b</mi><mo>, </mo><mi>i</mi></mrow></msub><mo>=</mo><mn>1</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="145">在式 (10) 中, 非负参数<i>γ</i>和<i>δ</i>控制3个能量之间的平衡。假设<mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">p</mi><mo>=</mo><mrow><mrow><mo>[</mo><mrow><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>f</mi><mtext>Τ</mtext></msubsup><mo>, </mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>b</mi><mtext>Τ</mtext></msubsup></mrow><mo>]</mo></mrow></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>。于是, 式 (10) 中的混合能量可重写为:</p>
                </div>
                <div class="p1">
                    <p id="147" class="code-formula">
                        <mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>ε</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">p</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">B</mi><mi mathvariant="bold-italic">p</mi><mo>-</mo><mn>2</mn><mi>γ</mi><mrow><mo>[</mo><mrow><mi mathvariant="bold-italic">s</mi><msubsup><mrow></mrow><mi>f</mi><mtext>Τ</mtext></msubsup><mo>, </mo><mi mathvariant="bold-italic">s</mi><msubsup><mrow></mrow><mi>b</mi><mtext>Τ</mtext></msubsup></mrow><mo>]</mo></mrow><mi mathvariant="bold-italic">p</mi><mo>+</mo><mi>γ</mi><mi mathvariant="bold-italic">s</mi><msubsup><mrow></mrow><mi>f</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>f</mi></msub><mo>+</mo><mi>γ</mi><mi mathvariant="bold-italic">s</mi><msubsup><mrow></mrow><mi>b</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>b</mi></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">B</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><mo>+</mo><mi>γ</mi><mi mathvariant="bold-italic">Ι</mi></mtd><mtd><mfrac><mi>δ</mi><mn>2</mn></mfrac><mi mathvariant="bold-italic">W</mi></mtd></mtr><mtr><mtd><mfrac><mi>δ</mi><mn>2</mn></mfrac><mi mathvariant="bold-italic">W</mi></mtd><mtd><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><mo>+</mo><mi>γ</mi><mi mathvariant="bold-italic">Ι</mi></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="148">如果没有对抗能量<mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><msub><mrow></mrow><mtext>A</mtext></msub><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>f</mi></msub><mo>, </mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>b</mi></msub></mrow><mo>) </mo></mrow></mrow></math></mathml>, 则式 (14) 中的非对角子矩阵将为0, <b><i>B</i></b>将为半正定矩阵。此时, <i>ε</i> (<b><i>p</i></b>) 在约束条件式 (11) 和式 (12) 下的最小化问题成为利用拉格朗日乘子等方法便可求解的二次规划问题<citation id="231" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。然而, 对抗能量项使<b><i>B</i></b>成为不定矩阵, 混合能量最小化问题成为难以求解的非凸问题。为此, 本文提出ACO算法, 将非凸问题分解为2个凸子问题进行求解。首先, 固定背景分布<b><i>p</i></b><sub><i>b</i></sub>后, 求解约束式 (11) 下的二次规划问题:</p>
                </div>
                <div class="p1">
                    <p id="150" class="code-formula">
                        <mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>f</mi></msub></mrow></munder><mrow><mo>{</mo><mrow><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>f</mi><mtext>Τ</mtext></msubsup><mo stretchy="false"> (</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><mo>+</mo><mi>γ</mi><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>f</mi></msub><mo>-</mo><mo stretchy="false"> (</mo><mn>2</mn><mi>γ</mi><mi mathvariant="bold-italic">s</mi><msubsup><mrow></mrow><mi>f</mi><mtext>Τ</mtext></msubsup><mo>-</mo><mi>δ</mi><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>b</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">W</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>f</mi></msub></mrow><mo>}</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="151">然后使用式 (15) 获得的<b><i>p</i></b><sub><i>f</i></sub>, 进一步求解式 (12) 约束下的另外一个二次规划问题, 便可对背景分布<b><i>p</i></b><sub><i>b</i></sub>进行更新。</p>
                </div>
                <div class="p1">
                    <p id="152" class="code-formula">
                        <mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>b</mi></msub></mrow></munder><mrow><mo>{</mo><mrow><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>b</mi><mtext>Τ</mtext></msubsup><mo stretchy="false"> (</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><mo>+</mo><mi>γ</mi><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>b</mi></msub><mo>-</mo><mo stretchy="false"> (</mo><mn>2</mn><mi>γ</mi><mi mathvariant="bold-italic">s</mi><msubsup><mrow></mrow><mi>b</mi><mtext>Τ</mtext></msubsup><mo>-</mo><mi>δ</mi><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>f</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">W</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>b</mi></msub></mrow><mo>}</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="153">ACO算法具体过程如下:</p>
                </div>
                <div class="p1">
                    <p id="154"><b>算法</b> ACO算法</p>
                </div>
                <div class="p1">
                    <p id="155"><b>输入</b> 帧<i>τ</i>的图<i>G</i>及先前帧的标签向量</p>
                </div>
                <div class="p1">
                    <p id="156"><b>输出</b> 前景分布<b><i>p</i></b><mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>和背景分布<b><i>p</i></b><mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="159"><b>步骤1</b> 利用式 (1) 和式 (3) 计算仿射矩阵和转移矩阵。</p>
                </div>
                <div class="p1">
                    <p id="160"><b>步骤2</b> 利用式 (2) 计算初始分布<b><i>r</i></b><mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>和<b><i>r</i></b><mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="163"><b>步骤3</b> 利用式 (7) 计算时空分布<b><i>s</i></b><mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>和<b><i>s</i></b><mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="166"><b>步骤4</b> 重复步骤1～步骤3。</p>
                </div>
                <div class="p1">
                    <p id="167"><b>步骤5</b> 利用式 (15) 进行前景分布<b><i>p</i></b><mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>的优化。</p>
                </div>
                <div class="p1">
                    <p id="169"><b>步骤6</b> 利用式 (16) 进行背景分布<b><i>p</i></b><mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>的优化。</p>
                </div>
                <div class="p1">
                    <p id="171"><b>步骤7</b> 利用式 (10) 进行前景和背景分布的交替凸优化, 直到<mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>, </mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>) </mo></mrow></mrow></math></mathml>停止下降。</p>
                </div>
                <div class="p1">
                    <p id="173">利用文献<citation id="232" type="reference">[<a class="sup">18</a>]</citation>中的软件可依次求解上述2个二次规划问题。<i>ACO</i>算法的运算复杂度主要取决于其中的步骤5和步骤6, 即求解凸二次规划问题的时间开销。该算法在求解过程中, 采用交替凸优化的策略, 即先固定背景分布来优化获得的前景分布, 然后利用前景分布来优化背景分布 (求解式 (15) 时, 初始分布<b><i>r</i></b><sub><i>b</i></sub>被当作是背景分布<b><i>p</i></b><sub><i>b</i></sub>) 。由文献<citation id="233" type="reference">[<a class="sup">18</a>]</citation>可知, 上述2个二次规划问题的计算开销都为多项式时间, 由于式 (15) 和式 (16) 中的二次规划问题, 式 (13) 中的混合能量单调下降且有下限, 因此交替进行的方式可以收敛且生成一个局部最优解。此外, 该算法的空间复杂度主要在于保存迭代过程中的变量值, 假设算法需要<i>n</i>步迭代来计算局部最优解, 每一步迭代需要计算<i>m</i>个子项, 则该算法的空间复杂度为<i>O</i> (<i>m</i>×<i>n</i>) 。因此, 无论从计算时间还是所需的存储空间来看, 该算法的开销都是可以接受的。</p>
                </div>
                <div class="p1">
                    <p id="174">本文以“跳水”视频为例, 分析各个能量项对最终获得的分布的影响, 结果如图5所示。其中, 边框表示实况对象的轮廓。将3个能量项中的某一项删除后分析其作用。图5 (a) 没有马尔可夫能量项<i>ε</i><sub>M</sub>, 此时分布没有按照节点的仿射性扩散且背景分布没有覆盖对象边界周围区域。图5 (b) 没有时空能量项<i>ε</i><sub><i>S</i></sub>, 此时时域和空域相关性没有得到利用, 因此, 前景分布只集中在一些超级像素上。图5 (c) 没有对抗能量项<i>ε</i><sub><i>A</i></sub>, 此时前景和背景分布均检测到对象, 且背景检测的效果更好。然而, 由于2个分布间没有交互, 前景分布没有检测到跳水员的腿部。相反, 图5 (d) 融合3个能量项, 将跳水员从背景中准确分离出来。</p>
                </div>
                <div class="area_img" id="175">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903041_175.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 “跳水”视频各种能量组合最小化时获得的分布" src="Detail/GetImg?filename=images/JSJC201903041_175.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5</b> “<b>跳水”视频各种能量组合最小化时获得的分布</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903041_175.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="176" name="176">1.5 前景和背景的标签确定</h4>
                <div class="p1">
                    <p id="177">运行ACO算法获得前景分布和背景分布后, 利用最大后验准则 (Maximum A Posteriori, MAP) <citation id="234" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>来确定各个超级像素的二元分割标签。设似然概率<i>p</i> (<i>x</i><sub><i>i</i></sub>|<i>w</i><sup> (<i>τ</i>) </sup><sub><i>f</i></sub>) 表示在帧<i>τ</i>内节点<i>i</i>上发现前景的概率<i>p</i><mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>f</mi><mo>, </mo><mi>i</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>, p (w<mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>) 表示在帧τ内前景的先验概率。<mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mrow><mo> (</mo><mrow><mrow><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><mi>w</mi><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>) </mo></mrow></mrow></math></mathml>和p (w<mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>) 的定义与此类似。于是, 后验概率可计算为:</p>
                </div>
                <div class="p1">
                    <p id="182" class="code-formula">
                        <mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>w</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mi>p</mi><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo></mrow><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>w</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mi>p</mi><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>w</mi><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mi>p</mi><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="183">其中, p (w<mathml id="184"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>|x<sub>i</sub>) 表示节点i被前景占据的概率。然后, 在节点i处分割得到的前景标签<mathml id="185"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><msubsup><mrow></mrow><mrow><mi>f</mi><mo>, </mo><mi>i</mi></mrow><mrow><mrow><mo> (</mo><mi>τ</mi><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>和背景标签<mathml id="186"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><msubsup><mrow></mrow><mrow><mi>b</mi><mo>, </mo><mi>i</mi></mrow><mrow><mrow><mo> (</mo><mi>τ</mi><mo>) </mo></mrow></mrow></msubsup></mrow></math></mathml>为:</p>
                </div>
                <div class="p1">
                    <p id="187" class="code-formula">
                        <mathml id="187"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><mi>l</mi><msubsup><mrow></mrow><mrow><mi>f</mi><mo>, </mo><mi>i</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>, </mo><mi>l</mi><msubsup><mrow></mrow><mrow><mi>b</mi><mo>, </mo><mi>i</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>) </mo></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mo stretchy="false"> (</mo><mn>1</mn><mo>, </mo><mn>0</mn><mo stretchy="false">) </mo><mo>, </mo><mi>p</mi><mrow><mo> (</mo><mrow><mrow><mrow><mi>w</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>|</mo></mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>) </mo></mrow><mo>&gt;</mo><mi>p</mi><mrow><mo> (</mo><mrow><mrow><mrow><mi>w</mi><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>|</mo></mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>) </mo></mrow></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">) </mo><mo>, </mo><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="188">利用先前帧 (τ-1) 的前景分布和背景分布, 在帧τ内估计出前景分布和背景分布的先验概率p (w<sup> (τ) </sup><sub>f</sub>) 和p (w<mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>) 。假设2个分布完全分离且每个分布在各自区域均匀扩散。于是, 各个分布占据的节点数量等于其均匀概率的倒数。受此启发, 可估计得到2个分布的先验概率为:</p>
                </div>
                <div class="p1">
                    <p id="190" class="code-formula">
                        <mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>f</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mrow><mi>max</mi></mrow><msub><mrow></mrow><mi>i</mi></msub><mspace width="0.25em" /><mi>p</mi><msubsup><mrow></mrow><mrow><mi>f</mi><mo>, </mo><mi>i</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>b</mi><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mrow><mi>max</mi></mrow><msub><mrow></mrow><mi>i</mi></msub><mspace width="0.25em" /><mi>p</mi><msubsup><mrow></mrow><mrow><mi>b</mi><mo>, </mo><mi>i</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>τ</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="191" name="191">1.6 视频对象分割的反向传递</h4>
                <div class="p1">
                    <p id="192">对于前向传递, 本文利用先前帧的分割结果改进当前帧的聚类性能, 因此, 后续帧的概率分布比先前帧更为可靠。然后, 进一步进行从后往前的反向传递以提高视频对象分割的质量。除重要对象选择外, 反向传递的方法与前向传递基本相同。反向传递是从前景超像素的多个连通成分中选择各个帧的主要对象。将其与超像素相对应的前景概率相加, 确定各个成分的优先级分值。然后, 优先级最高的成分就是主要对象。此外, 在以上描述的方法中, 各帧被过分割为超级像素以降低图形中的节点数量。为保证视频对象分割的可靠性, 本文利用文献<citation id="235" type="reference">[<a class="sup">14</a>]</citation>中的马尔可夫随机域优化方法, 将超像素级别上的分割结果精炼为像素级分割结果。</p>
                </div>
                <h3 id="193" name="193" class="anchor-tag">2 仿真结果分析</h3>
                <h4 class="anchor-tag" id="194" name="194">2.1 数据集和评价指标</h4>
                <div class="p1">
                    <p id="195">本文在SegTrack、SegTrack v2和VidSeg 3个数据集上测试ACO算法的视频对象分割性能, 并与其他典型视频对象分割算法进行对比, 所有实验采用相同参数设置。其中, SegTrack数据集提供6个视频序列, 各个视频中的重要对象尺寸非常接近, 且像素级实况已知。SegTrack v2数据集提供8个视频序列及其实况, 对SegTrack数据集进行拓展。本文选择其中的5个序列, 每个序列包含一个主要对象。同时, 本文提出一种新的数据集VidSeg:从YouTube采集8个视频和另外4个电影片断。除“跳远”序列外, 每5个帧提取一次实况图。由于视频帧长度较短, 因此对所有视频帧标注实况标签。VidSeg视频中的对象容易发生变形且外观复杂, 背景带噪, 视频较长, 因此进行对象分割的难度较大。</p>
                </div>
                <div class="p1">
                    <p id="196">在实验过程中, 将每个视频帧中被错误标记的像素数量作为性能评估指标。此外, 如果仅仅关注错误标注的平均像素数量而不考虑对象尺寸, 在性能评估时容易产生误解。为此, 本文引入并集交集指标 (Intersection-over-Union, <mathml id="197"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ι</mtext><mtext>o</mtext><mtext>U</mtext><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>1</mn><mn>9</mn><mo stretchy="false">]</mo></mrow></msup><mo>, </mo><mtext>Ι</mtext><mtext>o</mtext><mtext>U</mtext><mo>=</mo><mn>1</mn><mn>0</mn><mn>0</mn><mo>×</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>Τ</mi><mstyle displaystyle="true"><mo>∩</mo><mi>R</mi></mstyle></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>Τ</mi><mstyle displaystyle="true"><mo>∪</mo><mi>R</mi></mstyle></mrow><mo>|</mo></mrow></mrow></mfrac></mrow></math></mathml>, 其中, <i>T</i>和<i>R</i>分别表示分割结果中的前景像素集合及相应的实况图。因为SegTrack v2和VidSeg数据集中的对象尺寸变化较大, 本文同时利用IoU指标衡量算法的分割性能。此外, 本文计算出各个视频帧的IoU得分以及所有视频帧的平均IoU得分。</p>
                </div>
                <h4 class="anchor-tag" id="198" name="198">2.2 结果评估</h4>
                <div class="p1">
                    <p id="199">表1给出ACO算法与其他11种传统算法在SegTrack数据集的性能结果比较, 数值越低表示性能越好, 粗体表示最优, 下划线表示次优 (下同) 。从表1可以看到, ACO算法中各帧被错误标记的像素的平均数量始终优于无监督单重算法、无监督多重算法和2种有监督算法。这是因为ACO算法综合3种能量对视频对象的前景和背景分布进行概率估计, 并提出前向-反向策略进行目标分割, 充分利用视频对象的时空信息, 因此, 相比于已有算法, 该算法错误标记的像素数量显著降低。</p>
                </div>
                <div class="area_img" id="200">
                    <p class="img_tit"><b>表1 SegTrack数据集上各算法被错误标记像素的平均数量</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="200" border="1"><tr><td rowspan="2"><br />算法<br />类别</td><td rowspan="2">算法</td><td colspan="5"><br />视频 (帧数) </td></tr><tr><td>小鸟<br /> (30) </td><td>猎豹<br /> (29) </td><td>女孩<br /> (21) </td><td>猴子<br /> (71) </td><td>跳伞<br /> (51) </td></tr><tr><td rowspan="5"><br />无监督<br />单重</td><td>ACO算法</td><td><b>144</b></td><td><b>617</b></td><td><u>1 195</u></td><td><u>354</u></td><td><b>200</b></td></tr><tr><td><br />文献[10]算法</td><td>209</td><td>796</td><td><b>1 040</b></td><td>562</td><td><u>207</u></td></tr><tr><td><br />文献[13]算法</td><td>217</td><td>890</td><td>3 859</td><td><b>284</b></td><td>855</td></tr><tr><td><br />文献[15]算法</td><td><u>155</u></td><td><u>633</u></td><td>1 488</td><td>365</td><td>220</td></tr><tr><td><br />文献[12]算法</td><td>189</td><td>806</td><td>1 598</td><td>472</td><td>221</td></tr><tr><td rowspan="5"><br />无监督<br />多重</td><td>文献[8]算法</td><td>199</td><td>599</td><td>1 164</td><td>322</td><td>242</td></tr><tr><td><br />文献[9]算法</td><td>468</td><td>1 175</td><td>5 683</td><td>1 434</td><td>1 595</td></tr><tr><td><br />文献[6]算法</td><td>606</td><td>11 210</td><td>26 409</td><td>12 662</td><td>40 251</td></tr><tr><td><br />文献[11]算法</td><td>288</td><td>905</td><td>1 785</td><td>521</td><td>201</td></tr><tr><td><br />文献[7]算法</td><td>468</td><td>1 968</td><td>7 595</td><td>1 143</td><td>1 113</td></tr><tr><td rowspan="2"><br />有监督</td><td>文献[19]算法</td><td>252</td><td>1 142</td><td>1 304</td><td>563</td><td>235</td></tr><tr><td><br />文献[5]算法</td><td>454</td><td>1 217</td><td>1 755</td><td>683</td><td>502</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="201">表2对比ACO算法与源代码已经公开的2种传统算法<citation id="238" type="reference"><link href="27" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">15</a>]</sup></citation>在3个数据集上的IoU得分, 数值越高, 性能越好。从表2可以看到, ACO算法的性能优于另外2种算法。具体而言, 对于重要对象外观发生非刚性形变及背景发生变化的长视频, ACO算法尤其有效。ACO算法的平均得分分别比文献<citation id="236" type="reference">[<a class="sup">13</a>]</citation>和文献<citation id="237" type="reference">[<a class="sup">15</a>]</citation>算法高出19.0%和14.2%左右。</p>
                </div>
                <div class="area_img" id="202">
                    <p class="img_tit"><b>表2 不同算法的IoU得分比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="202" border="1"><tr><td>数据集</td><td>视频<br /> (帧数) </td><td>文献[13]<br />算法</td><td>文献[15]<br />算法</td><td>ACO<br />算法</td></tr><tr><td rowspan="5"><br />SegTrack</td><td>小鸟 (30) </td><td>3.88</td><td><u>71.98</u></td><td><b>73.29</b></td></tr><tr><td><br />猎豹 (29) </td><td>44.95</td><td><b>65.48</b></td><td><u>64.23</u></td></tr><tr><td><br />女孩 (21) </td><td>56.83</td><td><u>81.46</u></td><td><b>86.75</b></td></tr><tr><td><br />猴子 (71) </td><td><u>72.62</u></td><td>72.06</td><td><b>76.12</b></td></tr><tr><td><br />跳伞 (51) </td><td>85.61</td><td><u>94.47</u></td><td><b>94.68</b></td></tr><tr><td rowspan="5"><br />SegTrack <br />v2</td><td>极乐鸟 (98) </td><td><u>83.46</u></td><td>27.02</td><td><b>93.92</b></td></tr><tr><td><br />青蛙 (279) </td><td>65.20</td><td><u>72.00</u></td><td><b>81.58</b></td></tr><tr><td><br />猴子 (31) </td><td><b>69.28</b></td><td>63.28</td><td><u>63.96</u></td></tr><tr><td><br />士兵 (32) </td><td><b>46.48</b></td><td><u>39.57</u></td><td>36.84</td></tr><tr><td><br />蚯蚓 (243) </td><td><b>73.62</b></td><td>44.59</td><td><u>61.79</u></td></tr><tr><td rowspan="12"><br />VidSeg</td><td>自行车飞驰 (347) </td><td><u>21.82</u></td><td>0.59</td><td><b>46.13</b></td></tr><tr><td><br />自行车行进 (631) </td><td>34.87</td><td><u>73.80</u></td><td><b>77.41</b></td></tr><tr><td><br />跳水 (104) </td><td>60.28</td><td><u>77.82</u></td><td><b>84.56</b></td></tr><tr><td><br />自由体操 (114) </td><td><u>15.65</u></td><td>14.28</td><td><b>61.84</b></td></tr><tr><td><br />跳远 (84) </td><td>60.14</td><td><u>78.14</u></td><td><b>79.85</b></td></tr><tr><td><br />网球 (679) </td><td>33.89</td><td><u>45.81</u></td><td><b>56.08</b></td></tr><tr><td><br />白鸟 (628) </td><td>63.49</td><td><u>78.86</u></td><td><b>79.60</b></td></tr><tr><td><br />狼 (362) </td><td>17.15</td><td><b>78.30</b></td><td><u>75.91</u></td></tr><tr><td><br />废船 (160) </td><td><u>65.18</u></td><td>31.14</td><td><b>78.82</b></td></tr><tr><td><br />Jurassic Park (118) </td><td><u>50.79</u></td><td><b>83.60</b></td><td>37.97</td></tr><tr><td><br />Silver Surfer (100) </td><td><u>69.88</u></td><td>0.68</td><td><b>75.02</b></td></tr><tr><td><br />蜘蛛侠 (118) </td><td>32.24</td><td><u>37.54</u></td><td><b>58.84</b></td></tr><tr><td colspan="2"><br />平均</td><td>51.24</td><td><u>56.02</u></td><td><b>70.24</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="203">图6给出ACO算法及其他2种算法<citation id="243" type="reference"><link href="27" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">15</a>]</sup></citation>的分割结果, 从上至下, 每个子图分别表示文献<citation id="239" type="reference">[<a class="sup">13</a>]</citation>算法、文献<citation id="240" type="reference">[<a class="sup">15</a>]</citation>算法及ACO算法的分割结果。从图6可以看到, 视频序列中的对象即使发生外观变形、运动模糊 (例如“自由体操”视频) 及背景噪声 (例如“蜘蛛侠”视频) , ACO算法仍然准确有效地分割出重要对象。文献<citation id="241" type="reference">[<a class="sup">15</a>]</citation>算法依赖于对象建议, 因此当对象建议方法没有检测出“蜘蛛侠”中微小复杂的对象时, 算法失效。对于“自由体操”视频, 文献<citation id="242" type="reference">[<a class="sup">13</a>]</citation>算法严重依赖于运动边界, 因此分割效果不够理想。相反, ACO算法通过使马尔可夫能量、时空能量和对抗能量共同构成的混合能量最小化, 实现重要对象的有效检测。</p>
                </div>
                <div class="area_img" id="204">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903041_204.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法的视频对象分割结果比较" src="Detail/GetImg?filename=images/JSJC201903041_204.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 不同算法的视频对象分割结果比较</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903041_204.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="205" name="205">2.3 步骤分析</h4>
                <div class="p1">
                    <p id="206">表3给出执行ACO算法各个步骤后获得的平均IoU得分。前向传递步骤利用时域和空域相关性提升初始IoU得分。反向传递步骤对前向步骤中发生误判的分割结果进行修正。像素级精炼步骤将算法性能提升至70.24分。</p>
                </div>
                <div class="area_img" id="207">
                    <p class="img_tit"><b>表3 各步骤后的IoU平均得分</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="207" border="1"><tr><td><br />步骤</td><td>平均得分</td></tr><tr><td><br />初始视频</td><td>44.31</td></tr><tr><td><br />前向传递</td><td>64.80</td></tr><tr><td><br />反向传递</td><td>67.71</td></tr><tr><td><br />像素级精炼</td><td>70.24</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="208" name="208">2.4 能量项分析</h4>
                <div class="p1">
                    <p id="209">以VidSeg数据集为例, 进一步测试ACO算法中3个能量项的不同组合对于视频对象分割的作用, 计算得到各种组合的平均IoU得分, 如表4所示。从表4可以看到, 时空能量项<i>ε</i><sub>S</sub>利用运动信息及时空相关性, 因此对视频对象分割具有重要作用。马尔可夫能量项<i>ε</i><sub>M</sub>和对抗能量项<i>ε</i><sub>A</sub>也很重要, 但<i>ε</i><sub>M</sub>+<i>ε</i><sub>A</sub>组合的表现却最差, 这是因为缺少关于视频对象的时空信息后, 马尔可夫能量项和对抗能量项的结合不能有效地区分对象的前景和背景分布, 从而降低视频对象分割的准确性。而<i>ε</i><sub>M</sub>+<i>ε</i><sub>S</sub>+<i>ε</i><sub>A</sub>三者结合的表现显著优于<i>ε</i><sub>S</sub>+<i>ε</i><sub>A</sub>、<i>ε</i><sub>M</sub>+<i>ε</i><sub>S</sub>和<i>ε</i><sub>S</sub>等所有组合, 充分表明3个能量项互为补充, 将这些能量项综合后实现最小化, 便可有效分割视频对象。</p>
                </div>
                <div class="area_img" id="210">
                    <p class="img_tit"><b>表4 ACO算法采用不同能量组合时获得的IoU平均得分</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="210" border="1"><tr><td><br />能量组合</td><td>平均得分</td></tr><tr><td><br /><i>ε</i><sub><i>S</i></sub></td><td>52.81</td></tr><tr><td><br /><i>ε</i><sub><i>S</i></sub>+<i>ε</i><sub><i>A</i></sub></td><td>52.92</td></tr><tr><td><br /><i>ε</i><sub><i>M</i></sub>+<i>ε</i><sub><i>A</i></sub></td><td>11.30</td></tr><tr><td><br /><i>ε</i><sub><i>M</i></sub>+<i>ε</i><sub><i>S</i></sub></td><td>57.87</td></tr><tr><td><br /><i>ε</i><sub><i>M</i></sub>+<i>ε</i><sub><i>S</i></sub>+<i>ε</i><sub><i>A</i></sub></td><td>67.71</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="211" name="211">2.5 多个重要对象的分割</h4>
                <div class="p1">
                    <p id="212">对于多个重要对象的分割问题, 假设重要对象的数量<i>k</i>已知。初始化时, 首先利用1.2节中的算法获得初始前景和背景分布。然后, 利用<i>k</i>均值聚类算法将初始前景分布划分为<i>k</i>个分布。因此, 本文采用<i>k</i>个前景分布 (每个对象1个) 及1个背景分布, 剩下的步骤直接从单个对象分割的过程中归纳得出。本文以SegTrack v2数据集中的3个视频序列测试ACO算法与3种传统算法的性能, 这3种算法的代码已公开且适用于多对象分割, 对比结果如表5所示。其中, 文献<citation id="244" type="reference">[<a class="sup">11</a>]</citation>针对所有视频帧构建一组对象建议, 然后通过选择某种假设来提取重要对象。该方法生成的假设均带有优先级。本文采用2种方式对文献<citation id="245" type="reference">[<a class="sup">11</a>]</citation>的方法进行测试:在文献<citation id="246" type="reference">[<a class="sup">11</a>]</citation>-T列, 计算优先级最高的2种假设的IoU得分;在文献<citation id="247" type="reference">[<a class="sup">11</a>]</citation>-A列, 计算2种假设最优组合的IoU得分。文献<citation id="248" type="reference">[<a class="sup">7</a>]</citation>算法和文献<citation id="249" type="reference">[<a class="sup">9</a>]</citation>算法属于运动分割算法, 生成的分割结果密度较高。</p>
                </div>
                <div class="area_img" id="213">
                    <p class="img_tit"><b>表5 SegTrack v2数据集上不同算法的IoU得分</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="213" border="1"><tr><td>视频<br /> (帧数) </td><td>文献[7]<br />算法</td><td>文献[11]<br />-T算法</td><td>文献[11]<br />-A算法</td><td>文献[9]<br />算法</td><td>本文<br />算法</td></tr><tr><td>BMX (36) </td><td>4.90</td><td>37.25</td><td><b>63.76</b></td><td>4.90</td><td>55.42</td></tr><tr><td><br />汽车漂移 (74) </td><td><b>59.04</b></td><td>35.52</td><td>50.91</td><td>21.49</td><td>57.72</td></tr><tr><td><br />蜂雀 (29) </td><td>32.42</td><td>31.46</td><td><b>44.28</b></td><td>27.46</td><td>35.92</td></tr><tr><td><br />平均</td><td>32.12</td><td>34.74</td><td><b>52.98</b></td><td>17.95</td><td>49.69</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="214">为衡量这些算法在重要对象分割方面的性能, 利用IoU指标确定与各个实况对象最为匹配的分割结果。因此, 仅已知对象数量<i>k</i>的ACO算法与文献<citation id="250" type="reference">[<a class="sup">11</a>]</citation>-A、文献<citation id="251" type="reference">[<a class="sup">7</a>]</citation>和文献<citation id="252" type="reference">[<a class="sup">9</a>]</citation>中已知实况数据的算法并不具有可比性。尽管如此, ACO算法的性能仍然远优于文献<citation id="253" type="reference">[<a class="sup">11</a>]</citation>-T、文献<citation id="254" type="reference">[<a class="sup">7</a>]</citation>和文献<citation id="255" type="reference">[<a class="sup">9</a>]</citation>中的算法, 与文献<citation id="256" type="reference">[<a class="sup">11</a>]</citation>-A算法的性能相当, 充分表明ACO算法的鲁棒性较好, 能够应用于背景或前景具有复杂动态特性的实际场景。</p>
                </div>
                <h3 id="215" name="215" class="anchor-tag">3 结束语</h3>
                <div class="p1">
                    <p id="216">本文提出一种新的无监督视频对象分割算法, 并定义一种综合马尔可夫能量、时空能量和对抗能量的混合能量, 在此基础上, 通过使混合能量最小化实现重要对象的分割。仿真结果表明, 该算法的性能与当前其他最新的视频对象分割算法相比有所提高。下一步将对视频或图像序列中对象和区域的自动分割和跟踪问题进行分析, 拟研究一种基于嵌入式流形去噪和局部增强核函数的视频运动对象分割方法, 改善当前计算机视觉系统的性能。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Saliency-aware video object segmentation">

                                <b>[1]</b> WANG W, SHEN J, YANG R, et al.Saliency-aware video object segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018, 40 (1) :20-33.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201610007&amp;v=MTk1MjdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk3bFc3ck1LQ0xmWWJHNEg5Zk5yNDlGWTRRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 苏亮亮, 唐俊, 梁栋, 等.基于最大化子模和RRWM的视频协同分割[J].自动化学报, 2016, 42 (10) :1532-1541.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gamifying video object segmentation">

                                <b>[3]</b> SPAMPINATO C, PALAZZO S, GIORDANO D.Gamifying video object segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (10) :1942-1958.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Category Independent Object Proposals">

                                <b>[4]</b> ENDRES I, HOIEM D.Category independent object proposals[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2010:575-588.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive Fragments-Based Tracking of Non-Rigid Objects Using Level Sets">

                                <b>[5]</b> CHOCKALINGAM P, PRADEEP N, BIRCHFIELD S.Adaptive fragments-based tracking of non-rigid objects using level sets[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2009:1530-1537.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ViBe: A universal background subtraction algorithm for video sequences">

                                <b>[6]</b> Barnich O, DROOGENBROECK M V.ViBe:a universal background subtraction algorithm for video sequences [J].IEEE Transactions on Image Processing, 2011, 20 (6) :1709-1724.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object segmentation by long term analysis of point trajectories">

                                <b>[7]</b> BROX T, MALIK J.Object segmentation by long term analysis of point trajectories[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2010:282-295.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Superpixel-Based Video Object Segmentation Using Perceptual Organization and Location Prior">

                                <b>[8]</b> GIORDANO D, MURABITO F, PALAZZO S, et al.Superpixel-based video object segmentation using perceptual organization and location prior [C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:4814-4822.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Higher order motion models and spectral clustering">

                                <b>[9]</b> OCHS P, BROX T.Higher order motion models and spectral clustering[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:614-621.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Saliency-aware geodesic video object segmentation">

                                <b>[10]</b> WANG W, SHEN J, PORIKLI F.Saliency-aware geodesic video object segmentation[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:3395-3402.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Key-segments for video object segmentation">

                                <b>[11]</b> LEE Y J, KIM J, GRAUMAN K.Key-segments for video object segmentation[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEE Press, 2011:1995-2002.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Maximum weight cliques with mutex constraints for video object segmentation">

                                <b>[12]</b> MA T, LATECKI L J.Maximum weight cliques with mutex constraints for video object segmentation[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:670-677.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast object segmentation in unconstrained video">

                                <b>[13]</b> PAPAZOGLOU A, FERRARI V.Fast object segmentation in unconstrained video[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2013:1777-1784.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SLIC Superpixels Compared to State-of-the-Art Superpixel Methods">

                                <b>[14]</b> ACHANTA R, SHAJI A, SMITH K, et al.SLIC superpixels compared to state-of-the-art superpixel methods[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (11) :2274-2282.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Video object segmentation through spatially accurate and temporally dense extraction of primary object regions">

                                <b>[15]</b> ZHANG D, JAVED O, SHAH M.Video object segmentation through spatially accurate and temporally dense extraction of primary object regions[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2013:628-635.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Graph-driven diffusion and random walk schemes for image segmentation">

                                <b>[16]</b> BAMPIS C G, MARAGOS P, BOVIK A C.Graph-driven diffusion and random walk schemes for image segmentation[J].IEEE Transactions on Image Processing, 2017, 26 (1) :35-50.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Infeasibility detection in the alternating direction method of multipliers for convex optimization">

                                <b>[17]</b> BANJAC G, GOULART P, STELLATO B, et al.Infeasibility detection in the alternating direction method of multipliers for convex optimization[J].IEEE Transactions on Power Electronics, 2017, 32 (5) :4007-4020.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CVX:Matlab software for disciplined convex programming">

                                <b>[18]</b> GRANT M, BOYD S, YE Y.CVX:Matlab software for disciplined convex programming[M].Berlin, Germany:Springer, 2008:109-120.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Maximum-a-posteriori- based decoding for end-to-end acoustic models">

                                <b>[19]</b> KANDA N, LU X, KAWAI H.Maximum-a-posteriori- based decoding for end-to-end acoustic models[J].IEEE/ACM Transactions on Audio, Speech, and Language Proessing, 2017, 25 (5) :1023-1034.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201903041" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903041&amp;v=MjcwOTMzenFxQnRHRnJDVVJMT2VaZVJvRnk3bFc3ck1MejdCYmJHNEg5ak1ySTlCWllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
