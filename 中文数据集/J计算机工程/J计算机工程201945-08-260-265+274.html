<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637129055274806250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201908043%26RESULT%3d1%26SIGN%3dshoug6i1PXor3JZBL1sGUkmEHgM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201908043&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201908043&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201908043&amp;v=MDQyMTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2puVUwvQUx6N0JiYkc0SDlqTXA0OUJaNFE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#39" data-title="1 时空信息构造与特征表示 ">1 时空信息构造与特征表示</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#40" data-title="1.1 时空信息构造">1.1 时空信息构造</a></li>
                                                <li><a href="#46" data-title="1.2 视频指纹生成流程">1.2 视频指纹生成流程</a></li>
                                                <li><a href="#49" data-title="1.3 特征表示">1.3 特征表示</a></li>
                                                <li><a href="#62" data-title="1.4 特征融合">1.4 特征融合</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#66" data-title="2 量化与匹配 ">2 量化与匹配</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#67" data-title="2.1 特征量化">2.1 特征量化</a></li>
                                                <li><a href="#75" data-title="2.2 特征匹配">2.2 特征匹配</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#83" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#92" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="&lt;b&gt;图1 时空信息结构图&lt;/b&gt;"><b>图1 时空信息结构图</b></a></li>
                                                <li><a href="#43" data-title="&lt;b&gt;图2 时空切片&lt;/b&gt;"><b>图2 时空切片</b></a></li>
                                                <li><a href="#48" data-title="&lt;b&gt;图3 视频指纹流程&lt;/b&gt;"><b>图3 视频指纹流程</b></a></li>
                                                <li><a href="#64" data-title="&lt;b&gt;图4 不同特征视频指纹的ROC 对比&lt;/b&gt;"><b>图4 不同特征视频指纹的ROC 对比</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;表1 失真类型及其参数设置&lt;/b&gt;"><b>表1 失真类型及其参数设置</b></a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;图5 不同拷贝变换下的ROC对比&lt;/b&gt;"><b>图5 不同拷贝变换下的ROC对比</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;表2 各种失真情况下指纹平均假正类率&lt;/b&gt;"><b>表2 各种失真情况下指纹平均假正类率</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="108">


                                    <a id="bibliography_1" title=" CHOU C L, CHEN H T, LEE S Y.Pattern-based near-duplicate video retrieval and localization on Web-scale videos[J].IEEE Transactions on Multimedia, 2015, 17 (3) :382-395." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pattern-based near-duplicate video retrieval and localization on Web-scale videos">
                                        <b>[1]</b>
                                         CHOU C L, CHEN H T, LEE S Y.Pattern-based near-duplicate video retrieval and localization on Web-scale videos[J].IEEE Transactions on Multimedia, 2015, 17 (3) :382-395.
                                    </a>
                                </li>
                                <li id="110">


                                    <a id="bibliography_2" title=" 顾佳伟, 赵瑞玮, 姜育刚.视频拷贝检测方法综述[J].计算机研究与发展, 2017, 54 (6) :1238-1250." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201706009&amp;v=MzE3MjRSTE9lWmVScUZDam5VTC9BTHl2U2RMRzRIOWJNcVk5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         顾佳伟, 赵瑞玮, 姜育刚.视频拷贝检测方法综述[J].计算机研究与发展, 2017, 54 (6) :1238-1250.
                                    </a>
                                </li>
                                <li id="112">


                                    <a id="bibliography_3" title=" SHINDE S R, CHIDDARWAR G G.Recent advances in content based video copy detection[C]//Proceedings of International Conference on Pervasive Computing.Washington D.C., USA:IEEE Press, 2015:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recent advances in content based video copy detection">
                                        <b>[3]</b>
                                         SHINDE S R, CHIDDARWAR G G.Recent advances in content based video copy detection[C]//Proceedings of International Conference on Pervasive Computing.Washington D.C., USA:IEEE Press, 2015:1-6.
                                    </a>
                                </li>
                                <li id="114">


                                    <a id="bibliography_4" title=" KE Yan, SUKTHANKAR R.PCA-SIFT:a more distinctive representation for local image descriptors[C]//Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2004:506-513." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PCA-SIFT:A more distinctive representation for local image descriptors">
                                        <b>[4]</b>
                                         KE Yan, SUKTHANKAR R.PCA-SIFT:a more distinctive representation for local image descriptors[C]//Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2004:506-513.
                                    </a>
                                </li>
                                <li id="116">


                                    <a id="bibliography_5" title=" ZHU Yingying, HUANG Xiaoyan, HUANG Qiang, et al.Large-scale video copy retrieval with temporal-concentration SIFT[J].Neurocomputing, 2016, 187:83-91." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES43256D4AA9DF608292FA7FA86B155FFB&amp;v=MTQxODhlbm81eHhRYTZFa01Ud21UcEJSSGVMZVJNOHp0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TnhpeExxOHdLQT1OaWZPZmJlN0hOVEsyNHMwRmVKNw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         ZHU Yingying, HUANG Xiaoyan, HUANG Qiang, et al.Large-scale video copy retrieval with temporal-concentration SIFT[J].Neurocomputing, 2016, 187:83-91.
                                    </a>
                                </li>
                                <li id="118">


                                    <a id="bibliography_6" title=" JUN W, LEE Y, JUN B M.Duplicate video detection for large-scale multimedia[J].Multimedia Tools and Applications, 2015, 75 (23) :1-14." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Duplicate video detection for large-scale multimedia">
                                        <b>[6]</b>
                                         JUN W, LEE Y, JUN B M.Duplicate video detection for large-scale multimedia[J].Multimedia Tools and Applications, 2015, 75 (23) :1-14.
                                    </a>
                                </li>
                                <li id="120">


                                    <a id="bibliography_7" title=" ZHOU Zhili, WANG Yunlong, WU Q M J, et al.Effective and efficient global context verification for image copy detection[J].IEEE Transactions on Information Forensics and Security, 2017, 12 (1) :48-63." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Effective and efficient global context verification for image copy detection">
                                        <b>[7]</b>
                                         ZHOU Zhili, WANG Yunlong, WU Q M J, et al.Effective and efficient global context verification for image copy detection[J].IEEE Transactions on Information Forensics and Security, 2017, 12 (1) :48-63.
                                    </a>
                                </li>
                                <li id="122">


                                    <a id="bibliography_8" title=" JIANG Yugang, WANG Jianjun.Partial copy detection in videos:a benchmark and an evaluation of popular methods[J].IEEE Transactions on Big Data, 2016, 2 (1) :32-42." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Partial Copy Detection in Videos:A Benchmark and an Evaluation of Popular Methods">
                                        <b>[8]</b>
                                         JIANG Yugang, WANG Jianjun.Partial copy detection in videos:a benchmark and an evaluation of popular methods[J].IEEE Transactions on Big Data, 2016, 2 (1) :32-42.
                                    </a>
                                </li>
                                <li id="124">


                                    <a id="bibliography_9" title=" LI Mu, MONGA V.Compact video fingerprinting via structural graphical models[J].IEEE Transactions on Information Forensics and Security, 2013, 8 (11) :1709-1721." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Compact video fingerprinting via structural graphical models">
                                        <b>[9]</b>
                                         LI Mu, MONGA V.Compact video fingerprinting via structural graphical models[J].IEEE Transactions on Information Forensics and Security, 2013, 8 (11) :1709-1721.
                                    </a>
                                </li>
                                <li id="126">


                                    <a id="bibliography_10" title=" COSKUN B, SANKUR B, MEMON N.Spatio-temporal transform based video hashing[J].IEEE Transactions on Multimedia, 2006, 8 (6) :1190-1208." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatio-temporal transform based video hashing">
                                        <b>[10]</b>
                                         COSKUN B, SANKUR B, MEMON N.Spatio-temporal transform based video hashing[J].IEEE Transactions on Multimedia, 2006, 8 (6) :1190-1208.
                                    </a>
                                </li>
                                <li id="128">


                                    <a id="bibliography_11" title=" LEE S, YOO C D.Video fingerprinting based on centroids of gradient orientations[C]//Proceedings of IEEE International Conference on Acoustics Speech and Signal Processing Proceedings.Washongton D.C., USA:IEEE Press, 2006:1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Video fingerprinting based on centroids of gradient orientations">
                                        <b>[11]</b>
                                         LEE S, YOO C D.Video fingerprinting based on centroids of gradient orientations[C]//Proceedings of IEEE International Conference on Acoustics Speech and Signal Processing Proceedings.Washongton D.C., USA:IEEE Press, 2006:1-4.
                                    </a>
                                </li>
                                <li id="130">


                                    <a id="bibliography_12" title=" ADELSON E H, BERGEN J R.Spatiotemporal energy models for the perception of motion[J].Journal of the Optical Society of America A, 1985, 2 (2) :284-299." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatiotemporal energy models for the perception of motion">
                                        <b>[12]</b>
                                         ADELSON E H, BERGEN J R.Spatiotemporal energy models for the perception of motion[J].Journal of the Optical Society of America A, 1985, 2 (2) :284-299.
                                    </a>
                                </li>
                                <li id="132">


                                    <a id="bibliography_13" title=" 李新伟, 夏秀珍.基于内容结构图的鲁棒图像哈希[J].应用科学学报, 2016, 34 (6) :691-701." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YYKX201606005&amp;v=MDkzNzQ5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZDam5VTC9BUERUQWRyRzRIOWZNcVk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         李新伟, 夏秀珍.基于内容结构图的鲁棒图像哈希[J].应用科学学报, 2016, 34 (6) :691-701.
                                    </a>
                                </li>
                                <li id="134">


                                    <a id="bibliography_14" title=" 曾宪华, 袁知洪, 王国胤, 等.基于多特征多核哈希学习的大规模图像检索[J].中国科学:信息科学, 2017, 47 (8) :1109-1126." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=PZKX201708012&amp;v=MjkyODJmQWRyRzRIOWJNcDQ5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZDam5VTC9BTlQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         曾宪华, 袁知洪, 王国胤, 等.基于多特征多核哈希学习的大规模图像检索[J].中国科学:信息科学, 2017, 47 (8) :1109-1126.
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_15" title=" 刘胜蓝, 冯林, 孙木鑫, 等.分组排序多特征融合的图像检索方法[J].计算机研究与发展, 2017, 54 (5) :1067-1076." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201705016&amp;v=MTExOTZxQnRHRnJDVVJMT2VaZVJxRkNqblVML0FMeXZTZExHNEg5Yk1xbzlFWW9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         刘胜蓝, 冯林, 孙木鑫, 等.分组排序多特征融合的图像检索方法[J].计算机研究与发展, 2017, 54 (5) :1067-1076.
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_16" title=" 林莹, 杨扬, 凌康, 等.多特征综合的视频拷贝检测[J].中国图象图形学报, 2013, 18 (5) :591-599." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201305013&amp;v=MTIyMDVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2puVUwvQVB5cmZiTEc0SDlMTXFvOUVaNFFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         林莹, 杨扬, 凌康, 等.多特征综合的视频拷贝检测[J].中国图象图形学报, 2013, 18 (5) :591-599.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(08),260-265+274 DOI:10.19678/j.issn.1000-3428.0052107            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于时空信息特征融合的视频指纹算法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%95%E7%A4%BC%E5%B2%A9&amp;code=40424863&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">单礼岩</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%96%B0%E4%BC%9F&amp;code=31120023&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李新伟</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8D%97%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E7%94%B5%E6%B0%94%E5%B7%A5%E7%A8%8B%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AD%A6%E9%99%A2&amp;code=0026206&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河南理工大学电气工程与自动化学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8D%97%E7%9C%81%E9%AB%98%E7%AD%89%E5%AD%A6%E6%A0%A1%E6%8E%A7%E5%88%B6%E5%B7%A5%E7%A8%8B%E9%87%8D%E7%82%B9%E5%AD%A6%E7%A7%91%E5%BC%80%E6%94%BE%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河南省高等学校控制工程重点学科开放实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为满足视频拷贝检测系统的鲁棒性、独特性和紧凑性, 提出一种包含时空信息特征的视频指纹算法。利用时空切片和关键帧构成时空信息, 将包含视频关键帧空域信息的Gabor特征和时空切片时域信息的直方图特征加权融合, 量化后得到视频指纹。在公开数据库上进行对比实验, 结果表明, 与结构图模型、时间信息表示图像、梯度方向质心等算法相比, 该算法ROC性能突出, 鲁棒性得到明显提高, 整体性能更优。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E9%A2%91%E6%8C%87%E7%BA%B9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">视频指纹;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%B6%E7%A9%BA%E5%88%87%E7%89%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">时空切片;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%B3%E9%94%AE%E5%B8%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">关键帧;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gabor%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gabor变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%B2%81%E6%A3%92%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鲁棒性;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    单礼岩 (1992—) , 男, 硕士研究生, 主研方向为视频图像处理;;
                                </span>
                                <span>
                                    *李新伟 (通信作者) , 讲师、博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-16</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61402152, 61403130);</span>
                                <span>河南省高等学校控制工程重点学科开放实验室课题 (KG2014-06);</span>
                                <span>河南理工大学博士基金 (B2013-022);</span>
                    </p>
            </div>
                    <h1><b>Video Fingerprinting Algorithm Based on Temporal and Spatial Information Feature Fusion</b></h1>
                    <h2>
                    <span>SHAN Liyan</span>
                    <span>LI Xinwei</span>
            </h2>
                    <h2>
                    <span>School of Electrical Engineering and Automation, Henan Polytechnic University</span>
                    <span>Open Laboratory of Control Engineering based on Henan Provincial Key Disciplines in Universities</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To meet the robustness, uniqueness and compactness requirements of video copy detection systems, a video fingerprint algorithm including temporal and spatial information is proposed.The temporal and spatial information is composed of spatio-temporal slices and keyframes.Weighted fusion is implemented on Gabor features including the spatial information of video key frames, and on histogram features including temporal information of spatio-temporal slices.The fusion is quantized to generate the video fingerprint.Comparative experiments are carried out on the public database, and results show that the proposed algorithm has an outstanding ROC performance, obviously higher robustness, and better overall performance compared with structure diagram model, temporal information image, gradient direction centroid and other algorithms.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=video%20fingerprint&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">video fingerprint;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spatio-temporal%20slice&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spatio-temporal slice;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=key%20frame&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">key frame;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gabor%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gabor transform;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=robustness&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">robustness;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-07-16</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="36">视频指纹是采用特定的方法和技术从原始视频数据中提取的简短数据, 也被称作视频摘要、视频哈希、视频基因等<citation id="140" type="reference"><link href="108" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。视频指纹可用于互联网中多媒体数据的版权保护、视频监控计数、非法内容检测和视频推荐等。设计视频指纹算法的主要目的是减小视频数据存储空间和提高视频检索效率, 因此视频指纹的算法通常需要满足鲁棒性、独特性、紧凑性3个方面的特性要求。鲁棒性表示原始视频与其拷贝视频指纹码之间的相似程度, 其要求视频经过一系列失真变换后的指纹与原始指纹保持较好的相似度, 在指纹匹配时能保持较高的检测正确率。独特性表示不同视频指纹之间的差异程度, 指纹数据应随着视频数据的不同而存在明显差异, 进而在指纹匹配时能具有较低的误警率。紧凑性描述指纹码的长度, 在满足前两者的基础上, 指纹码越短越好, 可从根本上提高匹配效率。通常紧凑性与鲁棒性、独特性相矛盾, 因此如何平衡三者性能是一个值得研究的课题。</p>
                </div>
                <div class="p1">
                    <p id="37">目前对于视频特征提取的算法主要分为 2类<citation id="141" type="reference"><link href="110" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。一类算法在视频帧级别上选取关键帧, 然后对关键帧进行特征提取, 生成视频指纹。此类算法的主要思想是通过提取视频关键帧降低视频数据冗余。早期大量传统的图像特征提取方法被用于关键帧的特征提取, 例如文献<citation id="142" type="reference">[<a class="sup">3</a>]</citation>使用的颜色直方图及其改进算法, 文献<citation id="147" type="reference">[<a class="sup">4</a>,<a class="sup">5</a>]</citation>使用的尺度不变特征变换 (Scale Invariant Feature Transform, SIFT) 算法, 还有其他的图像特征提取方法<citation id="148" type="reference"><link href="118" rel="bibliography" /><link href="120" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>都是此类的经典算法, 但这些算法应用到视频上就丢失了视频的时间信息。另一类算法融合所有视频帧信息的视频整体描述特征。此类算法的主要思想是通过数据降维, 将高维视频数据用极少量的低维数据表示<citation id="143" type="reference"><link href="122" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。典型算法有结构图模型 (Structural Graphical Models, SGM) 算法<citation id="144" type="reference"><link href="124" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、时间信息表示图像 (Temporally Informative Representative Images, TIRI) 算法<citation id="145" type="reference"><link href="126" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>和梯度方向质心 (Centroids of Gradient Orientations, CGO) 算法<citation id="146" type="reference"><link href="128" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="38">总体来说, 第一类算法选取关键帧减少冗余的同时遗失了时间信息, 对时域信息变换不敏感, 受限于图像特征提取算法;第二类算法数据量大, 计算复杂, 对几何类失真和时域信息变换鲁棒性非常好, 但是会降低对局部弯曲类似的失真鲁棒性。为了解决上述问题, 同时提高鲁棒性、独特性和紧凑性, 本文将包含视频时域信息的时空切片和空域信息的关键帧组合, 构成具有鲁棒性的时空信息, 然后将时空切片的直方图特征和关键帧Gabor特征融合。</p>
                </div>
                <h3 id="39" name="39" class="anchor-tag">1 时空信息构造与特征表示</h3>
                <h4 class="anchor-tag" id="40" name="40">1.1 时空信息构造</h4>
                <div class="p1">
                    <p id="41">时空信息由时空切片和关键帧组成。文献<citation id="149" type="reference">[<a class="sup">12</a>]</citation>在1985年首次提出时空切片的概念。将视频看成一个三维图像序列, 3个维度分别是<i>x</i>、<i>y</i>和时间<i>t</i>, (<i>x</i>, <i>y</i>) 表示图像维, 如图1所示。在三维序列上沿着<i>t</i>轴方向做一个切割, 得到的截面就是时空切片。其中, 时空切片的一个维度是时间<i>t</i>, 另一个维度是<i>x</i>或<i>y</i>。维度 (<i>y</i>, <i>t</i>) 称为垂直切片, 维度 (<i>x</i>, <i>t</i>) 称为水平切片, 示例如图2所示。</p>
                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908043_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 时空信息结构图" src="Detail/GetImg?filename=images/JSJC201908043_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 时空信息结构图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908043_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="43">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908043_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 时空切片" src="Detail/GetImg?filename=images/JSJC201908043_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 时空切片</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908043_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="44">每一张切片只取一帧图像的一列 (行) , 相对于整帧图像要切取图像关键位置信息才有代表性, 垂直 (水平) 时空切片列 (行) 与列 (行) 之间包含了视频相邻帧的时间轴信息, 即视频时间信息, 每一列 (行) 像素包含对应视频帧少量空间信息, 垂直和水平时空切片构成的井字形结构能稳定的提取视频图像关键位置信息, 如图1所示。井字形时空切片结构是采样视频关键位置的数据, 要用反映图像整体特性的全局特征表示, 本文选用直方图特征。</p>
                </div>
                <div class="p1">
                    <p id="45">为了采样数据的完整性, 主要通过2种方法提取图像维关键帧:一种方法是均匀采样, 另一种方法是基于镜头检测的关键帧提取。本文采用均匀采样法, 提取2帧关键帧, 采样的关键帧和时空切片构成完整的时空信息, 如图1所示。时空切片信息使用直方图特征表示, 直方图特征忽略了图像数据的几何关系、形状信息和纹理信息, 所以对关键帧采用能捕捉图像中不同的空间频率、空间位置及方向信息的Gabor变换, 有效地提取局部细微变化对时空切片特征信息进行补充, 两者加权融合, 使之成为一个稳定的整体。一方面时空信息数据量比原始视频大幅降低, 计算简单;另一方面对局部弯曲类似的失真、几何失真、信号失真及时间域失真都具有较强鲁棒性, 满足视频指纹特性需求。</p>
                </div>
                <h4 class="anchor-tag" id="46" name="46">1.2 视频指纹生成流程</h4>
                <div class="p1">
                    <p id="47">视频指纹算法主要有特征提取和量化2个步骤。本文算法中的特征提取由时空切片、关键帧、灰度直方图、Gabor变换和加权融合组成, 量化过程使用随机自适应量化 (Randomized Adaptive Quantizer, RAQ) 。整个视频指纹生成过程如图3所示。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908043_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 视频指纹流程" src="Detail/GetImg?filename=images/JSJC201908043_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 视频指纹流程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908043_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="49" name="49">1.3 特征表示</h4>
                <div class="p1">
                    <p id="50">一个<i>N</i>帧的视频, 垂直时空切片<i>CUT</i>表示如下:</p>
                </div>
                <div class="p1">
                    <p id="51"><i>CUT</i>= (<i>h</i><sub>1</sub>, <i>h</i><sub>2</sub>, …, <i>h</i><sub><i>i</i></sub>, …, <i>h</i><sub><i>N</i></sub>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="52"><i>h</i><sub><i>i</i></sub>= (<i>P</i><sub><i>i</i></sub> (<i>x</i><sub><i>j</i></sub>, 1) , <i>P</i><sub><i>i</i></sub> (<i>x</i><sub><i>j</i></sub>, 2) , …, <i>P</i><sub><i>i</i></sub> (<i>x</i><sub><i>j</i></sub>, <i>y</i>) , …, <i>P</i><sub><i>i</i></sub> (<i>x</i><sub><i>j</i></sub>, <i>m</i>) ) <sup>T</sup>      (2) </p>
                </div>
                <div class="p1">
                    <p id="53">其中, (<i>x</i>, <i>y</i>) 表示图像维, 每帧图像的大小为<i>m</i>×<i>n</i>, 切取位置是第<i>j</i>列, <i>h</i><sub><i>i</i></sub>表示第<i>i</i>帧图像第<i>j</i>列像素, <i>P</i><sub><i>i</i></sub> (<i>x</i><sub><i>j</i></sub>, <i>y</i>) 表示第<i>i</i>帧图像第<i>j</i>列第<i>y</i>行的像素值, 其中1≤<i>j</i>≤<i>n</i>, 1≤<i>i</i>≤<i>N</i>, 1≤<i>y</i>≤<i>m</i>。水平时空切片处理方法类似。</p>
                </div>
                <div class="p1">
                    <p id="54">对每个时空切片生成灰度直方图特征, 然后压缩特征至16 bit, 4个切片可串成一组64 bit的特征数据。</p>
                </div>
                <div class="p1">
                    <p id="55">二维Gabor核函数表征如下:</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>ψ</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>, </mo><mi>v</mi></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>, </mo><mi>v</mi></mrow></msub><mo stretchy="false">∥</mo></mrow><mrow><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mrow><mi>exp</mi></mrow><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>, </mo><mi>v</mi></mrow></msub><mo stretchy="false">∥</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">∥</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow><mo>×</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mrow><mo>[</mo><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mtext>i</mtext><mi mathvariant="bold-italic">z</mi><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>, </mo><mi>v</mi></mrow></msub><mo stretchy="false">) </mo><mo>-</mo><mi>exp</mi><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">其中, <b><i>z</i></b>= (<i>x</i>, <i>y</i>) 为关键帧图像像素, <b><i>u</i></b>为方向因子, <b><i>v</i></b>为尺度因子, ‖·‖表示模, 向量<b><i>K</i></b><sub><i>u</i>, <i>v</i></sub>定义为<b><i>K</i></b><sub><i>u</i>, <i>v</i></sub>=<i>k</i><sub><i>v</i></sub>exp (i<i>φ</i><sub><i>u</i></sub>) , <i>k</i><sub><i>v</i></sub>=<i>k</i><sub>max</sub>/<i>f</i><sub><i>v</i></sub>, <i>φ</i><sub><i>u</i></sub>=π<b><i>u</i></b>/8, <i>k</i><sub>max</sub>为最大采样频率, 常取<i>k</i><sub>max</sub>=π/2, <i>f</i><sub><i>v</i></sub>为频率的采样步长, 常取<mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mn>2</mn></msqrt><mo>, </mo><mi>σ</mi></mrow></math></mathml>为标准差, 决定核函数的支撑区域, 改变该值可以使核函数匹配图像不同空间的结构, 本算法取σ=<i>π</i>, 改变<b><i>u</i></b>和<b><i>v</i></b>可以得到不同方向不同尺度的核函数, 即可以提取图像不同方向不同尺度的特征<citation id="150" type="reference"><link href="132" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="59">对于一帧关键帧图像<i>f</i> (<b><i>z</i></b>) , <b><i>z</i></b>= (<i>x</i>, <i>y</i>) , 其Gabor变换为图像与核函数的卷积:</p>
                </div>
                <div class="p1">
                    <p id="60"><i>G</i><sub><i>u</i>, <i>v</i></sub> (<b><i>z</i></b>) =<i>f</i> (<b><i>z</i></b>) *<i>ψ</i><sub><i>u</i>, <i>v</i></sub> (<b><i>z</i></b>)      (4) </p>
                </div>
                <div class="p1">
                    <p id="61">其中, *表示卷积运算, 进行卷积运算后系数矩阵中的每一个元素为一复数, <i>G</i><sub><i>u</i>, <i>v</i></sub> (<b><i>z</i></b>) 表示对应方向<b><i>u</i></b>尺度<b><i>v</i></b>时在位置处的变换系数, 取其幅值得到<i>G</i>′<sub><i>u</i>, <i>v</i></sub> (<b><i>z</i></b>) 。本文关键帧图像选择的是1个尺度、1个方向、尺寸大小为18×19的Gabor系数特征, 特征压缩至32 bit, 2帧关键帧可以得到一组64 bit的特征数据。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62">1.4 特征融合</h4>
                <div class="p1">
                    <p id="63">单一时空切片灰度直方图特征 (CUTHist) 包含空间域信息很少, 当视频受到旋转、剪切等几何攻击时, 时空切片内容发生改变, 生成的视频指纹码差异更大, 其对几何失真的抵抗较差。单一关键帧Gabor特征 (KeyGabor) 全是空域信息, 缺少时间信息, 生成的视频指纹存在先天缺陷。单一特征存在缺陷可用多特征融合来解决<citation id="151" type="reference"><link href="134" rel="bibliography" /><link href="136" rel="bibliography" /><link href="138" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>, 本文中的时空信息就是将两者连成一个整体, 且为了保持紧凑性, 使用加权特征融合。图4为不同特征生成的视频指纹的受试者工作特性 (Receiver Operating Characteristic, ROC) 对比。其中, 图4 (a) 的左下角曲线标注文字<i>c</i>-<i>d</i>分别代表CUTHist权重<i>c</i>和KeyGabor权重<i>d</i>。</p>
                </div>
                <div class="area_img" id="64">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908043_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同特征视频指纹的ROC 对比" src="Detail/GetImg?filename=images/JSJC201908043_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 不同特征视频指纹的ROC 对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908043_064.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="65">在特征融合中, 权重分配是关键, 图4 (a) 给出了CUTHist-KeyGabor分配不同权重时融合特征 (CUTG) 的ROC性能对比。由图4 (a) 可知, 特征融合最优权重分配是CUTHist权重为0.9, KeyGabor权重为0.1。图4 (b) 给出了2个单一特征和以最优权重加权融合的视频指纹ROC性能对比, 由图4 (b) 可知特征融合后视频指纹性能更优。</p>
                </div>
                <h3 id="66" name="66" class="anchor-tag">2 量化与匹配</h3>
                <h4 class="anchor-tag" id="67" name="67">2.1 特征量化</h4>
                <div class="p1">
                    <p id="68">本文使用RAQ<citation id="152" type="reference"><link href="124" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 1位自适应量化器<i>q</i><sub><i>r</i></sub> (·) 采用以下公式:</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>q</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>1</mn><mo>, </mo><mi>x</mi><mo>≥</mo><mi>X</mi></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>, </mo><mi>x</mi><mo>&lt;</mo><mi>X</mi></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">阈值<i>X</i>由下式求得:</p>
                </div>
                <div class="p1">
                    <p id="71">∫<mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo>-</mo><mi>∞</mi></mrow><mi>X</mi></msubsup></mrow></math></mathml><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>q</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false">) </mo><mtext>d</mtext><mi>u</mi><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="74">其中, <i>q</i><sub><i>r</i></sub> (·) 表示对应特征数列的概率密度函数。本文为每一个视频特征数列都进行一次学习训练, 以进一步提高性能。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75">2.2 特征匹配</h4>
                <div class="p1">
                    <p id="76">特征匹配的主要目的是判定待检测视频是否为视频库内注册视频的拷贝, 其采用指纹序列匹配的方法来判断, 分为基于同长度序列匹配和基于不同长度序列匹配2种, 本文是同长度序列匹配。常见的指纹特征相似度测量方法有汉明距离、闵可夫斯基距离、欧几里得距离和马氏距离等。汉明距离简单高效, 所以本文采用其判断指纹码相似度。</p>
                </div>
                <div class="p1">
                    <p id="77">经过自适应量化后的待检测视频指纹序列设为<i>H</i><sub><i>i</i></sub>, 库视频指纹序列设为<i>H</i><sub><i>j</i></sub>, 则<i>H</i><sub><i>i</i></sub>与<i>H</i><sub><i>j</i></sub>的归一化汉明距离为:</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mi>D</mi><mo stretchy="false"> (</mo><mi>Η</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>Η</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi>Η</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>-</mo><mi>Η</mi><msub><mrow></mrow><mrow><mi>j</mi><mi>k</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">将得到的汉明距离与设定的阈值进行比较, 以判定待检测视频是否为视频库中注册视频的拷贝数据。为了评价所提算法性能, 本文采用ROC表示其性能, 定义真正类率 (True Positive Rate, TPR) 和假正类率 (False Positive Rate, FPR) 分别为:</p>
                </div>
                <div class="p1">
                    <p id="80"><i>TPR</i>=<i>TP</i>/ (<i>TP</i>+<i>FN</i>)      (8) </p>
                </div>
                <div class="p1">
                    <p id="81"><i>FPR</i>=<i>FP</i>/ (<i>FP</i>+<i>TN</i>)      (9) </p>
                </div>
                <div class="p1">
                    <p id="82">其中, <i>TP</i>表示视频库中正确识别的拷贝视频数量, <i>FN</i>表示视频库中未被识别出的拷贝视频数量, <i>FP</i>表示视频库中错误识别的拷贝视频数量, <i>TN</i>表示视频库中正确识别的非拷贝视频数量。ROC曲线横轴表示<i>FPR</i>, 纵轴表示<i>TPR</i>, 绘制得到ROC曲线图, 通过曲线与坐标轴围成的面积<i>S</i>判断算法性能的优劣。实际上纵轴的数据使用的是 (1-<i>TPR</i>) , 因此面积S越小算法性能越好。</p>
                </div>
                <h3 id="83" name="83" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="84">本文实验环境如下:Windows 10 家庭版操作系统Inter (R) Core (TM) i7-7500U CPU @ 2.70 GHz 2.90 GHz处理器, 4 GB内存, Matlab R2014a。从YouTube下载的600个视频作为数据库, 和文献<citation id="153" type="reference">[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</citation>中典型的视频拷贝检测方法一样, 将表1中列出的失真应用于库中视频, 从而生成一对视觉上相似的原始视频和拷贝视频。</p>
                </div>
                <div class="area_img" id="85">
                    <p class="img_tit"><b>表1 失真类型及其参数设置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="85" border="1"><tr><td><br />失真类型</td><td>参数</td><td>数量</td></tr><tr><td><br />缩放</td><td>2倍～5倍</td><td>4</td></tr><tr><td><br />Gamma校正</td><td>校正因子0.8～1.3</td><td>6</td></tr><tr><td><br />丢帧</td><td>丢帧数 1～6</td><td>6</td></tr><tr><td><br />帧率下降</td><td>下降数 1、2、3、4</td><td>4</td></tr><tr><td><br />插入logo</td><td>大小[5, 10]、位置图像内随机坐标[<i>x</i>, <i>y</i>]</td><td>10</td></tr><tr><td><br />局部弯曲</td><td>幅度 [5, 50], 周期[10, 200]</td><td>10</td></tr><tr><td><br />时间子采样</td><td>采样频率 (倍) 4、9、16</td><td>3</td></tr><tr><td><br />旋转+剪切</td><td>角度2°、5°、10°+ 比例0.01、0.02</td><td>6</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="86">ROC被广泛用于测量视频指纹算法的性能。为了获得ROC, 将视频指纹的匹配问题转换为二进制数据计算问题。将600个拷贝视频及其对应原视频之间的汉明距离数据存储在矩阵<b><i>A</i></b>中。将拷贝视频和其非对应原视频之间的汉明距离数据存储在矩阵<b><i>B</i></b>中。假设阈值为<i>T</i>, 矩阵<b><i>A</i></b>中小于<i>T</i>的值数除以600就是真正类率, 矩阵<b><i>B</i></b>中小于<i>T</i>的值数除以 (600-1) ×600=359 400就是假正类率, 找出矩阵<b><i>A</i></b>和矩阵<b><i>B</i></b>中的最小数 (假设为<i>a</i>) , 最大数 (假设为<i>b</i>) , 在<i>a</i>和<i>b</i>之间均匀取100个值存入矩阵<b><i>C</i></b>作为阈值, 则可以得到一组TPR-FPR数据, 绘制成ROC曲线。</p>
                </div>
                <div class="p1">
                    <p id="87">为了全面评价算法的有效性, 将本文算法与经典算法SGM、TIRI和CGO进行对比, 所有算法的参数设置都是为了保持相同的指纹长度, 在紧凑性相同的基础上对算法进行公平比较。SGM算法在融合视频内所有帧信息的视频整体描述特征的指纹算法里具有代表性, 在抵抗旋转、剪切、丢帧、时间子采样等失真方面性能突出;TIRI算法特别适用于抵抗帧速率变化等时域失真;CGO算法对诸如压缩之类的视频失真具有较强鲁棒性。对表1中各种失真变换进行指纹匹配, 统计所有失真匹配结果得到ROC。图5为表1中8种失真情况的平均ROC。</p>
                </div>
                <div class="area_img" id="88">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908043_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同拷贝变换下的ROC对比" src="Detail/GetImg?filename=images/JSJC201908043_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 不同拷贝变换下的ROC对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908043_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="89">由图5可以看出CGO算法鲁棒性很强, 在各种失真攻击下能保持ROC性能基本不变, 但是独特性不够, 使之在4种算法中ROC性能最差。TIRI算法受各种失真攻击影响较大, 鲁棒性较弱, 对丢帧、帧率下降的鲁棒性和独特性最强, 因为此算法是在时间信息的基础上设计的, 对信号、几何失真的鲁棒性和独特性较差。如图5 (a) ～图5 (d) 所示, SGM算法对几何类的缩放、信号类的Gamma校正、时间域的丢帧和帧率下降等失真都有较好的鲁棒性和独特性, 是第二类指纹算法的经典代表, 本文算法对同种失真的ROC性能与之相比较优。对于表1中不同于3大类的失真情况, 如图5 (e) 所示的插入logo和图5 (f) 所示的局部弯曲, 大量改变SGM算法使用的所有帧数据, 使之ROC性能下降到略差于TIRI算法的程度, 而对本文算法使用的时空信息改变较小, 因此本文算法的ROC性能针对这2种失真也是4种算法中最优的。图5 (g) 所示的时间子采样是对时空信息结构冲击最大的失真拷贝, 但是对此类失真本文算法ROC性能仍优于对比算法。如图5 (h) 所示的组合失真, 选用的是旋转和剪切, 由实验结果可知此类失真下本文算法ROC性能也是优于3种对比算法。</p>
                </div>
                <div class="p1">
                    <p id="90">表2是4种算法的各种失真情况下平均真正类率-假正类率。从表2可以看出, 真正类率提高的同时伴随着假正类率的升高, 在真正类率高于0.905以后, CGO算法和TIRI算法的假正类率上升较大。相比之下SGM算法的假正类率上升较小, 只是在真正类率从0.999上升到1的时候, 假正类率突增, 这是因为在SGM算法中个别拷贝视频与原视频的汉明距离大于部分相似性较高视频的汉明距离, 使得阈值较大时, 大量相似视频误判为拷贝视频, 待检测视频匹配错误, 假正类率增大, 而本文算法没有这个缺点。由表2中数据可表明本文算法整体性能优于对比算法, 有很强的鲁棒性和独特性, 使得指纹匹配较高的真正类率时伴随较低的假正类率。</p>
                </div>
                <div class="area_img" id="91">
                    <p class="img_tit"><b>表2 各种失真情况下指纹平均假正类率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="91" border="1"><tr><td rowspan="2"><br />算法</td><td colspan="11"><br />真正类率</td></tr><tr><td>0.855</td><td>0.905</td><td>0.945</td><td>0.965</td><td>0.990</td><td>0.995</td><td>0.996</td><td>0.997</td><td>0.998</td><td>0.999</td><td>1.000</td></tr><tr><td>CGO</td><td>0.446</td><td>0.532</td><td>0.669</td><td>0.765</td><td>0.910</td><td>0.944</td><td>0.948</td><td>0.957</td><td>0.964</td><td>0.971</td><td>0.975</td></tr><tr><td><br />TIRI</td><td>0.057</td><td>0.058</td><td>0.145</td><td>0.327</td><td>0.678</td><td>0.686</td><td>0.860</td><td>0.863</td><td>0.875</td><td>0.912</td><td>0.947</td></tr><tr><td><br />SGM</td><td>0.021</td><td>0.028</td><td>0.054</td><td>0.069</td><td>0.159</td><td>0.246</td><td>0.263</td><td>0.283</td><td>0.342</td><td>0.442</td><td>0.943</td></tr><tr><td><br />本文算法</td><td>0.003</td><td>0.004</td><td>0.006</td><td>0.007</td><td>0.013</td><td>0.020</td><td>0.023</td><td>0.025</td><td>0.030</td><td>0.037</td><td>0.121</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="92" name="92" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="93">本文在时空切片和关键帧组合构成的时空信息上进行特征提取, 弥补了关键帧方法时间信息遗失的缺陷, 减少了所有帧方法的数据计算量, 同时提取更鲁棒、独特、紧凑的视频指纹。在时空切片上提取的灰度直方图特征包含视频空间域关键位置的信息和时间信息, 并在关键帧上采用能捕捉图像中不同的空间频率、空间位置及方向信息的Gabor变换特征, 两者融合弥补了单一特征的不足。实验结果表明, 对比SGM、TIRI和CGO算法, 本文算法在鲁棒性、独特性和紧凑性方面均较优, 在大幅提高真正类率的同时降低了假正类率。下一步将使用核学习进行特征融合, 进一步提高算法鲁棒性和独特性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="108">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pattern-based near-duplicate video retrieval and localization on Web-scale videos">

                                <b>[1]</b> CHOU C L, CHEN H T, LEE S Y.Pattern-based near-duplicate video retrieval and localization on Web-scale videos[J].IEEE Transactions on Multimedia, 2015, 17 (3) :382-395.
                            </a>
                        </p>
                        <p id="110">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201706009&amp;v=MDMwODI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2puVUwvQUx5dlNkTEc0SDliTXFZOUZiWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 顾佳伟, 赵瑞玮, 姜育刚.视频拷贝检测方法综述[J].计算机研究与发展, 2017, 54 (6) :1238-1250.
                            </a>
                        </p>
                        <p id="112">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recent advances in content based video copy detection">

                                <b>[3]</b> SHINDE S R, CHIDDARWAR G G.Recent advances in content based video copy detection[C]//Proceedings of International Conference on Pervasive Computing.Washington D.C., USA:IEEE Press, 2015:1-6.
                            </a>
                        </p>
                        <p id="114">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PCA-SIFT:A more distinctive representation for local image descriptors">

                                <b>[4]</b> KE Yan, SUKTHANKAR R.PCA-SIFT:a more distinctive representation for local image descriptors[C]//Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2004:506-513.
                            </a>
                        </p>
                        <p id="116">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES43256D4AA9DF608292FA7FA86B155FFB&amp;v=MDU1ODlmT0dRbGZDcGJRMzVOeGl4THE4d0tBPU5pZk9mYmU3SE5USzI0czBGZUo3ZW5vNXh4UWE2RWtNVHdtVHBCUkhlTGVSTTh6dENPTnZGU2lXV3I3SklGcG1hQnVIWQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> ZHU Yingying, HUANG Xiaoyan, HUANG Qiang, et al.Large-scale video copy retrieval with temporal-concentration SIFT[J].Neurocomputing, 2016, 187:83-91.
                            </a>
                        </p>
                        <p id="118">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Duplicate video detection for large-scale multimedia">

                                <b>[6]</b> JUN W, LEE Y, JUN B M.Duplicate video detection for large-scale multimedia[J].Multimedia Tools and Applications, 2015, 75 (23) :1-14.
                            </a>
                        </p>
                        <p id="120">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Effective and efficient global context verification for image copy detection">

                                <b>[7]</b> ZHOU Zhili, WANG Yunlong, WU Q M J, et al.Effective and efficient global context verification for image copy detection[J].IEEE Transactions on Information Forensics and Security, 2017, 12 (1) :48-63.
                            </a>
                        </p>
                        <p id="122">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Partial Copy Detection in Videos:A Benchmark and an Evaluation of Popular Methods">

                                <b>[8]</b> JIANG Yugang, WANG Jianjun.Partial copy detection in videos:a benchmark and an evaluation of popular methods[J].IEEE Transactions on Big Data, 2016, 2 (1) :32-42.
                            </a>
                        </p>
                        <p id="124">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Compact video fingerprinting via structural graphical models">

                                <b>[9]</b> LI Mu, MONGA V.Compact video fingerprinting via structural graphical models[J].IEEE Transactions on Information Forensics and Security, 2013, 8 (11) :1709-1721.
                            </a>
                        </p>
                        <p id="126">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatio-temporal transform based video hashing">

                                <b>[10]</b> COSKUN B, SANKUR B, MEMON N.Spatio-temporal transform based video hashing[J].IEEE Transactions on Multimedia, 2006, 8 (6) :1190-1208.
                            </a>
                        </p>
                        <p id="128">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Video fingerprinting based on centroids of gradient orientations">

                                <b>[11]</b> LEE S, YOO C D.Video fingerprinting based on centroids of gradient orientations[C]//Proceedings of IEEE International Conference on Acoustics Speech and Signal Processing Proceedings.Washongton D.C., USA:IEEE Press, 2006:1-4.
                            </a>
                        </p>
                        <p id="130">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatiotemporal energy models for the perception of motion">

                                <b>[12]</b> ADELSON E H, BERGEN J R.Spatiotemporal energy models for the perception of motion[J].Journal of the Optical Society of America A, 1985, 2 (2) :284-299.
                            </a>
                        </p>
                        <p id="132">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YYKX201606005&amp;v=MjE4ODRSTE9lWmVScUZDam5VTC9BUERUQWRyRzRIOWZNcVk5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 李新伟, 夏秀珍.基于内容结构图的鲁棒图像哈希[J].应用科学学报, 2016, 34 (6) :691-701.
                            </a>
                        </p>
                        <p id="134">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=PZKX201708012&amp;v=MDQ3MDVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2puVUwvQU5UZkFkckc0SDliTXA0OUVab1FLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 曾宪华, 袁知洪, 王国胤, 等.基于多特征多核哈希学习的大规模图像检索[J].中国科学:信息科学, 2017, 47 (8) :1109-1126.
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201705016&amp;v=Mjg1MDRkTEc0SDliTXFvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2puVUwvQUx5dlM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 刘胜蓝, 冯林, 孙木鑫, 等.分组排序多特征融合的图像检索方法[J].计算机研究与发展, 2017, 54 (5) :1067-1076.
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201305013&amp;v=MTg0MTJGQ2puVUwvQVB5cmZiTEc0SDlMTXFvOUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 林莹, 杨扬, 凌康, 等.多特征综合的视频拷贝检测[J].中国图象图形学报, 2013, 18 (5) :591-599.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201908043" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201908043&amp;v=MDQyMTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2puVUwvQUx6N0JiYkc0SDlqTXA0OUJaNFE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
