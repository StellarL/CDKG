<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131279106056250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201902041%26RESULT%3d1%26SIGN%3dQ1XABqYm2f78Y2IAgFTSOYc9Z4A%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902041&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902041&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902041&amp;v=MDA1NzZxQnRHRnJDVVJMT2VaZVJuRnlqa1ZiN0JMejdCYmJHNEg5ak1yWTlCWllRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#63" data-title="0概述 ">0概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#67" data-title="1 现有研究 ">1 现有研究</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#69" data-title="2 基于双稀疏优化的空域错误隐藏算法 ">2 基于双稀疏优化的空域错误隐藏算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="2.1 错误隐藏框架">2.1 错误隐藏框架</a></li>
                                                <li><a href="#73" data-title="2.2 图像生成">2.2 图像生成</a></li>
                                                <li><a href="#76" data-title="2.3 稀疏表示">2.3 稀疏表示</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#120" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#121" data-title="3.1 实验数据">3.1 实验数据</a></li>
                                                <li><a href="#124" data-title="3.2 参数设置">3.2 参数设置</a></li>
                                                <li><a href="#126" data-title="3.3 实验结果">3.3 实验结果</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#141" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#72" data-title="图1 本文算法整体框架">图1 本文算法整体框架</a></li>
                                                <li><a href="#75" data-title="图2 图像恢复过程">图2 图像恢复过程</a></li>
                                                <li><a href="#123" data-title="图3 测试图像">图3 测试图像</a></li>
                                                <li><a href="#129" data-title="图4 基于空域错误隐藏算法的Barbara恢复效果">图4 基于空域错误隐藏算法的Barbara恢复效果</a></li>
                                                <li><a href="#138" data-title="图5 不同空域错误隐藏算法的PSNR对比">图5 不同空域错误隐藏算法的PSNR对比</a></li>
                                                <li><a href="#139" data-title="图6 不同空域错误隐藏算法的MS＿SSIM对比">图6 不同空域错误隐藏算法的MS＿SSIM对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="33">


                                    <a id="bibliography_1" title="WIEGAND T, SULLIVAN G J, BJNTEGARD G.Overview of H.264/AVC video coding system[J].IEEE Transactions on Circuits System Video Technology, 2003, 13 (7) :560-576." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Overview of the H.264/AVC video coding standard">
                                        <b>[1]</b>
                                        WIEGAND T, SULLIVAN G J, BJNTEGARD G.Overview of H.264/AVC video coding system[J].IEEE Transactions on Circuits System Video Technology, 2003, 13 (7) :560-576.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_2" title="卢刘明, 陆肖元.基于网络丢包的网络视频质量评估[J].中国图像学报, 2009, 14 (1) :52-58." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB200901013&amp;v=MDM2NTg3QlB5cmZiTEc0SHRqTXJvOUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeWprVmI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        卢刘明, 陆肖元.基于网络丢包的网络视频质量评估[J].中国图像学报, 2009, 14 (1) :52-58.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_3" title="WANG Yao, WU Zhenyu, BOYCE J M.Modeling of transmission-loss-induced distortion in decoded video[J].IEEE Transactions on Circuits and Systems for Video Technology, 2006, 16 (6) :716-732." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modeling of transmission-loss-induced distortion in decoded video">
                                        <b>[3]</b>
                                        WANG Yao, WU Zhenyu, BOYCE J M.Modeling of transmission-loss-induced distortion in decoded video[J].IEEE Transactions on Circuits and Systems for Video Technology, 2006, 16 (6) :716-732.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_4" title="马宇峰, 魏维, 杨科利.视频通信中的错误隐藏技术[M].北京:国防工业出版社, 2007:122-156." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787118051667001&amp;v=MzIzOThsRFkrc1BEUk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWnU5dUZDdnNVNy9KSmw4ZFhGcXpHYks1RnRISnJv&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        马宇峰, 魏维, 杨科利.视频通信中的错误隐藏技术[M].北京:国防工业出版社, 2007:122-156.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_5" title="LI X.Image recovery via hybrid sparse representation:a deterministic annealing approach[J].IEEE Journal of Selected Topics in Signal Processing, 2011, 5 (5) :953-962." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Recovery Via Hybrid Sparse Representations: A Deterministic Annealing Approach">
                                        <b>[5]</b>
                                        LI X.Image recovery via hybrid sparse representation:a deterministic annealing approach[J].IEEE Journal of Selected Topics in Signal Processing, 2011, 5 (5) :953-962.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_6" title="LIU X, ZHAI D, ZHOU J.Sparsity-based image error concealment via adaptive dual dictionary learning and regularization[J].IEEE Transactions on Image Processing, 2016, 26 (2) :782-796." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparsity-based image error concealment via adaptive dual dictionary learning and regularization">
                                        <b>[6]</b>
                                        LIU X, ZHAI D, ZHOU J.Sparsity-based image error concealment via adaptive dual dictionary learning and regularization[J].IEEE Transactions on Image Processing, 2016, 26 (2) :782-796.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_7" title="SUN H, KWOK W.Concealment of damaged block transform coded images using projections onto convex sets[J].IEEETransactions on Image Processing, 1995, 4 (4) :470-477." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Concealment of damaged block transform coded images using projections onto convex sets">
                                        <b>[7]</b>
                                        SUN H, KWOK W.Concealment of damaged block transform coded images using projections onto convex sets[J].IEEETransactions on Image Processing, 1995, 4 (4) :470-477.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_8" title="SHIRANI S, KOSSENTINI F, WARD R.An adaptive Markov random field based error concealment method for video communication in an error prone environment[C]//Proceedings of 1999 IEEE International Conference on the Acoustics, Speech, and Signal Processing.Washington D.C., USA:IEEE Press, 1999:3117-3120." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An adaptive Markov random field based error concealment method for video communication in an error prone environment">
                                        <b>[8]</b>
                                        SHIRANI S, KOSSENTINI F, WARD R.An adaptive Markov random field based error concealment method for video communication in an error prone environment[C]//Proceedings of 1999 IEEE International Conference on the Acoustics, Speech, and Signal Processing.Washington D.C., USA:IEEE Press, 1999:3117-3120.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_9" title="LI X, ORCHARD M T.Novel sequential errorconcealment techniques using orientation adaptive interpolation[J].IEEE Transactions on Circuits System Video Technology, 2002, 12 (10) :857-864." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Novel sequential error-concealment techniques using orientation adaptive interpolation">
                                        <b>[9]</b>
                                        LI X, ORCHARD M T.Novel sequential errorconcealment techniques using orientation adaptive interpolation[J].IEEE Transactions on Circuits System Video Technology, 2002, 12 (10) :857-864.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_10" title="KOLODA J, OSTERGAARD J, JENSEN S H, et al.Sequential error concealment for video/images by sparse linear prediction[J].IEEE Transactions on Multimedia, 2013, 15 (4) :957-969." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sequential error concealment for video/images by sparse linear prediction">
                                        <b>[10]</b>
                                        KOLODA J, OSTERGAARD J, JENSEN S H, et al.Sequential error concealment for video/images by sparse linear prediction[J].IEEE Transactions on Multimedia, 2013, 15 (4) :957-969.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_11" title="LIU J, ZHAI G, YANG X, et al.Spatial error concealment with an adaptive linear predictor[J].IEEE Transactions on Circuits System Video Technology, 2015, 25 (3) :353-366." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatial error concealment with an adaptive linear predictor">
                                        <b>[11]</b>
                                        LIU J, ZHAI G, YANG X, et al.Spatial error concealment with an adaptive linear predictor[J].IEEE Transactions on Circuits System Video Technology, 2015, 25 (3) :353-366.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_12" title="练秋生, 张伟.基于图像块分类稀疏表示的超分辨率重构算法[J].电子学报, 2012, 40 (5) :920-925." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201205010&amp;v=MTM1MTFNcW85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5amtWYjdCSVRmVGU3RzRIOVA=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        练秋生, 张伟.基于图像块分类稀疏表示的超分辨率重构算法[J].电子学报, 2012, 40 (5) :920-925.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_13" title="ZHAI Deming, LIU Xianming, ZHOU Jiantao.Spatial error concealment via model based coupled sparse representation[C]//Proceedings of ICMEW’13.Washington D.C., USA:IEEE Press, 2013:1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatial error concealment via model based coupled sparse representation">
                                        <b>[13]</b>
                                        ZHAI Deming, LIU Xianming, ZHOU Jiantao.Spatial error concealment via model based coupled sparse representation[C]//Proceedings of ICMEW’13.Washington D.C., USA:IEEE Press, 2013:1-4.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_14" title="HARDOON D, S ZEDMAK S, SHAWE-TAYLOR J.Canonical correlation analysis:an overview with application to learning methods[J].Neural Computation, 2004, 16 (12) :2639-2664." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500012263&amp;v=Mjg3OTVQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGOFNheHM9TmlmSlpiSzlIdGpNcW85RlpPb05Ebm82b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        HARDOON D, S ZEDMAK S, SHAWE-TAYLOR J.Canonical correlation analysis:an overview with application to learning methods[J].Neural Computation, 2004, 16 (12) :2639-2664.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_15" title="余付平, 冯有前, 范成礼.基于主成分分析的字典学习[J].控制与决策, 2013, 28 (7) :1109-1112." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201307031&amp;v=MDIwMzlCTGpmU2JiRzRIOUxNcUk5R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5amtWYjc=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        余付平, 冯有前, 范成礼.基于主成分分析的字典学习[J].控制与决策, 2013, 28 (7) :1109-1112.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(02),245-249 DOI:10.19678/j.issn.1000-3428.0050093            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于双稀疏优化的空域错误隐藏</span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%A5%E9%9D%99%E6%96%87&amp;code=38707679&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">严静文</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%82%96%E6%99%B6&amp;code=17385900&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">肖晶</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%AB%98%E6%88%88&amp;code=09012457&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高戈</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E6%B1%89%E5%A4%A7%E5%AD%A6%E5%9B%BD%E5%AE%B6%E5%A4%9A%E5%AA%92%E4%BD%93%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83&amp;code=0009404&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武汉大学国家多媒体软件工程技术研究中心</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E6%B1%89%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武汉大学计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>现有空域错误隐藏算法通常利用线性插值或者常规稀疏表达恢复丢失像素, 但线性插值在恢复不平滑图像时因邻域信息不一致导致恢复图像模糊, 而常规稀疏表达因字典构建不当造成丢失像素重建效果较差。为此, 提出一种改进的空域错误隐藏算法, 采用动态阈值搜索潜在集合和模板集合提高字典构建精度, 利用典型相关分析获得双稀疏优化的初值, 通过稀疏重建恢复丢失像素。实验结果表明, 与现有主流算法相比, 该算法的峰值信噪比至少提高1. 23 dB, 具有较好的错误隐藏效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A9%BA%E5%9F%9F%E9%94%99%E8%AF%AF%E9%9A%90%E8%97%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">空域错误隐藏;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">线性插值;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=I%E5%B8%A7%E4%B8%A2%E5%A4%B1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">I帧丢失;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AD%97%E5%85%B8%E6%9E%84%E5%BB%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">字典构建;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A8%80%E7%96%8F%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">稀疏优化;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    严静文 (1990—) , 女, 硕士研究生, 主研方向为音频信号处理;E-mail: yanjingwen@ whu. edu. cn
;
                                </span>
                                <span>
                                    肖晶、副教授。
;
                                </span>
                                <span>
                                    高戈, 副教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61471271);</span>
                    </p>
            </div>
                    <h1>Spatial Error Concealment Based on Coupled Sparse Optimization</h1>
                    <h2>
                    <span>YAN Jingwen</span>
                    <span>XIAO Jing</span>
                    <span>GAO Ge</span>
            </h2>
                    <h2>
                    <span>National Engineering Research Center for Multimedia Software, Wuhan University</span>
                    <span>School of Computer, Wuhan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Linear interpolation algorithm or conventional sparse representation algorithm are used to recover the lost pixels currently. However, linear interpolation restores image blur due to inconsistent neighborhood information when restoring unsmooth images. For the conventional sparse representation algorithm, improper dictionary construction will result in a poor recovered image quality. To solve these problem, an improved spatial error concealment algorithm is proposed. The proposed algorithm optimizes the process of potential set and template set search by means of dynamic threshold searching, which improves the precision of the constructed dictionary. It can obtain the value of double sparse optimization using Canonical Correlation Analysis (CCA) , and recover lost pixels by sparse reconstruction. Experimental results show that the proposed algorithm improves the Peak Signal to Noise Ratio (PSNR) by at least 1. 23 dB compared with the current mainstream algorithm, and has a good error hiding effect.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spatial%20error%20concealment&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spatial error concealment;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=linear%20interpolation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">linear interpolation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=I-frame%20loss&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">I-frame loss;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dictionary%20construction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dictionary construction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sparse%20optimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sparse optimization;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-15</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="63" name="63" class="anchor-tag">0概述</h3>
                <div class="p1">
                    <p id="64">H.264/AVC编码标准<citation id="146" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>对比其他视频压缩标准在图像/视频压缩上具有更高的效率, 但是其带来高效率的同时, 容易引起压缩码流对信道误码更加敏感, 导致压缩码流在传输过程中更易发生丢包和错误<citation id="147" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。一个比特的丢失会在后续帧中引起错误扩散, 这将导致当前编码帧的失真, 严重影响接收端的图像质量。重传视频是解决这一问题的最简单方法, 但该方法在实际应用中因为带宽和实时性的限制, 实现代价高、实用性差。而错误隐藏的基本原理是在不改变编码器的情况下, 在解码端采用一系列错误隐藏算法恢复丢失信息来达到错误掩盖的效果。这样做的优势在于能保持原有码率, 不需要额外的带宽要求, 就可以较好地保证丢失信息图像的质量。</p>
                </div>
                <div class="p1">
                    <p id="65">通常错误隐藏算法分为空域错误隐藏<citation id="148" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、时域错误隐藏以及时空域错误隐藏<citation id="149" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。时域错误隐藏算法的核心思想是利用前一帧的运动矢量去预测后一帧, 然而在很多情况下, 运动矢量不易得到, 因而导致时域错误隐藏难以实现, 本文主要针对空域错误隐藏进行研究。空域错误隐藏算法通常基于邻域信息相关的特性, 利用周围信息进行线性插值来恢复丢失的像素。但空域错误隐藏算法存在的问题是:对于不平滑的图像, 甚至是丢失域占比很大的图像, 用于插值的邻近像素的选择会受到限制, 将会导致图像许多细节恢复的效果不好。</p>
                </div>
                <div class="p1">
                    <p id="66">近年来, 信号稀疏表达被广泛应用于图像处理中, 现有稀疏表达图像恢复问题所用技术基于离散余弦变换 (Discrete Cosine Transform, DCT) 和快速傅里叶变换 (Fast Fourier Transform, FFT) <citation id="150" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>, 并且用于稀疏重建的字典是线下训练的, 需要大量图片作为训练前提, 实际应用场景中无法使用单张图像进行训练。文献<citation id="151" type="reference">[<a class="sup">6</a>]</citation>提出的利用双稀疏表达 (Dual Spare Representation, DSR) 恢复丢失区域的方法使用y和y<sub>j</sub>的欧式距离小于某一阈值来确定用于构建字典的潜在集合和模板集合, 但由固定阈值带来的匹配块和潜在块选取不当会引起局部线性相关模型建立不准, 并且局部线性相关模型的选取不当会造成稀疏重建的初始值不准。针对上述问题, 本文提出基于稀疏优化的错误隐藏算法, 将固定阈值改为自适应阈值, 并利用典型相关分析 (Canonical Correlation Analysis, CCA) 作为局部线性相关模型, 以提高稀疏优化的准确性。</p>
                </div>
                <h3 id="67" name="67" class="anchor-tag">1 现有研究</h3>
                <div class="p1">
                    <p id="68">文献<citation id="152" type="reference">[<a class="sup">7</a>]</citation>提出一种凸集投影 (Projections onto Convex Sets, POCS) 约束方法。该方法利用先验知识及丢失块周围的信息确定凸集, 并通过傅里叶变换以及傅里叶逆变换不断迭代最终确定丢失像素值, 但POCS恢复的图像具有严重的块效应。文献<citation id="153" type="reference">[<a class="sup">8</a>]</citation>提出一种基于马尔可夫随机场 (Markov Random Field, M RF) 的错误隐藏技术, 通过计算丢失宏块的Sobel算子来确定用于错误隐藏的像素位置, 采用加权方式估计当前丢失的像素。文献<citation id="154" type="reference">[<a class="sup">9</a>]</citation>提出一种自适应序列插值 (Orientation Adaptive Interpolation, OAI) 方法, 将8个方向的预测值加权作为丢失像素的估计值, 该方法固定的扫描顺序会导致错误扩散。文献<citation id="155" type="reference">[<a class="sup">10</a>]</citation>提出一种线性稀疏预测 (Sparse Linear Prediction, SLP) 方法, 通过分析用于预测的权值与周围可知像素的关系, 推断两者呈一定的指数关系, 利用这一关系顺序地恢复出受损图像, 从而恢复纹理信息, 但是图像细节恢复效果不佳。文献<citation id="156" type="reference">[<a class="sup">11</a>]</citation>提出一种线性自适应预测 (Adaptive Linear Prediction, ALP) 方法, 可以根据当前环境自适应地调整扫描顺序和潜在像素集的形状, 但是丢失块内部像素的恢复效果不理想。目前基于稀疏表达的错误隐藏方法选择线下训练字典, 需要大量图片作为训练前提, 对于当前单张图像的恢复问题不适用, 因而无法应用于实际传输中错误的恢复。文献<citation id="157" type="reference">[<a class="sup">6</a>]</citation>提出一种双稀疏表达的方法。该方法通过主成分分析 (Principal Component Analysis, PCA) 进行字典构建, 解决了因数据不足造成字典训练无法完成的问题。上述方法存在的问题在于寻找用于重建的潜在像素不准, 因而重建图像质量不高。本文提出的稀疏优化算法, 利用自适应阈值提高搜索潜在像素集合和模板像素集合的准确性, 改善稀疏重建的效果, 使得受损图像的恢复效果更好。</p>
                </div>
                <h3 id="69" name="69" class="anchor-tag">2 基于双稀疏优化的空域错误隐藏算法</h3>
                <h4 class="anchor-tag" id="70" name="70">2.1 错误隐藏框架</h4>
                <div class="p1">
                    <p id="71">在H.264/AVC编码标准中, 视频/图像通常被划分为独立的宏块来进行帧内/帧间预测。经过H.264/编码后的码流通常分片打包传输, 丢失的一个数据包至少为一个16×16的宏块, 本文针对16×16宏块独立丢失的情况进行研究。本文算法的具体框架如图1所示, 针对2×2的小块进行错误隐藏, 当输入一张受损图像时, 本文算法将利用动态阈值确定与当前待恢复像素块对应的潜在像素块和模板像素块, 并建立对应潜在像素块和模板像素块的字典, 同时利用典型相关分析作为两者的局部线性相关模型, 通过稀疏重建恢复出丢失的像素。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902041_07200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文算法整体框架" src="Detail/GetImg?filename=images/JSJC201902041_07200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文算法整体框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902041_07200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="73" name="73">2.2 图像生成</h4>
                <div class="p1">
                    <p id="74">由于恢复16×16的块通常会造成错误扩散, 因此本文采用与文献<citation id="158" type="reference">[<a class="sup">6</a>]</citation>相同的设置。具体设置如图2 (a) 所示, x是丢失宏块中的一个2×2的小方块, y表示x周围6×6区域中所有像素值已知的区域;x<sub>j</sub>和y<sub>j</sub>所组成的区域形状与x和y组成的区域形状完全相同, x<sub>j</sub>和y<sub>j</sub>均为像素值已知的宏块。本文将所有像素值未知的区域定义为L, 所有像素值已知的区域定义为S。由图2 (a) 可知, 丢失的宏块大小为16×16, 并划分为64个2×2的小方块, 小方块的恢复顺序如图2 (b) 所示, 较亮区域的像素将优先恢复, 并为后续像素的恢复提供最大的置信度, 较暗区域表示像素随之被恢复。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902041_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 图像恢复过程" src="Detail/GetImg?filename=images/JSJC201902041_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 图像恢复过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902041_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="76" name="76">2.3 稀疏表示</h4>
                <div class="p1">
                    <p id="77">研究表明, 图像块可以被表示为字典的线性稀疏形式<citation id="159" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 这样可以通过为每个丢失块建立稀疏表达模型来恢复丢失的像素。稀疏模型的一般表示为:</p>
                </div>
                <div class="area_img" id="78">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_07800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="79">其中, Y表示原始信号, D=[d<sub>1</sub>, d<sub>2</sub>, …, d<sub>p</sub>]表示稀疏表达的字典矩阵, d<sub>i</sub> (i∈<citation id="160" type="reference"><link href="33" rel="bibliography" />[1, p</citation>]) 表示字典的基本向量, ε表示残差。当<image id="143" type="formula" href="images/JSJC201902041_14300.jpg" display="inline" placement="inline"><alt></alt></image><image id="143" type="formula" href="images/JSJC201902041_14301.jpg" display="inline" placement="inline"><alt></alt></image>时, 该模型是稀疏的。为了获得更高效的算法, 通常将l<sub>0</sub>范式转换为l<sub>1</sub>范式, 于是更新为如下形式:</p>
                </div>
                <div class="area_img" id="80">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="81">其中, λ为正则化参数, 其目的是为了平衡重建效果和稀疏性。最终原始信号的重建值为:</p>
                </div>
                <div class="area_img" id="82">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_08200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="83">同理, 丢失的像素块x的重建值可以表示为:</p>
                </div>
                <div class="area_img" id="84">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_08400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="85">其中, d<sub>x</sub>表示用于重建x的字典, ξ<sub>x</sub><sup>*</sup>表示用于稀疏重建中字典d<sub>x</sub>对应的系数矩阵。通过式 (4) 可知, 解决本文的关键在于字典d<sub>x</sub>及字典d<sub>x</sub>对应系数矩阵的求解。</p>
                </div>
                <h4 class="anchor-tag" id="86" name="86">2.3.1 集合匹配</h4>
                <div class="p1">
                    <p id="87">为确定潜在集合与模板集合, 即找到与x对应的潜在像素块x<sub>j</sub>以及与y对应的模板像素块y<sub>j</sub>。通过计算y与y<sub>j</sub>的欧式距离, 并使其小于某一阈值τ即可解决该问题<citation id="161" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 具体表示如下:</p>
                </div>
                <div class="area_img" id="88">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_08800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="89">其中, τ表示一个常数。由于固定的阈值会造成某些块匹配的不准确, 这将严重影响字典构建以及线性相关模型的准确性, 从而影响重建图像质量, 因此对式 (4) 进行改进, 得到:</p>
                </div>
                <div class="area_img" id="90">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_09000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="91">其中, L<sub>j</sub>为y和y<sub>j</sub>的欧式距离, 将所有的欧式距离进行升序排序, 获得排序后的欧式距离集合L={L<sub>1</sub>, L<sub>2</sub>, …, L<sub>K</sub>, L<sub>K+1</sub>, …, L<sub>N</sub>}。最终的K个潜在像素块和模板像素块可以通过式 (7) 获得:</p>
                </div>
                <div class="area_img" id="92">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_09200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="93">其中, L<sub>K</sub>表示当前待恢复像素周围的y与潜在像素块y<sub>K</sub>的欧式距离。由此可以得到最终的K个潜在像素块和模板像素块组成的集合分别为:潜在集合<image id="144" type="formula" href="images/JSJC201902041_14400.jpg" display="inline" placement="inline"><alt></alt></image>和模板集合<image id="145" type="formula" href="images/JSJC201902041_14500.jpg" display="inline" placement="inline"><alt></alt></image><image id="145" type="formula" href="images/JSJC201902041_14501.jpg" display="inline" placement="inline"><alt></alt></image></p>
                </div>
                <h4 class="anchor-tag" id="96" name="96">2.3.2 局部线性相关模型</h4>
                <div class="p1">
                    <p id="97">CCA作为多元统计学的一个重要部分, 是用于研究2组变量之间的一种统计分析方法, 能够有效地揭示2组变量之间的相互线性依赖关系, 通常应用于多重回归、判别分析和相应分析<citation id="162" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。给定两组变量U={u<sub>1</sub>, u<sub>2</sub>, …, u<sub>m</sub>}和V={v<sub>1</sub>, v<sub>2</sub>, …, v<sub>n</sub>}, CCA旨在找到两组向量w<sub>u</sub>和w<sub>v</sub>使得w<sub>u</sub><sup>T</sup>U和w<sub>v</sub><sup>T</sup>V的相关性最大, U和V的典型相关关系可以表示为:</p>
                </div>
                <div class="area_img" id="98">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_09800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="99">其中, ρ表示U和V的典型相关系数, cov (w<sub>u</sub><sup>T</sup>U, w<sub>v</sub><sup>T</sup>V) 表示w<sub>u</sub><sup>T</sup>U和w<sub>v</sub><sup>T</sup>V的协方差, 将式 (8) 变形可得:</p>
                </div>
                <div class="area_img" id="100">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="101">受到H.264/AVC中帧内预测的启发, 获知相邻像素之间存在强相关性。CCA通常用于两组变量之间的线性关系, 鉴于典型相关分析可以找到使两组变量最相关的对应系数矩阵。本文利用典型相关分析作为局部线性相关模型, 即找到可以使φ<sub>y</sub>和φ<sub>x</sub>相关性最大的对应系数矩阵W<sub>y</sub>和W<sub>x</sub>, 建立潜在集合φ<sub>y</sub>和模板集合φ<sub>x</sub>的相关关系, 相应的CCA模型为:</p>
                </div>
                <div class="area_img" id="102">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="103">其中, Λ是一个对角矩阵, 反映了y和y<sub>j</sub>的相似性, 表达式为:</p>
                </div>
                <div class="area_img" id="104">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_10400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="105">为了更好地变形式 (10) , 使x'=xΛ, y'=yΛ, C<sub>xx</sub>'=Λxx<sup>T</sup>Λ, C<sub>yy</sub>'=Λyy<sup>T</sup>Λ, 将式 (10) 变换为拉格朗日函数:</p>
                </div>
                <div class="area_img" id="106">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_10600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="107">根据式 (12) , 最终x的初值为:</p>
                </div>
                <div class="area_img" id="108">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="109">通过学习φ<sub>y</sub>和φ<sub>x</sub>的映射关系, 可以得到φ<sub>y</sub>和φ<sub>x</sub>的稀疏表达关系为:</p>
                </div>
                <div class="area_img" id="110">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="111">式 (14) 可以变换为:</p>
                </div>
                <div class="area_img" id="112">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_11200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="113">为方便表示, 令S=d<sub>x</sub><sup>T</sup>W<sub>x</sub><sup>-1</sup>W<sub>y</sub>d<sub>y</sub>。</p>
                </div>
                <div class="p1">
                    <p id="114">本文利用核主成分分析 (Kernel Principal Component Analysis, KPCA) 来学习潜在集合φ<sub>y</sub>和模板集合φ<sub>x</sub>对应的最相关字典d<sub>y</sub>和d<sub>x</sub>。KPCA方法结合KSVD方法与PCA方法, 可以降低构建字典的误差<sup>[</sup><citation id="163" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation><sup>]</sup>。</p>
                </div>
                <div class="p1">
                    <p id="115">最终采用双字典优化来求解ξ<sub>x</sub>, 具体表达式为:</p>
                </div>
                <div class="area_img" id="116">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_11600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="117">其中, x是最初的估计值。对式 (16) 进行求解, x可以表示为:</p>
                </div>
                <div class="area_img" id="118">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="119">当恢复x后, 剩余像素将按照图2 (b) 所示的顺序依次进行恢复, 先恢复较亮区域的像素, 再恢复较暗区域的像素。</p>
                </div>
                <h3 id="120" name="120" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="121" name="121">3.1 实验数据</h4>
                <div class="p1">
                    <p id="122">为测试本文算法的有效性, 在25%丢包率场景下选择错误隐藏算法常用的数据进行测试, 测试图像包括Barbara (512像素×512像素) 、Cameraman (256像素×256像素) 、Baboon (512像素×512像素) 、Goldhill (512像素×512像素) 、Butterfly (256像素×256像素) 、Plants (256像素×256像素) 、S-tarfish (256像素×256像素) 、Leaves (256像素×256像素) 、Peppers (512像素×512像素) 、Lena (512像素×512像素) , 如图3所示。</p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902041_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 测试图像" src="Detail/GetImg?filename=images/JSJC201902041_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 测试图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902041_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="124" name="124">3.2 参数设置</h4>
                <div class="p1">
                    <p id="125">本文需要设置的参数如下:当利用动态阈值寻找最佳潜在像素y<sub>j</sub>和模板像素x<sub>j</sub>时, 本文选出K=40个对应的潜在像素块和模板像素块。将式 (11) 中的Σ<sup>2</sup>根据经验设置为:Σ<sup>2</sup>=length (y) <citation id="164" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 即Σ<sup>2</sup>的值为y区域中用于估计x的像素个数。在本文所有实验中, λ值设置为0.000 1。</p>
                </div>
                <h4 class="anchor-tag" id="126" name="126">3.3 实验结果</h4>
                <h4 class="anchor-tag" id="127" name="127">3.3.1 主观实验结果</h4>
                <div class="p1">
                    <p id="128">为验证本文算法的有效性, 选择3组主流算法与本文算法进行对比, 包括SLP-E<citation id="165" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、ALP<citation id="166" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>这2种线性插值算法及双稀疏表达DSR算法<citation id="167" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。图4给出了Barbara使用其他空域错误隐藏算法和本文算法对图像进行错误恢复的主观结果。从图4 (c) 中可以看出, 本文算法可以较好地恢复受损图像, 尤其对受损图像眼睛和鼻子部分的恢复效果比其他算法好, 恢复的图像更加接近原始图像。</p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902041_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 基于空域错误隐藏算法的Barbara恢复效果" src="Detail/GetImg?filename=images/JSJC201902041_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 基于空域错误隐藏算法的Barbara恢复效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902041_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="130" name="130">3.3.2 客观实验结果</h4>
                <div class="p1">
                    <p id="131">本文使用峰值信噪比 (Peak Signal to Noise Ratio, PSNR) 和多尺度结构相似性 (Multi-scale Structural Similarity Index, MS＿SSIM) 这2个客观评价指标对算法进行评价。PSNR定义为:</p>
                </div>
                <div class="area_img" id="132">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_13200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="133">其中, MSE是受损图像及原图像的均方差。</p>
                </div>
                <div class="area_img" id="134">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_13400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="135">其中, m、n分别表示图像的行列数。MS＿SSIM定义为:</p>
                </div>
                <div class="area_img" id="136">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902041_13600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="137">其中, u<sub>I</sub>、u<sub>K</sub>分别表示图像I和图像K的均值, σ<sub>I</sub>、σ<sub>K</sub>分别表示图像I和图像K的标准差, σ<sub>IK</sub>表示2幅图像的协方差, C为常数。通过不同算法恢复的图像PSNR以及M S＿SSIM如图5、图6所示。</p>
                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902041_13800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同空域错误隐藏算法的PSNR对比" src="Detail/GetImg?filename=images/JSJC201902041_13800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同空域错误隐藏算法的PSNR对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902041_13800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902041_13900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同空域错误隐藏算法的MS＿SSIM对比" src="Detail/GetImg?filename=images/JSJC201902041_13900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同空域错误隐藏算法的MS＿SSIM对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902041_13900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="140">从图5可以看出, 本文算法的PSNR比ALP错误隐藏算法平均提高1.9 dB, 比DSR算法平均提高1.23 dB。另外, 本文算法对于Barbara、Lena的提升效果更明显, 而对于Camera、Plants的提升幅度较小。这是由于Cameraman中的三脚架与地面的区别很小, 在恢复过程中通常出现三脚架柱子截断的现象;而对于Plants来说, 内部的白色区域在恢复时会发生边缘抖动的现象。从图6可以看出, 本文算法的MS＿SSIM对比DSR算法平均提高1.72%。对于Barabara、Plants、Peppers、Lena这些图像, 恢复图像的结构相似性高达99%, 由此可以看出本文算法可以更好地还原图像。</p>
                </div>
                <h3 id="141" name="141" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="142">针对码流传输过程中图像部分像素丢失的情况, 线性插值算法在处理非平滑图像时效果不理想, 稀疏表达算法在构建算法字典时不能满足实时传输的需要。为解决上述问题, 本文提出一种基于双稀疏优化的空域错误隐藏算法。该算法采用动态阈值搜索潜在像素集合与模板像素集合, 利用CCA建立集合之间的关系, 基于KPCA构建集合字典, 通过稀疏表达重建丢失的像素。实验结果表明, 本文算法恢复的图像主观效果相较于其他算法具有明显提升, 错误隐藏效果较好。但该算法在搜索潜在像素集合与模板像素集合时使用多层循环, 需要进行多次迭代恢复, 从而造成运算复杂度较高, 因此下一步将对集合搜索算法进行优化, 降低运算复杂度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="33">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Overview of the H.264/AVC video coding standard">

                                <b>[1]</b>WIEGAND T, SULLIVAN G J, BJNTEGARD G.Overview of H.264/AVC video coding system[J].IEEE Transactions on Circuits System Video Technology, 2003, 13 (7) :560-576.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB200901013&amp;v=Mjg4NDRSTE9lWmVSbkZ5amtWYjdCUHlyZmJMRzRIdGpNcm85RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>卢刘明, 陆肖元.基于网络丢包的网络视频质量评估[J].中国图像学报, 2009, 14 (1) :52-58.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modeling of transmission-loss-induced distortion in decoded video">

                                <b>[3]</b>WANG Yao, WU Zhenyu, BOYCE J M.Modeling of transmission-loss-induced distortion in decoded video[J].IEEE Transactions on Circuits and Systems for Video Technology, 2006, 16 (6) :716-732.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787118051667001&amp;v=MTU0MjFsOGRYRnF6R2JLNUZ0SEpyb2xEWStzUERSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZadTl1RkN2c1U3L0pK&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>马宇峰, 魏维, 杨科利.视频通信中的错误隐藏技术[M].北京:国防工业出版社, 2007:122-156.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Recovery Via Hybrid Sparse Representations: A Deterministic Annealing Approach">

                                <b>[5]</b>LI X.Image recovery via hybrid sparse representation:a deterministic annealing approach[J].IEEE Journal of Selected Topics in Signal Processing, 2011, 5 (5) :953-962.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparsity-based image error concealment via adaptive dual dictionary learning and regularization">

                                <b>[6]</b>LIU X, ZHAI D, ZHOU J.Sparsity-based image error concealment via adaptive dual dictionary learning and regularization[J].IEEE Transactions on Image Processing, 2016, 26 (2) :782-796.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Concealment of damaged block transform coded images using projections onto convex sets">

                                <b>[7]</b>SUN H, KWOK W.Concealment of damaged block transform coded images using projections onto convex sets[J].IEEETransactions on Image Processing, 1995, 4 (4) :470-477.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An adaptive Markov random field based error concealment method for video communication in an error prone environment">

                                <b>[8]</b>SHIRANI S, KOSSENTINI F, WARD R.An adaptive Markov random field based error concealment method for video communication in an error prone environment[C]//Proceedings of 1999 IEEE International Conference on the Acoustics, Speech, and Signal Processing.Washington D.C., USA:IEEE Press, 1999:3117-3120.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Novel sequential error-concealment techniques using orientation adaptive interpolation">

                                <b>[9]</b>LI X, ORCHARD M T.Novel sequential errorconcealment techniques using orientation adaptive interpolation[J].IEEE Transactions on Circuits System Video Technology, 2002, 12 (10) :857-864.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sequential error concealment for video/images by sparse linear prediction">

                                <b>[10]</b>KOLODA J, OSTERGAARD J, JENSEN S H, et al.Sequential error concealment for video/images by sparse linear prediction[J].IEEE Transactions on Multimedia, 2013, 15 (4) :957-969.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatial error concealment with an adaptive linear predictor">

                                <b>[11]</b>LIU J, ZHAI G, YANG X, et al.Spatial error concealment with an adaptive linear predictor[J].IEEE Transactions on Circuits System Video Technology, 2015, 25 (3) :353-366.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201205010&amp;v=MjAyMDVMT2VaZVJuRnlqa1ZiN0JJVGZUZTdHNEg5UE1xbzlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>练秋生, 张伟.基于图像块分类稀疏表示的超分辨率重构算法[J].电子学报, 2012, 40 (5) :920-925.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatial error concealment via model based coupled sparse representation">

                                <b>[13]</b>ZHAI Deming, LIU Xianming, ZHOU Jiantao.Spatial error concealment via model based coupled sparse representation[C]//Proceedings of ICMEW’13.Washington D.C., USA:IEEE Press, 2013:1-4.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500012263&amp;v=MjU0NDRxbzlGWk9vTkRubzZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklJRjhTYXhzPU5pZkpaYks5SHRqTQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>HARDOON D, S ZEDMAK S, SHAWE-TAYLOR J.Canonical correlation analysis:an overview with application to learning methods[J].Neural Computation, 2004, 16 (12) :2639-2664.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201307031&amp;v=MzEzMjViRzRIOUxNcUk5R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5amtWYjdCTGpmU2I=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>余付平, 冯有前, 范成礼.基于主成分分析的字典学习[J].控制与决策, 2013, 28 (7) :1109-1112.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201902041" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902041&amp;v=MDA1NzZxQnRHRnJDVVJMT2VaZVJuRnlqa1ZiN0JMejdCYmJHNEg5ak1yWTlCWllRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
