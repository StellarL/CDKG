<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637129055337618750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201908044%26RESULT%3d1%26SIGN%3dDw0e0shJo97fBXTlpUJkGP92a5U%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201908044&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201908044&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201908044&amp;v=MjU1NDdlWmVScUZDamxXcnZMTHo3QmJiRzRIOWpNcDQ5QllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#53" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#56" data-title="1 基于核相关滤波器的目标跟踪 ">1 基于核相关滤波器的目标跟踪</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#87" data-title="2 自适应多特征联合模型的目标跟踪算法 ">2 自适应多特征联合模型的目标跟踪算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#89" data-title="2.1 基于&lt;i&gt;L&lt;/i&gt;1范数的核相关滤波器跟踪模型">2.1 基于<i>L</i>1范数的核相关滤波器跟踪模型</a></li>
                                                <li><a href="#112" data-title="2.2 基于颜色直方图的跟踪模型">2.2 基于颜色直方图的跟踪模型</a></li>
                                                <li><a href="#125" data-title="2.3 模型联合位置估计">2.3 模型联合位置估计</a></li>
                                                <li><a href="#134" data-title="2.4 尺度估计">2.4 尺度估计</a></li>
                                                <li><a href="#142" data-title="2.5 算法框架">2.5 算法框架</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#145" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#147" data-title="3.1 实验参数">3.1 实验参数</a></li>
                                                <li><a href="#149" data-title="3.2 评估方法">3.2 评估方法</a></li>
                                                <li><a href="#153" data-title="3.3 结果分析">3.3 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#163" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#130" data-title="&lt;b&gt;图1 KCF算法的响应情况&lt;/b&gt;"><b>图1 KCF算法的响应情况</b></a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;图2 本文跟踪算法框架&lt;/b&gt;"><b>图2 本文跟踪算法框架</b></a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;图3 主流跟踪算法在不同干扰下的准确率对比&lt;/b&gt;"><b>图3 主流跟踪算法在不同干扰下的准确率对比</b></a></li>
                                                <li><a href="#157" data-title="&lt;b&gt;图4 主流跟踪算法在不同干扰下的成功率对比&lt;/b&gt;"><b>图4 主流跟踪算法在不同干扰下的成功率对比</b></a></li>
                                                <li><a href="#158" data-title="&lt;b&gt;表1 精度前10名算法的速度对比&lt;/b&gt;"><b>表1 精度前10名算法的速度对比</b></a></li>
                                                <li><a href="#160" data-title="&lt;b&gt;表2 6个视频序列的干扰因素&lt;/b&gt;"><b>表2 6个视频序列的干扰因素</b></a></li>
                                                <li><a href="#161" data-title="&lt;b&gt;图5 3种算法在6个视频序列上的跟踪结果对比&lt;/b&gt;"><b>图5 3种算法在6个视频序列上的跟踪结果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="190">


                                    <a id="bibliography_1" title=" 张晶, 王旭, 范洪博.自适应学习的时空上下文目标跟踪算法[J].计算机工程, 2018, 44 (6) :294-299." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201806050&amp;v=Mjc2NDRSTE9lWmVScUZDamxXcnZMTHo3QmJiRzRIOW5NcVk5QVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         张晶, 王旭, 范洪博.自适应学习的时空上下文目标跟踪算法[J].计算机工程, 2018, 44 (6) :294-299.
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_2" title=" WANG Naiyan, SHI Jianping, YEUNG D Y, et al.Understanding and diagnosing visual tracking systems[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2015:3101-3109." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Understanding and diagnosing visual tracking systems">
                                        <b>[2]</b>
                                         WANG Naiyan, SHI Jianping, YEUNG D Y, et al.Understanding and diagnosing visual tracking systems[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2015:3101-3109.
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_3" title=" 孔军, 成静, 蒋敏, 等.组合范数正则化稀疏编码和自适应加权残差的鲁棒跟踪[J].计算机辅助设计与图形学学报, 2018, 30 (4) :634-641." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201804011&amp;v=MzI2NjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2psV3J2TEx6N0JhTEc0SDluTXE0OUVaWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         孔军, 成静, 蒋敏, 等.组合范数正则化稀疏编码和自适应加权残差的鲁棒跟踪[J].计算机辅助设计与图形学学报, 2018, 30 (4) :634-641.
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_4" title=" 魏全禄, 老松杨, 白亮.基于相关滤波器的视觉目标跟踪综述[J].计算机科学, 2016, 43 (11) :1-5." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201611002&amp;v=MzI3NTdydkxMejdCYjdHNEg5Zk5ybzlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRkNqbFc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         魏全禄, 老松杨, 白亮.基于相关滤波器的视觉目标跟踪综述[J].计算机科学, 2016, 43 (11) :1-5.
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_5" title=" BOLME D S, BEVERIDGE J R, DRAPER B A, et al.Visual object tracking using adaptive correlation filters[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2010:2544-2550." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual object tracking using adaptive correlation filters">
                                        <b>[5]</b>
                                         BOLME D S, BEVERIDGE J R, DRAPER B A, et al.Visual object tracking using adaptive correlation filters[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2010:2544-2550.
                                    </a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_6" title=" HENRIQUES J F, CASEIRO R, MARTINS P, et al.Exploiting the circulant structure of tracking-by-detection with kernels[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2012:702-715." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of tracking-by-detection with kernels">
                                        <b>[6]</b>
                                         HENRIQUES J F, CASEIRO R, MARTINS P, et al.Exploiting the circulant structure of tracking-by-detection with kernels[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2012:702-715.
                                    </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_7" title=" HENRIQUES J F, RUI C, MARTINS P, et al.High-speed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2014, 37 (3) :583-596." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Highspeed tracking with kernelized correlation filters">
                                        <b>[7]</b>
                                         HENRIQUES J F, RUI C, MARTINS P, et al.High-speed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2014, 37 (3) :583-596.
                                    </a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_8" title=" DALAL N, TRIGGS B.Histograms of oriented gradients for human detection[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2005:886-893." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Histograms of oriented gradients for human detection">
                                        <b>[8]</b>
                                         DALAL N, TRIGGS B.Histograms of oriented gradients for human detection[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2005:886-893.
                                    </a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_9" title=" YAO Rui, XIA Shixiong, ZHANG Zhen, et al.Real-time correlation filter tracking by efficient dense belief propagation with structure preserving[J].IEEE Transactions on Multimedia, 2017, 19 (4) :772-784." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time correlation filter tracking by efficient dense belief propagation with structure preserving">
                                        <b>[9]</b>
                                         YAO Rui, XIA Shixiong, ZHANG Zhen, et al.Real-time correlation filter tracking by efficient dense belief propagation with structure preserving[J].IEEE Transactions on Multimedia, 2017, 19 (4) :772-784.
                                    </a>
                                </li>
                                <li id="208">


                                    <a id="bibliography_10" title=" 李冠彬, 吴贺丰.基于颜色纹理直方图的带权分块均值漂移目标跟踪算法[J].计算机辅助设计与图形学学报, 2011, 23 (12) :2059-2066." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201112017&amp;v=MjAwMzdydkxMejdCYUxHNEg5RE5yWTlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRkNqbFc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         李冠彬, 吴贺丰.基于颜色纹理直方图的带权分块均值漂移目标跟踪算法[J].计算机辅助设计与图形学学报, 2011, 23 (12) :2059-2066.
                                    </a>
                                </li>
                                <li id="210">


                                    <a id="bibliography_11" title=" POSSEGGER H, MAUTHNER T, BISCHOF H.In defense of color-based model-free tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:2113-2120." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=In defense of color-based model-free tracking">
                                        <b>[11]</b>
                                         POSSEGGER H, MAUTHNER T, BISCHOF H.In defense of color-based model-free tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:2113-2120.
                                    </a>
                                </li>
                                <li id="212">


                                    <a id="bibliography_12" title=" BERTINETTO L, VALMADRE J, GOLODETZ S, et al.Staple:complementary learners for real-time tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2016:1401-1409." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Staple:Complementary learners for realtime tracking">
                                        <b>[12]</b>
                                         BERTINETTO L, VALMADRE J, GOLODETZ S, et al.Staple:complementary learners for real-time tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2016:1401-1409.
                                    </a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_13" title=" BAO Chenglong, WU Yi, LING Haibin, et al.Real time robust L1 tracker using accelerated proximal gradient approach[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:1830-1837." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real time robust l1 tracker using accelerated proximal gradient approach">
                                        <b>[13]</b>
                                         BAO Chenglong, WU Yi, LING Haibin, et al.Real time robust L1 tracker using accelerated proximal gradient approach[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:1830-1837.
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_14" title=" WILLIAMS C K I.Learning with kernels:support vector machines, regularization, optimization, and beyond[J].Publications of the American Statistical Association, 2003, 98 (462) :489-489." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800007020&amp;v=MTI4NTk3SHRmT3A0OUZaT3NJREg0NW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUx2TElGNGRiaEU9TmpuQmFySw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         WILLIAMS C K I.Learning with kernels:support vector machines, regularization, optimization, and beyond[J].Publications of the American Statistical Association, 2003, 98 (462) :489-489.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_15" title=" RIFKIN R, YEO G, POGGIO T.Regularized least-squares classification[EB/OL].[2018-08-25].http://cbcl.mit.edu/publications/ps/rlsc.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Regularized least-squares classification">
                                        <b>[15]</b>
                                         RIFKIN R, YEO G, POGGIO T.Regularized least-squares classification[EB/OL].[2018-08-25].http://cbcl.mit.edu/publications/ps/rlsc.pdf.
                                    </a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_16" title=" JIANG Min, SHEN Jianyu, KONG Jun, et al.Robust visual tracking based on kernelized correlation filters[C]//Proceedings of IEEE International Conference on Information and Automation.Washington D.C., USA:IEEE Press, 2017:110-115." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust visual tracking based on kernelized correlation filters">
                                        <b>[16]</b>
                                         JIANG Min, SHEN Jianyu, KONG Jun, et al.Robust visual tracking based on kernelized correlation filters[C]//Proceedings of IEEE International Conference on Information and Automation.Washington D.C., USA:IEEE Press, 2017:110-115.
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     BECK A, TEBOULLE M.A fast iterative shrinkage-thresholding algorithm for linear inverse problems[J].SIAM Journal on Imaging Sciences, 2009, 2 (1) :183-202.</a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_18" title=" DANELLJAN M, H GER G, KHAN F S, et al.Accurate scale estimation for robust visual tracking[C]//Proceedings of British Machine Vision Conference.[S.l.]:BMVA Press, 2014:1-11." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accurate scale estimation for robust visual tracking">
                                        <b>[18]</b>
                                         DANELLJAN M, H GER G, KHAN F S, et al.Accurate scale estimation for robust visual tracking[C]//Proceedings of British Machine Vision Conference.[S.l.]:BMVA Press, 2014:1-11.
                                    </a>
                                </li>
                                <li id="226">


                                    <a id="bibliography_19" title=" WU Yi, LIM J, YANG Minghuan.Online object tracking:a benchmark[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2013:2411-2418." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Online object tracking:A benchmark">
                                        <b>[19]</b>
                                         WU Yi, LIM J, YANG Minghuan.Online object tracking:a benchmark[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2013:2411-2418.
                                    </a>
                                </li>
                                <li id="228">


                                    <a id="bibliography_20" title=" BIBI A, GHANEM B.Multi-template scale-adaptive kernelized correlation filters[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2015:613-620." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-template Scale-Adaptive Kernelized Correlation Filters">
                                        <b>[20]</b>
                                         BIBI A, GHANEM B.Multi-template scale-adaptive kernelized correlation filters[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2015:613-620.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(08),266-274 DOI:10.19678/j.issn.1000-3428.0052593            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于自适应多模型联合的目标跟踪算法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%BB%BB%E5%8D%8E&amp;code=09753259&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王任华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B2%88%E5%89%91%E5%AE%87&amp;code=35779299&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">沈剑宇</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%92%8B%E6%95%8F&amp;code=10801746&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蒋敏</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%B0%91%E5%85%AC%E5%AE%89%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E6%8A%80%E6%9C%AF%E4%B8%8E%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=0021316&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国人民公安大学信息技术与网络安全学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B1%9F%E5%8D%97%E5%A4%A7%E5%AD%A6%E7%89%A9%E8%81%94%E7%BD%91%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0074200&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">江南大学物联网工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>基于核相关滤波器的跟踪算法对于目标的空间结构具有较强的依赖性, 无法有效应对遮挡、形变等干扰因素, 且单一的特征模型在复杂的跟踪场景下无法准确表述目标信息。为此, 提出一种基于自适应多模型联合的算法。通过自适应权重将相关滤波模型与颜色直方图模型进行联合, 并将稀疏表示的思想引入相关滤波模型的训练过程中, 以增强算法的鲁棒性。OTB视频序列数据集上的实验结果表明, 该算法可有效缓解跟踪过程中的遮挡、形变等因素的干扰, 与Staple算法、KCF算法相比, 目标跟踪的精度显著提升。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标跟踪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E9%80%82%E5%BA%94%E6%9D%83%E9%87%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自适应权重;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A0%B8%E7%9B%B8%E5%85%B3%E6%BB%A4%E6%B3%A2%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">核相关滤波器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%94%E5%90%88%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">联合模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%3Ci%3EL%3C%2Fi%3E1%E8%8C%83%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank"><i>L</i>1范数;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王任华 (1972—) , 女, 副教授、硕士, 主研方向为视频侦查、模式识别;E-mail: renhuawang@ 163. com;
                                </span>
                                <span>
                                    沈剑宇, 硕士研究生;;
                                </span>
                                <span>
                                    蒋敏, 教授、博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-07</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61362030, 61201429);</span>
                                <span>中国博士后科学基金 (2015M581720, 2016M600360);</span>
                                <span>科技援疆专项计划 (2017E0279);</span>
                                <span>公安部技术研究计划 (2018JSYJA01);</span>
                    </p>
            </div>
                    <h1><b>Target Tracking Algorithm Based on Adaptive Multi-Model Joint</b></h1>
                    <h2>
                    <span>WANG Renhua</span>
                    <span>SHEN Jianyu</span>
                    <span>JIANG Min</span>
            </h2>
                    <h2>
                    <span>College of Information Technology and Network Security, People's Public Security University of China</span>
                    <span>School of Internet of Things Engineering, Jiangnan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The tracking algorithm based on Kernelized Correlation Filter (KCF) has strong dependence on the spatial structure of the target, cannot effectively deal with the occlusion, deformation and other interference factors, and the single feature model is unable to accurately represent the target information in complex tracking occasions.Therefore, an adaptive multi-model tracking algorithm is proposed.The correlation filter model and the color histogram model are combined by adaptive weight, and the idea of sparse representation is introduced into the training process of the correlation filter model to further enhance the robustness of the algorithm.Experimental results on the OTB dataset show that the algorithm can effectively mitigate the interferences from various factors such as occlusion and deformation in the tracking process, and compred with Staple algorithm, KCF algorithm and others, the algorithm achieves significant improvement in target tracking accuracy.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=target%20tracking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">target tracking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=adaptive%20weight&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">adaptive weight;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Kernelized%20Correlation%20Filter%20(KCF)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Kernelized Correlation Filter (KCF) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=joint%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">joint model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=L1%20norm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">L1 norm;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-09-07</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="53" name="53" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="54">目标跟踪作为机器视觉领域最具挑战性的研究内容之一, 受到国内外研究者的关注和重视, 其在视频监控、无人驾驶、智能诊断、人机交互等领域有不同程度的应用<citation id="230" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。但在实际复杂的环境中, 跟踪目标时会出现多种干扰因素, 包括目标遮挡、目标形变、外部光照变化、背景杂乱等<citation id="231" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。这些干扰因素会导致非目标像素的累积, 产生漂移现象, 最终跟踪失败<citation id="232" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。近年来, 相关滤波器因其计算速度和定位性能在目标跟踪领域取得许多成功的应用<citation id="233" type="reference"><link href="196" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。文献<citation id="234" type="reference">[<a class="sup">5</a>]</citation>将相关滤波器应用到目标跟踪领域, 提出基于最小输出平方和误差 (Minimum Output Sum of Squared Error, MOSSE) 的相关滤波器。文献<citation id="235" type="reference">[<a class="sup">6</a>]</citation>在此基础上提出基于循环结构的核检测跟踪 (Circulant Structure of tracking-by-detection with Kernel, CSK) 算法, 利用循环移位进行密集采样并引入岭回归。然而, CSK算法仅采用灰度特征, 缺乏对目标信息的完整表述。文献<citation id="236" type="reference">[<a class="sup">7</a>]</citation>将核方法引入CSK中, 并与梯度方向直方图 (Histogram of Oriented Gradient, HOG) <citation id="237" type="reference"><link href="204" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>特征结合, 提出核相关滤波器 (Kernelized Correlation Filter, KCF) , 其在速度和精度上都取得较好的效果。KCF算法对空间结构的依赖性导致其对形变、遮挡等干扰敏感<citation id="238" type="reference"><link href="206" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。当目标发生形变时, 目标以及背景的整体颜色分布并不会随之改变, 因此, 基于颜色直方图的跟踪算法可以很好地应对形变等干扰因素<citation id="239" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>的影响, 但这类方法易受背景中相似颜色物体的干扰, 对运动模糊和光照变化等因素较为敏感。文献<citation id="240" type="reference">[<a class="sup">11</a>]</citation>提出颜色感知算法 (Distractor-Aware Tracker, DAT) , 通过自适应阈值来抑制与目标颜色相似的背景的影响, 但对于背景混杂的情况, 其判别性与基于相关滤波的跟踪算法相比有一定的欠缺。文献<citation id="241" type="reference">[<a class="sup">12</a>]</citation>在此基础上提出Staple算法, 通过分配固定的权重将DAT算法与基于核相关滤波器的算法进行联合学习, 取得较好的效果, 但是固定权重的联合在复杂情况下无法体现其优势。</p>
                </div>
                <div class="p1">
                    <p id="55">在上述研究的基础上, 本文提出基于自适应多模型联合的跟踪算法, 将KCF跟踪模型和基于颜色直方图的跟踪模型进行联合。在目标位置评估时, 采用自适应权重联合的策略, 充分利用2种模型的互补特性, 实现鲁棒的目标跟踪。由于在跟踪过程中, 多种干扰因素会对目标外观产生影响, 本文在KCF模型训练的过程中加入<i>L</i>1范数的正则化<citation id="242" type="reference"><link href="214" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 利用稀疏跟踪的部分思想, 使滤波器能更好地拟合目标期望值, 以提高算法的精确度。</p>
                </div>
                <h3 id="56" name="56" class="anchor-tag">1 基于核相关滤波器的目标跟踪</h3>
                <div class="p1">
                    <p id="57">KCF算法在候选区域内通过对基样本循环移位采样获取大量训练样本, 对于得到的训练样本与标签<mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>) </mo></mrow><mo>, </mo><mrow><mo> (</mo><mrow><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>) </mo></mrow><mo>, </mo><mo>⋯</mo><mo>, </mo><mrow><mo> (</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>n</mi></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>) </mo></mrow></mrow></math></mathml>, 利用岭回归对滤波器<i>w</i>进行训练, 使得样本<i>x</i><sub><i>i</i></sub>与高斯型的期望值<i>y</i><sub><i>i</i></sub>之间的平方误差最小并获得闭合解。KCF算法的损失函数如下:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>w</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">w</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>) </mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">其中, <i>λ</i>为惩罚项。上式的矩阵形式可以表示为:</p>
                </div>
                <div class="p1">
                    <p id="61" class="code-formula">
                        <mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>w</mi></munder><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">w</mi><mo>-</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="62">其中, <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">X</mi><mo>=</mo><mrow><mrow><mo>[</mo><mrow><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>]</mo></mrow></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>为训练样本矩阵。对<b><i>w</i></b>求导, 并令导数为0, 得如下解:</p>
                </div>
                <div class="p1">
                    <p id="64"><b><i>w</i></b>= (<b><i>X</i></b><sup>T</sup><b><i>X</i></b>+<i>λ</i><b><i>I</i></b>) <sup>-1</sup><b><i>X</i></b><sup>T</sup><b><i>y</i></b>      (3) </p>
                </div>
                <div class="p1">
                    <p id="65">为了将上式转换到傅里叶域内, 实现快速计算, 先将上式转化为复数域表达:</p>
                </div>
                <div class="p1">
                    <p id="66"><b><i>w</i></b>= (<b><i>X</i></b><sup>H</sup><b><i>X</i></b>+<i>λ</i><b><i>I</i></b>) <sup>-1</sup><b><i>X</i></b><sup>H</sup><b><i>y</i></b>      (4) </p>
                </div>
                <div class="p1">
                    <p id="67">其中, <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Η</mtext></msup><mo>=</mo><mrow><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mo>*</mo></msup></mrow><mo>) </mo></mrow></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow></math></mathml>为<b><i>X</i></b>的复共轭转置矩阵, <b><i>X</i></b><sup>*</sup>表示<b><i>X</i></b>的复共轭。一般通过求解高维线性方程得到式 (4) 的解, KCF算法可以根据循环矩阵的特性, 利用离散傅里叶变换 (Discrete Fourier Transform, DFT) 来避免求解高维线性方程, 节省计算时间。此时, <b><i>X</i></b>可表示为如下形式:</p>
                </div>
                <div class="p1">
                    <p id="69"><b><i>X</i></b>=<b><i>F</i></b>diag<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><mo>) </mo></mrow><mi mathvariant="bold-italic">F</mi><msup><mrow></mrow><mtext>Η</mtext></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="71">其中, <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow></math></mathml>为DFT变换后的结果, <b><i>F</i></b>为离散傅里叶矩阵, 是常量。由此, 式 (4) 可以表示为:</p>
                </div>
                <div class="p1">
                    <p id="73"><b><i>w</i></b>=<b><i>F</i></b>diag<mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msup><mrow></mrow><mo>*</mo></msup></mrow><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msup><mrow></mrow><mo>*</mo></msup><mo>⊙</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>+</mo><mi>λ</mi></mrow></mfrac></mrow><mo>) </mo></mrow><mi mathvariant="bold-italic">F</mi><msup><mrow></mrow><mtext>Η</mtext></msup><mi mathvariant="bold-italic">y</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="75">其中, ⊙表示按像素点相乘。利用循环矩阵的卷积性质将上式简化为:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">w</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>=</mo><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msup><mrow></mrow><mo>*</mo></msup><mo>⊙</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msup><mrow></mrow><mo>*</mo></msup><mo>⊙</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">x</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>+</mo><mi>λ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">其中, <i>F</i>表示DFT。由此时域中的解<b><i>w</i></b>可以通过傅里叶逆变换得到, 避免复杂矩阵的求逆等运算。对一幅<i>m</i>×<i>m</i>的图像实行卷积操作, 其时间复杂度为<i>O</i> (<i>m</i><sup>4</sup>) , 通过DFT变换将卷积操作转化到频域中, 则相同情形下所需的时间复杂度仅为<i>O</i> (<i>m</i><sup>2</sup>lg <i>m</i>) , 计算速率得到大幅提升。</p>
                </div>
                <div class="p1">
                    <p id="78">考虑到实际应用中大量的非线性可分数据, 文献<citation id="243" type="reference">[<a class="sup">7</a>]</citation>引入核方法, 利用高低维空间之间的映射关系, 将参数转换到对偶空间, 则<b><i>w</i></b>可由映射后的样本<i>φ</i> (<i>x</i>) 的线性组合<citation id="244" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>表示:<mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">w</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>α</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>φ</mi><mrow><mo> (</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>) </mo></mrow></mrow></math></mathml>, 由此得到岭回归的解<citation id="245" type="reference"><link href="218" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="80"><i>α</i>= (<b><i>K</i></b>+<i>λ</i><b><i>I</i></b>) <sup>-1</sup><b><i>y</i></b>      (8) </p>
                </div>
                <div class="p1">
                    <p id="81">其中, <i>α</i>是由<i>α</i><sub><i>i</i></sub>构成的向量, <b><i>K</i></b>为核矩阵, 由核函数<mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>k</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>x</mi><mo>´</mo><mo stretchy="false">) </mo></mrow><mo>=</mo><mi mathvariant="bold-italic">φ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mrow><mo> (</mo><mi>x</mi><mo>) </mo></mrow><mi mathvariant="bold-italic">φ</mi><mrow><mo> (</mo><mrow><mi>x</mi><mo>´</mo></mrow><mo>) </mo></mrow></mrow></math></mathml>组成, <b><i>I</i></b>为单位矩阵。无论是线性核、高斯核还是多项式核, 大部分的核函数都满足循环结构。因而, 可以利用循环矩阵在傅里叶域的特殊性质来求解<i>α</i>:</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">α</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>=</mo><mfrac><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">k</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msup><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msup><mo>+</mo><mi>λ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">其中, <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">k</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msup><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msup></mrow></math></mathml>为核矩阵<b><i>K</i></b>的首行元素。最后, 对于任意测试样本<b><i>Z</i></b>的滤波器响应值可以表示为:</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mrow><mo> (</mo><mi mathvariant="bold-italic">Ζ</mi><mo>) </mo></mrow><mo>=</mo><mi mathvariant="bold-italic">w</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>z</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>i</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>k</mi><mo stretchy="false"> (</mo><mi>z</mi><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="87" name="87" class="anchor-tag">2 自适应多特征联合模型的目标跟踪算法</h3>
                <div class="p1">
                    <p id="88">基于颜色直方图的算法模型利用目标与背景的颜色统计信息, 可以很好地应对目标遮挡与形变等情况, 但无法在光照变化和运动模糊等条件下取得较好成绩。基于核相关滤波器的跟踪模型由于刚性模板的固有特性, 其对目标形变非常敏感, 为弥补这一问题, 本文通过自适应权重联合2个模型, 提高算法在复杂情况下的鲁棒性。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89">2.1 基于<i>L</i>1范数的核相关滤波器跟踪模型</h4>
                <div class="p1">
                    <p id="90">在跟踪目标的过程中, 由于目标外观受到遮挡、光照变化、物体形变等因素的影响, 在取样的过程中有较大误差, 产生离群值影响。简单的平方损失函数无法很好地拟合这种情形, 容易引起过拟合, 导致跟踪失败。为此, 本文在文献<citation id="246" type="reference">[<a class="sup">16</a>]</citation>的KCF损失函数的基础上, 参考稀疏表示, 引入<i>L</i>1范数以优化原始的目标函数。通过<i>L</i>1损失允许跟踪过程中出现稀疏离群值的特性, 使得训练得到的滤波器可以很好地拟合高斯型目标回归值, 可在很大程度上忽略跟踪过程中由目标外观变化带来的较大误差值, 从而缓解过拟合现象, 获得更加鲁棒的目标函数。具体形式如下:</p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi mathvariant="bold">m</mi><mi mathvariant="bold">i</mi><mi mathvariant="bold">n</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">w</mi><mo>, </mo><mi mathvariant="bold-italic">e</mi></mrow></munder><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">φ</mi><mrow><mo> (</mo><mi mathvariant="bold-italic">X</mi><mo>) </mo></mrow><mi mathvariant="bold-italic">w</mi><mo>-</mo><mi mathvariant="bold-italic">y</mi><mo>+</mo><mi mathvariant="bold-italic">e</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>β</mi><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">e</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92">其中, <b><i>X</i></b>为由循环采样构成的样本矩阵, <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>φ</mi><mrow><mo> (</mo><mo>⋅</mo><mo>) </mo></mrow></mrow></math></mathml>为映射函数, y是期望值, λ与β均为正则化参数。在式 (11) 中的<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">e</mi><mo>=</mo><mi mathvariant="bold-italic">y</mi><mo>-</mo><mi>φ</mi><mrow><mo> (</mo><mi mathvariant="bold-italic">X</mi><mo>) </mo></mrow><mi mathvariant="bold-italic">w</mi></mrow></math></mathml>为残差值, ‖<b><i>e</i></b>‖<sub>1</sub>项用来消除离群值的影响, 正则化项‖<b><i>w</i></b>‖<mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>用来保证回归的稳定性, 提高模型的可靠性。</p>
                </div>
                <div class="p1">
                    <p id="96">上述的目标函数无法直接求解, 但可将其划分成2个子问题, 通过迭代计算获得式 (11) 的近似解:</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>w</mi></munder><mo stretchy="false">∥</mo><mi>φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">w</mi><mo>-</mo><mi mathvariant="bold-italic">y</mi><mo>+</mo><mi mathvariant="bold-italic">e</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>e</mi></munder><mrow><mo stretchy="false">∥</mo><mi>φ</mi><mrow><mo> (</mo><mi mathvariant="bold-italic">X</mi><mo>) </mo></mrow><mi mathvariant="bold-italic">w</mi><mo>-</mo><mi mathvariant="bold-italic">y</mi><mo>+</mo><mi mathvariant="bold-italic">e</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>β</mi><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">e</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">在求解式 (12) 时, <b><i>e</i></b>取某个固定值<b><i>e</i></b>′, 得到:</p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>w</mi></munder><mrow><mo stretchy="false">∥</mo><mi>φ</mi><mrow><mo> (</mo><mi mathvariant="bold-italic">X</mi><mo>) </mo></mrow><mi mathvariant="bold-italic">w</mi><mo>-</mo><mi mathvariant="bold-italic">y</mi><mo>+</mo><msup><mi mathvariant="bold-italic">e</mi><mo>′</mo></msup><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">w</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100">式 (14) 与KCF算法中的原始损失函数类似, 可根据KCF算法的求解方法获得其在对偶空间的解, 如下:</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">α</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>=</mo><mfrac><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">e</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">k</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msup><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msup><mo>+</mo><mi>λ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">最后通过逆傅里叶变换得到当前最优解<i>α</i>′。</p>
                </div>
                <div class="p1">
                    <p id="103">类似地, 在求解式 (13) 时, 将当前的最优解<i>α</i>′固定, 然后求解<b><i>e</i></b>的最优值, 优化问题可以改写为:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>e</mi></munder><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Κ</mi><msup><mi mathvariant="bold-italic">α</mi><mo>′</mo></msup><mo>-</mo><mi mathvariant="bold-italic">y</mi><mo>+</mo><mi mathvariant="bold-italic">e</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>β</mi><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">e</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">式 (16) 的求解作为一个凸优化问题, 可以通过收缩阈值算子<citation id="247" type="reference"><link href="222" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>进行求解:</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi mathvariant="bold-italic">e</mi><mo>=</mo><mi>S</mi></mrow><msub><mrow></mrow><mi>β</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">F</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo> (</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">α</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mi mathvariant="bold-italic">e</mi><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">k</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msup><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msup></mrow><mo>) </mo></mrow><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">其中, <i>S</i>为收缩阈值算子, 计算如下:</p>
                </div>
                <div class="p1">
                    <p id="108"><i>S</i><sub>ϑ</sub> (<i>x</i>) =sign<mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mrow><mi>max</mi></mrow><mrow><mo> (</mo><mrow><mrow><mo>|</mo><mi>x</mi><mo>|</mo></mrow><mo>-</mo><mtext>ϑ</mtext><mo>, </mo><mn>0</mn></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="110">在此帧的候选区域内, 即以上一帧的目标位置为中心的采样框内, 通过循环采样获取样本<i>z</i>, 对其检测获取响应值, 如下:</p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>z</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi mathvariant="bold-italic">F</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false"> (</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">k</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msup><mrow></mrow><mrow><mi>x</mi><mi>z</mi></mrow></msup><mi mathvariant="bold-italic">e</mi><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">α</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="112" name="112">2.2 基于颜色直方图的跟踪模型</h4>
                <div class="p1">
                    <p id="113">为缓解形变等干扰的负面效应, 本文在候选区域<i>Ω</i>上引入基于贝叶斯分类器<i>h</i>的颜色直方图模型, 其响应值可以表示为积分图像的平均值, 如下:</p>
                </div>
                <div class="p1">
                    <p id="114" class="code-formula">
                        <mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">S</mi><msub><mrow></mrow><mi mathvariant="bold-italic">h</mi></msub><mo>=</mo><mi mathvariant="bold-italic">ω</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mrow><mo> (</mo><mrow><mfrac><mn>1</mn><mrow><mrow><mo>|</mo><mi>Ω</mi><mo>|</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>γ</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mi>Ι</mi></mstyle><mo stretchy="false">[</mo><mi>γ</mi><mo stretchy="false">]</mo></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="115">其中, <i>ω</i>表示该模型的权重矩阵, <i>I</i>表示区域<i>Ω</i>内颜色直方图特征。对于一个区域<i>Ω</i>′, 该模型的损失函数表示为:</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>ω</mi></munder><mfrac><mn>1</mn><mrow><mrow><mo>|</mo><msup><mi>Ω</mi><mo>′</mo></msup><mo>|</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>γ</mi><mo>∈</mo><msup><mi>Ω</mi><mo>′</mo></msup></mrow></munder><mrow><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">ω</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">[</mo><mi>γ</mi><mo stretchy="false">]</mo><mo>-</mo><mi>y</mi></mrow><mo>) </mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">其中, <i>y</i>为回归目标值。式 (21) 可以化简为在目标区域<i>O</i>和目标以外区域<i>B</i>分别提取样本 (<i>v</i>, 1) 和<mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><msup><mi>υ</mi><mo>′</mo></msup><mo>, </mo><mn>0</mn></mrow><mo>) </mo></mrow></mrow></math></mathml>, 得到如下形式:</p>
                </div>
                <div class="p1">
                    <p id="119" class="code-formula">
                        <mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>ω</mi></munder><mfrac><mn>1</mn><mrow><mrow><mo>|</mo><mi>Ο</mi><mo>|</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>γ</mi><mo>∈</mo><mi>Ο</mi></mrow></munder><mrow><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">ω</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">[</mo><mi>γ</mi><mo stretchy="false">]</mo><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mfrac><mn>1</mn><mrow><mrow><mo>|</mo><mi>B</mi><mo>|</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>γ</mi><mo>∈</mo><mi>B</mi></mrow></munder><mrow><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">ω</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">[</mo><mi>γ</mi><mo stretchy="false">]</mo></mrow><mo>) </mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="120">上述线性回归方程的解为:</p>
                </div>
                <div class="p1">
                    <p id="121" class="code-formula">
                        <mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">ω</mi><mo>=</mo><mfrac><mrow><mi>ρ</mi><mo stretchy="false"> (</mo><mi>Ο</mi><mo stretchy="false">) </mo></mrow><mrow><mi>ρ</mi><mo stretchy="false"> (</mo><mi>Ο</mi><mo stretchy="false">) </mo><mo>+</mo><mi>ρ</mi><mo stretchy="false"> (</mo><mi>B</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="122">其中, <mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><mrow><mo> (</mo><mi>Η</mi><mo>) </mo></mrow><mo>=</mo><mi>Ν</mi><mrow><mo> (</mo><mi>Η</mi><mo>) </mo></mrow><mo>/</mo><mrow><mo> (</mo><mi>Η</mi><mo>) </mo></mrow><mo>, </mo><mi>Ν</mi><mrow><mo> (</mo><mi>Η</mi><mo>) </mo></mrow></mrow></math></mathml>是直方图特征总数, <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mrow><mo> (</mo><mi>Η</mi><mo>) </mo></mrow><mo>=</mo><mrow><mo>|</mo><mrow><mrow><mo>{</mo><mrow><mi>γ</mi><mo>∈</mo><mi>Η</mi><mo>:</mo><mi>Ι</mi><mo stretchy="false">[</mo><mi>γ</mi><mo stretchy="false">]</mo><mo>≠</mo><mn>0</mn></mrow><mo>}</mo></mrow></mrow><mo>|</mo></mrow></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="125" name="125">2.3 模型联合位置估计</h4>
                <div class="p1">
                    <p id="126">基于颜色直方图的算法模型不依赖于图像特征的空间排列, 虽能提高在目标形变和遮挡情况下的算法鲁棒性, 但当目标与背景颜色相近时, 该算法不具备较强的判别能力, 难以将目标从周围环境中区分出来。基于核相关滤波器的跟踪算法可较好地将目标从复杂背景中分离出来, 但该算法对图像特征的空间分布很敏感, 当目标外观发生较大变化时, 其性能急剧降低。针对2种模型各自的特点, 本文采用自适应联合权重的方法联合这2个模型, 提高算法在复杂情况下的鲁棒性。最后的目标位置可以由联合响应图得到:</p>
                </div>
                <div class="p1">
                    <p id="127"><i>S</i>=<i>ψ</i><sub><i>h</i></sub><i>S</i><sub><i>h</i></sub>+<i>ψ</i><sub><i>w</i></sub><i>S</i><sub><i>w</i></sub>      (24) </p>
                </div>
                <div class="p1">
                    <p id="128">其中, <i>ψ</i><sub><i>h</i></sub>和<i>ψ</i><sub><i>w</i></sub>分别是核模型与颜色模型的权重, 且<i>ψ</i><sub><i>w</i></sub>=1-<i>ψ</i><sub><i>h</i></sub>。固定比例的方法虽然可以省去一些不必要的运算, 但在不同环境下的普适性有所欠缺。</p>
                </div>
                <div class="p1">
                    <p id="129">根据KCF算法的实现原理以及在实验过程中每帧的最大响应值变化可知, 当目标外观受到剧烈变化时, 该帧的响应值会急剧变小。如图1所示, 在Bolt视频序列的第254帧目标开始受到遮挡物影响, 此时, 该帧由KCF算法得到的最大响应值为0.269, 到下一帧时, 目标已经被完全遮挡, 得到的最大响应值下降为0.194。</p>
                </div>
                <div class="area_img" id="130">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908044_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 KCF算法的响应情况" src="Detail/GetImg?filename=images/JSJC201908044_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 KCF算法的响应情况</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908044_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="131">基于对上述实验规律的总结与分析, 为保证联合模型的有效性, 本文提出自适应权重的联合标准, 根据2个模型各自的响应值来确定响应的比例, 如下:</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ψ</mi><msub><mrow></mrow><mi>h</mi></msub><mo>=</mo><mfrac><mrow><mi>max</mi><mo stretchy="false"> (</mo><mi>S</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>max</mi><mo stretchy="false"> (</mo><mi>S</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi>max</mi><mo stretchy="false"> (</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">其中, max (<i>S</i><sub><i>h</i></sub>) 、max (<i>S</i><sub><i>w</i></sub>) 分别表示模型在当前帧得到的响应图的最大值。由前文可知, 当目标受遮挡、形变等因素影响时, max (<i>S</i><sub><i>w</i></sub>) 会突然变小, 但颜色模型由于对形变不敏感, 其响应图的max (<i>S</i><sub><i>h</i></sub>) 基本维持稳定状态。若当前帧出现遮挡情况, 改进KCF模型的响应图的可信度下降, max (<i>S</i><sub><i>w</i></sub>) 减小, 模型最终的响应值更依赖于颜色模型, 因此, 通过式 (25) 可以得到较大的<i>ψ</i><sub><i>h</i></sub>, 而<i>ψ</i><sub><i>w</i></sub>的值较小。最终, 通过式 (24) 可以得到联合响应图, 其最大值位置即为预测的当前帧目标位置。</p>
                </div>
                <h4 class="anchor-tag" id="134" name="134">2.4 尺度估计</h4>
                <div class="p1">
                    <p id="135">为了适应跟踪过程中目标尺度的变化, 本文基于文献<citation id="248" type="reference">[<a class="sup">18</a>]</citation>的思想, 在跟踪算法的框架中使用独立的核相关滤波器作为尺度滤波器, 对目标尺度的变化进行处理。当由联合响应图得到此帧的目标位置后, 以该位置为中心, 围绕中心取不同尺度大小的图像块提取特征, 分别与尺度滤波器进行相关操作以获得响应图, 响应值最大的响应图所对应的样本尺度即为当前帧的目标尺度。</p>
                </div>
                <div class="p1">
                    <p id="136">设<i>A</i>×<i>B</i>表示前一帧的目标尺度, 首先围绕当前帧的目标位置提取大小为<i>a</i><sup><i>n</i></sup><i>A</i>×<i>a</i><sup><i>n</i></sup><i>B</i>的尺度样本<i>j</i><sup><i>n</i></sup>, 其中, <mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>n</mi><mo>∈</mo><mrow><mo>{</mo><mrow><mrow><mo>|</mo><mrow><mo>-</mo><mfrac><mrow><mi>S</mi><mo>-</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>|</mo></mrow><mo>, </mo><mrow><mo>|</mo><mrow><mo>-</mo><mfrac><mrow><mi>S</mi><mo>-</mo><mn>2</mn></mrow><mn>2</mn></mfrac></mrow><mo>|</mo></mrow><mo>, </mo><mo>⋯</mo><mo>, </mo><mrow><mo>|</mo><mrow><mfrac><mrow><mi>S</mi><mo>-</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>|</mo></mrow></mrow><mo>}</mo></mrow><mo>, </mo><mi>S</mi></mrow></math></mathml>表示尺度等级, a为尺度因子。通过式 (26) 计算每个尺度样本的响应值, 具体计算过程如下:</p>
                </div>
                <div class="p1">
                    <p id="138" class="code-formula">
                        <mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mi>F</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo>{</mo><mrow><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><mrow><mi>j</mi><msubsup><mrow></mrow><mi>n</mi><mi>k</mi></msubsup></mrow></mstyle><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>Μ</mi><msup><mrow></mrow><mi>k</mi></msup></mrow></mstyle><mrow><mspace width="0.25em" /><mo>—</mo></mrow></mover></mrow><mrow><mi>Ν</mi><mo>+</mo><mi>γ</mi></mrow></mfrac></mrow><mo>}</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="139">其中, d是特征维度, δ为惩罚项。由此得到的最大响应值所对应的目标尺寸即为当前帧的目标尺度。式 (26) 中的M和N可通过式 (27) 和式 (28) 得到:</p>
                </div>
                <div class="p1">
                    <p id="140" class="code-formula">
                        <mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Μ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>θ</mi><mo stretchy="false">) </mo><mi>Μ</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>θ</mi><mover accent="true"><mrow><mi>G</mi><msub><mrow></mrow><mi>t</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mi>F</mi><msub><mrow></mrow><mi>t</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ν</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>θ</mi><mo stretchy="false">) </mo><mi>Ν</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>θ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><mrow><mover accent="true"><mrow><mi>F</mi><msup><mrow></mrow><mi>k</mi></msup></mrow><mo stretchy="true">¯</mo></mover></mrow></mstyle><mi>F</mi><msup><mrow></mrow><mi>k</mi></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="141">其中, t表示帧, θ表示学习率。</p>
                </div>
                <h4 class="anchor-tag" id="142" name="142">2.5 算法框架</h4>
                <div class="p1">
                    <p id="143">本文跟踪算法的框架如图2所示。当跟踪第<i>t</i>帧的目标时, 首先在候选窗内循环移位得到训练样本, 提取HOG特征, 并通过Cosine窗平滑边缘噪声。然后, 与优化后的基于<i>L</i>1范数正则化的核相关滤波器进行相关操作得到响应图, 同时, 由颜色直方图模型得到同一候选窗内的直方图响应。通过自适应权重对2个模型进行有效融合, 将融合后的响应图最大值的位置作为当前帧的目标位置, 并提取HOG特征。与独立的尺度滤波器进行相关操作后, 得到该帧的目标尺度信息, 从而确定第<i>t</i>帧的目标状态。最后, 对整个算法模型的滤波器进行更新。</p>
                </div>
                <div class="area_img" id="144">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908044_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文跟踪算法框架" src="Detail/GetImg?filename=images/JSJC201908044_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 本文跟踪算法框架</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908044_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="145" name="145" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="146">本文的实验环境为Intel Core i5 CPU@3.20 GHz, Window7系统, 内存8 GB, 所用的软件平台为Matlab R2014a。</p>
                </div>
                <h4 class="anchor-tag" id="147" name="147">3.1 实验参数</h4>
                <div class="p1">
                    <p id="148">与其他核相关滤波跟踪模型类似, 本文使用HOG特征进行实验。在位置估计时, 式 (11) 中的<i>λ</i>与<i>β</i>的取值均为1×10<sup>4</sup>, 求解式 (11) 的迭代次数设置为15次。此外, 联合权重的初始值采用<i>ψ</i><sub><i>h</i></sub>和<i>ψ</i><sub><i>w</i></sub>分别取0.3和0.7。在尺度估计时, 式 (26) 中的<i>δ</i>取值为1×10<sup>4</sup>, 等级<i>S</i>取33, 尺度因子<i>a</i>为1.02, <i>θ</i>设置为0.025。</p>
                </div>
                <h4 class="anchor-tag" id="149" name="149">3.2 评估方法</h4>
                <div class="p1">
                    <p id="150">本文实验采用文献<citation id="249" type="reference">[<a class="sup">19</a>]</citation>提出的OTB视频数据集, 并延用该视频数据集的评估指标:准确率和成功率。其中, 准确率由预测的目标中心位置与手工标定的准确位置之间的平均欧氏距离, 即中心像素误差 (Center Location Error, CLE) 来确定。当某一帧中心位置误差小于给定阈值时, 认为该算法在这一帧成功, 并以成功跟踪的帧数占总帧数的百分比与阈值的关系绘制精确度图。成功率以重叠率<i>S</i>为评价指标, 其具体计算过程如下:<mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mrow><mo>|</mo><mrow><mfrac><mrow><mi>r</mi><msub><mrow></mrow><mi>t</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>r</mi></mstyle><msub><mrow></mrow><mi>a</mi></msub></mrow><mrow><mi>r</mi><msub><mrow></mrow><mi>t</mi></msub><mstyle displaystyle="true"><mo>∪</mo><mi>r</mi></mstyle><msub><mrow></mrow><mi>a</mi></msub></mrow></mfrac></mrow><mo>|</mo></mrow></mrow></math></mathml>, 其中, <i>r</i><sub><i>a</i></sub>和<i>r</i><sub><i>t</i></sub>分别表示得到的目标跟踪框和手工标定的准确跟踪框。若<i>S</i>大于给定阈值, 则认为跟踪成功。以重叠率<i>S</i>与阈值的关系绘制覆盖成功率图。</p>
                </div>
                <div class="p1">
                    <p id="152">将本文算法与OTB数据集上的25个经典算法<citation id="250" type="reference"><link href="226" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>, 即IVT、L1APG、SemiT、CT、CPF、Frag、VTS、DFT、VR-V、BSBT、TLD、ORIA、ASLA、MTT、LSK、CXT、LOT、SMS、OAB、MIL、SCM、VTD、KMS、Struck、CSK, 以及KCF<citation id="251" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、DSST<citation id="252" type="reference"><link href="224" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、MTSA<citation id="253" type="reference"><link href="228" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、Staple<citation id="254" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>算法进行对比实验。其中包括生成式跟踪算法和判别式跟踪算法, 同时将拥有类似思想的KCF算法和Staple算法列入对比实验组。上述所有算法的代码从OTB数据库和相应作者的主页上获得, 并选取最佳参数进行实验, 且所有结果均在同一实验平台下完成。实验使用的视频序列涵盖了数据库标定的11种干扰因素, 分别为形变、遮挡、光照变化、运动模糊、尺度变化、平面内旋转、平面外旋转、快速移动、背景杂乱、超出视野范围和低分辨率。</p>
                </div>
                <h4 class="anchor-tag" id="153" name="153">3.3 结果分析</h4>
                <div class="p1">
                    <p id="154">考虑到视频初始化位置对跟踪算法的影响, 本文采用OTB数据集中的时间鲁棒性评价 (Temporal Robustness Evaluation, TRE) 指标进行评估, 即利用视频序列中的任意帧作为实验的第1帧进行跟踪, 实验的准确率和成功率对比结果分别如图3、图4所示, 图例中方括号内的值为AUC (Area Under Curve) 值。为便于观察, 图中仅显示排名前10的算法结果。从图3、图4可以看出, 除了在快速移动这一干扰因素下, 本文算法 (Ours_co算法) 效果略逊于Staple外, 在其余干扰因素下本文算法都表现出良好的鲁棒性, 在所有对比算法中位列第一。尤其是在应对形变和光照干扰方面, 本文算法与排名第2的Staple算法相比, 准确率和成功率都提高了5%左右。在遮挡干扰的处理上, 本文算法也表现出较好的鲁棒性。同时, 本文跟踪算法在OTB数据库上的平均速度为58.3 frame/s, 完全可以满足实际应用环境下的实时性要求。为进一步体现本文算法的应用价值, 选取精度前10名的算法做实时性分析, 结果如表1所示。从表1可以看出, 本文算法的平均速度为58.3 frame/s, 可以满足实际应用环境下的实时性要求。</p>
                </div>
                <div class="area_img" id="156">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908044_156.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 主流跟踪算法在不同干扰下的准确率对比" src="Detail/GetImg?filename=images/JSJC201908044_156.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 主流跟踪算法在不同干扰下的准确率对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908044_156.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="157">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908044_157.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 主流跟踪算法在不同干扰下的成功率对比" src="Detail/GetImg?filename=images/JSJC201908044_157.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 主流跟踪算法在不同干扰下的成功率对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908044_157.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="158">
                    <p class="img_tit"><b>表1 精度前10名算法的速度对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"> (frame·s<sup>-1</sup>) </p>
                    <table id="158" border="1"><tr><td>算法</td><td>速度</td><td>算法</td><td>速度</td></tr><tr><td colspan="2"><br /></td><td colspan="2"></td></tr><tr><td rowspan="2">Ours_co</td><td rowspan="2">58.3</td><td rowspan="2">Staple</td><td rowspan="2">44.9</td></tr><tr></tr><tr><td><br />KCF</td><td>189.1</td><td>DSST</td><td>25.9</td></tr><tr><td><br />MTSA</td><td>20.5</td><td>Struck</td><td>10.1</td></tr><tr><td><br />VTS</td><td>2.3</td><td>VTD</td><td>2.3</td></tr><tr><td><br />ASLA</td><td>4.2</td><td>SCM</td><td>0.2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="159">为更直观地展现算法在不同视频序列上、不同干扰因素下的跟踪效果, 本文从OTB数据库中选取6个具有代表性的视频序列, 其包含的干扰因素如表2所示。图5给出本文算法与KCF算法、Staple算法在这6个视频序列上的对比跟踪效果。其中, 实线、虚线和点划线框出的部分分别对应本文算法、KCF算法和Staple算法的结果。</p>
                </div>
                <div class="area_img" id="160">
                    <p class="img_tit"><b>表2 6个视频序列的干扰因素</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="160" border="1"><tr><td><br />视频序列</td><td>干扰因素</td></tr><tr><td><br />Basketball</td><td>光照变化、遮挡、形变、旋转、背景杂乱</td></tr><tr><td><br />CarScale</td><td>尺度变化、遮挡、快速运动、旋转</td></tr><tr><td><br />FaceOcc2</td><td>光照变化、遮挡、旋转</td></tr><tr><td><br />Couple</td><td>尺度变化、遮挡、形变、快速运动、旋转、背景杂乱</td></tr><tr><td><br />Trellis</td><td>光照变换、尺度变化、背景杂乱、旋转</td></tr><tr><td><br />Skating1</td><td>光照变化、尺度变化、遮挡、形变、旋转、背景杂乱</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="161">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908044_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 3种算法在6个视频序列上的跟踪结果对比" src="Detail/GetImg?filename=images/JSJC201908044_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 3种算法在6个视频序列上的跟踪结果对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908044_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="162">从图5可以看出, 在Basketball序列中, 第10帧时3种算法都能实现较准确的跟踪, 随着遮挡逐渐严重, KCF算法和Staple算法开始出现目标漂移。当发生形变、光照变化时, Staple算法定位的目标位置完全偏离真实目标位置, 这是因为Staple算法在实现模型联合时, 只是简单地分配固定比例的模型权重, 当相关滤波模型在产生较大偏差却又被分配较高权重时, 跟踪失败。本文算法根据每一帧的响应值适时地调整权重比例, 当2个模型中任何一个出现较大偏差时, 通过式 (25) 可自适应地分配权重, 缓解干扰因素对最终跟踪结果的影响。在CarScale序列中, 本文算法对尺度变化展现出良好的应对能力。在FaceOcc2序列中, 当目标发生旋转和遮挡时, KCF算法和Staple算法都发生不同程度的中心位置偏移。相比较而言, 本文算法表现出较好的准确性。在Couple序列中, 背景杂乱、遮挡、形变、快速运动等多种干扰因素的影响较严重。在第44帧, 受到背景杂乱的干扰, KCF算法在训练过程中引入过多的错误训练样本, 滤波器区分背景和目标的能力下降, 最终跟踪失败。随着跟踪的推进, 错误像素慢慢累积, 产生较大误差, 而Staple算法无法有效利用互补模型对其进行矫正, 最终跟踪失败, 而本文算法实现较为稳定、准确的跟踪。在Trellis序列中, Staple算法逐渐发生较大的中心偏差, KCF算法未对目标尺度进行处理, 而本文算法始终能够成功定位到目标 (脸部) 。在Skating1序列中, 第177帧的目标受到相似颜色的物体遮挡, 颜色模型的响应图出现偏差, 但由于未能实时调整权重比例, Staple算法开始发生漂移, 最终跟踪失败。KCF算法虽然能大致定位到目标, 但无法应对目标的尺度变化, 也出现了目标中心偏移的现象。</p>
                </div>
                <h3 id="163" name="163" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="164">本文提出一种自适应的多模型联合算法。将基于<i>L</i>1范数的核相关滤波器跟踪模型与颜色直方图模型相结合, 利用2个模型各自的良好特性, 以解决形变等干扰因素导致的跟踪失败问题, 优化其在复杂环境下的鲁棒性。通过自适应联合权重来调整2个模型的权重比例, 最终确定目标位置。实验结果表明, 相较于其他生成式跟踪算法和判别式跟踪算法, 该算法在复杂环境下具有更好的鲁棒性。下一步将简化跟踪算法的目标函数, 并尝试寻找更加高效的模型融合策略, 以提高跟踪结果的精度, 减少算法的运行时间。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="190">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201806050&amp;v=MDg3MjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZDamxXcnZMTHo3QmJiRzRIOW5NcVk5QVpJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 张晶, 王旭, 范洪博.自适应学习的时空上下文目标跟踪算法[J].计算机工程, 2018, 44 (6) :294-299.
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Understanding and diagnosing visual tracking systems">

                                <b>[2]</b> WANG Naiyan, SHI Jianping, YEUNG D Y, et al.Understanding and diagnosing visual tracking systems[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2015:3101-3109.
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201804011&amp;v=MDk3NDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRkNqbFdydkxMejdCYUxHNEg5bk1xNDlFWllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 孔军, 成静, 蒋敏, 等.组合范数正则化稀疏编码和自适应加权残差的鲁棒跟踪[J].计算机辅助设计与图形学学报, 2018, 30 (4) :634-641.
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201611002&amp;v=Mjc1MjllUnFGQ2psV3J2TEx6N0JiN0c0SDlmTnJvOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 魏全禄, 老松杨, 白亮.基于相关滤波器的视觉目标跟踪综述[J].计算机科学, 2016, 43 (11) :1-5.
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual object tracking using adaptive correlation filters">

                                <b>[5]</b> BOLME D S, BEVERIDGE J R, DRAPER B A, et al.Visual object tracking using adaptive correlation filters[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2010:2544-2550.
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of tracking-by-detection with kernels">

                                <b>[6]</b> HENRIQUES J F, CASEIRO R, MARTINS P, et al.Exploiting the circulant structure of tracking-by-detection with kernels[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2012:702-715.
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Highspeed tracking with kernelized correlation filters">

                                <b>[7]</b> HENRIQUES J F, RUI C, MARTINS P, et al.High-speed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2014, 37 (3) :583-596.
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Histograms of oriented gradients for human detection">

                                <b>[8]</b> DALAL N, TRIGGS B.Histograms of oriented gradients for human detection[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2005:886-893.
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time correlation filter tracking by efficient dense belief propagation with structure preserving">

                                <b>[9]</b> YAO Rui, XIA Shixiong, ZHANG Zhen, et al.Real-time correlation filter tracking by efficient dense belief propagation with structure preserving[J].IEEE Transactions on Multimedia, 2017, 19 (4) :772-784.
                            </a>
                        </p>
                        <p id="208">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201112017&amp;v=MDA3Nzh2TEx6N0JhTEc0SDlETnJZOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2psV3I=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 李冠彬, 吴贺丰.基于颜色纹理直方图的带权分块均值漂移目标跟踪算法[J].计算机辅助设计与图形学学报, 2011, 23 (12) :2059-2066.
                            </a>
                        </p>
                        <p id="210">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=In defense of color-based model-free tracking">

                                <b>[11]</b> POSSEGGER H, MAUTHNER T, BISCHOF H.In defense of color-based model-free tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:2113-2120.
                            </a>
                        </p>
                        <p id="212">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Staple:Complementary learners for realtime tracking">

                                <b>[12]</b> BERTINETTO L, VALMADRE J, GOLODETZ S, et al.Staple:complementary learners for real-time tracking[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2016:1401-1409.
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real time robust l1 tracker using accelerated proximal gradient approach">

                                <b>[13]</b> BAO Chenglong, WU Yi, LING Haibin, et al.Real time robust L1 tracker using accelerated proximal gradient approach[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:1830-1837.
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800007020&amp;v=MTIzMTZIdGZPcDQ5RlpPc0lESDQ1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHZMSUY0ZGJoRT1Oam5CYXJLNw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> WILLIAMS C K I.Learning with kernels:support vector machines, regularization, optimization, and beyond[J].Publications of the American Statistical Association, 2003, 98 (462) :489-489.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Regularized least-squares classification">

                                <b>[15]</b> RIFKIN R, YEO G, POGGIO T.Regularized least-squares classification[EB/OL].[2018-08-25].http://cbcl.mit.edu/publications/ps/rlsc.pdf.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust visual tracking based on kernelized correlation filters">

                                <b>[16]</b> JIANG Min, SHEN Jianyu, KONG Jun, et al.Robust visual tracking based on kernelized correlation filters[C]//Proceedings of IEEE International Conference on Information and Automation.Washington D.C., USA:IEEE Press, 2017:110-115.
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 BECK A, TEBOULLE M.A fast iterative shrinkage-thresholding algorithm for linear inverse problems[J].SIAM Journal on Imaging Sciences, 2009, 2 (1) :183-202.
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accurate scale estimation for robust visual tracking">

                                <b>[18]</b> DANELLJAN M, H GER G, KHAN F S, et al.Accurate scale estimation for robust visual tracking[C]//Proceedings of British Machine Vision Conference.[S.l.]:BMVA Press, 2014:1-11.
                            </a>
                        </p>
                        <p id="226">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Online object tracking:A benchmark">

                                <b>[19]</b> WU Yi, LIM J, YANG Minghuan.Online object tracking:a benchmark[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2013:2411-2418.
                            </a>
                        </p>
                        <p id="228">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-template Scale-Adaptive Kernelized Correlation Filters">

                                <b>[20]</b> BIBI A, GHANEM B.Multi-template scale-adaptive kernelized correlation filters[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2015:613-620.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201908044" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201908044&amp;v=MjU1NDdlWmVScUZDamxXcnZMTHo3QmJiRzRIOWpNcDQ5QllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
