<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131287514207500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201902039%26RESULT%3d1%26SIGN%3dcQCEeyaaVldxH2liOiovQPDwozE%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902039&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902039&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902039&amp;v=MTgyNTVHYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqbFc3L09MejdCYmJHNEg5ak1yWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#63" data-title="0概述 ">0概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#66" data-title="1 聚焦形貌恢复原理 ">1 聚焦形貌恢复原理</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#75" data-title="2 基于区域像素重构的聚焦形貌恢复方法 ">2 基于区域像素重构的聚焦形貌恢复方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#76" data-title="2.1 图像噪声检测与除噪">2.1 图像噪声检测与除噪</a></li>
                                                <li><a href="#88" data-title="2.2 图像区域像素重构">2.2 图像区域像素重构</a></li>
                                                <li><a href="#95" data-title="2.3 改进的聚焦评价函数">2.3 改进的聚焦评价函数</a></li>
                                                <li><a href="#102" data-title="2.4 聚焦形貌恢复算法描述">2.4 聚焦形貌恢复算法描述</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#135" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#80" data-title="图1 像素点的邻域示意图">图1 像素点的邻域示意图</a></li>
                                                <li><a href="#90" data-title="图2 当评价窗口为3&#215;3时参与计算的邻域窗口">图2 当评价窗口为3×3时参与计算的邻域窗口</a></li>
                                                <li><a href="#94" data-title="图3 图像重构示意图">图3 图像重构示意图</a></li>
                                                <li><a href="#98" data-title="图4 3&#215;3邻域窗口示意图">图4 3×3邻域窗口示意图</a></li>
                                                <li><a href="#118" data-title="图5 不同方法形貌恢复结果">图5 不同方法形貌恢复结果</a></li>
                                                <li><a href="#120" data-title="表1 不同实验对象的形貌恢复评价结果">表1 不同实验对象的形貌恢复评价结果</a></li>
                                                <li><a href="#121" data-title="图6 不同实验对象的形貌恢复评价结果统计柱状图">图6 不同实验对象的形貌恢复评价结果统计柱状图</a></li>
                                                <li><a href="#124" data-title="图7 3种实验对象的形貌恢复效果">图7 3种实验对象的形貌恢复效果</a></li>
                                                <li><a href="#126" data-title="表2 不同滤波方法形貌恢复评价结果的RMSE值">表2 不同滤波方法形貌恢复评价结果的RMSE值</a></li>
                                                <li><a href="#127" data-title="表3 不同滤波方法形貌恢复评价结果的Correlation值">表3 不同滤波方法形貌恢复评价结果的Correlation值</a></li>
                                                <li><a href="#128" data-title="图8 不同滤波方法形貌恢复评价结果的RMSE值统计柱状图">图8 不同滤波方法形貌恢复评价结果的RMSE值统计柱状图</a></li>
                                                <li><a href="#129" data-title="图9 不同滤波方法形貌恢复评价结果的Correlation值统计柱状图">图9 不同滤波方法形貌恢复评价结果的Correlation值统计柱状图</a></li>
                                                <li><a href="#131" data-title="图1 0 实验装置及实验对象">图1 0 实验装置及实验对象</a></li>
                                                <li><a href="#133" data-title="图1 1 4种方法形貌恢复结果">图1 1 4种方法形貌恢复结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="33">


                                    <a id="bibliography_1" title="NAYAR S K, NAKAGAWA Y.Shape from focus[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1994, 16 (8) :824-831." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Shape from focus">
                                        <b>[1]</b>
                                        NAYAR S K, NAKAGAWA Y.Shape from focus[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1994, 16 (8) :824-831.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_2" title="SUBBARAO M, CHOI T S.Accurate recovery of three dimensional shape from image focus[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1995, 17 (3) :266-274." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accurate recovery of three-dimensional shape from image focus">
                                        <b>[2]</b>
                                        SUBBARAO M, CHOI T S.Accurate recovery of three dimensional shape from image focus[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1995, 17 (3) :266-274.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                    SHIM S O, MALIK A S, CHOI T S.Noise reduction using mean shift algorithm for estimating 3D shape[J].Imaging Science, 2011, 59 (4) :267-273.</a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_4" title="LEE I H, MAHMOOD M T, SHIM S O, et al.Optimizing image focus for 3D shape recovery through genetic algorithm[J].Multimedia Tools and Applications, 2014, 71 (1) :247-262." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14062400005926&amp;v=MTg4NTJaT3NLQlg0L29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGNGNhaFE9Tmo3QmFySzhIdGZPcTQ5Rg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        LEE I H, MAHMOOD M T, SHIM S O, et al.Optimizing image focus for 3D shape recovery through genetic algorithm[J].Multimedia Tools and Applications, 2014, 71 (1) :247-262.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_5" title="KALEEM M, MAHMOOD M T.Combining focus measures through genetic algorithm for shape from focus[C]//Proceedings of IEEE International Conference on Information Science and Applications.Washington D.C., USA:IEEE Press, 2014:4441-4446." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Combining focus measures through genetic algorithm for shape from focus">
                                        <b>[5]</b>
                                        KALEEM M, MAHMOOD M T.Combining focus measures through genetic algorithm for shape from focus[C]//Proceedings of IEEE International Conference on Information Science and Applications.Washington D.C., USA:IEEE Press, 2014:4441-4446.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_6" title="XIA Xiaohua, YIN Lijuan, YAO Yunshi, et al.Combining two focus measures to improve performance[J].Measurement Science and Technology, 2017, 28 (10) ." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Combining two focus measures to improve performance">
                                        <b>[6]</b>
                                        XIA Xiaohua, YIN Lijuan, YAO Yunshi, et al.Combining two focus measures to improve performance[J].Measurement Science and Technology, 2017, 28 (10) .
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_7" title="JIANG Bo, GUO Liqiang, CHEN Fubing.Shape from focus using statistics methods[C]//Proceedings of 2017International Smart Cities Conference.Washington D.C., USA:IEEE Press, 2017:1-7." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Shape from focus using statistics methods">
                                        <b>[7]</b>
                                        JIANG Bo, GUO Liqiang, CHEN Fubing.Shape from focus using statistics methods[C]//Proceedings of 2017International Smart Cities Conference.Washington D.C., USA:IEEE Press, 2017:1-7.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_8" title="TSENG C Y, WANG S J.Shape-from-focus depth reconstruction with a spatial consistency model[J].IEEE Transactions on Circuits and Systems for Video Technology, 2014, 24 (12) :2063-2076." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Shape-from-focus depth reconstruction with a spatial consistency model">
                                        <b>[8]</b>
                                        TSENG C Y, WANG S J.Shape-from-focus depth reconstruction with a spatial consistency model[J].IEEE Transactions on Circuits and Systems for Video Technology, 2014, 24 (12) :2063-2076.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_9" title="FAHAD M, JAWAD M, SHAHID Q W, et al.3-D shape recovery from image focus using rank transform[C]//Proceedings of the 12th International Symposium on Visual Computing.Berlin, Germany:Springer, 2016:514-523. (244) 239" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=3-D shape recovery from image focus using rank transform">
                                        <b>[9]</b>
                                        FAHAD M, JAWAD M, SHAHID Q W, et al.3-D shape recovery from image focus using rank transform[C]//Proceedings of the 12th International Symposium on Visual Computing.Berlin, Germany:Springer, 2016:514-523. (244) 239
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_10" title="KUMAR C H, VINOD H I, SAHAY R R.Shape-fromfocus using total variation prior and split Bregman algorithm[C]//Proceedings of 2014 Indian Conference on Computer Vision Graphics and Image Processing.New York, USA:ACM Press, 2014:80." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Shape-from-focus using total variation prior and split Bregman algorithm">
                                        <b>[10]</b>
                                        KUMAR C H, VINOD H I, SAHAY R R.Shape-fromfocus using total variation prior and split Bregman algorithm[C]//Proceedings of 2014 Indian Conference on Computer Vision Graphics and Image Processing.New York, USA:ACM Press, 2014:80.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_11" title="FAN Tiantian, YU Hongbin.A novel shape from focus method based on 3D steerable filters for improved performance on treating textureless region[J].Optics Communications, 2018, 410 (1) :254-261." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel shape from focus method based on 3Dsteerable filters for improved performance on treating textureless region">
                                        <b>[11]</b>
                                        FAN Tiantian, YU Hongbin.A novel shape from focus method based on 3D steerable filters for improved performance on treating textureless region[J].Optics Communications, 2018, 410 (1) :254-261.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_12" title="康宇, 陈念年, 范勇, 等.基于扩散的聚焦形貌恢复算法[J].计算机工程, 2016, 42 (3) :259-265." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201603047&amp;v=MjkwNjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeWpsVzcvT0x6N0JiYkc0SDlmTXJJOUJZNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        康宇, 陈念年, 范勇, 等.基于扩散的聚焦形貌恢复算法[J].计算机工程, 2016, 42 (3) :259-265.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_13" title="SHIM S O, MALIK A S, CHOI T S.Noise reduction using mean shift algorithm for estimating 3D shape[J].Imaging Science, 2011, 59 (5) :267-273." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Noise reduction using mean shift algorithm for estimating 3D shape">
                                        <b>[13]</b>
                                        SHIM S O, MALIK A S, CHOI T S.Noise reduction using mean shift algorithm for estimating 3D shape[J].Imaging Science, 2011, 59 (5) :267-273.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_14" title="SUBBARAO M, LU M C.Image sensing model and computer simulation for CCD camera systems[J].Machine Vision and Applications, 1994, 7 (4) :277-289." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002055991&amp;v=MDc5MTllYnVkdEZDSGxVNy9BSUZnPU5qN0Jhck80SHRIT3I0cEFiZUlPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3Ujdx&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        SUBBARAO M, LU M C.Image sensing model and computer simulation for CCD camera systems[J].Machine Vision and Applications, 1994, 7 (4) :277-289.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_15" title="AAMIR S M, TAE S C.A novel algorithm for estimation of depth map using image focus for 3D shape recovery in the presence of noise[J].Pattern Recognition, 2008, 41 (7) :2200-2225." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739194&amp;v=MjExMTNIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklJRjRjYWhRPU5pZk9mYks3SHRETnFZOUZZK2dHRFhVOW9CTVQ2VDRQUQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        AAMIR S M, TAE S C.A novel algorithm for estimation of depth map using image focus for 3D shape recovery in the presence of noise[J].Pattern Recognition, 2008, 41 (7) :2200-2225.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(02),233-239+244 DOI:10.19678/j.issn.1000-3428.0049958            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于图像区域像素重构的聚焦形貌恢复</span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E6%B4%AA%E7%9B%9B&amp;code=38707630&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵洪盛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%81%E5%8D%8E&amp;code=09922322&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">丁华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%BB%BA%E6%88%90&amp;code=31244151&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘建成</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%AA%E5%8E%9F%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E6%9C%BA%E6%A2%B0%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0077528&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">太原理工大学机械工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%AA%E5%B9%B3%E6%B4%8B%E5%A4%A7%E5%AD%A6%E5%B7%A5%E7%A8%8B%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0175936&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">太平洋大学工程与计算机科学学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为提高三维形貌图像的恢复精度, 提出一种基于最大最小算子与区域像素重构的聚焦形貌恢复方法。利用最大最小算子判定图像序列中的噪声像素点, 并采用中值滤波方法消除图像噪声。对图像序列进行区域像素重构, 根据重构图像相邻像素的灰度差值设计聚焦评价函数, 确定区域聚焦等级, 实现聚焦形貌恢复。实验结果表明, 该方法恢复的三维形貌图像精度优于传统形貌恢复方法, 并对含噪图像具有较好的鲁棒性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%9A%E7%84%A6%E5%BD%A2%E8%B2%8C%E6%81%A2%E5%A4%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聚焦形貌恢复;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%99%AA%E5%A3%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像噪声;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%80%E5%A4%A7%E6%9C%80%E5%B0%8F%E7%AE%97%E5%AD%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">最大最小算子;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8C%BA%E5%9F%9F%E5%83%8F%E7%B4%A0%E9%87%8D%E6%9E%84&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">区域像素重构;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%9A%E7%84%A6%E8%AF%84%E4%BB%B7%E5%87%BD%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聚焦评价函数;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    赵洪盛 (1991—) , 男, 硕士, 主研方向为图像处理;E-mail:hongsheng8759@163.com
;
                                </span>
                                <span>
                                    丁华, 副教授、博士;
;
                                </span>
                                <span>
                                    刘建成, 教授、博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>山西省自然科学基金 (201601D011050);</span>
                                <span>山西省煤机重点科技攻关项目 (MJ2014-05-02);</span>
                                <span>山西省研究生联合培养基地人才培养项目 (2016JD13);</span>
                    </p>
            </div>
                    <h1>Shape from Focus Based on Image Regional Pixel Reconstruction</h1>
                    <h2>
                    <span>ZHAO Hongsheng</span>
                    <span>DING Hua</span>
                    <span>LIU Jiancheng</span>
            </h2>
                    <h2>
                    <span>School of Mechanical Engineering, Taiyuan University of Technology</span>
                    <span>School of Engineering and Computer Science, University of the Pacific</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to improve the accuracy of 3 D morphology image recovery, a novel method for Shape from Focus ( SFF) based on max-min operator and regional pixel reconstruction is proposed. The max-min operator is used to determine the noise pixels in the image sequence, and the median filtering is used to the noise points, so as to eliminate the image noise. It performs the regional pixel reconstruction on the image sequence. According to the gray difference of the adjacent pixels in the reconstructed image, the focus measure is designed to determine the focus level of the region to realize SFF. Experimental results show that the accuracy of the three-dimensional topography restored by this method is superior than that of the traditional one, and it has better robustness to noisy images.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Shape%20from%20Focus%20(SFF)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Shape from Focus (SFF) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20noise&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image noise;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=max-min%20operator&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">max-min operator;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=regional%20pixel%20reconstruction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">regional pixel reconstruction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=focus%20evaluation%20function&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">focus evaluation function;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-03</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="63" name="63" class="anchor-tag">0概述</h3>
                <div class="p1">
                    <p id="64">聚焦形貌恢复 (Shape from Focus, SFF) 技术是以被测物图像各像素点的聚焦等级为线索搜索获得其对应表面的深度信息, 是实现复杂表面三维形貌恢复与测量的重要方法之一, 并且在显微图像处理、碰撞避免和工业产品检测等领域应用广泛。因其方法简单、成本低、实时性好, 且具有较高的精度, 自此项技术被提出以来, 一直是国内外学术界研究的热点。传统SFF技术的主要算法思路集中在Nayar法<citation id="139" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>和FIS法<citation id="141" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 但其恢复精度有限。近些年, 国内外研究主要从图像噪声处理方法和高性能聚焦评价函数设计两方面入手提升SFF精度。文献<citation id="142" type="reference">[<a class="sup">3</a>]</citation>在图像滤波中引入均值漂移算法, 可同时减少高斯噪声和脉冲噪声影响, 保留图像细节。文献<citation id="143" type="reference">[<a class="sup">4</a>]</citation>用维纳滤波器处理图像噪声。由于单一的聚焦评价函数无法得到精确的高度图, 因此文献<citation id="140" type="reference">[<a class="sup">5</a>,<a class="sup">6</a>]</citation>将遗传算法结合不同的聚焦评价算法, 从而得到精确的高度图。文献<citation id="144" type="reference">[<a class="sup">7</a>]</citation>对于含噪图像, 提出基于方向统计量的聚焦评价方法。文献<citation id="145" type="reference">[<a class="sup">8</a>]</citation>将最大后验分布引入空间一致性先验模型估算每个像素的深度值。文献<citation id="146" type="reference">[<a class="sup">9</a>]</citation>提出秩变换聚焦评价算法。文献<citation id="147" type="reference">[<a class="sup">10</a>]</citation>提出用全变分预处理和分裂算法再处理方法恢复高度图, 从而得到更精确的高度图。文献<citation id="148" type="reference">[<a class="sup">11</a>]</citation>结合图像聚焦程度与边缘响应, 设计三维方向可调滤波聚焦评价方法, 对低纹理区域深度恢复有较好效果。文献<citation id="149" type="reference">[<a class="sup">12</a>]</citation>针对聚焦形貌恢复技术在测量运行时对上位机内存需求量大的缺陷, 提出一种聚焦形貌恢复算法。然而, 上述图像噪声滤波方法在去除图像噪声的同时, 都会改变图像非噪声区域灰度信息。上述聚焦评价函数也都需要选择该像素点一定邻域范围的区域作为评价窗口, 然而评价窗口过小容易受图像噪声影响, 而过大的评价窗口又会引入一些非相关像素, 从而掩盖被测图像表面的细节部分并导致图像表面细节模糊。</p>
                </div>
                <div class="p1">
                    <p id="65">针对以上问题, 为滤除图像噪声同时保留图像细节, 本文提出最大最小算子图像噪声检测算法, 用于判定图像中的噪声像素点, 同时利用中值滤波的优势, 对噪声点采用中值滤波, 构建无噪声图像序列。为免去选择评价窗口, 本文提出图像区域像素重构方法, 完成图像序列重构, 并且根据图像邻域像素灰度差异性, 改进现有聚焦评价函数。</p>
                </div>
                <h3 id="66" name="66" class="anchor-tag">1 聚焦形貌恢复原理</h3>
                <div class="p1">
                    <p id="67">聚焦形貌恢复是一种通过2D序列图像实现3D形貌恢复的方法。该技术使用小景深的图像采集设备, 沿光轴方向等步长采集K帧被测表面的部分聚焦图像I<sub>k</sub> (k=1, 2, …, K) , 使其包含被测表面的全部深度信息, 通过聚焦信息获取每个像素点的深度信息, 从而近似出被测物表面的深度图。在聚焦形貌恢复技术中, 通常以像素点的锋利性来表征其清晰度的尺度, 运用聚焦评价函数量化序列图像每个像素点的聚焦程度。目前应用最广泛的聚焦评价函数有改进的拉普拉斯算子 (SML) 、Tenengrad聚焦评价函数 (TEN) 和灰度方差算子 (GLV) 。为增加评价函数的鲁棒性, 通常选择像素点 (x, y) 的邻域窗口U (x, y) 代替像素点作为计算对象, 其尺寸大小为w×w, 表示为:</p>
                </div>
                <div class="area_img" id="68">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_06800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="69">其中, (ξ, η) 表示邻域U (x, y) 中的像素点, k为图像序号。</p>
                </div>
                <div class="p1">
                    <p id="70">当选定一个评价函数后, 可求得像素点 (x, y) 的评价函数值序列F<sub>k</sub> (x, y) :</p>
                </div>
                <div class="area_img" id="71">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_07100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="72">由于清晰像素点可提供此像素对应表面元素的深度信息, 因此通过获取图像中每个像素点对应评价函数值序列的最大值对应的图像序号, 即可求得每个像素对应表面元素的深度值, 进而获得被测物体表面的初始深度图。计算公式为:</p>
                </div>
                <div class="area_img" id="73">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_07300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="74">最后利用近似方法或机器学习方法实现初始深度图连续化, 进一步提高三维形貌图的精度。</p>
                </div>
                <h3 id="75" name="75" class="anchor-tag">2 基于区域像素重构的聚焦形貌恢复方法</h3>
                <h4 class="anchor-tag" id="76" name="76">2.1 图像噪声检测与除噪</h4>
                <div class="p1">
                    <p id="77">在聚焦形貌恢复技术中, 由于硬件设备、物体表面纹理及光源等诸多因素的影响, 图像在获取、采集过程中会不可避免地引入噪声干扰, 图像噪声的存在大大影响了聚焦评价函数值的准确性。消除噪声干扰的主要手段通常是采用滤波的方法, 均值滤波消除噪声的同时会减弱图像的边缘条件, 中值滤波可以有效去除图像中的椒盐噪声, 然而这些滤波方法通常采用图像遍历操作, 在去除噪声的同时难免会改变非噪声像素点的灰度值。大多数聚焦评价函数都以图像像素点的灰度值作为表征图像清晰度尺度的重要参数, 因此改变图像的灰度值会影响评价函数值的准确性。</p>
                </div>
                <div class="p1">
                    <p id="78">图像在采集过程中主要会产生2种噪声, 分别为高斯噪声和椒盐噪声, 其中椒盐噪声对初始评价函数值序列准确性影响最大<citation id="150" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。图像中椒盐噪声点的最大特点是灰度值与其邻域像素点差别较大。因此中值滤波为最佳滤波方法, 但为了不改变图像中非噪声像素的灰度值, 可利用最大最小算子检测图像中的噪声点, 然后对噪声点采用中值滤波方法。设第k帧图像中像素点 (i, j) 的灰度值为I<sub>k</sub> (i, j) , 将该像素点的邻域分为4个区域, 分别定义为R<sub>1</sub>、R<sub>2</sub>、R<sub>3</sub>、R<sub>4</sub>, 其示意图如图1所示。</p>
                </div>
                <div class="p1">
                    <p id="79">R<sub>1</sub>=[I<sub>k</sub> (i-1, j-1) , I<sub>k</sub> (i, j-1) , I<sub>k</sub> (i-1, j) , I<sub>k</sub> (i, j) ] (4) R<sub>2</sub>=[I<sub>k</sub> (i, j-1) , I<sub>k</sub> (i+1, j-1) , I<sub>k</sub> (i, j) , I<sub>k</sub> (i+1, j) ] (5) R<sub>3</sub>=[I<sub>k</sub> (i-1, j) , I<sub>k</sub> (i, j) , I<sub>k</sub> (i-1, j+1) , I<sub>k</sub> (i, j+1) ] (6) R<sub>4</sub>=[I<sub>k</sub> (i, j) , I<sub>k</sub> (i+1, j) , I<sub>k</sub> (i, j+1) , I<sub>k</sub> (i+1, j+1) ] (7) </p>
                </div>
                <div class="area_img" id="80">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 像素点的邻域示意图" src="Detail/GetImg?filename=images/JSJC201902039_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 像素点的邻域示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="81">最大最小算子的定义如下:</p>
                </div>
                <div class="area_img" id="82">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_08200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="83">由最大最小算子可以求得像素点 (i, j) 邻域内的2个值分别为Max和Min, 当该像素点的灰度值与这2个值的差值都在一定的阈值K内时, 则可判定该像素点为非噪声点, 并设定该像素点的标志值Flag (i, j) 为1, 否则判定该像素点为噪声点并设定该像素点的标志值Flag (i, j) 为0, 计算如下:</p>
                </div>
                <div class="area_img" id="84">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_08400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="85">设像素点 (i, j) 在3×3邻域内灰度值的中值为Med。当像素点 (i, j) 的标志值Flag (i, j) 为1时, 该点的灰度值不变;当像素点 (i, j) 的标志值Flag (i, j) 为0时, 该点的灰度值为Med。表示如下:</p>
                </div>
                <div class="area_img" id="86">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="87">通过上述图像噪声检测与除噪方法处理采集的图像I<sub>k</sub>, 可得处理后的图像I'<sub>k</sub>。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88">2.2 图像区域像素重构</h4>
                <div class="p1">
                    <p id="89">在传统的聚焦形貌恢复算法中, 为求得像素点对应表面更准确的深度值, 像素点聚焦评价值的计算通常需要选择该像素点一定邻域范围的区域作为评价窗口, 并以该评价窗口内所有像素点评价函数值的均值作为该像素点的评价函数值。随着评价窗口的增大, 恢复求得的形貌图趋于平滑, 错误值减少, 但也会使形貌图失真。计算某个像素点的评价函数值所涉及的邻域像素点越多, 失真越严重。以3×3评价窗口为例, 所计算像素点的评价函数值为其邻域内3×3评价窗口内所有像素评价函数值的平均值, 而每个像素的评价函数值计算又是与其相邻像素的函数关系为依据, 因此实际参与该像素点计算的是5×5邻域窗口, 如图2所示。</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_09000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 当评价窗口为3&#215;3时参与计算的邻域窗口" src="Detail/GetImg?filename=images/JSJC201902039_09000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 当评价窗口为3×3时参与计算的邻域窗口  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_09000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="91">为克服以上计算方法的不足, 本文提出图像区域像素重构方法。从图像左上角开始, 以4个相邻像素为单位取4个像素的灰度均值为重构图像的灰度值, 其示意图如图3所示。设原图像I'左上角为图像原点, 沿水平方向为i, 竖直方向为j, 重构后图像为I″, 其重构过程为:</p>
                </div>
                <div class="area_img" id="92">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_09200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="93">由以上重构过程可知, 图像的长度和宽度都缩减为原图像的一半, 因此可以大大缩减原有算法的计算量, 同时能降低因高斯噪声产生错误值的概率。</p>
                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_09400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 图像重构示意图" src="Detail/GetImg?filename=images/JSJC201902039_09400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 图像重构示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_09400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="95" name="95">2.3 改进的聚焦评价函数</h4>
                <div class="p1">
                    <p id="96">传统基于梯度的灰度差分算子仅考虑了中心像素点与水平和垂直方向相邻像素间的差分, 虽然计算性能得到加强, 但聚焦曲线过于平坦, 即在焦点附近灵敏度不高, 且峰值位置不突出。根据图像聚焦离焦理论, 图像越清晰, 其邻域像素间的灰度值变化特征越明显, 且中心像素点邻域范围大小及对角线方向的灰度变化对该点的图像清晰度计算也会产生一定影响。因此, 综合考虑像素点邻域内不同方向上的灰度变化情况为聚焦判据会更有效, 同时结合以上重构图像可以免去合适邻域大小的选择。</p>
                </div>
                <div class="p1">
                    <p id="97">基于以上思想, 从邻域像素灰度差异性角度出发, 采用灰度差值表征图像的清晰度, 设计一种改进的聚焦评价函数。该函数加入了对角线方向上的灰度差异性。假定重构图像中像素点 (i, j) 邻域大小为3×3, 如图4所示, 定义水平、垂直方向上相邻像素点中心距为1, 如点 (i, j) 与点 (i-1, j) 之间的距离, 对角线上相邻像素点的中心距为槡2, 如点 (i, j) 与点 (i-1, j-1) 之间的距离。</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_09800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 3&#215;3邻域窗口示意图" src="Detail/GetImg?filename=images/JSJC201902039_09800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 3×3邻域窗口示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_09800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="99">根据以上分析, 改进的聚焦评价函数表达式为:</p>
                </div>
                <div class="area_img" id="100">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="100">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_10001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="102" name="102">2.4 聚焦形貌恢复算法描述</h4>
                <div class="p1">
                    <p id="103">根据上述理论设计聚焦形貌恢复算法, 具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="104">步骤1利用最大最小算子检测图像序列I<sub>k</sub>, 对于判定为噪声的像素点用中值滤波方法赋予新的灰度值, 得到预处理后序列图像I'<sub>k</sub>, 从而降低噪声对恢复精度的干扰。</p>
                </div>
                <div class="p1">
                    <p id="105">步骤2应用图像区域像素重构方法对预处理后序列图像I'<sub>k</sub>进行图像重构, 求得重构序列图像I″<sub>k</sub>。</p>
                </div>
                <div class="p1">
                    <p id="106">步骤3运用改进的聚焦评价函数计算序列图像I″<sub>k</sub>每个像素点 (i, j) 的聚焦评价值。</p>
                </div>
                <div class="area_img" id="107">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="108">其中, M、N分别为序列图像的行数和列数, K为序列图像总数量。</p>
                </div>
                <div class="p1">
                    <p id="109">步骤4获取初始深度值。将由步骤3得到的每个像素点 (i, j) 在序列图像中的聚焦评价值进行比较, 并找到最大评价值对应的图像序号, 从而获得初始深度值。</p>
                </div>
                <div class="area_img" id="110">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="111">步骤5根据所有像素点的最终深度值, 通过插值及拟合方法重构三维形貌图。</p>
                </div>
                <h3 id="112" name="112" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="113">为验证本文方法的有效性, 选用圆锥面、简单曲面及复杂曲面3种虚拟模型为形貌恢复对象, 利用模拟相机成像数学模型<citation id="151" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 分别生成与3种模型对应的不同聚焦等级的100帧360像素×360像素大小的图像序列。对取得的图像序列进行形貌恢复实验, 对比实际形貌与实验求得的形貌, 利用均方根误差 (RMSE) 及相关性 (Correlation) <citation id="152" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>定量评价恢复效果。其中RMSE与Correlation分别用于评价参考数据与真实数据之间的误差与近似程度, RMSE值越小, Correlation值越大, 表示参考数据与真实数据越符合。RMSE与Correlation的计算方法如下:</p>
                </div>
                <div class="area_img" id="114">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_11400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="114">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902039_11401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="116">其中, M和N表示图像的行数与列数, D' (i, j) 表示像素点 (i, j) 的实际深度值, <image id="137" type="formula" href="images/JSJC201902039_13700.jpg" display="inline" placement="inline"><alt></alt></image>表示图像中所有像素点的实际平均深度值, 同理, D (i, j) 表示像素点 (i, j) 的估计深度值, <image id="138" type="formula" href="images/JSJC201902039_13800.jpg" display="inline" placement="inline"><alt></alt></image>表示图像中所有像素点的估计平均深度值。</p>
                </div>
                <div class="p1">
                    <p id="117">将主流的F<sub>GLV</sub>、F<sub>SM L</sub>、F<sub>TEN</sub>聚焦算子作为参考方法, 评价窗口大小选择为3×3, 利用本文提出的F<sub>Pro</sub>方法对3种虚拟模型生成的序列图像进行形貌恢复, 恢复结果如图5所示。图5中第1列为3种虚拟模型的实际形貌图, 第2列～第5列分别为F<sub>Pro</sub>、F<sub>TEN</sub>、F<sub>GLV</sub>和F<sub>SM L</sub>方法获取的3种虚拟模型的三维形貌图。结果显而易见, 对于3种模型, 由其他3种传统方法恢复求得的三维形貌图中均出现不同程度的错误值, 本文方法获得的三维形貌更加完整可观、光滑平整, 几乎没有明显的错误值, 更加接近实际形貌。</p>
                </div>
                <div class="area_img" id="118">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同方法形貌恢复结果" src="Detail/GetImg?filename=images/JSJC201902039_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同方法形貌恢复结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="119">表1统计了4种恢复方法下圆锥面、简单曲面和复杂曲面3种模型形貌恢复结果的RMSE和Correlation数据。图6 (a) 和图6 (b) 分别为RM SE和Correlation统计结果的柱状图。结果显示, 对于RM SE而言, 无论何种实验对象, F<sub>Pro</sub>方法对应的RM SE值均明显小于其他3种评价方法的对应值, 因此F<sub>Pro</sub>方法对应的形貌图误差最小。对于Correlation而言, 无论何种实验对象, F<sub>Pro</sub>方法对应的Correlation值均大于其他3种评价方法的对应值, 说明F<sub>Pro</sub>方法对应的形貌图与实际形貌图相关性更大。综合表明F<sub>Pro</sub>方法恢复效果最优。通过定性与定量分析可知, F<sub>Pro</sub>方法较传统方法在恢复精度方面具有一定的优越性。</p>
                </div>
                <div class="area_img" id="120">
                                            <p class="img_tit">
                                                表1 不同实验对象的形貌恢复评价结果
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_12000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201902039_12000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_12000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 不同实验对象的形貌恢复评价结果" src="Detail/GetImg?filename=images/JSJC201902039_12000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_12100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同实验对象的形貌恢复评价结果统计柱状图" src="Detail/GetImg?filename=images/JSJC201902039_12100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同实验对象的形貌恢复评价结果统计柱状图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_12100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="122">为验证本文提出的最大最小算子滤波方法的适用性, 分别为圆锥面、简单曲面和复杂曲面的图像序列的第10、20、30、40、50、60、70、80、90、100帧中加入密度为0.01的椒盐噪声, 对噪声图像进行中值滤波和最大最小算子滤波, 将F<sub>TEN</sub>、F<sub>GLV</sub>、F<sub>SM L</sub>这3种传统聚焦算子作为参考方法, 并对比含噪图像序列、中值滤波图像序列及最大最小算子滤波图像序列的形貌恢复效果。同时, 为验证本文方法设计的聚焦评价函数的有效性, 对含噪图像序列同样采用最大最小算子滤波, 通过对比本文设计的聚焦评价函数与其他3种传统聚焦算子恢复得到的三维形貌图, 验证本文方法对于含噪图像同样具有可行性。</p>
                </div>
                <div class="p1">
                    <p id="123">图7 (a) 、7 (b) 和7 (c) 分别为3种实验对象的形貌恢复效果, 其中第1行～第3行分别为不做滤波处理图像序列、采用中值滤波后图像序列及采用最大最小算子滤波后图像序列的恢复结果。每幅图中第1列～第4列分别为F<sub>Pro</sub>、F<sub>TEN</sub>、F<sub>GLV</sub>及F<sub>SM L</sub>这4种评价方法的恢复效果。由此可知, 当图像中含有噪声时, 3种评价算子均有较多的错误值, 其中F<sub>GLV</sub>算子错误值最多, 恢复结果严重失真, 对噪声图像进行滤波处理后, 错误值明显减少, 但仍然有部分错误值存在。对比复杂曲面中的第2行与第3行可以发现, 对于3种实验对象, 采用最大最小算子滤波方法处理图像后, 形貌恢复结果中错误值少于采用中值滤波图像得到的结果。另外, 由圆锥面、简单曲面、复杂曲面中最后一行4种评价函数均采用最大最小算子滤波方法的形貌恢复结果可以看出, 利用本文设计的评价函数恢复得到的形貌图有少许错误值出现, 但是明显少于其他3种评价函数得到的恢复结果。</p>
                </div>
                <div class="area_img" id="124">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_12400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 3种实验对象的形貌恢复效果" src="Detail/GetImg?filename=images/JSJC201902039_12400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 3种实验对象的形貌恢复效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_12400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="125">表2和表3分别统计了针对3种实验对象的添加噪声、中值滤波和最大最小算子滤波处理的图像序列, 利用不同评价函数取得的形貌恢复结果的RM SE和Correlation数据。图8和图9分别为表2和表3对应的数据统计柱状图。数据统计显示, 对于3种实验恢复对象, 相较于含噪声图像序列, 由滤波处理后图像序列恢复求得的形貌图的RMSE和Correlation值, F<sub>TEN</sub>、F<sub>GLV</sub>及F<sub>SM L</sub>这3种聚焦评价算法对应的RMSE明显减小, Correlation明显增大, 且最大最小算子滤波方法对应的RMSE值更小, Correlation值更大, 由此可知2种滤波方法均可提高形貌恢复精度, 并且本文设计的最大最小算子滤波方法更优。此外, 对比4种采用最大最小算子滤波方法的评价函数的形貌恢复结果, 由此可知, 对于3种实验对象, 本文设计的聚焦评价函数对应的RM SE值略小于其他3种评价函数的对应值, Correlation值略大于其他3种评价函数, 因此本文设计的聚焦评价函数具有更高的准确性。</p>
                </div>
                <div class="area_img" id="126">
                                            <p class="img_tit">
                                                表2 不同滤波方法形貌恢复评价结果的RMSE值
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201902039_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 不同滤波方法形貌恢复评价结果的RMSE值" src="Detail/GetImg?filename=images/JSJC201902039_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="127">
                                            <p class="img_tit">
                                                表3 不同滤波方法形貌恢复评价结果的Correlation值
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201902039_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 不同滤波方法形貌恢复评价结果的Correlation值" src="Detail/GetImg?filename=images/JSJC201902039_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_12800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同滤波方法形貌恢复评价结果的RMSE值统计柱状图" src="Detail/GetImg?filename=images/JSJC201902039_12800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同滤波方法形貌恢复评价结果的RMSE值统计柱状图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_12800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 不同滤波方法形貌恢复评价结果的Correlation值统计柱状图" src="Detail/GetImg?filename=images/JSJC201902039_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 不同滤波方法形貌恢复评价结果的Correlation值统计柱状图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="130">同时, 为了验证本文方法在实际应用中形貌恢复精度及有效性, 选用金属零件为恢复对象, 对于实验对象利用步进电机驱动摄像机顺序采集100帧659像素×494像素的图像, 摄像机型号为Basler Ace acA645-100μm mono-chrome。对采集的图像序列进行形貌恢复实验, 实验参考F<sub>GLV</sub>、F<sub>SM L</sub>、F<sub>TEN</sub>这3种聚焦评价方法, 评价窗口大小选择为3×3, 通过观察对比实际形貌与实验求得的形貌, 定性评价恢复效果。图10为实验装置及实验对象。</p>
                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_13100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 0 实验装置及实验对象" src="Detail/GetImg?filename=images/JSJC201902039_13100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 0 实验装置及实验对象  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_13100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="132">图11为4种方法的形貌恢复结果, 由此可知, 基于梯度二阶差分的F<sub>SM L</sub>方法和F<sub>TEN</sub>方法恢复得到的三维形貌图出现了较多错误值, 尤其在金属圆盘中心处深度信息丢失严重。此外, F<sub>SM L</sub>方法边缘凹凸不平, 平整性较差, F<sub>TEN</sub>方法小部分边缘形貌信息有所丢失。F<sub>GLV</sub>方法获取的形貌图重建效果有所改善, 图像整体轮廓基本重建出来, 但圆盘边缘处仍有部分错误值, 相比之下F<sub>Pro</sub>方法求得的形貌图更接近原零件表面形貌, 不论在边缘还是中心处都显得很平整, 整体恢复效果最佳。总体而言, 其他3种方法均会出现不同程度的形貌信息错误问题, 且表面粗糙, 而本文方法获得的三维形貌更完整、平滑, 接近原形貌。因此, 本文方法相较于传统方法精度更高、更有效。</p>
                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902039_13300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 1 4种方法形貌恢复结果" src="Detail/GetImg?filename=images/JSJC201902039_13300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 1 4种方法形貌恢复结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902039_13300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="134">综上所述, 在图像降噪方面, 本文提出的最大最小算子滤波方法具备中值滤波的优点, 可减少图像中的椒盐噪声, 同时可以最大程度保证图像中的非噪声区域不改变, 对于含噪声图像的聚焦形貌恢复具有更高的精确性。在聚焦评价方面, 相较于传统聚焦评价方法, 无论是含噪声图像序列, 还是无噪声图像序列, 本文设计的聚焦评价函数均具有更好准确性。对于总体聚焦形貌恢复而言, 本文的聚焦形貌恢复方法同样具有可行性和有效性。</p>
                </div>
                <h3 id="135" name="135" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="136">本文将最大最小算子滤波方法与基于图像区域像素重构的改进聚焦评价算子相结合, 提出一种高精度的聚焦形貌恢复方法。通过最大最小算子滤波方法检测图像中的椒盐噪声, 并完成噪声点的中值滤波。采用基于图像区域像素重构的改进聚焦评价函数, 以一定大小的区域重构原图像后形成重构图像, 并利用邻域像素灰度差异性评价像素点的聚焦等级。实验结果表明, 本文设计的最大最小算子滤波方法比传统中值滤波方法更准确有效, 提出的基于图像区域像素重构的改进聚焦评价函数比传统聚焦评价函数更精确。结合以上2种方法, 形成基于最大最小算子与区域像素重构的聚焦形貌恢复方法在有效消除噪声干扰引入的恢复精度误差的同时, 能满足聚焦形貌恢复峰值定位要求, 获得的深度值更精确可靠, 在兼具形貌恢复的高精度与有效性方面均优于传统方法。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="33">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Shape from focus">

                                <b>[1]</b>NAYAR S K, NAKAGAWA Y.Shape from focus[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1994, 16 (8) :824-831.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accurate recovery of three-dimensional shape from image focus">

                                <b>[2]</b>SUBBARAO M, CHOI T S.Accurate recovery of three dimensional shape from image focus[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1995, 17 (3) :266-274.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                SHIM S O, MALIK A S, CHOI T S.Noise reduction using mean shift algorithm for estimating 3D shape[J].Imaging Science, 2011, 59 (4) :267-273.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14062400005926&amp;v=MTczMzZhaFE9Tmo3QmFySzhIdGZPcTQ5RlpPc0tCWDQvb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSUY0Yw==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>LEE I H, MAHMOOD M T, SHIM S O, et al.Optimizing image focus for 3D shape recovery through genetic algorithm[J].Multimedia Tools and Applications, 2014, 71 (1) :247-262.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Combining focus measures through genetic algorithm for shape from focus">

                                <b>[5]</b>KALEEM M, MAHMOOD M T.Combining focus measures through genetic algorithm for shape from focus[C]//Proceedings of IEEE International Conference on Information Science and Applications.Washington D.C., USA:IEEE Press, 2014:4441-4446.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Combining two focus measures to improve performance">

                                <b>[6]</b>XIA Xiaohua, YIN Lijuan, YAO Yunshi, et al.Combining two focus measures to improve performance[J].Measurement Science and Technology, 2017, 28 (10) .
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Shape from focus using statistics methods">

                                <b>[7]</b>JIANG Bo, GUO Liqiang, CHEN Fubing.Shape from focus using statistics methods[C]//Proceedings of 2017International Smart Cities Conference.Washington D.C., USA:IEEE Press, 2017:1-7.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Shape-from-focus depth reconstruction with a spatial consistency model">

                                <b>[8]</b>TSENG C Y, WANG S J.Shape-from-focus depth reconstruction with a spatial consistency model[J].IEEE Transactions on Circuits and Systems for Video Technology, 2014, 24 (12) :2063-2076.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=3-D shape recovery from image focus using rank transform">

                                <b>[9]</b>FAHAD M, JAWAD M, SHAHID Q W, et al.3-D shape recovery from image focus using rank transform[C]//Proceedings of the 12th International Symposium on Visual Computing.Berlin, Germany:Springer, 2016:514-523. (244) 239
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Shape-from-focus using total variation prior and split Bregman algorithm">

                                <b>[10]</b>KUMAR C H, VINOD H I, SAHAY R R.Shape-fromfocus using total variation prior and split Bregman algorithm[C]//Proceedings of 2014 Indian Conference on Computer Vision Graphics and Image Processing.New York, USA:ACM Press, 2014:80.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel shape from focus method based on 3Dsteerable filters for improved performance on treating textureless region">

                                <b>[11]</b>FAN Tiantian, YU Hongbin.A novel shape from focus method based on 3D steerable filters for improved performance on treating textureless region[J].Optics Communications, 2018, 410 (1) :254-261.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201603047&amp;v=MjAxNzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqbFc3L09MejdCYmJHNEg5Zk1ySTlCWTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>康宇, 陈念年, 范勇, 等.基于扩散的聚焦形貌恢复算法[J].计算机工程, 2016, 42 (3) :259-265.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Noise reduction using mean shift algorithm for estimating 3D shape">

                                <b>[13]</b>SHIM S O, MALIK A S, CHOI T S.Noise reduction using mean shift algorithm for estimating 3D shape[J].Imaging Science, 2011, 59 (5) :267-273.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002055991&amp;v=MTg4NjZkdEZDSGxVNy9BSUZnPU5qN0Jhck80SHRIT3I0cEFiZUlPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>SUBBARAO M, LU M C.Image sensing model and computer simulation for CCD camera systems[J].Machine Vision and Applications, 1994, 7 (4) :277-289.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739194&amp;v=MDY3Nzhud1plWnVIeWptVUxiSUlGNGNhaFE9TmlmT2ZiSzdIdEROcVk5RlkrZ0dEWFU5b0JNVDZUNFBRSC9pclJkR2VycVFUTQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>AAMIR S M, TAE S C.A novel algorithm for estimation of depth map using image focus for 3D shape recovery in the presence of noise[J].Pattern Recognition, 2008, 41 (7) :2200-2225.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201902039" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902039&amp;v=MTgyNTVHYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqbFc3L09MejdCYmJHNEg5ak1yWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
