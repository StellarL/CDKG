<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130385740301250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201906025%26RESULT%3d1%26SIGN%3dgnkdcvIRa2stvarn53tDwWS5ihc%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201906025&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201906025&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201906025&amp;v=MTkyNTVsVkwvTkx6N0JiYkc0SDlqTXFZOUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeW4=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#41" data-title="1 系统模型 ">1 系统模型</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="2 信道和功率分配算法 ">2 信道和功率分配算法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#107" data-title="3 仿真与结果分析 ">3 仿真与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#109" data-title="1) 融合周期&lt;i&gt;B&lt;/i&gt;对本文算法性能的影响。">1) 融合周期<i>B</i>对本文算法性能的影响。</a></li>
                                                <li><a href="#112" data-title="2) 主用户活跃度对本文算法性能的影响。">2) 主用户活跃度对本文算法性能的影响。</a></li>
                                                <li><a href="#115" data-title="3) 信道数、主用户数和认知用户数变化对系统能量效率的影响。">3) 信道数、主用户数和认知用户数变化对系统能量效率的影响。</a></li>
                                                <li><a href="#121" data-title="4) 算法性能比较。">4) 算法性能比较。</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#126" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="&lt;b&gt;图1 强化学习反馈过程&lt;/b&gt;"><b>图1 强化学习反馈过程</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;图2 融合周期&lt;i&gt;B&lt;/i&gt;对系统性能的影响&lt;/b&gt;"><b>图2 融合周期<i>B</i>对系统性能的影响</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;图3 不同&lt;i&gt;λ&lt;/i&gt;下系统的冲突概率变化&lt;/b&gt;"><b>图3 不同<i>λ</i>下系统的冲突概率变化</b></a></li>
                                                <li><a href="#117" data-title="&lt;b&gt;图4 信道数变化对系统性能的影响&lt;/b&gt;"><b>图4 信道数变化对系统性能的影响</b></a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;图5 主用户数变化对系统性能的影响&lt;/b&gt;"><b>图5 主用户数变化对系统性能的影响</b></a></li>
                                                <li><a href="#119" data-title="&lt;b&gt;图6 认知用户数变化对系统性能的影响&lt;/b&gt;"><b>图6 认知用户数变化对系统性能的影响</b></a></li>
                                                <li><a href="#123" data-title="&lt;b&gt;图7 4种算法系统容量结果比较&lt;/b&gt;"><b>图7 4种算法系统容量结果比较</b></a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;图8 4种算法系统能量效率结果比较&lt;/b&gt;"><b>图8 4种算法系统能量效率结果比较</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;图9 4种算法系统冲突概率结果比较&lt;/b&gt;"><b>图9 4种算法系统冲突概率结果比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="5">


                                    <a id="bibliography_1" title=" 罗骥.基于自适应中继的认知协作网络功率分配[J].计算机工程, 2017, 43 (7) :151-155." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201707026&amp;v=MjA2NjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5bmxWTC9OTHo3QmJiRzRIOWJNcUk5SFlvUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         罗骥.基于自适应中继的认知协作网络功率分配[J].计算机工程, 2017, 43 (7) :151-155.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_2" title=" 刁鸣, 张志强, 高洪元.离散量子粒子群优化的认知无线电频谱分配[J].计算机工程, 2015, 41 (11) :126-130." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201511023&amp;v=MDQ3MDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeW5sVkwvTkx6N0JiYkc0SDlUTnJvOUhaNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         刁鸣, 张志强, 高洪元.离散量子粒子群优化的认知无线电频谱分配[J].计算机工程, 2015, 41 (11) :126-130.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_3" title=" 马朋委.Q_learning强化学习算法的改进及应用研究[D].安徽淮南:安徽理工大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016185774.nh&amp;v=MjAyNzBSb0Z5bmxWTC9OVkYyNkdMS3dHOWJMcTVFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         马朋委.Q_learning强化学习算法的改进及应用研究[D].安徽淮南:安徽理工大学, 2016.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_4" title=" LIN Yun, WANG Chao, WANG Jiaxing.A novel dynamic spectrum access framework based on reinforcement learning for cognitive radio sensor networks[J].Sensors, 2016, 16 (10) :1-22." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel dynamic spectrum access framew ork based on reinforcement learning for cognitive radio sensor netw orks">
                                        <b>[4]</b>
                                         LIN Yun, WANG Chao, WANG Jiaxing.A novel dynamic spectrum access framework based on reinforcement learning for cognitive radio sensor networks[J].Sensors, 2016, 16 (10) :1-22.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_5" title=" YAO Yanjun, FENG Zhiyong.Centralized channel and power allocation for cognitive radio networks:a Q-learning solution[C]//Proceeding of FNMS’10.Washington D.C., USA:IEEE Press, 2010:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Centralized channel and power allocation for cognitive radio networks:a Q-learning solution">
                                        <b>[5]</b>
                                         YAO Yanjun, FENG Zhiyong.Centralized channel and power allocation for cognitive radio networks:a Q-learning solution[C]//Proceeding of FNMS’10.Washington D.C., USA:IEEE Press, 2010:1-8.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_6" title=" MOROZS N, CLARKE T, GRACE D.Distributed Q-learning based dynamic spectrum management in cognitive cellular systems:choosing the right learning rate[C]//Proceedings of IEEE Symposium on Computers and Communication.Washington D.C., USA:IEEE Press, 2014:1-10." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distributed Q-learning based dynamic spectrum management in cognitive cellular systems:choosing the right learning rate">
                                        <b>[6]</b>
                                         MOROZS N, CLARKE T, GRACE D.Distributed Q-learning based dynamic spectrum management in cognitive cellular systems:choosing the right learning rate[C]//Proceedings of IEEE Symposium on Computers and Communication.Washington D.C., USA:IEEE Press, 2014:1-10.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_7" title=" 伍春, 江虹, 易克初.聚类多Agent强化学习认知无线电资源分配[J].北京邮电大学学报, 2014, 37 (1) :80-84." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJYD201401018&amp;v=MjczMzA1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnlubFZML05KeWZTYXJHNEg5WE1ybzlFYklRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         伍春, 江虹, 易克初.聚类多Agent强化学习认知无线电资源分配[J].北京邮电大学学报, 2014, 37 (1) :80-84.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_8" title=" LALL S, SADHU A K, KONAR A.Multi-agent reinforcement learning for stochastic power management in cognitive radio network[C]//Proceedings of International Conference on Microelectronics, Computing and Communications.Washington D.C., USA:IEEE Press, 2016:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-agent reinforcement learning for stochastic power management in cognitive radio network">
                                        <b>[8]</b>
                                         LALL S, SADHU A K, KONAR A.Multi-agent reinforcement learning for stochastic power management in cognitive radio network[C]//Proceedings of International Conference on Microelectronics, Computing and Communications.Washington D.C., USA:IEEE Press, 2016:1-6.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_9" title=" BOUMEDIENE L, GAO Zhenguo, LIU Sheng.Distributed multi-agent Q-learning for joint channel allocation and power control in cognitive radio networks[J].Journal of Computational Information Systems, 2012, 8 (17) :7071-7078." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distributed multi-agent Q-learning for joint channel allocation and power control in cognitive radio networks">
                                        <b>[9]</b>
                                         BOUMEDIENE L, GAO Zhenguo, LIU Sheng.Distributed multi-agent Q-learning for joint channel allocation and power control in cognitive radio networks[J].Journal of Computational Information Systems, 2012, 8 (17) :7071-7078.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_10" title=" HE Jian, PENG Jun, JIANG Fu, et al.A distributed Q learning spectrum decision scheme for cognitive radio sensor network[J].International Journal of Distributed Sensor Networks, 2015 (1) :1-10." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A distributed Q learning spectrum decision scheme for cognitive radio sensor network">
                                        <b>[10]</b>
                                         HE Jian, PENG Jun, JIANG Fu, et al.A distributed Q learning spectrum decision scheme for cognitive radio sensor network[J].International Journal of Distributed Sensor Networks, 2015 (1) :1-10.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_11" title=" 胡图, 景志宏, 张磊, 等.认知Ad hoc网络中基于凸优化的功率控制算法[J].空军工程大学学报, 2012, 13 (1) :79-84." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KJGC201201018&amp;v=MjM0Njk5UE1ybzlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnlubFZML05MaWZNYmJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         胡图, 景志宏, 张磊, 等.认知Ad hoc网络中基于凸优化的功率控制算法[J].空军工程大学学报, 2012, 13 (1) :79-84.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_12" title=" WU Cheng, WANG Yiming, YIN Zhijie.Energy-efficiency opportunistic spectrum allocation in cognitive wireless sensor network[J].Eurasip Journal on Wireless Communications and Networking, 2018 (1) :13-24." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Energy-efficiency opportunistic spectrum allocation in cognitive wireless sensor network">
                                        <b>[12]</b>
                                         WU Cheng, WANG Yiming, YIN Zhijie.Energy-efficiency opportunistic spectrum allocation in cognitive wireless sensor network[J].Eurasip Journal on Wireless Communications and Networking, 2018 (1) :13-24.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_13" title=" 梁泉.未知环境中基于强化学习的移动机器人路径规划[J].2012, 29 (4) :477-481." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JDGC201204028&amp;v=MjA3MDk5UE1xNDlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnlubFZML05MeW5NYmJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         梁泉.未知环境中基于强化学习的移动机器人路径规划[J].2012, 29 (4) :477-481.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_14" title=" 冯陈伟, 袁江南.基于强化学习的异构无线网络资源管理算法[J].电信科学, 2015, 31 (8) :99-106." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DXKX201508014&amp;v=MDgzMjVMT2VaZVJvRnlubFZML05JVFhBZHJHNEg5VE1wNDlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         冯陈伟, 袁江南.基于强化学习的异构无线网络资源管理算法[J].电信科学, 2015, 31 (8) :99-106.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_15" title=" 苏小红, 杨博, 王亚东.基于进化稳定策略的遗传算法[J].软件学报, 2003, 14 (11) :1863-1868." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200311006&amp;v=MjAwMzBSb0Z5bmxWTC9OTnlmVGJMRzRIdExOcm85RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         苏小红, 杨博, 王亚东.基于进化稳定策略的遗传算法[J].软件学报, 2003, 14 (11) :1863-1868.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     梶田秀司.类机器人[M].管贻生, 译.北京:清华大学出版社, 2007.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(06),160-164+174 DOI:10.19678/j.issn.1000-3428.0050704            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于分布式协作Q学习的信道与功率分配算法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E7%90%B3&amp;code=23890621&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐琳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E7%9F%A5%E5%8A%B2&amp;code=07054931&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵知劲</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%9D%AD%E5%B7%9E%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E9%80%9A%E4%BF%A1%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0073968&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杭州电子科技大学通信工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为提高分布式认知无线网络认知用户信道与功率分配算法的能量效率和收敛速度, 将单位能量的平均比特数作为通信效率指标, 平衡用户通信质量和系统能量消耗, 提出一种基于多Agent协作强化学习的分布式信道与功率分配算法。在多Agent独立Q学习的基础上引入协作学习, 各用户通过独立Q学习后, 共享<i>Q</i>值并进行融合再学习。仿真结果表明, 与基于能效的独立Q学习算法、独立Q学习算法以及随机功率分配算法相比, 该算法能够有效提高认知用户发射功率和信道分配时的收敛速度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BF%A1%E9%81%93%E4%B8%8E%E5%8A%9F%E7%8E%87%E5%88%86%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信道与功率分配;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%8F%E4%BD%9CQ%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">协作Q学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AE%A4%E7%9F%A5%E6%97%A0%E7%BA%BF%E7%94%B5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">认知无线电;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%BD%E9%87%8F%E6%95%88%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">能量效率;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%86%B2%E7%AA%81%E6%A6%82%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">冲突概率;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    徐琳 (1994—) , 女, 硕士研究生, 主研方向为认知无线电、信号处理;E-mail: xulin@hdu.edu.cn;
                                </span>
                                <span>
                                    赵知劲, 教授、博士生导师。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-03-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>“十二五”国防预研项目 (41001010401);</span>
                    </p>
            </div>
                    <h1><b>Channel and Power Allocation Algorithm Based on Distributed Cooperative Q Learning</b></h1>
                    <h2>
                    <span>XU Lin</span>
                    <span>ZHAO Zhijin</span>
            </h2>
                    <h2>
                    <span>School of Communication Engineering, Hangzhou Dianzi University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to improve the energy efficiency and convergence speed of cognitive user channel and power allocation algorithms in distributed cognitive wireless networks, use the average number of bits per unit of energy as a communication efficiency indicator, and balance user communication quality and system energy consumption, this paper proposes a distributed channel and power allocation algorithm based on multi-Agent cooperative reinforcement learning.The collaborative learning is introduced on the basis of multi-agent independent Q-learning is introduced, and users share <i>Q</i> values and fuse after independent Q-learning.Simulation results show that the algorithm can effectively improve the convergence speed of cognitive users in transmitting power and channel allocation compared with energy efficiency-based independent Q-learning algorithm, independent Q-learning algorithm and random power allocation algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=channel%20and%20power%20allocation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">channel and power allocation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=cooperative%20Q%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">cooperative Q learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=cognitive%20radio&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">cognitive radio;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=energy%20efficiency&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">energy efficiency;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=collision%20probability&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">collision probability;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-03-09</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="38">随着无线应用需求的不断增长, 频谱容量需求日益增加<citation id="128" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。认知无线电技术使得认知用户可接入空闲频谱, 从而提高频谱利用率。资源分配是认知无线电的关键技术之一, 它通过分配最佳信道、优化传输功率等参数来提高系统的整体性能<citation id="129" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="39">强化学习算法的学习过程是根据当前所处环境的变化, 不断更新动作选择策略, 从而做出最优决策<citation id="130" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。在强化学习中最常用的算法是Q学习<citation id="131" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 其已成功地应用于认知无线电的资源分配问题。文献<citation id="132" type="reference">[<a class="sup">5</a>]</citation>提出基于经典Q学习的信道和传输功率联合分配算法。文献<citation id="133" type="reference">[<a class="sup">6</a>]</citation>将Win-or-Learn-Fast可变学习速率的Q学习算法用于信道分配。文献<citation id="134" type="reference">[<a class="sup">7</a>]</citation>对信道选择和功率控制分层处理, 利用基于奖赏值的可变速率Q学习完成功率的分配。以上研究都是基于集中式网络架构, 需要中心控制信道, 因此降低了整个网络的通信效率和灵活性, 增加了资源消耗。在分布式网络架构下, 文献<citation id="135" type="reference">[<a class="sup">8</a>]</citation>在多Agent Q学习中结合3种均衡策略, 对传输功率进行控制, 但需事先确定用户所在信道;文献<citation id="136" type="reference">[<a class="sup">9</a>]</citation>利用独立Q学习完成了信道和功率分配, 但能量效率较低;文献<citation id="137" type="reference">[<a class="sup">10</a>]</citation>在基于独立Q学习的信道和功率分配过程中考虑了信干噪比, 提升了能量效率, 但收敛速度低。</p>
                </div>
                <div class="p1">
                    <p id="40">针对上述问题, 本文提出一种协作式多Agent Q学习算法来实现信道和功率的联合分配。无需预先已知认知用户的通信信道, 在学习过程中通过融合各用户的<i>Q</i>值, 以提高系统能量效率。</p>
                </div>
                <h3 id="41" name="41" class="anchor-tag">1 系统模型</h3>
                <div class="p1">
                    <p id="42">本文考虑一个多用户的分布式认知无线电协作网络<citation id="138" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 各认知用户可以感知其他用户节点信息, 并进行自主决策。假设网络中存在<i>M</i>个主用户、<i>K</i>个认知用户以及<i>N</i>个可用于认知用户的信道, 且在学习期间, 信道数量是固定的。由于是多用户通信, 接收端可能存在高斯白噪声和用户间的相互干扰。一方面, 用户需要提高传输功率, 以获得更高的信干噪比和传输速率, 保证其服务质量需求和正常通信;另一方面, 用户必须降低传输功率, 实现节能目标, 并减少对其他用户的干扰。因此, 本文以冲突概率衡量用户是否能正常通信, 并提出通信效率指标来考虑通信质量和能量消耗的平衡。将单位能量的平均比特数<i>Φ</i><sup><i>i</i></sup>, 即能量效率<citation id="139" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>作为通信效率指标, 如式 (1) 所示。</p>
                </div>
                <div class="p1">
                    <p id="43" class="code-formula">
                        <mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Φ</mi><msup><mrow></mrow><mi>i</mi></msup><mo>=</mo><mfrac><mrow><mi>W</mi><mtext>l</mtext><mtext>b</mtext><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mi>η</mi><msup><mrow></mrow><mi>i</mi></msup><mo stretchy="false">) </mo></mrow><mrow><mi>p</mi><msup><mrow></mrow><mi>i</mi></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="44">其中, <i>i</i>为认知用户编号, <i>W</i>为频谱带宽, <i>p</i><sup><i>i</i></sup>∈{<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub>, …, <i>P</i><sub><i>Z</i></sub>}为认知用户<i>i</i>选择的传输功率, <i>Z</i>为功率总级别数, <i>P</i><sub>min</sub>≤<i>P</i><sub>1</sub>≤<i>P</i><sub>2</sub>≤…≤<i>P</i><sub><i>Z</i></sub>≤<i>P</i><sub>max</sub>, <i>η</i><sup><i>i</i></sup>为认知用户<i>i</i>处的信干噪比, 其表达式如式 (2) 所示。</p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>η</mi><msup><mrow></mrow><mi>i</mi></msup><mo>=</mo><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mi>h</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>i</mi></mrow></msub><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi>g</mi></mstyle><msub><mrow></mrow><mrow><mi>k</mi><mi>i</mi></mrow></msub><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo><mi>p</mi><msubsup><mrow></mrow><mi>k</mi><mrow><mi>p</mi><mi>u</mi></mrow></msubsup><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>Κ</mi><mo>\</mo><mo stretchy="false">{</mo><mi>i</mi><mo stretchy="false">}</mo></mrow><mi>Κ</mi></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mi>h</mi><msub><mrow></mrow><mrow><mi>j</mi><mi>i</mi></mrow></msub><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">其中, <i>h</i><sub><i>ji</i></sub> (<i>m</i>) 为在信道<i>m</i>上认知用户<i>j</i>到认知用户<i>i</i>的信道增益, <i>g</i><sub><i>ki</i></sub> (<i>m</i>) 为在信道<i>m</i>上主用户<i>k</i>到认知用户<i>i</i>的信道增益, 假定在学习期间都是固定的, <i>p</i><mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mrow><mi>p</mi><mi>u</mi></mrow></msubsup></mrow></math></mathml>为主用户k的传输功率, n<sub>0</sub>为高斯白噪声功率。</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag">2 信道和功率分配算法</h3>
                <div class="p1">
                    <p id="49">强化学习<citation id="140" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>是一种在线学习技术, 其输入为环境状态, 通过与环境的互动得到的反馈奖励信号来选择适合当前环境状态的最佳动作<citation id="141" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。强化学习系统主要包括以下4个部分:状态<i>s</i>, 动作<i>a</i>, 奖赏函数<i>r</i>和Agent学习策略, 强化学习反馈过程如图1所示<citation id="142" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906025_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 强化学习反馈过程" src="Detail/GetImg?filename=images/JSJC201906025_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 强化学习反馈过程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906025_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="51">目前最常用的强化学习方法是Q学习。在Q学习过程中, 长期累积奖励由Q函数的评估函数值确定。定义评估函数值<i>Q</i><sub><i>t</i></sub> (<i>s</i>, <i>a</i>) 为Agent在状态<i>s</i>下选取动作<i>a</i>, 并在下个状态选取最优动作的折扣奖励累积值。在学习过程中, 通过递归的方式不断更新该<i>Q</i>值, 以获得最大的长期累积奖励, 从而得到预期目标下的最佳分配策略。<i>Q</i>值的更新如式 (3) 所示<citation id="143" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Q</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>α</mi><mo stretchy="false">) </mo><mi>Q</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>α</mi><mo stretchy="false"> (</mo><mi>r</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi>γ</mi><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>a</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></munder><mspace width="0.25em" /><mi>Q</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">其中, <i>r</i><sub><i>t</i></sub>为奖赏值, <i>α</i>为学习速率, 0&lt;<i>α</i>&lt;1, <i>γ</i>为奖励折扣值, 0&lt;<i>γ</i>&lt;1, <i>a</i><sub><i>t</i>+1</sub>为下一状态的最优动作。</p>
                </div>
                <div class="p1">
                    <p id="54">在分布式认知无线电协作网络的信道和功率分配问题中, 为了达到保证通信质量及加快收敛速度的目的, 本文将各认知用户视为一个学习Agent, 在上述Q学习算法中引入协作学习, 提出一种协作式多Agent Q学习算法。对于Agent <i>i</i>, 假设其环境状态为<i>S</i>, 动作集为<i>A</i>, 奖赏函数为<i>r</i><mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml>, 动作选择策略为π (s, a) 。</p>
                </div>
                <div class="p1">
                    <p id="56">利用<i>Q</i>学习的资源分配算法描述如下:</p>
                </div>
                <div class="p1">
                    <p id="57">1) 状态S:定义认知用户当前所占用信道ch为环境状态, 即s<mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml>=ch<mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml>, ch<mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml>∈{1, 2, …, N}。</p>
                </div>
                <div class="p1">
                    <p id="61">2) 动作集A:每个<i>Agent</i>采取的动作分为2个方面:信道分配和传输功率分配, 即a<sub>i</sub>=[n<sub>i</sub>, p<sub>i</sub>]∈A, 其中, n<sub>i</sub>∈{1, 2, …, N}为可用信道。</p>
                </div>
                <div class="p1">
                    <p id="62">3) 奖赏函数r<mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml>:本文中奖赏函数的设置参考文献<citation id="144" type="reference">[<a class="sup">9</a>,<a class="sup">10</a>]</citation>, 由以下3个部分组成:</p>
                </div>
                <div class="p1">
                    <p id="64"> (1) 认知用户与主用户发生冲突的奖罚:当认知用户与主用户选择同一信道时会发生冲突, 主用户的通信会受到干扰, 给予-5的惩罚。</p>
                </div>
                <div class="p1">
                    <p id="65"> (2) 认知用户间发生冲突的奖罚:由于一个信道只能由一个主用户或者认知用户占用, 因此当认知用户选择同一信道时会发生冲突, 导致用户无法正常通信, 给予-3的惩罚。</p>
                </div>
                <div class="p1">
                    <p id="66"> (3) 功率控制:认知用户可以调整功率来实现服务质量和能耗约束。因此, 将通信效率指标Φ<sup>i</sup>作为奖励值, 但用户的信干噪比η<sup>i</sup>必须满足式 (4) 的约束;否则, 奖励值为0。</p>
                </div>
                <div class="p1">
                    <p id="67">η<sup>i</sup>≥η<sup>*</sup>      (4) </p>
                </div>
                <div class="p1">
                    <p id="68">其中, η<sup>*</sup>为信干噪比阈值。</p>
                </div>
                <div class="p1">
                    <p id="69">综上所述, 奖赏函数r<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml>的定义如式 (5) 所示。</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mo>-</mo><mn>5</mn><mo>, </mo><mtext>与</mtext><mtext>主</mtext><mtext>用</mtext><mtext>户</mtext><mtext>冲</mtext><mtext>突</mtext></mtd></mtr><mtr><mtd columnalign="left"><mo>-</mo><mn>3</mn><mo>, </mo><mtext>与</mtext><mtext>认</mtext><mtext>知</mtext><mtext>用</mtext><mtext>户</mtext><mtext>冲</mtext><mtext>突</mtext></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>, </mo><mi>η</mi><msup><mrow></mrow><mtext>i</mtext></msup><mo>&lt;</mo><mi>η</mi><msup><mrow></mrow><mo>*</mo></msup></mtd></mtr><mtr><mtd columnalign="left"><mn>1</mn><mo>+</mo><mi>Φ</mi><msup><mrow></mrow><mi>i</mi></msup><mo>, </mo><mtext>正</mtext><mtext>常</mtext><mtext>传</mtext><mtext>输</mtext></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">4) 动作选择策略π (s, a<sup>*</sup>) :在<i>Q</i>学习算法的策略选择中, 存在探索和开发间的平衡问题。探索意味着<i>Agent</i>通过不断学习知识来更新Q值, 发现更好的策略;开发意味着<i>Agent</i>从所有行动中选择最佳行动。为解决该平衡问题, 通常使用ε-贪心算法和<i>Boltzmann</i>分布算法。本文选择<i>Boltzmann</i>分布算法来确定最优动作, 如式 (6) 所示。</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>π</mi><mo stretchy="false"> (</mo><mi>s</mi><mo>, </mo><mi>a</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext></mrow></mstyle><mrow><mi>a</mi><msup><mrow></mrow><mo>*</mo></msup></mrow></munder><mfrac><mrow><mtext>e</mtext><msup><mrow></mrow><mrow><mi>Q</mi><mo stretchy="false"> (</mo><mi>s</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>/</mo><mi>Τ</mi></mrow></msup></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>U</mi></munderover><mtext>e</mtext></mstyle><msup><mrow></mrow><mrow><mi>Q</mi><mo stretchy="false"> (</mo><mi>s</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo><mo>/</mo><mi>Τ</mi></mrow></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">其中, a<sup>*</sup>为当前状态s下选择的最优动作, T&gt;0为温度参数, T较大意味着所有动作都能被等概率地选取。随着T的减少, Q值最大的动作将以最大概率被选中, U为动作总类数。</p>
                </div>
                <div class="p1">
                    <p id="75">5) 协作学习算法</p>
                </div>
                <div class="p1">
                    <p id="76">如果系统中的认知用户数量较多, 各用户仅依靠相同的奖赏函数和动作策略不能做到提高收敛速度。因此, 本文提出一种协作<i>Q</i>学习算法, 该算法将协作算法和<i>Q</i>学习算法相结合, 即各用户在执行<i>Q</i>学习算法时相互合作, 以加快收敛速率。</p>
                </div>
                <div class="p1">
                    <p id="77">在本文的多<i>Agent</i>系统中, 各<i>Agent</i>是同构的, 有一致的学习目标, 即系统性能最大化。在这样的环境中, 每个<i>Agent</i>都有相似的学习过程, 且经过大量的<i>Q</i>学习之后, 各<i>Agent</i>得到的效果也是相似的。因此, <i>Agent</i>之间可以进行交互学习, 即可以通过共享和融合各自的Q值来加快单个<i>Agent</i>的学习速率。这相当于在学习过程中给认知用户提供了学习经验, 从而避免了选择不必要的动作, 能促使<i>Agent</i>更快地达到收敛状态。</p>
                </div>
                <div class="p1">
                    <p id="78">因此, 协作算法的思路是各认知用户利用<i>Q</i>学习算法进行独立学习, 在学习一定时间后, 共享当前的Q值并进行融合, 将融合后的Q值作为下一次<i>Q</i>学习的初值, 进行再学习。其具体过程如下:</p>
                </div>
                <div class="p1">
                    <p id="79">1) 每个认知用户进行B次独立学习后, 在各状态下, 从所有认知用户所共享得Q<mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml> (s, a) 值中找出最大的Q值, 即:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Q</mi><msubsup><mrow></mrow><mi>t</mi><mo>*</mo></msubsup><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>a</mi><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mn>1</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>Κ</mi></mrow></munder><mo stretchy="false">{</mo><mi>Q</mi><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>a</mi><mo stretchy="false">) </mo><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">2) 计算:</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Q</mi><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>a</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mi>Q</mi><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>a</mi><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac><mspace width="0.25em" /><mo>, </mo><mspace width="0.25em" /><mi>Q</mi><msubsup><mrow></mrow><mi>t</mi><mo>*</mo></msubsup><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>a</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Q</mi><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>a</mi><mo stretchy="false">) </mo><mo>&gt;</mo><mn>0</mn></mtd></mtr><mtr><mtd><mn>2</mn><mi>Q</mi><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>a</mi><mo stretchy="false">) </mo><mspace width="0.25em" /><mo>, </mo><mi>Q</mi><msubsup><mrow></mrow><mi>t</mi><mo>*</mo></msubsup><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>a</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Q</mi><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>a</mi><mo stretchy="false">) </mo><mo>=</mo><mn>0</mn></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">3) 对于所有<i>Agent</i>, 有:</p>
                </div>
                <div class="p1">
                    <p id="85">Q<mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>i</mi></msubsup></mrow></math></mathml> (s<sub>k</sub>, a) =Q<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml> (s<sub>k</sub>, a) ,  i∈{1, 2, …, K}      (9) </p>
                </div>
                <div class="p1">
                    <p id="88">上述算法表明, 由于一个信道只能由一个认知用户占用, 在多个用户处于相同信道状态时, 对Q值最大的用户实行最大化, 即进行Q值加倍;获取最大Q值所对应的信道, 同时减小其他用户对应该信道的Q值, 即进行Q值减半, 从而降低系统的冲突概率, 提高各<i>Agent</i>的学习效率。</p>
                </div>
                <div class="p1">
                    <p id="89">因此, 可得本文提出的基于协作式多<i>Agent Q</i>学习算法的资源分配方法, 具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="90"><b>步骤1</b> 系统初始化, <i>t</i>←0, <i>Q</i><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml>←0, 设定<i>α</i>、<i>γ</i>和<i>T</i><sub>0</sub>, 以及初始状态<i>s</i><sub>0</sub>, 总迭代数<i>G</i>。</p>
                </div>
                <div class="p1">
                    <p id="92"><b>步骤2</b> 对于每个用户Agent <i>i</i>, 执行Q学习算法:</p>
                </div>
                <div class="p1">
                    <p id="93"><b>步骤2.1</b> 观察当前状态<i>s</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml>;</p>
                </div>
                <div class="p1">
                    <p id="95"><b>步骤2.2</b> 由式 (6) 选择动作<i>a</i><sub><i>t</i></sub>并执行;</p>
                </div>
                <div class="p1">
                    <p id="96"><b>步骤2.3</b> 观察后续状态<i>s</i><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>i</mi></msubsup></mrow></math></mathml>, 并由式 (5) 计算奖赏函数r<mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml>;</p>
                </div>
                <div class="p1">
                    <p id="99"><b>步骤2.4</b> 根据式 (3) 更新<i>Q</i><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml> (<i>s</i>, <i>a</i>) 值。</p>
                </div>
                <div class="p1">
                    <p id="101"><b>步骤3</b> 当<i>t</i>能被<i>B</i>整除时, 则使用上述的协作学习算法对<i>Q</i>值进行融合更新。</p>
                </div>
                <div class="p1">
                    <p id="102"><b>步骤4</b><i>t</i>←<i>t</i>+1, <i>T</i>按下式更新:</p>
                </div>
                <div class="p1">
                    <p id="103"><i>T</i>=<i>T</i><sub>0</sub>-<i>T</i><sub>0</sub>×<i>t</i>/<i>G</i></p>
                </div>
                <div class="p1">
                    <p id="104"><b>步骤5</b> 当<i>t</i>达到设定的总迭代次数<i>G</i>时, 则结束;否则, <i>s</i><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml>←<i>s</i><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>i</mi></msubsup></mrow></math></mathml>, 转步骤2。</p>
                </div>
                <h3 id="107" name="107" class="anchor-tag">3 仿真与结果分析</h3>
                <div class="p1">
                    <p id="108">本节为验证协作学习算法的有效性, 在仿真中设定主用户数<i>M</i>为3, 认知用户数<i>K</i>为2, 信道数<i>N</i>为10, 频谱带宽<i>W</i>为1.5 MHz, 主用户功率为200 mW, 认知用户可选的传输功率<i>P</i><sub><i>i</i></sub>∈{100, 125, 150, 175, 200} mW, <i>n</i><sub>0</sub>=10<sup>-7</sup>mW, 各信道增益服从均值为1的瑞利分布, 温度参数初始值<i>T</i><sup>0</sup>为0.6, 信干噪比阈值<i>η</i><sup>*</sup>为0 dB, <i>α</i>为0.15。假设主用户固定占用一个信道, 总迭代次数<i>G</i>为10 000次, 均分为20个学习阶段进行统计, 且在后续的所有对比算法中采用了相同的参数设定。仿真结果均取10次独立实验的平均值。</p>
                </div>
                <h4 class="anchor-tag" id="109" name="109">1) 融合周期<i>B</i>对本文算法性能的影响。</h4>
                <div class="p1">
                    <p id="110">融合周期<i>B</i>分别取50、150、450、600、850, 且主用户以概率0.5占用信道时, 应用本文算法的系统能量效率曲线如图2所示。由图2可知, 随着<i>B</i>的增加, 收敛速度加快;但当<i>B</i>增加到一定程度时, 收敛速度不再提高;<i>B</i>选择过大或过小都可能导致系统能量效率降低。为综合考虑收敛速度和系统能效, 下文选取<i>B</i>为450。</p>
                </div>
                <div class="area_img" id="111">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906025_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 融合周期B对系统性能的影响" src="Detail/GetImg?filename=images/JSJC201906025_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 融合周期<i>B</i>对系统性能的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906025_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="112" name="112">2) 主用户活跃度对本文算法性能的影响。</h4>
                <div class="p1">
                    <p id="113">主用户以概率<i>λ</i>分别为0.2、0.5、0.7和1.0在其信道上通信。应用本文算法的系统冲突概率曲线如图3所示。由图3可知, 采用本文提出的基于协作式多Agent Q学习算法的资源分配方法时, 认知用户在不同的主用户活跃程度下都以概率1成功通信, 这意味着认知用户能够根据频谱可用性动态地调整自己的行为。且随主用户出现概率的增大, 学习速率会降低。在本文仿真中取<i>λ</i>为0.5。</p>
                </div>
                <div class="area_img" id="114">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906025_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同λ下系统的冲突概率变化" src="Detail/GetImg?filename=images/JSJC201906025_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 不同<i>λ</i>下系统的冲突概率变化</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906025_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="115" name="115">3) 信道数、主用户数和认知用户数变化对系统能量效率的影响。</h4>
                <div class="p1">
                    <p id="116">本文算法的系统容量、能量效率和冲突概率随信道数、主用户数和认知用户数变化曲线分别如图4～图6所示。各系统容量、能量效率和冲突概率值均取自于系统达到稳定状态后的值。由图4可知, 当信道数小于5时, 系统容量和能量效率随信道数增加而明显增加, 冲突概率逐渐降低;当信道数大于5时, 系统容量和能量效率有略微波动, 用户间不再产生冲突。由图5可知, 当主用户数小于8时, 系统容量和能量效率随主用户数变化有略微波动, 用户间没有产生冲突;当主用户数大于8时, 认知用户的系统容量和能量效率下降, 冲突概率大幅增大, 这是由主用户数增加, 使得主用户占用信道通信的概率增大导致的。由图6可知, 当认知用户小于8时, 系统容量和能量效率随认知用户数增加而增加;当认知用户大于8时, 由于用户数多于信道数, 冲突概率大幅增大, 系统容量和能量效率相应减小。</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906025_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 信道数变化对系统性能的影响" src="Detail/GetImg?filename=images/JSJC201906025_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 信道数变化对系统性能的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906025_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="118">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906025_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 主用户数变化对系统性能的影响" src="Detail/GetImg?filename=images/JSJC201906025_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 主用户数变化对系统性能的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906025_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906025_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 认知用户数变化对系统性能的影响" src="Detail/GetImg?filename=images/JSJC201906025_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 认知用户数变化对系统性能的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906025_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="120">综上可得, 在信道数和此频段上工作的主用户数一定情况下, 选择认知用户数为信道数与主用户数之差, 应用本文算法的系统可以获得最佳性能。</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121">4) 算法性能比较。</h4>
                <div class="p1">
                    <p id="122">本文算法、基于能效的独立Q学习算法<citation id="145" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、独立Q学习算法<citation id="146" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>以及随机功率分配算法的系统容量、能量效率和冲突概率曲线分别如图7～图9所示。由图7～图9可知, 本文算法在2 000次迭代后系统性能稳定, 达到收敛状态, 具有最佳的系统容量和能量效率, 且冲突概率下降最快;而基于能效的Q学习算法和独立Q学习算法分别在3 000次和5 000次迭代后达到收敛状态, 因此本文算法的收敛速度明显较快;而随机功率分配算法的各方面性能都是最差的;独立Q学习算法虽然可以达到收敛, 但其分配功率时没有考虑信噪比, 所以无法实现高能效。3种基于Q学习的算法都能使冲突概率降低为0, 保证用户正常通信, 但本文算法的冲突概率明显低于基于能效的独立Q学习和独立Q学习算法, 因此, 可以快速选择最优信道和最佳功率, 为认知系统提供更好的服务质量保证。</p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906025_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 4种算法系统容量结果比较" src="Detail/GetImg?filename=images/JSJC201906025_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 4种算法系统容量结果比较</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906025_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="124">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906025_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 4种算法系统能量效率结果比较" src="Detail/GetImg?filename=images/JSJC201906025_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图8 4种算法系统能量效率结果比较</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906025_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="125">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906025_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 4种算法系统冲突概率结果比较" src="Detail/GetImg?filename=images/JSJC201906025_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图9 4种算法系统冲突概率结果比较</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906025_125.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="126" name="126" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="127">本文主要研究分布式认知无线网络结构, 提出分布式协作Q学习的信道和功率分配算法。通过引入协作学习, 各用户在进行独自一周期的Q学习后共享<i>Q</i>值, 并对<i>Q</i>值进行融合再学习。实验结果表明, 该算法能够有效提高认知用户信道分配时的发射功率和系统的收敛速度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="5">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201707026&amp;v=MTIyODBGckNVUkxPZVplUm9GeW5sVkwvTkx6N0JiYkc0SDliTXFJOUhZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 罗骥.基于自适应中继的认知协作网络功率分配[J].计算机工程, 2017, 43 (7) :151-155.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201511023&amp;v=MTg0MzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeW5sVkwvTkx6N0JiYkc0SDlUTnJvOUhaNFE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 刁鸣, 张志强, 高洪元.离散量子粒子群优化的认知无线电频谱分配[J].计算机工程, 2015, 41 (11) :126-130.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016185774.nh&amp;v=MDM2NzFMcTVFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5bmxWTC9OVkYyNkdMS3dHOWI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 马朋委.Q_learning强化学习算法的改进及应用研究[D].安徽淮南:安徽理工大学, 2016.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel dynamic spectrum access framew ork based on reinforcement learning for cognitive radio sensor netw orks">

                                <b>[4]</b> LIN Yun, WANG Chao, WANG Jiaxing.A novel dynamic spectrum access framework based on reinforcement learning for cognitive radio sensor networks[J].Sensors, 2016, 16 (10) :1-22.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Centralized channel and power allocation for cognitive radio networks:a Q-learning solution">

                                <b>[5]</b> YAO Yanjun, FENG Zhiyong.Centralized channel and power allocation for cognitive radio networks:a Q-learning solution[C]//Proceeding of FNMS’10.Washington D.C., USA:IEEE Press, 2010:1-8.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distributed Q-learning based dynamic spectrum management in cognitive cellular systems:choosing the right learning rate">

                                <b>[6]</b> MOROZS N, CLARKE T, GRACE D.Distributed Q-learning based dynamic spectrum management in cognitive cellular systems:choosing the right learning rate[C]//Proceedings of IEEE Symposium on Computers and Communication.Washington D.C., USA:IEEE Press, 2014:1-10.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJYD201401018&amp;v=MzIwOTdML05KeWZTYXJHNEg5WE1ybzlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnlubFY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 伍春, 江虹, 易克初.聚类多Agent强化学习认知无线电资源分配[J].北京邮电大学学报, 2014, 37 (1) :80-84.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-agent reinforcement learning for stochastic power management in cognitive radio network">

                                <b>[8]</b> LALL S, SADHU A K, KONAR A.Multi-agent reinforcement learning for stochastic power management in cognitive radio network[C]//Proceedings of International Conference on Microelectronics, Computing and Communications.Washington D.C., USA:IEEE Press, 2016:1-6.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distributed multi-agent Q-learning for joint channel allocation and power control in cognitive radio networks">

                                <b>[9]</b> BOUMEDIENE L, GAO Zhenguo, LIU Sheng.Distributed multi-agent Q-learning for joint channel allocation and power control in cognitive radio networks[J].Journal of Computational Information Systems, 2012, 8 (17) :7071-7078.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A distributed Q learning spectrum decision scheme for cognitive radio sensor network">

                                <b>[10]</b> HE Jian, PENG Jun, JIANG Fu, et al.A distributed Q learning spectrum decision scheme for cognitive radio sensor network[J].International Journal of Distributed Sensor Networks, 2015 (1) :1-10.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KJGC201201018&amp;v=MjUwOTJybzlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnlubFZML05MaWZNYmJHNEg5UE0=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 胡图, 景志宏, 张磊, 等.认知Ad hoc网络中基于凸优化的功率控制算法[J].空军工程大学学报, 2012, 13 (1) :79-84.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Energy-efficiency opportunistic spectrum allocation in cognitive wireless sensor network">

                                <b>[12]</b> WU Cheng, WANG Yiming, YIN Zhijie.Energy-efficiency opportunistic spectrum allocation in cognitive wireless sensor network[J].Eurasip Journal on Wireless Communications and Networking, 2018 (1) :13-24.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JDGC201204028&amp;v=MzA2NjNNYmJHNEg5UE1xNDlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnlubFZML05MeW4=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 梁泉.未知环境中基于强化学习的移动机器人路径规划[J].2012, 29 (4) :477-481.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DXKX201508014&amp;v=MDgzNjR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnlubFZML05JVFhBZHJHNEg5VE1wNDlFWUlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 冯陈伟, 袁江南.基于强化学习的异构无线网络资源管理算法[J].电信科学, 2015, 31 (8) :99-106.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200311006&amp;v=MDIwMTlHRnJDVVJMT2VaZVJvRnlubFZML05OeWZUYkxHNEh0TE5ybzlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 苏小红, 杨博, 王亚东.基于进化稳定策略的遗传算法[J].软件学报, 2003, 14 (11) :1863-1868.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 梶田秀司.类机器人[M].管贻生, 译.北京:清华大学出版社, 2007.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201906025" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201906025&amp;v=MTkyNTVsVkwvTkx6N0JiYkc0SDlqTXFZOUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeW4=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
