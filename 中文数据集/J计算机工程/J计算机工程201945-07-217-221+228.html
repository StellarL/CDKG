<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637129940466837500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201907035%26RESULT%3d1%26SIGN%3dKVXczviysqpMzagm0eQ4MCOgdDA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201907035&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201907035&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201907035&amp;v=MjA4OTQ5R1lZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScEZDamhWcjdMTHo3QmJiRzRIOWpNcUk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#50" data-title="2 MFCA算法 ">2 MFCA算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="2.1 问题描述">2.1 问题描述</a></li>
                                                <li><a href="#55" data-title="2.2 MFCA算法实现">2.2 MFCA算法实现</a></li>
                                                <li><a href="#64" data-title="2.3 MFCA算法优化">2.3 MFCA算法优化</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#99" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#101" data-title="3.1 实验设置">3.1 实验设置</a></li>
                                                <li><a href="#104" data-title="3.2 内存使用率分析">3.2 内存使用率分析</a></li>
                                                <li><a href="#109" data-title="3.3 性能分析">3.3 性能分析</a></li>
                                                <li><a href="#113" data-title="3.4 算法复杂度分析">3.4 算法复杂度分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#120" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="&lt;b&gt;图1 3种卷积过程&lt;/b&gt;"><b>图1 3种卷积过程</b></a></li>
                                                <li><a href="#58" data-title="&lt;b&gt;图2 MFCA算法卷积过程&lt;/b&gt;"><b>图2 MFCA算法卷积过程</b></a></li>
                                                <li><a href="#61" data-title="&lt;b&gt;表1 各矩阵信息对比&lt;/b&gt;"><b>表1 各矩阵信息对比</b></a></li>
                                                <li><a href="#66" data-title="&lt;b&gt;图3 分块卷积过程&lt;/b&gt;"><b>图3 分块卷积过程</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;表2 &lt;i&gt;O&lt;/i&gt;&lt;/b&gt;&lt;sub&gt;&lt;b&gt;&lt;i&gt;W&lt;/i&gt;&lt;/b&gt;&lt;/sub&gt;&lt;b&gt;能被&lt;i&gt;m&lt;/i&gt;整除时的矩阵信息&lt;/b&gt;"><b>表2 <i>O</i></b><sub><b><i>W</i></b></sub><b>能被<i>m</i>整除时的矩阵信息</b></a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;表3 测试集信息&lt;/b&gt;"><b>表3 测试集信息</b></a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;表4 3种卷积算法的内存开销对比&lt;/b&gt;"><b>表4 3种卷积算法的内存开销对比</b></a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;图4 3种卷积算法的内存开销柱状图比较&lt;/b&gt;"><b>图4 3种卷积算法的内存开销柱状图比较</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;图5 不同卷积算法的运行时间对比&lt;/b&gt;"><b>图5 不同卷积算法的运行时间对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="140">


                                    <a id="bibliography_1" title=" DALAL N, TRIGGS B.Histograms of oriented gradients for human detection[C]//Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2005:886-893." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Histograms of oriented gradients for human detection">
                                        <b>[1]</b>
                                         DALAL N, TRIGGS B.Histograms of oriented gradients for human detection[C]//Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2005:886-893.
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_2" title=" ZHOU Huiyu, YUAN Yuan, SHI Chunmei.Object tracking using SIFT features and mean shift[J].Computer Vision and Image Understanding, 2009, 113 (3) :345-352." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083791&amp;v=MDk3MTBqbVVMakxJRm9SYXhFPU5pZk9mYks3SHRETnFvOUVaT01NQzNVNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         ZHOU Huiyu, YUAN Yuan, SHI Chunmei.Object tracking using SIFT features and mean shift[J].Computer Vision and Image Understanding, 2009, 113 (3) :345-352.
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_3" title=" SHARIF R A, AZIZPOUR H, SULLIVAN J, et al.CNN features off-the-shelf:an astounding baseline for recognition[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition Workshops.Washington D.C., USA:IEEE Press, 2014:156-163." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cnn Features off-the-shelf:An Astounding Baseline for Recognition">
                                        <b>[3]</b>
                                         SHARIF R A, AZIZPOUR H, SULLIVAN J, et al.CNN features off-the-shelf:an astounding baseline for recognition[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition Workshops.Washington D.C., USA:IEEE Press, 2014:156-163.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_4" title=" 王晓晖, 盛斌, 申瑞民.基于深度学习的深度图超分辨率采样[J].计算机工程, 2017, 43 (11) :252-260." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201711042&amp;v=MTMxNzE0TzN6cXFCdEdGckNVUkxPZVplUnBGQ2poVnI3TEx6N0JiYkc0SDliTnJvOUJab1FLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         王晓晖, 盛斌, 申瑞民.基于深度学习的深度图超分辨率采样[J].计算机工程, 2017, 43 (11) :252-260.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_5" title=" 李传朋, 秦品乐, 张晋京.基于深度卷积神经网络的图像去噪研究[J].计算机工程, 2017, 43 (3) :253-260." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201703042&amp;v=MTUyMjRSTE9lWmVScEZDamhWcjdMTHo3QmJiRzRIOWJNckk5QlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         李传朋, 秦品乐, 张晋京.基于深度卷积神经网络的图像去噪研究[J].计算机工程, 2017, 43 (3) :253-260.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_6" title=" 周飞燕, 金林鹏, 董军.卷积神经网络研究综述[J].计算机学报, 2017, 40 (6) :1229-1251." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201706001&amp;v=MjUwNDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScEZDamhWcjdMTHo3QmRyRzRIOWJNcVk5RlpZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         周飞燕, 金林鹏, 董军.卷积神经网络研究综述[J].计算机学报, 2017, 40 (6) :1229-1251.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_7" title=" YANG Fan, CHOI W, LIN Yuanqing.Exploit all the layers:fast and accurate CNN object detector with scale dependent pooling and cascaded rejection classifiers[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2016:236-243." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploit All the Layers:Fast and Accurate CNN Object Detector With Scale Dependent Pooling and Cascaded Rejection Classifiers">
                                        <b>[7]</b>
                                         YANG Fan, CHOI W, LIN Yuanqing.Exploit all the layers:fast and accurate CNN object detector with scale dependent pooling and cascaded rejection classifiers[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2016:236-243.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_8" title=" WANG Xiaolong, SHRIVASTAVA A, GUPTA A.A-fast-RCNN:hard positive generation via adversary for object detection[EB/OL].[2018-04-29].https://arxiv.org/pdf/1704.03414.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A-fast-RCNN:hard positive generation via adversary for object detection">
                                        <b>[8]</b>
                                         WANG Xiaolong, SHRIVASTAVA A, GUPTA A.A-fast-RCNN:hard positive generation via adversary for object detection[EB/OL].[2018-04-29].https://arxiv.org/pdf/1704.03414.pdf.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_9" title=" JIA Yangqing, SHELHAMER E, DONAHUE J, et al.Caffe:convolutional architecture for fast feature embedding[C]//Proceedings of the 22nd ACM International Conference on Multimedia.New York, USA:ACM Press, 2014:269-280." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CAFFE:Convolutional Architecture for Fast Feature Embedding">
                                        <b>[9]</b>
                                         JIA Yangqing, SHELHAMER E, DONAHUE J, et al.Caffe:convolutional architecture for fast feature embedding[C]//Proceedings of the 22nd ACM International Conference on Multimedia.New York, USA:ACM Press, 2014:269-280.
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_10" title=" CHO M, BRAND D.MEC:memory-efficient convolu-tion for deep neural network[EB/OL].[2018-04-25].https://arxiv.org/pdf/1706.06873.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=MEC:memory-efficient convolu-tion for deep neural network">
                                        <b>[10]</b>
                                         CHO M, BRAND D.MEC:memory-efficient convolu-tion for deep neural network[EB/OL].[2018-04-25].https://arxiv.org/pdf/1706.06873.pdf.
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_11" title=" BERGSTRA J, BASTIEN F, BREULEUX O, et al.Theano:deep learning on GPUs with Python[EB/OL].[2018-04-25].http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.678.1889&amp;amp;rep=rep1&amp;amp;type=pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Theano:deep learning on GPUs with Python">
                                        <b>[11]</b>
                                         BERGSTRA J, BASTIEN F, BREULEUX O, et al.Theano:deep learning on GPUs with Python[EB/OL].[2018-04-25].http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.678.1889&amp;amp;rep=rep1&amp;amp;type=pdf.
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_12" title=" CHETLUR S, WOOLLEY C, VANDERMERSCH P, et al.cuDNN:efficient primitives for deep learning[EB/OL].[2018-04-25].https://arxiv.org/pdf/1410.0759.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=cuDNN:efficient primitives for deep learning">
                                        <b>[12]</b>
                                         CHETLUR S, WOOLLEY C, VANDERMERSCH P, et al.cuDNN:efficient primitives for deep learning[EB/OL].[2018-04-25].https://arxiv.org/pdf/1410.0759.pdf.
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_13" title=" JIA Yangqing.Learning semantic image representations at a large scale[EB/OL].[2018-04-26].https://cloudfront.escholarship.org/dist/prd/content/qt64c2v6sn/qt64c2v6sn.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning semantic image representations at a large scale">
                                        <b>[13]</b>
                                         JIA Yangqing.Learning semantic image representations at a large scale[EB/OL].[2018-04-26].https://cloudfront.escholarship.org/dist/prd/content/qt64c2v6sn/qt64c2v6sn.pdf.
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_14" title=" ZEE F G V.BLIS:a framework for rapidly instantiating BLAS functionality[J].ACM Transactions on Mathematical Software, 2013, 41 (3) :1-33." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCME3082E305B81CE4EBE1F724A1883AB7C&amp;v=MDA3NDJhN0h0bk8yb3hGWVprSERROU15Mk5obno0TFQzM20zUk05Y2JIbE43M3NDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOOWl4THk2d2FzPU5pZklZOA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         ZEE F G V.BLIS:a framework for rapidly instantiating BLAS functionality[J].ACM Transactions on Mathematical Software, 2013, 41 (3) :1-33.
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_15" title=" CIREŞAN D C, MEIER U, MASCI J, et al.High-performance neural networks for visual object classification[EB/OL].[2018-04-26].https://arxiv.org/pdf/1102.0183.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-performance neural networks for visual object classification">
                                        <b>[15]</b>
                                         CIREŞAN D C, MEIER U, MASCI J, et al.High-performance neural networks for visual object classification[EB/OL].[2018-04-26].https://arxiv.org/pdf/1102.0183.pdf.
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_16" title=" SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[EB/OL].[2018-04-28].https://arxiv.org/pdf/1409.1556.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">
                                        <b>[16]</b>
                                         SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[EB/OL].[2018-04-28].https://arxiv.org/pdf/1409.1556.pdf.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_17" title=" WINOGRAD S.Arithmetic complexity of computations[M].[S.l.]:Society for Industrial and Applied Mathematics, 1980." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Arithmetic complexity of computations">
                                        <b>[17]</b>
                                         WINOGRAD S.Arithmetic complexity of computations[M].[S.l.]:Society for Industrial and Applied Mathematics, 1980.
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_18" title=" VASILACHE N, ZINENKO O, THEODORIDIS T, et al.Tensor comprehensions:framework-agnostic high-performance machine learning abstractions[EB/OL].[2018-04-25].https://arxiv.org/pdf/1802.04730.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor comprehensions:framework-agnostic high-performance machine learning abstractions">
                                        <b>[18]</b>
                                         VASILACHE N, ZINENKO O, THEODORIDIS T, et al.Tensor comprehensions:framework-agnostic high-performance machine learning abstractions[EB/OL].[2018-04-25].https://arxiv.org/pdf/1802.04730.pdf.
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_19" title=" NVIDIA C.CUBLAS library[EB/OL].[2018-04-28].https://arcb.csc.ncsu.edu/～mueller/cluster/nvidia/0.8/NVIDIA_CUBLAS_Library_0.8.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CUBLAS library">
                                        <b>[19]</b>
                                         NVIDIA C.CUBLAS library[EB/OL].[2018-04-28].https://arcb.csc.ncsu.edu/～mueller/cluster/nvidia/0.8/NVIDIA_CUBLAS_Library_0.8.pdf.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(07),217-221+228 DOI:10.19678/j.issn.1000-3428.0051507            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于矩阵转换的卷积计算优化方法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%96%B9%E7%8E%89%E7%8E%B2&amp;code=33811973&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">方玉玲</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E5%BA%86%E5%A5%8E&amp;code=09616877&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈庆奎</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E7%AE%A1%E7%90%86%E5%AD%A6%E9%99%A2&amp;code=0256814&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海理工大学管理学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E5%85%89%E7%94%B5%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海理工大学光电信息与计算机工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>提出一种基于矩阵转换的高效卷积计算优化方法MCFA。根据输出矩阵的宽度和卷积核大小对输入矩阵进行分块, 通过im2col方法转换输入矩阵子块和核函数矩阵, 利用计算统一设备架构中封装的矩阵-矩阵乘法加速库提升卷积计算的速度。在此基础上, 将输出子块按序排列, 最终得到完整的输出矩阵。实验结果证明, 该方法相比im2col方法能节省61.25%的计算空间, 相比MEC方法能提高20.57%的计算速度, 且在分块情况下可以缓解大输入矩阵引起的缓存压力, 提高缓存利用率。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积计算;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B4%E6%8E%A5%E5%8D%B7%E7%A7%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">直接卷积;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%A9%E9%98%B5%E5%88%86%E5%9D%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">矩阵分块;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AE%A1%E7%AE%97%E7%BB%9F%E4%B8%80%E8%AE%BE%E5%A4%87%E6%9E%B6%E6%9E%84&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算统一设备架构;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积优化;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    方玉玲 (1990—) , 女, 博士研究生, 主研方向为计算机视觉、并行计算、GPU集群可靠性分析, E-mail: forwardfyl@ 163. com;;
                                </span>
                                <span>
                                    陈庆奎, 教授、博士、博士生导师。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-05-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61572325, 60970012);</span>
                                <span>高等学校博士学科点专项科研博导基金 (20113120110008);</span>
                                <span>上海重点科技攻关项目 (14511107902, 16DZ1203603);</span>
                                <span>上海市工程中心建设项目 (GCZX14014);</span>
                                <span>上海智能家居大规模物联共性技术工程中心项目 (GCZX14014);</span>
                                <span>上海市一流学科建设项目 (XTKX2012);</span>
                                <span>沪江基金研究基地专项 (C14001);</span>
                    </p>
            </div>
                    <h1><b>Convolution Calculation Optimization Method Based on Matrix Transformation</b></h1>
                    <h2>
                    <span>FANG Yuling</span>
                    <span>CHEN Qingkui</span>
            </h2>
                    <h2>
                    <span>Business School, University of Shanghai for Science and Technology</span>
                    <span>School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>An efficient convolution calculation optimization method MCFA based on matrix transformation is proposed.The input matrix is divided into blocks according to the width and the convolution core size of the output matrix.The input matrix sub-blocks and the core function matrix are transformed by im2 col method.The matrix-matrix multiplication library encapsulated in the Computing Unified Device Architecture (CUDA) is used to speed up the convolution calculation.On this basis, the output sub-blocks are arranged in order, and the complete output matrix is finally obtained.Experimental results show that this method can save 61.25% of the computing space compared with im2 col method, improve 20.57% of the computing speed compared with MEC method, and relieve the cathe pressure caused by large input matrix in the case of block, thus improve the cache utilization.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolution%20calculation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolution calculation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=direct%20convolution&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">direct convolution;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=matrix%20blocking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">matrix blocking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Computing%20Unified%20Device%20Architecture%20(CUDA)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Computing Unified Device Architecture (CUDA) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolution%20optimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolution optimization;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-05-09</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="42">在计算机视觉、模式识别以及人工智能领域, 深度学习得到广泛应用, 其效果与性能优于传统方法, 如HOG (Histogram of Oriented Gradients) <citation id="178" type="reference"><link href="140" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、SIFT (Scale-Invariant Feature Transform) <citation id="179" type="reference"><link href="142" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>等。在深度学习算法与模型中, 卷积神经网络 (Convolutional Neural Network, CNN) <citation id="181" type="reference"><link href="144" rel="bibliography" /><link href="146" rel="bibliography" /><link href="148" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>是重要的组成部分。CNN无需对图像进行复杂的前期预处理而直接输入原始图像, 且在如下3个方面具有明显优势:局部感受野, 有助于神经元从原始图像中提取基本信息, 包括边缘和角点信息;权值共享, 局部感受野通过权值共享减少了神经网络需要训练的参数数目, 在不影响精度的情况下能够简化计算过程;空间或时间子采样, 通过子采样可以降低特征映射的分辨率, 并输出对移位和失真的敏感度<citation id="180" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。与传统方法相比, CNN在实际应用中面临的主要挑战是需要花费较多的检测时间, 其中, 卷积计算占据很大比例。因此, 对CNN中的卷积计算过程进行优化具有现实意义。</p>
                </div>
                <div class="p1">
                    <p id="43">目前, 学者们主要从内存使用效率与处理速度2个方面对CNN进行优化, 提出快速CNN<citation id="182" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、RCNN<citation id="183" type="reference"><link href="154" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等方法。这些方法在很大程度上提高了前馈过程的速度, 但是并未解决内存受限的问题。随着深度学习应用范围的扩大, 设备的内存受限问题越来越突出, 提升卷积中的内存占用效率对于深度学习在各种设备和平台上的应用至关重要。文献<citation id="184" type="reference">[<a class="sup">9</a>]</citation>提出将输入矩阵转换为列向量组合 (im2col) 的方法, 该方法虽然产生了中间矩阵转换开销, 但是转换后的矩阵与核函数卷积可以利用相关加速库 (如cuBLAS、OpenBLAS中封装的矩阵-向量乘) 进行加速。在此基础上, 文献<citation id="185" type="reference">[<a class="sup">10</a>]</citation>提出一种内存高效的卷积优化算法MEC, 该算法根据输出矩阵的行、列对输入矩阵分段读取并将其转换到一个中间矩阵中, 然后每次取转换矩阵的一段与核函数转换向量进行卷积。虽然MEC算法降低了额外的内存开销, 但是分段卷积控制逻辑复杂, 且分段矩阵地址不对齐, 不利于使用GPU进行并行控制。</p>
                </div>
                <div class="p1">
                    <p id="44">针对上述问题, 本文提出一种基于计算统一设备架构 (Computing Unified Device Architecture, CUDA) 加速库的卷积计算优化算法MFCA。根据输出矩阵的大小对输入矩阵进行分块, 采用im2col方法转换各子块和相应的核函数矩阵, 利用cuBLAS中矩阵-矩阵乘法加速库对卷积运算实现加速, 在此基础上, 对输出结果按序存储以得到输出矩阵。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag">1 相关工作</h3>
                <div class="p1">
                    <p id="46">目前主流的CNN及相关计算架构有Caffe<citation id="186" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、Theano<citation id="187" type="reference"><link href="160" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、cuDNN<citation id="188" type="reference"><link href="162" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>等。他们使用的卷积计算加速算法可以分为以下3种:</p>
                </div>
                <div class="p1">
                    <p id="47">1) im2col+GEMM:将输入的原始图像 (image) 信息转换为多个小的列向量 (column) 并重组为中间转换矩阵, 然后利用高度优化并封装好的BLAS<citation id="189" type="reference"><link href="164" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>中的矩阵乘法进行加速。这类方法的典型代表有OpenBLAS<citation id="190" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和文档处理<citation id="191" type="reference"><link href="168" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>中的应用。</p>
                </div>
                <div class="p1">
                    <p id="48">2) FFT (Fast Fourier Transform) :基于FFT的卷积变换主要用于时域和频域之间的转换<citation id="192" type="reference"><link href="170" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 在频域中卷积可以作为乘法进行计算, 但这种计算会因为必须将卷积核填充到与输入图像相同大小而增加内存开销。因此, FFT不适用于卷积核较小的情况。</p>
                </div>
                <div class="p1">
                    <p id="49">3) Winograd:基于Winograd的卷积来源于Coppersmith-Winograd算法<citation id="193" type="reference"><link href="172" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。该方法以增加中间计算开销为代价来减少乘法计算量, 目前, 其通常与FFT相结合被应用于NNPACK库中<citation id="194" type="reference"><link href="174" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。</p>
                </div>
                <h3 id="50" name="50" class="anchor-tag">2 MFCA算法</h3>
                <h4 class="anchor-tag" id="51" name="51">2.1 问题描述</h4>
                <div class="p1">
                    <p id="52">现有典型内存优化的卷积方法包括直接卷积、im2col卷积和MEC卷积, 三者的卷积过程如图1所示。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201907035_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 3种卷积过程" src="Detail/GetImg?filename=images/JSJC201907035_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 3种卷积过程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201907035_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="54">从图1可以看出, 在相同输入矩阵<b><i>I</i></b> (<i>i</i><sub><i>h</i></sub>×<i>i</i><sub><i>w</i></sub>×<i>i</i><sub><i>c</i></sub>=7×7×1) 、卷积核<b><i>K</i></b> (<i>k</i><sub><i>h</i></sub>×<i>k</i><sub><i>w</i></sub>×<i>k</i><sub><i>c</i></sub>=3×3×1) 、步长<i>s</i><sub><i>h</i></sub>=<i>s</i><sub><i>w</i></sub>=1且pad为0时, 3种卷积方法的输出矩阵均为<b><i>O</i></b> (<i>o</i><sub><i>h</i></sub>×<i>o</i><sub><i>w</i></sub>×<i>o</i><sub><i>c</i></sub>=5×5×1) 。其中, 直接卷积根据卷积的定义进行计算, 如图1 (a) 中灰色部分与卷积核的内积即为输出矩阵的一个元素, 随后按步长滑动卷积窗口直至得到整个输出。im2col卷积方法对输入矩阵和核函数进行转换, 得到中间矩阵和核函数的列向量并对两者进行相乘, 最终得到相同的输出矩阵。该卷积方法虽然因为中间转换矩阵增加了内存开销, 但是其可以利用矩阵向量乘库对卷积进行加速, 最终提升计算性能。MEC方法在im2col方法的基础上, 按输出矩阵大小分段读取输入矩阵并得到对应的中间矩阵, 该方法对计算性能的改进与im2col相同。MEC方法虽然也引入了中间矩阵, 但是其比im2col节省了51.2%的内存空间。但是, MEC方法也存在不足, 即在矩阵转换时矩阵分块逻辑复杂, 且得到的小矩阵地址空间不对齐。</p>
                </div>
                <h4 class="anchor-tag" id="55" name="55">2.2 MFCA算法实现</h4>
                <div class="p1">
                    <p id="56">为进一步提升卷积的计算性能, 本文基于im2col方法, 提出一种节省内存空间并能够利用cuBLAS<citation id="195" type="reference"><link href="176" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>中矩阵-矩阵乘法加速库的MFCA算法。该算法对输入矩阵按行读取并转换为中间矩阵的一行, 即复制滑动窗口<mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">W</mi><mrow><mo> (</mo><mrow><mi>i</mi><msub><mrow></mrow><mi>h</mi></msub><mo>×</mo><mi>i</mi><msub><mrow></mrow><mi>w</mi></msub><mo>=</mo><mn>3</mn><mo>×</mo><mn>7</mn></mrow><mo>) </mo></mrow></mrow></math></mathml>所覆盖的部分作为中间矩阵<b><i>L</i></b>的一行, 滑动窗口步长设为1。MFCA算法具体卷积过程如图2所示。</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201907035_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 MFCA算法卷积过程" src="Detail/GetImg?filename=images/JSJC201907035_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 MFCA算法卷积过程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201907035_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="59">在图2中, <b><i>A</i></b>是输入矩阵<b><i>I</i></b>的第1部分, <b><i>A</i></b>=<b><i>I</i></b>[1:3, 1:7]。将步长<i>s</i><sub><i>h</i></sub>=1的滑动窗口<b><i>W</i></b>所覆盖范围作为第2部分, <b><i>B</i></b>=<b><i>I</i></b>[2:4, 1:7]。继续滑动子窗口<b><i>W</i></b>直至覆盖到输入矩阵<b><i>I</i></b>的最后一行<b><i>E</i></b>=<b><i>I</i></b>[5:7, 1:7]。得到的5个子块分别对应中间矩阵<b><i>L</i></b>的5行<b><i>A</i>、<i>B</i>、<i>C</i>、<i>D</i>、<i>E</i></b>。核函数矩阵<b><i>K</i></b>中的元素分别与原始卷积中的位置相对应, 得到中间矩阵<b><i>K</i></b>′。其中, <b><i>K</i></b>′中非零元素为<i>K</i><sub><i>W</i></sub>×<i>K</i><sub><i>H</i></sub>×<i>O</i><sub><i>W</i></sub>个, 其余均是为利用加速库而填充的0值。最终, 通过调用BLAS3级库中矩阵-矩阵乘接口实现<b><i>O</i></b>=<b><i>K</i></b>′×<b><i>L</i></b>的输出。与MEC方法相比, MFCA的中间转换矩阵较大, 但控制逻辑简单, 易于GPU并行实现, 且具有更好的计算性能。</p>
                </div>
                <div class="p1">
                    <p id="60">在实际应用中, 若输入矩阵为<b><i>I</i></b> (<i>I</i><sub><i>H</i></sub>×<i>I</i><sub><i>W</i></sub>×<i>I</i><sub><i>C</i></sub>) , 卷积核为<b><i>K</i></b> (<i>K</i><sub><i>H</i></sub>×<i>K</i><sub><i>W</i></sub>×<i>K</i><sub><i>C</i></sub>) , 输入矩阵的中间矩阵为<b><i>L</i></b> (<i>L</i><sub><i>H</i></sub>×<i>L</i><sub><i>W</i></sub>×<i>L</i><sub><i>C</i></sub>) , 输出矩阵为<b><i>O</i></b> (<i>O</i><sub><i>H</i></sub>×<i>O</i><sub><i>W</i></sub>×<i>O</i><sub><i>C</i></sub>) 。在使用MFCA算法后, 他们存在如表1所示的关系 (在计算过程中不考虑图像通道个数和卷积核个数) 。</p>
                </div>
                <div class="area_img" id="61">
                    <p class="img_tit"><b>表1 各矩阵信息对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="61" border="1"><tr><td>矩阵</td><td>行</td><td>列</td><td>大小</td></tr><tr><td><br />中间矩阵<b><i>L</i></b></td><td><i>O</i><sub><i>H</i></sub></td><td><i>I</i><sub><i>W</i></sub>×<i>K</i><sub><i>H</i></sub></td><td><i>O</i><sub><i>H</i></sub>×<i>I</i><sub><i>W</i></sub>×<i>K</i><sub><i>H</i></sub></td></tr><tr><td><br />核函数矩阵<b><i>K</i></b>′</td><td><i>I</i><sub><i>W</i></sub>×<i>K</i><sub><i>H</i></sub></td><td><i>O</i><sub><i>W</i></sub></td><td><i>I</i><sub><i>W</i></sub>×<i>K</i><sub><i>H</i></sub>×<i>O</i><sub><i>W</i></sub></td></tr><tr><td><br />输出矩阵<b><i>O</i></b></td><td><i>O</i><sub><i>H</i></sub></td><td><i>O</i><sub><i>W</i></sub></td><td><i>O</i><sub><i>H</i></sub>×<i>O</i><sub><i>W</i></sub></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="62">在表1中, 核函数矩阵<b><i>K</i></b>′的行 (高度) 由中间矩阵<b><i>L</i></b>的列 (宽度) <i>I</i><sub><i>W</i></sub>×<i>K</i><sub><i>H</i></sub>决定, 但在实际计算中, <b><i>K</i></b>′只有<i>K</i><sub><i>H</i></sub>×<i>K</i><sub><i>W</i></sub>×<i>O</i><sub><i>W</i></sub>个非0值, 其他的<mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mo>) </mo></mrow><mo>×</mo><mrow><mi>Κ</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>×</mo></mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow></math></mathml>个均为0。非0值所占比例越小, 计算所需的内存开销越大。因此, 为减少<b><i>K</i></b>′中值为0的元素个数, 本文对MFCA算法进行改进。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64">2.3 MFCA算法优化</h4>
                <div class="p1">
                    <p id="65">将原始输入矩阵<b><i>I</i></b>按列分为<i>m</i>块, 分别进行中间矩阵转换, 然后与核函数矩阵做卷积, 最终得到<i>m</i>个输出分量, 并按序组成输出矩阵。以图3为例, 输入矩阵大小为8×8, 在计算过程中将输入矩阵平均分为2块, 即<i>m</i>=2, 则2个分块按序存放得到对应的输出矩阵。</p>
                </div>
                <div class="area_img" id="66">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201907035_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 分块卷积过程" src="Detail/GetImg?filename=images/JSJC201907035_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 分块卷积过程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201907035_066.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="67">在图3中, 根据输出矩阵的大小决定分块矩阵是否需要进行填充。若<i>I</i><sub><i>W</i></sub>/<i>m</i>&lt;<i>O</i><sub><i>W</i></sub>/<i>m</i>+<i>K</i><sub><i>W</i></sub>-1, 则需要对子矩阵<b><i>A</i></b>和<b><i>B</i></b>进行填充, 填充元素个数为<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>n</mi><mo>=</mo><mrow><mo> (</mo><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub><mo>/</mo><mi>m</mi><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mi>W</mi></msub><mo>/</mo><mi>m</mi></mrow></math></mathml>, 填充元素来自与该块相邻的上/下一个块的按列存储的前<i>n</i>个元素, 例如图3中子矩阵<b><i>A</i></b>中的右侧阴影部分和子矩阵<b><i>B</i></b>中的左侧阴影部分, 则转换矩阵为<b><i>A</i></b>′中的右侧虚线框部分和<b><i>B</i></b>′中的左侧虚线框部分。2个子矩阵分别与核函数矩阵进行卷积, 得到最终的输出矩阵<b><i>O</i></b>。</p>
                </div>
                <div class="p1">
                    <p id="69">已知输出矩阵宽度为<i>O</i><sub><i>W</i></sub>, 每块的输出宽度为<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac></mrow></math></mathml> (假设<i>O</i><sub><i>W</i></sub>能被<i>m</i>整除) , 则分割后的每块输入矩阵宽度为<mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow></math></mathml>, 对应的中间矩阵的宽度 (列) 为<mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mi>Η</mi></msub></mrow></math></mathml>。各矩阵具体信息如表2所示。</p>
                </div>
                <div class="area_img" id="73">
                    <p class="img_tit"><b>表2 <i>O</i></b><sub><b><i>W</i></b></sub><b>能被<i>m</i>整除时的矩阵信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="73" border="1"><tr><td><br />矩阵</td><td>行</td><td>列</td></tr><tr><td><br />中间矩阵<b><i>L</i></b></td><td><i>O</i><sub><i>H</i></sub></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mi>Η</mi></msub></mrow></math></td></tr><tr><td><br />核函数矩阵<b><i>K</i></b>′</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mi>Η</mi></msub></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac></mrow></math></td></tr><tr><td><br />输出矩阵<b><i>O</i></b></td><td><i>O</i><sub><i>H</i></sub></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac></mrow></math></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="74">表2显示了被分割后的一块输入矩阵所对应的中间矩阵、核函数矩阵及输出矩阵的行列信息, 则中间矩阵<b><i>L</i></b>的总内存开销为:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msub><mrow></mrow><mi mathvariant="bold-italic">L</mi></msub><mo>=</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>×</mo><mi>Ο</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>×</mo><mi>m</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">核函数矩阵的内存开销为:</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msub><mrow></mrow><mi mathvariant="bold-italic">Κ</mi></msub><mo>=</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>×</mo><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">其中, <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mi>Η</mi></msub></mrow></math></mathml>为核函数矩阵的行 (高度) , 同时也是分块矩阵的列 (宽度) 。此时, 转换矩阵的总内存开销为:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Μ</mi><mo>=</mo><mi>Μ</mi><msub><mrow></mrow><mi mathvariant="bold-italic">L</mi></msub><mo>+</mo><mi>Μ</mi><msub><mrow></mrow><mi mathvariant="bold-italic">Κ</mi></msub><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>×</mo><mrow><mo> (</mo><mrow><mi>m</mi><mo>×</mo><mi>Ο</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>+</mo><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">上述转换需要满足3个条件:</p>
                </div>
                <div class="p1">
                    <p id="82">1) 当M最小时确定分块个数m。</p>
                </div>
                <div class="p1">
                    <p id="83">2) M<sub><i>min</i></sub>&lt;M<sub><i>im</i>2<i>col</i></sub>=O<sub>W</sub>×O<sub>H</sub>×K<sub>W</sub>×K<sub>H</sub>+K<sub>W</sub>×K<sub>H</sub>。</p>
                </div>
                <div class="p1">
                    <p id="84"><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>3</mn><mo stretchy="false">) </mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>≤</mo><mfrac><mrow><mi>Ι</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac></mrow></math></mathml>且1≤<i>m</i>。</p>
                </div>
                <div class="p1">
                    <p id="86">结合上述条件可得:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mtext>Μ</mtext><mtext>F</mtext><mtext>C</mtext><mtext>A</mtext></mrow></msub><mo>=</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mi>m</mi></mfrac><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>×</mo><mrow><mo> (</mo><mrow><mi>Ο</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>×</mo><mi>m</mi><mo>+</mo><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">将式 (4) 对<i>m</i>求导可得:</p>
                </div>
                <div class="p1">
                    <p id="89" class="code-formula">
                        <mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>Μ</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mtext>Μ</mtext><mtext>F</mtext><mtext>C</mtext><mtext>A</mtext></mrow></msub><mo>=</mo><mrow><mo> (</mo><mrow><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>×</mo><mi>Ο</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>-</mo><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow><mrow><mi>m</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>×</mo><mi>Κ</mi><msub><mrow></mrow><mi>Η</mi></msub><mo>×</mo><mi>Ο</mi><msub><mrow></mrow><mi>W</mi></msub></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="90">则有:</p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>m</mi><mo>=</mo><msqrt><mrow><mfrac><mrow><mi>Ο</mi><msubsup><mrow></mrow><mi>W</mi><mn>2</mn></msubsup></mrow><mrow><mrow><mo> (</mo><mrow><mi>Κ</mi><msub><mrow></mrow><mi>W</mi></msub><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>×</mo><mi>Ο</mi><msub><mrow></mrow><mi>Η</mi></msub></mrow></mfrac></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92">得到的<i>m</i>值分为2种情况:</p>
                </div>
                <div class="p1">
                    <p id="93">1) 当<i>m</i>为整数时, 输入矩阵的第<i>m</i>个子块矩阵无需进行0值填充。</p>
                </div>
                <div class="p1">
                    <p id="94">2) 当<i>m</i>不是整数时, 则有2个可能值:⎣<i>m</i>」, 「<i>m</i>⎤, 比较他们对应的总内存大小, 选择内存开销较小的<i>m</i>值, 并对第<i>m</i>个子块进行0值填充。</p>
                </div>
                <div class="p1">
                    <p id="95">将得到的<i>m</i>值带入式 (4) , 得到最小的总内存开销<i>M</i><sub>MFCA<sub>min</sub></sub>, 并与im2col和MEC的内存开销进行比较。其中, im2col和MEC的总内存开销可分别由式 (6) 、式 (7) 计算:</p>
                </div>
                <div class="p1">
                    <p id="96"><i>M</i><sub>im2col</sub>=<i>O</i><sub><i>W</i></sub>×<i>O</i><sub><i>H</i></sub>×<i>K</i><sub><i>W</i></sub>×<i>K</i><sub><i>H</i></sub>+<i>K</i><sub><i>W</i></sub>×<i>K</i><sub><i>H</i></sub>      (6) </p>
                </div>
                <div class="p1">
                    <p id="97"><i>M</i><sub>MEC</sub>=<i>O</i><sub><i>H</i></sub>×<i>I</i><sub><i>H</i></sub>×<i>K</i><sub><i>W</i></sub>+<i>K</i><sub><i>H</i></sub>×<i>K</i><sub><i>W</i></sub>      (7) </p>
                </div>
                <div class="p1">
                    <p id="98">比较式 (4) 、式 (6) 和式 (7) 可知, <i>M</i><sub>MCE</sub>&lt;<i>M</i><sub>im2col</sub>, <i>M</i><sub>MFCA<sub>min</sub></sub>&lt;<i>M</i><sub>im2col</sub>, 而<i>M</i><sub>MCE</sub>与<i>M</i><sub>MFCA<sub>min</sub></sub>间的大小关系与需要计算的输入矩阵大小、卷积核尺寸以及<i>m</i>值都有关, 具体比较结果见3.2节。</p>
                </div>
                <h3 id="99" name="99" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="100">本文基于CUDA架构对深度学习中的卷积计算进行优化, 并通过多组实验来比较分析各算法的性能。</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101">3.1 实验设置</h4>
                <div class="p1">
                    <p id="102">在CPU+GPU的实验平台上使用C++结合CUDA架构实现本文算法, CPU为Intel i7-4790 CPU@3.60 GHz, GPU为NVIDIA GTX 970。其中, 由NVIDIA提供的封装好的矩阵运算库cuBLAS对本文算法的卷积运算进行加速。为更全面地对算法进行验证与比较, 在该实验环境下执行im2col和MEC 2种方法, 实验的测试集信息如表3所示。</p>
                </div>
                <div class="area_img" id="103">
                    <p class="img_tit"><b>表3 测试集信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="103" border="1"><tr><td><br />实验</td><td>输入矩阵大小<i>I</i><sub><i>H</i></sub>×<i>I</i><sub><i>W</i></sub></td><td>核函数矩阵大小<i>K</i><sub><i>H</i></sub>×<i>K</i><sub><i>W</i></sub></td></tr><tr><td><br />CV1</td><td>227×227</td><td>11×11</td></tr><tr><td><br />CV2</td><td>227×227</td><td>7×7</td></tr><tr><td><br />CV3</td><td>24×24</td><td>3×3</td></tr><tr><td><br />CV4</td><td>112×112</td><td>3×3</td></tr><tr><td><br />CV5</td><td>56×56</td><td>3×3</td></tr><tr><td><br />CV6</td><td>514×514</td><td>3×3</td></tr><tr><td><br />CV7</td><td>720×480</td><td>5×5</td></tr><tr><td><br />CV8</td><td>1 920×1 080</td><td>5×5</td></tr><tr><td><br />CV9</td><td>7×7</td><td>3×3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="104" name="104">3.2 内存使用率分析</h4>
                <div class="p1">
                    <p id="105">3种算法的内存开销比较如表4所示。为简化分析, 对表4中的<i>M</i><sub>im2col</sub>、<i>M</i><sub>MEC</sub>和<i>M</i><sub>MFCA</sub>内存开销进行柱状图比较, 结果如图4所示。其中, 为方便对比, 以im2col算法的内存开销为基准。</p>
                </div>
                <div class="area_img" id="106">
                    <p class="img_tit"><b>表4 3种卷积算法的内存开销对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="106" border="1"><tr><td>实验</td><td><i>M</i><sub>im2col</sub></td><td><i>M</i><sub>MEC</sub></td><td><i>m</i>值</td><td><i>M</i><sub>MFCA</sub></td><td>最优<i>m</i>值</td></tr><tr><td>CV1</td><td>2 359 305</td><td>789 513</td><td>16.0</td><td>887 808</td><td>16</td></tr><tr><td><br />CV2</td><td>5 697 890</td><td>541 970</td><td>4.6</td><td>764 794</td><td>5</td></tr><tr><td><br />CV3</td><td>2 393 258</td><td>351 218</td><td>6.1</td><td>463 842</td><td>6</td></tr><tr><td><br />CV4</td><td>4 365</td><td>1 593</td><td>3.3</td><td>2 464</td><td>3</td></tr><tr><td><br />CV5</td><td>108 909</td><td>36 969</td><td>7.4</td><td>46 765</td><td>7</td></tr><tr><td><br />CV6</td><td>26 253</td><td>9 081</td><td>5.2</td><td>12 441</td><td>5</td></tr><tr><td><br />CV7</td><td>8 520 425</td><td>2 577 625</td><td>8.9</td><td>1 968 355</td><td>9</td></tr><tr><td><br />CV8</td><td>51 540 425</td><td>18 393 625</td><td>12.3</td><td>11 271 846</td><td>12</td></tr><tr><td><br />CV9</td><td>234</td><td>114</td><td>1.6</td><td>202</td><td>2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201907035_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 3种卷积算法的内存开销柱状图比较" src="Detail/GetImg?filename=images/JSJC201907035_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 3种卷积算法的内存开销柱状图比较</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201907035_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="108">从图4可以看出, 本文MFCA算法产生的中间转换矩阵的内存开销明显优于im2col算法, 平均内存使用率提升61.25%。尤其对于大输入矩阵, 如CV2, 效果提升更高, 达到86.57%。与MEC算法相比, 本文算法在大输入矩阵中优势明显, 如CV7和CV8, 在输入矩阵较小时不占优势。</p>
                </div>
                <h4 class="anchor-tag" id="109" name="109">3.3 性能分析</h4>
                <div class="p1">
                    <p id="110">为验证本文算法对卷积计算的性能改进效果, 对不同算法的执行时间进行统计, 结果如图5所示, 同样以im2col算法的运行时间为基准。</p>
                </div>
                <div class="area_img" id="111">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201907035_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同卷积算法的运行时间对比" src="Detail/GetImg?filename=images/JSJC201907035_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 不同卷积算法的运行时间对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201907035_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="112">从图5可以看出, 当输入矩阵较小时, MFCA与MEC对运行时间性能改进相差不大, 但是当输入矩阵较大时, 本文算法比MEC效果好, 情况最佳时其卷积计算速度为MEC的2倍, 如CV8。在图5的9组不同实验中, MFCA比MEC的卷积计算速度平均提高20.57%。</p>
                </div>
                <h4 class="anchor-tag" id="113" name="113">3.4 算法复杂度分析</h4>
                <div class="p1">
                    <p id="114">离散二维卷积计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="115" class="code-formula">
                        <mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">B</mi><mrow><mo> (</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow><mo>) </mo></mrow><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>0</mn></mrow></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow></munder><mi mathvariant="bold-italic">Κ</mi></mstyle></mrow></mstyle><mrow><mo> (</mo><mrow><mi>m</mi><mo>, </mo><mi>n</mi></mrow><mo>) </mo></mrow><mo>*</mo><mi mathvariant="bold-italic">A</mi><mrow><mo> (</mo><mrow><mi>i</mi><mo>-</mo><mi>m</mi><mo>, </mo><mi>j</mi><mo>-</mo><mi>n</mi></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="116">其中, <b><i>A</i></b>为输入矩阵, <b><i>K</i></b>为卷积核, <b><i>B</i></b>为卷积结果, 即输出矩阵。卷积计算时间复杂度计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><mi>i</mi><mi>m</mi><mi>e</mi><mo>∼</mo><mi>Ο</mi><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mn>2</mn></msup><mo>⋅</mo><mi mathvariant="bold-italic">Κ</mi><msup><mrow></mrow><mn>2</mn></msup><mo>⋅</mo><mi>C</mi><msub><mrow></mrow><mrow><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo>⋅</mo><mi>C</mi><msub><mrow></mrow><mrow><mtext>o</mtext><mtext>u</mtext><mtext>t</mtext></mrow></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">为简化说明, 此处统一假设输入矩阵和卷积核都是正方形, <i>C</i><sub>in</sub>为每个卷积核通道数, <i>C</i><sub>out</sub>为输出通道数。通过分析可知, 3种算法的上述参数完全相同, 因此, 3种算法具有相同的时间复杂度。算法所需的存储空间包括3个部分:算法本身占用的存储空间, 算法的输入输出数据所占用的存储空间, 算法运行时临时占用的存储空间。根据2.3节相关分析可知, <i>M</i><sub>im2col</sub>&gt;<i>M</i><sub>MEC</sub>, 而<i>M</i><sub>MEC</sub>与<i>M</i><sub>MFCA</sub>的关系与输入数据大小有关, 当输入矩阵较大时, 有<i>M</i><sub>MEC</sub>&gt;<i>M</i><sub>MFCA</sub>。且MFCA中分块输入矩阵地址空间连续能够提高缓存利用率, 同时能够充分利用矩阵乘法库来加速计算过程。因此, MFCA的空间复杂度较低, im2col的空间复杂度较高。</p>
                </div>
                <div class="p1">
                    <p id="119">综上, 本文卷积优化方法MFCA在im2col的基础上, 能够明显提升内存使用率, 同时采用分块矩阵的思想能有效降低大矩阵计算对有限的访存资源的压力, 提高数据局部性与缓存利用率。此外, MFCA方法的中间转换过程可以利用cuBLAS中的矩阵-矩阵乘法库, 进一步提升卷积计算性能, 尤其对大输入矩阵, 其优势更加明显。</p>
                </div>
                <h3 id="120" name="120" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="121">本文提出一种基于矩阵转换的卷积计算优化方法MFCA。对输入矩阵按列进行分块, 采用im2col方法对各子块和卷积核矩阵实现转换, 以节省内存空间, 然后利用矩阵运算库cuBLAS对矩阵和矩阵乘的卷积运算进行加速, 达到提高卷积计算性能的目的。实验结果验证了MFCA方法的有效性。将该方法推广到多通道多区域的卷积应用场景是下一步的研究方向。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="140">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Histograms of oriented gradients for human detection">

                                <b>[1]</b> DALAL N, TRIGGS B.Histograms of oriented gradients for human detection[C]//Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2005:886-893.
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083791&amp;v=MTM1NDlPTU1DM1U0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGpMSUZvUmF4RT1OaWZPZmJLN0h0RE5xbzlFWg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> ZHOU Huiyu, YUAN Yuan, SHI Chunmei.Object tracking using SIFT features and mean shift[J].Computer Vision and Image Understanding, 2009, 113 (3) :345-352.
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cnn Features off-the-shelf:An Astounding Baseline for Recognition">

                                <b>[3]</b> SHARIF R A, AZIZPOUR H, SULLIVAN J, et al.CNN features off-the-shelf:an astounding baseline for recognition[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition Workshops.Washington D.C., USA:IEEE Press, 2014:156-163.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201711042&amp;v=MTA3ODllUnBGQ2poVnI3TEx6N0JiYkc0SDliTnJvOUJab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 王晓晖, 盛斌, 申瑞民.基于深度学习的深度图超分辨率采样[J].计算机工程, 2017, 43 (11) :252-260.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201703042&amp;v=MDE5ODhIOWJNckk5QlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScEZDamhWcjdMTHo3QmJiRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 李传朋, 秦品乐, 张晋京.基于深度卷积神经网络的图像去噪研究[J].计算机工程, 2017, 43 (3) :253-260.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201706001&amp;v=MjI5MTZWcjdMTHo3QmRyRzRIOWJNcVk5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScEZDamg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 周飞燕, 金林鹏, 董军.卷积神经网络研究综述[J].计算机学报, 2017, 40 (6) :1229-1251.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploit All the Layers:Fast and Accurate CNN Object Detector With Scale Dependent Pooling and Cascaded Rejection Classifiers">

                                <b>[7]</b> YANG Fan, CHOI W, LIN Yuanqing.Exploit all the layers:fast and accurate CNN object detector with scale dependent pooling and cascaded rejection classifiers[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2016:236-243.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A-fast-RCNN:hard positive generation via adversary for object detection">

                                <b>[8]</b> WANG Xiaolong, SHRIVASTAVA A, GUPTA A.A-fast-RCNN:hard positive generation via adversary for object detection[EB/OL].[2018-04-29].https://arxiv.org/pdf/1704.03414.pdf.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CAFFE:Convolutional Architecture for Fast Feature Embedding">

                                <b>[9]</b> JIA Yangqing, SHELHAMER E, DONAHUE J, et al.Caffe:convolutional architecture for fast feature embedding[C]//Proceedings of the 22nd ACM International Conference on Multimedia.New York, USA:ACM Press, 2014:269-280.
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=MEC:memory-efficient convolu-tion for deep neural network">

                                <b>[10]</b> CHO M, BRAND D.MEC:memory-efficient convolu-tion for deep neural network[EB/OL].[2018-04-25].https://arxiv.org/pdf/1706.06873.pdf.
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Theano:deep learning on GPUs with Python">

                                <b>[11]</b> BERGSTRA J, BASTIEN F, BREULEUX O, et al.Theano:deep learning on GPUs with Python[EB/OL].[2018-04-25].http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.678.1889&amp;rep=rep1&amp;type=pdf.
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=cuDNN:efficient primitives for deep learning">

                                <b>[12]</b> CHETLUR S, WOOLLEY C, VANDERMERSCH P, et al.cuDNN:efficient primitives for deep learning[EB/OL].[2018-04-25].https://arxiv.org/pdf/1410.0759.pdf.
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning semantic image representations at a large scale">

                                <b>[13]</b> JIA Yangqing.Learning semantic image representations at a large scale[EB/OL].[2018-04-26].https://cloudfront.escholarship.org/dist/prd/content/qt64c2v6sn/qt64c2v6sn.pdf.
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCME3082E305B81CE4EBE1F724A1883AB7C&amp;v=MzIwMjRIdG5PMm94Rllaa0hEUTlNeTJOaG56NExUMzNtM1JNOWNiSGxONzNzQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TjlpeEx5Nndhcz1OaWZJWThhNw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> ZEE F G V.BLIS:a framework for rapidly instantiating BLAS functionality[J].ACM Transactions on Mathematical Software, 2013, 41 (3) :1-33.
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-performance neural networks for visual object classification">

                                <b>[15]</b> CIREŞAN D C, MEIER U, MASCI J, et al.High-performance neural networks for visual object classification[EB/OL].[2018-04-26].https://arxiv.org/pdf/1102.0183.pdf.
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">

                                <b>[16]</b> SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[EB/OL].[2018-04-28].https://arxiv.org/pdf/1409.1556.pdf.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Arithmetic complexity of computations">

                                <b>[17]</b> WINOGRAD S.Arithmetic complexity of computations[M].[S.l.]:Society for Industrial and Applied Mathematics, 1980.
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor comprehensions:framework-agnostic high-performance machine learning abstractions">

                                <b>[18]</b> VASILACHE N, ZINENKO O, THEODORIDIS T, et al.Tensor comprehensions:framework-agnostic high-performance machine learning abstractions[EB/OL].[2018-04-25].https://arxiv.org/pdf/1802.04730.pdf.
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CUBLAS library">

                                <b>[19]</b> NVIDIA C.CUBLAS library[EB/OL].[2018-04-28].https://arcb.csc.ncsu.edu/～mueller/cluster/nvidia/0.8/NVIDIA_CUBLAS_Library_0.8.pdf.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201907035" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201907035&amp;v=MjA4OTQ5R1lZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScEZDamhWcjdMTHo3QmJiRzRIOWpNcUk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
