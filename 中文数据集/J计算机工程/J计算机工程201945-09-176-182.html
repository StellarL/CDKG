<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637128034725030000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201909028%26RESULT%3d1%26SIGN%3dF9tZalh28X0lsHFZvWSeLlegSEM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201909028&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201909028&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201909028&amp;v=MDU5MzQvaFZidk5MejdCYmJHNEg5ak1wbzlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#38" data-title="1 相关研究 ">1 相关研究</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#39" data-title="1.1 传统推荐算法">1.1 传统推荐算法</a></li>
                                                <li><a href="#44" data-title="1.2 基于深度学习的推荐算法">1.2 基于深度学习的推荐算法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#49" data-title="2 DeepCoNN模型 ">2 DeepCoNN模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="2.1 评论文本深度建模">2.1 评论文本深度建模</a></li>
                                                <li><a href="#90" data-title="2.2 注意力机制">2.2 注意力机制</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="3 ACoNN网络结构设计 ">3 ACoNN网络结构设计</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#113" data-title="3.1 网络结构">3.1 网络结构</a></li>
                                                <li><a href="#117" data-title="3.2 网络训练">3.2 网络训练</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#125" data-title="4 实验与结果分析 ">4 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#126" data-title="4.1 数据集">4.1 数据集</a></li>
                                                <li><a href="#130" data-title="4.2 评价指标">4.2 评价指标</a></li>
                                                <li><a href="#134" data-title="4.3 实验结果对比">4.3 实验结果对比</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#147" data-title="5 结束语 ">5 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="&lt;b&gt;图1 DeepCoNN模型网络结构&lt;/b&gt;"><b>图1 DeepCoNN模型网络结构</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;图2 基于注意力机制的权值更新层&lt;/b&gt;"><b>图2 基于注意力机制的权值更新层</b></a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;图3 ACoNN网络结构&lt;/b&gt;"><b>图3 ACoNN网络结构</b></a></li>
                                                <li><a href="#139" data-title="&lt;b&gt;表1 ADM 数据集实验结果对比&lt;/b&gt;"><b>表1 ADM 数据集实验结果对比</b></a></li>
                                                <li><a href="#140" data-title="&lt;b&gt;表2 AMT 数据集实验结果对比&lt;/b&gt;"><b>表2 AMT 数据集实验结果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="183">


                                    <a id="bibliography_1" title=" 韩路.协同过滤推荐算法的研究[J].无线互联科技,2013(2):160." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXHK201302128&amp;v=MjE0ODJYRFpiRzRIOUxNclk1SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckZ5L2hWYnZOTWo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         韩路.协同过滤推荐算法的研究[J].无线互联科技,2013(2):160.
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_2" title=" 汪静.协同过滤推荐算法研究综述[J].中国新通信,2014(13):111-113." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXWL201413086&amp;v=MTExODVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeS9oVmJ2Tk1UWGNZckc0SDlYTnJJOU5Zb1FLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         汪静.协同过滤推荐算法研究综述[J].中国新通信,2014(13):111-113.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_3" title=" 冷亚军,陆青,梁昌勇.协同过滤推荐技术综述[J].模式识别与人工智能,2014,27(8):720-734." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201408007&amp;v=MDQ1MDRiTEc0SDlYTXA0OUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeS9oVmJ2TktEN1k=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         冷亚军,陆青,梁昌勇.协同过滤推荐技术综述[J].模式识别与人工智能,2014,27(8):720-734.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_4" title=" DIELEMAN S,SCHRAUWEN B.Deep content-based music recommendation[C]//Proceedings of International Conference on Neural Information Processing Systems.[S.l.]:Neural Information Processing Systems,Inc.,2013:2643-2651." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep content-based music recommendation">
                                        <b>[4]</b>
                                         DIELEMAN S,SCHRAUWEN B.Deep content-based music recommendation[C]//Proceedings of International Conference on Neural Information Processing Systems.[S.l.]:Neural Information Processing Systems,Inc.,2013:2643-2651.
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_5" title=" ELKAHKY A M,SONG Yang,HE Xiaodong.A multi-view deep learning approach for cross domain user modeling in recommendation systems[C]//Proceedings of the 24th International Conference on World Wide Web.New York,USA:ACM Press,2015:278-288." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A multi-view deep learning approach for cross domain user modeling in recommendation systems">
                                        <b>[5]</b>
                                         ELKAHKY A M,SONG Yang,HE Xiaodong.A multi-view deep learning approach for cross domain user modeling in recommendation systems[C]//Proceedings of the 24th International Conference on World Wide Web.New York,USA:ACM Press,2015:278-288.
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_6" title=" ZHENG Lei,NOROOZI V,YU P S.Joint deep modeling of users and items using reviews for recommendation[C]//Proceedings of the 10th ACM International Conference on Web Search and Data Mining.New York,USA:ACM Press,2017:425-434." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint deep modeling of users and items using reviews for recommendation">
                                        <b>[6]</b>
                                         ZHENG Lei,NOROOZI V,YU P S.Joint deep modeling of users and items using reviews for recommendation[C]//Proceedings of the 10th ACM International Conference on Web Search and Data Mining.New York,USA:ACM Press,2017:425-434.
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_7" title=" MNIH V,HEESS N,GRAVES A,et al.Recurrent models of visual attention[C]//Proceedings of International Conference on Neural Information Processing Systems.[S.l.]:Neural Information Processing Systems,Inc.,2014:2204-2212." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recurrent models of visual attention">
                                        <b>[7]</b>
                                         MNIH V,HEESS N,GRAVES A,et al.Recurrent models of visual attention[C]//Proceedings of International Conference on Neural Information Processing Systems.[S.l.]:Neural Information Processing Systems,Inc.,2014:2204-2212.
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_8" title=" BAHDANAU D,CHO K,BENGIO Y.Neural machine translation by jointly learning to align and translate[EB/OL].[2018-04-01].https://arxiv.org/abs/1409.0473." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">
                                        <b>[8]</b>
                                         BAHDANAU D,CHO K,BENGIO Y.Neural machine translation by jointly learning to align and translate[EB/OL].[2018-04-01].https://arxiv.org/abs/1409.0473.
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_9" title=" FENG Minwei,XIANG Bing,GLASS M R,et al.Applying deep learning to answer selection:a study and an open task[C]//Proceedings of 2015 IEEE Workshop on Automatic Speech Recognition and Understanding.Washington D.C.,USA:IEEE Press,2015:813-820." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Applying Deep Learning to Answer Selection:A Study and an Open Task">
                                        <b>[9]</b>
                                         FENG Minwei,XIANG Bing,GLASS M R,et al.Applying deep learning to answer selection:a study and an open task[C]//Proceedings of 2015 IEEE Workshop on Automatic Speech Recognition and Understanding.Washington D.C.,USA:IEEE Press,2015:813-820.
                                    </a>
                                </li>
                                <li id="201">


                                    <a id="bibliography_10" title=" YIN Wenpeng,SCH&#220;TZE H,XIANG Bing,et al.ABCNN:attention-based convolutional neural network for modeling sentence pairs[J].Transactions of the Association for Computational Linguistics,2016(4):259-272." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ABCNN:Attention-Based Convolutional Neural Network for Modeling Sentence Pairs">
                                        <b>[10]</b>
                                         YIN Wenpeng,SCH&#220;TZE H,XIANG Bing,et al.ABCNN:attention-based convolutional neural network for modeling sentence pairs[J].Transactions of the Association for Computational Linguistics,2016(4):259-272.
                                    </a>
                                </li>
                                <li id="203">


                                    <a id="bibliography_11" title=" GONG Yuyun,ZHANG Qi.Hashtag recommendation using attention-based convolutional neural network[C]//Proceedings of International Joint Conference on Artificial Intelligence.[S.l.]:AAAI Press,2016:2782-2788." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hashtag recommendation using attention-based convolutional neural network">
                                        <b>[11]</b>
                                         GONG Yuyun,ZHANG Qi.Hashtag recommendation using attention-based convolutional neural network[C]//Proceedings of International Joint Conference on Artificial Intelligence.[S.l.]:AAAI Press,2016:2782-2788.
                                    </a>
                                </li>
                                <li id="205">


                                    <a id="bibliography_12" title=" WANG Xuejian,YU Lantao,REN Kan,et al.Dynamic attention deep model for article recommendation by learning human editors’demonstration[C]//Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York,USA:ACM Press,2017:2051-2059." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dynamic attention deep model for article recommendation by learning human editors&amp;#39;&amp;#39; demonstration">
                                        <b>[12]</b>
                                         WANG Xuejian,YU Lantao,REN Kan,et al.Dynamic attention deep model for article recommendation by learning human editors’demonstration[C]//Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York,USA:ACM Press,2017:2051-2059.
                                    </a>
                                </li>
                                <li id="207">


                                    <a id="bibliography_13" title=" 黄立威,江碧涛,吕守业,等.基于深度学习的推荐系统研究综述[J].计算机学报,2018,41(7):191-219." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201807011&amp;v=MDQ3Njg2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeS9oVmJ2Tkx6N0Jkckc0SDluTXFJOUVaWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         黄立威,江碧涛,吕守业,等.基于深度学习的推荐系统研究综述[J].计算机学报,2018,41(7):191-219.
                                    </a>
                                </li>
                                <li id="209">


                                    <a id="bibliography_14" title=" BLEI D M,NG A Y,JORDAN M I.Latent Dirichlet allocation[J].Machine Learning Research Archive,2003,3:993-1022." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Latent Dirichlet allocation">
                                        <b>[14]</b>
                                         BLEI D M,NG A Y,JORDAN M I.Latent Dirichlet allocation[J].Machine Learning Research Archive,2003,3:993-1022.
                                    </a>
                                </li>
                                <li id="211">


                                    <a id="bibliography_15" title=" MCAULEY J,LESKOVEC J.Hidden factors and hidden topics:understanding rating dimensions with review text[C]//Proceedings of the 7th ACM Conference on Recommender Systems.New York,ACM Press,2013:165-172." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hidden factors and hidden topics:understanding rating dimensions with review text">
                                        <b>[15]</b>
                                         MCAULEY J,LESKOVEC J.Hidden factors and hidden topics:understanding rating dimensions with review text[C]//Proceedings of the 7th ACM Conference on Recommender Systems.New York,ACM Press,2013:165-172.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(09),176-182 DOI:10.19678/j.issn.1000-3428.0051339            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于注意力机制与评论文本深度模型的推荐方法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E6%96%87%E6%98%8E&amp;code=10551776&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄文明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%AB%E4%B8%87%E6%88%90&amp;code=37347622&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卫万成</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%81%A5&amp;code=37347623&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张健</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%93%E7%8F%8D%E8%8D%A3&amp;code=17542375&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邓珍荣</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=0269119&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林电子科技大学计算机与信息安全学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E5%B9%BF%E8%A5%BF%E5%8F%AF%E4%BF%A1%E8%BD%AF%E4%BB%B6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林电子科技大学广西可信软件重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>传统推荐系统依赖人工进行规则设计和特征提取,对评论文本内容的特征和隐信息的提取能力有限。针对该问题,融合注意力机制并基于深度学习对推荐系统进行改进,提出一种对评论文本深度建模的推荐方法。使用词嵌入模型表达数据集评论中的语义,引入注意力机制对输入内容进行重新赋权,通过并行的卷积神经网络挖掘用户和项目评论数据中的隐含特征,将两组特征耦合输入并采用因子分解机进行评分预测,得到推荐结果。实验结果表明,该方法可有效提高推荐准确率,均方误差较DeepCoNN方法提升2%以上。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">推荐系统;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">注意力机制;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%A0%E5%AD%90%E5%88%86%E8%A7%A3%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">因子分解机;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    黄文明(1963—),男,教授,主研方向为人工智能、大数据处理、图形图像处理;;
                                </span>
                                <span>
                                    卫万成,硕士研究生;;
                                </span>
                                <span>
                                    张健,硕士研究生;;
                                </span>
                                <span>
                                    邓珍荣,研究员。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-04-24</p>

                    <p>

                            <b>基金：</b>
                                                        <span>广西自然科学基金(2018GXNSFAA138132);</span>
                                <span>广西高校云计算与复杂系统重点实验室项目(yf17106);</span>
                                <span>桂林电子科技大学研究生教育创新计划(2018YJCX55);</span>
                    </p>
            </div>
                    <h1><b>Recommendation Method Based on Attention Mechanism and Review Text Deep Model</b></h1>
                    <h2>
                    <span>HUANG Wenming</span>
                    <span>WEI Wancheng</span>
                    <span>ZHANG Jian</span>
                    <span>DENG Zhenrong</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Information Security,Guilin University of Electronic Technology</span>
                    <span>Guangxi Key Laboratory of Trusted Software,Guilin University of Electronic Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The traditional recommendation system relies on manual rule design and feature extraction,resulting in insufficient extraction of the features and implicit information of the review text content.Aiming at this problem,a recommendation method for deep modeling of review text is proposed combining the attention mechanism and the improved recommendation system based on deep learning.The word embedding model is used to express the semantics in dataset comments,the attention mechanism is introduced to re-weight the input content,and the hidden features in the user and project comment data are mined through the parallel convolutional neural network.The two sets of features are coupled and input and scored by a factorization machine to obtain the recommendation results.Experimental results show that the proposed algorithm can efficiently improve the recommendation precision,and the mean square error is improved by more than 2% than that of the DeepCoNN algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=recommendation%20system&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">recommendation system;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=attention%20mechanism&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">attention mechanism;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolution%20Neural%20Network%20(CNN)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolution Neural Network (CNN);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=factorization%20machine&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">factorization machine;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-04-24</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="34">当今社会处于一个信息数据快速增长的时代,诸如在线内容服务、即时通信和社交网络等新兴网络信息服务在日常生活中扮演着重要的角色,网络上每天都进行着巨量的数据交换,而推荐系统能为用户对海量信息进行筛选并推荐。根据CNNIC发布的报告,截至2017年底,中国的网民规模已达7.72亿。如此大规模的用户表明推荐系统蕴含着巨大的研究和应用价值。</p>
                </div>
                <div class="p1">
                    <p id="35">对于用户而言,推荐系统能辅助决策;对于商家而言,推荐系统能提高用户信任度和粘性,由此增加营收。传统推荐系统设计存在结构上的局限性,其极度依赖人工进行规则的设计与特征的提取,使得算法模型对于特征和隐信息的提取能力有限,一定程度上限制了推荐系统的使用。</p>
                </div>
                <div class="p1">
                    <p id="36">近年来,随着深度学习在计算机视觉和自然语言处理等领域取得大量进展,其对数据特征进行挖掘和提取的优势逐渐展现。而特征提取正是推荐系统中的重要环节,特征学习的好坏关乎推荐系统的成败。因此,近年来研究人员逐渐加大对深度学习的研究力度。</p>
                </div>
                <div class="p1">
                    <p id="37">目前大部分推荐算法主要基于数据中的数值型数据和人工分类数据,对于数据的特征提取深度及广度有限,在一定程度上影响了推荐系统的性能和推荐准确度。为此,本文基于卷积神经网络(Convolutional Neural Network,CNN)和注意力机制,提出一种新的评论文本深度建模方法,以提升推荐系统性能和推荐准确性。</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag">1 相关研究</h3>
                <h4 class="anchor-tag" id="39" name="39">1.1 传统推荐算法</h4>
                <div class="p1">
                    <p id="40">目前,传统推荐算法主要分2大类:基于内容的推荐和协同过滤推荐。</p>
                </div>
                <div class="p1">
                    <p id="41">1)基于内容的推荐算法,其基本步骤是先获取目标项目和有过用户行为的项目特征,计算其相似度,再结合历史评分进行推荐。</p>
                </div>
                <div class="p1">
                    <p id="42">2)协同过滤推荐,作为业界当前应用最广泛的推荐算法,主要包含2类:基于模型的协同过滤和基于内存的协同过滤<citation id="213" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。基于模型的协同过滤根据大量的用户历史行为数据设计出可用模型对目标用户的未来行为进行预测<citation id="214" type="reference"><link href="185" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>,产生推荐结果。由选取的目标对象不同,基于内存的协同过滤可分为基于用户的协同过滤和基于项目的协同过滤<citation id="215" type="reference"><link href="187" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="43">目前大量的推荐系统研究主要针对挖掘系统中的数值型数据和通过人工设计规则提取数据的特征进行算法设计。随着网络的飞速发展,交互式应用遍布所有角落,由此产生了巨量的用户文本内容,推荐系统能获取包含更大信息量的数据。受限于目前推荐算法对数据中尤其是文本内容的特征提取能力不足,业界逐渐将目光投向深度学习领域。</p>
                </div>
                <h4 class="anchor-tag" id="44" name="44">1.2 基于深度学习的推荐算法</h4>
                <div class="p1">
                    <p id="45">深度学习在自然语言处理方面上的优势,高度契合推荐系统使用原始评论文本数据的需求。基于深度学习对推荐系统进行研究使得其发展有了新的突破口。目前用于推荐系统中的深度学习技术主要有自编码器(Autoencoder,AE)、CNN、循环神经网络(Recurrent Neural Network,RNN)、受限波尔茨曼机(Restricted Boltzmann Machine,RBM)等。本文主要使用CNN对评论文本特征深度建模,并引入注意力机制,技术优势及相关研究如下:</p>
                </div>
                <div class="p1">
                    <p id="46">1)CNN的优势在于能从多源异构数据中实现局部和全局的表示,自动且充分地完成抽象特征提取。文献<citation id="216" type="reference">[<a class="sup">4</a>]</citation>设计一个基于内容的音乐推荐系统,通过将矩阵分解与CNN融合成一个新的网络结构,对用户的历史数据和音乐的音频信号数据组合成的数据对进行处理,将提取的数据对特征投影到同一特征空间上,进而执行后续的推荐系统任务。文献<citation id="217" type="reference">[<a class="sup">5</a>]</citation>提出一种应用在推荐系统针对跨领域用户建模的多视图深度学习方法,通过在原CNN结构基础上引入多视图深层学习扩展模型,从不同领域和用户特征中共同学习项目特征。该设计有助于提高全领域的推荐质量,并产生更紧凑和语义丰富的用户潜在特征向量,极大提升了推荐效果。文献<citation id="218" type="reference">[<a class="sup">6</a>]</citation>提出深度协作神经网络模型DeepCoNN,通过并行2个结构相同的CNN,对用户和项目的评论文本进行特征学习,并采用输出层与因子分解机(Factorization Machine,FM)的组合进行评分预测,充分利用了数据集中的评论文本。</p>
                </div>
                <div class="p1">
                    <p id="47">2)注意力机制的引入可使神经网络将训练的重点集中在输入内容中与目标关联度高的部分,由此加强对处理内容重点部分的关注。注意力机制早在20世纪90年代中期便被提出,直到2014年由Google团队将其实现在RNN模型上对图像进行分类并取得优秀的效果才引起业界的重视<citation id="219" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。同年文献<citation id="220" type="reference">[<a class="sup">8</a>]</citation>将注意力机制引入RNN结构上做机器翻译任务,这也是注意力机制在自然语言处理领域较早期的应用。文献<citation id="221" type="reference">[<a class="sup">9</a>]</citation>提出BCNN结构,将深度学习框架运用到问答模型上,并取得较好的效果,接着文献<citation id="222" type="reference">[<a class="sup">10</a>]</citation>在此基础上引入注意力机制,提出ABCNN结构,提高了对句对模型的处理效率和提炼结果的准确度,将深度学习处理文本内容的能力进一步提升,而这也是注意力机制较早在文本领域CNN结构上的应用。文献<citation id="223" type="reference">[<a class="sup">11</a>]</citation>提出一种应用于标签推荐的结合注意力机制的CNN,通过CNN提取微博数据的特征,设计一个包含全局通道和局部注意力通道的模型,以提升获取微博文本重点内容的能力,增强推荐系统性能。文献<citation id="224" type="reference">[<a class="sup">12</a>]</citation>将单个注意力模型应用在新闻推荐及筛选领域,新闻文本的内容和种类特征通过结合注意力机制的CNN模型处理为固定长度的隐向量表示,同时考虑到用户对于不同类型喜好的时效性及选择规律,最终输出一个二分类问题的结果。</p>
                </div>
                <div class="p1">
                    <p id="48">由于深度学习的神经网络结构具有强大的自动学习特征的能力与自动对非线性结构进行深层次学习的能力,因此,将其与推荐系统融合的优势可归纳为两点:第一,深度学习可以自动从多源异构数据中进行特征学习,将不同数据映射至同一空间,由此可以提取数据特征并表达到同一个特征空间上;第二,深度学习能自动进行训练和学习,得到深层次的非线性网络结构,由此挖掘并表征数据的深层次特征表示<citation id="225" type="reference"><link href="207" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。这些优势让推荐系统的研究发展有了一个全新的突破点。</p>
                </div>
                <h3 id="49" name="49" class="anchor-tag">2 DeepCoNN模型</h3>
                <div class="p1">
                    <p id="50">本文基于CNN提出一种融合注意力机制对评论文本深度建模的推荐方法,主要步骤为:</p>
                </div>
                <div class="p1">
                    <p id="51">1)评论文本深度建模:使用一个并行的CNN结构,分别基于用户评论及商品评论进行文本特征建模,实现推荐系统对文本数据的充分利用。</p>
                </div>
                <div class="p1">
                    <p id="52">2)引入注意力机制:将注意力机制引入第1步设计的CNN结构中,提升对重点内容的关注,实现对评论文本更准确的建模。</p>
                </div>
                <h4 class="anchor-tag" id="53" name="53">2.1 评论文本深度建模</h4>
                <div class="p1">
                    <p id="54">深度学习中的神经网络结构具有强大的自动学习特征的能力及能自动对非线性结构进行的深层次学习的能力,能有效利用多源异构数据进行特征学习和实现更深层次的数据特征表示。</p>
                </div>
                <div class="p1">
                    <p id="55">本文研究的深度评论文本模型是对文献<citation id="226" type="reference">[<a class="sup">6</a>]</citation>DeepCoNN模型的改进。</p>
                </div>
                <h4 class="anchor-tag" id="56" name="56">2.1.1 神经网络结构</h4>
                <div class="p1">
                    <p id="57">DeepCoNN模型是2个并行的神经网络组合,其中一个网络用于处理用户评论(标记为Net<sub>u</sub>),提取用户的行为特征;另一个网络用于处理项目评论Net<sub>i</sub>),提取商品具有的特性。在最后一层,将这2个网络生成的结果进行耦合并生成最终结果。DeepCoNN模型网络结构如图1所示。</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909028_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 DeepCoNN模型网络结构" src="Detail/GetImg?filename=images/JSJC201909028_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 DeepCoNN模型网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909028_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="59">DeepCoNN模型的具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="60">1)对用户的评论文本和项目的评论文本进行处理,得到相应的表达。</p>
                </div>
                <div class="p1">
                    <p id="61">2)将用户评论和项目评论各自的表达分别输入Net<sub>u</sub>和Net<sub>i</sub>,进行卷积处理,提取深层特征。</p>
                </div>
                <div class="p1">
                    <p id="62">3)进行最大池化操作,降低第2个步骤卷积层的特征向量维度,并解决过拟合问题。</p>
                </div>
                <div class="p1">
                    <p id="63">4)将结果输入全连接层,并映射学习到的特征到样本标记空间。</p>
                </div>
                <div class="p1">
                    <p id="64">5)对2个并行CNN结构输出的用户特征向量及项目特征向量进行处理并使用评分预测函数得到用户相应的评分。该目标函数也将作为模型的损失函数进行迭代训练,以得到最优结果。</p>
                </div>
                <h4 class="anchor-tag" id="65" name="65">2.1.2 词向量表示</h4>
                <div class="p1">
                    <p id="66">词向量表示是目前对自然语言处理领域效果最优的文本数据处理方法之一,其原理是通过使用词嵌入模型,将数据集中用户与项目的评论文本通过模型函数映射到一个新的表达空间,由此得到词向量表示,即<i>f</i>:<i>word</i><sub><i>n</i></sub>→<i><b>R</b></i><sub><i>n</i></sub>,其中,<i>word</i><sub><i>n</i></sub>代表数据集中组成字典的每个单词,<i><b>R</b></i><sub><i>n</i></sub>代表经过参数化的函数映射得到一个<i>n</i>维特征向量。</p>
                </div>
                <div class="p1">
                    <p id="67">共同出现率高或近义的词汇在特征空间中会被投影成相似的角度。向量表示方式的优点是:避免因词汇量过大造成数据稀疏,同时可以对数据进行降维;加入了词对间的相互关系,实现句子级的表示。</p>
                </div>
                <div class="p1">
                    <p id="68">在输入层中,评论文本经过处理被表示为一个词嵌入矩阵。本文挖掘并利用数据集评论中的语义的具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="69">1)将单个用户<i>U</i><sub><i>u</i></sub>的所有评论内容的单词合并为一个文档,代表该用户的字典<i>w</i><mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>∶</mo><mi>n</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>,其中w<mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>u</mi></msubsup></mrow></math></mathml>代表该用户字典中第k个词。</p>
                </div>
                <div class="p1">
                    <p id="70">2)处理用户字典内所有词汇得到相应的词向量表示,得到用户的词向量字典(<i><b>w</b></i><mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>∶</mo><mi>n</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>)′,其中(<i><b>w</b></i><mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>u</mi></msubsup></mrow></math></mathml>)′代表第<i>k</i>个词的词向量表示。</p>
                </div>
                <div class="p1">
                    <p id="71">3)在用户的词向量字典(<i><b>w</b></i><mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>∶</mo><mi>n</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>)′的组合过程中保留词汇在评论文本中的原始顺序,此举将有利于语义的挖掘与表示,由此得到用户<i>U</i><sub><i>u</i></sub>的词向量矩阵<i><b>M</b></i><sub><i>u</i></sub>为:</p>
                </div>
                <div class="p1">
                    <p id="72"><i><b>M</b></i><sub><i>u</i></sub>=(<i><b>w</b></i><mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>u</mi></msubsup></mrow></math></mathml>)′∶(<i><b>w</b></i><mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>u</mi></msubsup></mrow></math></mathml>)′∶…∶(<i><b>w</b></i><mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mi>u</mi></msubsup></mrow></math></mathml>)′      (1)</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73">2.1.3 卷积神经网络层</h4>
                <div class="p1">
                    <p id="74">CNN层用于评论文本特征的提取,主要包含卷积层、最大池化层和全连接层。以用户<i>U</i><sub><i>u</i></sub>为例,具体细节如下:</p>
                </div>
                <div class="p1">
                    <p id="75">1)卷积层:每层中包含<i>n</i>个神经元,将输入的用户词向量矩阵<i><b>M</b></i><sub><i>u</i></sub>进行卷积操作提取新的特征。在每个神经元<i>neuron</i><sub><i>k</i></sub>中,对应尺寸为<i>m</i>×<i>t</i>的过滤器<i><b>filter</b></i><sub><i>k</i></sub>。其中,<i>m</i>为词嵌入模型产生特征维度,<i>k</i>为设计的滑动词窗口大小。在CNN中,每个卷积核经卷积操作对应产生一个特征图<i><b>map</b></i><sub><i>n</i></sub>,具体公式如下:</p>
                </div>
                <div class="p1">
                    <p id="76"><i><b>map</b></i><sub><i>n</i></sub>=<i>f</i>(<i><b>M</b></i><sub><i>u</i></sub>⨂<i><b>filter</b></i><sub><i>k</i></sub>+<i><b>b</b></i><sub><i>k</i></sub>)      (2)</p>
                </div>
                <div class="p1">
                    <p id="77">其中,<i>f</i>为激活函数ReLU,⨂为卷积操作,<i><b>b</b></i><sub><i>k</i></sub>为过滤器<i><b>filter</b></i><sub><i>k</i></sub>对应的偏置。</p>
                </div>
                <div class="p1">
                    <p id="78">2)池化层:模型DeepCoNN采取最大池化操作。通过选取每一个池化层过滤器对应区域中的最大值,最终在输入的原特征图<i><b>map</b></i><sub><i>n</i></sub>中提取主要特征,得到新的特征图。使用最大池化操作,有利于对不同长度的文本输入进行处理,解决评论文本长度不一致的问题。通过使用最大池化层,网络对特征图进行压缩使其规模变小,同时只提取主要特征,不仅简化网络计算的复杂度,也一定程度上解决过拟合现象。得到的池化特征图<i><b>map</b></i>′<sub><i>n</i></sub>为:</p>
                </div>
                <div class="p1">
                    <p id="79"><i><b>map</b></i>′<sub><i>n</i></sub>=<i><b>map</b></i><sub><i>n</i></sub>(Max(<i>allfeature</i>))      (3)</p>
                </div>
                <div class="p1">
                    <p id="80">3)全连接层:将经过最大池化操作得到的特征图<i><b>map</b></i>′<sub><i>n</i></sub>输入全连接层,与本层的权值矩阵相乘并加上偏置求和,引入Dropout策略,对特征进行随机丢弃。加入全连接层,能进一步缓解过拟合并进行分类输出。加权求和得到分类输出的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="81"><i><b>output</b></i><sub><i>u</i></sub>=<i>f</i>(<i><b>W</b></i>×<i><b>map</b></i>′<sub><i>n</i></sub>+<i><b>b</b></i><sub>all-connected</sub>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="82">其中,<i>f</i>是激活函数ReLU,<i><b>output</b></i><sub><i>u</i></sub>为该用户<i>u</i>的分类输出,<i><b>W</b></i>为全连接层的权值矩阵,<i><b>b</b></i><sub>all-connected</sub>为全连接层的偏置。</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83">2.1.4 共享层</h4>
                <div class="p1">
                    <p id="84">虽然经过上述传统神经网络结构输出得到了用户和项目的特征矩阵,但是这2种输出存在于不同的特征空间中,并不能直接进行比较。因此,本文模型在网络结构的顶部设计了一个共享层,其具体操作细节如下:</p>
                </div>
                <div class="p1">
                    <p id="85">1)将用户<i>u</i>的特征矩阵<i><b>output</b></i><sub><i>u</i></sub>与项目<i>i</i>的特征矩阵<i><b>output</b></i><sub><i>i</i></sub>进行连接,构建用户-项目向量<i><b>z</b></i>=(<i><b>output</b></i><sub><i>u</i></sub>,<i><b>output</b></i><sub><i>i</i></sub>)。</p>
                </div>
                <div class="p1">
                    <p id="86">2)引入FM,将向量<i><b>z</b></i>输入其中经多次训练得到最终用户<i>u</i>对项目<i>i</i>的预测评分,根据DeepCoNN模型,给出具体的目标损失函数,如下式所示:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>y</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>a</mtext><mtext>l</mtext></mrow></msub><mo>-</mo><mo stretchy="false">(</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>w</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover></mrow><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><munderover><mstyle mathsize="140%" displaystyle="true"><mi>Σ</mi></mstyle><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">z</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover><mo stretchy="false">|</mo></mrow></munderover><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>w</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>z</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><munderover><mstyle mathsize="140%" displaystyle="true"><mtext>Σ</mtext></mstyle><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">z</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover><mo stretchy="false">|</mo></mrow></munderover><munderover><mstyle mathsize="140%" displaystyle="true"><mtext>Σ</mtext></mstyle><mrow><mi>j</mi><mo>=</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">z</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover><mo stretchy="false">|</mo></mrow></munderover><mi>w</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>z</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>z</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover></mrow><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">其中,<i>y</i><sub>real</sub>为用户对项目的真实评分值,<mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>w</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover><msub><mrow></mrow><mn>0</mn></msub></mrow></math></mathml>为全局偏置量,<mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>w</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>表示用户-项目特征组合向量<i><b>z</b></i>中第<i>i</i>个分量的权重值,<mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mo>&lt;</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>v</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>,</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>v</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>&gt;</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>f</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>z</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover><mo stretchy="false">|</mo></mrow></munderover><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>v</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>f</mi></mrow></msub></mrow></mstyle><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>v</mi></mstyle><mrow><mspace width="0.25em" /><mo>-</mo></mrow></mover><msub><mrow></mrow><mrow><mi>j</mi><mo>,</mo><mi>f</mi></mrow></msub></mrow></mrow></math></mathml>。基于矩阵分解思想,实现各分量之间的二阶交互,并对此建模,挖掘出任意2条特征的相关程度。</p>
                </div>
                <div class="p1">
                    <p id="89">3)训练过程即最小化目标损失函数(式(5))。为进行参数更新以优化模型,将训练集拆分成若干小集合,以<i>mini</i>-<i>batch</i>形式使用<i>RMSprop</i>优化算法进行参数更新。该方法能更契合神经网络的非凸函数特点,将传统优化算法的梯度累积转变为根据梯度绝对值自适应移动来控制历史信息的获取。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90">2.2 注意力机制</h4>
                <div class="p1">
                    <p id="91">人类在观察和阅读时会对对象内容的特定部分进行重点关注,而后对这一区域投入更多注意力资源,以获取更多所需要关注目标的细节信息。受此启发,研究人员提出注意力机制。本文将注意力机制融入CNN对评论文本特征的提取过程中,提出的一种评论文本深度建模方法,加大对文本核心内容的关注,由此实现对评论文本更准确的建模,提升推荐准确度。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92">2.2.1 基于注意力机制的词向量权值更新算法</h4>
                <div class="p1">
                    <p id="93">本文设计的注意力机制算法是基于单个词汇级别上进行注意力权值计算。</p>
                </div>
                <div class="p1">
                    <p id="94"><b>算法</b> 基于注意力机制的词向量权值更新</p>
                </div>
                <div class="p1">
                    <p id="95"><b>输入</b> 目标用户<i>U</i><sub><i>u</i></sub>所有文本评论数据的词向量矩阵<i><b>M</b></i><sub><i>u</i></sub>,用户<i>U</i><sub><i>u</i></sub><sub>all</sub>的所有词汇各自的词向量表示(<i><b>w</b></i><mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>∶</mo><mi>n</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>)′</p>
                </div>
                <div class="p1">
                    <p id="96"><b>输出</b> 目标用户<i>U</i><sub><i>u</i></sub>采用注意力机制更新后的词向量矩阵<i><b>M</b></i><mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mrow><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="97">1)将用户U<sub>u</sub><sub><i>all</i></sub>的所有词向量表示(<i><b>w</b></i><mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>∶</mo><mi>n</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>)′按单个词取出。</p>
                </div>
                <div class="p1">
                    <p id="98">2)(循环1)计算目标用户评论文本中每个词汇的词向量表示(<i><b>w</b></i><mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>u</mi></msubsup></mrow></math></mathml>)′与用户评论词向量字典中的每个词汇(<i><b>w</b></i><mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mn>1</mn><mo>∶</mo><mi>n</mi></mrow><mi>u</mi></msubsup></mrow></math></mathml>)′的相似度<i>sim</i><sub><i>k</i></sub>,使用余弦相似度计算方法实现,具体如式(6)所示。</p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi>cos</mi></mrow></mstyle><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><msubsup><mrow></mrow><mi>k</mi><mi>u</mi></msubsup><msup><mo stretchy="false">)</mo><mo>′</mo></msup><mo>,</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><msubsup><mrow></mrow><mrow><mn>1</mn><mo>∶</mo><mi>n</mi></mrow><mi>u</mi></msubsup><msup><mo stretchy="false">)</mo><mo>′</mo></msup><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100">3)(循环2)通过softmax函数分别对每个词向量的相似度权重进行归一化处理,得到每个词向量分别对应的注意力权重<i>a</i><sub><i>k</i></sub>,具体如式(7)所示。</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>a</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mtext>e</mtext><msup><mrow></mrow><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></msup></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mtext>e</mtext></mstyle><msup><mrow></mrow><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">4)将所有词向量的注意力权重,与其在原评论文本的词序进行拼接,得到目标用户<i>U</i><sub><i>u</i></sub>的注意力权值矩阵<i><b>A</b></i>(<i>U</i><sub><i>u</i></sub>),具体如式(8)所示。</p>
                </div>
                <div class="p1">
                    <p id="103"><i><b>A</b></i>(<i>U</i><sub><i>u</i></sub>)=(<i>a</i><sub>1</sub>,<i>a</i><sub>2</sub>,…,<i>a</i><sub><i>k</i></sub>,…,<i>a</i><sub><i>n</i></sub>)      (8)</p>
                </div>
                <div class="p1">
                    <p id="104">5)结束循环1。</p>
                </div>
                <div class="p1">
                    <p id="105">6)结束循环2。</p>
                </div>
                <div class="p1">
                    <p id="106">7)使用注意力权值矩阵<i><b>A</b></i>(<i>U</i><sub><i>u</i></sub>)与用户<i>U</i><sub><i>u</i></sub>的原词向量矩阵<i><b>M</b></i><sub><i>u</i></sub>进行对应相乘,得到更新的词向量矩阵<i><b>M</b></i><mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mrow><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml>,具体如式(9)所示。</p>
                </div>
                <div class="p1">
                    <p id="107"><i><b>M</b></i><mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mrow><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></math></mathml>=<i><b>A</b></i>(<i>U</i><sub><i>u</i></sub>)<i><b>M</b></i><sub><i>u</i></sub>      (9)</p>
                </div>
                <h4 class="anchor-tag" id="108" name="108">2.2.2 基于注意力机制的权值更新层</h4>
                <div class="p1">
                    <p id="109">本文在卷积层的输入前设置一层基于注意力机制的权值更新层。该层通过将输入层的词向量序列重新赋权,实现对重点内容的更高关注。</p>
                </div>
                <div class="p1">
                    <p id="110">该层的设计原理是利用注意力机制对原输入进行权值更新,产生与原输入尺寸一样的输入图,并保留原输入,将卷积层的输入通道拓展为双通道进行输入,其实现如图2所示。</p>
                </div>
                <div class="area_img" id="111">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909028_111.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于注意力机制的权值更新层" src="Detail/GetImg?filename=images/JSJC201909028_111.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 基于注意力机制的权值更新层</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909028_111.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="112" name="112" class="anchor-tag">3 ACoNN网络结构设计</h3>
                <h4 class="anchor-tag" id="113" name="113">3.1 网络结构</h4>
                <div class="p1">
                    <p id="114">本文提出的融合注意力机制的评论文本深度建模方法是通过设计一组并行的CNN结构分别对用户及项目的评论文本内容进行特征提取并构建两者的模型,在最顶层通过引入的因子分解机实现评分预测以达到推荐功能。在对评论文本内容进行词向量表示后,本文加入一层基于注意力机制的权值更新层实现对评论文本内容的进一步优化,加强网络对重点内容的关注以实现更准确的建模效果,以提升推荐准确性。</p>
                </div>
                <div class="p1">
                    <p id="115">加入注意力权值更新层的ACoNN网络结构如图3所示。</p>
                </div>
                <div class="area_img" id="116">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909028_116.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 ACoNN网络结构" src="Detail/GetImg?filename=images/JSJC201909028_116.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 ACoNN网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909028_116.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="117" name="117">3.2 网络训练</h4>
                <div class="p1">
                    <p id="118">ACoNN网络训练步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="119">1)数据处理:首先将单个用户的所有评论文本和单个项目的所有评论文本分别连接成一个文档,保留所有词在原评论文本的顺序。然后进入输入层,通过词嵌入模型得到用户和项目的两组词向量表达<i><b>M</b></i><sub><i>u</i></sub>及<i><b>M</b></i><sub><i>i</i></sub>,作为下一层权值更新层的输入。</p>
                </div>
                <div class="p1">
                    <p id="120">2)基于注意力机制的权值更新:通过对<i><b>M</b></i><sub><i>u</i></sub>与<i><b>M</b></i><sub><i>i</i></sub>进行基于注意力机制的权值更新得到<i><b>M</b></i>′<sub><i>u</i></sub>及<i><b>M</b></i>′<sub><i>i</i></sub>,并将更新后的输入图与原输入图作为双通道输入,一起输入到下一层卷积层中进行卷积操作。</p>
                </div>
                <div class="p1">
                    <p id="121">3)特征抽取:将用户和项目2组表达分别输入至并行的2个卷积层中进行特征抽取,得到用户特征图<i><b>map</b></i><sub><i>u</i></sub>和项目特征图<i><b>map</b></i><sub><i>i</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="122">4)池化采样:将<i><b>map</b></i><sub><i>u</i></sub>和<i><b>map</b></i><sub><i>i</i></sub>分别输入池化层,经最大池化操作,在保留重要特征的基础上减少参数数量,简化计算复杂度,并缓解过拟合现象。输出新的用户特征图<i><b>map</b></i>′<sub><i>u</i></sub>和项目特征图<i><b>map</b></i>′<sub><i>i</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="123">5)全连接层:将<i><b>map</b></i>′<sub><i>u</i></sub>和<i><b>map</b></i>′<sub><i>i</i></sub>分别输入全连接层进一步缓解过拟合并进行分类输出。得到用户输出<i><b>output</b></i><sub><i>u</i></sub>和项目输出<i><b>output</b></i><sub><i>i</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="124">6)分享层参数训练:连接<i><b>output</b></i><sub><i>u</i></sub>和<i><b>output</b></i><sub><i>i</i></sub>,构建用户-项目向量<i><b>z</b></i>,引入因子分解机,根据最小化其损失函数进行训练,更新参数,最终完成模型训练。进而得到预测评分,实现用户推荐。</p>
                </div>
                <h3 id="125" name="125" class="anchor-tag">4 实验与结果分析</h3>
                <h4 class="anchor-tag" id="126" name="126">4.1 数据集</h4>
                <div class="p1">
                    <p id="127">本文实验使用亚马逊数字音乐评价数据集(Amazon Digital Music,ADM)和亚马逊电影电视评价数据集(Amazon Movies&amp;TV,AMT),分别包含64 706条真实评论及评分和1 697 533条真实评论及评分,其中每条数据均有9个属性,包含用户id、项目id、用户名、其他用户给予的该评论有效分、用户评论内容、用户评分、评论摘要、评论unix时间戳以及评论日期。本文摘录一条数据,如下所示:</p>
                </div>
                <div class="p1">
                    <p id="128">{"reviewerID":"A38IRL0X2T4DPF","asin":"5555991584","reviewText":"I never thought Enya would reach the sublime heights of Evacuee or Marble Halls from′Shepherd Moons.′′The Celts,Watermark and Day…′ were all pleasant and admirable throughout,but are less ambitious both lyrically and musically.But Hope Has a Place from ′Memory…′reaches those heights and beyond.It is Enya at her most inspirational and comforting.I′m actually glad that this song didn′t get overexposed the way Only Time did.It makes it that much more special to all who own this album.","overall":5.0}</p>
                </div>
                <div class="p1">
                    <p id="129">为减轻运算读取数据的负担,将没有使用的数据删除,仅保留需要数据,分别为:用户id(reviewerID),项目id(asin),用户评论内容(reviewText),用户评分(overall)。实验根据用户对项目(音乐、电影或电视)的评价文本和项目的所有用户评价文本进行深度建模,挖掘出用户对项目的喜好程度,最终根据喜好程度对用户个性化推荐对应的项目。在实验中,将数据集10%作为测试集、80%作为训练集、10%作为验证集。</p>
                </div>
                <h4 class="anchor-tag" id="130" name="130">4.2 评价指标</h4>
                <div class="p1">
                    <p id="131">实验采用推荐系统常用度量指标均方误差<i>RMSE</i>和平均绝对误差<i>MAE</i>作为推荐结果的评价指标。</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><mi>Μ</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mrow><msqrt><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>u</mi><mo>,</mo><mi>n</mi><mo>∈</mo><mi>u</mi><mo>,</mo><mi>a</mi><mi>l</mi><mi>l</mi></mrow></munder><mrow><mo stretchy="false">(</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>,</mo><mi>n</mi></mrow></msub><mo>-</mo><mi>r</mi><mi>e</mi><mi>a</mi><mi>l</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>,</mo><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow><mrow><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>Μ</mi><mi>A</mi><mi>E</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>u</mi><mo>,</mo><mi>n</mi><mo>∈</mo><mi>u</mi><mo>,</mo><mi>a</mi><mi>l</mi><mi>l</mi></mrow></munder><mo stretchy="false">|</mo></mstyle><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>,</mo><mi>n</mi></mrow></msub><mo>-</mo><mi>r</mi><mi>e</mi><mi>a</mi><mi>l</mi><msub><mrow></mrow><mrow><mi>u</mi><mo>,</mo><mi>n</mi></mrow></msub><mo stretchy="false">|</mo></mrow><mrow><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">其中,下标<i>u</i>,<i>n</i>代表目标用户<i>U</i><sub><i>u</i></sub>评分的目标项目<i>n</i>,下标<i>u</i>,<i>all</i>代表目标用户<i>U</i><sub><i>u</i></sub>的所有预测评分项目集,<i>P</i><sub><i>u</i></sub>,<i>n</i>代表目标用户<i>U</i><sub><i>u</i></sub>对目标项目<i>n</i>的预测评分,<i>real</i><sub><i>u</i></sub>,<i>n</i>代表目标用户<i>U</i><sub><i>u</i></sub>对目标项目<i>n</i>在测试集中的真实评分,<i>all</i>代表测试集中目标用户<i>U</i><sub><i>u</i></sub>的所有评分数量。</p>
                </div>
                <h4 class="anchor-tag" id="134" name="134">4.3 实验结果对比</h4>
                <div class="p1">
                    <p id="135">本文对比实验如下所示:</p>
                </div>
                <div class="p1">
                    <p id="136">1)纵向对比:通过ACoNN和DeepCoNN模型验证融合注意力机制对推荐性能的提升。</p>
                </div>
                <div class="p1">
                    <p id="137">2)横向对比:ACoNN、概率矩阵分解算法(PMF)、文档主题生成算法(LDA)<citation id="227" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、协同过滤推荐算法(CF)。其中,LDA通过获取用户的偏好主题,在推荐过程中引入偏好主题,对用户推荐包含偏好主题的项目,从而达到最终的推荐效果<citation id="228" type="reference"><link href="211" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。通过以上基准方法的对比,验证基于深度学习对推荐性能的提升。</p>
                </div>
                <div class="p1">
                    <p id="138">实验相关参数设定为:神经网络模型以经验为主进行参数设置,并进行多次实验得到最优参数。其中,词嵌入模型维度为300,学习率初始值设定为0.001,卷积核数量为100,用户特征维度为50,项目特征维度为50,滑动词窗口大小为3,模型训练批尺寸为100,Drop-out参数设定为默认值0.5。实验结果如表1和表2所示。</p>
                </div>
                <div class="area_img" id="139">
                    <p class="img_tit"><b>表1 ADM 数据集实验结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="139" border="1"><tr><td><br />算法</td><td><i>RMSE</i></td><td><i>MAE</i></td></tr><tr><td><br />ACoNN</td><td>0.862 80</td><td>0.626 81</td></tr><tr><td><br />DeepCoNN</td><td>0.885 22</td><td>0.633 80</td></tr><tr><td><br />PMF</td><td>0.922 17</td><td>0.659 64</td></tr><tr><td><br />LDA</td><td>0.915 22</td><td>0.650 23</td></tr><tr><td><br />CF</td><td>0.909 25</td><td>0.640 75</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="140">
                    <p class="img_tit"><b>表2 AMT 数据集实验结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="140" border="1"><tr><td><br />算法</td><td><i>RMSE</i></td><td><i>MAE</i></td></tr><tr><td><br />ACoNN</td><td>0.975 31</td><td>0.703 93</td></tr><tr><td><br />DeepCoNN</td><td>0.998 64</td><td>0.726 86</td></tr><tr><td><br />PMF</td><td>1.123 27</td><td>0.921 02</td></tr><tr><td><br />LDA</td><td>1.113 05</td><td>0.887 46</td></tr><tr><td><br />CF</td><td>1.064 72</td><td>0.845 13</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="141">由表1和表2可以看出:</p>
                </div>
                <div class="p1">
                    <p id="142">1)纵向对比:在ADM 数据集中,ACoNN算法的<i>RSME</i>和<i>MAE</i>分别比DeepCoNN算法低0.022 42和0.006 99;在AMT数据集中,ACoNN算法的<i>RSME</i>和<i>MAE</i>分别比DeepCoNN算法低0.023 33和0.022 93。</p>
                </div>
                <div class="p1">
                    <p id="143">2)横向对比:在ADM 数据集中,ACoNN算法的<i>RSME</i>和<i>MAE</i>均最低,DeepCoNN算法其次,其他3种对比算法较差;AMT数据集中的结论与Amazon Digital Music 数据集的结论相同。</p>
                </div>
                <div class="p1">
                    <p id="144">综上,基于深度学习的算法推荐效果较好,而ACoNN算法引入注意力机制,其指标比DeepCoNN算法提升2%以上。</p>
                </div>
                <div class="p1">
                    <p id="145">在实验中,所有算法在ADM数据集中的表现优于AMT数据集。这是因为AMT数据集内容更丰富(数据集含用户数量以及项目数量更多),数据量更大(评价数量提升262%),导致其准确度下降。</p>
                </div>
                <div class="p1">
                    <p id="146">对比实验在一定程度上表明,深度学习能提高传统推荐算法对特征提取和利用的能力从而提升推荐系统的性能。同时,本文提出的基于注意力机制的改进也有效提升推荐准确性。</p>
                </div>
                <h3 id="147" name="147" class="anchor-tag">5 结束语</h3>
                <div class="p1">
                    <p id="148">本文对DeepCoNN模型进行改进,设计融合注意力机制的评论文本深度建模方法,并将其用于推荐系统。实验结果表明,相比PMF、LD和CF算法,该方法采用深度模型,能有效提升推荐性能。同时,本文方法引入注意力机制,其推荐结果优于DeepCoNN算法。但是本文方法依赖于词嵌入模型的训练语料库,扩展难度较大,并且神经网络存在可解释性不足的问题,因此下一步将对此展开研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="183">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXHK201302128&amp;v=MTg0MzQ1SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckZ5L2hWYnZOTWpYRFpiRzRIOUxNclk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 韩路.协同过滤推荐算法的研究[J].无线互联科技,2013(2):160.
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXWL201413086&amp;v=MTk1NDZPZVplUnJGeS9oVmJ2Tk1UWGNZckc0SDlYTnJJOU5Zb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 汪静.协同过滤推荐算法研究综述[J].中国新通信,2014(13):111-113.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201408007&amp;v=MTAyNDNVUkxPZVplUnJGeS9oVmJ2TktEN1liTEc0SDlYTXA0OUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 冷亚军,陆青,梁昌勇.协同过滤推荐技术综述[J].模式识别与人工智能,2014,27(8):720-734.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep content-based music recommendation">

                                <b>[4]</b> DIELEMAN S,SCHRAUWEN B.Deep content-based music recommendation[C]//Proceedings of International Conference on Neural Information Processing Systems.[S.l.]:Neural Information Processing Systems,Inc.,2013:2643-2651.
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A multi-view deep learning approach for cross domain user modeling in recommendation systems">

                                <b>[5]</b> ELKAHKY A M,SONG Yang,HE Xiaodong.A multi-view deep learning approach for cross domain user modeling in recommendation systems[C]//Proceedings of the 24th International Conference on World Wide Web.New York,USA:ACM Press,2015:278-288.
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint deep modeling of users and items using reviews for recommendation">

                                <b>[6]</b> ZHENG Lei,NOROOZI V,YU P S.Joint deep modeling of users and items using reviews for recommendation[C]//Proceedings of the 10th ACM International Conference on Web Search and Data Mining.New York,USA:ACM Press,2017:425-434.
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recurrent models of visual attention">

                                <b>[7]</b> MNIH V,HEESS N,GRAVES A,et al.Recurrent models of visual attention[C]//Proceedings of International Conference on Neural Information Processing Systems.[S.l.]:Neural Information Processing Systems,Inc.,2014:2204-2212.
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">

                                <b>[8]</b> BAHDANAU D,CHO K,BENGIO Y.Neural machine translation by jointly learning to align and translate[EB/OL].[2018-04-01].https://arxiv.org/abs/1409.0473.
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Applying Deep Learning to Answer Selection:A Study and an Open Task">

                                <b>[9]</b> FENG Minwei,XIANG Bing,GLASS M R,et al.Applying deep learning to answer selection:a study and an open task[C]//Proceedings of 2015 IEEE Workshop on Automatic Speech Recognition and Understanding.Washington D.C.,USA:IEEE Press,2015:813-820.
                            </a>
                        </p>
                        <p id="201">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ABCNN:Attention-Based Convolutional Neural Network for Modeling Sentence Pairs">

                                <b>[10]</b> YIN Wenpeng,SCHÜTZE H,XIANG Bing,et al.ABCNN:attention-based convolutional neural network for modeling sentence pairs[J].Transactions of the Association for Computational Linguistics,2016(4):259-272.
                            </a>
                        </p>
                        <p id="203">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hashtag recommendation using attention-based convolutional neural network">

                                <b>[11]</b> GONG Yuyun,ZHANG Qi.Hashtag recommendation using attention-based convolutional neural network[C]//Proceedings of International Joint Conference on Artificial Intelligence.[S.l.]:AAAI Press,2016:2782-2788.
                            </a>
                        </p>
                        <p id="205">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dynamic attention deep model for article recommendation by learning human editors&amp;#39;&amp;#39; demonstration">

                                <b>[12]</b> WANG Xuejian,YU Lantao,REN Kan,et al.Dynamic attention deep model for article recommendation by learning human editors’demonstration[C]//Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York,USA:ACM Press,2017:2051-2059.
                            </a>
                        </p>
                        <p id="207">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201807011&amp;v=MDYyNDZHNEg5bk1xSTlFWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnkvaFZidk5MejdCZHI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 黄立威,江碧涛,吕守业,等.基于深度学习的推荐系统研究综述[J].计算机学报,2018,41(7):191-219.
                            </a>
                        </p>
                        <p id="209">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Latent Dirichlet allocation">

                                <b>[14]</b> BLEI D M,NG A Y,JORDAN M I.Latent Dirichlet allocation[J].Machine Learning Research Archive,2003,3:993-1022.
                            </a>
                        </p>
                        <p id="211">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hidden factors and hidden topics:understanding rating dimensions with review text">

                                <b>[15]</b> MCAULEY J,LESKOVEC J.Hidden factors and hidden topics:understanding rating dimensions with review text[C]//Proceedings of the 7th ACM Conference on Recommender Systems.New York,ACM Press,2013:165-172.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201909028" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201909028&amp;v=MDU5MzQvaFZidk5MejdCYmJHNEg5ak1wbzlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cEJVZU4zZUZ4TTFMY3grWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
