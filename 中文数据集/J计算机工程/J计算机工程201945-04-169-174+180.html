<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130603638868750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201904029%26RESULT%3d1%26SIGN%3d7kkr1eaO%252fI0KSjnaFQJT5glAoys%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201904029&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201904029&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201904029&amp;v=MDUzNDI3QmJiRzRIOWpNcTQ5SGJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L25VNzdCTHo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="2 多样化特征卷积神经网络 ">2 多样化特征卷积神经网络</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="2.1 特征计算">2.1 特征计算</a></li>
                                                <li><a href="#59" data-title="2.2 特征构建">2.2 特征构建</a></li>
                                                <li><a href="#72" data-title="2.3 网络模型">2.3 网络模型</a></li>
                                                <li><a href="#102" data-title="2.4 模型训练">2.4 模型训练</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#114" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#118" data-title="3.1 参数设置">3.1 参数设置</a></li>
                                                <li><a href="#121" data-title="3.2 实验模型">3.2 实验模型</a></li>
                                                <li><a href="#129" data-title="3.3 结果分析">3.3 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#140" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="&lt;b&gt;图1 多样化特征卷积神经网络结构&lt;/b&gt;"><b>图1 多样化特征卷积神经网络结构</b></a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;图2 拼接操作输入矩阵&lt;/b&gt;"><b>图2 拼接操作输入矩阵</b></a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;图3 运算操作输入矩阵&lt;/b&gt;"><b>图3 运算操作输入矩阵</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;图4 卷积操作&lt;/b&gt;"><b>图4 卷积操作</b></a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;表1 实验使用的数据集&lt;/b&gt;"><b>表1 实验使用的数据集</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;表2 参数设置&lt;/b&gt;"><b>表2 参数设置</b></a></li>
                                                <li><a href="#171" data-title="表3 不同模型的情感分类结果对比">表3 不同模型的情感分类结果对比</a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;图5 2种模型在不同数据集上的召回率对比&lt;/b&gt;"><b>图5 2种模型在不同数据集上的召回率对比</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;图6 3种模型在微博语料数据集上的F值对比&lt;/b&gt;"><b>图6 3种模型在微博语料数据集上的F值对比</b></a></li>
                                                <li><a href="#137" data-title="&lt;b&gt;图7 2种模型在COAE2014数据集上的召回率对比&lt;/b&gt;"><b>图7 2种模型在COAE2014数据集上的召回率对比</b></a></li>
                                                <li><a href="#138" data-title="&lt;b&gt;图8 2种模型在微博语料数据集上的召回率对比&lt;/b&gt;"><b>图8 2种模型在微博语料数据集上的召回率对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" PANG B, LEE L.Opinion mining and sentiment analysis[J].Foundations and Trends in Information Retrieval, 2008, 2 (1/2) :1-135." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Opinion mining and sentiment analysis">
                                        <b>[1]</b>
                                         PANG B, LEE L.Opinion mining and sentiment analysis[J].Foundations and Trends in Information Retrieval, 2008, 2 (1/2) :1-135.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" HU M, LIU B.Mining and summarizing customer reviews[C]//Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM Press, 2004:168-177." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mining and summarizing customer reviews">
                                        <b>[2]</b>
                                         HU M, LIU B.Mining and summarizing customer reviews[C]//Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM Press, 2004:168-177.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 王仲远, 程健鹏, 王海勋, 等.短文本理解研究[J].计算机研究与发展, 2016, 53 (2) :262-269." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201602004&amp;v=MDYzMjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L25VNzdBTHl2U2RMRzRIOWZNclk5RllJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         王仲远, 程健鹏, 王海勋, 等.短文本理解研究[J].计算机研究与发展, 2016, 53 (2) :262-269.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" JOSHI A, BALAMURALI A R, BHATTACHARYYA P, et al.C-Feel-It:a sentiment analyzer for micro-blogs[C]//Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:Human Language Tech-nologies:Systems Demonstrations.Stroudsburg, USA:Association for Computational Linguistics, 2011:127-132." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=C-Feel-It:a sentiment analyzer for micro-blogs">
                                        <b>[4]</b>
                                         JOSHI A, BALAMURALI A R, BHATTACHARYYA P, et al.C-Feel-It:a sentiment analyzer for micro-blogs[C]//Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:Human Language Tech-nologies:Systems Demonstrations.Stroudsburg, USA:Association for Computational Linguistics, 2011:127-132.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" CHESLEY P, VINCENT B, XU L, et al.Using verbs and adjectives to automatically classify blog sentiment[J].Training, 2006, 580 (263) :233-235." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using verbs and adjectives to automatically classify blog sentiment">
                                        <b>[5]</b>
                                         CHESLEY P, VINCENT B, XU L, et al.Using verbs and adjectives to automatically classify blog sentiment[J].Training, 2006, 580 (263) :233-235.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     BOIY E, MOENS M F.A machine learning approach to sentiment analysis in multilingual Web texts[J].Information Retrieval, 2009, 12 (5) :526-558.</a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" KIM Y.Convolutional neural networks for sentence classification[C]//Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:Association for Computational Linguistics, 2014:1746-1751." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">
                                        <b>[7]</b>
                                         KIM Y.Convolutional neural networks for sentence classification[C]//Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:Association for Computational Linguistics, 2014:1746-1751.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" WANG X, LIU Y, SUN C, et al.Predicting polarities of Tweets by composing word embeddings with long short-term memory[C]//Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg, USA:Association for Computational Linguistics, 2015:1343-1353." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Predicting polarities of tweets by composing word embeddings with long short-term memory">
                                        <b>[8]</b>
                                         WANG X, LIU Y, SUN C, et al.Predicting polarities of Tweets by composing word embeddings with long short-term memory[C]//Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg, USA:Association for Computational Linguistics, 2015:1343-1353.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" QIAN Q, HUANG M, ZHU X.Linguistically regularized LSTMs for sentiment classification[C]//Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:Association for Computa-tional Linguistics, 2017:1679-1689." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Linguistically regularized lstms for sentiment classification">
                                        <b>[9]</b>
                                         QIAN Q, HUANG M, ZHU X.Linguistically regularized LSTMs for sentiment classification[C]//Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:Association for Computa-tional Linguistics, 2017:1679-1689.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 刘龙飞, 杨亮, 张绍武, 等.基于卷积神经网络的微博情感倾向性分析[J].中文信息学报, 2015, 29 (6) :159-165." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201506022&amp;v=MjI0MDg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeS9uVTc3QUtDallmYkc0SDlUTXFZOUhab1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         刘龙飞, 杨亮, 张绍武, 等.基于卷积神经网络的微博情感倾向性分析[J].中文信息学报, 2015, 29 (6) :159-165.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 陈钊, 徐睿峰, 桂林, 等.结合卷积神经网络和词语情感序列特征的中文情感分析[J].中文信息学报, 2015, 29 (6) :172-178." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201506024&amp;v=MDEwODRmYkc0SDlUTXFZOUhZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeS9uVTc3QUtDalk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         陈钊, 徐睿峰, 桂林, 等.结合卷积神经网络和词语情感序列特征的中文情感分析[J].中文信息学报, 2015, 29 (6) :172-178.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 何炎祥, 孙松涛, 牛菲菲, 等.用于微博情感分析的一种情感语义增强的深度学习模型[J].计算机学报, 2016, 40 (4) :773-790." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201704001&amp;v=MTA3NDNCZHJHNEg5Yk1xNDlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkvblU3N0FMejc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         何炎祥, 孙松涛, 牛菲菲, 等.用于微博情感分析的一种情感语义增强的深度学习模型[J].计算机学报, 2016, 40 (4) :773-790.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" BOIY E, MOENS M F.A machine learning approach to sentiment analysis in multilingual Web texts[J].Information Retrieval, 2009, 12 (5) :526-558." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003567381&amp;v=MTYxMTN1ZHRGQzdsVkwzSUlWWT1OajdCYXJPNEh0SFBxb2xDWitNT1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVi&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         BOIY E, MOENS M F.A machine learning approach to sentiment analysis in multilingual Web texts[J].Information Retrieval, 2009, 12 (5) :526-558.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" 张志琳, 宗成庆.基于多样化特征的中文微博情感分类方法研究[J].中文信息学报, 2015, 29 (4) :134-143." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201504021&amp;v=MDQyMDc0SDlUTXE0OUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeS9uVTc3QUtDallmYkc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         张志琳, 宗成庆.基于多样化特征的中文微博情感分类方法研究[J].中文信息学报, 2015, 29 (4) :134-143.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[C]//Proceedings of the 27th Advances in Neural Information Processing Systems.Cambridge, USA:MIT Press, 2013:3111-3119." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distributed representations of words and phrases and their compositionality">
                                        <b>[15]</b>
                                         MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[C]//Proceedings of the 27th Advances in Neural Information Processing Systems.Cambridge, USA:MIT Press, 2013:3111-3119.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" COLLOBERT R, WESTON J, BOTTOU L, et al.Natural language processing (almost) from scratch[J].Journal of Machine Learning Research, 2011, 12 (8) :2493-2537" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Natural language processing (almost) from scratch">
                                        <b>[16]</b>
                                         COLLOBERT R, WESTON J, BOTTOU L, et al.Natural language processing (almost) from scratch[J].Journal of Machine Learning Research, 2011, 12 (8) :2493-2537
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" ZEILER M D.ADADELTA:an adaptive learning rate method[EB/OL].[2018-01-05].https://arxiv.org/pdf/1212.5701.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ADADELTA:an adaptive learning rate method">
                                        <b>[17]</b>
                                         ZEILER M D.ADADELTA:an adaptive learning rate method[EB/OL].[2018-01-05].https://arxiv.org/pdf/1212.5701.pdf.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(04),169-174+180 DOI:10.19678/j.issn.1000-3428.0050338            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于多样化特征卷积神经网络的情感分析</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%94%A1%E6%9E%97%E6%A3%AE&amp;code=38707677&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蔡林森</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BD%AD%E8%B6%85&amp;code=32422199&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">彭超</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%80%9D%E8%BF%9C&amp;code=38707676&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈思远</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E5%85%B0%E8%8B%B1&amp;code=38707678&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭兰英</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%9C%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2%E4%B8%8A%E6%B5%B7%E5%B8%82%E9%AB%98%E5%8F%AF%E4%BF%A1%E8%AE%A1%E7%AE%97%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0092795&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华东师范大学计算机科学与软件工程学院上海市高可信计算重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>深度网络模型在微博情感倾向性分析过程中难以有效利用情感特征信息, 为此, 提出一种基于多样化特征信息的卷积神经网络 (MF-CNN) 模型。结合词语多样化的抽象特征和2种网络输入矩阵计算方法, 利用句中的情感信息, 以优化情感分类效果。在COAE2014和微博语料数据集上进行文本情感分析, 结果表明, MF-CNN模型的情感分类效果优于传统的分类器和深度卷积神经网络模型。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感分析;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自然语言处理;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    蔡林森 (1992—) , 男, 硕士研究生, 主研方向为自然语言处理、情感分析;;
                                </span>
                                <span>
                                    彭超, 副教授、博士;;
                                </span>
                                <span>
                                    陈思远, 硕士研究生。;
                                </span>
                                <span>
                                    郭兰英, 硕士研究生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61232006);</span>
                                <span>上海市自然科学基金 (14ZR1412400);</span>
                    </p>
            </div>
                    <h1><b>Sentiment Analysis Based on Multiple Features Convolutional Neural Networks</b></h1>
                    <h2>
                    <span>CAI Linsen</span>
                    <span>PENG Chao</span>
                    <span>CHEN Siyuan</span>
                    <span>GUO Lanying</span>
            </h2>
                    <h2>
                    <span>Shanghai Key Laboratory of Trustworthy Computing, School of Computer Science and Software Engineering, East China Normal University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In the task of Micro-Blog sentiment analysis, the deep neural-based models are difficult to make full use of the sentiment information.To solve this problem, a Multiple Features Convolutional Neural Networks (MF-CNN) model is proposed.The emotional information in sentences is effectively utilized by combining the abstract features of words and two kinds of calculation methods of neural model input matrix, and then the sentiment classification result is optimized.The sentiment analysis is carried out on COAE2014 and Micro-Blog text data set, and the results show that the classification effect of MF-CNN model is better than that of traditional classifier and deep Convolutional Neural Network (CNN) model.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sentiment%20analysis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sentiment analysis;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sentiment%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sentiment feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Neural%20Network%20(CNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Neural Network (CNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=natural%20language%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">natural language processing;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-29</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="38">在人们的日常生活中, 微博已成为最重要的社交平台之一, 如何从微博中获取有用的情感信息已成为学术界和工业界广泛关注的问题<citation id="142" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。情感分析通过对文本上下文信息的分析、处理、归纳来挖掘情感极性, 是自然语言处理领域的研究热点之一<citation id="143" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。不同于普通文本分类, 情感分析文本包含独特的情感特征信息, 如何对这些信息进行充分挖掘是情感分析的关键<citation id="144" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="39">传统文本分类技术主要分为基于规则的方法和基于机器学习的方法2类。基于规则的方法主要通过对文本信息进行分析和学习, 以获取特定的分类规则, 从而对文本进行分类<citation id="146" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。基于机器学习的方法通过人工方式标注一部分样本, 构造训练数据集, 使用机器学习算法从该数据集中学习分类模型, 然后对未知标签的样本进行类别预测, 以此实现文本的自动分类<citation id="145" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="40">近年来, 由于深度网络模型具有不依赖于复杂的特征工程、可充分挖掘文本的特征信息等特点, 深度学习技术越来越多地应用于情感分析任务中。文献<citation id="147" type="reference">[<a class="sup">7</a>]</citation>提出一种使用卷积神经网络 (Convolution Neural Networks, CNN) 对电影评论进行情感倾向性分析的深度学习模型。文献<citation id="148" type="reference">[<a class="sup">8</a>]</citation>基于长短期记忆 (Long-Short Term Memory, LSTM) 网络提出一种文本情感分析网络模型。文献<citation id="149" type="reference">[<a class="sup">9</a>]</citation>利用文本中的情感词、否定词等, 构造一种LSTM情感分类模型。文献<citation id="150" type="reference">[<a class="sup">10</a>]</citation>基于CNN提出一种结合不同输入粒度的深度网络模型, 用于微博文本情感分析。为了更加充分地利用文本中的情感信息, 文献<citation id="151" type="reference">[<a class="sup">11</a>]</citation>将文本中的情感词作为序列特征加入CNN。文献<citation id="152" type="reference">[<a class="sup">12</a>]</citation>基于微博文本中的情感符号构建情感空间的特征表示。这些深度学习方法能充分利用文本中的情感特征, 有效识别情感极性。</p>
                </div>
                <div class="p1">
                    <p id="41">基于上述研究成果, 本文提出一种结合多样化特征的卷积神经网络 (Multiple Features Convolution Neural Networks, MF-CNN) 模型。将词语按不同的情感得分和权重得分映射为一个多维的连续值向量, 从而把将词语的情感信息和权重信息有效地应用到情感分类任务中。通过2种不同的CNN输入层计算方法来拓展网络模型, 以挖掘更多隐藏信息。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag">1 相关工作</h3>
                <div class="p1">
                    <p id="43">文本情感分析主要通过对内容信息进行特征挖掘和学习来判断其情感极性, 是关联情感的文本分类任务。文献<citation id="153" type="reference">[<a class="sup">5</a>]</citation>利用动词和形容词构建情感模板来获取文本的情感信息, 实现情感分类。文献<citation id="154" type="reference">[<a class="sup">4</a>]</citation>通过人工标注的Twitter情感信息, 遍历文本中的情感得分来判断情感极性。这些基于规则的方法在情感分析任务中通过人工整理的词典和规则, 自动获取情感极性。但是, 这类方法需要专门针对语料构造特定的规则集合, 人工成本较高, 且无法识别规则之外的文本情感信息。基于传统机器学习方法, 文献<citation id="155" type="reference">[<a class="sup">13</a>]</citation>通过训练多种机器学习模型, 将其级联为最终的情感分类模型, 以解决多语言的情感分析问题。该方法通过不同模型的组合, 有效地弥补了单一算法的不足。级联的方式不仅可以有效提升情感分析的正确率, 同时也大大降低了人工成本。文献<citation id="156" type="reference">[<a class="sup">14</a>]</citation>利用一种结合多样化特征的支持向量机 (Support Vector Machine, SVM) 分类模型来完成微博文本情感分类任务。该模型对不同类型的词语进行特征表示, 能够更加充分地利用句中的情感信息, 提高情感分类的效果。</p>
                </div>
                <div class="p1">
                    <p id="44">基于深度学习的情感分类方法, 以词为单位将句子表示为一个词序列, 并将其映射为一个多维向量来构造词向量集合, 通过深度神经网络提取文本中的特征信息, 自动实现情感倾向性判别。现有的词语向量化方法中, 文献<citation id="157" type="reference">[<a class="sup">15</a>]</citation>利用连续词袋 (Continuous Bag of Words, CBOW) 模型和Skip-gram模型计算词向量, 能够很好地度量词与词之间的相似性。在情感分析任务中, 基于深度学习的网络模型主要有CNN模型和LSTM网络模型2种。基于LSTM的网络模型可接收文本的序列化输入, 每一个神经单元的运算都结合上一时间步神经单元的隐藏层输出, 有效地保留了句子之间的依赖关系。文献<citation id="158" type="reference">[<a class="sup">9</a>]</citation>利用LSTM网络和文本的词向量信息构造Tweets短文本情感分析模型。基于CNN的情感分类模型能接收文本的平行化输入, 将矩阵一次性输入到网络中, 可有效地减少模型的训练时间。文献<citation id="159" type="reference">[<a class="sup">10</a>]</citation>将词向量和字向量特征信息作为CNN的输入, 从不同粒度的信息中, 更加充分地挖掘微博短文本的情感信息。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag">2 多样化特征卷积神经网络</h3>
                <div class="p1">
                    <p id="46">为了更好地利用文本中的词语和情感信息, 本文基于CNN提出MF-CNN模型, 如图1所示。该模型能够将情感分析任务中有用的特征与CNN结合, 提高模型的分类效果。</p>
                </div>
                <div class="area_img" id="47">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904029_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 多样化特征卷积神经网络结构" src="Detail/GetImg?filename=images/JSJC201904029_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 多样化特征卷积神经网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904029_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="48" name="48">2.1 特征计算</h4>
                <div class="p1">
                    <p id="49">情感分析的任务是根据句中的词语信息, 尤其是情感词信息, 正确判断句子的情感极性。例如句子“我喜欢粉色的奥迪”, 句中“喜欢”一词带有很强的情感色彩, 该词对整个句子的情感极性起着决定性作用。为了充分利用情感词信息, 根据其在数据集内不同极性的句子中出现的频率来计算情感得分, 构造情感向量特征空间。本文使用Hownet情感词典, 同时, 由于微博文本包含大量网络用语, 因此本文在情感词典中手动加入“坑爹”“奇葩”“给力”等带有感情色彩的词语。通过计算情感词在不同数据集上出现的文档频数来计算情感得分:</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>F</mi><mi>r</mi><mi>e</mi><mi>q</mi><mo stretchy="false"> (</mo><mi>s</mi><mi>e</mi><mi>n</mi><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi>α</mi><mo>×</mo><mi>Ν</mi><mi>Τ</mi><msub><mrow></mrow><mrow><mi>s</mi><mi>e</mi><mi>n</mi><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>-</mo><mi>β</mi><mo>×</mo><mi>Ν</mi><mi>F</mi><msub><mrow></mrow><mrow><mi>s</mi><mi>e</mi><mi>n</mi><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false"> (</mo><mi>s</mi><mi>e</mi><mi>n</mi><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51"><image href="images/JSJC201904029_052.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>F</mi><mi>r</mi><mi>e</mi><mi>q</mi><mo stretchy="false"> (</mo><mi>s</mi><mi>e</mi><mi>n</mi><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>F</mi><mi>r</mi><mi>e</mi><mi>q</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub></mrow><mrow><mi>F</mi><mi>r</mi><mi>e</mi><mi>q</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo>-</mo><mi>F</mi><mi>r</mi><mi>e</mi><mi>q</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub></mrow></mfrac><mo>×</mo><mi>θ</mi></mrow></math></mathml><image href="images/JSJC201904029_054.jpg" type="" display="inline" placement="inline"><alt></alt></image> (2) </p>
                </div>
                <div class="p1">
                    <p id="55">其中, sent<sub>i</sub>为情感词典的第i个情感词, NT<sub>sent<sub>i</sub></sub>为包含情感词sent<sub>i</sub>的积极情感数据样本个数, NF<sub>sent<sub>i</sub></sub>为包含情感词sent<sub>i</sub>的消极情感数据样本个数, Freq (sent<sub>i</sub>) 为情感词sent<sub>i</sub>在数据集上的文档频数。Freq<sub><i>min</i></sub>为最小文档频数, Freq<sub><i>max</i></sub>为最大文档频数, Score (sent<sub>i</sub>) 为包含情感词sent<sub>i</sub>的情感得分。α、β、θ为可调参数, α和β调整不同极性数据集文档频数的重要程度, θ控制情感得分的阈值。</p>
                </div>
                <div class="p1">
                    <p id="56">每个普通词条对应一个权重得分, 计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="57">Weight (w<sub>i</sub>) =⎣α×NT<sub>w<sub>i</sub></sub>-β×NF<sub>w<sub>i</sub></sub>」      (3) </p>
                </div>
                <div class="p1">
                    <p id="58">其中, NT<sub>w<sub>i</sub></sub>为包含普通词条w<sub>i</sub>的积极情感数据集样本个数, NF<sub>w<sub>i</sub></sub>为包含普通词条w<sub>i</sub>的消极情感数据集样本个数, Weight (w<sub>i</sub>) 为普通词条w<sub>i</sub>的权重得分。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59">2.2 特征构建</h4>
                <div class="p1">
                    <p id="60">由于CNN需要一次性接收文本的平行化输入, 因此本文使用相同维度的向量来表示情感词的情感得分和普通词条的权重得分。对每一个情感得分值, 都用一个多维的连续值向量来表示:</p>
                </div>
                <div class="p1">
                    <p id="61"><b><i>es</i></b><sub><i>i</i></sub>=[<i>e</i><sub>1</sub>, <i>e</i><sub>2</sub>, …, <i>e</i><sub><i>p</i></sub>]      (4) </p>
                </div>
                <div class="p1">
                    <p id="62">其中, <b><i>es</i></b><sub><i>i</i></sub>∈<image href="images/JSJC201904029_063.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>p</i></sup>为情感得分为<i>i</i>的向量表示。数据集中的所有情感词均可得到情感得分向量集合<b><i>ES</i></b>∈<image href="images/JSJC201904029_064.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mrow><mi>p</mi><mo>×</mo><mrow><mo>|</mo><mrow><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>|</mo></mrow></mrow></msup><mo>, </mo><mrow><mo>|</mo><mrow><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>|</mo></mrow></mrow></math></mathml>为情感得分集合的大小。</p>
                </div>
                <div class="p1">
                    <p id="66">用同样的方法将每一个普通词条的权重得分映射为一个维度相同的多维连续值向量:</p>
                </div>
                <div class="p1">
                    <p id="67"><b><i>ew</i></b><sub><i>i</i></sub>=[<i>e</i><sub>1</sub>, <i>e</i><sub>2</sub>, …, <i>e</i><sub><i>p</i></sub>]      (5) </p>
                </div>
                <div class="p1">
                    <p id="68">其中, <b><i>ew</i></b><sub><i>i</i></sub>∈<image href="images/JSJC201904029_069.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>p</i></sup>为权重得分为<i>i</i>的向量表示。对于数据集中的所有词条, 均可得到普通词条权重向量集合<b><i>EW</i></b>∈<image href="images/JSJC201904029_070.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mrow><mi>p</mi><mo>×</mo><mrow><mo>|</mo><mrow><mi>W</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi></mrow><mo>|</mo></mrow></mrow></msup><mo>, </mo><mrow><mo>|</mo><mrow><mi>W</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi></mrow><mo>|</mo></mrow></mrow></math></mathml>为权重得分集合的大小。</p>
                </div>
                <h4 class="anchor-tag" id="72" name="72">2.3 网络模型</h4>
                <div class="p1">
                    <p id="73">对于长度为n的句子<b><i>s</i></b>={<i>w</i><sub>1</sub>, <i>w</i><sub>2</sub>, …, <i>w</i><sub><i>n</i></sub>}, <i>w</i><sub><i>i</i></sub>为句中第<i>i</i>个词条。神经网络需接收文本词语的向量化输入以提取句子的特征信息, 本文以词为单位将句子表示为一个由词向量组成的二维矩阵:</p>
                </div>
                <div class="p1">
                    <p id="74"><b><i>e</i></b><sub>1:<i>n</i></sub>=<b><i>e</i></b><sub>1</sub>♁<b><i>e</i></b><sub>2</sub>♁…♁<b><i>e</i></b><sub><i>n</i></sub>      (6) </p>
                </div>
                <div class="p1">
                    <p id="75">其中, <image id="166" type="formula" href="images/JSJC201904029_16600.jpg" display="inline" placement="inline"><alt></alt></image>为拼接操作, <b><i>e</i></b><sub>1:<i>n</i></sub>∈<image href="images/JSJC201904029_076.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>n</i>×<i>m</i></sup>, <i>m</i>为词向量维度。<b><i>e</i></b><sub><i>i</i></sub>为词条<i>w</i><sub><i>i</i></sub>的词向量, 即句子中的每一个词条都映射为一个<i>m</i>维的连续值向量。在CNN的输入层, 本文使用2种不同的矩阵计算方式来验证本文MF-CNN模型的有效性, 2种不同的输入矩阵计算方式如图2、图3所示。</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904029_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 拼接操作输入矩阵" src="Detail/GetImg?filename=images/JSJC201904029_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 拼接操作输入矩阵</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904029_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904029_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 运算操作输入矩阵" src="Detail/GetImg?filename=images/JSJC201904029_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 运算操作输入矩阵</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904029_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="79">在图2中, 将不同的向量拼接成网络词语的向量表示。若该词为情感词, 向量的计算方式如式 (7) 所示, 若为普通词, 计算方式如式 (8) 所示。</p>
                </div>
                <div class="area_img" id="167">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201904029_16700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="168">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201904029_16800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="82">为了更充分地平衡词向量和特征向量对词语的影响程度, 使用权重矩阵来控制其输入, 如式 (9) 、式 (10) 所示。</p>
                </div>
                <div class="area_img" id="169">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201904029_16900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="170">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201904029_17000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="85">其中, <b><i>R</i></b>∈<image href="images/JSJC201904029_086.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>m</i>×<i>p</i></sup>为可调权重矩阵, 通过<b><i>R</i></b>可控制特征向量的分量输入, ⊙表示矩阵相乘。</p>
                </div>
                <div class="p1">
                    <p id="87">CNN可接收句子的平行化输入, 对于长度为<i>h</i>的卷积窗口, 通过卷积核对输入矩阵<b><i>x</i></b><sub>1:<i>n</i></sub>进行卷积操作, 如式 (11) 所示。</p>
                </div>
                <div class="p1">
                    <p id="88"><i>c</i><sub><i>i</i></sub>=<i>f</i> (<b><i>w</i></b>·<b><i>x</i></b><sub><i>i</i>:<i>i</i>+<i>h</i>-1</sub>+<i>b</i>)      (11) </p>
                </div>
                <div class="p1">
                    <p id="89">其中, <b><i>w</i></b>∈<image href="images/JSJC201904029_090.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>h</i>×<i>d</i></sup>为卷积核权重, <i>d</i>为<b><i>x</i></b><sub><i>i</i></sub>的维度, <i>b</i>∈<image href="images/JSJC201904029_091.jpg" type="" display="inline" placement="inline"><alt></alt></image>为偏置, <i>f</i>为激活函数, <b><i>x</i></b><sub><i>i</i>:<i>i</i>+<i>h</i>-1</sub>为一个卷积窗口的词向量矩阵。</p>
                </div>
                <div class="p1">
                    <p id="92">长度为<i>n</i>的句子通过卷积操作可得到卷积后特征向量:</p>
                </div>
                <div class="p1">
                    <p id="93"><b><i>c</i></b>=[<i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>, …, <i>c</i><sub><i>n</i>-<i>h</i>+1</sub>]      (12) </p>
                </div>
                <div class="p1">
                    <p id="94">其中, <b><i>c</i></b>∈<image href="images/JSJC201904029_095.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>n</i>-<i>h</i>+1</sup>。以长度为2的卷积窗口为例, 通过卷积操作可得到如图4所示的卷积特征向量。</p>
                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904029_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 卷积操作" src="Detail/GetImg?filename=images/JSJC201904029_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 卷积操作</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904029_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="97">为了提取句中最重要的特征信息, 本文采用最大池化 (Max-over-time Pooling) <citation id="160" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的方法对卷积后的特征向量进行池化操作, 提取最重要的特征信息, 即<mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>c</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>=</mo><mrow><mi>max</mi></mrow><mo stretchy="false">{</mo><mi mathvariant="bold-italic">c</mi><mo stretchy="false">}</mo></mrow></math></mathml>。从每一个特征向量中提取一个最大值, 对于有m个卷积核的窗口, 得到:</p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">z</mi><mo>=</mo><mo stretchy="false">[</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>c</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>c</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>c</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100">其中, <b><i>z</i></b>∈<image href="images/JSJC201904029_101.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>m</i></sup>为CNN提取得到的特征向量。</p>
                </div>
                <h4 class="anchor-tag" id="102" name="102">2.4 模型训练</h4>
                <div class="p1">
                    <p id="103">通过<i>softmax</i>函数输出分类结果, 如式 (14) 、式 (15) 所示。</p>
                </div>
                <div class="p1">
                    <p id="104">y=softmax (<b><i>W</i></b>·<b><i>X</i></b>+<i>b</i>)      (14) </p>
                </div>
                <div class="p1">
                    <p id="105"><b><i>X</i></b>=<b><i>z</i></b>。 <b><i>r</i></b>      (15) </p>
                </div>
                <div class="p1">
                    <p id="106">其中, <b><i>r</i></b>∈<image href="images/JSJC201904029_107.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>m</i></sup>为下采样层输出的正则项限制, 符号。 表示对应元素相乘。<b><i>W</i></b>∈<image href="images/JSJC201904029_108.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mrow><mrow><mo>|</mo><mi mathvariant="bold-italic">X</mi><mo>|</mo></mrow></mrow></msup></mrow></math></mathml>为全连接层权重矩阵, b∈<image href="images/JSJC201904029_110.jpg" type="" display="inline" placement="inline"><alt></alt></image>为全连接层偏置。使用反向传播算法训练模型, 通过最小化交叉熵来优化模型, 计算过程如式 (16) 所示。</p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mrow><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>D</mi></mrow></munder><mrow></mrow></mstyle></mrow><mtext> </mtext><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>C</mi></mrow></munder><mrow></mrow></mstyle></mrow><mtext> </mtext><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mtext> </mtext><mtext>l</mtext><mtext>b</mtext><mtext> </mtext><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi>θ</mi><mo stretchy="false">∥</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="112">其中, D为训练集数据集合, C为数据的类别集合, y为待分类句子的预测类别, <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow></math></mathml>为实际类别, <i>λ</i>‖<i>θ</i>‖<sup>2</sup>为交叉熵正则项。</p>
                </div>
                <h3 id="114" name="114" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="115">本文使用2014年中文观点倾向性分析评测 (<i>COAE</i>2014) 语料中任务4的数据集以及中文微博语料数据集 (<i>Micro</i>-<i>Blog data</i>) 进行实验。通过与现有研究中取得突破性成果的模型进行对比, 验证本文<i>MF</i>-<i>CNN</i>模型的有效性。从<i>COAE</i>2014数据集中标注6 000条带有极性的数据, 其中, 正面情绪2 864条, 负面情绪3 136条。从不同领域微博语料中爬取6 000条带有极性的文本作为微博语料数据集, 其中, 正面情绪3 574条, 负面情绪2 426条, 微博语料数据保留文本中的表情符号。详细数据如表1所示。</p>
                </div>
                <div class="area_img" id="116">
                    <p class="img_tit"><b>表1 实验使用的数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="116" border="1"><tr><td><br />数据集</td><td>极性</td><td>训练集</td><td>测试集</td></tr><tr><td rowspan="2"><br />COAE2014</td><td><br />积极</td><td>2 284</td><td>580</td></tr><tr><td><br />消极</td><td>2 516</td><td>620</td></tr><tr><td rowspan="2"><br />微博语料</td><td><br />积极</td><td>2 854</td><td>720</td></tr><tr><td><br />消极</td><td>1 946</td><td>480</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="117">本文使用ICTCLAS分词工具对中文数据进行分词, 词向量采用Leipzig Corpora Collection进行初始化, 其维度为300维。对于未登录词, 采用均匀分布<i>U</i> (-0.01, 0.01) 随机初始化词向量。</p>
                </div>
                <h4 class="anchor-tag" id="118" name="118">3.1 参数设置</h4>
                <div class="p1">
                    <p id="119">为了充分考虑不同极性训练数据样本对词语得分的影响, 使得分不偏向于任何一个极性, 本文在计算COAE2014数据集情感词和普通词语得分时, <i>α</i>和<i>β</i>分别取1.2和1.0, 在计算微博语料时, <i>α</i>和<i>β</i>分别取1.2和1.5。取值过大会造成词语映射复杂, 取值过小则无法有效区分不同影响力的词语。在平衡不同极性词语的得分后, <i>θ</i>在2个数据集上的取值都为200, 即固定特征取值的个数为200, 从而有效区分不同极性词语得分并充分考虑对情感极性判别有同等影响力的词语之间的联系。由于词向量包含句子的主要信息, 因此实验中的特征向量维度取值为100。在CNN中, 使用多窗口、多卷积核对输入句子进行卷积操作, 充分挖掘句子的局部特征。窗口大小分别为2、3、4、5, 每种窗口的卷积核个数均为100。为了防止过拟合, 本文使用dropout机制和权重的正则化限制, 其中, 权重限制最大值为3。训练过程采用文献<citation id="161" type="reference">[<a class="sup">17</a>]</citation>的Adadelta更新规则, 详细参数如表2所示。</p>
                </div>
                <div class="area_img" id="120">
                    <p class="img_tit"><b>表2 参数设置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="120" border="1"><tr><td><br />参数</td><td>数值</td></tr><tr><td><br />卷积核窗口大小</td><td>2～5</td></tr><tr><td><br />每种卷积核数量</td><td>100</td></tr><tr><td><br />权重正则限制</td><td>3</td></tr><tr><td><br />Dropout</td><td>0.5</td></tr><tr><td><br />Mini-batch</td><td>32</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="121" name="121">3.2 实验模型</h4>
                <div class="p1">
                    <p id="122">将本文MF-CNN模型与其他在微博文本情感分析研究中取得成果的模型进行对比, 各种模型介绍如下:</p>
                </div>
                <div class="p1">
                    <p id="123">1) MF-CNN-1:本文提出的MF-CNN模型, 其中, 输入矩阵通过词向量和特征向量拼接的方式得到。</p>
                </div>
                <div class="p1">
                    <p id="124">2) MF-CNN-2:本文提出的MF-CNN模型, 其中, 输入矩阵通过词向量和特征向量的矩阵运算方式得到。</p>
                </div>
                <div class="p1">
                    <p id="125">3) SVM<citation id="162" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>:多样化分类特征和SVM分类器相结合的方法。</p>
                </div>
                <div class="p1">
                    <p id="126">4) CNN<citation id="163" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>:未结合特征信息的CNN模型。</p>
                </div>
                <div class="p1">
                    <p id="127">5) WFCNN<citation id="164" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>:结合情感词典的CNN模型, 有效利用了文本中的情感特征信息。</p>
                </div>
                <div class="p1">
                    <p id="128">6) EMCNN<citation id="165" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>:结合表情符号的CNN模型, 充分利用了句中的表情信息。</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129">3.3 结果分析</h4>
                <div class="p1">
                    <p id="130">本文在COAE2014和微博语料数据集上进行6组实验以验证MF-CNN模型的有效性, 准确率 (<i>P</i>) 、召回率 (<i>R</i>) 和综合评价指标 (<i>F</i>) 的对比结果如表3所示, 其中, 黑体数值为最优指标。从表3可以看出, 本文MF-CNN模型在2个数据集上的情感分类结果均优于其他对比实验模型。其中, MF-CNN-2模型在微博积极语料数据集上的分类效果最好, F值达88.86%, 比以往效果最优的EMCNN模型提高1.24%。对比CNN、WFCNN和EMCNN模型可知, 仅使用词向量的CNN模型在2个数据集上的分类效果均不理想。在微博语料数据集上, CNN、WFCNN和EMCNN 3种模型的平均F值分别为82.37%、84.04%和84.56%, 说明在情感分析任务中, 结合情感特征的模型能更好地学习句中的情感倾向。对比加入情感特征的SVM模型和WFCNN模型, 其在COAE2014消极样本上的分类效果差距最大, WFCNN模型的F值相比SVM模型提升0.82%, 说明结合情感特征的CNN模型比传统方法的分类效果更好。</p>
                </div>
                <div class="area_img" id="171">
                                            <p class="img_tit">
                                                表3 不同模型的情感分类结果对比
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904029_17100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201904029_17100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                <p class="img_note">%</p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904029_17100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 不同模型的情感分类结果对比" src="Detail/GetImg?filename=images/JSJC201904029_17100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="132">将本文MF-CNN-1模型和WFCNN模型进行比较, 在不同数据集上的召回率对比如图5所示。从图5可以看出, MF-CNN-1模型的分类召回率除了在微博语料积极样本数据集上略低于WFCNN模型外, 在其他数据集上均优于WFCNN模型, 在消极样本上的分类效果提升尤为明显。结合表3数据可知, 本文MF-CNN-1模型在COAE2014数据集和微博语料数据集2个消极样本上的分类召回率分别为75.81%和84.79%, 比WFCNN模型分别提升3.07%和5.21%。这是因为WFCNN模型在构造情感序列特征时仅对情感词进行特征提取, 忽略了句中权重较大的非情感词, 本文MF-CNN-1模型除了对句中的情感词进行特征向量化之外, 对非情感词也进行了特征提取。由于微博文本中的句子普遍较短, 某些带有强烈感情色彩的句子并不包含情感词, 因此本文将普通词语按权重得分进行向量化操作的方法, 可将句中普通词语的特征信息加入网络模型中, 挖掘句中的隐藏信息, 得到正确的情感分析结果。</p>
                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904029_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 2种模型在不同数据集上的召回率对比" src="Detail/GetImg?filename=images/JSJC201904029_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 2种模型在不同数据集上的召回率对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904029_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="134">在微博语料数据集上, 对比本文MF-CNN模型和EMCNN模型, 结果如图6所示。从图6可以看出, 本文MF-CNN模型在微博语料的积极样本和消极样本数据集上的F值均优于EMCNN模型。其中, 在微博语料消极样本中, MF-CNN-2模型的F值比EMCNN模型提升了1.9%, 说明本文的多样化特征方法在微博文本情感分析任务中具有更好的分类效果。这是由于相比仅使用表情特征的EMCNN模型, 本文MF-CNN-2模型既关注句中的情感词信息, 同时也考虑了普通词语对句子情感信息的影响。MF-CNN-2模型通过控制特征向量的权重矩阵, 调整参数和学习句子的情感信息, 取得更好的分类效果。</p>
                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904029_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 3种模型在微博语料数据集上的F值对比" src="Detail/GetImg?filename=images/JSJC201904029_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 3种模型在微博语料数据集上的F值对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904029_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="136">本文的MF-CNN-1模型和MF-CNN-2模型在不同实验中都取得了较好的分类效果, 但是2个模型在不同数据集上的分类优势各有不同。为了分析MF-CNN-1和MF-CNN-2模型在不同特征维度下的分类性能, 本文采用不同维度的特征向量在COAE2014和微博语料数据集上进行对比实验, 分类召回率对比结果如图7、图8所示。</p>
                </div>
                <div class="area_img" id="137">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904029_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 2种模型在COAE2014数据集上的召回率对比" src="Detail/GetImg?filename=images/JSJC201904029_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 2种模型在COAE2014数据集上的召回率对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904029_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904029_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 2种模型在微博语料数据集上的召回率对比" src="Detail/GetImg?filename=images/JSJC201904029_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图8 2种模型在微博语料数据集上的召回率对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904029_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="139">从图7和图8可以看出, 在特征向量维度小于100时, MF-CNN-1模型和MF-CNN-2模型的分类召回率都呈上升趋势, 表明2个模型都随着特征向量维度的提升而获得更多的特征信息。同时, MF-CNN-2模型的分类效果优于MF-CNN-1模型, 在特征向量维度为10时尤为明显, 说明在特征向量维度较小时, 能通过调整权重矩阵中不同分量元素的值, 使模型学习更多的特征信息, 提升模型的分类效果。当特征向量维度为150时, MF-CNN-1模型在2个数据集上的分类召回率仍有一定的提升, 而MF-CNN-2模型的分类召回率有所下降。当特征向量维度为300时, MF-CNN-2模型的分类召回率下降非常明显, 表明模型在特征向量维度取值较大时会出现严重的过拟合现象。而MF-CNN-1模型的分类召回率虽然有所下降, 但是下降并不明显, 因为在特征向量维度增大的时候, MF-CNN-1模型不会出现严重的过拟合现象。因此, 在特征向量维度取值较小时, MF-CNN-2模型具有更好的分类效果, 而当特征向量维度取值较大时, MF-CNN-1模型能避免出现过拟合现象, 取得更好的分类效果。</p>
                </div>
                <h3 id="140" name="140" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="141">本文提出一种基于多样化特征信息的情感分析模型, 将深度学习中常用的CNN与微博文本情感分析任务中常用的特征信息相结合, 通过计算文本中不同词语的权重对词语进行向量化操作。在COAE2014和微博语料数据集上进行实验, 结果表明, MF-CNN模型在微博积极和消极语料数据集上分类效果最好, F值可达88.86%和83.40%, 分类效果优于SVM、CNN等模型, 验证了MF-CNN模型的有效性。此外, 本文提出2种不同的输入矩阵计算方法。在特征向量维度取值较大时, 2种方法都会出现一定的过拟合现象, MF-CNN-2模型尤为严重。下一步将研究使用更有效的输入矩阵计算方法, 缓解过拟合问题。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Opinion mining and sentiment analysis">

                                <b>[1]</b> PANG B, LEE L.Opinion mining and sentiment analysis[J].Foundations and Trends in Information Retrieval, 2008, 2 (1/2) :1-135.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mining and summarizing customer reviews">

                                <b>[2]</b> HU M, LIU B.Mining and summarizing customer reviews[C]//Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM Press, 2004:168-177.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201602004&amp;v=MTY4NjZHNEg5Zk1yWTlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkvblU3N0FMeXZTZEw=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 王仲远, 程健鹏, 王海勋, 等.短文本理解研究[J].计算机研究与发展, 2016, 53 (2) :262-269.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=C-Feel-It:a sentiment analyzer for micro-blogs">

                                <b>[4]</b> JOSHI A, BALAMURALI A R, BHATTACHARYYA P, et al.C-Feel-It:a sentiment analyzer for micro-blogs[C]//Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:Human Language Tech-nologies:Systems Demonstrations.Stroudsburg, USA:Association for Computational Linguistics, 2011:127-132.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using verbs and adjectives to automatically classify blog sentiment">

                                <b>[5]</b> CHESLEY P, VINCENT B, XU L, et al.Using verbs and adjectives to automatically classify blog sentiment[J].Training, 2006, 580 (263) :233-235.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 BOIY E, MOENS M F.A machine learning approach to sentiment analysis in multilingual Web texts[J].Information Retrieval, 2009, 12 (5) :526-558.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">

                                <b>[7]</b> KIM Y.Convolutional neural networks for sentence classification[C]//Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:Association for Computational Linguistics, 2014:1746-1751.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Predicting polarities of tweets by composing word embeddings with long short-term memory">

                                <b>[8]</b> WANG X, LIU Y, SUN C, et al.Predicting polarities of Tweets by composing word embeddings with long short-term memory[C]//Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg, USA:Association for Computational Linguistics, 2015:1343-1353.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Linguistically regularized lstms for sentiment classification">

                                <b>[9]</b> QIAN Q, HUANG M, ZHU X.Linguistically regularized LSTMs for sentiment classification[C]//Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:Association for Computa-tional Linguistics, 2017:1679-1689.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201506022&amp;v=MzAyNjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L25VNzdBS0NqWWZiRzRIOVRNcVk5SFpvUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 刘龙飞, 杨亮, 张绍武, 等.基于卷积神经网络的微博情感倾向性分析[J].中文信息学报, 2015, 29 (6) :159-165.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201506024&amp;v=MDQwNzN5L25VNzdBS0NqWWZiRzRIOVRNcVk5SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 陈钊, 徐睿峰, 桂林, 等.结合卷积神经网络和词语情感序列特征的中文情感分析[J].中文信息学报, 2015, 29 (6) :172-178.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201704001&amp;v=MTE0NDllUm9GeS9uVTc3QUx6N0Jkckc0SDliTXE0OUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 何炎祥, 孙松涛, 牛菲菲, 等.用于微博情感分析的一种情感语义增强的深度学习模型[J].计算机学报, 2016, 40 (4) :773-790.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003567381&amp;v=MTE5NDZIN1I3cWVidWR0RkM3bFZMM0lJVlk9Tmo3QmFyTzRIdEhQcW9sQ1orTU9ZM2s1ekJkaDRqOTlTWHFScnhveGNN&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> BOIY E, MOENS M F.A machine learning approach to sentiment analysis in multilingual Web texts[J].Information Retrieval, 2009, 12 (5) :526-558.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201504021&amp;v=MDc0NjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L25VNzdBS0NqWWZiRzRIOVRNcTQ5SFpZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 张志琳, 宗成庆.基于多样化特征的中文微博情感分类方法研究[J].中文信息学报, 2015, 29 (4) :134-143.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distributed representations of words and phrases and their compositionality">

                                <b>[15]</b> MIKOLOV T, SUTSKEVER I, CHEN K, et al.Distributed representations of words and phrases and their compositionality[C]//Proceedings of the 27th Advances in Neural Information Processing Systems.Cambridge, USA:MIT Press, 2013:3111-3119.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Natural language processing (almost) from scratch">

                                <b>[16]</b> COLLOBERT R, WESTON J, BOTTOU L, et al.Natural language processing (almost) from scratch[J].Journal of Machine Learning Research, 2011, 12 (8) :2493-2537
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ADADELTA:an adaptive learning rate method">

                                <b>[17]</b> ZEILER M D.ADADELTA:an adaptive learning rate method[EB/OL].[2018-01-05].https://arxiv.org/pdf/1212.5701.pdf.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201904029" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201904029&amp;v=MDUzNDI3QmJiRzRIOWpNcTQ5SGJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L25VNzdCTHo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
