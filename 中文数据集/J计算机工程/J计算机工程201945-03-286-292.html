<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130640109337500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201903048%26RESULT%3d1%26SIGN%3dZzLP0PjnVUsxzKcdK3Ad%252f%252fXVU1I%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903048&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903048&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903048&amp;v=MzAxMTVtVXI3UEx6N0JiYkc0SDlqTXJJOUJiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#47" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#51" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="1.1 特定目标情感分析">1.1 特定目标情感分析</a></li>
                                                <li><a href="#54" data-title="1.2 注意力机制">1.2 注意力机制</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#56" data-title="2 深度网络模型 ">2 深度网络模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="2.1 任务定义">2.1 任务定义</a></li>
                                                <li><a href="#72" data-title="2.2 卷积神经网络">2.2 卷积神经网络</a></li>
                                                <li><a href="#86" data-title="2.3 区域划分">2.3 区域划分</a></li>
                                                <li><a href="#91" data-title="2.4 区域&lt;i&gt;LSTM&lt;/i&gt;网络">2.4 区域<i>LSTM</i>网络</a></li>
                                                <li><a href="#102" data-title="2.5 模型训练">2.5 模型训练</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#111" data-title="3.1 实验数据">3.1 实验数据</a></li>
                                                <li><a href="#114" data-title="3.2 参数设置">3.2 参数设置</a></li>
                                                <li><a href="#117" data-title="3.3 对比实验">3.3 对比实验</a></li>
                                                <li><a href="#135" data-title="3.4 结果分析">3.4 结果分析</a></li>
                                                <li><a href="#150" data-title="3.5 模型训练时间分析">3.5 模型训练时间分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#154" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="&lt;b&gt;图1 CNN-RLSTM模型框架&lt;/b&gt;"><b>图1 CNN-RLSTM模型框架</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;图2 区域LSTM网络结构&lt;/b&gt;"><b>图2 区域LSTM网络结构</b></a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;表1 实验数据集分类情况统计&lt;/b&gt;"><b>表1 实验数据集分类情况统计</b></a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;表2 实验参数设置&lt;/b&gt;"><b>表2 实验参数设置</b></a></li>
                                                <li><a href="#137" data-title="&lt;b&gt;表3 不同模型的三分类实验对比结果&lt;/b&gt; %"><b>表3 不同模型的三分类实验对比结果</b> %</a></li>
                                                <li><a href="#140" data-title="&lt;b&gt;表4 不同模型的二分类实验对比结果&lt;/b&gt; %"><b>表4 不同模型的二分类实验对比结果</b> %</a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;图3 不同模型的三分类实验对比结果柱状图&lt;/b&gt;"><b>图3 不同模型的三分类实验对比结果柱状图</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;图4 不同模型的二分类实验对比结果柱状图&lt;/b&gt;"><b>图4 不同模型的二分类实验对比结果柱状图</b></a></li>
                                                <li><a href="#147" data-title="&lt;b&gt;图5 不同区域长度三分类实验对比结果&lt;/b&gt;"><b>图5 不同区域长度三分类实验对比结果</b></a></li>
                                                <li><a href="#148" data-title="&lt;b&gt;图6 不同区域长度二分类实验对比结果&lt;/b&gt;"><b>图6 不同区域长度二分类实验对比结果</b></a></li>
                                                <li><a href="#152" data-title="&lt;b&gt;表5 不同网络模型完成一次迭代的训练时间&lt;/b&gt; s"><b>表5 不同网络模型完成一次迭代的训练时间</b> s</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     PANG B, LEE L.Opinion mining and sentiment analysis[J].Foundations and Trends in Information Retrieval, 2008, 2 (1/2) :102-135.</a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 王仲远, 程健鹏, 王海勋, 等.短文本理解研究[J].计算机研究与发展, 2016, 53 (2) :262-269." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201602004&amp;v=MDA4MzQ3bVVyN1BMeXZTZExHNEg5Zk1yWTlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         王仲远, 程健鹏, 王海勋, 等.短文本理解研究[J].计算机研究与发展, 2016, 53 (2) :262-269.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" PONTIKI M, GALANIS D, PAVLOPOULOS J, et al.SemEval-2014 task 4:aspect based sentiment analysis[C]//Proceedings of the 8th International Workshop on Semantic Evaluation.Stroudsburg, USA:ACL Press, 2014:27-35." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sem Eval-2014 Task 4:Aspect Based Sentiment Analysis">
                                        <b>[3]</b>
                                         PONTIKI M, GALANIS D, PAVLOPOULOS J, et al.SemEval-2014 task 4:aspect based sentiment analysis[C]//Proceedings of the 8th International Workshop on Semantic Evaluation.Stroudsburg, USA:ACL Press, 2014:27-35.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" BOIY E, MOENS M F.A machine learning approach to sentiment analysis in multilingual Web texts[J].Information Retrieval, 2009, 12 (5) :526-558." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003567381&amp;v=MTk1NzF0RkM3bFZiekpJVms9Tmo3QmFyTzRIdEhQcW9sQ1orTU9ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVk&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         BOIY E, MOENS M F.A machine learning approach to sentiment analysis in multilingual Web texts[J].Information Retrieval, 2009, 12 (5) :526-558.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 余凯, 贾磊, 陈雨强, 等.深度学习的昨天、今天和明天[J].计算机研究与发展, 2013, 50 (9) :1799-1804." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201309002&amp;v=MTM4NTZVcjdQTHl2U2RMRzRIOUxNcG85RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N20=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         余凯, 贾磊, 陈雨强, 等.深度学习的昨天、今天和明天[J].计算机研究与发展, 2013, 50 (9) :1799-1804.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 王盛玉, 曾碧卿, 胡翩翩.基于卷积神经网络参数优化的中文情感分析[J].计算机工程, 2017, 43 (8) :200-207, 214." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201708035&amp;v=MDU4OTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdtVXI3UEx6N0JiYkc0SDliTXA0OUdZWVE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         王盛玉, 曾碧卿, 胡翩翩.基于卷积神经网络参数优化的中文情感分析[J].计算机工程, 2017, 43 (8) :200-207, 214.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" KIM Y.Convolutional neural networks for sentence classification[C]//Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2014:1746-1751." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">
                                        <b>[7]</b>
                                         KIM Y.Convolutional neural networks for sentence classification[C]//Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2014:1746-1751.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" ZHOU P, SHI W, TIAN J, et al.Attention-based bidirectional long short-term memory networks for relation classification[C]//Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL Press, 2016:207-212." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attention-based bidirectional long short-term memory networks for relation classification">
                                        <b>[8]</b>
                                         ZHOU P, SHI W, TIAN J, et al.Attention-based bidirectional long short-term memory networks for relation classification[C]//Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL Press, 2016:207-212.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" TANG D, QIN B, LIU T.Aspect level sentiment classification with deep memory network[C]//Proceedings of 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2016:214-224." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Aspect Level Sentiment Classification with Deep Memory Network">
                                        <b>[9]</b>
                                         TANG D, QIN B, LIU T.Aspect level sentiment classification with deep memory network[C]//Proceedings of 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2016:214-224.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 梁斌, 刘全, 徐进, 等.基于多注意力卷积神经网络的特定目标情感分析[J].计算机研究与发展, 2017, 54 (8) :1724-1735." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201708009&amp;v=MDQ0NTM0OUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdtVXI3UEx5dlNkTEc0SDliTXA=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         梁斌, 刘全, 徐进, 等.基于多注意力卷积神经网络的特定目标情感分析[J].计算机研究与发展, 2017, 54 (8) :1724-1735.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" HU M, LIU B.Mining and summarizing customer reviews[C]//Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2004:168-177." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mining and summarizing customer reviews">
                                        <b>[11]</b>
                                         HU M, LIU B.Mining and summarizing customer reviews[C]//Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2004:168-177.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" HU M, LIU B.Mining opinion features in customer reviews[C]//Proceedings of the 19th National Conference on Artifical Intelligence.Palo Alto, USA:AAAI Press, 2004:755-760." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mining opinion features in customer reviews">
                                        <b>[12]</b>
                                         HU M, LIU B.Mining opinion features in customer reviews[C]//Proceedings of the 19th National Conference on Artifical Intelligence.Palo Alto, USA:AAAI Press, 2004:755-760.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" KIRITCHENKO S, ZHU X, CHERRY C, et al.NRC-Canada-2014:detecting aspects and sentiment in customer reviews[C]//Proceedings of the 8th International Workshop on Semantic Evaluation.Stroudsburg, USA:ACL Press, 2014:437-442." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=NRC-Canada-2014:detecting aspects and sentiment in customer reviews">
                                        <b>[13]</b>
                                         KIRITCHENKO S, ZHU X, CHERRY C, et al.NRC-Canada-2014:detecting aspects and sentiment in customer reviews[C]//Proceedings of the 8th International Workshop on Semantic Evaluation.Stroudsburg, USA:ACL Press, 2014:437-442.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" NGUYEN T H, SHIRAI K.PhraseRNN:phrase recursive neural network for aspect-based sentiment analysis[C]//Proceedings of 2015 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2015:2509-2514." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Phrase RNN:Phrase Recursive Neural Network for Aspect-based Sentiment Analysis">
                                        <b>[14]</b>
                                         NGUYEN T H, SHIRAI K.PhraseRNN:phrase recursive neural network for aspect-based sentiment analysis[C]//Proceedings of 2015 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2015:2509-2514.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" DONG L, WEI F, TAN C, et al.Adaptive recursive neural network for target-dependent twitter sentiment classification[C]//Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL Press, 2014:49-54." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification">
                                        <b>[15]</b>
                                         DONG L, WEI F, TAN C, et al.Adaptive recursive neural network for target-dependent twitter sentiment classification[C]//Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL Press, 2014:49-54.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" BAHDANAU D, CHO K, BENGIO Y.Neural machine translation by jointly learning to align and translate[EB/OL].[2017-11-15].https://arxiv.org/abs/1409.0473." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">
                                        <b>[16]</b>
                                         BAHDANAU D, CHO K, BENGIO Y.Neural machine translation by jointly learning to align and translate[EB/OL].[2017-11-15].https://arxiv.org/abs/1409.0473.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" YIN W, SCH&#220;TZE H, XIANG B, et al.ABCNN:attention-based convolutional neural network for modeling sentence pairs[J].Transactions of the Association for Computational Linguistics, 2016, 4 (11) :259-272." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ABCNN:Attention-Based Convolutional Neural Network for Modeling Sentence Pairs">
                                        <b>[17]</b>
                                         YIN W, SCH&#220;TZE H, XIANG B, et al.ABCNN:attention-based convolutional neural network for modeling sentence pairs[J].Transactions of the Association for Computational Linguistics, 2016, 4 (11) :259-272.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" WANG Y, HUANG M, ZHAO L, et al.Attention-based LSTM for aspect-level sentiment classification[C]//Proceedings of 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2016:606-615." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attention-based LSTM for Aspect-level Sentiment Classification">
                                        <b>[18]</b>
                                         WANG Y, HUANG M, ZHAO L, et al.Attention-based LSTM for aspect-level sentiment classification[C]//Proceedings of 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2016:606-615.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" COLLOBERT R, WESTON J, BOTTOU L, et al.Natural language processing (almost) from scratch[J].Journal of Machine Learning Research, 2011, 12:2493-2537." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Natural language processing (almost) from scratch">
                                        <b>[19]</b>
                                         COLLOBERT R, WESTON J, BOTTOU L, et al.Natural language processing (almost) from scratch[J].Journal of Machine Learning Research, 2011, 12:2493-2537.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" PENNINGTON J, SOCHER R, MANNING C D.GloVe:Global Vectors for Word Representation[C]//Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2014:1532-1543." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Glove:Global vectors for word representation">
                                        <b>[20]</b>
                                         PENNINGTON J, SOCHER R, MANNING C D.GloVe:Global Vectors for Word Representation[C]//Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2014:1532-1543.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" MIKOLOV T, CHEN K, CORRADO G, et al.Efficient estimation of word representations in vector space[EB/OL].[2017-11-15].https://arxiv.org/abs/1301.3781." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient estimation of word representations in vector space">
                                        <b>[21]</b>
                                         MIKOLOV T, CHEN K, CORRADO G, et al.Efficient estimation of word representations in vector space[EB/OL].[2017-11-15].https://arxiv.org/abs/1301.3781.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" WANG X, LIU Y, SUN C, et al.Predicting polarities of tweets by composing word embeddings with long short-term memory[C]//Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg, USA:ACL Press, 2015:1343-1353." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Predicting polarities of tweets by composing word embeddings with long short-term memory">
                                        <b>[22]</b>
                                         WANG X, LIU Y, SUN C, et al.Predicting polarities of tweets by composing word embeddings with long short-term memory[C]//Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg, USA:ACL Press, 2015:1343-1353.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(03),286-292 DOI:10.19678/j.issn.1000-3428.0050035            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种用于特定目标情感分析的深度网络模型</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%80%9D%E8%BF%9C&amp;code=38707676&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈思远</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BD%AD%E8%B6%85&amp;code=32422199&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">彭超</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%94%A1%E6%9E%97%E6%A3%AE&amp;code=38707677&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蔡林森</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E5%85%B0%E8%8B%B1&amp;code=38707678&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭兰英</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%9C%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0092795&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华东师范大学计算机科学与软件工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>基于注意力机制的长短期记忆 (LSTM) 网络在训练过程中需要耗费大量时间, 且仅以句子作为网络输入难以有效区分同一句中不同目标的情感极性。为此, 提出一种结合卷积神经网络 (CNN) 和区域LSTM的深度网络模型。通过区域LSTM实现特定目标的区域划分, 在保留特定目标重要情感信息的同时, 有效区分不同目标的特征信息, 并利用CNN保留整个句子的情感信息。实验结果表明, 该模型能有效识别不同目标的情感极性, 相比传统网络模型具有更短的模型训练时间。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感分析;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%AE%9A%E7%9B%AE%E6%A0%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特定目标;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长短期记忆网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度网络模型;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    陈思远 (1993—) , 男, 硕士研究生, 主研方向为自然语言处理、情感分析;;
                                </span>
                                <span>
                                    彭超, 副教授;;
                                </span>
                                <span>
                                    蔡林森, 硕士研究生。;
                                </span>
                                <span>
                                    郭兰英, 硕士研究生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61232006);</span>
                                <span>上海市自然科学基金 (14ZR1412400);</span>
                    </p>
            </div>
                    <h1><b>A Deep Network Model for Specific Target Sentiment Analysis</b></h1>
                    <h2>
                    <span>CHEN Siyuan</span>
                    <span>PENG Chao</span>
                    <span>CAI Linsen</span>
                    <span>GUO Lanying</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Software Engineering, East China Normal University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The Long Short Term Memory (LSTM) network based on attention mechanism generally takes a lot of time during the training process, and only uses sentences as a network input, which is difficult to effectively distinguish the different polarities of different targets in the same sentence.To address this problem, this paper proposes a deep neural model of combining Convolutional Neural Network (CNN) and Regional LSTM (CNN-RLSTM) .By segmenting the region according to the specific target through the regional LSTM, the feature information of different targets can be effectively distinguished while retaining the specific emotional information of the specific target, and the emotional information of the entire sentence is retained by the CNN.Experimental results show that, the CNN-RLSTM model can effectively identify the emotional polarity of different targets, and the model training time is shorter than the traditional network model.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sentiment%20analysis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sentiment analysis;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=specific%20target&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">specific target;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Neural%20Network%20(CNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Neural Network (CNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Long%20Short%20Term%20Memory%20(LSTM)%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Long Short Term Memory (LSTM) network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20network%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep network model;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-09</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="47" name="47" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="48">近年来, 特定目标情感分析作为深层次的情感分析任务, 已成为自然语言处理领域的研究热点之一<citation id="159" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。与普通情感分析不同, 特定目标情感分析需要针对文本中不同的特定目标分析其情感极性, 不仅依赖于文本的上下文信息, 同时要考虑文本中不同目标的情感信息<citation id="156" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。在同一个文本中不同的目标词可能会出现相反的情感极性。在已有研究中, 传统机器学习方法在普通情感分析任务中取得了较好的效果, 但需要依赖复杂的人工规则和特征工程, 而且同一句中的不同目标经常被预测为相同的情感极性<citation id="157" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 因此深度学习方法在自然语言处理领域得到越来越广泛的应用<citation id="160" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。受到图像领域中注意力机制的启发, 研究者们尝试将注意力机制应用于自然语言处理任务<citation id="158" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。这类结合注意力机制的深度网络模型在训练过程中高度关注特定目标的特征信息, 并且能有效针对不同目标调整神经网络的参数信息, 挖掘更多的隐藏特征信息。</p>
                </div>
                <div class="p1">
                    <p id="49">在特定目标情感分析任务中, 长短期记忆 (Long Short Term Memory, LSTM) 网络和卷积神经网络 (Convolution Neural Network, CNN) 模型通过结合注意力机制, 使模型高度关注特定目标的情感信息。一方面, 结合注意力机制的LSTM网络模型需要接收文本的序列性输入, 而且注意力矩阵和输入词向量的运算需要权重矩阵的支持, 导致模型的训练时间大幅增加<citation id="161" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。另一方面, 结合注意力机制的CNN模型需要结合不同的情感特征信息和不同的注意力矩阵, 增加了模型中特征工程的工作量<citation id="162" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="50">针对上述问题, 本文提出一种结合区域LSTM网络和CNN的深度网络模型 (CNN-RLSTM) , 将其应用于特定目标情感分析任务。根据特定目标的位置将输入句子切分为特定目标区域, 通过减少输入文本的长度降低LSTM网络计算时间。同时, 为防止因区域划分不合理造成情感信息的丢失, 使用CNN挖掘整个句子的情感特征信息。</p>
                </div>
                <h3 id="51" name="51" class="anchor-tag">1 相关工作</h3>
                <h4 class="anchor-tag" id="52" name="52">1.1 特定目标情感分析</h4>
                <div class="p1">
                    <p id="53">特定目标情感分析是通过学习文本上下文的信息来判别文本中特定目标的情感极性, 是更深层次的情感分析, 也是细粒度的文本分类任务, 一直以来受到学者们的广泛关注<citation id="166" type="reference"><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>。文献<citation id="163" type="reference">[<a class="sup">13</a>]</citation>使用一种结合多种特征的支持向量机 (Support Vector Machine, SVM) 分类模型, 应用于基于方面的情感分析任务。该方法在libSVM模型上加入了unigram、bigram、词典等特征, 使模型可以挖掘输入文本中的多种情感信息, 有效识别句子中不同方面的情感极性。在基于深度学习的方法中, 文献<citation id="164" type="reference">[<a class="sup">14</a>]</citation>基于递归神经网络 (Recursive Neural Network, RNN) 与依存树提出一种特定目标情感分析模型。该模型利用一个结合句子成分结构和句子依存关系树的二叉短语依赖树获取特定方面的表示, 从而获得不同方面在句子中和其他词语的依赖关系, 有效提升特定目标情感分析的正确率, 同时降低任务中的特征工程。文献<citation id="165" type="reference">[<a class="sup">15</a>]</citation>使用一种带适应能力的递归神经网络模型 (AdaRNN) 解决特定目标情感分析问题。该模型利用一个自适应的神经网络模型学习特定目标和词语之间的相互联系以及句子的句法结构, 并通过词语和目标词之间的联系扩展句子中的情感信息, 从而有效识别句子中特定目标的情感极性。</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54">1.2 注意力机制</h4>
                <div class="p1">
                    <p id="55">注意力机制能有效解决同一句子中不同目标的情感极性判别问题。注意力机制最早在图像处理领域被提出, 目的是为了使神经网络在处理输入时重点关注某些信息。为解决NLP任务中长输入序列的问题, 文献<citation id="167" type="reference">[<a class="sup">16</a>]</citation>将注意力机制应用到自然语言处理领域, 结合循环神经网络解决机器翻译任务。文献<citation id="168" type="reference">[<a class="sup">17</a>]</citation>提出一种基于注意力机制的CNN用于句子对建模任务, 该模型分别在卷积层和池化层中构造注意力矩阵, 在句对间建立联系, 取得了较好的效果。文献<citation id="169" type="reference">[<a class="sup">18</a>]</citation>将注意力机制引入到LSTM网络模型中, 使每一个神经元高度关注特定目标的情感信息, 挖掘出句子中对目标词情感极性具有重要性的上下文词语, 并在不同领域的数据集上都取得了较好的情感极性识别结果。</p>
                </div>
                <h3 id="56" name="56" class="anchor-tag">2 深度网络模型</h3>
                <div class="p1">
                    <p id="57">本文提出的CNN-RLSTM模型既可以区分不同目标词的重要特征信息, 又可以充分利用整个句子的情感信息。CNN-RLSTM模型 (见图1) 主要由以下部分组成:</p>
                </div>
                <div class="p1">
                    <p id="58">1) CNN输入矩阵。本文保留待分类句子中所有的词向量, 拼接成二维矩阵作为CNN的输入矩阵。</p>
                </div>
                <div class="p1">
                    <p id="59">2) 区域LSTM输入矩阵。本文以特定目标为中心, 对句子进行区域划分, 提取对特定目标有重要影响的词语作为LSTM网络的序列性输入矩阵。</p>
                </div>
                <div class="p1">
                    <p id="60">3) CNN。为使模型结构简单, 本文使用一层卷积层和一层池化层构建CNN模型, 提取句子中重要的特征信息。</p>
                </div>
                <div class="p1">
                    <p id="61">4) 区域LSTM网络。本文使用区域LSTM网络接收特定目标的区域信息, 可以充分挖掘特定目标在句子中的前后依赖关系。同时, 该区域LSTM网络接收特定目标的注意力信息和CNN输出的特征信息, 使模型在训练过程中高度关注特定目标在整个句子中的情感信息。</p>
                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903048_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 CNN-RLSTM模型框架" src="Detail/GetImg?filename=images/JSJC201903048_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 CNN-RLSTM模型框架</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903048_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="63" name="63">2.1 任务定义</h4>
                <div class="p1">
                    <p id="64">对于句子<mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mo>=</mo><mrow><mo>{</mo><mrow><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>t</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>w</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>, 其中<i>t</i><sub><i>i</i></sub>和<i>t</i><sub><i>j</i></sub>为2个不同的目标词, 特定目标情感分析的任务是针对不同的目标进行情感极性判别。例如句子“Good food but dreadful service at that restaurant”, 对于目标“food”是积极情感极性, 而对于目标“service”则是消极情感极性, 在同一个句子中, 针对不同的目标会出现相反的情感极性。</p>
                </div>
                <div class="p1">
                    <p id="66">本文在实验中将句子表示为词序列, 每个词映射为<i>d</i>维向量<b><i>x</i></b><sub><i>i</i></sub>∈<image href="images/JSJC201903048_067.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>。对于长度为<i>n</i>的句子可以表示为如式 (1) 所示的矩阵。</p>
                </div>
                <div class="p1">
                    <p id="68"><b><i>x</i></b><sub>1:<i>n</i></sub>=<b><i>x</i></b><sub>1</sub>♁<b><i>x</i></b><sub>2</sub>♁…♁<b><i>a</i></b><sub><i>i</i></sub>♁…♁<b><i>a</i></b><sub><i>j</i></sub>♁…♁<b><i>x</i></b><sub><i>n</i></sub>      (1) </p>
                </div>
                <div class="p1">
                    <p id="69">其中, <b><i>x</i></b><sub>1:<i>n</i></sub>∈<image href="images/JSJC201903048_070.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>n</i>×<i>d</i></sup>, ♁为拼接操作, <b><i>a</i></b>∈<image href="images/JSJC201903048_071.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>为特定目标向量。</p>
                </div>
                <h4 class="anchor-tag" id="72" name="72">2.2 卷积神经网络</h4>
                <div class="p1">
                    <p id="73"><i>CNN</i>可以接收句子的平行化输入, 对于长度为l的卷积窗口, <i>CNN</i>通过卷积核对输入矩阵进行卷积操作:</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>f</mi><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">w</mi><mo>⋅</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>:</mo><mi>i</mi><mo>+</mo><mi>l</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>b</mi></mrow><mo>) </mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">其中, <b><i>w</i></b>∈<image href="images/JSJC201903048_076.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>l</i>×<i>d</i></sup>为卷积核权重, <i>b</i>∈<image href="images/JSJC201903048_077.jpg" type="" display="inline" placement="inline"><alt></alt></image>为偏置, <i>f</i>为激活函数, <b><i>x</i></b><sub><i>i</i>:<i>i</i>+<i>l</i>-1</sub>为一个卷积窗口的词向量矩阵。对于长度为<i>n</i>的句子, 通过卷积操作可得到特征向量。</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">c</mi><mo>=</mo><mrow><mo>[</mo><mrow><mi>c</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>c</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>c</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>-</mo><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">其中, <b><i>c</i></b>∈<image href="images/JSJC201903048_080.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>n</i>-<i>l</i>+1</sup>。本文采用max-over-time pooling方法<citation id="170" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>对卷积后的特征向量进行池化, 提取重要特征<mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>^</mo></mover><mo>=</mo><mrow><mi>max</mi></mrow><mrow><mo>{</mo><mi mathvariant="bold-italic">c</mi><mo>}</mo></mrow></mrow></math></mathml>。对于有m个卷积核的窗口得到如下特征向量:</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>^</mo></mover><mo>=</mo><mrow><mo>[</mo><mrow><mover accent="true"><mi>c</mi><mo>^</mo></mover><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mover accent="true"><mi>c</mi><mo>^</mo></mover><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mover accent="true"><mi>c</mi><mo>^</mo></mover><msub><mrow></mrow><mi>m</mi></msub></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">其中, <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>^</mo></mover><mo>∈</mo></mrow></math></mathml><image href="images/JSJC201903048_085.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>m</i></sup>为CNN提取的特征向量, 本文将该特征向量以注意力向量的形式作为区域LSTM的输入。</p>
                </div>
                <h4 class="anchor-tag" id="86" name="86">2.3 区域划分</h4>
                <div class="p1">
                    <p id="87">本文提出将句子以特定目标为中心来划分区域的方法, 既可以保留句子中特定目标的重要特征信息, 也可以区分句子中不同目标的情感信息。例如句子<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mo>=</mo><mrow><mo>{</mo><mrow><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>t</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>w</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>有t<sub>i</sub>和t<sub>j</sub>这2个目标词, 本文将以2个不同的目标词为中心, 将该句子划分成2个长度为h的独立区域<mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mrow><mo>{</mo><mrow><mi>w</mi><msub><mrow></mrow><mi>m</mi></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>w</mi><msub><mrow></mrow><mrow><mi>h</mi><mo>+</mo><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>和<mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mrow><mo>{</mo><mrow><mi>w</mi><msub><mrow></mrow><mi>n</mi></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>t</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>w</mi><msub><mrow></mrow><mrow><mi>h</mi><mo>+</mo><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>。通过区域划分有效缩减句子长度, 降低<i>LSTM</i>网络的训练时间。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91">2.4 区域<i>LSTM</i>网络</h4>
                <div class="p1">
                    <p id="92">区域LSTM接收以词为单位的句子作为网络的序列化输入, 为使网络可以高度关注句子中的特定目标信息, 本文将CNN提取到的特征向量和特定目标的词向量以注意力向量的形式作为区域LSTM网络的输入。图2为区域LSTM网络结构。</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903048_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 区域LSTM网络结构" src="Detail/GetImg?filename=images/JSJC201903048_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 区域LSTM网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903048_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="94">区域LSTM的输入由本次输入的词向量、上一个时间步神经单元隐藏层的输出以及特定目标的注意力词向量组成, 计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">e</mi><mo>=</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>h</mi></msub><mo>⋅</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⊕</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>a</mi></msub><mo>⋅</mo><mi mathvariant="bold-italic">a</mi><mo>⊕</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>c</mi></msub><mo>⋅</mo><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>^</mo></mover><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">其中, <b><i>W</i></b><sub><i>h</i></sub>∈<image href="images/JSJC201903048_097.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>l</i></sup>为隐藏层输出<b><i>h</i></b><sub><i>i</i></sub>的权重矩阵, <i>l</i>为隐藏层输出<b><i>h</i></b><sub><i>i</i></sub>的维度, 即<b><i>h</i></b><sub><i>i</i></sub>∈<image href="images/JSJC201903048_098.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>l</i></sup>, <b><i>W</i></b><sub><i>a</i></sub>∈<image href="images/JSJC201903048_099.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>为特定方面词向量<b><i>a</i></b>的权重矩阵, <b><i>W</i></b><sub><i>c</i></sub>∈<image href="images/JSJC201903048_100.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>m</i></sup>为CNN输出特征向量<mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>^</mo></mover></math></mathml>的权重矩阵。区域<i>LSTM</i>网络在训练过程中可以通过调整每个权重矩阵的分量来调整不同向量对分类结果的影响程度, 充分挖掘句子的情感特征信息。</p>
                </div>
                <h4 class="anchor-tag" id="102" name="102">2.5 模型训练</h4>
                <div class="p1">
                    <p id="103">本文使用softmax函数计算模型的输出结果, 得到待分类句子的情感极性分类结果。</p>
                </div>
                <div class="p1">
                    <p id="104"><i>y</i>=softmax (<b><i>W</i></b><sub><i>s</i></sub><b><i>h</i></b><sub><i>N</i></sub>+<i>b</i>)      (6) </p>
                </div>
                <div class="p1">
                    <p id="105">其中, <b><i>W</i></b><sub><i>s</i></sub>为权重矩阵, <i>b</i>为偏置, <b><i>h</i></b><sub><i>N</i></sub>为区域LSTM最后一个神经单元的隐藏层输出。在模型训练中, 交叉熵损失函数的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">l</mi><mi mathvariant="bold-italic">o</mi><mi mathvariant="bold-italic">s</mi><mi mathvariant="bold-italic">s</mi><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi mathvariant="bold-italic">i</mi><mo>∈</mo><mi mathvariant="bold-italic">D</mi></mrow></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi mathvariant="bold-italic">j</mi><mo>∈</mo><mi mathvariant="bold-italic">C</mi></mrow></munder><mrow></mrow></mstyle></mrow></mstyle><mover accent="true"><mi mathvariant="bold-italic">y</mi><mo>^</mo></mover><msubsup><mrow></mrow><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">j</mi></msubsup><mrow><mi mathvariant="bold">l</mi><mi mathvariant="bold">n</mi></mrow><mspace width="0.25em" /><mi mathvariant="bold-italic">y</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">j</mi></msubsup><mo>+</mo><mi mathvariant="bold-italic">λ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">θ</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">其中, <i>D</i>为训练集数据集合, <i>C</i>为数据类别集合, <i>y</i>为预测类别, <mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">y</mi><mo>^</mo></mover></math></mathml>为实际类别, <i>λ</i>‖<i>θ</i>‖<sup>2</sup>为交叉熵正则项。</p>
                </div>
                <h3 id="109" name="109" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="110">本文在3个不同领域的数据集上进行实验, 通过与现有研究中取得最好效果的模型进行对比实验, 验证本文<i>CNN</i>-<i>RLSTM</i>模型在特定目标情感分析任务中的有效性。在本文实验中, 英文词向量采用<i>Glove</i>词向量<citation id="171" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>, 每个词向量为300维。中文词向量采用从汽车之家网站爬取并利用<i>word</i>2<i>vec</i>的<i>skip</i>-<i>gram</i>训练得到的用户评论<citation id="172" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>, 每个词向量为300维。对于未登录词, 采用均匀分布U (-0.01, 0.01) 随机初始化词向量, 并利用结巴工具包对中文数据进行分词。在中文数据集中, 将所有目标词作为用户词典进行分词并训练词向量。在英文数据集中, 对于单个词的目标, 使用该单词的词向量作为特定目标的向量表示, 例如“<i>food</i>”“<i>staff</i>”等。对于由多个词组成的目标词, 使用多个词的词向量平均值作为目标向量表示, 例如“<i>dim sum</i>”“<i>battery life</i>”等。</p>
                </div>
                <h4 class="anchor-tag" id="111" name="111">3.1 实验数据</h4>
                <div class="p1">
                    <p id="112">本文使用2种不同语言的数据集进行对比实验。英文采用<i>SemEval</i>2016任务5数据集中的<i>laptop</i>和<i>restaurant</i>领域的用户评论<i>REST</i>和<i>LAPT</i>数据集, 中文采用2016<i>CCF</i>大数据与计算智能大赛中基于视角的领域情感分析赛题中的汽车领域评论<i>AUTO</i>数据集。数据样本的情感极性分为积极、消极和中性, 本文实验数据集分类情况统计如表1所示, 其中, <i>Train</i>是训练集, <i>Test</i>是测试集。</p>
                </div>
                <div class="area_img" id="113">
                    <p class="img_tit"><b>表1 实验数据集分类情况统计</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="113" border="1"><tr><td>数据集</td><td>积极句子</td><td>消极句子</td><td>中性句子</td></tr><tr><td>REST-Train</td><td>1 647</td><td>741</td><td>101</td></tr><tr><td><br />REST-Test</td><td>601</td><td>202</td><td>40</td></tr><tr><td><br />LAPT-Train</td><td>1 631</td><td>1 076</td><td>183</td></tr><tr><td><br />LAPT-Test</td><td>480</td><td>268</td><td>42</td></tr><tr><td><br />AUTO-Train</td><td>2 686</td><td>1 089</td><td>543</td></tr><tr><td><br />AUTO-Test</td><td>854</td><td>243</td><td>138</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="114" name="114">3.2 参数设置</h4>
                <div class="p1">
                    <p id="115">为获取句子中丰富的特征信息, 本文在CNN中使用多窗口、多卷积核对输入句子进行卷积操作。在区域LSTM网络中, 每个独立区域的长度设置为11, 即以目标词为中心, 前后各取5个词。此外, 为防止过拟合, 本文在实验中使用dropout机制和权重正则化限制, 实验具体参数设置如表2所示。</p>
                </div>
                <div class="area_img" id="116">
                    <p class="img_tit"><b>表2 实验参数设置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="116" border="1"><tr><td><br />超参数</td><td>参数值</td></tr><tr><td><br />卷积核窗口数量</td><td>2～5</td></tr><tr><td><br />卷积核数量</td><td>100</td></tr><tr><td><br />权重正则限制数量</td><td>3</td></tr><tr><td><br />批训练数量</td><td>32</td></tr><tr><td><br />丢弃率</td><td>0.5</td></tr><tr><td><br />区域长度</td><td>11</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="117" name="117">3.3 对比实验</h4>
                <div class="p1">
                    <p id="118">为验证本文模型的有效性, 将其与传统机器学习方法 (SVM) 、传统网络模型 (CNN、LSTM) 以及在特定目标情感分析中取得重要突破的网络模型进行对比实验。</p>
                </div>
                <h4 class="anchor-tag" id="119" name="119">1) ATT-RLSTM:</h4>
                <div class="p1">
                    <p id="120">区域LSTM模型。该模型是本文提出的深度网络模型的一部分, 只保留了区域LSTM和特定目标注意力机制。</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121">2) CNN-RLSTM:</h4>
                <div class="p1">
                    <p id="122">本文提出的深度网络模型。该模型使用CNN接收整个句子的平行化输入, 提取句子中重要的局部特征, 将CNN提取到的特征向量以及特定目标的词向量以注意力形式加入区域LSTM网络, 使网络模型可以充分利用和区分不同目标的情感特征信息。</p>
                </div>
                <h4 class="anchor-tag" id="123" name="123">3) SVM:</h4>
                <div class="p1">
                    <p id="124">文献<citation id="173" type="reference">[<a class="sup">11</a>]</citation>提出的基于特征的SVM分类模型。该模型在特定目标的用户评论实验中取得了比以往研究更好的情感分类效果。</p>
                </div>
                <h4 class="anchor-tag" id="125" name="125">4) CNN:</h4>
                <div class="p1">
                    <p id="126">文献<citation id="174" type="reference">[<a class="sup">7</a>]</citation>提出的卷积神经网络模型。该模型没有结合特定方面的注意力机制, 无法在训练过程中高度关注特定目标情感信息。</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127">5) LSTM:</h4>
                <div class="p1">
                    <p id="128">文献<citation id="175" type="reference">[<a class="sup">22</a>]</citation>提出的LSTM网络模型。该模型是最基础的LSTM网络模型, 可以保留句子中词语的时序关系, 获取词语间的依赖关系, 但也无法在训练过程中高度关注特定目标的情感信息。</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129">6) ATT-CNN:</h4>
                <div class="p1">
                    <p id="130">文献<citation id="176" type="reference">[<a class="sup">17</a>]</citation>提出的基于注意力机制的CNN模型。该模型使用一种作用在卷积层的注意力机制, 可使模型在训练过程中高度关注特定目标的情感信息。</p>
                </div>
                <h4 class="anchor-tag" id="131" name="131">7) ATT-LSTM:</h4>
                <div class="p1">
                    <p id="132">文献<citation id="177" type="reference">[<a class="sup">18</a>]</citation>提出的结合注意力机制的LSTM网络模型。该模型加入特定目标的注意力信息, 在特定目标情感分析任务中取得了比以往研究更好的情感分类效果。</p>
                </div>
                <h4 class="anchor-tag" id="133" name="133">8) MATT-CNN:</h4>
                <div class="p1">
                    <p id="134">文献<citation id="178" type="reference">[<a class="sup">10</a>]</citation>提出的多注意力CNN模型。该模型使用多种注意力机制高度关注句子中特定目标的情感信息。</p>
                </div>
                <h4 class="anchor-tag" id="135" name="135">3.4 结果分析</h4>
                <div class="p1">
                    <p id="136">本文在REST数据集、LAPT数据集和AUTO数据集上进行实验, 通过实验验证和分析本文提出的CNN-RLSTM模型在特定目标情感分析中的有效性, 得到的情感分类正确率如表3所示。</p>
                </div>
                <div class="area_img" id="137">
                    <p class="img_tit"><b>表3 不同模型的三分类实验对比结果</b> % <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="137" border="1"><tr><td rowspan="2"><br />模型</td><td colspan="3"><br />正确率</td></tr><tr><td><br />REST数据集</td><td>LAPT数据集</td><td>AUTO数据集</td></tr><tr><td>SVM</td><td>76.63</td><td>66.58</td><td>81.62</td></tr><tr><td><br />CNN</td><td>66.55</td><td>60.25</td><td>73.04</td></tr><tr><td><br />LSTM</td><td>69.28</td><td>62.41</td><td>74.82</td></tr><tr><td><br />ATT-CNN</td><td>75.56</td><td>65.70</td><td>80.32</td></tr><tr><td><br />ATT-LSTM</td><td>78.29</td><td>67.59</td><td>83.24</td></tr><tr><td><br />MATT-CNN</td><td>78.89</td><td>67.22</td><td>84.21</td></tr><tr><td><br />ATT-RLSTM</td><td>78.05</td><td>67.09</td><td>83.89</td></tr><tr><td><br />CNN-RLSTM</td><td>78.53</td><td>67.85</td><td>85.51</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="138">从表3可以看出, CNN-RLSTM模型在3个不同领域数据集上都取得较好的情感分类效果, 其中在AUTO数据集上分类正确率为85.51%, 比MATT-CNN模型提升1.3%, 比SVM模型提升3.89%, 从而验证CNN-RLSTM模型在特定目标情感分析任务中的有效性。未加入特定目标注意力机制的CNN和LSTM模型在3个领域数据集上的分类效果不理想, 其中正确率最高的AUTO数据集也只有73.04%和74.82%。而加入注意力机制的ATT-CNN和ATT-LSTM模型在AUTO数据集上的分类正确率为80.32%和83.24%, 比CNN和LSTM模型分别提升7.28%和8.42%。此外, 没有结合CNN的ATT-RLSTM模型虽然在AUTO数据集上的分类正确率为83.89%, 比ATT-LSTM模型提升0.65%, 但是比MATT-CNN模型降低0.32%, 同时在REST和LAPT数据集上的分类正确率只有78.05%和67.09%, 均低于MATT-CNN和ATT-LSTM模型。而结合CNN的CNN-RLSTM模型在3个领域数据集上都取得不错的分类效果, 其中在提升最高的AUTO数据集上相比ATT-LSTM、MATT-CNN和ATT-RLSTM模型分别提升2.27%、1.3%和1.62%。</p>
                </div>
                <div class="p1">
                    <p id="139">为进一步验证本文提出的CNN-RLSTM模型在特定目标情感分析任务中的有效性, 只保留3个数据集的积极和消极样本对CNN-RLSTM、ATT-RLSTM、MATT-CNN和ATT-LSTM这4个模型进行二分类对比实验, 结果如表4所示。</p>
                </div>
                <div class="area_img" id="140">
                    <p class="img_tit"><b>表4 不同模型的二分类实验对比结果</b> % <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="140" border="1"><tr><td rowspan="2"><br />模型</td><td colspan="3"><br />正确率</td></tr><tr><td><br />REST数据集</td><td>LAPT数据集</td><td>AUTO数据集</td></tr><tr><td>ATT-LSTM</td><td>88.92</td><td>86.10</td><td>92.43</td></tr><tr><td><br />MATT-CNN</td><td>89.66</td><td>85.56</td><td>93.16</td></tr><tr><td><br />ATT-RLSTM</td><td>88.67</td><td>85.43</td><td>93.44</td></tr><tr><td><br />CNN-RLSTM</td><td>90.16</td><td>86.36</td><td>94.35</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="141">从表4可以看出, 本文提出的CNN-RLSTM模型在3个领域数据集上的二分类实验都取得了较好的分类效果, 其中在效果最好的AUTO数据集上的正确率为94.35%, 相比其他3个模型分别提升1.92%、1.19%和0.91%, 验证了本文提出的CNN-RLSTM模型在特定目标情感分析任务中的有效性。综合表3和表4, 本文对比4组模型的实验结果, 如图3和图4所示。</p>
                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903048_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同模型的三分类实验对比结果柱状图" src="Detail/GetImg?filename=images/JSJC201903048_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 不同模型的三分类实验对比结果柱状图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903048_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="143">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903048_143.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同模型的二分类实验对比结果柱状图" src="Detail/GetImg?filename=images/JSJC201903048_143.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 不同模型的二分类实验对比结果柱状图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903048_143.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="144">从对比结果可以看出, 本文提出的CNN-RLSTM模型在所有实验中综合表现最好, 在二分类实验中CNN-RLSTM模型在3个数据集上都取得较好的分类效果。对比CNN-RLSTM模型和已有研究中取得最好效果的MATT-CNN模型可以看出, 除了在三分类的REST数据集上CNN-RLSTM模型的分类效果比MATT-CNN模型降低0.36%之外, 在其余实验中CNN-RLSTM模型都优于MATT-CNN模型。说明与仅使用CNN的MATT-CNN模型相比, 结合LSTM网络的CNN-RLSTM模型通过LSTM网络保留句子中不同词语之间的依赖关系, 能使模型充分学习句子的长距离依赖关系。因此, 本文提出的CNN-RLSTM模型在仅使用词向量的情况下取得了比MATT-CNN模型更好的分类效果。</p>
                </div>
                <div class="p1">
                    <p id="145">对比ATT-RLSTM和ATT-LSTM模型可以看出, ATT-RLSTM模型在REST和LAPT数据集上的分类效果均比ATT-LSTM模型差, 在AUTO数据集上的分类结果则优于ATT-LSTM模型。说明基于句子的特定目标词划分区域的方法虽然在一定程度上能帮助模型区分不同目标的情感信息, 但在区域划分不合理时也会丢失对特定目标有重要影响的词语。对比本文CNN-RLSTM模型和ATT-LSTM模型的实验结果可以看出, CNN-RLSTM模型在所有实验中的分类正确率均高于ATT-LSTM模型, 其中在提升最高的AUTO数据集上的三分类实验中, CNN-RLSTM模型比ATT-LSTM模型提升2.27%。说明结合CNN的CNN-RLSTM模型相比仅使用LSTM网络的ATT-LSTM模型能够更加充分地利用句子的情感特征信息。</p>
                </div>
                <div class="p1">
                    <p id="146">为进一步分析本文基于特定目标词来划分区域对实验结果的影响, 将ATT-RLSTM和CNN-RLSTM模型在AUTO数据集上采用不同长度的区域划分进行对比实验, 结果如图5和图6所示。</p>
                </div>
                <div class="area_img" id="147">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903048_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同区域长度三分类实验对比结果" src="Detail/GetImg?filename=images/JSJC201903048_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 不同区域长度三分类实验对比结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903048_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="148">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903048_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同区域长度二分类实验对比结果" src="Detail/GetImg?filename=images/JSJC201903048_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 不同区域长度二分类实验对比结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903048_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="149">综合图5和图6结果可以看出, CNN-RLSTM模型在所有区域长度的分类正确率都高于ATT-RLSTM模型, 从而验证结合区域LSTM和CNN的模型有效性。当区域长度为5时, ATT-RLSTM模型的分类正确率大幅下降, 说明基于特定目标词的区域划分方法在区域长度较短时会丢失对特定目标有重要影响的词语, 从而导致模型无法充分利用句子中的情感极性。CNN-RLSTM模型在区域长度为5时分类正确率最多只降低了3.46%, 说明CNN-RLSTM模型在区域划分不合理的情况下能根据CNN挖掘到的特征信息判断句子中特定目标的情感极性, 有效缓解因区域划分不当给模型带来的影响。此外, 当区域长度取值为15时, 2个模型的情感分类正确率都有所下降, 说明随着区域长度的增加, 会给特定目标的区域引入词语噪音, 从而导致模型无法有效区别不同目标的情感极性。当区域长度大于11时, CNN-RLSTM模型的分类正确率趋向平稳, 而随着区域长度的增大, 模型训练时间也会增加, 因此, 本文在实验中的区域长度取值为11。</p>
                </div>
                <h4 class="anchor-tag" id="150" name="150">3.5 模型训练时间分析</h4>
                <div class="p1">
                    <p id="151">为验证CNN-RLSTM模型相比传统结合注意力机制的LSTM模型具有更好的时间性能, 本文在相同的GPU、CPU、网络框架等环境下进行对比实验, 记录不同网络模型在REST数据集上完成一次迭代所需的时间, 实验结果如表5所示。</p>
                </div>
                <div class="area_img" id="152">
                    <p class="img_tit"><b>表5 不同网络模型完成一次迭代的训练时间</b> s <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="152" border="1"><tr><td><br />模型</td><td>时间</td></tr><tr><td><br />CNN</td><td>11</td></tr><tr><td><br />LSTM</td><td>126</td></tr><tr><td><br />ATT-CNN</td><td>28</td></tr><tr><td><br />ATT-LSTM</td><td>386</td></tr><tr><td><br />MATT-CNN</td><td>82</td></tr><tr><td><br />ATT-RLSTM</td><td>136</td></tr><tr><td><br />CNN-RLSTM</td><td>153</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="153">从表5可以看出, 在相同环境下LSTM网络完成一次迭代的时间是126 s, 是CNN完成一次迭代的11倍多, 说明LSTM网络的训练时间代价要远大于CNN。结合注意力机制的ATT-LSTM模型由于每一个神经元的计算都要考虑特定目标的注意力信息, 因此完成一次迭代需要的时间最长为386 s, 几乎是结合注意力机制的ATT-CNN模型的14倍, 说明接收句子序列性输入的LSTM网络相比接收平行化输入的CNN在考虑注意力信息时完成一次迭代需要更长的时间。对比结合注意力机制的LSTM中的ATT-LSTM、ATT-RLSTM、CNN-LSTM模型和传统LSTM模型可以看出, 结合注意力机制的ATT-LSTM模型完成一次迭代训练时间是传统LSTM模型的3倍多, 说明注意力机制的运算在训练过程中需要花费大量时间。而本文提出的CNN-RLSTM模型完成一次迭代的时间为153 s, 由于注意力的运算, 本文CNN-RLSTM模型虽然比传统LSTM模型高27 s, 但是远低于ATT-LSTM模型, 说明其在提升分类效果的前提下, 训练时间仍与传统LSTM模型在同一层次。</p>
                </div>
                <h3 id="154" name="154" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="155">本文结合CNN和LSTM网络提出一种深度网络模型并将其用于特定目标情感分析。在3种不同领域数据集上的实验结果表明, CNN-RLSTM模型能有效针对不同目标提取句子中的情感极性, 相比结合特征的SVM模型、结合注意力机制的LSTM模型、结合多种注意力机制的CNN模型具有更好的情感分类效果。在二分类实验中, CNN-RLSTM模型在AUTO数据集上的分类正确率为94.35%, 相比MATT-CNN模型提升1.19%。同时, CNN-RLSTM模型相比结合注意力机制的ATT-LSTM模型, 完成一次迭代所需的时间降低233 s。从实验结果可以看出, CNN-RLSTM模型在区域划分不合理时, 分类正确率会受到一定影响, 特别是当区域长度较小时, 下降比较明显。因此, 下一将研究更有效的区域划分方法, 提高模型分类效果和稳定性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 PANG B, LEE L.Opinion mining and sentiment analysis[J].Foundations and Trends in Information Retrieval, 2008, 2 (1/2) :102-135.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201602004&amp;v=MDk3NzZVcjdQTHl2U2RMRzRIOWZNclk5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N20=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 王仲远, 程健鹏, 王海勋, 等.短文本理解研究[J].计算机研究与发展, 2016, 53 (2) :262-269.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sem Eval-2014 Task 4:Aspect Based Sentiment Analysis">

                                <b>[3]</b> PONTIKI M, GALANIS D, PAVLOPOULOS J, et al.SemEval-2014 task 4:aspect based sentiment analysis[C]//Proceedings of the 8th International Workshop on Semantic Evaluation.Stroudsburg, USA:ACL Press, 2014:27-35.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003567381&amp;v=MDI3NDFDN2xWYnpKSVZrPU5qN0Jhck80SHRIUHFvbENaK01PWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRG&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> BOIY E, MOENS M F.A machine learning approach to sentiment analysis in multilingual Web texts[J].Information Retrieval, 2009, 12 (5) :526-558.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201309002&amp;v=MTA1MzR6cXFCdEdGckNVUkxPZVplUm9GeTdtVXI3UEx5dlNkTEc0SDlMTXBvOUZab1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 余凯, 贾磊, 陈雨强, 等.深度学习的昨天、今天和明天[J].计算机研究与发展, 2013, 50 (9) :1799-1804.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201708035&amp;v=MDMwMTQ5R1lZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N21VcjdQTHo3QmJiRzRIOWJNcDQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 王盛玉, 曾碧卿, 胡翩翩.基于卷积神经网络参数优化的中文情感分析[J].计算机工程, 2017, 43 (8) :200-207, 214.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">

                                <b>[7]</b> KIM Y.Convolutional neural networks for sentence classification[C]//Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2014:1746-1751.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attention-based bidirectional long short-term memory networks for relation classification">

                                <b>[8]</b> ZHOU P, SHI W, TIAN J, et al.Attention-based bidirectional long short-term memory networks for relation classification[C]//Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL Press, 2016:207-212.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Aspect Level Sentiment Classification with Deep Memory Network">

                                <b>[9]</b> TANG D, QIN B, LIU T.Aspect level sentiment classification with deep memory network[C]//Proceedings of 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2016:214-224.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201708009&amp;v=MDEwOTFNcDQ5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N21VcjdQTHl2U2RMRzRIOWI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 梁斌, 刘全, 徐进, 等.基于多注意力卷积神经网络的特定目标情感分析[J].计算机研究与发展, 2017, 54 (8) :1724-1735.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mining and summarizing customer reviews">

                                <b>[11]</b> HU M, LIU B.Mining and summarizing customer reviews[C]//Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2004:168-177.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mining opinion features in customer reviews">

                                <b>[12]</b> HU M, LIU B.Mining opinion features in customer reviews[C]//Proceedings of the 19th National Conference on Artifical Intelligence.Palo Alto, USA:AAAI Press, 2004:755-760.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=NRC-Canada-2014:detecting aspects and sentiment in customer reviews">

                                <b>[13]</b> KIRITCHENKO S, ZHU X, CHERRY C, et al.NRC-Canada-2014:detecting aspects and sentiment in customer reviews[C]//Proceedings of the 8th International Workshop on Semantic Evaluation.Stroudsburg, USA:ACL Press, 2014:437-442.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Phrase RNN:Phrase Recursive Neural Network for Aspect-based Sentiment Analysis">

                                <b>[14]</b> NGUYEN T H, SHIRAI K.PhraseRNN:phrase recursive neural network for aspect-based sentiment analysis[C]//Proceedings of 2015 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2015:2509-2514.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification">

                                <b>[15]</b> DONG L, WEI F, TAN C, et al.Adaptive recursive neural network for target-dependent twitter sentiment classification[C]//Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL Press, 2014:49-54.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">

                                <b>[16]</b> BAHDANAU D, CHO K, BENGIO Y.Neural machine translation by jointly learning to align and translate[EB/OL].[2017-11-15].https://arxiv.org/abs/1409.0473.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ABCNN:Attention-Based Convolutional Neural Network for Modeling Sentence Pairs">

                                <b>[17]</b> YIN W, SCHÜTZE H, XIANG B, et al.ABCNN:attention-based convolutional neural network for modeling sentence pairs[J].Transactions of the Association for Computational Linguistics, 2016, 4 (11) :259-272.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attention-based LSTM for Aspect-level Sentiment Classification">

                                <b>[18]</b> WANG Y, HUANG M, ZHAO L, et al.Attention-based LSTM for aspect-level sentiment classification[C]//Proceedings of 2016 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2016:606-615.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Natural language processing (almost) from scratch">

                                <b>[19]</b> COLLOBERT R, WESTON J, BOTTOU L, et al.Natural language processing (almost) from scratch[J].Journal of Machine Learning Research, 2011, 12:2493-2537.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Glove:Global vectors for word representation">

                                <b>[20]</b> PENNINGTON J, SOCHER R, MANNING C D.GloVe:Global Vectors for Word Representation[C]//Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL Press, 2014:1532-1543.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient estimation of word representations in vector space">

                                <b>[21]</b> MIKOLOV T, CHEN K, CORRADO G, et al.Efficient estimation of word representations in vector space[EB/OL].[2017-11-15].https://arxiv.org/abs/1301.3781.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Predicting polarities of tweets by composing word embeddings with long short-term memory">

                                <b>[22]</b> WANG X, LIU Y, SUN C, et al.Predicting polarities of tweets by composing word embeddings with long short-term memory[C]//Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg, USA:ACL Press, 2015:1343-1353.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201903048" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903048&amp;v=MzAxMTVtVXI3UEx6N0JiYkc0SDlqTXJJOUJiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
