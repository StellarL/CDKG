<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637128046243311250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201909040%26RESULT%3d1%26SIGN%3dezZO32Fu3l3U58LNDydcbR0ZH6M%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201909040&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201909040&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201909040&amp;v=MTQ4ODZHNEg5ak1wbzlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnk3bFZiN01MejdCYmI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#45" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#49" data-title="1 Contourlet变换 ">1 Contourlet变换</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#66" data-title="2 高斯马尔科夫随机场纹理建模 ">2 高斯马尔科夫随机场纹理建模</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#68" data-title="2.1 高斯马尔科夫随机场">2.1 高斯马尔科夫随机场</a></li>
                                                <li><a href="#77" data-title="2.2 GMRF建模及参数求解">2.2 GMRF建模及参数求解</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="3 声呐图像多尺度GMRF水平集分割算法 ">3 声呐图像多尺度GMRF水平集分割算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#86" data-title="3.1 四相水平集分割算法">3.1 四相水平集分割算法</a></li>
                                                <li><a href="#93" data-title="3.2 多尺度GMRF水平集分割算法">3.2 多尺度GMRF水平集分割算法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#97" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="5 结束语 ">5 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="&lt;b&gt;图1 Contourlet变换分解结构&lt;/b&gt;"><b>图1 Contourlet变换分解结构</b></a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;图2 声呐图像Contourlet多尺度变换&lt;/b&gt;"><b>图2 声呐图像Contourlet多尺度变换</b></a></li>
                                                <li><a href="#76" data-title="&lt;b&gt;图3 GMRF的1阶～4阶邻域模型结构&lt;/b&gt;"><b>图3 GMRF的1阶～4阶邻域模型结构</b></a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;图4 多尺度GMRF水平集分割算法流程&lt;/b&gt;"><b>图4 多尺度GMRF水平集分割算法流程</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;图5 声图分割过程&lt;/b&gt;"><b>图5 声图分割过程</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;图6 不同算法水下沉船声图分割效果对比1&lt;/b&gt;"><b>图6 不同算法水下沉船声图分割效果对比1</b></a></li>
                                                <li><a href="#100" data-title="&lt;b&gt;图7 不同算法水下飞机残骸声图分割效果对比1&lt;/b&gt;"><b>图7 不同算法水下飞机残骸声图分割效果对比1</b></a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;图8 不同算法水下沉船声图分割效果对比2&lt;/b&gt;"><b>图8 不同算法水下沉船声图分割效果对比2</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;图9 不同算法水下飞机残骸声图分割效果对比2&lt;/b&gt;"><b>图9 不同算法水下飞机残骸声图分割效果对比2</b></a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;表1 不同水平集分割算法的性能对比&lt;/b&gt;"><b>表1 不同水平集分割算法的性能对比</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;图10 不同噪声水平对分割效果影响对比&lt;/b&gt;"><b>图10 不同噪声水平对分割效果影响对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="148">


                                    <a id="bibliography_1" title=" 李海森,周天,徐超.多波束测深声纳技术研究新进展[J].声学技术,2013,32(2):73-80." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SXJS201302001&amp;v=MDU2MjdlWmVSckZ5N2xWYjdQTmpYQmZiRzRIOUxNclk5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         李海森,周天,徐超.多波束测深声纳技术研究新进展[J].声学技术,2013,32(2):73-80.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_2" title=" LANGNER F,KNAUER C,JANS W,et al.Side scan sonar image resolution and automatic object detection,classification and identification[C]//Proceedings of OCEANS’09.Washington D.C.,USA:IEEE Press,2009:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Side scan sonar image resolution and automatic object detection,classification and identi-fication">
                                        <b>[2]</b>
                                         LANGNER F,KNAUER C,JANS W,et al.Side scan sonar image resolution and automatic object detection,classification and identification[C]//Proceedings of OCEANS’09.Washington D.C.,USA:IEEE Press,2009:1-8.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_3" title=" 朱玲羚.基于Otsu法的声呐图像多阈值分割方法[J].水雷战与舰船防护,2016,24(4):68-71,47." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SLZH201604015&amp;v=MzIzMDVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeTdsVmI3UE5pSFJackc0SDlmTXE0OUVZWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         朱玲羚.基于Otsu法的声呐图像多阈值分割方法[J].水雷战与舰船防护,2016,24(4):68-71,47.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_4" title=" 李阳,庞永杰,盛明伟.结合空间信息的模糊聚类侧扫声纳图像分割[J].中国图象图形学报,2015,20(7):865-870." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201507002&amp;v=MDA4MDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnk3bFZiN1BQeXJmYkxHNEg5VE1xSTlGWm9RS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         李阳,庞永杰,盛明伟.结合空间信息的模糊聚类侧扫声纳图像分割[J].中国图象图形学报,2015,20(7):865-870.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_5" title=" ASHRAF A B,GAVENONIS S C,DAYE D,et al.A multichannel Markov random field framework for tumor segmentation with an application to classification of gene expression-based breast cancer recurrence risk[J].IEEE Transactions on Medical Imaging,2013,32(4):637-648." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Multichannel Markov Random Field Framework for TumorSegmentation With an Application to Classification of Gene Expression-Based Breast Cancer RecurrenceRisk">
                                        <b>[5]</b>
                                         ASHRAF A B,GAVENONIS S C,DAYE D,et al.A multichannel Markov random field framework for tumor segmentation with an application to classification of gene expression-based breast cancer recurrence risk[J].IEEE Transactions on Medical Imaging,2013,32(4):637-648.
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_6" title=" 王雷,叶秀芬,王天.模糊聚类的侧扫声纳图像分割算法[J].华中科技大学学报(自然科学版),2012,40(9):25-29." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HZLG201209007&amp;v=MjcwMThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnk3bFZiN1BMVGZIYWJHNEg5UE1wbzlGWTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         王雷,叶秀芬,王天.模糊聚类的侧扫声纳图像分割算法[J].华中科技大学学报(自然科学版),2012,40(9):25-29.
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_7" title=" SONG Sanming,SI Bailu,FENG Xisheng,et al.Label field initialization for MRF-based sonar image segmentation by selective autoencoding[C]//Proceedings of OCEANS’16.Washington D.C.,USA:IEEE Press,2016:1-5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Label field initialization for MRF-based sonar image segmentation by selective autoencoding">
                                        <b>[7]</b>
                                         SONG Sanming,SI Bailu,FENG Xisheng,et al.Label field initialization for MRF-based sonar image segmentation by selective autoencoding[C]//Proceedings of OCEANS’16.Washington D.C.,USA:IEEE Press,2016:1-5.
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_8" title=" SUN Ning,SHIM T,HAHN H.Sonar image segmentation based on Markov Gauss-Rayleigh mixture model[C]//Proceedings of International Workshop on Education Technology and International Workshop on Geoscience and Remote Sensing.Washington D.C.,USA:IEEE Computer Society,2008:704-709." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sonar image segmentation based on Markov Gauss-Rayleigh mixture model">
                                        <b>[8]</b>
                                         SUN Ning,SHIM T,HAHN H.Sonar image segmentation based on Markov Gauss-Rayleigh mixture model[C]//Proceedings of International Workshop on Education Technology and International Workshop on Geoscience and Remote Sensing.Washington D.C.,USA:IEEE Computer Society,2008:704-709.
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_9" title=" SANG Enfang,SHEN Zhengyan,FAN Chang,et al.Sonar image segmentation based on implicit active contours[C]//Proceedings of IEEE International Conference on Intelligent Computing and Intelligent Systems.Washington D.C.,USA:IEEE Press,2009:228-231." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sonar image segmentation based on implicit active con-tours">
                                        <b>[9]</b>
                                         SANG Enfang,SHEN Zhengyan,FAN Chang,et al.Sonar image segmentation based on implicit active contours[C]//Proceedings of IEEE International Conference on Intelligent Computing and Intelligent Systems.Washington D.C.,USA:IEEE Press,2009:228-231.
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_10" title=" LIU Guangyu,BIAN Hongyu,SHI Hong.Sonar image segmentation based on an improved level set method[J].Physics Procedia,2012,33:1168-1175." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300108768&amp;v=MDMyODZveG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxySUpsNFNheFU9TmlmT2ZiSzdIdEROckk5Rlplc0hDMw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         LIU Guangyu,BIAN Hongyu,SHI Hong.Sonar image segmentation based on an improved level set method[J].Physics Procedia,2012,33:1168-1175.
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_11" title=" WANG Xingmei,GUO Longxiang,YIN Jingwei,et al.Narrowband Chan-Vese model of sonar image segmentation:a adaptive ladder initialization approach[J].Applied Acoustics,2016,113:238-254." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESCAA127CEF53A66D1E8738E3C2FB42A1E&amp;v=MTU1NjBxUHd3RXU0TWZYby91eGRtNGpoK1FBcmgzeEJEQzdhV05MdnFDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOMWh3cmk1d2E4PU5pZk9mY0RKYjlETw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         WANG Xingmei,GUO Longxiang,YIN Jingwei,et al.Narrowband Chan-Vese model of sonar image segmentation:a adaptive ladder initialization approach[J].Applied Acoustics,2016,113:238-254.
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_12" title=" LU Wen,ZENG Kai,TAO Dacheng,et al.No-reference image quality assessment in contourlet domain[J].Neurocomputing,2010,73(4/6):784-794." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501911804&amp;v=MTgyMDl5am1VTHJJSmw0U2F4VT1OaWZPZmJLN0h0RE5xbzlFYmVvT0JIdzlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         LU Wen,ZENG Kai,TAO Dacheng,et al.No-reference image quality assessment in contourlet domain[J].Neurocomputing,2010,73(4/6):784-794.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_13" title=" DO M N,VETTERLI M.The contourlet transform:an efficient directional multiresolution image representation[J].IEEE Transactions on Image Processing,2005,14(12):2091-2106." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The contourlet transform: an efficient directional multiresolution image representation">
                                        <b>[13]</b>
                                         DO M N,VETTERLI M.The contourlet transform:an efficient directional multiresolution image representation[J].IEEE Transactions on Image Processing,2005,14(12):2091-2106.
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_14" title=" EMARY I M M E,RAMAKRISHNAN S.A critical review of statistical modeling of digital images[J].IAENG International Journal of Computer Science,2010,37(1):99-109." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJNG&amp;filename=SJNG13110800000895&amp;v=MjUyMTJIeWptVUxySUpsNFNheFU9TmlmRmFiSzdIOURNcDQ5RlpPc1BCSFU4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         EMARY I M M E,RAMAKRISHNAN S.A critical review of statistical modeling of digital images[J].IAENG International Journal of Computer Science,2010,37(1):99-109.
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_15" title=" YANG Xi,GAO Xinbo,TAO Dacheng,et al.An efficient MRF embedded level set method for image segmentation[J].IEEE Transactions on Image Processing,2014,24(1):9-21." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An efficient MRF embedded level set method for image segmentation">
                                        <b>[15]</b>
                                         YANG Xi,GAO Xinbo,TAO Dacheng,et al.An efficient MRF embedded level set method for image segmentation[J].IEEE Transactions on Image Processing,2014,24(1):9-21.
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_16" title=" ONURAL L.Gibbs random fields and Markov random fields with constraints[EB/OL].[2019-02-15].https://arxiv.org/pdf/1603.01481.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gibbs random fields and Markov random fields with constraints">
                                        <b>[16]</b>
                                         ONURAL L.Gibbs random fields and Markov random fields with constraints[EB/OL].[2019-02-15].https://arxiv.org/pdf/1603.01481.pdf.
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_17" title=" WANG Keqi,BAI Xuebing.Classification of wood surface texture based on Gauss-MRF model[J].Journal of Forestry Research,2006,17(1):57-61." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00000786803&amp;v=MDE2MzZyeG94Y01IN1I3cWVidWR0RkMzbFZiL09JVms9Tmo3QmFyTzRIdEhNcUlkRGJPc01ZM2s1ekJkaDRqOTlTWHFS&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         WANG Keqi,BAI Xuebing.Classification of wood surface texture based on Gauss-MRF model[J].Journal of Forestry Research,2006,17(1):57-61.
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_18" title=" YE Xiufen,ZHANG Zhehui,LIU P X,et al.Sonar image segmentation based on GMRF and level-set models[J].Ocean Engineering,2010,37(10):891-901." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600775015&amp;v=MDIzNTJlcnFRVE1ud1plWnVIeWptVUxySUpsNFNheFU9TmlmT2ZiSzdIdEROcVk5Rlkrd0tESDA4b0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         YE Xiufen,ZHANG Zhehui,LIU P X,et al.Sonar image segmentation based on GMRF and level-set models[J].Ocean Engineering,2010,37(10):891-901.
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_19" title=" COHEN R.The Chan-Vese algorithm[J].Computer Science,2011,5(1):10-16." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Chan-Vese algorithm">
                                        <b>[19]</b>
                                         COHEN R.The Chan-Vese algorithm[J].Computer Science,2011,5(1):10-16.
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_20" title=" B&#205;LKOV&#193; Z,SOUKUP J,KUERA V.Cell segmentation using level set methods with a new variance term[C]//Proceedings of International Conference on Image Analysis and Recognition.Berlin,Germany:Springer,2016:183-190." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cell segmentation using level set methods with a new variance term">
                                        <b>[20]</b>
                                         B&#205;LKOV&#193; Z,SOUKUP J,KUERA V.Cell segmentation using level set methods with a new variance term[C]//Proceedings of International Conference on Image Analysis and Recognition.Berlin,Germany:Springer,2016:183-190.
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_21" title=" VANTARAM S R,SABER E.Survey of contemporary trends in color image segmentation[EB/OL].[2019-02-15].http://spie.org/Publications/Journal/10.1117/1.JEI.21.4.040901." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEG848DBFE08C53BCC97272F5325D98F55D&amp;v=MDEwMDlhOD1OaWZPYWJ1OEZxVysyZnBGYkpnS0R3NUt2QjhVNkRoL1BucmhyaGRCY0xyaVFML3JDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOMWh3cmk1dw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         VANTARAM S R,SABER E.Survey of contemporary trends in color image segmentation[EB/OL].[2019-02-15].http://spie.org/Publications/Journal/10.1117/1.JEI.21.4.040901.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(09),253-259 DOI:10.19678/j.issn.1000-3428.0054281            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>Contourlet域下基于多尺度特征的声呐图像分割</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E9%B9%8F&amp;code=26992131&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李鹏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E5%98%89%E7%90%A6&amp;code=41898046&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈嘉琦</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E5%91%B3%E6%95%8F&amp;code=39556634&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马味敏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8F%B6%E6%96%B9%E8%B7%83&amp;code=38353438&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">叶方跃</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E4%BA%AC%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E6%B1%9F%E8%8B%8F%E7%9C%81%E6%B0%94%E8%B1%A1%E6%8E%A2%E6%B5%8B%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0151773&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南京信息工程大学江苏省气象探测与信息处理重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E4%BA%AC%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E6%B1%9F%E8%8B%8F%E7%9C%81%E6%B0%94%E8%B1%A1%E4%BC%A0%E6%84%9F%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF%E5%B7%A5%E7%A8%8B%E4%B8%AD%E5%BF%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南京信息工程大学江苏省气象传感网络技术工程中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>水下环境复杂多变,导致声呐技术成像后的图像质量差,影响目标识别。为此,提出一种基于Contourlet域下多尺度高斯马尔可夫随机场(GMRF)模型的水平集声呐图像分割算法。采用Contourlet变换及逆变换获取声呐图像各尺度层下的纹理特征,通过GMRF对各层纹理特征建模,以描述局部结构空间信息并降低对噪声的敏感度。根据各层纹理特征模型,对声呐图像进行由粗到细尺度的水平集分割以得到分割结果。实验结果表明,该算法在不同声呐图像中的分割准确度超过90%,优于Otsu算法,且具有较低的复杂度和较强的鲁棒性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Contourlet%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Contourlet变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E6%96%AF%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%9A%8F%E6%9C%BA%E5%9C%BA%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高斯马尔科夫随机场模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B0%B4%E5%B9%B3%E9%9B%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">水平集;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A3%B0%E5%91%90%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">声呐图像分割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">纹理特征;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李鹏(1966—),男,教授、博士,主研方向为超声成像、图像处理;;
                                </span>
                                <span>
                                    陈嘉琦,硕士研究生。;
                                </span>
                                <span>
                                    马味敏,硕士研究生。;
                                </span>
                                <span>
                                    叶方跃,硕士研究生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-18</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(41075115);</span>
                                <span>江苏省重点研发计划社会发展项目(BE201569);</span>
                                <span>江苏省“六大人才高峰”第十一批高层次人才项目(2014-XXRJ-006);</span>
                    </p>
            </div>
                    <h1><b>Sonar Image Segmentation Based on Multiscale Features in Contourlet Domain</b></h1>
                    <h2>
                    <span>LI Peng</span>
                    <span>CHEN Jiaqi</span>
                    <span>MA Weimin</span>
                    <span>YE Fangyue</span>
            </h2>
                    <h2>
                    <span>Jiangsu Key Laboratory of Meteorological Observation and Information Processing,Nanjing University of Information Science and Technology</span>
                    <span>Jiangsu Technology and Engineering Center of Meteorological Sensor Network,Nanjing University of Information Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Complex and changeable underwater environment leads to the poor quality of sonar images,decreasing the accuracy of target recognition.Therefore,a level set sonar image segmentation algorithm based on multiscale Gaussian Markov Random Field(GMRF) model under Contourlet domain is proposed.Contourlet transform and inverse transform are used to obtain the texture feature under each scale layer of the sonar image.The texture feature of each layer is modeled by GMRF to describe the local structure spatial information and reduce the sensitivity to noise.Based on the texture feature models of each layer,coarse-to-fine segmentation for level sets is performed on sonar images to obtain segmentation results.Experimental results show that the accuracy of the algorithm exceeds 90% in different sonar images,which is better than Otsu algorithm and has lower complexity and stronger robustness.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Contourlet%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Contourlet transform;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gauss%20Markov%20Random%20Field%20(GMRF)model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gauss Markov Random Field (GMRF)model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=level%20set&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">level set;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sonar%20image%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sonar image segmentation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=texture%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">texture feature;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-03-18</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="45" name="45" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="46">近年来,海洋水下观测受到国内外学者的广泛关注。随着水下声学研究和信号处理技术的发展<citation id="190" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>,声呐成像技术成为人类探索水下世界,诸如水下资源勘查、地形地貌研究、水底目标搜寻及打捞的有力工具。由于水下环境复杂,且目标具有不确定性,对声呐图像进行分割成为海洋水下观测的研究热点<citation id="191" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="47">文献<citation id="192" type="reference">[<a class="sup">3</a>]</citation>提出Otsu方法,通过调整图像亮度,利用最大类间方差获取多阈值,从而对声呐图像进行分割,该方法解决了水声图像对比度偏暗的问题,但忽略了水下复杂背景纹理灰度分布对阈值的影响。为解决该问题,文献<citation id="193" type="reference">[<a class="sup">4</a>]</citation>采用改进模糊C均值(Fuzzy C Mean,FCM)方法对水声图像进行分割,通过组合邻域中值滤波克服FCM对噪声敏感的缺点,但该方法未考虑平滑对高频细节的影响,导致分割后边缘模糊。文献<citation id="194" type="reference">[<a class="sup">5</a>]</citation>提出基于图形间空间关系的马尔科夫随机场(Markov Random Field,MRF)分割方法,该方法描述了像素与其领域像素间的依赖关系。在此基础上,国内外学者对MRF模型应用于水下声呐图形分割进行深入研究并取得了一定成果<citation id="199" type="reference"><link href="158" rel="bibliography" /><link href="160" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>,但相关方法需要初始分割且运算复杂,不满足实时性图形处理的要求。文献<citation id="195" type="reference">[<a class="sup">8</a>]</citation>利用Gauss-Rayleigh混合分布作为MRF特征向量对声呐图像进行分割,这在一定程度上提高了分割效率。文献<citation id="196" type="reference">[<a class="sup">9</a>]</citation>将偏微分方程应用于图像数据处理中,使基于水平集的声呐图像分割效果有较大提升。文献<citation id="197" type="reference">[<a class="sup">10</a>]</citation>提出基于提升水平集的目标分割方法,该方法仅对目标单区域分割,存在拓扑性差的问题。文献<citation id="198" type="reference">[<a class="sup">11</a>]</citation>提出改进多相CV模型,并将该模型应用于声呐图像分割,在一定程度上降低了背景噪声对分割算法的影响,但该模型需要多次迭代,影响分割准确度。</p>
                </div>
                <div class="p1">
                    <p id="48">本文根据水下声呐图像特点,基于分割准确度、背景噪声抑制和运算效率,提出Contourlet域下高斯马尔科夫随机场(Gauss Markov Random Field,GMRF)模型的多尺度水平集声呐图像分割算法。采用Contourlet变换及逆变换获取各尺度层下的分解纹理特征,通过GMRF对各层分解纹理特征建模,描述其局部结构空间信息,根据各层纹理模型,对声图进行由粗到细尺度的水平集分割,从而验证本文算法的有效性。</p>
                </div>
                <h3 id="49" name="49" class="anchor-tag">1 Contourlet变换</h3>
                <div class="p1">
                    <p id="50">Contourlet变换是针对图像几何结构以获取线或面奇异性稀疏表示的一种多分辨率分析工具,将<i>L</i><sub>2</sub>(<i>R</i><sup>2</sup>)分解为不同方向且互相正交的子空间,有:</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>R</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mi>V</mi><msub><mrow></mrow><mi>J</mi></msub><mo>⊕</mo><mrow><mo>(</mo><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mo>⊕</mo></mstyle><mrow><mi>j</mi><mo>≤</mo><mi>J</mi></mrow></munder><mi>Μ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>V</mi><msub><mrow></mrow><mi>J</mi></msub><mo>⊕</mo><mrow><mo>(</mo><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mo>⊕</mo></mstyle><mrow><mi>j</mi><mo>≤</mo><mi>J</mi></mrow></munder><mrow><mo>(</mo><mrow><munderover><mstyle mathsize="140%" displaystyle="true"><mo>⊕</mo></mstyle><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mn>2</mn><msup><mrow></mrow><mrow><mi>l</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mn>1</mn></mrow></msup></mrow></munderover><mi>Μ</mi><msubsup><mrow></mrow><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mrow><mo stretchy="false">(</mo><mi>l</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></msubsup></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow><mo>,</mo><mo stretchy="false">(</mo><mi>j</mi><mo>,</mo><mi>k</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>Ζ</mi><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">其中,<i>V</i><sub><i>J</i></sub>表示一系列闭子空间,<i>M</i><sub><i>j</i></sub>表示尺度为<i>j</i>的小波空间,该变换克服了小波分析在二维图像曲线轮廓等奇异处刻画不足的问题<citation id="200" type="reference"><link href="170" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。Contourlet变换的基本思想:采用拉普拉斯塔式(Laplacian Pyramid,LP)滤波器与方向滤波器组(Directional Filter Bank,DFB)以实现多分辨率、局部性和各方向尺度异性的图形稀疏描述,Contourlet变换分解具有多尺度和多方向分析的特点。Contourlet变换分解结构如图1所示<citation id="201" type="reference"><link href="172" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909040_053.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Contourlet变换分解结构" src="Detail/GetImg?filename=images/JSJC201909040_053.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 Contourlet变换分解结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909040_053.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="54">采用LP对图形进行多尺度分析,原声呐图像经LP分解产生的一个低频近似子带和高频细节子带,继续对该低频子带采用LP迭代滤波,逐步得到图像多分辨率分解。LP分解表达式为:</p>
                </div>
                <div class="p1">
                    <p id="55"><i>a</i><sub><i>j</i></sub>[<i>n</i>]=&lt;<i>x</i>,<i>φ</i><sub><i>j</i></sub>&gt;      (2)</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>φ</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>,</mo><mi>n</mi></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>n</mi><mo>∈</mo><mi>Ζ</mi></mrow></munder><mi>h</mi></mstyle><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mi>φ</mi><mo stretchy="false">(</mo><mn>2</mn><mi>t</mi><mo>-</mo><mi>n</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">其中,<i>h</i>(<i>n</i>)为低通滤波器,<i>φ</i><sub><i>j</i></sub>,<i>n</i>为尺度函数。二维DFB对LP分解后的高频子带分解为2<sup><i>n</i></sup>个不同方向子带,方向滤波器由“梅花”形滤波器组<i>H</i><sub>0</sub>、<i>H</i><sub>1</sub>、<i>G</i><sub>0</sub>、<i>G</i><sub>1</sub>构成,DFB需要满足如下完全重构条件:</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>Η</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo><mi>G</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo><mo>+</mo><mi>Η</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo><mi>G</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn></mtd></mtr><mtr><mtd columnalign="left"><mi>Η</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">(</mo><mi>w</mi><mo>+</mo><mtext>π</mtext><mo stretchy="false">)</mo><mi>G</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo><mo>+</mo><mi>Η</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>w</mi><mo>+</mo><mtext>π</mtext><mo stretchy="false">)</mo><mi>G</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">高频方向子带<i>c</i><sub><i>j</i></sub>,<i>k</i>表示为:</p>
                </div>
                <div class="p1">
                    <p id="60"><i>c</i><sub><i>j</i></sub>,<i>k</i>=&lt;<i>a</i><sub><i>j</i></sub>,<i>φ</i><sub><i>j</i></sub>&gt;=&lt;&lt;<i>x</i>,<i>φ</i><sub><i>j</i></sub>&gt;,<i>φ</i><sub><i>j</i></sub>&gt;      (5)</p>
                </div>
                <div class="p1">
                    <p id="61">其中,<i>φ</i><sub><i>j</i></sub>为DFB系数空间基函数。信号在Contourlet域下由低频子带<i>a</i><sub><i>J</i></sub>和细节子带<i>c</i><sub><i>j</i></sub>,<i>k</i>近似构成,其表达式为:</p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo>≈</mo><mi>a</mi><msub><mrow></mrow><mi>J</mi></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>l</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munderover><mi>c</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63">Contourlet变换本质为由LP捕获图像奇异点,再由LP与DFB相结合将分布于某一方向的奇异点连成周线结构,从而更好地逼近图像轮廓曲线。</p>
                </div>
                <div class="p1">
                    <p id="64">图2是一幅水下沉船的声呐图像在不同尺度的分解和重构图像。图2(a)是输入的声呐图像{<i>f</i>(<i>x</i>,<i>y</i>)<i>x</i>,<i>y</i>∈<i>D</i>},其中,(<i>x</i>,<i>y</i>)为像素索引,<i>D</i>为图像域,对声图进行Contourlet变换,经带通滤波器分解得到低频子带系数<i>a</i><sub><i>j</i></sub>[<i>n</i>]和高频子带系数<i>b</i><sub><i>j</i></sub>[<i>n</i>],<i>j</i>为Contourlet变换所对应分解层数,DFB对第<i>l</i><sub><i>j</i></sub>层分解声图<i>b</i><sub><i>j</i></sub>[<i>n</i>],并进一步分解为2<sup><i>l</i></sup><sub><i>j</i></sub>个不同方向细节子带系数<i>c</i><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mrow><mi>l</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msubsup></mrow></math></mathml>[<i>n</i>],<i>k</i>=0,1,…,2<sup><i>l</i></sup><sub><i>j</i></sub>-1,其分解后各尺度和各方向的图像如图2(b)所示,该Contourlet变换为2层结构,从低到高每层分别对应4个和8个不同方向子带信息,第2层分解结果显示Contourlet支撑域为长和宽可变的“矩形”结构,采用该结构优势在于对图像表达更具稀疏性,且在每级中方向子带个数为可变,即可由多方向来逼近图像轮廓曲线,因此采用Contourlet变换可有效获取原始声图全局纹理特征规律及目标边缘轮廓信息。图2(c)为各层重构后图形<i>W</i><sub><i>j</i></sub>,顺序依次为由粗到细变化的尺度,可以看出,粗尺度包含原始声图主要纹理特征,细尺度主要为声图的高频信息即目标轮廓。观察第2层高频子带重构图形不难发现其仅含有原始声图边缘轮廓信息,该特性可为图像细分割后得到更加完整、精确的边缘轮廓提供理论依据。本文从声呐灰度图像低分辨率、复杂背景混响区及目标边缘残破不清晰等特点出发,采用Contourlet对声呐图像进行多尺度分解,将其重构后获得声呐图像各尺度层下的分解特征纹理。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909040_065.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 声呐图像Contourlet多尺度变换" src="Detail/GetImg?filename=images/JSJC201909040_065.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 声呐图像Contourlet多尺度变换</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909040_065.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="66" name="66" class="anchor-tag">2 高斯马尔科夫随机场纹理建模</h3>
                <div class="p1">
                    <p id="67">本文将变换方法与模型相结合,通过Contourlet域下获取各尺度层图像的分解特征纹理。纹理模型的建立有多种方法,如运用统计、信号分析等方法<citation id="202" type="reference"><link href="174" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>,其中,GMRF作为一种描述图像像素间空间相关性的概率模型,能较好地表现图像纹理特征,为此,本文采用GMRF方法对各尺度层图形进行分解并构建纹理模型。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68">2.1 高斯马尔科夫随机场</h4>
                <div class="p1">
                    <p id="69">设<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mrow><mo>(</mo><mrow><mi>s</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>s</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>s</mi><msub><mrow></mrow><mi>Ν</mi></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>为二维空间随机场位置集,∀s∈S处随机场X={x<sub>s</sub>,s∈S}称为标号场,在S上二维空间邻域系统ξ={ξ(s)|s∈S},称ξ(s)为s的空间邻域点集,称r∈ξ(s)为s的邻点,对于∀n≥0,ξ<sup>n</sup>(s)⊂ξ<sup>n+1</sup>(s),即低阶系统需包含在高阶邻域系统中<citation id="203" type="reference"><link href="176" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。设有如下条件:</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false">{</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo stretchy="false">}</mo><mo>&gt;</mo><mn>0</mn><mo>,</mo><mo>∀</mo><mi>x</mi><mo>⊂</mo><mi>X</mi></mtd></mtr><mtr><mtd><mi>p</mi><mo stretchy="false">{</mo><mi>X</mi><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mi>x</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">|</mo><mi>X</mi><msub><mrow></mrow><mi>r</mi></msub><mo>=</mo><mi>x</mi><msub><mrow></mrow><mi>r</mi></msub><mo>,</mo><mi>r</mi><mo>≠</mo><mi>s</mi><mo>,</mo><mo>∀</mo><mi>r</mi><mo>∈</mo><mi>ξ</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>p</mi><mo stretchy="false">{</mo><mi>X</mi><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mi>x</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">|</mo><mi>X</mi><msub><mrow></mrow><mi>r</mi></msub><mo>=</mo><mi>x</mi><msub><mrow></mrow><mi>r</mi></msub><mo>,</mo><mi>r</mi><mo>∈</mo><mi>ξ</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71">若随机场<mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><mo>=</mo><mrow><mo>{</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">|</mo><mi>s</mi><mo>∈</mo><mi>S</mi></mrow><mo>}</mo></mrow></mrow></math></mathml>满足式(7),则称X是关于邻域系统ξ的n阶<i>GMRF</i>,该表达式满足2个条件:正定性和马尔科夫性。因此二维图形纹理可以看作是一个<i>MRF</i><citation id="204" type="reference"><link href="178" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>,即图形区域内任意像素点灰度值由该邻域内灰度值决定,与邻域外其他灰度无关。当<i>MRF</i>服从高斯分布时,其条件概率为:</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">|</mo><mi>X</mi><msub><mrow></mrow><mi>r</mi></msub><mo>,</mo><mi>r</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mtext>π</mtext></mrow></msqrt><mi>σ</mi></mrow></mfrac><mrow><mi>exp</mi></mrow><mo stretchy="false">{</mo><mo>-</mo><mo stretchy="false">[</mo><mi>X</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>-</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder><mi>θ</mi></mstyle><msub><mrow></mrow><mi>r</mi></msub><mi>X</mi><msub><mrow></mrow><mi>r</mi></msub></mrow><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup><mo>/</mo><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">其中,σ为分布条件方差,N<mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>k</mi></msubsup></mrow></math></mathml>={s+r,r∈η<sup>k</sup>}为点s邻域集,以二阶对称邻域为例,r={(1,0),(1,-1),(0,-1),(-1,-1),(-1,0),(-1,1),(0,1),(1,1)},θ<sub>r</sub>描述像素间相互关系与空间结构信息。当纹理图像服从均值为0的高斯随机过程时,<i>GMRF</i>模型可由差分方程表示邻域中心点与相邻点间关系,即:</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>X</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder><mi>θ</mi></mstyle><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false">[</mo><mi>X</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo><mo>+</mo><mi>X</mi><mo stretchy="false">(</mo><mo>-</mo><mi>r</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mtd></mtr><mtr><mtd><mi>s</mi><mo>∈</mo><mi>S</mi><mo>,</mo><mi>S</mi><mo>=</mo><mrow><mo>{</mo><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>,</mo><mn>1</mn><mo>≤</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>≤</mo><mi>Μ</mi></mrow><mo>}</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">不同邻域有不同N<sub>s</sub>,图3所示为<i>GMRF</i>的1阶～4阶邻域模型结构,可以看出,该模型邻域参数具有对称性,遍历像素点S可得到关于{X(s)}的方程组X=<i><b>G</b></i><i>θ</i>,通过最小二乘可求出GMRF特征向量<mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">θ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow></math></mathml>,则提取图形特征问题就转变成求解GMRF模型参数方程<citation id="205" type="reference"><link href="180" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>问题。</p>
                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909040_076.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 GMRF的1阶～4阶邻域模型结构" src="Detail/GetImg?filename=images/JSJC201909040_076.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 GMRF的1阶～4阶邻域模型结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909040_076.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="77" name="77">2.2 GMRF建模及参数求解</h4>
                <div class="p1">
                    <p id="78">在Contourlet域中获取声图各尺度下的重构图像纹理特征,尺度由粗到细分别代表声呐图像概貌特征与高频边缘纹理信息,由于图像纹理像素间存在空间依赖关系<citation id="206" type="reference"><link href="182" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>,因此,Contourlet域各尺度分解图形纹理也有相近依赖关系,如果细尺度分解层中某像素周围为目标轮廓,那么该点为目标轮廓的概率就较大,从而降低对噪声的敏感度。通过获取原始声呐图像,为Contourlet域的各层多尺度分解图形纹理构建GMRF模型,用于描述声呐图像纹理间空间结构信息,以融合全局与局部特征,从而精准描述水下声呐目标特征纹理。</p>
                </div>
                <div class="p1">
                    <p id="79">设Contourlet变换在第<i>l</i><sub><i>j</i></sub>层子带系数为<i>c</i><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mrow><mi>l</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msubsup></mrow></math></mathml>,<i>k</i>=0,1…,2<sup><i>l</i></sup><sub><i>j</i></sub>-1,对该层子带系数Contourlet逆变换获得该尺度层重构特征<i>w</i><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>j</mi></msubsup></mrow></math></mathml>s∈<image href="images/JSJC201909040_121.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup>2</sup>,由式(8)可得<i>GMRF</i>条件概率密度函数为:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false">(</mo><mi>w</mi><msubsup><mrow></mrow><mi>s</mi><mi>j</mi></msubsup><mo stretchy="false">|</mo><mi>w</mi><msubsup><mrow></mrow><mrow><mi>s</mi><mo>+</mo><mi>r</mi></mrow><mi>j</mi></msubsup><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mtext>π</mtext></mrow></msqrt><mi>σ</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>,</mo><mi>r</mi></mrow></msub></mrow></mfrac><mrow><mi>exp</mi></mrow><mo stretchy="false">{</mo><mo>-</mo><mrow><mo>[</mo><mrow><mi>w</mi><msubsup><mrow></mrow><mi>s</mi><mi>j</mi></msubsup><mo>-</mo><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder><mi>θ</mi></mstyle><msub><mrow></mrow><mrow><mi>j</mi><mo>,</mo><mi>r</mi></mrow></msub><mi>w</mi><msubsup><mrow></mrow><mrow><mi>s</mi><mo>+</mo><mi>r</mi></mrow><mi>j</mi></msubsup></mrow></mrow><mo>]</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>/</mo><mn>2</mn><mrow><mo stretchy="false">(</mo><mi>σ</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>,</mo><mi>r</mi></mrow></msub><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">其中,∀r∈η,θ<sub>j,r</sub>=θ<sub>j,-r</sub>,σ<sub>j,r</sub>为<i>GMRF</i>分布的方向参数与方差,表示各层分解图像纹理特征,该式说明p(w<sup>j</sup><sub>s</sub>)的<i>MRF</i>性即取值仅与当前邻域空间位置有关。为进一步求解参数特征,设第j层尺度重构特征量w<mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>j</mi></msubsup></mrow></math></mathml>的n阶<i>GMRF</i>纹理模型表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msubsup><mrow></mrow><mi>s</mi><mi>j</mi></msubsup><mo>=</mo><mi mathvariant="bold-italic">θ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">Q</mi><msub><mrow></mrow><mi>s</mi></msub><mo>+</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mtext>π</mtext></mrow></msqrt><mi>σ</mi></mrow></mfrac><mrow><mi>exp</mi></mrow><mrow><mo>(</mo><mrow><mfrac><mrow><mo>-</mo><mi>w</mi><msubsup><mrow></mrow><mi>s</mi><mi>j</mi></msubsup><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">其中,<i>θ</i>为所有<i>θ</i><sub><i>j</i></sub>,<i>r</i>构成的GMRF参数向量,<i><b>Q</b></i><sub><i>s</i></sub>=[<i>w</i><sub><i>s</i></sub>+<i>r</i>1+<i>w</i><sub><i>s</i></sub>-<i>r</i>1,<i>w</i><sub><i>s</i></sub>+<i>r</i>2+<i>w</i><sub><i>s</i></sub>-<i>r</i>2,…,<i>w</i><sub><i>s</i></sub>+<i>rn</i>+<i>w</i><sub><i>s</i></sub>-<i>rn</i>]<sup>T</sup>,由式(11)通过最小二乘求得参数<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">θ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow></math></mathml>和方差<mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>σ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">θ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>=</mo><mo stretchy="false">[</mo><mstyle displaystyle="true"><mo>∑</mo><mi mathvariant="bold-italic">Q</mi></mstyle><msub><mrow></mrow><mi>s</mi></msub><mi mathvariant="bold-italic">θ</mi><msubsup><mrow></mrow><mi>S</mi><mtext>Τ</mtext></msubsup><mo stretchy="false">]</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false">[</mo><mstyle displaystyle="true"><mo>∑</mo><mi mathvariant="bold-italic">Q</mi></mstyle><msub><mrow></mrow><mi>s</mi></msub><mi>w</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">]</mo></mtd></mtr><mtr><mtd columnalign="left"><mover><mstyle mathsize="140%" displaystyle="true"><mi>σ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Μ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mstyle displaystyle="true"><mo>∑</mo><mo stretchy="false">(</mo></mstyle><mi>w</mi><msub><mrow></mrow><mi>s</mi></msub><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">θ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mi mathvariant="bold-italic">Q</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">)</mo></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="85" name="85" class="anchor-tag">3 声呐图像多尺度GMRF水平集分割算法</h3>
                <h4 class="anchor-tag" id="86" name="86">3.1 四相水平集分割算法</h4>
                <div class="p1">
                    <p id="87">水平集分割算法基本思想为:初始曲线沿法线方向在能量函数驱动下向目标边缘移动,完成对目标分割,将图形分割问题转化成求解能量泛函最小化问题,该算法具有较强的拓扑自适应性。依据该思想,可以把水下声呐图像分割的过程看作在二维平面上,将一些特征参数作用在一系列闭合曲线并向声呐图像边缘运动的过程。对于声呐图像,除目标区外,还包括目标影区,而阴影区形状在后续目标判别中起到一定作用,因此,本文采用四相水平集分割模型,将声呐图像分割为3类,模型在确定待分割种类个数后,利用水平集函数互相约束,以达到分割目的,设原始声呐图像<i>I</i><sub>0</sub>:<i>Ω</i>→<i>R</i>,对文献<citation id="207" type="reference">[<a class="sup">19</a>]</citation>中能量驱动泛函进行改进,有:</p>
                </div>
                <div class="area_img" id="88">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201909040_08800.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="89">其中,<i>N</i>为GMRF纹理特征阶数,<mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mrow><mo>(</mo><mrow><mi>φ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>为<i>Heaviside</i>函数,φ<sub>j</sub>(j=1,2)为水平集函数,w<sup>n</sup>为<i>GMRF</i>模型不同阶邻域纹理特征向量,c为w<sup>n</sup>的特征均值,通过求解能量泛函所对应<i>Euler</i>-<i>Lagrange</i>方程<citation id="208" type="reference"><link href="186" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>,得到水平集函数演化方程。</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mo>∂</mo><mspace width="0.25em" /><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mo>∂</mo><mspace width="0.25em" /><mi>t</mi></mrow></mfrac><mo>=</mo><mi>λ</mi><mrow><mo>[</mo><mrow><mtext>Δ</mtext><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>d</mi><mi>i</mi><mi>v</mi><mo stretchy="false">(</mo><mfrac><mrow><mtext>Δ</mtext><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>|</mo></mrow></mrow></mfrac><mo stretchy="false">)</mo></mrow><mo>]</mo></mrow><mo>+</mo><mi>δ</mi><msub><mrow></mrow><mi>ε</mi></msub><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">{</mo><mi>v</mi><mo>⋅</mo><mi>d</mi><mi>i</mi><mi>v</mi><mo stretchy="false">(</mo><mfrac><mrow><mo>∇</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>|</mo></mrow></mrow></mfrac><mo stretchy="false">)</mo><mo>-</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mfrac><mn>1</mn><mrow><mi>Ν</mi><mo>+</mo><mn>1</mn></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><mo>+</mo><mn>1</mn></mrow></munderover><mi>λ</mi></mstyle><msup><mrow></mrow><mi>n</mi></msup><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>w</mi><msup><mrow></mrow><mi>n</mi></msup><mo>-</mo><mi>C</mi><msubsup><mrow></mrow><mn>1</mn><mi>n</mi></msubsup><mo stretchy="false">)</mo><mn>2</mn><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mi>w</mi><msup><mrow></mrow><mi>n</mi></msup><mo>-</mo><mi>C</mi><msubsup><mrow></mrow><mn>3</mn><mi>n</mi></msubsup><mo stretchy="false">)</mo><mn>2</mn><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo>-</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mi>w</mi><msup><mrow></mrow><mi>n</mi></msup><mo>-</mo><mi>C</mi><msubsup><mrow></mrow><mn>2</mn><mi>n</mi></msubsup><mo stretchy="false">)</mo><mn>2</mn><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo>-</mo><mo stretchy="false">(</mo><mi>w</mi><msup><mrow></mrow><mi>n</mi></msup><mo>-</mo><mi>C</mi><msubsup><mrow></mrow><mn>4</mn><mi>n</mi></msubsup><mo stretchy="false">)</mo><mn>2</mn><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mo>∂</mo><mspace width="0.25em" /><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mo>∂</mo><mspace width="0.25em" /><mi>t</mi></mrow></mfrac><mo>=</mo><mi>λ</mi><mrow><mo>[</mo><mrow><mtext>Δ</mtext><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mi>d</mi><mi>i</mi><mi>v</mi><mo stretchy="false">(</mo><mfrac><mrow><mtext>Δ</mtext><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>|</mo></mrow></mrow></mfrac><mo stretchy="false">)</mo></mrow><mo>]</mo></mrow><mo>+</mo><mi>δ</mi><msub><mrow></mrow><mi>ε</mi></msub><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">{</mo><mi>v</mi><mo>⋅</mo><mi>d</mi><mi>i</mi><mi>v</mi><mo stretchy="false">(</mo><mfrac><mrow><mo>∇</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>|</mo></mrow></mrow></mfrac><mo stretchy="false">)</mo><mo>-</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mfrac><mn>1</mn><mrow><mi>Ν</mi><mo>+</mo><mn>1</mn></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><mo>+</mo><mn>1</mn></mrow></munderover><mi>λ</mi></mstyle><msup><mrow></mrow><mi>n</mi></msup><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>w</mi><msup><mrow></mrow><mi>n</mi></msup><mo>-</mo><mi>C</mi><msubsup><mrow></mrow><mn>1</mn><mi>n</mi></msubsup><mo stretchy="false">)</mo><mn>2</mn><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mi>w</mi><msup><mrow></mrow><mi>n</mi></msup><mo>-</mo><mi>C</mi><msubsup><mrow></mrow><mn>3</mn><mi>n</mi></msubsup><mo stretchy="false">)</mo><mn>2</mn><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo>-</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mi>w</mi><msup><mrow></mrow><mi>n</mi></msup><mo>-</mo><mi>C</mi><msubsup><mrow></mrow><mn>2</mn><mi>n</mi></msubsup><mo stretchy="false">)</mo><mn>2</mn><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo>-</mo><mo stretchy="false">(</mo><mi>w</mi><msup><mrow></mrow><mi>n</mi></msup><mo>-</mo><mi>C</mi><msubsup><mrow></mrow><mn>4</mn><mi>n</mi></msubsup><mo stretchy="false">)</mo><mn>2</mn><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mn>1</mn><mi>n</mi></msubsup><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>Ω</mi></msub><mi>w</mi></mrow></mstyle><msup><mrow></mrow><mi>n</mi></msup><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mtext>d</mtext><mi>x</mi><mtext>d</mtext><mi>y</mi></mrow><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>Ω</mi></msub><mi>Η</mi></mrow></mstyle><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mtext>d</mtext><mi>x</mi><mtext>d</mtext><mi>y</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mn>2</mn><mi>n</mi></msubsup><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>Ω</mi></msub><mi>w</mi></mrow></mstyle><msup><mrow></mrow><mi>n</mi></msup><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">[</mo><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mtext>d</mtext><mi>x</mi><mtext>d</mtext><mi>y</mi></mrow><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>Ω</mi></msub><mi>Η</mi></mrow></mstyle><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">[</mo><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mtext>d</mtext><mi>x</mi><mtext>d</mtext><mi>y</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mn>3</mn><mi>n</mi></msubsup><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>Ω</mi></msub><mi>w</mi></mrow></mstyle><msup><mrow></mrow><mi>n</mi></msup><mo stretchy="false">[</mo><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mtext>d</mtext><mi>x</mi><mtext>d</mtext><mi>y</mi></mrow><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>Ω</mi></msub><mo stretchy="false">[</mo></mrow></mstyle><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mtext>d</mtext><mi>x</mi><mtext>d</mtext><mi>y</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>c</mi><msubsup><mrow></mrow><mn>4</mn><mi>n</mi></msubsup><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>Ω</mi></msub><mi>w</mi></mrow></mstyle><msup><mrow></mrow><mi>n</mi></msup><mo stretchy="false">[</mo><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mtext>d</mtext><mi>x</mi><mtext>d</mtext><mi>y</mi></mrow><mrow><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>Ω</mi></msub><mo stretchy="false">[</mo></mrow></mstyle><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mn>1</mn><mo>-</mo><mi>Η</mi><mo stretchy="false">(</mo><mi>φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mtext>d</mtext><mi>x</mi><mtext>d</mtext><mi>y</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>9</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92">水平集函数<i>φ</i><sub>1</sub>与<i>φ</i><sub>2</sub>将图形分成4个区域,设<i>φ</i><sub>1</sub>演化为声呐图像目标亮区边沿函数,则<i>φ</i><sub>2</sub>演化为声呐图像目标影区边沿函数,<i>φ</i><sub>1</sub>和<i>φ</i><sub>2</sub>之外的部分为背景区,在运算过程中初始轮廓线交叠现象将逐步消失,从最初4个区域逐步演变为3个区域,最终完成分割过程。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93">3.2 多尺度GMRF水平集分割算法</h4>
                <div class="p1">
                    <p id="94">由于声呐图像灰度对比度低,整体成像效果远不如光学图像,采用传统分割算法较难从复杂水下混响背景区提取目标与阴影,利用<i>Contourlet</i>变换将原始声呐图像由粗到细分解为J层,每一级包含一个低频与若干个高频分量,实现图形多尺度分解,再对每层高频系数重构,以实现层级各方向特征融合。由于图形像素间空间相关性,各尺度分解后的重构图像W<sub>j</sub>也必然存在此特性,因此本文引入<i>GMRF</i>对W<sub>j</sub>建模,用来表达隐藏的局部结构关系,进而融合图像纹理局部与全局特征。声呐图像经<i>Contourlet</i>分解后,粗尺度低频近似分量包含主要纹理信息,可将粗尺度低频系数<i>GMRF</i>特征向量参数作为水平集驱动,对声呐图像进行粗分割得到初始轮廓,由于不包含复杂细节与高频噪声,降低了曲线演化迭代次数。多尺度<i>GMRF</i>水平集算法的流程描述如图4所示。图5是水下飞机残骸声呐图像的分割过程,图5(<i>b</i>)为粗分割10次迭代结果,将前一级分割后的轮廓线进行插值并作为后一级尺度分割的初始轮廓。由于细尺度高频分量主要为图像轮廓信息,一方面可加速迭代速度,另一方面使分割后曲线更加逼近真实目标轮廓,图5(<i>c</i>)和5(<i>d</i>)分别为细尺度1和细尺度2迭代15次分割结果,重复上一步直到第J层,得到声呐目标分割最终结果,如图5(<i>e</i>)所示。</p>
                </div>
                <div class="area_img" id="95">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909040_095.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 多尺度GMRF水平集分割算法流程" src="Detail/GetImg?filename=images/JSJC201909040_095.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 多尺度GMRF水平集分割算法流程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909040_095.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909040_096.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 声图分割过程" src="Detail/GetImg?filename=images/JSJC201909040_096.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 声图分割过程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909040_096.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="97" name="97" class="anchor-tag">4 实验结果与分析</h3>
                <div class="p1">
                    <p id="98">为验证本文算法对于水下声呐目标分割的有效性,对不同声呐图像进行分割,并采用不同分割算法进行对比实验。本文实验在Intel Core i3-2100 CPU 3.10 GHz、4 GB内存、Windows7操作系统平台环境中运行。图6和图7分别是水下沉船和飞机残骸声呐图像采用不同算法的分割结果。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909040_099.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法水下沉船声图分割效果对比1" src="Detail/GetImg?filename=images/JSJC201909040_099.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 不同算法水下沉船声图分割效果对比1</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909040_099.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909040_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同算法水下飞机残骸声图分割效果对比1" src="Detail/GetImg?filename=images/JSJC201909040_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 不同算法水下飞机残骸声图分割效果对比1</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909040_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="101">从图6、图7可以看出,传统CV算法因声呐图像影区与背景灰度值相差较大,受背景干扰小,而目标亮区与部分背景区灰度对比度近似,受背景干扰严重,整体分割效果不理想,因而传统CV算法仅能应用于目标与背景对比度大的场景,不适用于具有复杂背景纹理的水下声呐图像分割;GMRF-CV算法在考虑纹理像素间空间相关性下,有效降低了背景纹理对目标的影响,但分割最终结果含有孤立噪声点,且最终轮廓曲线对原始声图边缘逼近程度不理想,影响分割效果;与CV算法和GMRF-CV算法相比,本文所提出在Contourlet域下多尺度GMRF水平集声呐图像分割算法的背景噪声被有效抑制,且声呐图像目标轮廓曲线更贴近实际,其边缘分割准确度高、效果较为理想。在运行效率方面,图6(a)、图6(c)和图6(e)的水平集函数分别迭代900次、500次与150次,图7(a)、图7(b)和图7(c)分别迭代700次、300次和100次。实验结果表明,本文算法在不影响分割效果的情况下能够缩短运行时间,提高声图分割效率。</p>
                </div>
                <div class="p1">
                    <p id="102">为进一步评价本文算法的性能,采用Ostu算法<citation id="209" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>和FCM-MRF算法<citation id="210" type="reference"><link href="158" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>作为对比算法,并对声呐图像进行分割。图8和图9所示为不同形状水下目标声呐图像分割效果对比结果。可以看出,Ostu算法在背景纹理灰度均匀下可获得一定分割效果,但在高噪声背景下由于受声呐图像本身灰度分布影响,较难获得理想的分割效果;FCM-MRF算法虽然可以达到一定分割效果,但分割结果出现许多孤立噪点,且在分割前需要确定聚类个数,影响实时性;本文算法在背景混响区抑制和在目标边缘细节保持等方面明显优于其他算法。</p>
                </div>
                <div class="area_img" id="103">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909040_103.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同算法水下沉船声图分割效果对比2" src="Detail/GetImg?filename=images/JSJC201909040_103.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图8 不同算法水下沉船声图分割效果对比2</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909040_103.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="104">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909040_104.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 不同算法水下飞机残骸声图分割效果对比2" src="Detail/GetImg?filename=images/JSJC201909040_104.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图9 不同算法水下飞机残骸声图分割效果对比2</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909040_104.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="105">上述评判标准是基于主观视觉评价,依赖于观察主体经验、主观感受及环境条件,不同观察者有不同的评价方式,具有一定随机性和不确定性,无法对图形分割质量进行定量分析,因此本文采用合理评价标准即客观评价,通过指标分析函数计算图形分割效果,以评判分割优劣,其中,分割准确度(Segmentation Accuracy,SA)是客观评价标准之一<citation id="211" type="reference"><link href="188" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>,其计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mi>A</mi><mo>=</mo><mfrac><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>a</mi></msub></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">其中,<i>P</i><sub><i>a</i></sub>为正确分割像素,<i>P</i><sub><i>t</i></sub>为总像素。时间复杂度是评价算法运算有效性的标准,算法的运算速度决定数据处理的实时性。声呐成像过程中由于受到噪声干扰,导致所成图像不清晰,因此分割算法应具有一定抗噪性。表1所示为不同声呐图像采用不同算法分割性能对比。</p>
                </div>
                <div class="area_img" id="108">
                    <p class="img_tit"><b>表1 不同水平集分割算法的性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="108" border="1"><tr><td>图编号</td><td>评价指标</td><td>传统CV算法</td><td>GMRF-CV算法</td><td>本文算法</td></tr><tr><td rowspan="2"><br />图5</td><td><i>SA</i>/%</td><td>79</td><td>92</td><td>97</td></tr><tr><td><br /><i>t</i>/s</td><td>11</td><td>6</td><td>2</td></tr><tr><td rowspan="2"><br />图6</td><td><i>SA</i>/%</td><td>45</td><td>82</td><td>94</td></tr><tr><td><br /><i>t</i>/s</td><td>30</td><td>19</td><td>8</td></tr><tr><td rowspan="2"><br />图7</td><td><i>SA</i>/%</td><td>73</td><td>89</td><td>96</td></tr><tr><td><br /><i>t</i>/s</td><td>21</td><td>12</td><td>5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="109">从表1可以看出,在不同声呐图像场景中,本文算法各项指标均优于其他算法。在抗噪性方面分别对图6和图9添加不同噪声水平,对比结果如图10所示。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909040_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 不同噪声水平对分割效果影响对比" src="Detail/GetImg?filename=images/JSJC201909040_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图10 不同噪声水平对分割效果影响对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909040_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="111">从图10可以看出,随着噪声水平的增加,Otsu、FCM-MRF、GMRF-CV这3种算法的分割准确度迅速降低,但本文算法受噪声影响小,分割准确度较为平稳,具有一定抗噪性。从直观与客观两方面分析对比声图分割效果,可以得出,本文所提算法在保证分割准确率情况下,能够降低运算复杂度及减少时间开销。</p>
                </div>
                <h3 id="112" name="112" class="anchor-tag">5 结束语</h3>
                <div class="p1">
                    <p id="113">本文从分割准确度、背景噪声抑制和运算效率3个角度出发,提出基于Contourlet域下GMRF模型的多尺度水平集声呐图像分割算法。在Contourlet域下获取声呐图像各尺度层下的分解纹理特征,按尺度由粗到细对声呐图像进行水平集分割以加快其迭代速度,通过粗尺度层平滑作用及细尺度层纹理近似目标边缘轮廓特性,可有效抑制背景噪声。同时,考虑纹理间空间相关性,利用GMRF对各层建模,以融合纹理局部与全局特征及抑制噪声。实验结果表明,该算法具有较高的分割准确度,且分割效率较高,鲁棒性较好。后续将对GMRF的特征参数进行优化,进一步提升本文算法的鲁棒性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="148">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SXJS201302001&amp;v=MjQxMTN5N2xWYjdQTmpYQmZiRzRIOUxNclk5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 李海森,周天,徐超.多波束测深声纳技术研究新进展[J].声学技术,2013,32(2):73-80.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Side scan sonar image resolution and automatic object detection,classification and identi-fication">

                                <b>[2]</b> LANGNER F,KNAUER C,JANS W,et al.Side scan sonar image resolution and automatic object detection,classification and identification[C]//Proceedings of OCEANS’09.Washington D.C.,USA:IEEE Press,2009:1-8.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SLZH201604015&amp;v=MTMzMzdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckZ5N2xWYjdQTmlIUlpyRzRIOWZNcTQ5RVk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 朱玲羚.基于Otsu法的声呐图像多阈值分割方法[J].水雷战与舰船防护,2016,24(4):68-71,47.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201507002&amp;v=MzA2ODY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckZ5N2xWYjdQUHlyZmJMRzRIOVRNcUk5RlpvUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 李阳,庞永杰,盛明伟.结合空间信息的模糊聚类侧扫声纳图像分割[J].中国图象图形学报,2015,20(7):865-870.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Multichannel Markov Random Field Framework for TumorSegmentation With an Application to Classification of Gene Expression-Based Breast Cancer RecurrenceRisk">

                                <b>[5]</b> ASHRAF A B,GAVENONIS S C,DAYE D,et al.A multichannel Markov random field framework for tumor segmentation with an application to classification of gene expression-based breast cancer recurrence risk[J].IEEE Transactions on Medical Imaging,2013,32(4):637-648.
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HZLG201209007&amp;v=MTY4MzdCdEdGckNVUkxPZVplUnJGeTdsVmI3UExUZkhhYkc0SDlQTXBvOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 王雷,叶秀芬,王天.模糊聚类的侧扫声纳图像分割算法[J].华中科技大学学报(自然科学版),2012,40(9):25-29.
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Label field initialization for MRF-based sonar image segmentation by selective autoencoding">

                                <b>[7]</b> SONG Sanming,SI Bailu,FENG Xisheng,et al.Label field initialization for MRF-based sonar image segmentation by selective autoencoding[C]//Proceedings of OCEANS’16.Washington D.C.,USA:IEEE Press,2016:1-5.
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sonar image segmentation based on Markov Gauss-Rayleigh mixture model">

                                <b>[8]</b> SUN Ning,SHIM T,HAHN H.Sonar image segmentation based on Markov Gauss-Rayleigh mixture model[C]//Proceedings of International Workshop on Education Technology and International Workshop on Geoscience and Remote Sensing.Washington D.C.,USA:IEEE Computer Society,2008:704-709.
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sonar image segmentation based on implicit active con-tours">

                                <b>[9]</b> SANG Enfang,SHEN Zhengyan,FAN Chang,et al.Sonar image segmentation based on implicit active contours[C]//Proceedings of IEEE International Conference on Intelligent Computing and Intelligent Systems.Washington D.C.,USA:IEEE Press,2009:228-231.
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300108768&amp;v=MTMxNDhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMcklKbDRTYXhVPU5pZk9mYks3SHRETnJJOUZaZXNIQzNveA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> LIU Guangyu,BIAN Hongyu,SHI Hong.Sonar image segmentation based on an improved level set method[J].Physics Procedia,2012,33:1168-1175.
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESCAA127CEF53A66D1E8738E3C2FB42A1E&amp;v=MDA5OTZwYlEzNU4xaHdyaTV3YTg9TmlmT2ZjREpiOURPcVB3d0V1NE1mWG8vdXhkbTRqaCtRQXJoM3hCREM3YVdOTHZxQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> WANG Xingmei,GUO Longxiang,YIN Jingwei,et al.Narrowband Chan-Vese model of sonar image segmentation:a adaptive ladder initialization approach[J].Applied Acoustics,2016,113:238-254.
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501911804&amp;v=MTA0NTBud1plWnVIeWptVUxySUpsNFNheFU9TmlmT2ZiSzdIdEROcW85RWJlb09CSHc5b0JNVDZUNFBRSC9pclJkR2VycVFUTQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> LU Wen,ZENG Kai,TAO Dacheng,et al.No-reference image quality assessment in contourlet domain[J].Neurocomputing,2010,73(4/6):784-794.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The contourlet transform: an efficient directional multiresolution image representation">

                                <b>[13]</b> DO M N,VETTERLI M.The contourlet transform:an efficient directional multiresolution image representation[J].IEEE Transactions on Image Processing,2005,14(12):2091-2106.
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJNG&amp;filename=SJNG13110800000895&amp;v=MDkwMDVUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTHJJSmw0U2F4VT1OaWZGYWJLN0g5RE1wNDlGWk9zUEJIVThvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> EMARY I M M E,RAMAKRISHNAN S.A critical review of statistical modeling of digital images[J].IAENG International Journal of Computer Science,2010,37(1):99-109.
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An efficient MRF embedded level set method for image segmentation">

                                <b>[15]</b> YANG Xi,GAO Xinbo,TAO Dacheng,et al.An efficient MRF embedded level set method for image segmentation[J].IEEE Transactions on Image Processing,2014,24(1):9-21.
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gibbs random fields and Markov random fields with constraints">

                                <b>[16]</b> ONURAL L.Gibbs random fields and Markov random fields with constraints[EB/OL].[2019-02-15].https://arxiv.org/pdf/1603.01481.pdf.
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00000786803&amp;v=MTI5NTRkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZDM2xWYi9PSVZrPU5qN0Jhck80SHRITXFJZERiT3NNWTNrNXpC&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> WANG Keqi,BAI Xuebing.Classification of wood surface texture based on Gauss-MRF model[J].Journal of Forestry Research,2006,17(1):57-61.
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600775015&amp;v=MDY5MTdlWnVIeWptVUxySUpsNFNheFU9TmlmT2ZiSzdIdEROcVk5Rlkrd0tESDA4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53Wg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> YE Xiufen,ZHANG Zhehui,LIU P X,et al.Sonar image segmentation based on GMRF and level-set models[J].Ocean Engineering,2010,37(10):891-901.
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Chan-Vese algorithm">

                                <b>[19]</b> COHEN R.The Chan-Vese algorithm[J].Computer Science,2011,5(1):10-16.
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cell segmentation using level set methods with a new variance term">

                                <b>[20]</b> BÍLKOVÁ Z,SOUKUP J,KUERA V.Cell segmentation using level set methods with a new variance term[C]//Proceedings of International Conference on Image Analysis and Recognition.Berlin,Germany:Springer,2016:183-190.
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEG848DBFE08C53BCC97272F5325D98F55D&amp;v=MTAwMDlsZkNwYlEzNU4xaHdyaTV3YTg9TmlmT2FidThGcVcrMmZwRmJKZ0tEdzVLdkI4VTZEaC9QbnJocmhkQmNMcmlRTC9yQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> VANTARAM S R,SABER E.Survey of contemporary trends in color image segmentation[EB/OL].[2019-02-15].http://spie.org/Publications/Journal/10.1117/1.JEI.21.4.040901.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201909040" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201909040&amp;v=MTQ4ODZHNEg5ak1wbzlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnk3bFZiN01MejdCYmI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgrZ2s5ZFZ2NXFCRFB1QzdEST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
