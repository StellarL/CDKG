<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130615467931250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201904042%26RESULT%3d1%26SIGN%3dgXxodXurtScf1GNVIbnz8htfCi8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201904042&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201904042&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201904042&amp;v=MDcxMTR6cXFCdEdGckNVUkxPZVplUm9GeS9nVUw3T0x6N0JiYkc0SDlqTXE0OUJab1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#55" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#57" data-title="1 相关研究 ">1 相关研究</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="2 U-Net卷积神经网络 ">2 U-Net卷积神经网络</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#76" data-title="3 多尺度特征结构的U-Net肺结节检测算法 ">3 多尺度特征结构的U-Net肺结节检测算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#78" data-title="3.1 网络结构">3.1 网络结构</a></li>
                                                <li><a href="#85" data-title="3.2 多尺度特征结构">3.2 多尺度特征结构</a></li>
                                                <li><a href="#90" data-title="3.3 密集连接网络">3.3 密集连接网络</a></li>
                                                <li><a href="#105" data-title="3.4 训练过程">3.4 训练过程</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#113" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#116" data-title="4.1 评价指标">4.1 评价指标</a></li>
                                                <li><a href="#126" data-title="4.2 结果分析">4.2 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#131" data-title="5 结束语 ">5 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#73" data-title="&lt;b&gt;图1 U-Net卷积神经网络&lt;/b&gt;"><b>图1 U-Net卷积神经网络</b></a></li>
                                                <li><a href="#80" data-title="&lt;b&gt;图2 多尺度特征结构的U-Net卷积神经网络&lt;/b&gt;"><b>图2 多尺度特征结构的U-Net卷积神经网络</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;图3 多尺度特征结构&lt;/b&gt;"><b>图3 多尺度特征结构</b></a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;图4 密集网络结构&lt;/b&gt;"><b>图4 密集网络结构</b></a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;表1 U-Net算法与本文算法的Dice系数比较结果&lt;/b&gt;"><b>表1 U-Net算法与本文算法的Dice系数比较结果</b></a></li>
                                                <li><a href="#122" data-title="&lt;b&gt;图5 网络层数对不同尺度肺结节检测准确率的影响&lt;/b&gt;"><b>图5 网络层数对不同尺度肺结节检测准确率的影响</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;表2 U-Net算法与本文算法的假阳率比较结果&lt;/b&gt; %"><b>表2 U-Net算法与本文算法的假阳率比较结果</b> %</a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;图6 中大尺寸肺结节检测结果&lt;/b&gt;"><b>图6 中大尺寸肺结节检测结果</b></a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;图7 小尺寸肺结节检测结果&lt;/b&gt;"><b>图7 小尺寸肺结节检测结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 朱国策.基于深度卷积神经网络的医学图像肺结节检测方法研究[D].无锡:江南大学, 2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017250536.nh&amp;v=MjQ3MTZVTDdPVkYyNkdiRzlIdFRQcVpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L2c=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         朱国策.基于深度卷积神经网络的医学图像肺结节检测方法研究[D].无锡:江南大学, 2017.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 周兵.CT影像中肺结节检测与识别方法的研究[D].成都:电子科技大学, 2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017076161.nh&amp;v=MjI0MjRSTE9lWmVSb0Z5L2dVTDdPVkYyNkdiTy9HTkRLcnBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         周兵.CT影像中肺结节检测与识别方法的研究[D].成都:电子科技大学, 2017.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 胡伟俭, 陈为, 冯浩哲, 等.应用于平扫CT图像肺结节检测的深度学习方法综述[J].浙江大学学报 (理学版) , 2017, 44 (4) :379-384." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HZDX201704001&amp;v=Mjk5MzVnVUw3T0xUZlBkckc0SDliTXE0OUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeS8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         胡伟俭, 陈为, 冯浩哲, 等.应用于平扫CT图像肺结节检测的深度学习方法综述[J].浙江大学学报 (理学版) , 2017, 44 (4) :379-384.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" KOSTIS W J, REEVES A P, YANKELEVITZ D F, et al.Three-dimensional segmentation and growth-rate estimation of small pulmonary nodules in helical CT images[J].IEEE Transactions on Medical Imaging, 2013, 22 (10) :1259-1274." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Three-Dimensional Segmentation and Growth-Rate Estimation of Small Pulmonary Nodules in Helical CT Images">
                                        <b>[4]</b>
                                         KOSTIS W J, REEVES A P, YANKELEVITZ D F, et al.Three-dimensional segmentation and growth-rate estimation of small pulmonary nodules in helical CT images[J].IEEE Transactions on Medical Imaging, 2013, 22 (10) :1259-1274.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" GAO T, GONG J, WANG Y, et al.Three dimensional adaptive template matching algorithm for lung nodule detection[J].Journal of Image and Graphics, 2014, 19 (9) :1384-1391." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201409016&amp;v=MjQxMDVMT2VaZVJvRnkvZ1VMN09QeXJmYkxHNEg5WE1wbzlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         GAO T, GONG J, WANG Y, et al.Three dimensional adaptive template matching algorithm for lung nodule detection[J].Journal of Image and Graphics, 2014, 19 (9) :1384-1391.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" LIN D, YAN C R, CHEN W T.Autonomous detection of pulmonary nodules on CT images with a neural network-based fuzzy system[J].Computerized Medical Imaging and Graphics, 2005, 29 (6) :447-458." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300049354&amp;v=MTc1NzZRSC9pclJkR2VycVFUTW53WmVadUh5am1VTG5JSjFzWGF4UT1OaWZPZmJLN0h0RE9ySTlGWk84R0QzazlvQk1UNlQ0UA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         LIN D, YAN C R, CHEN W T.Autonomous detection of pulmonary nodules on CT images with a neural network-based fuzzy system[J].Computerized Medical Imaging and Graphics, 2005, 29 (6) :447-458.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" HONG H, JIN M G.Automatic segmentation of ground-glass opacity nodule on chest CT images by histogram modeling and local contrast[C]//Proceedings of Radiological Society of North America 2012 Scientific Assembly and Annual Meeting.Berlin, Germany:Springer, 2012:99-107." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic segmentation of ground-glass opacity nodule on chest CT images by histogram modeling and local contrast">
                                        <b>[7]</b>
                                         HONG H, JIN M G.Automatic segmentation of ground-glass opacity nodule on chest CT images by histogram modeling and local contrast[C]//Proceedings of Radiological Society of North America 2012 Scientific Assembly and Annual Meeting.Berlin, Germany:Springer, 2012:99-107.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" CHEN G H.Solving sobole active contour models via level set[C]//Proceedings of 2014 International Conference on Advanced Control, Automation and Robotics.New York, USA:ACM Press, 2014:8-12." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Solving sobole active contour models via level set">
                                        <b>[8]</b>
                                         CHEN G H.Solving sobole active contour models via level set[C]//Proceedings of 2014 International Conference on Advanced Control, Automation and Robotics.New York, USA:ACM Press, 2014:8-12.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" PAIK D S, BEAULIEU C F, RUBIN G D, et al.Surface normal overlap:a computer-aided detection algorithm with application to colonic polyps and lung nodules in helical CT[J].IEEE Transactions on Medical Imaging, 2004, 23 (6) :661-667." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Surface normal overlap: A computer-aided detection algorithm with application to colonic polyps and lung nodules in helical CT">
                                        <b>[9]</b>
                                         PAIK D S, BEAULIEU C F, RUBIN G D, et al.Surface normal overlap:a computer-aided detection algorithm with application to colonic polyps and lung nodules in helical CT[J].IEEE Transactions on Medical Imaging, 2004, 23 (6) :661-667.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" KATSUMATA Y, ITAI Y S M.Automatic detection of GGO candidate regions employing four statistical features on thoracic MDCT image[C]//Proceedings of International Conference on Control, Automatic and System.New York, USA:ACM Press, 2007:10-20." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic Detection of GGOCandidate Regions Employing Four Statistical Features on Thoracic MDCT Image">
                                        <b>[10]</b>
                                         KATSUMATA Y, ITAI Y S M.Automatic detection of GGO candidate regions employing four statistical features on thoracic MDCT image[C]//Proceedings of International Conference on Control, Automatic and System.New York, USA:ACM Press, 2007:10-20.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" CHEN S, SUZUKI K, MACMAHON H.Development and evaluation of a computer-aided diagnostic scheme for lung nodule detection in chest radiographs by means of two-stage nodule enhancement with support vector classification[J].Medical Physics, 2011, 38 (4) :1844-1858." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Development and evaluation of a computer-aided diagnostic scheme for lung nodule detection in chest radiographs by means of two-stage nodule enhancement with support vector classification">
                                        <b>[11]</b>
                                         CHEN S, SUZUKI K, MACMAHON H.Development and evaluation of a computer-aided diagnostic scheme for lung nodule detection in chest radiographs by means of two-stage nodule enhancement with support vector classification[J].Medical Physics, 2011, 38 (4) :1844-1858.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" CAMPADELLI P, CASIRAGHI E, ARTIOLI D.A fully automated method for lung nodule detection from postero-anterior chest radiographs[J].IEEE Transactions on Medical Imaging, 2006, 25 (12) :1588-1603." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A fully automated method for lung nodule detection from postero-anterior chest radiographs">
                                        <b>[12]</b>
                                         CAMPADELLI P, CASIRAGHI E, ARTIOLI D.A fully automated method for lung nodule detection from postero-anterior chest radiographs[J].IEEE Transactions on Medical Imaging, 2006, 25 (12) :1588-1603.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" SNOEREN P R, LITJENS G J S, GINNEKEN B V, et al.Training a computer aided detection system with simulated lung nodules in chest radiographs[C]//Proceedings of the 3rd International Workshop on Pulmonary Image Analysis.New York, USA:ACM Press, 2016, 139-142." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Training a computer aided detection system with simulated lung nodules in chest radiographs">
                                        <b>[13]</b>
                                         SNOEREN P R, LITJENS G J S, GINNEKEN B V, et al.Training a computer aided detection system with simulated lung nodules in chest radiographs[C]//Proceedings of the 3rd International Workshop on Pulmonary Image Analysis.New York, USA:ACM Press, 2016, 139-142.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" 孟以爽, 易平, 顾问, 等.基于深度学习的肺结节检测[J].计算机时代, 2018 (2) :5-9." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJS201802003&amp;v=MTQ1NDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L2dVTDdPTHo3QmZiRzRIOW5Nclk5Rlo0UUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         孟以爽, 易平, 顾问, 等.基于深度学习的肺结节检测[J].计算机时代, 2018 (2) :5-9.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 赵鹏飞, 赵涓涓, 强彦, 等.多输入卷积神经网络肺结节检测方法研究[J].计算机科学, 2018, 45 (1) :162-166." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201801031&amp;v=MzE0NDI3QmI3RzRIOW5Ncm85R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L2dVTDdPTHo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         赵鹏飞, 赵涓涓, 强彦, 等.多输入卷积神经网络肺结节检测方法研究[J].计算机科学, 2018, 45 (1) :162-166.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" RONNEBERGER O, FISCHER P, BROX T.U-Net:convolutional networks for biomedical image segmenta-tion[EB/OL].[2018-04-18].https://arxiv.org/abs/1505.04597v1." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=U-Net:convolutional networks for biomedical image segmenta-tion">
                                        <b>[16]</b>
                                         RONNEBERGER O, FISCHER P, BROX T.U-Net:convolutional networks for biomedical image segmenta-tion[EB/OL].[2018-04-18].https://arxiv.org/abs/1505.04597v1.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" GAO H, ZHUANG L.Densely connected convolutional networks[EB/OL].[2018-04-18].https://arxiv.org/abs/1608.06993" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Densely connected convolutional networks">
                                        <b>[17]</b>
                                         GAO H, ZHUANG L.Densely connected convolutional networks[EB/OL].[2018-04-18].https://arxiv.org/abs/1608.06993
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" 陈鸿翔.基于卷积神经网络的图像语义分割[D].杭州:浙江大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016063691.nh&amp;v=MjI3OTZVTDdPVkYyNkdMTytIZGZGcnBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L2c=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         陈鸿翔.基于卷积神经网络的图像语义分割[D].杭州:浙江大学, 2016.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2015:3431-3440." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">
                                        <b>[19]</b>
                                         LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2015:3431-3440.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" 芮杰.多源遥感数据测绘应用关键技术研究[D].北京:中国科学院大学, 2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1017721023.nh&amp;v=MDQ3NjR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkvZ1VMN09WRjI2R2JTNkg5SE9ySkViUElRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         芮杰.多源遥感数据测绘应用关键技术研究[D].北京:中国科学院大学, 2017.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" QIN P, LI C, CHEN J, et al.Research on improved algorithm of object detection based on feature pyramid[J].Multimedia Tools and Applications, 2019, 78 (1) :913-927." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Research on improved algorithm of object detection based on feature pyramid">
                                        <b>[21]</b>
                                         QIN P, LI C, CHEN J, et al.Research on improved algorithm of object detection based on feature pyramid[J].Multimedia Tools and Applications, 2019, 78 (1) :913-927.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" LIN T Y, DOLLAR P, GIRSHICK R, et al.Feature pyramid networks for object detection[EB/OL].[2018-04-18].https://arxiv.org/abs/1612.03144v2." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature pyramid networks for object detection">
                                        <b>[22]</b>
                                         LIN T Y, DOLLAR P, GIRSHICK R, et al.Feature pyramid networks for object detection[EB/OL].[2018-04-18].https://arxiv.org/abs/1612.03144v2.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" LIN G H, LUO S W, HUANG Y P, et al.A novel regularization method based on convolution neural network[J].Journal of Computer Research and Development, 2014, 51 (9) :1891-1900." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201409002&amp;v=MjYyMTJGeS9nVUw3T0x5dlNkTEc0SDlYTXBvOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                         LIN G H, LUO S W, HUANG Y P, et al.A novel regularization method based on convolution neural network[J].Journal of Computer Research and Development, 2014, 51 (9) :1891-1900.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" DICE L R.Measures of the amount of ecologic association between species[J].Ecology, 1945, 26 (3) :297-302." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Measures of the amount of ecological association between species">
                                        <b>[24]</b>
                                         DICE L R.Measures of the amount of ecologic association between species[J].Ecology, 1945, 26 (3) :297-302.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" 刘宝生, 闫莉萍, 周东华.几种相似性测度的比较[J].计算机应用研究, 2006, 23 (11) :1-3." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ200611000&amp;v=MTI4MjFyQ1VSTE9lWmVSb0Z5L2dVTDdPTHo3U1pMRzRIdGZOcm85RlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                         刘宝生, 闫莉萍, 周东华.几种相似性测度的比较[J].计算机应用研究, 2006, 23 (11) :1-3.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_26" title=" 周清华, 范亚光, 王颖, 等.中国肺部结节分类、诊断与治疗指南[J].中国肺癌杂志, 2016, 19 (12) :793-798." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=FAIZ201612001&amp;v=MjQ3MjZHNEg5Zk5yWTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkvZ1VMN09JeXpDZEw=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                         周清华, 范亚光, 王颖, 等.中国肺部结节分类、诊断与治疗指南[J].中国肺癌杂志, 2016, 19 (12) :793-798.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(04),254-261 DOI:10.19678/j.issn.1000-3428.0051769            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于多尺度特征结构的U-Net肺结节检测算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E8%BE%89&amp;code=39853136&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱辉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A7%A6%E5%93%81%E4%B9%90&amp;code=25670970&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">秦品乐</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%8C%97%E5%A4%A7%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E9%99%A2&amp;code=0036109&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中北大学大数据学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对肺结节低层特征在网络传输过程中的缺失问题, 基于多尺度特征结构, 提出一种改进的U-Net卷积神经网络肺结节检测算法。采用卷积操作与池化操作获取高层特征, 通过密集网络使得特征信息在输入层和输出层之间高速流通, 并结合扩张卷积生成多尺度特征, 提高肺结节低层特征的利用率。实验结果表明, 与传统U-Net卷积神经网络的肺结节检测算法相比, 改进算法对于小型结节的检测准确率约提高20%, 可实现更准确的肺部病灶区域定位。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">小目标检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AF%86%E9%9B%86%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">密集网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%82%BA%E7%BB%93%E8%8A%82&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">肺结节;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    朱辉 (1993—) , 男, 硕士研究生, 主研方向为医学图像处理、深度学习;;
                                </span>
                                <span>
                                    秦品乐, 副教授、博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-06-07</p>

                    <p>

                            <b>基金：</b>
                                                        <span>山西省自然科学基金 (2015011045);</span>
                    </p>
            </div>
                    <h1><b>U-Net Pulmonary Nodule Detection Algorithm Based on Multi-scale Feature Structure</b></h1>
                    <h2>
                    <span>ZHU Hui</span>
                    <span>QIN Pinle</span>
            </h2>
                    <h2>
                    <span>School of Data Science and Technlogy, North University of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the defect problem in the low-level characteristics of pulmonary nodules in the process of network transmission, an improved U-Net convolution neural network algorithm based on multi-scale feature structure for pulmonary nodule detection is proposed.High-level features are acquired by convolution and pooling operations, high-speed flow of feature information between input and output layers is achieved by using dense network, and multi-scale features are generated combining with expanded convolution to improve the utilization of low-level features of pulmonary nodules.Experimental results show that, compared with the traditional U-Net convolution neural network detection algorithm of pulmonary nodules, the improved algorithm improves the detection accuracy of small nodules by nearly 20%, and achieves more accurate localization of pulmonary lesions.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=small%20object%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">small object detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Neural%20Network%20(CNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Neural Network (CNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dense%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dense network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=pulmonary%20nodule&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">pulmonary nodule;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-06-07</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="55" name="55" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="56">空气质量严重影响肺部疾病的发病率, 肺部疾病的检测一般依靠CT图像, 但是CT图像数量的增加给医生带来了巨大的工作量, 因此借助机器来判断病灶区域是未来病情判断的趋势。肺部结节检测算法一般包括图像预处理、肺实质提取、肺结节候选区域提取和检测以及结节的分类识别<citation id="133" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。对于肺结节候选区域的检测有很多方法, 包括模板匹配法、基于阈值的图像分割方法、模糊聚类法、基于活动轮廓模型的方法等, 其中模板匹配法依赖参数的调节, 基于阈值的图像分割方法依赖阈值的选择, 模糊聚类法难以处理边界问题, 基于活动轮廓模型的方法对噪声比较敏感, 易发生边界泄露<citation id="134" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。利用肺结节的医学特征对其进行检测, 一般会加入先验知识, 因此不同滤波器能检测不同形状的肺结节。肺结节增强后, 可见性增加, 检测难度降低。深度学习在检测肺结节上取得不错的效果, 一种是针对特征差异性, 利用人工神经网络训练大批数据, 得到预期结果。另一种是通过卷积神经网络在图像处理上的显著效果, 设计符合肺结节特征提取的深度卷积神经网络<citation id="135" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。本文利用密集网络集合物体的底层特征, 并结合扩张卷积生成低中高3种尺度的特征, 构建基于改进U-Net特征提取的目标检测网络, 并将该网络应用于肺结节检测。</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag">1 相关研究</h3>
                <div class="p1">
                    <p id="58">目前, 多数肺结节候选区域的检测方法能达到较好的效果, 具体为:1) 模板匹配法。文献<citation id="136" type="reference">[<a class="sup">4</a>]</citation>利用肺结节形态上的特征, 得到肺结节数学形态学模板, 将该模板与原图做卷积运算, 得到分割结果。文献<citation id="137" type="reference">[<a class="sup">5</a>]</citation>利用相似性原理计算自适应模板和三维归一化互相关 (Normalized Cross Correlation, NCC) 系数, 在阈值高于设定阈值时, 标记目标区域为肺结节。2) 基于阈值的图像分割方法。阈值选取决定了分割效果, 该方法采用自适应阈值。文献<citation id="138" type="reference">[<a class="sup">6</a>]</citation>通过先验知识已知肺结节和血管的像素值较高且呈类圆形, 并对图像直方图的分析找出灰度较大的像素作为疑似结节的候选点。3) 模糊聚类法。文献<citation id="139" type="reference">[<a class="sup">7</a>]</citation>通过肺实质影像的灰度概率密度函数建立高斯混合模型 (Gauss Mixture Model, GMM) , 并对区域纹理似然图自动分割检测到的磨玻璃不透明度 (Ground Glass Opacity, GGO) 区域进行分析。4) 基于活动轮廓模型的方法。该方法适用于分割不均匀强度的图像<citation id="140" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="59">分割只是疑似结节区域的获取, 最终检测还需利用肺结节的的医学特征。肺结节像素法线一般相互交叉。文献<citation id="141" type="reference">[<a class="sup">9</a>]</citation>利用该特征设计滤波器, 该滤波器输出的是邻域像素的法线通过该像素的个数, 如果个数越多, 则越可能是肺结节。文献<citation id="142" type="reference">[<a class="sup">10</a>]</citation>拉伸灰度图像的对比度, 再用上下层相关信息提取球形结构的物体。在肺结节增强方面, 文献<citation id="143" type="reference">[<a class="sup">11</a>]</citation>通过形态学操作和径向梯度法增强肺结节所在区域。但该方法检测精度的高低依赖于分割效果的好坏。为找到隐藏在心脏、脊柱和横膈膜后的肺区域, 文献<citation id="144" type="reference">[<a class="sup">12</a>]</citation>采用多尺度方法处理分割区域, 从而增强结节的可见性。</p>
                </div>
                <div class="p1">
                    <p id="60">神经网络的利用在肺结节的检测上取得了不错的效果。文献<citation id="145" type="reference">[<a class="sup">13</a>]</citation>使用基于灰度收敛和位置特征的神经网络来搜索疑似结节的区域, 假阳性较高。针对检出率不高的问题, 国内学者利用深度学习方法取得了较好的效果。文献<citation id="146" type="reference">[<a class="sup">14</a>]</citation>通过多片染色重叠来增强肺结节和其他组织的差异性, 并将该差异作为深度神经网络的学习目标, 得到较好的检出率。文献<citation id="147" type="reference">[<a class="sup">15</a>]</citation>利用肺结节候选区域的灰度图层、CT图层和灰度增强图层作为卷积神经网络的多个输入, 并通过阈值标注疑似结节, 然而该方法类似于数据增强, 扩大数据集使网络参数训练得更好。总体而言, 上述方法存在以下问题:1) 肺结节特征选择依靠人为设计, 检测精度过度依赖经验。2) 无法做到自适应特征提取, 对于不规则肺结节, 检测精度低。3) 无法针对体积小的肺结节检测问题提出解决方案。</p>
                </div>
                <div class="p1">
                    <p id="61">本文充分考虑以上方法的优势和不足, 在U-Net<citation id="148" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>卷积神经网络的基础上, 提出针对肺结节的改进特征提取方式。为解决卷积网络层数的加深不能充分利用特征学习时的低层特征, 反而会导致低层特征在网络传输过程中的缺失问题, 本文加入密集网络<citation id="149" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。为充分利用肺结节最底层的特征, 在网络的前3层引入扩张卷积。该网络以原始医学图像为输入, 疑似肺结节的掩模图像为输出, 构建从原始图像到目标图像的非线性映射。本文以LUNA2016为训练集, 使用Keras深度学习框架在GPU上进行训练, 最终得到预期实验效果。</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag">2 U-Net卷积神经网络</h3>
                <div class="p1">
                    <p id="63">U-Net是一个语义分割网络, 较多用于医学图像。因为在许多视觉任务中, 尤其是在生物医学图像处理中, 期望的输出应该包括定位, 即将类别标签分配给每个像素。此外, 在生物医学任务中, 通常无法获得数以千计的训练图像, 为解决数据量不足的问题, U-Net网络提供了一种解决思路。</p>
                </div>
                <div class="p1">
                    <p id="64">以往在图像分类或者图像目标检测方面, 一般做法是原始图像通过不断地卷积下采样, 将图像的尺度变小并得到若干特征图。在一系列的特征提取后, 提取出高层语义特征, 然后进入非线性分类器或者线性分类器进行图像分类, 或者通过位置回归进行目标识别和检测。然而, 在进行目标分割时, 传统基于CNN的分割方法为了对像素进行分类, 将该像素的领域像素块作为CNN的输入<citation id="150" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>, 但该方法有以下缺点:</p>
                </div>
                <div class="p1">
                    <p id="65">1) 存储开销大。卷积操作不断滑动窗口, 然后进行判别分类, 需要的存储空间消耗大。</p>
                </div>
                <div class="p1">
                    <p id="66">2) 存在大量冗余计算。图像的相邻像素在空间上重复, 计算每个像素块的卷积时存在大量像素冗余和重复计算。</p>
                </div>
                <div class="p1">
                    <p id="67">3) 感受野被限制。像素块尺寸小, 在该区域进行卷积操作只能提取少量的特征, 会导致分类任务难以进行。</p>
                </div>
                <div class="p1">
                    <p id="68">全卷积网络 (Fully Convolutional Network, FCN) 是语义分割网络中的一种<citation id="151" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。传统CNN在进行分类任务时, 在最后一层卷积层中加入全连接层得到固定长度的特征向量, 而FCN可以将多种尺寸的图像作为网络输入, 为使网络输出和网络输入的尺寸保持一致, 利用反卷积将最后一层的特征图上采样到原图大小, 既能保留原始图像的空间信息, 又能在像素级别进行分类<citation id="152" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>。原始图像通过卷积操作提取特征, 得到的特征图越来越小, 分辨率越来越低, 而分辨率低的特征层恢复到了原图的分辨率, FCN使用上采样。经过5次卷积和池化后, 图像分辨率依次缩小了2倍、4倍、8倍、16倍、32倍。最后一层的特征图在进行32倍的上采样后能得到的图像大小和原图一样。同理, 对倒数第2层的输出特征图进行16倍的上采样。如果将这2次上采样后的特征图合并, 就可以得到分辨率更高的输出图像。</p>
                </div>
                <div class="p1">
                    <p id="69">FCN不限制输入图像的尺寸, 且不增加像素块的存储开销, 并避免了卷积计算冗余, 但FCN也存在以下问题:</p>
                </div>
                <div class="p1">
                    <p id="70">1) 细节模糊。不同倍率的多倍上采样虽然效果提升显著, 但是单次上采样难以集合图像低层特征, 导致结果对图像中的细节不敏感。</p>
                </div>
                <div class="p1">
                    <p id="71">2) 忽略局部和整体的关系。对各像素进行分类虽能分割物体, 但像素与像素之间存在连续性, 因此缺乏空间一致性。</p>
                </div>
                <div class="p1">
                    <p id="72">为解决上述问题, 文献<citation id="153" type="reference">[<a class="sup">16</a>]</citation>提出利用U-Net网络进行医学图像分割。图1是典型的U-Net卷积神经网络结构, 该网络由收缩路径和扩张路径组成, 收缩路径获取上下文信息, 对称的扩张路径用于精确定位。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904042_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 U-Net卷积神经网络" src="Detail/GetImg?filename=images/JSJC201904042_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 U-Net卷积神经网络</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904042_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="74">在收缩路径中主要是进行特征提取, U-Net卷积网络在特征提取上与一般卷积神经网络无区别, 都是在空间结构中采用增加特征图个数而降低特征图尺度的策略。在网络扩张路径部分, 每层网络需要对特征图进行3种操作:上采样, 侧边合并, 卷积。在上采样部分, 网络将低分辨率的图像信息传播到更高分辨率的层。在侧边合并部分, 需要提供网络低层特征, 以获取目标区域的位置等信息, 由于每个卷积中边界像素的丢失, 需进行适当的裁剪, 因此可以看到侧边合并部分, 特征图的大小不相等。卷积操作仅对合并的特征图进行特征提取操作, 并将卷积后的特征图作为上采样的输入。最终需要对多通道特征图卷积操作得到分割map, 而map通道数可根据具体问题确定, 需要和分类数量一致。如果是单目标分割, map通道数为2, 分割出的图像是二值化图像。</p>
                </div>
                <div class="p1">
                    <p id="75">总体而言, U-Net采用对称结构, 下采样减少池化层的空间维度, 上采样修复物体的细节和空间维度。而侧边连接能更好地修复目标的细节。不断的卷积和池化可以提取图片的深层特征, 但同时得到的特征图的大小相较于原来的图片也在不断的减小, 网络越深, 丢失的信息越多。因此, 对于每一次下采样, 采用一次上采样使之恢复原来的尺寸大小, 而每一个上采样的结果都与前期相应尺寸的特征图进行相连, 这样便实现了高层特征与低层特征的结合, 并且能更精确地预测每一个像素的类别。由于标签所在区域和背景区域属于不同的分类, 因此能在分割后对目标进行检测。虽然针对FCN细节处理不敏感的问题, U-Net网络使用侧边连接可弥补不足, 但低层信息的不充分利用导致检测效果不理想。对于肺结节来说, 其语义特征稀少, 低层信息偏多, 针对其空间一致性和特征连续性, U-Net存在以下问题:1) 较少考虑特征之间的连续性, 忽略了图像本身与目标之间的关系, 导致分割区域存在定位不清、偏移较大的问题。2) 较多考虑高层特征, 较少对低层信息进行重复利用, 并且未从多尺度角度分析目标所在区域。</p>
                </div>
                <h3 id="76" name="76" class="anchor-tag">3 多尺度特征结构的U-Net肺结节检测算法</h3>
                <div class="p1">
                    <p id="77">本文提出一种在U-Net卷积网络中利用特征多尺度结构检测目标的算法。算法原理如下:1) 为解决特征之间的连续性, 在U-Net网络的收缩路径加入密集网络, 从而构建由低到高不同尺度的特征, 不同尺度特征检测不同尺度的目标;2) 考虑肺结节的形状小、语义特征少的特殊性, 在网络中尽可能复用低层特征, 因此在U-Net网络的收缩路径中加入扩张卷积, 为检测任务提供像素级的特征。3) 为最大程度利用肺结节的语义特征, 在U-Net网络的扩张路径中, 采用连续上采样而不是一次上采样, 因为一次反卷积损失的语义特征多, 肺结节体积较小且特征稀缺, 所以2次上采样都需用到低层特征, 能尽可能减少特征的丢失。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">3.1 网络结构</h4>
                <div class="p1">
                    <p id="79">在保留U-Net网络对称性的基础上, 构建特征结构多尺度网络。网络采用左右对称结构, 网络收缩路径用于图像特征的学习, 网络扩张路径通过上采样, 将特征图放大到远图像大小, 能够达到像素级别的分类, 从而实现小目标检测。不同之处在于, U-Net网络收缩路径只是简单卷积和池化, 对特征利用率远不够。因此, 本文利用U-Net网络对像素的敏感性, 解决特征复用率不高的问题, 设计多尺度特征结构的U-Net网络, 如图2所示。</p>
                </div>
                <div class="area_img" id="80">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904042_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 多尺度特征结构的U-Net卷积神经网络" src="Detail/GetImg?filename=images/JSJC201904042_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 多尺度特征结构的U-Net卷积神经网络</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904042_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="81">在图2中, D<i>n</i> (<i>n</i>=1, 2, 3) 表示密集网络中的Dense Block, T<i>n</i> (<i>n</i>=1, 2, 3) 表示Transition Layer, Up<i>n</i> (<i>n</i>=6, 7, …, 12) 表示由上采样和侧边连接合并得到的特征图。网络输入是大小为512×512的1通道的CT图像, 使用3×3的卷积核将原图转成32个大小为512×512的特征层Conv1, Conv1接着执行2种操作, 操作1:Conv1通过池化后, 连接到密集块Dense Block和Transition Layer中, 也就是图2中的D1和T1。设置growth rate的<i>k</i>值为3, 该操作得到128个特征图大小为256×256的特征层D1, 并在Transition Layer得到128个特征图大小为128×128的特征层T1, T1再经过kernel为3×3的卷积得到64个特征图大小为128×128的特征层Conv2。操作2:Conv1在通过池化后需要经过kernel为3×3的扩张卷积, 其中, dilaion值为2, stride为2, pad为2, 特征图由256×256下采样至128×128, 然而特征图数量不变。因此, 特征层Conv2特征图大小为128×128, 特征图个数为96。</p>
                </div>
                <div class="p1">
                    <p id="82">此时, 在下采样阶段使用扩张卷积, 而不是池化, 因为池化会造成一些底层信息的损失<citation id="154" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>。而操作1在下采样阶段使用池化操作, 因为在语义特征的提取上, 允许存在少数特征的损失。</p>
                </div>
                <div class="p1">
                    <p id="83">特征层Conv2和Conv1类似, 同样需要2个操作, 即连接密集块操作和扩张卷积下采样操作。Conv2在连接密集块操作后, 并通过kernel为3×3的卷积操作得到128个特征图大小为128×128的特征层Conv3, 同时, Conv2在通过dilaion值为2、stride为2、pad为2的扩张卷积下采样的操作下, 得到96个特征图大小为128×128的特征层Conv3。在合并后, Conv3的特征图数量为224。同样地, Conv3经过一系列操作后, 得到480个特征图大小为8×8的特征层Conv4。经过以上操作, 多尺度特征结构形成, 以特征层Conv2、Conv3、Conv4为代表构成低、中、高3类尺度的特征。</p>
                </div>
                <div class="p1">
                    <p id="84">在上采样过程中, 特征层Conv5经过kernel为2×2、stride为2的反卷积操作, 得到512个特征图大小为8×8的特征层Up6, 同时, 通过特征融合将特征层Conv4合并到Up6中, 因而Up6的最终特征图大小为8×8, 特征图数量为992个。接着, 通过kernel为3×3、stride为1的卷积操作, 得到特征图数量为480、特征图大小不变的特征层Conv6, 该特征层和Conv6在尺度和大小上一样, 因此不会违背U-Net网络左右对称的原则。因为网络在收缩部分加入了密集块, 为解决特征图尺度不一样的问题, 在Conv6上采样阶段, 语义特征扩大太多, 肺结节检测属于小目标检测, 特征稀缺, 而且2次上采样都用到了低层特征, 能尽量减少特征的丢失。经过2次上采样, 特征层Up8的特征图数量为1 600, 特征图大小为32×32。同样, Up8会通过一个卷积层, 得到特征层Conv8, 将该特征层的尺度和大小都还原到和Conv3一样。由于加入2个密集块, 并且需要连续2次上采样, 最终得到特征层Up12, 其特征图大小为512×512, 特征图数为256, 此时特征图的尺度和原图一样。网络的最后是两层卷积层, 输出与原图像尺度、通道数一样的图像。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85">3.2 多尺度特征结构</h4>
                <div class="p1">
                    <p id="86">一个高质量的视觉显著性模型可以使用深度卷积神经网络抽取多尺度特征进行学习<citation id="155" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>。因此, 本文提出一种在3个不同尺度上进行特征提取的神经网络架构, 3种特征即低层特征、中间层特征、顶层特征。其中, 低层特征包括纹理、颜色、位置等, 中层特征包括形状、轮廓等, 顶层特征包括语义特征。</p>
                </div>
                <div class="p1">
                    <p id="87">识别肺结节涉及到肺结节的全部特征, 在尽可能多地获取肺结节特征后, 准确率才有较大的提升。由于卷积神经网络在下采样的过程就是特征的不断提取过程, 一般来说, 目标检测只会用到顶层语义特征, 然而该方式会出现特征损失, 因为在特征选择时忽略了肺结节的中间层特征和低层特征而只选择最高层特征。深层卷积神经网络有利于分类任务的进行, 而检测任务需要回归物体的位置, 深层特征的感受野较大, 难以预测感受野较小的物体位置, 因此对于目标检测任务来说, 需要结合高层语义特征和低层位置特征。</p>
                </div>
                <div class="p1">
                    <p id="88">本文充分利用卷积提取特征后产生的多级特征层, 构建特征结构多尺度检测模型, 如图3所示, 利用卷积网络产生的多尺度特征图、低层特征图多次下采样并与高层特征图融合, 得到既有高层语义又包含丰富定位信息的特征图。</p>
                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904042_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 多尺度特征结构" src="Detail/GetImg?filename=images/JSJC201904042_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 多尺度特征结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904042_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="90" name="90">3.3 密集连接网络</h4>
                <div class="p1">
                    <p id="91">神经网络的层数加深容易出现梯度消失的现象, 因为网络传递时经过的层数越多, 输入信息和梯度信息的影响力越小, 解决该问题的思路是缩短初始输入与损失函数之间的连接距离, 其中密集连接会使网络的每一层都与输入和损失直接连接, 一定程度上减轻梯度消散现象及正则化效果, 抑制网络过拟合现象<citation id="156" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="92">图4为密集网络结构, 设计细节具体如下:</p>
                </div>
                <div class="p1">
                    <p id="93">1) 为达到特征复用效果, 跨层连接使用特征图通道数合并操作。</p>
                </div>
                <div class="p1">
                    <p id="94">2) 因为摒弃了逐元素相加的策略, 所以网络输出的特征图的维度升维到与输入维度一致, 并且不需要1×1的卷积操作。</p>
                </div>
                <div class="p1">
                    <p id="95">3) 在设计密集块时使用预激活策略, 将Batch Normalization操作放到激活函数前。</p>
                </div>
                <div class="p1">
                    <p id="96">4) 每个密集块在最后输出时必然会接受前面所有的特征层, 这样会导致输出的特征图维度过高, 从而引起网络参数的增加。为解决该问题, 在下采样阶段, 利用卷积操作降低维度再进行池化操作。</p>
                </div>
                <div class="p1">
                    <p id="97">5) 设置固定增长率。以图4为例, 增长率<i>k</i>为3。密集块中特征层之间是以维度相加的方式进行特征融合, 因此每经过一个密集块, 特征层的维度就会增长<i>k</i>倍, 网络学习能力也相应增强。然而, 该方法会引起模型尺寸和网络参数的增加。</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904042_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 密集网络结构" src="Detail/GetImg?filename=images/JSJC201904042_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 密集网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904042_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="99">在设计理念上, DenseNet和残差网络 (Residual Neural Network, RestNet) 都使用了跨层连接, 但是其实现原理有本质的区别, 式 (1) 和式 (2) 分别是ResNet和DenseNet的实现方式。<i>l</i>代表层, <i>x</i><sub><i>l</i></sub>表示<i>l</i>层的输出, <i>H</i><sub><i>l</i></sub>代表非线性变换, 不管是RestNet还是DenseNet, 非线性变换的参数都是多个。ResNet中为得到第<i>l</i>层的输出, 将<i>l</i>-1层的输出加上对<i>l</i>-1层输出的非线性变换, 其通道数不变。DenseNet中为得到<i>l</i>层的输出, 将从0层到第<i>l</i>-1层的所有特征层做通道合并操作, 其通道数明显增加。</p>
                </div>
                <div class="p1">
                    <p id="100"><i>x</i><sub><i>l</i></sub>=<i>H</i><sub><i>l</i></sub> (<i>x</i><sub><i>l</i></sub>-1) +<i>x</i><sub><i>l</i>-1</sub>      (1) </p>
                </div>
                <div class="p1">
                    <p id="101"><i>x</i><sub><i>l</i></sub>=<i>H</i><sub><i>l</i></sub> ([<i>x</i><sub>0</sub>, <i>x</i><sub>1</sub>, …, <i>x</i><sub><i>l</i>-1</sub>])      (2) </p>
                </div>
                <div class="p1">
                    <p id="102">在具体实现上, DenseNet有2个重要结构:Dense Block和Transition Layer。Dense Block中的生长率指的是每个密集块中每层网络输出的特征图数量。因为生长率越大, 网络越宽, 所以使用较小的生长率, 如32和48, 避免网络参数过多。此外, 为减少特征图的数量, 达到降维效果, 融合特征图中所有通道的特征, 需要在Dense Block中加入一个Bottleneck Layer操作。具体做法是在每个Dense Block中的3×3卷积前加上一个1×1的卷积操作。Transition Layer放在2个Dense Block中间, 是因为每个Dense Block结束后的输出channel个数较多, 需要用1×1的卷积核来降维。总体来说, 密集连接卷积网络具有以下特点:</p>
                </div>
                <div class="p1">
                    <p id="103">1) 减缓梯度消散问题, 在网络传输过程中, 每一层都会收集前面所有层网络的特征信息, 网络深度加深不再是梯度减小的原因。</p>
                </div>
                <div class="p1">
                    <p id="104">2) 减少网络模型的尺寸, 加入密集连接网络后, 网络模型可以重复利用特征, 通过较少的卷积核即可产生大量的特征, 从而降低网络参数。</p>
                </div>
                <h4 class="anchor-tag" id="105" name="105">3.4 训练过程</h4>
                <div class="p1">
                    <p id="106">网络损失函数包含2个部分, 其中<i>QS</i>表示Dice系数, <i>D</i>表示归一化积相关, <i>x</i><sub><i>k</i></sub>表示标签中的像素值, <i>y</i><sub><i>k</i></sub>表示预测图中对应位置的像素值。loss函数的表达式为<i>L</i>=<i>QS</i>×<i>D</i>。</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo>=</mo><mfrac><mrow><mn>2</mn><mrow><mo>|</mo><mrow><mi>X</mi><mstyle displaystyle="true"><mo>∩</mo><mi>Y</mi></mstyle></mrow><mo>|</mo></mrow><mo>+</mo><mi>s</mi><mi>m</mi><mi>o</mi><mi>o</mi><mi>t</mi><mi>h</mi></mrow><mrow><mrow><mo>|</mo><mi>X</mi><mo>|</mo></mrow><mo>+</mo><mrow><mo>|</mo><mi>Y</mi><mo>|</mo></mrow><mo>+</mo><mi>s</mi><mi>m</mi><mi>o</mi><mi>o</mi><mi>t</mi><mi>h</mi></mrow></mfrac><mo>×</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>x</mi></mstyle><mtext> </mtext><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mi>y</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mrow><mrow><mo stretchy="false">[</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mo stretchy="false"> (</mo><mi>x</mi><mtext> </mtext><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup><mrow><mo stretchy="false">[</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mo stretchy="false"> (</mo><mi>y</mi><mtext> </mtext><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108">网络损失函数一部分使用Dice系数, Dice距离用于度量2个集合的相似性, 因为可以把网络输出结果理解为二维矩阵, 而二维矩阵就是一种集合, 所以Dice距离也可以用于度量两张图片的相似性。本文不使用交叉熵作为损失函数, 因为交叉熵强调的是2种分布的相似性, 而Dice系数更注重集合<i>A</i>中的元素与集合<i>B</i>对应元素之间的相似性, 这样更能对比像素级的相似性<citation id="157" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>。Dice系数定义如下:</p>
                </div>
                <div class="p1">
                    <p id="109" class="code-formula">
                        <mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Q</mi><mi>S</mi><mo>=</mo><mfrac><mrow><mn>2</mn><mrow><mo>|</mo><mrow><mi>X</mi><mstyle displaystyle="true"><mo>∩</mo><mi>Y</mi></mstyle></mrow><mo>|</mo></mrow><mo>+</mo><mi>s</mi><mi>m</mi><mi>o</mi><mi>o</mi><mi>t</mi><mi>h</mi></mrow><mrow><mrow><mo>|</mo><mi>X</mi><mo>|</mo></mrow><mo>+</mo><mrow><mo>|</mo><mi>Y</mi><mo>|</mo></mrow><mo>+</mo><mi>s</mi><mi>m</mi><mi>o</mi><mi>o</mi><mi>t</mi><mi>h</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="110">其中, <i>smooth</i>是平滑系数, <i>X</i>、<i>Y</i>分别表示标签图和预测图。由此可见, 当<i>QS</i>越接近1, 表示训练模型越好, 但是噪声的存在会降低<i>QS</i>值。同时, 由于CT具有旋转不敏感性, 因此本文利用图像旋转的方式进行数据增强, 使数据成倍增加。</p>
                </div>
                <div class="p1">
                    <p id="111">损失函数的另外一部分使用的是归一化积相关 (Normalizated Product Correlation, NProd) <citation id="158" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>运算。肺结节由于尺寸不同, 代表不同程度的病情。对于小结节来说, 检测到的区域如果过大, 则会加大假阳性的概率;对于大结节来说, 检测区域过小, 则会损失目标的部分特征, 使得目标难以检测。因此, 除了Dice相关系数, 位置信息也是需要考虑的问题。位置信息可以用积相关表示, 而数据归一化便于训练网络。归一化积相关的表达式为:</p>
                </div>
                <div class="p1">
                    <p id="112" class="code-formula">
                        <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>x</mi></mstyle><mtext> </mtext><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mi>y</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mrow><mrow><mo stretchy="false">[</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mo stretchy="false"> (</mo><mi>x</mi><mtext> </mtext><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup><mrow><mo stretchy="false">[</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mo stretchy="false"> (</mo><mi>y</mi><mtext> </mtext><msubsup><mrow></mrow><mi>k</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="113" name="113" class="anchor-tag">4 实验结果与分析</h3>
                <div class="p1">
                    <p id="114">为验证本文提出的多尺度特征结构检测算法, 使用LUNA-2016数据集作为网络输入, 训练网络模型, 并与传统U-Net目标检测算法进行比较。实验使用的GPU是NVIDIA Tesla M40, 并采用Keras深度学习框架进行训练。</p>
                </div>
                <div class="p1">
                    <p id="115">LUNA-2016数据集是CT扫描图片, 标签记录了肺结节的位置信息和直径大小, 其特点是输入信息量大、待检测目标小。1.25 mm层厚的CT一般包含200多张影像, 每张影像大小一般为512像素×512像素, 而小的肺结节直径仅有4个像素。本文使用的批次 (<i>batch</i>) 大小为2, 迭代次数为<i>n</i>/<i>batch</i>×20, <i>n</i>代表CT切片大小。</p>
                </div>
                <h4 class="anchor-tag" id="116" name="116">4.1 评价指标</h4>
                <div class="p1">
                    <p id="117">Dice系数是一种重要的分割评价系数。表1对比了U-Net算法和本文算法在原数据和数据增强情况下的Dice系数, 从而验证本文算法的有效性。</p>
                </div>
                <div class="area_img" id="118">
                    <p class="img_tit"><b>表1 U-Net算法与本文算法的Dice系数比较结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="118" border="1"><tr><td><br />数据类型</td><td>算法</td><td>Dice系数</td></tr><tr><td rowspan="2"><br />原数据</td><td><br />U-Net算法</td><td>0.476 4</td></tr><tr><td><br />本文算法</td><td>0.632 1</td></tr><tr><td rowspan="2"><br />增强数据</td><td><br />U-Net算法</td><td>0.572 7</td></tr><tr><td><br />本文算法</td><td>0.733 2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="119">数据增强的方式是将原图旋转180°并加入到原数据集中。通过对比实验可以得出, 数据集的大小对检测结果能产生较大影响。采用数据增强的方式, U-Net算法和本文算法的Dice系数能提高约1个百分点, 但是本文算法不论是经过数据增强还是未经过数据增强, 均能较大程度提高Dice系数的值。</p>
                </div>
                <div class="p1">
                    <p id="120">经过训练后, 在测试集中, U-Net算法和本文算法在检测小结节上存在一定差异, 由于U-Net网络更多利用高层特征, 因此在检测正常结节时2种算法区别不大, 然而, 在小结节检测上本文算法效果更好。</p>
                </div>
                <div class="p1">
                    <p id="121">为验证网络层数对不同尺度肺结节检测精度的影响, 分别对比网络层数加深和网络层数减少情况下的检测精度。根据文献<citation id="159" type="reference">[<a class="sup">26</a>]</citation>, 直径在5 mm以下的肺结节属于肺癌低危结节, 直径介于5 mm～15 mm之间的肺结节属于肺癌中危结节, 直径大于15 mm属于肺癌高危结节。图5是浅层、正常、深层的U-Net算法和本文算法检测3种尺度肺结节的检测准确率比较, 其中, 浅层网络表示网络结构中, 收缩路径去掉卷积层Conv4, 相应扩张路径去掉卷积层Conv6;正常网络表示网络层数不变;深层网络表示收缩路径加上一层卷积层, 相应扩张路径也增加一层卷积层, 使网络更深。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904042_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 网络层数对不同尺度肺结节检测准确率的影响" src="Detail/GetImg?filename=images/JSJC201904042_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 网络层数对不同尺度肺结节检测准确率的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904042_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="123">本文从实验结果中随机抽取一部分数据, 这些数据用于观察肺结节检测的准确率。通过比较可以发现, 当肺结节直径大于15 mm时, 不论是U-Net还是本文算法的检测准确率都较高, 能达到91%左右。当尺寸范围在5 mm～15 mm时, 本文检测算法体现了优势, 准确率在82%左右, 而U-Net的准确率在71%上下浮动。在小结节检测上, 本文算法优势更加明显, 准确率能达到62%, 而U-Net的准确率仅为43%, 提升了近20%。通过对比浅层网络、正常网络和深层网络中肺结节检测的准确率可以发现, 随着网络的加深, 不管是U-Net还是本文算法, 中、大尺度肺结节的检测精度略有提升, 但小尺度肺结节检测精度并无明显提升。</p>
                </div>
                <div class="p1">
                    <p id="124">假阳率是指实际上没有肺结节而检测结果中含有肺结节的数量占所有检测结果的比值。通常来说, 如果肺结节检测精度的提升伴随着假阳率的升高, 那么该算法可用性较低。通过U-Net算法的预测结果和本文算法的预测结果分别统计假阳率, 如表2所示, 可以看出, 2种检测算法在假阳率上无较大区别, 均未以牺牲假阳率为代价来提高检测精度。</p>
                </div>
                <div class="area_img" id="125">
                    <p class="img_tit"><b>表2 U-Net算法与本文算法的假阳率比较结果</b> % <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="125" border="1"><tr><td><br />算法</td><td>假阳率</td></tr><tr><td><br />U-Net算法</td><td>4.91</td></tr><tr><td><br />本文算法</td><td>4.88</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="126" name="126">4.2 结果分析</h4>
                <div class="p1">
                    <p id="127">图6显示了大尺寸 (≥15 mm) 肺结节和中等尺寸 (5 mm～15 mm) 肺结节的检测效果, 图6是4×6的显示方式, 第1行代表原图, 第2行代表基于U-Net算法的检测效果, 第3行代表基于本文算法的检测效果, 第4行是标签, 代表该CT切片肺结节的位置以及大小。其中, 第1列～第3列是大尺寸肺结节的检测结果, 第4列～第6列是中等尺寸肺结节检测结果。可以看出, 在大结节检测方面, 2种算法均能实现较好的效果, 能准确表示位置信息和大小信息。然而, 在检测中等尺寸的肺结节时, 相比于U-Net算法, 本文算法能检测出更小的肺结节, 说明本文算法在中等尺寸检测效果上更有优势。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904042_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 中大尺寸肺结节检测结果" src="Detail/GetImg?filename=images/JSJC201904042_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 中大尺寸肺结节检测结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904042_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="129">图7显示了小尺寸 (3 mm～5 mm) 肺结节的检测效果, 本文随机抽取一些3 mm～5 mm的肺结节, 分别通过上述2种网络模型, 从对比结果可以看出, 在小尺寸肺结节检测上, 基于U-Net的检测算法的检测效果不理想。除了那些极小的结节, 本文算法均可实现有效检测, 因此, 在小结节检测方面, 本文算法检测效果更佳。</p>
                </div>
                <div class="area_img" id="130">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904042_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 小尺寸肺结节检测结果" src="Detail/GetImg?filename=images/JSJC201904042_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 小尺寸肺结节检测结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904042_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="131" name="131" class="anchor-tag">5 结束语</h3>
                <div class="p1">
                    <p id="132">本文利用不同层次的特征, 提出一种基于多尺度特征结构的U-Net肺结节检测算法。实验结果表明, 该算法对于小型结节与大型结节均具有较高的检测精度。下一步将利用RestNet等特征学习能力较强的卷积神经网络作为基础网络提取特征, 并在预训练模型的基础上训练网络, 提高检测精度。另外, 肺结节检测不能仅依靠二维图像, 需构建基于三维特征的多尺度结构网络, 进一步提高中小型肺结节的检测精度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017250536.nh&amp;v=MTEzNDBWRjI2R2JHOUh0VFBxWkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkvZ1VMN08=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 朱国策.基于深度卷积神经网络的医学图像肺结节检测方法研究[D].无锡:江南大学, 2017.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017076161.nh&amp;v=MjQ0OTNwRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeS9nVUw3T1ZGMjZHYk8vR05ES3I=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 周兵.CT影像中肺结节检测与识别方法的研究[D].成都:电子科技大学, 2017.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HZDX201704001&amp;v=MjgwMTN5L2dVTDdPTFRmUGRyRzRIOWJNcTQ5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 胡伟俭, 陈为, 冯浩哲, 等.应用于平扫CT图像肺结节检测的深度学习方法综述[J].浙江大学学报 (理学版) , 2017, 44 (4) :379-384.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Three-Dimensional Segmentation and Growth-Rate Estimation of Small Pulmonary Nodules in Helical CT Images">

                                <b>[4]</b> KOSTIS W J, REEVES A P, YANKELEVITZ D F, et al.Three-dimensional segmentation and growth-rate estimation of small pulmonary nodules in helical CT images[J].IEEE Transactions on Medical Imaging, 2013, 22 (10) :1259-1274.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201409016&amp;v=MTg5OTVxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L2dVTDdPUHlyZmJMRzRIOVhNcG85RVlvUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> GAO T, GONG J, WANG Y, et al.Three dimensional adaptive template matching algorithm for lung nodule detection[J].Journal of Image and Graphics, 2014, 19 (9) :1384-1391.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300049354&amp;v=MjY4MTZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMbklKMXNYYXhRPU5pZk9mYks3SHRET3JJOUZaTzhHRDNrOQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> LIN D, YAN C R, CHEN W T.Autonomous detection of pulmonary nodules on CT images with a neural network-based fuzzy system[J].Computerized Medical Imaging and Graphics, 2005, 29 (6) :447-458.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic segmentation of ground-glass opacity nodule on chest CT images by histogram modeling and local contrast">

                                <b>[7]</b> HONG H, JIN M G.Automatic segmentation of ground-glass opacity nodule on chest CT images by histogram modeling and local contrast[C]//Proceedings of Radiological Society of North America 2012 Scientific Assembly and Annual Meeting.Berlin, Germany:Springer, 2012:99-107.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Solving sobole active contour models via level set">

                                <b>[8]</b> CHEN G H.Solving sobole active contour models via level set[C]//Proceedings of 2014 International Conference on Advanced Control, Automation and Robotics.New York, USA:ACM Press, 2014:8-12.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Surface normal overlap: A computer-aided detection algorithm with application to colonic polyps and lung nodules in helical CT">

                                <b>[9]</b> PAIK D S, BEAULIEU C F, RUBIN G D, et al.Surface normal overlap:a computer-aided detection algorithm with application to colonic polyps and lung nodules in helical CT[J].IEEE Transactions on Medical Imaging, 2004, 23 (6) :661-667.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic Detection of GGOCandidate Regions Employing Four Statistical Features on Thoracic MDCT Image">

                                <b>[10]</b> KATSUMATA Y, ITAI Y S M.Automatic detection of GGO candidate regions employing four statistical features on thoracic MDCT image[C]//Proceedings of International Conference on Control, Automatic and System.New York, USA:ACM Press, 2007:10-20.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Development and evaluation of a computer-aided diagnostic scheme for lung nodule detection in chest radiographs by means of two-stage nodule enhancement with support vector classification">

                                <b>[11]</b> CHEN S, SUZUKI K, MACMAHON H.Development and evaluation of a computer-aided diagnostic scheme for lung nodule detection in chest radiographs by means of two-stage nodule enhancement with support vector classification[J].Medical Physics, 2011, 38 (4) :1844-1858.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A fully automated method for lung nodule detection from postero-anterior chest radiographs">

                                <b>[12]</b> CAMPADELLI P, CASIRAGHI E, ARTIOLI D.A fully automated method for lung nodule detection from postero-anterior chest radiographs[J].IEEE Transactions on Medical Imaging, 2006, 25 (12) :1588-1603.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Training a computer aided detection system with simulated lung nodules in chest radiographs">

                                <b>[13]</b> SNOEREN P R, LITJENS G J S, GINNEKEN B V, et al.Training a computer aided detection system with simulated lung nodules in chest radiographs[C]//Proceedings of the 3rd International Workshop on Pulmonary Image Analysis.New York, USA:ACM Press, 2016, 139-142.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJS201802003&amp;v=MjI5NTE0TzN6cXFCdEdGckNVUkxPZVplUm9GeS9nVUw3T0x6N0JmYkc0SDluTXJZOUZaNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 孟以爽, 易平, 顾问, 等.基于深度学习的肺结节检测[J].计算机时代, 2018 (2) :5-9.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201801031&amp;v=MDgxMjR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkvZ1VMN09MejdCYjdHNEg5bk1ybzlHWllRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 赵鹏飞, 赵涓涓, 强彦, 等.多输入卷积神经网络肺结节检测方法研究[J].计算机科学, 2018, 45 (1) :162-166.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=U-Net:convolutional networks for biomedical image segmenta-tion">

                                <b>[16]</b> RONNEBERGER O, FISCHER P, BROX T.U-Net:convolutional networks for biomedical image segmenta-tion[EB/OL].[2018-04-18].https://arxiv.org/abs/1505.04597v1.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Densely connected convolutional networks">

                                <b>[17]</b> GAO H, ZHUANG L.Densely connected convolutional networks[EB/OL].[2018-04-18].https://arxiv.org/abs/1608.06993
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016063691.nh&amp;v=MTgzODVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeS9nVUw3T1ZGMjZHTE8rSGRmRnJwRWJQSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 陈鸿翔.基于卷积神经网络的图像语义分割[D].杭州:浙江大学, 2016.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">

                                <b>[19]</b> LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2015:3431-3440.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1017721023.nh&amp;v=MjExMjViUzZIOUhPckpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L2dVTDdPVkYyNkc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 芮杰.多源遥感数据测绘应用关键技术研究[D].北京:中国科学院大学, 2017.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Research on improved algorithm of object detection based on feature pyramid">

                                <b>[21]</b> QIN P, LI C, CHEN J, et al.Research on improved algorithm of object detection based on feature pyramid[J].Multimedia Tools and Applications, 2019, 78 (1) :913-927.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature pyramid networks for object detection">

                                <b>[22]</b> LIN T Y, DOLLAR P, GIRSHICK R, et al.Feature pyramid networks for object detection[EB/OL].[2018-04-18].https://arxiv.org/abs/1612.03144v2.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201409002&amp;v=MDUwNTJwbzlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkvZ1VMN09MeXZTZExHNEg5WE0=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b> LIN G H, LUO S W, HUANG Y P, et al.A novel regularization method based on convolution neural network[J].Journal of Computer Research and Development, 2014, 51 (9) :1891-1900.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Measures of the amount of ecological association between species">

                                <b>[24]</b> DICE L R.Measures of the amount of ecologic association between species[J].Ecology, 1945, 26 (3) :297-302.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ200611000&amp;v=MTE2NjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L2dVTDdPTHo3U1pMRzRIdGZOcm85RlpJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b> 刘宝生, 闫莉萍, 周东华.几种相似性测度的比较[J].计算机应用研究, 2006, 23 (11) :1-3.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=FAIZ201612001&amp;v=MDA4NDZHNEg5Zk5yWTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkvZ1VMN09JeXpDZEw=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b> 周清华, 范亚光, 王颖, 等.中国肺部结节分类、诊断与治疗指南[J].中国肺癌杂志, 2016, 19 (12) :793-798.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201904042" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201904042&amp;v=MDcxMTR6cXFCdEdGckNVUkxPZVplUm9GeS9nVUw3T0x6N0JiYkc0SDlqTXE0OUJab1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
