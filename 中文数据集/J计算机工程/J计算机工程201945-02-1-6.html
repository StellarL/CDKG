<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131270576368750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201902001%26RESULT%3d1%26SIGN%3dIfNrpUzo70r5UnGowu2%252b%252b1l7X6M%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902001&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902001&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902001&amp;v=MDUwOTRuaFZyM01MejdCYmJHNEg5ak1yWTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#67" data-title="0概述 ">0概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#72" data-title="1 相关研究 ">1 相关研究</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#73" data-title="1.1 实时用户活动识别建模">1.1 实时用户活动识别建模</a></li>
                                                <li><a href="#78" data-title="1.2 基于传感器依赖的建模方法">1.2 基于传感器依赖的建模方法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#91" data-title="2 基于传感器距离的建模方法 ">2 基于传感器距离的建模方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#93" data-title="2.1 基于传感器距离的互信息">2.1 基于传感器距离的互信息</a></li>
                                                <li><a href="#106" data-title="2.2 基于传感器距离对上次活动的推测">2.2 基于传感器距离对上次活动的推测</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#124" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#125" data-title="3.1 数据集">3.1 数据集</a></li>
                                                <li><a href="#128" data-title="3.2 实验设置">3.2 实验设置</a></li>
                                                <li><a href="#133" data-title="3.3 结果对比分析">3.3 结果对比分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#149" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#127" data-title="表1 数据集基本特征统计">表1 数据集基本特征统计</a></li>
                                                <li><a href="#137" data-title="图1 基于SVM分类器的建模方法比较 (不包含“其他”活动) ">图1 基于SVM分类器的建模方法比较 (不包含“其他”活动) </a></li>
                                                <li><a href="#138" data-title="图2 基于KNN分类器的建模方法比较 (不包含“其他”活动) ">图2 基于KNN分类器的建模方法比较 (不包含“其他”活动) </a></li>
                                                <li><a href="#141" data-title="图3 数据B3中每个活动的F1值">图3 数据B3中每个活动的F1值</a></li>
                                                <li><a href="#146" data-title="图4 基于SVM分类器的建模方法比较 (包含“其他”活动) ">图4 基于SVM分类器的建模方法比较 (包含“其他”活动) </a></li>
                                                <li><a href="#147" data-title="图5 基于KNN分类器的建模方法比较 (包含“其他”活动) ">图5 基于KNN分类器的建模方法比较 (包含“其他”活动) </a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="35">


                                    <a id="bibliography_1" title="RASHIDI P, COOK D J, HOLDER L B, et al.Discovering activities to recognize and track in a smart environment[J].IEEE Transactions on Knowledge and Data Engineering, 2011, 23 (4) :527-539." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discovering Activities to Recognize and Track in a Smart Environment">
                                        <b>[1]</b>
                                        RASHIDI P, COOK D J, HOLDER L B, et al.Discovering activities to recognize and track in a smart environment[J].IEEE Transactions on Knowledge and Data Engineering, 2011, 23 (4) :527-539.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_2" title="SPRINT G, COOK D J, FRITZ R, et al.Detecting health and behavior change by analyzing smart home sensor data[C]//Proceedings of International Conference on Smart Computing.St Louis, USA:IEEE Press, 2016:152-164." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detecting health and behavior change by analyzing smart home sensor data">
                                        <b>[2]</b>
                                        SPRINT G, COOK D J, FRITZ R, et al.Detecting health and behavior change by analyzing smart home sensor data[C]//Proceedings of International Conference on Smart Computing.St Louis, USA:IEEE Press, 2016:152-164.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_3" title="RASHIDI P, MIHAIlIDIS A.A survey on ambient-assisted living tools for older adults[J].IEEE Journal of Biomedical and Health Informatics, 2013, 17 (3) :579-590." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A survey on ambient-assisted living tools for older adults">
                                        <b>[3]</b>
                                        RASHIDI P, MIHAIlIDIS A.A survey on ambient-assisted living tools for older adults[J].IEEE Journal of Biomedical and Health Informatics, 2013, 17 (3) :579-590.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_4" title="高晨兰, 朱嘉钢.静止背景下的人体行为识别方法[J].计算机工程, 2017, 43 (10) :192-197." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201710033&amp;v=MjE1NDc0SDliTnI0OUdaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeW5oVnIzTUx6N0JiYkc=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        高晨兰, 朱嘉钢.静止背景下的人体行为识别方法[J].计算机工程, 2017, 43 (10) :192-197.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_5" title="卢先领, 徐仙.基于加速度与HGA-BP神经网络的人体行为识别[J].计算机工程, 2015, 41 (9) :220-224, 232." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201509042&amp;v=MDU4NjhaZVJuRnluaFZyM01MejdCYmJHNEg5VE1wbzlCWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        卢先领, 徐仙.基于加速度与HGA-BP神经网络的人体行为识别[J].计算机工程, 2015, 41 (9) :220-224, 232.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_6" title="SPRINT G, COOK D J, FRITZ R, et al.Using smart homes to detect and analyze health events[J].Computer, 2016, 49 (11) :29-37." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using smart homes to detect and analyze health events">
                                        <b>[6]</b>
                                        SPRINT G, COOK D J, FRITZ R, et al.Using smart homes to detect and analyze health events[J].Computer, 2016, 49 (11) :29-37.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_7" title="BAGAVEYEV S, COOK D J.Designing and evaluating active learning methods for activity recognition[C]//Proceedings of ACM International Joint Conference on Pervasive and Ubiquitous Computing:Adjunct Publication.New York, USA:ACM Press, 2014:142-156." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Designing and evaluating active learning methods for activity recognition">
                                        <b>[7]</b>
                                        BAGAVEYEV S, COOK D J.Designing and evaluating active learning methods for activity recognition[C]//Proceedings of ACM International Joint Conference on Pervasive and Ubiquitous Computing:Adjunct Publication.New York, USA:ACM Press, 2014:142-156.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_8" title="YALA N, FERGANI B, FLEURY A.Feature extraction for human activity recognition on streaming data[C]//Proceedings of International Symposium on Innovations in Intelligent Systems and Applications.Madrid, Spain:IEEE Press, 2015:147-158." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature extraction for human activity recognition on streaming data">
                                        <b>[8]</b>
                                        YALA N, FERGANI B, FLEURY A.Feature extraction for human activity recognition on streaming data[C]//Proceedings of International Symposium on Innovations in Intelligent Systems and Applications.Madrid, Spain:IEEE Press, 2015:147-158.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_9" title="COOK D J, KRISHNAN N C, RASHIDI P.Activity discovery and activity recognition:a new partnership[J].IEEE Transactions on Cybernetics, 2013, 43 (3) :820-828." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Activity discovery and activity recognition:A new partnership">
                                        <b>[9]</b>
                                        COOK D J, KRISHNAN N C, RASHIDI P.Activity discovery and activity recognition:a new partnership[J].IEEE Transactions on Cybernetics, 2013, 43 (3) :820-828.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_10" title="YAN S, LIAO Y, FENG X, et al.Real time activity recognition on streaming sensor data for smart environments[C]//Proceedings of the 2016 International Conference on Progress in Informatics and Computing.Shanghai, China:[s.n.], 2017:123-132." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real time activity recognition on streaming sensor data for smart environments">
                                        <b>[10]</b>
                                        YAN S, LIAO Y, FENG X, et al.Real time activity recognition on streaming sensor data for smart environments[C]//Proceedings of the 2016 International Conference on Progress in Informatics and Computing.Shanghai, China:[s.n.], 2017:123-132.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_11" title="COOK D J, KRISHNAN N C.Activity learning:discovering, recognizing, and predicting human behavior from sensor data[M].New Jersey, USA:John Wiley and Sons, Inc., 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Activity learning:discovering recognizing and predicting human behavior from sensor data">
                                        <b>[11]</b>
                                        COOK D J, KRISHNAN N C.Activity learning:discovering, recognizing, and predicting human behavior from sensor data[M].New Jersey, USA:John Wiley and Sons, Inc., 2015.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_12" title="KRISHNAN N C, COOK D J.Activity recognition on streaming sensor data[J].Pervasive and Mobile Computing, 2014, 10 (B) :138-154." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300240361&amp;v=MDc3MTlpclJkR2VycVFUTW53WmVadUh5am1VTGJJSVZvUmFCWT1OaWZPZmJLN0h0RE5ySTlGWnU4UEQzbzRvQk1UNlQ0UFFILw==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        KRISHNAN N C, COOK D J.Activity recognition on streaming sensor data[J].Pervasive and Mobile Computing, 2014, 10 (B) :138-154.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_13" title="YALA N, FERGANI B, FLEURI A.Towards improving feature extraction and classification for activity recognition on streaming data[J].Journal of Ambient Intelligence and Humanized Computing, 2016, 8 (2) :1-13." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Towards improving feature extraction and classification for activity recognition on streaming data">
                                        <b>[13]</b>
                                        YALA N, FERGANI B, FLEURI A.Towards improving feature extraction and classification for activity recognition on streaming data[J].Journal of Ambient Intelligence and Humanized Computing, 2016, 8 (2) :1-13.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_14" title="RASHIDI P, COOK D J.Multi home transfer learning for resident activity discovery and recognition[C]//Proceedings of International Workshop on Knowledge Discovery from Sensor Data.Washington D.C., USA:IEEE Press, 2010:345-354." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Multi home transfer learning for resident activity discovery andrecognition&amp;quot;">
                                        <b>[14]</b>
                                        RASHIDI P, COOK D J.Multi home transfer learning for resident activity discovery and recognition[C]//Proceedings of International Workshop on Knowledge Discovery from Sensor Data.Washington D.C., USA:IEEE Press, 2010:345-354.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_15" title="MINOR B, DOPPA J R, COOK D J.Data-driven activity prediction:algorithms, evaluation methodology, and applications[C]//Proceedings of the 21st ACMSIGKDD International Conference on Knowledge Discovery and Data Mining.Sydney, Australia:ACM Press, 2015:243-254." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Data-driven activity prediction:algorithms evaluation methodology and applications">
                                        <b>[15]</b>
                                        MINOR B, DOPPA J R, COOK D J.Data-driven activity prediction:algorithms, evaluation methodology, and applications[C]//Proceedings of the 21st ACMSIGKDD International Conference on Knowledge Discovery and Data Mining.Sydney, Australia:ACM Press, 2015:243-254.
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_16" title="COOK D J, CRANDALL A S, THOMAS B L, et al.CASAS:a smart home in a box[J].Computer, 2013, 46 (7) :62-69." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CAS AS:a smart home in a box">
                                        <b>[16]</b>
                                        COOK D J, CRANDALL A S, THOMAS B L, et al.CASAS:a smart home in a box[J].Computer, 2013, 46 (7) :62-69.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(02),1-6 DOI:10.19678/j.issn.1000-3428.0049937            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于传感器距离的实时用户活动识别建模方法</span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%B9%E6%B5%A9%E5%93%B2&amp;code=38808999&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曹浩哲</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E9%B9%8F&amp;code=06708082&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张鹏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%A2%E6%9A%BE&amp;code=13985324&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卢暾</a>
                                <a href="javascript:;">顾寒苏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A1%BE%E5%AE%81&amp;code=06695406&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">顾宁</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%8D%E6%97%A6%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0075855&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">复旦大学计算机科学技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%8D%E6%97%A6%E5%A4%A7%E5%AD%A6%E4%B8%8A%E6%B5%B7%E5%B8%82%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">复旦大学上海市数据科学重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B8%8C%E6%8D%B7%E7%A7%91%E6%8A%80%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">希捷科技有限公司</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对传统的用户活动识别建模方法在实时性要求下精度较低的缺点, 提出一种改进的实时用户活动识别建模方法。利用已标注的传感器事件流数据建立传感器触发概率矩阵, 并计算出传感器距离, 作为建模的先验知识, 在后续建模过程中赋予每个传感器事件不同的权重。根据传感器距离的内在含义判断活动转移发生的位置, 通过概率矩阵推测上次活动作为新的特征维度来建模当前活动。在Aruba、Tulum2010和HH106 3个公开数据集上的实验结果表明, 与SWMI、SWMIex等方法相比, 该建模方法在精度和F1 2个指标上最大提升可超过10%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B4%BB%E5%8A%A8%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">活动识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%88%E9%AA%8C%E7%9F%A5%E8%AF%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">先验知识;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">滑动窗口;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BC%A0%E6%84%9F%E5%99%A8%E8%B7%9D%E7%A6%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">传感器距离;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%92%E4%BF%A1%E6%81%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">互信息;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    曹浩哲 (1992—) , 男, 硕士研究生, 主研方向为物联网、协同计算、人机交互;
;
                                </span>
                                <span>
                                    张鹏, 博士研究生;
;
                                </span>
                                <span>
                                    卢暾, 副教授、博士;
;
                                </span>
                                <span>
                                    顾寒苏, 博士;
;
                                </span>
                                <span>
                                    顾宁, 教授、博士生导师。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-02</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划 (2016YFB1001404);</span>
                    </p>
            </div>
                    <h1>Real-time User Activity Recognition Modeling Method Based on Sensor Distance</h1>
                    <h2>
                    <span>CAO Haozhe</span>
                    <span>ZHANG Peng</span>
                    <span>LU Tun</span>
                    <span>GU Hansu</span>
                    <span>GU Ning</span>
            </h2>
                    <h2>
                    <span>School of Computer Science, Fudan University</span>
                    <span>Shanghai Key Laboratory of Data Science, Fudan University</span>
                    <span>Seagate Technology Co., Ltd.</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the shortcomings of traditional user activity recognition modeling method with insufficient accuracy under real-time requirements, an improved real-time user activity recognition modeling method is proposed. The method constructs the sensor trigger probability matrix using the labeled sensor event flow data, and calculates the sensor distance. As a prior knowledge of modeling, the sensor events are given different weights in the subsequent modeling process. According to the intrinsic meaning of sensor distance, the location of activity transfer is judged, and the current activity is modeled by inferring the last activity as a new feature dimension through probability matrix. Experimental results on the three public datasets of Aruba, Tulum2010 and HH106 show that compared with SWMI, SWMIex and other methods, the proposed modeling method can increase the accuracy and F1 by more than 10%.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=activity%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">activity recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=priori%20knowledge&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">priori knowledge;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sliding%20window&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sliding window;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sensor%20distance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sensor distance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Mutual%20Information%20(MI)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Mutual Information (MI) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-02</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="67" name="67" class="anchor-tag">0概述</h3>
                <div class="p1">
                    <p id="68">用户活动识别旨在识别用户的日常行为活动 (Activities of Daily Living, ADL) <citation id="154" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 如吃饭、睡觉、如厕等。相关研究表明, 规律地执行日常活动的能力通常能够反映用户尤其是老年人的身心健康状态<citation id="155" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。因此, 日常活动识别是评估用户身体机能状态、保证用户安全、幸福、舒适生活的重要手段。近年来, 随着物联网和机器学习技术的发展, 基于非侵入式传感器的活动识别得到了广泛关注与研究<citation id="151" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 与传统的基于计算机视觉<citation id="152" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>和可穿戴传感器<citation id="153" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>的活动识别相比, 非侵入式传感器的使用具有易于部署、成本低廉、隐私性好等诸多优点。</p>
                </div>
                <div class="p1">
                    <p id="69">实时活动识别要求识别用户当前正在执行的活动<citation id="156" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>, 是一个典型的多分类问题<citation id="157" type="reference"><link href="47" rel="bibliography" /><link href="49" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>。具体来说, 当用户在执行一项日常活动时, 通常会触发一个或多个传感器, 造成传感器输出状态的改变, 每次改变被记录为一个传感器事件, 多个传感器事件按照时间顺序组成传感器事件流。实时活动识别需要根据事件流中若干个传感器事件判断用户当前正在执行活动的类别。</p>
                </div>
                <div class="p1">
                    <p id="70">传统的基于非侵入式传感器的活动识别通常选择基于事件的窗口分割方法, 该方法将事件流分割成事件数目相等的若干个窗口<citation id="159" type="reference"><link href="51" rel="bibliography" /><link href="53" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>, 并对每个窗口提取活动的空间特征和时间特征<citation id="158" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。其中, 空间特征由窗口内每个传感器的出现次数表征, 时间特征则由窗口的开始时间、结束时间和窗口时长来表征。但上述的实时活动识别建模方法在提取空间特征时存在较大的缺陷。由于使用窗口内传感器出现的次数来表征空间特征, 一旦窗口内出现2个不同的活动, 即出现了活动的转移, 那么来自前一个活动的空间特征同样被用来描述当前活动的空间特征, 容易导致分类器将其识别为前一个活动, 影响识别的实时性与精度。为了弥补上述缺陷, 文献<citation id="160" type="reference">[<a class="sup">12</a>,<a class="sup">13</a>]</citation>提出基于传感器依赖的建模方法, 分别通过统计2个传感器在事件流中相邻出现的频率以及在窗口中先后出现的频率来衡量传感器之间的依赖, 赋予每个事件不同的权重, 从而弱化来自前一个活动的传感器事件对建模当前活动的影响。但上述方法都只考虑了传感器事件之间的相关性, 忽视了有监督识别场景下事件与活动之间的相关性, 影响了识别精度。</p>
                </div>
                <div class="p1">
                    <p id="71">基于上述研究, 本文综合考虑事件与活动的对应关系, 引入传感器距离的概念来定义不同事件在建模当前活动中的权重, 同时根据传感器距离捕获窗口内活动转移发生的位置推测上次活动, 并将其作为新的特征维度加入到活动建模中。</p>
                </div>
                <h3 id="72" name="72" class="anchor-tag">1 相关研究</h3>
                <h4 class="anchor-tag" id="73" name="73">1.1 实时用户活动识别建模</h4>
                <div class="p1">
                    <p id="74">在基于非侵入式传感器的活动识别中, 每个传感器事件都可表示成一个四元组{ts, s, m, l}<citation id="161" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 其中, ts表示传感器被触发的时间戳 (包括日期和时间) , s表示传感器标识符, m表示传感器消息, l只出现在有监督活动识别中, 表示触发该传感器的活动标签, l为空时表示该传感器事件没有对应的具体活动类别。</p>
                </div>
                <div class="p1">
                    <p id="75">对传感器事件流, 相关研究普遍使用滑动窗口方法对其进行分割, 每个窗口可表示为w<sub>i</sub>=[e<sub>i</sub>, e<sub>i+1</sub>, …, e<sub>i+m-1</sub>], 其中, w<sub>i</sub>表示第i个窗口, e<sub>i</sub>表示事件流中的第i个事件, m表示窗口长度。可以看出, 窗口的滑动距离固定为1, 因为实时活动识别要求识别每一个最新的传感器事件所对应的活动。</p>
                </div>
                <div class="p1">
                    <p id="76">对窗口w<sub>i</sub>, 提取空间特征和时间特征构建特征向量, 记为x<sub>i</sub>。实时活动识别要求识别最近的活动, 因此, 选择窗口内最后一个事件e<sub>i+m-1</sub>所对应的活动标签作为当前窗口的真实标签, 记作y<sub>i</sub>, 且y<sub>i</sub>∈A, 其中, A为所有活动类别的集合<citation id="162" type="reference"><link href="63" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="77">当特征向量与对应的标签提取完成后, 使用常见的机器学习分类方法进行训练。在实际应用场景中, 每当出现一个新的传感器事件时, 则结合前 (m-1) 个事件组成新的窗口, 提取特征向量, 作为已训练好的分类器的输入, 其输出即为模型认为的用户当前正在执行的活动, 从而完成活动识别目标。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">1.2 基于传感器依赖的建模方法</h4>
                <div class="p1">
                    <p id="79">对每个窗口, 传统的建模方法使用窗口内每个传感器出现的次数来表征活动的空间特征, 但该方法在实际应用时存在缺陷。例如, 对第i个窗口w<sub>i</sub>=[e<sub>i</sub>, e<sub>i+1</sub>, …, e<sub>i+k-1</sub>, e<sub>i+k</sub>, …, e<sub>i+m-1</sub>], 假设前k个事件由用户在执行活动a<sub>1</sub>的过程中触发, 剩余事件由活动a<sub>2</sub>触发。实时活动识别要求识别当前窗口内的活动为a<sub>2</sub>, 但在提取空间特征的过程中, 来自活动a<sub>1</sub>的传感器事件同样被用来对活动a<sub>2</sub>进行定义和建模, 进而影响分类器的学习和判断, 造成实时识别精度的下降。基于此, 文献<citation id="163" type="reference">[<a class="sup">12</a>,<a class="sup">13</a>]</citation>提出基于传感器依赖的建模方法, 赋予每个传感器事件不同的权重, 具体介绍如下。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80">1.2.1 传感器依赖</h4>
                <div class="p1">
                    <p id="81">文献<citation id="164" type="reference">[<a class="sup">12</a>]</citation>引入互信息 (Mutual Information, MI) 的概念来定义窗口内每个传感器事件在特征向量中的权重。互信息通常用来衡量2个随机变量之间的依赖, 即一个变量中包含关于另一个变量的信息量大小。在活动识别场景下, 每个传感器被看作是一个随机变量, 2个传感器间的互信息通过其在传感器事件流中连续出现的频率来表征, 即<citation id="165" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>:</p>
                </div>
                <div class="area_img" id="82">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902001_08200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="83">其中:</p>
                </div>
                <div class="area_img" id="84">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902001_08400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="85">其中, N为传感器事件的总数目, s<sub>k</sub>表示第k个传感器, MI (i, j) 表示传感器s<sub>i</sub>与s<sub>j</sub>之间的互信息。可以看出, 当且仅当前一个传感器是s<sub>i</sub>而后一个传感器是s<sub>j</sub>时, 式 (1) 中的求和项才取值为1。这意味如果2个传感器总是被连续触发, 则它们的互信息值更高。</p>
                </div>
                <div class="p1">
                    <p id="86">另外, 从式 (1) 、式 (2) 可以看出, 互信息矩阵需要遍历整个传感器事件流, 因此只能通过离线方式进行计算, 作为活动建模的先验知识。然后在构建特征向量的过程中, 依次计算窗口内每个传感器事件与最后一个事件的互信息, 作为该事件在空间特征中的权重, 来代替简单的计数特征。这种方法记作SWMI (Sensor Window Mutual Information) 。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87">1.2.2 传感器依赖的改进</h4>
                <div class="p1">
                    <p id="88">SWM I方法仅仅考虑了相邻的2个传感器事件, 忽视了传感器被活动触发的随机性。假设有4个传感器s<sub>1</sub>、s<sub>2</sub>、s<sub>3</sub>和s<sub>4</sub>, 用户在执行某项活动的过程中触发传感器的顺序可能是s<sub>1</sub>→s<sub>2</sub>→s<sub>3</sub>→s<sub>4</sub>, 也可能是s<sub>1</sub>→s<sub>3</sub>→s<sub>2</sub>→s<sub>4</sub>。可以看到, 在这2种情况下, s<sub>1</sub>和s<sub>2</sub>之间都存在依赖关系。如果使用SWMI方法计算s<sub>1</sub>与s<sub>2</sub>之间的互信息, 就只考虑了第1条路径中两者的依赖, 而损失了第2条路径中两者的依赖。基于此, 文献<citation id="166" type="reference">[<a class="sup">13</a>]</citation>对SWMI方法进行了改进, 通过考察2个传感器在一个窗口内出现的频率, 代替相邻出现的频率来计算互信息, 计算方法如下<citation id="167" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>:</p>
                </div>
                <div class="area_img" id="89">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902001_08900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="90">其中, W是窗口的总数目, m是每个窗口的长度。该互信息矩阵同样在离线环境下计算得到, 然后用来定义每个传感器事件的权重。这种方法记作SWMIex (Sensor Window Mutual Information extension) 。</p>
                </div>
                <h3 id="91" name="91" class="anchor-tag">2 基于传感器距离的建模方法</h3>
                <div class="p1">
                    <p id="92">尽管SWMIex对SWMI进行改进, 但它们都只考虑了传感器事件之间的相关性来衡量传感器依赖, 忽视了在有监督识别场景下事件与已标注的活动类别之间的相关性。实际上, 由于传感器被固定在周围环境, 每个活动又通常发生在固定的空间, 因此一项活动在被执行过程中只可能触发它附近的部分传感器。此外, 如果2个活动发生在同一空间下, 那么它们也可能触发同样的传感器。基于此, 本文提出传感器距离的概念进行活动建模。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93">2.1 基于传感器距离的互信息</h4>
                <div class="p1">
                    <p id="94">本文定义2个传感器之间的距离为它们被同一活动触发的概率。通过分析可以看出, 距离越小, 说明它们更有可能被同一活动触发, 反之, 距离越大, 说明它们更有可能来自不同的活动。</p>
                </div>
                <div class="p1">
                    <p id="95">与上文的传感器依赖计算方法类似, 传感器距离矩阵需要通过遍历已标注的传感器事件流得到, 并作为建模的先验知识。具体计算方法如下:</p>
                </div>
                <div class="p1">
                    <p id="96">1) 对事件流进行统计, 构造二维矩阵C, 其中, c<sub>ij</sub>表示事件流中第i个传感器s<sub>i</sub>被第j个活动a<sub>j</sub>触发的次数。</p>
                </div>
                <div class="p1">
                    <p id="97">2) 对矩阵C按照式 (4) 进行标准化处理, 得到二维矩阵P:</p>
                </div>
                <div class="area_img" id="98">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902001_09800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="99">其中, n表示活动类别的数目, p<sub>ij</sub>可以看作是传感器s<sub>i</sub>被活动a<sub>j</sub>触发的统计概率。</p>
                </div>
                <div class="p1">
                    <p id="100">3) 利用矩阵P, 定义传感器s<sub>i</sub>和s<sub>j</sub>之间的距离如下:</p>
                </div>
                <div class="area_img" id="101">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902001_10100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="102">记传感器距离矩阵为D, 其中, d<sub>ij</sub>=dis (i, j) 。可见, dis (i, j) 的取值范围为[0, 1]。其值越接近0, 说明s<sub>i</sub>和s<sub>j</sub>更有可能被同样的活动触发, 相反, 其值越接近1, 说明s<sub>i</sub>和s<sub>j</sub>更可能来自不同的活动。</p>
                </div>
                <div class="p1">
                    <p id="103">根据传感器距离的定义可知, 传感器距离越大, 在建模过程中的权重应该更小, 因此, 本文引入指数函数重新定义互信息:</p>
                </div>
                <div class="area_img" id="104">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902001_10400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="105">同样, 在构建特征向量的过程中, 利用该互信息矩阵对每个传感器事件赋予不同的权重。这种方法记作MISD (Mutual Information Based on Sensor Distance) 。</p>
                </div>
                <h4 class="anchor-tag" id="106" name="106">2.2 基于传感器距离对上次活动的推测</h4>
                <div class="p1">
                    <p id="107">上文描述的方法只考虑了当前窗口内的信息, 并没有考虑过去的情境信息, 如上次活动。实际上, 上次活动的类别对建模当前活动非常重要。例如吃饭总是发生在做饭后, 如果可以知道上次活动是做饭, 则有更大的置信度认为当前的活动是吃饭。但在实时活动识别场景下, 无法准确地得到上次活动的真实类别, 因此, 只能通过当前窗口内的信息推测上次活动可能的类别来定义过去情境特征。</p>
                </div>
                <div class="p1">
                    <p id="108">由传感器距离的定义可以推断, 如果窗口内2个相邻的传感器s<sub>i</sub>到s<sub>j</sub>之间的距离dis (i, j) 大于某个阈值, 则可以断定它们来自不同的活动, 即从s<sub>i</sub>到s<sub>j</sub>出现了一次活动的转移。最简单地, 可以根据上次活动触发的传感器s<sub>i</sub>和概率矩阵P来初步推测上次活动a<sup>*</sup>:</p>
                </div>
                <div class="area_img" id="109">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902001_10900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="110">即总是选取有最大统计概率触发传感器s<sub>i</sub>的活动作为推测的上次活动。如果窗口内没有捕获到活动转移, 则使用前一个窗口内推测的上次活动。依次类推。</p>
                </div>
                <div class="p1">
                    <p id="111">显然, 该特征不能单独使用, 需要结合空间特征和时间特征共同使用, 从而更完整地建模当前活动, 该特征记作IPA (Inferred Previous Activity) 。</p>
                </div>
                <div class="p1">
                    <p id="112">综上所述, 基于传感器距离的实时用户活动识别建模步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="113">1) 遍历传感器事件流, 计算传感器被不同活动触发的频率矩阵C, 并根据式 (4) 和式 (5) 计算相应的概率矩阵P以及传感器距离矩阵D, 作为建模的先验知识。</p>
                </div>
                <div class="p1">
                    <p id="114">2) 使用滑动窗口对传感器事件流进行分割, 并对每个窗口提取特征向量x和真实活动类别y, 具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="115"> (1) 将前m个传感器事件加入到窗口中, 记这m个事件中的传感器分别为s<sub>1</sub>, s<sub>2</sub>, …, s<sub>m</sub>, 对应的时间戳分别为ts<sub>1</sub>, ts<sub>2</sub>, …, ts<sub>m</sub>。</p>
                </div>
                <div class="p1">
                    <p id="116"> (2) 初始化x为n<sub>s</sub>+3+1维度向量, 其中, n<sub>s</sub>为传感器个数, 对应n<sub>s</sub>个传感器在建模当前活动中的贡献, 3表示3个时间特征, 1表示上次活动特征。</p>
                </div>
                <div class="p1">
                    <p id="117"> (3) 根据式 (6) , 依次计算每个传感器s<sub>i</sub> (1≤i≤m) 与传感器s<sub>m</sub>之间的互信息, 填入s<sub>i</sub>对应的维度, 作为空间特征。</p>
                </div>
                <div class="p1">
                    <p id="118"> (4) 只考虑时间戳中的时间信息, 将其转换成相对于0 h 0 min的秒数, 使用ts<sub>1</sub>和ts<sub>m</sub>对应的秒数以及两者的差值作为时间特征。</p>
                </div>
                <div class="p1">
                    <p id="119"> (5) 依次计算传感器s<sub>i</sub>与s<sub>i-1</sub> (2≤i≤m) 之间的距离, 如果该距离大于给定阈值, 则根据式 (7) 找到具有最大概率触发传感器s<sub>i-1</sub>的活动作为上一次活动特征;否则, 沿用前一个窗口的上次活动特征。</p>
                </div>
                <div class="p1">
                    <p id="120"> (6) 使用最后一个传感器s<sub>m</sub>对应的活动类别作为真实标签y。</p>
                </div>
                <div class="p1">
                    <p id="121"> (7) 移除窗口内的第1个事件, 同时增加一个新事件, 重复步骤 (2) ～步骤 (7) 提取特征和真实标签。</p>
                </div>
                <div class="p1">
                    <p id="122">3) 选定分类模型, 使用步骤2) 提取的特征和标签进行分类器的训练。</p>
                </div>
                <div class="p1">
                    <p id="123">4) 将训练好的分类器应用到实际环境时, 按照步骤 (2) ～步骤 (5) 提取每个窗口特征向量作为分类器的输入, 其输出即为识别的当前活动。</p>
                </div>
                <h3 id="124" name="124" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="125" name="125">3.1 数据集</h4>
                <div class="p1">
                    <p id="126">本文使用了来自华盛顿大学CASAS项目<citation id="168" type="reference"><link href="65" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的3个公开数据集, 分别为Aruba、Tulum2010和HH106。为了方便后续表述, 将其分别记作B1、B2和B3, 每个数据集的特点如表1所示。</p>
                </div>
                <div class="area_img" id="127">
                                            <p class="img_tit">
                                                表1 数据集基本特征统计
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902001_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201902001_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902001_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 数据集基本特征统计" src="Detail/GetImg?filename=images/JSJC201902001_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="128" name="128">3.2 实验设置</h4>
                <div class="p1">
                    <p id="129">本文使用支持向量机 (Support Vector Machine, SVM) 和K近邻 (K-Nearest Neighbors, KNN) 2种常用的分类方法进行活动识别建模, 它们也是文献<citation id="169" type="reference">[<a class="sup">12</a>,<a class="sup">13</a>]</citation>中使用的方法, 已被证明在活动识别领域具有较好的性能表现。</p>
                </div>
                <div class="p1">
                    <p id="130">本文选择scikit-learn平台 (基于Python 2.7) 进行数据处理和模型训练。数据处理过程设置滑动窗口的长度为10, 该值也是文献<citation id="170" type="reference">[<a class="sup">13</a>]</citation>中使用的窗口长度。模型训练过程设置SVM的惩罚参数为100, 与文献<citation id="171" type="reference">[<a class="sup">12</a>,<a class="sup">13</a>]</citation>保持一致, 剩余参数及KNN的全部参数均使用scikit-learn平台的缺省值。</p>
                </div>
                <div class="p1">
                    <p id="131">由于日常活动中某些活动出现的频次会明显高于其他活动, 因此活动识别数据通常呈现出较强的不平衡性。此时, 仅仅依靠常用的精度指标来评估模型的性能是不准确的, 因为它容易被占比较大的活动类别所影响, 所以本文引入F1度量作为评估模型性能的第2个指标, 同时使用5折交叉验证方法获得模型的泛化性能, 作为最终的结果。</p>
                </div>
                <div class="p1">
                    <p id="132">此外, 本文中的所有实验都运行在个人计算机上, 其软硬件配置为Windows 10专业版系统, 4核i5 CPU以及16 GB内存。</p>
                </div>
                <h4 class="anchor-tag" id="133" name="133">3.3 结果对比分析</h4>
                <div class="p1">
                    <p id="134">在传感器事件流数据中, 存在部分事件没有对应的活动标签, 对于这些事件, 在数据预处理过程中将其标记为“其他”活动。考虑到对“其他”活动的识别并不是活动识别研究的重点, 但这些活动在现实中确实存在且占比较大, 因此本文进行了2组实验, 下文第3.3.1节实验在模型训练和测试阶段都不包含“其他”活动, 第3.3.2节实验则包含“其他”活动<citation id="172" type="reference"><link href="57" rel="bibliography" /><link href="59" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="135" name="135">3.3.1 不包含“其他”活动的建模方法比较</h4>
                <div class="p1">
                    <p id="136">本文测试了SWMI、SWMIex、MISD 3个方法在数据集上的表现, 实验结果如图1、图2所示。可以看出, SWMIex相较于SWMI在精度和F1上的提升都不明显, 平均不足1%。但本文提出的MISD方法在3个数据集上都取得了最优的性能表现, 最大的性能提升体现在数据集B2上, 与SWMI方法相比, MISD方法在精度和F1指标上的提升分别为7.7%、13.6% (SVM分类器) 以及7.5%、12.9% (KNN分类器) 。</p>
                </div>
                <div class="area_img" id="137">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902001_13700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于SVM分类器的建模方法比较 (不包含“其他”活动)" src="Detail/GetImg?filename=images/JSJC201902001_13700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 基于SVM分类器的建模方法比较 (不包含“其他”活动)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902001_13700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902001_13800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于KNN分类器的建模方法比较 (不包含“其他”活动)" src="Detail/GetImg?filename=images/JSJC201902001_13800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 基于KNN分类器的建模方法比较 (不包含“其他”活动)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902001_13800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="139">考虑到MISD方法在3个数据集上都取得了最优的性能表现, 本文在MISD的基础上引入IPA特征重新进行实验, 结果见图1、图2。可以看到, 加入IPA特征后, 活动识别的精度和F1都有所提升。其中最大的提升出现在数据集B3上, 当使用SVM分类器时, 精度和F1分别增加了7.9%和12.0%, 使用KNN分类器时, 则分别增加了3.4%和4.5%。</p>
                </div>
                <div class="p1">
                    <p id="140">为进一步表明IPA特征在活动识别中的作用, 本文比较了使用IPA和不使用IPA时数据集B3中每个活动的F1值, 如图3所示。从图3可以明显看到, 当引入IPA特征后, “Eat”和“Work＿At＿Table”2个活动的F1都取得了很大幅度的提升, 分别为73%和52%。实际上, 当不使用IPA特征时, 这2个活动总是被互相误分类, 因为它们发生的空间是相同的, 都在桌子附近, 即它们的空间特征是相似的, 即使加入时间特征, 也无法有效地对它们进行判别。但加入IPA特征后, 由于两者的IPA特征取值明显不同, 分类器很容易学习到区分两者的依据, 因此分类性能得到了明显提升。类似的现象同样可以在“Cook”系列活动和“Wash”系列活动上观察到。此外, 当使用KNN分类器时, 也能得到相同的结论。</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902001_14100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 数据B3中每个活动的F1值" src="Detail/GetImg?filename=images/JSJC201902001_14100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 数据B3中每个活动的F1值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902001_14100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="142">另外, 横向比较3个数据集时可以发现, 不管使用任何方法和模型, 数据集B2性能表现总是最差, 因为该数据集收集了2个用户的日常活动数据, 分类器很难区分某个活动具体是由哪个用户执行的。</p>
                </div>
                <h4 class="anchor-tag" id="143" name="143">3.3.2 包含“其他”活动的建模方法比较</h4>
                <div class="p1">
                    <p id="144">为验证不同建模方法在实际环境下的表现, 本次实验在分类器的训练和测试阶段包含了“其他”活动。但在最后计算精度和F1指标时, 真实类别为“其他”的这些活动并不参与其中, 因为本文主要关注模型在已知活动上的表现。此外, IPA特征也不包含“其他”活动, 因为它不能提供有效的过去情境信息。</p>
                </div>
                <div class="p1">
                    <p id="145">本组实验的结果如图4、图5所示。从图4、图5可以看出, 与不包含“其他”活动的实验结果相比, 活动识别的精度和F1在3个数据集上都呈现出大幅下降。这是因为“其他”活动通常发生在已知活动之间, 其在空间和时间上与已知活动出现重叠, 即它们没有相对固定的空间特征、时间特征或过去情境特征, 所以导致很多活动被误分类成“其他”活动, 造成了在已知活动上识别性能的大幅下降。</p>
                </div>
                <div class="area_img" id="146">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902001_14600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 基于SVM分类器的建模方法比较 (包含“其他”活动)" src="Detail/GetImg?filename=images/JSJC201902001_14600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 基于SVM分类器的建模方法比较 (包含“其他”活动)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902001_14600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="147">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902001_14700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 基于KNN分类器的建模方法比较 (包含“其他”活动)" src="Detail/GetImg?filename=images/JSJC201902001_14700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 基于KNN分类器的建模方法比较 (包含“其他”活动)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902001_14700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="148">但是本文提出的基于MISD方法与基于SWM的方法相比, 依旧在3个数据集上取得了不同程度的识别精度和F1提升, 即不包含“其他”活动的结论在本组实验中依旧有效。</p>
                </div>
                <h3 id="149" name="149" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="150">本文通过提出利用传感器距离的概念来衡量传感器之间的互信息, 重新定义不同传感器事件在活动建模中的权重。同时利用传感器距离的内在含义引入推测的上次活动作为新的特征维度。在3个公开数据集上的实验结果表明, 与SWMI、SWMIex等方法相比, 本文方法在精度和F1 2个指标上都取得了较大提升。下一步考虑将传感器距离概念引入到基于主动学习方法的活动识别过程中, 以降低活动标注的成本。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="35">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discovering Activities to Recognize and Track in a Smart Environment">

                                <b>[1]</b>RASHIDI P, COOK D J, HOLDER L B, et al.Discovering activities to recognize and track in a smart environment[J].IEEE Transactions on Knowledge and Data Engineering, 2011, 23 (4) :527-539.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detecting health and behavior change by analyzing smart home sensor data">

                                <b>[2]</b>SPRINT G, COOK D J, FRITZ R, et al.Detecting health and behavior change by analyzing smart home sensor data[C]//Proceedings of International Conference on Smart Computing.St Louis, USA:IEEE Press, 2016:152-164.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A survey on ambient-assisted living tools for older adults">

                                <b>[3]</b>RASHIDI P, MIHAIlIDIS A.A survey on ambient-assisted living tools for older adults[J].IEEE Journal of Biomedical and Health Informatics, 2013, 17 (3) :579-590.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201710033&amp;v=MTkzMTFuRnluaFZyM01MejdCYmJHNEg5Yk5yNDlHWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>高晨兰, 朱嘉钢.静止背景下的人体行为识别方法[J].计算机工程, 2017, 43 (10) :192-197.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201509042&amp;v=MDk4MjNVUkxPZVplUm5GeW5oVnIzTUx6N0JiYkc0SDlUTXBvOUJab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>卢先领, 徐仙.基于加速度与HGA-BP神经网络的人体行为识别[J].计算机工程, 2015, 41 (9) :220-224, 232.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using smart homes to detect and analyze health events">

                                <b>[6]</b>SPRINT G, COOK D J, FRITZ R, et al.Using smart homes to detect and analyze health events[J].Computer, 2016, 49 (11) :29-37.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Designing and evaluating active learning methods for activity recognition">

                                <b>[7]</b>BAGAVEYEV S, COOK D J.Designing and evaluating active learning methods for activity recognition[C]//Proceedings of ACM International Joint Conference on Pervasive and Ubiquitous Computing:Adjunct Publication.New York, USA:ACM Press, 2014:142-156.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature extraction for human activity recognition on streaming data">

                                <b>[8]</b>YALA N, FERGANI B, FLEURY A.Feature extraction for human activity recognition on streaming data[C]//Proceedings of International Symposium on Innovations in Intelligent Systems and Applications.Madrid, Spain:IEEE Press, 2015:147-158.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Activity discovery and activity recognition:A new partnership">

                                <b>[9]</b>COOK D J, KRISHNAN N C, RASHIDI P.Activity discovery and activity recognition:a new partnership[J].IEEE Transactions on Cybernetics, 2013, 43 (3) :820-828.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real time activity recognition on streaming sensor data for smart environments">

                                <b>[10]</b>YAN S, LIAO Y, FENG X, et al.Real time activity recognition on streaming sensor data for smart environments[C]//Proceedings of the 2016 International Conference on Progress in Informatics and Computing.Shanghai, China:[s.n.], 2017:123-132.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Activity learning:discovering recognizing and predicting human behavior from sensor data">

                                <b>[11]</b>COOK D J, KRISHNAN N C.Activity learning:discovering, recognizing, and predicting human behavior from sensor data[M].New Jersey, USA:John Wiley and Sons, Inc., 2015.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300240361&amp;v=MTA3ODRlcnFRVE1ud1plWnVIeWptVUxiSUlWb1JhQlk9TmlmT2ZiSzdIdEROckk5Rlp1OFBEM280b0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>KRISHNAN N C, COOK D J.Activity recognition on streaming sensor data[J].Pervasive and Mobile Computing, 2014, 10 (B) :138-154.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Towards improving feature extraction and classification for activity recognition on streaming data">

                                <b>[13]</b>YALA N, FERGANI B, FLEURI A.Towards improving feature extraction and classification for activity recognition on streaming data[J].Journal of Ambient Intelligence and Humanized Computing, 2016, 8 (2) :1-13.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Multi home transfer learning for resident activity discovery andrecognition&amp;quot;">

                                <b>[14]</b>RASHIDI P, COOK D J.Multi home transfer learning for resident activity discovery and recognition[C]//Proceedings of International Workshop on Knowledge Discovery from Sensor Data.Washington D.C., USA:IEEE Press, 2010:345-354.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Data-driven activity prediction:algorithms evaluation methodology and applications">

                                <b>[15]</b>MINOR B, DOPPA J R, COOK D J.Data-driven activity prediction:algorithms, evaluation methodology, and applications[C]//Proceedings of the 21st ACMSIGKDD International Conference on Knowledge Discovery and Data Mining.Sydney, Australia:ACM Press, 2015:243-254.
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CAS AS:a smart home in a box">

                                <b>[16]</b>COOK D J, CRANDALL A S, THOMAS B L, et al.CASAS:a smart home in a box[J].Computer, 2013, 46 (7) :62-69.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201902001" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902001&amp;v=MDUwOTRuaFZyM01MejdCYmJHNEg5ak1yWTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
