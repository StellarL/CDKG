<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637129940636993750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201907038%26RESULT%3d1%26SIGN%3dNtDLVXujecF7yMhHL3l9OnEcZN4%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201907038&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201907038&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201907038&amp;v=MTYxMDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJwRkNqaFZyL0FMejdCYmJHNEg5ak1xSTlHYklRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#53" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#59" data-title="1 研究背景 ">1 研究背景</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#60" data-title="1.1 SLU任务">1.1 SLU任务</a></li>
                                                <li><a href="#68" data-title="1.2 基于&lt;i&gt;LSTM&lt;/i&gt;的&lt;i&gt;SLU&lt;/i&gt;">1.2 基于<i>LSTM</i>的<i>SLU</i></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#75" data-title="2 基于标签分解的SLU模型 ">2 基于标签分解的SLU模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#76" data-title="2.1 标签分解">2.1 标签分解</a></li>
                                                <li><a href="#92" data-title="2.2 联合模型">2.2 联合模型</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#101" data-title="3 实验和结果分析 ">3 实验和结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#102" data-title="3.1 数据集和评价指标">3.1 数据集和评价指标</a></li>
                                                <li><a href="#107" data-title="3.2 实验模型">3.2 实验模型</a></li>
                                                <li><a href="#113" data-title="3.3 结果分析">3.3 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#124" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="&lt;b&gt;表1 IOB标注示例&lt;/b&gt;"><b>表1 IOB标注示例</b></a></li>
                                                <li><a href="#70" data-title="&lt;b&gt;图1 简单RNN结构&lt;/b&gt;"><b>图1 简单RNN结构</b></a></li>
                                                <li><a href="#72" data-title="&lt;b&gt;图2 LSTM单元内部结构&lt;/b&gt;"><b>图2 LSTM单元内部结构</b></a></li>
                                                <li><a href="#74" data-title="&lt;b&gt;图3 BiLSTM结构&lt;/b&gt;"><b>图3 BiLSTM结构</b></a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;图4 ATIS数据集标签统计&lt;/b&gt;"><b>图4 ATIS数据集标签统计</b></a></li>
                                                <li><a href="#115" data-title="&lt;b&gt;表2 不同模型&lt;i&gt;F&lt;/i&gt;1值的对比&lt;/b&gt;"><b>表2 不同模型<i>F</i>1值的对比</b></a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;图5 不同模型测试集&lt;i&gt;F&lt;/i&gt;1值的变化&lt;/b&gt;"><b>图5 不同模型测试集<i>F</i>1值的变化</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="142">


                                    <a id="bibliography_1" title=" MORI R D, FREDERIC B, HAKKANI-TUR D, et al.Spoken language understanding[J].IEEE Signal Processing Magazine, 2008, 25 (3) :50-58." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spoken language understanding">
                                        <b>[1]</b>
                                         MORI R D, FREDERIC B, HAKKANI-TUR D, et al.Spoken language understanding[J].IEEE Signal Processing Magazine, 2008, 25 (3) :50-58.
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_2" title=" HAFFNER P, TUR G, WRIGHT J H.Optimizing SVMs for complex call classification[C]//Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing.Washington D.C., USA:IEEE Press, 2003:632-635." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Optimizing SVMs for complex call classification">
                                        <b>[2]</b>
                                         HAFFNER P, TUR G, WRIGHT J H.Optimizing SVMs for complex call classification[C]//Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing.Washington D.C., USA:IEEE Press, 2003:632-635.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_3" title=" SARIKAYA R, HINTON G E, RAMABHADRAN B.Deep belief nets for natural language call-routing[C]//Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing.Washington D.C., USA:IEEE Press, 2011:5680-5683." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Belief Nets for Natural Language Call-Routing">
                                        <b>[3]</b>
                                         SARIKAYA R, HINTON G E, RAMABHADRAN B.Deep belief nets for natural language call-routing[C]//Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing.Washington D.C., USA:IEEE Press, 2011:5680-5683.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_4" title=" MCCALLUM A, FREITAG D, PEREIRA F.Maximum entropy Markov models for information extraction and segmentation[C]//Proceedings of the 17th International Conference on Machine Learning.San Francisco, USA:Morgan Kaufmann Publishers Inc., 2000:591-598." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Maximum entropy Markov models for information extraction and segmentation">
                                        <b>[4]</b>
                                         MCCALLUM A, FREITAG D, PEREIRA F.Maximum entropy Markov models for information extraction and segmentation[C]//Proceedings of the 17th International Conference on Machine Learning.San Francisco, USA:Morgan Kaufmann Publishers Inc., 2000:591-598.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_5" title=" RAYMOND C, RICCARDI G.Generative and discriminative algorithms for spoken language understanding[C]//Proceedings of International Speech Communication Association.Antwerp, Belgium:[s.n.], 2007:1605-1608." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generative and discriminative algorithms for spoken language understanding">
                                        <b>[5]</b>
                                         RAYMOND C, RICCARDI G.Generative and discriminative algorithms for spoken language understanding[C]//Proceedings of International Speech Communication Association.Antwerp, Belgium:[s.n.], 2007:1605-1608.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_6" title=" YAO Kaisheng, PENG Baolin, ZHANG Yu, et al.Spoken language understanding using long short-term memory neural networks[C]//Proceedings of Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2015:189-194." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spoken language understanding using long shortterm memory neural networks">
                                        <b>[6]</b>
                                         YAO Kaisheng, PENG Baolin, ZHANG Yu, et al.Spoken language understanding using long short-term memory neural networks[C]//Proceedings of Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2015:189-194.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_7" title=" MESNIL G, DAUPHIN Y, YAO Kaisheng, et al.Using recurrent neural networks for slot filling in spoken language understanding[J].IEEE/ACM Transactions on Audio Speech and Language Processing, 2015, 23 (3) :530-539." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM89CE857892F07D097EA96145D33832E1&amp;v=MjA3ODlLQT1OaWZJWTd1eGJhVEVxb2hOYmVsNURIdE56eDhVbjA1MFRuN21xV1kyZXJxWFI4K2VDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOOWl4THk2dw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         MESNIL G, DAUPHIN Y, YAO Kaisheng, et al.Using recurrent neural networks for slot filling in spoken language understanding[J].IEEE/ACM Transactions on Audio Speech and Language Processing, 2015, 23 (3) :530-539.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_8" title=" LIU Bing, LANE I.Recurrent neural network structured output prediction for spoken language understanding[C]//Proceedings of NIPS Workshop on Machine Learning for Spoken Language Understanding and Interactions.Montreal, Canada:[s.n.], 2015:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recurrent neural network structured output prediction for spoken language understanding">
                                        <b>[8]</b>
                                         LIU Bing, LANE I.Recurrent neural network structured output prediction for spoken language understanding[C]//Proceedings of NIPS Workshop on Machine Learning for Spoken Language Understanding and Interactions.Montreal, Canada:[s.n.], 2015:1-9.
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_9" title=" GUO D, TUR G, YIH W T, et al.Joint semantic utterance classification and slot filling with recursive neural networks[C]//Proceedings of Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2015:554-559." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint semantic utterance classification and slot filling with recursive neural networks">
                                        <b>[9]</b>
                                         GUO D, TUR G, YIH W T, et al.Joint semantic utterance classification and slot filling with recursive neural networks[C]//Proceedings of Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2015:554-559.
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_10" title=" XU Puyang, SARIKAYA R.Convolutional neural network based triangular CRF for joint intent detection and slot filling[C]//Proceedings of Automatic Speech Recognition and Understanding.Washington D.C., USA:IEEE Press, 2014:78-83." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural network based triangular CRF for joint intent detection and slot filling">
                                        <b>[10]</b>
                                         XU Puyang, SARIKAYA R.Convolutional neural network based triangular CRF for joint intent detection and slot filling[C]//Proceedings of Automatic Speech Recognition and Understanding.Washington D.C., USA:IEEE Press, 2014:78-83.
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_11" title=" MINKER W, BENNACEF S, GAUVAIN J.A stochastic case frame approach for natural language understanding[C]//Proceedings of International Conference on Spoken Language.Washington D.C., USA:IEEE Press, 1996:1013-1016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A stochastic case frame approach for natural language understanding">
                                        <b>[11]</b>
                                         MINKER W, BENNACEF S, GAUVAIN J.A stochastic case frame approach for natural language understanding[C]//Proceedings of International Conference on Spoken Language.Washington D.C., USA:IEEE Press, 1996:1013-1016.
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_12" title=" RAYMOND C, RICCARDI G.Generative and discriminative algorithms for spoken language understanding[C]//Proceedings of International Speech Communication Association.Antwerp, Belgium:[s.n.], 2007:1605-1608." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generative and discriminative algorithms for spoken language understanding">
                                        <b>[12]</b>
                                         RAYMOND C, RICCARDI G.Generative and discriminative algorithms for spoken language understanding[C]//Proceedings of International Speech Communication Association.Antwerp, Belgium:[s.n.], 2007:1605-1608.
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                     LAFFERTY J D, MCCALLUM A, PEREIRA F C N.Conditional random fields:probabilistic models for segmenting and labeling sequence data[C]//Proceedings of the 18th International Conference on Machine Learning.San Francisco, USA:Morgan Kaufmann Publishers Inc., 2001:282-289.</a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_14" title=" MESNIL G, HE Xiaodong, DENG Li, et al.Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding[C]//Proceedings of International Speech Communication Association.Lyon, France:[s.n.], 2013:3771-3775." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding">
                                        <b>[14]</b>
                                         MESNIL G, HE Xiaodong, DENG Li, et al.Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding[C]//Proceedings of International Speech Communication Association.Lyon, France:[s.n.], 2013:3771-3775.
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_15" title=" KOLBOEK M, TAN Zhenghua, JENSEN J.Speech enhancement using long short-term memory based recurrent neural networks for noise robust speaker verification[C]//Proceedings of IEEE Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2016:305-311." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Speech enhancement using Long Short-Term Memory based recurrent Neural Networks for noise robust Speaker Verification">
                                        <b>[15]</b>
                                         KOLBOEK M, TAN Zhenghua, JENSEN J.Speech enhancement using long short-term memory based recurrent neural networks for noise robust speaker verification[C]//Proceedings of IEEE Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2016:305-311.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     BENGIO Y, DUCHARME R, VINCENT P, et al.A neural probabilistic language model[J].Journal of Machine Learning Research, 2006, 3 (6) :1137-1155.</a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_17" title=" 吴旭康, 杨旭光, 陈园园, 等.主题联合词向量模型[J].计算机工程, 2018, 44 (2) :233-237." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201802040&amp;v=MzExODFyQ1VSTE9lWmVScEZDamhWci9BTHo3QmJiRzRIOW5Nclk5QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         吴旭康, 杨旭光, 陈园园, 等.主题联合词向量模型[J].计算机工程, 2018, 44 (2) :233-237.
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_18" title=" 余冲, 李晶, 孙旭东, 等.基于词嵌入与概率主题模型的社会媒体话题识别[J].计算机工程, 2017, 43 (12) :184-191." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201712034&amp;v=MTEwOTZWci9BTHo3QmJiRzRIOWJOclk5R1lJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScEZDamg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         余冲, 李晶, 孙旭东, 等.基于词嵌入与概率主题模型的社会媒体话题识别[J].计算机工程, 2017, 43 (12) :184-191.
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_19" title=" HEMPHILL C T, GODFREY J J, DODDINGTON G R.The ATIS spoken language systems pilot corpus[C]//Proceedings of the Darpa Speech and Natural Language Workshop.Hidden Valley, USA:[s.n.], 1990:96-101." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The ATIS spoken language systems pilot corpus">
                                        <b>[19]</b>
                                         HEMPHILL C T, GODFREY J J, DODDINGTON G R.The ATIS spoken language systems pilot corpus[C]//Proceedings of the Darpa Speech and Natural Language Workshop.Hidden Valley, USA:[s.n.], 1990:96-101.
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_20" title=" TUR G, HAKKANI-TUR D, HECK L.What is left to be understood in ATIS?[C]//Proceedings of Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2011:19-24." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=What is left to be understood in ATIS?">
                                        <b>[20]</b>
                                         TUR G, HAKKANI-TUR D, HECK L.What is left to be understood in ATIS?[C]//Proceedings of Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2011:19-24.
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_21" title=" RAMSHAW L A, MARCUS M P.Text chunking using transformation-based learning[J].Text Speech and Language Technology, 1995, 11:82-94." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Text chunking using transformation-based learning">
                                        <b>[21]</b>
                                         RAMSHAW L A, MARCUS M P.Text chunking using transformation-based learning[J].Text Speech and Language Technology, 1995, 11:82-94.
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_22" >
                                        <b>[22]</b>
                                     ELMAN J.Finding structure in time[J].Cognitive Science, 1990, 14 (2) :179-211.</a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_23" title=" PENG Baolin, YAO Kaisheng, JING Li, et al.Recurrent neural networks with external memory for spoken language understanding[C]//Proceeding of Natural Language Processing and Chinese Computing.Berlin, Germany:Springer, 2015:25-35." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recurrent neural networks with external memory for spoken language understanding">
                                        <b>[23]</b>
                                         PENG Baolin, YAO Kaisheng, JING Li, et al.Recurrent neural networks with external memory for spoken language understanding[C]//Proceeding of Natural Language Processing and Chinese Computing.Berlin, Germany:Springer, 2015:25-35.
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_24" title=" JORDAN M I.Serial order:A parallel distributed processing approach[J].Advances in Psychology, 1997, 121:471-495." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011702280759&amp;v=MzA0NDl5am1VTGpMSUZvUmFobz1OaWZPZmJLN0h0RE5xSTlIWnVNUEMza3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                         JORDAN M I.Serial order:A parallel distributed processing approach[J].Advances in Psychology, 1997, 121:471-495.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(07),237-241 DOI:10.19678/j.issn.1000-3428.0051291            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于标签分解的口语理解模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%AE%B8%E8%8E%B9%E8%8E%B9&amp;code=36812136&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">许莹莹</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E6%B5%A9&amp;code=09251991&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄浩</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%96%B0%E7%96%86%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0181515&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">新疆大学信息科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在双向长短时记忆网络的基础上, 提出一种用于口语理解的标签拆分策略, 并构建一个联合模型。通过将1次127种标签分类转换成3次独立的分类, 平衡ATIS数据集的标签。针对ATIS数据集资源较少的问题, 引入外部词向量以提升模型的分类性能。实验结果表明, 与循环神经网络及其变体结构相比, 该模型的<i>F</i>1值有显著提升, 最高可达95.63%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%A3%E8%AF%AD%E7%90%86%E8%A7%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">口语理解;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A7%BD%E5%A1%AB%E5%85%85&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">槽填充;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%8C%E5%90%91%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">双向长短时记忆网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%8D%E5%90%91%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">词向量;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%94%E5%90%88%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">联合模型;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    许莹莹 (1990—) , 女, 硕士研究生, 主研方向为自然语言处理、语音通信;;
                                </span>
                                <span>
                                    黄浩, 教授、博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-04-23</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61663044, 61365005);</span>
                    </p>
            </div>
                    <h1><b>Spoken Language Understanding Model Based on Label Decomposition</b></h1>
                    <h2>
                    <span>XU Yingying</span>
                    <span>HUANG Hao</span>
            </h2>
                    <h2>
                    <span>College of Information Science and Engineering, Xinjiang University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Based on the Bi-Long Short Term Memory (BiLSTM) , this paper proposes a label splitting strategy for Spoken Language Understanding (SLU) and constructs a joint model.The model convert a classification of 127 labels into 3 independent classifications to balance the labels in the ATIS database.Due to the scarcity of ATIS data, this paper introduces external word embedding to improve the classification performance of the model.Experimental results show that compared with the traditional recurrent neural network and its variants, the proposed joint model obtains significantly improvement in <i>F</i>1 value, which can be up to 95.63%.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Spoken%20Language%20Understanding%20(SLU)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Spoken Language Understanding (SLU) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=slot%20filling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">slot filling;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Bi-Long%20Short%20Term%20Memory%20(BiLSTM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Bi-Long Short Term Memory (BiLSTM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=word%20embedding&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">word embedding;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hibrid%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hibrid model;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-04-23</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="53" name="53" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="54">口语理解 (Spoken Language Understanding, SLU) <citation id="190" type="reference"><link href="142" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>是口语对话系统中的关键组成部分。SLU根据说话者的意图利用自然语言查询提取语义成分, 即SLU包括意图检测和槽填充2个任务。这2个任务通常是分开处理的。</p>
                </div>
                <div class="p1">
                    <p id="55">意图检测可以被看作语义层面的话语分类问题, 常采用支持向量机 (Support Vector Machine, SVM) <citation id="191" type="reference"><link href="144" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>和深度神经网络方法<citation id="192" type="reference"><link href="146" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>解决这类问题。槽填充可以被视为序列标注任务, 可采用最大熵马尔可夫模型 (Maximum Entropy Markov Model, MEMM) <citation id="193" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、条件随机场 (Conditional Random Field, CRF) <citation id="194" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>以及循环神经网络 (Recurrent Neural Network, RNN) <citation id="195" type="reference"><link href="152" rel="bibliography" /><link href="154" rel="bibliography" /><link href="156" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>完成这类任务。文献<citation id="196" type="reference">[<a class="sup">9</a>,<a class="sup">10</a>]</citation>提出意图检测和槽填充的联合模型, 用1个模型完整2个任务的训练和微调, 简化了SLU系统。</p>
                </div>
                <div class="p1">
                    <p id="56">本文研究用词汇语义来标记单词, 即语义槽填充, 它是SLU的关键任务之一。例如, 在句子“Book a flight from Beijing to New York”中, “Beijing”应该被标记为出发城市, 而“New York”则应该被标记为到达城市。解决SLU中的语义槽填充问题的传统方法包括2类模型:生成模型和判别模型, 如隐马尔可夫模型 (Hidden Markov Model, HMM) <citation id="197" type="reference"><link href="162" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和CRF<citation id="198" type="reference"><link href="164" rel="bibliography" /><link href="166" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>等。</p>
                </div>
                <div class="p1">
                    <p id="57">近年来, 神经网络已经被应用在语义槽填充任务中。文献<citation id="200" type="reference">[<a class="sup">14</a>,<a class="sup">15</a>]</citation>利用RNN和长短期记忆神经网络 (Long Short Term Memory, LSTM) <citation id="199" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation> 分析ATIS (Airline Travel Information System) 数据库。同时, 词向量<citation id="201" type="reference"><link href="172" rel="bibliography" /><link href="174" rel="bibliography" /><link href="176" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>将用于词表示的超高维稀疏向量投影到低维密集向量中, 已经被广泛应用于各种自然语言任务中。</p>
                </div>
                <div class="p1">
                    <p id="58">标准ATIS<citation id="202" type="reference"><link href="178" rel="bibliography" /><link href="180" rel="bibliography" /><sup>[<a class="sup">19</a>,<a class="sup">20</a>]</sup></citation>数据集具有以下特点:某些标签对应的样本较少, 导致预测效果较差;O标签较多, 分类器容易将不是O的标签标记为O标签。为此, 本文提出一种联合模型, 通过拆分标签来增加每个样本的监督信息。针对ATIS数据集样本稀少的问题, 增加预训练词向量, 引入外部语义信息并加以比较。</p>
                </div>
                <h3 id="59" name="59" class="anchor-tag">1 研究背景</h3>
                <h4 class="anchor-tag" id="60" name="60">1.1 SLU任务</h4>
                <div class="p1">
                    <p id="61">不同的SLU任务对应不同的语义表示形式。对于简单的SLU任务, 可以使用符合该任务语义结构的语义框架和语义槽直接建模输入。而对于较为复杂的SLU任务, 例如有很长短语的任务, 这种框架和语义槽方式就不再合适。IOB (Inside, Outside, Beginning) 标注策略<citation id="203" type="reference"><link href="182" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation> 用给定输入序列的状态序列标签来输出预测序列, 可以较好地解决这类问题。通常, 输出和输入序列已经对齐。在对齐中, 输入可以对应于空标签或单个标签。表1为SLU任务中的IOB标注示例, 标注名称简短化, O表示对SLU任务无用的词, B表示短语开始, I为短语的延续。</p>
                </div>
                <div class="area_img" id="62">
                    <p class="img_tit"><b>表1 IOB标注示例</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="62" border="1"><tr><td>Book</td><td>a</td><td>fight</td><td>from</td><td>Beijing</td><td>to</td><td>New</td><td>York</td></tr><tr><td><br />O</td><td>O</td><td>O</td><td>O</td><td>B-dpt</td><td>O</td><td>B-arv</td><td>I-arv</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="63">对于给定的一个长度为<i>T</i>的输入序列<i>x</i><mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>Τ</mi></msubsup></mrow></math></mathml>、对应的输出标签序列y<mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>Τ</mi></msubsup></mrow></math></mathml>以及一个对齐A, 后验概率p近似于:</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>y</mi><msubsup><mrow></mrow><mn>1</mn><mi>Τ</mi></msubsup><mo>, </mo><mi>x</mi><msubsup><mrow></mrow><mn>1</mn><mi>Τ</mi></msubsup><mo stretchy="false">) </mo><mo>≈</mo><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mi>p</mi></mstyle><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo><mi>x</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mi>k</mi></mrow><mrow><mi>t</mi><mo>+</mo><mi>k</mi></mrow></msubsup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">其中, k为上下文窗口大小, t为对齐索引中的序数。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68">1.2 基于<i>LSTM</i>的<i>SLU</i></h4>
                <div class="p1">
                    <p id="69">RNN擅于处理序列问题。图1为具有输入层<i>x</i>、隐藏层<i>h</i>和输出层<i>y</i>的RNN结构。 LSTM与RNN相似, 只是隐藏层更新被专用记忆单元取代, 因此其可以更好地发现和利用序列中的长距离依赖关系<citation id="204" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。与RNN<citation id="205" type="reference"><link href="184" rel="bibliography" /><link href="186" rel="bibliography" /><link href="188" rel="bibliography" /><sup>[<a class="sup">22</a>,<a class="sup">23</a>,<a class="sup">24</a>]</sup></citation>不同, LSTM使用具有线性激活功能的记忆单元来存储信息, 这在一定程度上避免了训练过程中梯度反向传播时发生的梯度爆炸和梯度消失问题。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201907038_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 简单RNN结构" src="Detail/GetImg?filename=images/JSJC201907038_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 简单RNN结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201907038_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="71">本文将LSTM应用于序列标注任务, 图2为单个LSTM存储单元。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201907038_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 LSTM单元内部结构" src="Detail/GetImg?filename=images/JSJC201907038_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 LSTM单元内部结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201907038_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="73">在序列标记任务中, 需要知道在预测时间点的过去和未来一段时间窗口内的信息, 本文采用双向LSTM (BiLSTM) , 可以有效地利用过去的信息 (通过前向隐层状态) 和未来的信息 (通过后向隐层状态) , 并使用随时间反向传播的梯度下降算法BPTT训练网络, 如图3所示。除了拼接所有时间步骤的前向和后向隐层状态之外, 还需要在序列的开头与结尾处进行特殊处理, 计算前向和后向LSTM网络隐层状态的方式与常规LSTM网络的方式一致。在编程实现BiLSTM算法时, 需要对整个句子做前向和后向计算, 并且需要在每个句子的前向/后向开始前将隐层状态重置为0, 通过批处理实现, 可以同时处理多个句子。</p>
                </div>
                <div class="area_img" id="74">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201907038_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 BiLSTM结构" src="Detail/GetImg?filename=images/JSJC201907038_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 BiLSTM结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201907038_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="75" name="75" class="anchor-tag">2 基于标签分解的SLU模型</h3>
                <h4 class="anchor-tag" id="76" name="76">2.1 标签分解</h4>
                <div class="p1">
                    <p id="77">本文采用的ATIS数据集共包含5 871个句子, 句子中每个词都有一个标签, 标签类别共127种。在数据集中所有标签统计结果如图4所示。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201907038_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 ATIS数据集标签统计" src="Detail/GetImg?filename=images/JSJC201907038_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 ATIS数据集标签统计</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201907038_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="79">从图4可以看出, 数据集中的标签非常不平衡, 且分为3种形式:</p>
                </div>
                <div class="p1">
                    <p id="80">1) 仅含有1种信息的标签, 即O标签。</p>
                </div>
                <div class="p1">
                    <p id="81">2) 含有2种信息的标签, 如B-airline_name、I-round_trip等。</p>
                </div>
                <div class="p1">
                    <p id="82">3) 含有3种信息的标签, 如B-fromloc.city_name、I-fromloc.city_name等。</p>
                </div>
                <div class="p1">
                    <p id="83">因此, 本文提出一种采用标签拆分策略, 对3种形式的标签分别进行标签拆分:</p>
                </div>
                <div class="p1">
                    <p id="84">1) 对于仅含有1种信息的标签, 即O标签, 拆分成“A”“NULL”“NULL”。</p>
                </div>
                <div class="p1">
                    <p id="85">2) 对于含有2种信息的标签, 拆分成“A”“NULL”“C”。</p>
                </div>
                <div class="p1">
                    <p id="86">3) 对于含有3种信息的标签, 拆分成“A”“B”“C”。</p>
                </div>
                <div class="p1">
                    <p id="87">则127种标签分类问题转换成3次独立的分类问题:</p>
                </div>
                <div class="p1">
                    <p id="88">1) 对于A类信息的分类, 是一个3类分类问题 (B, I, O) 。</p>
                </div>
                <div class="p1">
                    <p id="89">2) 对于B类信息的分类, 是一个10类分类问题 (fromloc, stoploc, arrive_date, arrive_time, depart_date, toloc, return_time, depart_time, return_date, NULL) 。</p>
                </div>
                <div class="p1">
                    <p id="90">3) 对于C类信息的分类, 是一个45类分类问题 (day_number, round_trip, state_name等) 。</p>
                </div>
                <div class="p1">
                    <p id="91">在原来的分类问题中, O标签占了相当大的比重, 剩余的126个标签独立与O标签竞争, 通过拆分标签, 变成了B、I标签与O标签竞争, 缓解了数据不平衡。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92">2.2 联合模型</h4>
                <div class="p1">
                    <p id="93">上述拆分策略存在一个问题, 即在测试阶段, 可能出现3次独立分类的结果无法组合成一个有效的标签, 如“O-arrive_date”就不存在于原来的标签集合中。因此, 本文提出一种联合训练模型来解决这一问题。</p>
                </div>
                <div class="p1">
                    <p id="94">BiLSTM模型对127种标签进行序列标注任务的过程如下:对于一个句子中的词, 其经过BiLSTM编码后的隐层状态为<b><i>h</i></b>, 则特征<b><i>h</i></b>对当前词做127种分类的损失定义如下:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mn>1</mn><mn>2</mn><mn>6</mn></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mi>y</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo>×</mo><mrow><mi>lg</mi></mrow><mtext> </mtext><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mspace width="0.25em" /><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><mi mathvariant="bold-italic">h</mi><mo>+</mo><mi mathvariant="bold-italic">b</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">联合模型将拆分标签后的3次分类模型与原来的1次127种分类模型联合训练, 最终依然使用127种分类模型来预测, 其损失函数定义如下:</p>
                </div>
                <div class="p1">
                    <p id="97"><i>L</i>oss=<i>α</i>×<i>loss</i>+<i>α</i><sub>1</sub>×<i>loss</i><sub>1</sub>+<i>α</i><sub>2</sub>×<i>loss</i><sub>2</sub>+<i>α</i><sub>3</sub>×<i>loss</i><sub>3</sub>      (4) </p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mn>2</mn></munderover><mo stretchy="false"> (</mo></mstyle><mi>y</mi><msubsup><mrow></mrow><mn>1</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>×</mo><mrow><mi>lg</mi></mrow><mtext> </mtext><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msubsup><mrow></mrow><mn>1</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mn>1</mn></msub><mi mathvariant="bold-italic">h</mi><mspace width="0.25em" /><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mn>9</mn></munderover><mo stretchy="false"> (</mo></mstyle><mi>y</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>×</mo><mrow><mi>lg</mi></mrow><mtext> </mtext><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msubsup><mrow></mrow><mn>2</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mn>2</mn></msub><mi mathvariant="bold-italic">h</mi><mspace width="0.25em" /><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><msub><mrow></mrow><mn>3</mn></msub><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mn>4</mn><mn>4</mn></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mi>y</mi><msubsup><mrow></mrow><mn>3</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>×</mo><mrow><mi>lg</mi></mrow><mtext> </mtext><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msubsup><mrow></mrow><mn>3</mn><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">y</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msub><mrow></mrow><mn>3</mn></msub><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mn>3</mn></msub><mi mathvariant="bold-italic">h</mi><mspace width="0.25em" /><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100">其中, <i>loss</i><sub>1</sub>、<i>loss</i><sub>2</sub>、<i>loss</i><sub>3</sub>分别表示3次独立分类的损失, <i>α</i>、<i>α</i><sub>1</sub>、<i>α</i><sub>2</sub>、<i>α</i><sub>3</sub> 用于调节各部分损失的权重, 且 <i>α</i>+<i>α</i><sub>1</sub>+<i>α</i><sub>2</sub>+<i>α</i><sub>3</sub>=1。</p>
                </div>
                <h3 id="101" name="101" class="anchor-tag">3 实验和结果分析</h3>
                <h4 class="anchor-tag" id="102" name="102">3.1 数据集和评价指标</h4>
                <div class="p1">
                    <p id="103">本文在SLU任务中的ATIS数据集上进行实验。数据集共包含5 871个句子, 切分成训练集 (3 983个句子) 、验证集 (995个句子) 和测试集 (893个句子) 。句子中每个词都有一个标签, 标签类别共127种。</p>
                </div>
                <div class="p1">
                    <p id="104">本文采用的评价指标为<i>F</i>1值, 计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mn>1</mn><mo>=</mo><mfrac><mrow><mn>2</mn><mo>×</mo><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>×</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac><mspace width="0.25em" /><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">其中, <i>Precision</i>为准确率, <i>Recall</i>为召回率。</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107">3.2 实验模型</h4>
                <div class="p1">
                    <p id="108">本文在ubuntu16.04LTS操作系统上基于tensorflow1.2搭建实验平台, 用于验证各种模型的有效性。其中, BiLSTM模型:前向和反向隐层节点数都设置为100, 随机初始化词嵌入维度为100;基于adam的批处理随机梯度下降算法优化模型:批大小为200, 学习率为0.02。此外, 为缓解过拟合问题, 本文引入dropout技术和L2正则化技术, dropout率为0.5, L2正则化系数为0.000 1。</p>
                </div>
                <div class="p1">
                    <p id="109">由于ATIS数据集比较小, 因此若使用随机初始化词向量的方式, 将无法得到较好的词向量, 模型的分类性能也会受到影响。因此, 本文引入外部词嵌入以提升模型的分类性能:</p>
                </div>
                <div class="p1">
                    <p id="110">1) BiLSTM+w2v300模型:在BiLSTM模型中添加谷歌word2vec预训练的词向量, 训练语料为谷歌新闻语料, 语料中包含约1 000亿个词, 预训练词嵌入词表大小为3 000 000, 维度为300。该模型首先在预训练词表中查找ATIS中的单词, 如果能够查找到, 则抽取其对应的词向量, 否则, 使用随机初始化方式生成词向量。</p>
                </div>
                <div class="p1">
                    <p id="111">2) BiLSTM+glv300模型:在BiLSTM模型中添加Glove模型预训练的词向量, 训练语料来自互联网爬取, 语料中包含约420亿个词, 预训练词嵌入词表大小为 1 917 494, 维度为300。该模型获取词向量方式与BiLSTM+w2v300模型相同。</p>
                </div>
                <div class="p1">
                    <p id="112">3) BiLSTM+glv100模型:在BiLSTM模型中添加Glove模型预训练的词向量, 训练语料来自维基百科和千兆词, 语料中包含约60亿个词, 预训练词嵌入词表大小为400 000, 维度为100。该模型获取词向量方式与BiLSTM+w2v300模型相同。</p>
                </div>
                <h4 class="anchor-tag" id="113" name="113">3.3 结果分析</h4>
                <div class="p1">
                    <p id="114">实验结果如表2所示, 其中, split代表引入标签拆分策略。</p>
                </div>
                <div class="area_img" id="115">
                    <p class="img_tit"><b>表2 不同模型<i>F</i>1值的对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"> %</p>
                    <table id="115" border="1"><tr><td><br />模型</td><td><i>F</i>1值</td></tr><tr><td><br />CRF<sup>[5]</sup></td><td>92.94</td></tr><tr><td><br />Jordan-RNN<sup>[7]</sup></td><td>93.13</td></tr><tr><td><br />Elman-RNN<sup>[7]</sup></td><td>94.24</td></tr><tr><td><br />LSTM<sup>[6]</sup></td><td>94.54</td></tr><tr><td><br />BiLSTM</td><td>94.95</td></tr><tr><td><br />BiLSTM+w2v300</td><td>94.86</td></tr><tr><td><br />BiLSTM+glv300</td><td>94.82</td></tr><tr><td><br />BiLSTM+glv100</td><td>95.14</td></tr><tr><td><br />BiLSTM+split</td><td>95.36</td></tr><tr><td><br />BiLSTM+glv100+split</td><td><b>95.63</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="116">从表2可以看出:</p>
                </div>
                <div class="p1">
                    <p id="117">1) 通过比较BiLSTM和BiLSTM+glv100, 以及BiLSTM+split和BiLSTM+glv100+split, 结果表明引入外来预训练的词向量, 可以有效提高SLU的性能。这是因为模型通过外部词向量获取了外部语义信息。</p>
                </div>
                <div class="p1">
                    <p id="118">2) 通过对比BiLSTM+w2v300、BiLSTM+glv300、BiLSTM, 发现BiLSTM的效果更好。这是因为嵌入的外来词向量维度较大, 导致模型参数过多, 从而产生副作用。</p>
                </div>
                <div class="p1">
                    <p id="119">3) 通过比较BiLSTM和BiLSTM+split, 以及BiLSTM+glv100和BiLSTM+glv100+split, 结果表明拆分标签能明显提升SLU的性能。这是因为拆分标签的策略缓解了数据的不平衡。从联合模型的角度解释, 则是通过添加额外监督 (3个独立的分类监督) , 提升了原来的127种分类的效果。</p>
                </div>
                <div class="p1">
                    <p id="120">BiLSTM和BiLSTM+split以及BiLSTM+glv100和BiLSTM+glv100+split测试集<i>F</i>1值随训练迭代轮数变化的曲线如图5所示。如图5 (a) 所示, 对比BiLSTM和BiLSTM+split的训练过程, 可以看到, 虽然两者曲线都有起伏, 但BiLSTM+split始终在BiLSTM曲线上方, 即达到相同的<i>F</i>1值, 前者需要更少的跌代轮数, 说明BiLSTM+split模型不光最终效果更好, 而且收敛更快, 不需要增加迭代轮数来提升效果。如图5 (b) 所示, 对比BiLSTM+glv100和BiLSTM+glv100+split的训练过程, 发现BiLSTM+glv100+split始终在BiLSTM+glv100曲线上方, 前者在第10轮时<i>F</i>1值已经突破了94%, 而后者用了18轮才达到这一结果, 且前18轮两者差异明显, 进一步证明标签拆分策略能提升模型收敛速度。</p>
                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201907038_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同模型测试集F1值的变化" src="Detail/GetImg?filename=images/JSJC201907038_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 不同模型测试集<i>F</i>1值的变化</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201907038_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="122">可以看到4个模型的<i>F</i>1值在上升期过后, 都有不同程度的波动甚至下降, 但是不论取哪一轮的测试结果, 经过标签拆分的模型都表现更好。</p>
                </div>
                <div class="p1">
                    <p id="123">综合以上结论, 在BiLSTM和BiLSTM+glv100模型基础上引入标签拆分策略并联合训练模型可以提高模型收敛速度。</p>
                </div>
                <h3 id="124" name="124" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="125">本文提出一种标签拆分策略, 将1次127种标签分类转换成3次独立的分类, 并将其应用于BiLSTM, 组建联合模型。针对ATIS数据集资源较少的问题, 引入外部词嵌入以提升模型的分类性能。通过在ATIS数据集上进行对比实验, 结果表明, 标签拆分策略能有效提升模型收敛速度, 且模型通过外部词向量可获取外部语义信息, 提升模型的分类性能。下一步将引入注意力机制或CRF, 提升模型的分类性能。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="142">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spoken language understanding">

                                <b>[1]</b> MORI R D, FREDERIC B, HAKKANI-TUR D, et al.Spoken language understanding[J].IEEE Signal Processing Magazine, 2008, 25 (3) :50-58.
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Optimizing SVMs for complex call classification">

                                <b>[2]</b> HAFFNER P, TUR G, WRIGHT J H.Optimizing SVMs for complex call classification[C]//Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing.Washington D.C., USA:IEEE Press, 2003:632-635.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Belief Nets for Natural Language Call-Routing">

                                <b>[3]</b> SARIKAYA R, HINTON G E, RAMABHADRAN B.Deep belief nets for natural language call-routing[C]//Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing.Washington D.C., USA:IEEE Press, 2011:5680-5683.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Maximum entropy Markov models for information extraction and segmentation">

                                <b>[4]</b> MCCALLUM A, FREITAG D, PEREIRA F.Maximum entropy Markov models for information extraction and segmentation[C]//Proceedings of the 17th International Conference on Machine Learning.San Francisco, USA:Morgan Kaufmann Publishers Inc., 2000:591-598.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generative and discriminative algorithms for spoken language understanding">

                                <b>[5]</b> RAYMOND C, RICCARDI G.Generative and discriminative algorithms for spoken language understanding[C]//Proceedings of International Speech Communication Association.Antwerp, Belgium:[s.n.], 2007:1605-1608.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spoken language understanding using long shortterm memory neural networks">

                                <b>[6]</b> YAO Kaisheng, PENG Baolin, ZHANG Yu, et al.Spoken language understanding using long short-term memory neural networks[C]//Proceedings of Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2015:189-194.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM89CE857892F07D097EA96145D33832E1&amp;v=MDMzMTBBPU5pZklZN3V4YmFURXFvaE5iZWw1REh0Tnp4OFVuMDUwVG43bXFXWTJlcnFYUjgrZUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU45aXhMeTZ3Sw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> MESNIL G, DAUPHIN Y, YAO Kaisheng, et al.Using recurrent neural networks for slot filling in spoken language understanding[J].IEEE/ACM Transactions on Audio Speech and Language Processing, 2015, 23 (3) :530-539.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recurrent neural network structured output prediction for spoken language understanding">

                                <b>[8]</b> LIU Bing, LANE I.Recurrent neural network structured output prediction for spoken language understanding[C]//Proceedings of NIPS Workshop on Machine Learning for Spoken Language Understanding and Interactions.Montreal, Canada:[s.n.], 2015:1-9.
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint semantic utterance classification and slot filling with recursive neural networks">

                                <b>[9]</b> GUO D, TUR G, YIH W T, et al.Joint semantic utterance classification and slot filling with recursive neural networks[C]//Proceedings of Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2015:554-559.
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural network based triangular CRF for joint intent detection and slot filling">

                                <b>[10]</b> XU Puyang, SARIKAYA R.Convolutional neural network based triangular CRF for joint intent detection and slot filling[C]//Proceedings of Automatic Speech Recognition and Understanding.Washington D.C., USA:IEEE Press, 2014:78-83.
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A stochastic case frame approach for natural language understanding">

                                <b>[11]</b> MINKER W, BENNACEF S, GAUVAIN J.A stochastic case frame approach for natural language understanding[C]//Proceedings of International Conference on Spoken Language.Washington D.C., USA:IEEE Press, 1996:1013-1016.
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generative and discriminative algorithms for spoken language understanding">

                                <b>[12]</b> RAYMOND C, RICCARDI G.Generative and discriminative algorithms for spoken language understanding[C]//Proceedings of International Speech Communication Association.Antwerp, Belgium:[s.n.], 2007:1605-1608.
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                 LAFFERTY J D, MCCALLUM A, PEREIRA F C N.Conditional random fields:probabilistic models for segmenting and labeling sequence data[C]//Proceedings of the 18th International Conference on Machine Learning.San Francisco, USA:Morgan Kaufmann Publishers Inc., 2001:282-289.
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding">

                                <b>[14]</b> MESNIL G, HE Xiaodong, DENG Li, et al.Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding[C]//Proceedings of International Speech Communication Association.Lyon, France:[s.n.], 2013:3771-3775.
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Speech enhancement using Long Short-Term Memory based recurrent Neural Networks for noise robust Speaker Verification">

                                <b>[15]</b> KOLBOEK M, TAN Zhenghua, JENSEN J.Speech enhancement using long short-term memory based recurrent neural networks for noise robust speaker verification[C]//Proceedings of IEEE Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2016:305-311.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 BENGIO Y, DUCHARME R, VINCENT P, et al.A neural probabilistic language model[J].Journal of Machine Learning Research, 2006, 3 (6) :1137-1155.
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201802040&amp;v=MjE1ODBGckNVUkxPZVplUnBGQ2poVnIvQUx6N0JiYkc0SDluTXJZOUJaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 吴旭康, 杨旭光, 陈园园, 等.主题联合词向量模型[J].计算机工程, 2018, 44 (2) :233-237.
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201712034&amp;v=MTgyMTMzenFxQnRHRnJDVVJMT2VaZVJwRkNqaFZyL0FMejdCYmJHNEg5Yk5yWTlHWUlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 余冲, 李晶, 孙旭东, 等.基于词嵌入与概率主题模型的社会媒体话题识别[J].计算机工程, 2017, 43 (12) :184-191.
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The ATIS spoken language systems pilot corpus">

                                <b>[19]</b> HEMPHILL C T, GODFREY J J, DODDINGTON G R.The ATIS spoken language systems pilot corpus[C]//Proceedings of the Darpa Speech and Natural Language Workshop.Hidden Valley, USA:[s.n.], 1990:96-101.
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=What is left to be understood in ATIS?">

                                <b>[20]</b> TUR G, HAKKANI-TUR D, HECK L.What is left to be understood in ATIS?[C]//Proceedings of Spoken Language Technology Workshop.Washington D.C., USA:IEEE Press, 2011:19-24.
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Text chunking using transformation-based learning">

                                <b>[21]</b> RAMSHAW L A, MARCUS M P.Text chunking using transformation-based learning[J].Text Speech and Language Technology, 1995, 11:82-94.
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_22" >
                                    <b>[22]</b>
                                 ELMAN J.Finding structure in time[J].Cognitive Science, 1990, 14 (2) :179-211.
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recurrent neural networks with external memory for spoken language understanding">

                                <b>[23]</b> PENG Baolin, YAO Kaisheng, JING Li, et al.Recurrent neural networks with external memory for spoken language understanding[C]//Proceeding of Natural Language Processing and Chinese Computing.Berlin, Germany:Springer, 2015:25-35.
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011702280759&amp;v=MDk0NTdiSzdIdEROcUk5SFp1TVBDM2t3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGpMSUZvUmFobz1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b> JORDAN M I.Serial order:A parallel distributed processing approach[J].Advances in Psychology, 1997, 121:471-495.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201907038" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201907038&amp;v=MTYxMDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJwRkNqaFZyL0FMejdCYmJHNEg5ak1xSTlHYklRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9wS0dTT3lHTXAzN1YxWUJuaTVBbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
