<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130639941525000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201903043%26RESULT%3d1%26SIGN%3d5ak9asnR5wgsDYh%252b7BeDRvMP%252fYk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903043&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903043&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903043&amp;v=MjgxOTlBTHo3QmJiRzRIOWpNckk5Qlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N2xXN3I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#45" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#51" data-title="1 检测算法具体步骤 ">1 检测算法具体步骤</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="1.1 图像质量检测与校正">1.1 图像质量检测与校正</a></li>
                                                <li><a href="#65" data-title="1.2 改进的眨眼检测">1.2 改进的眨眼检测</a></li>
                                                <li><a href="#93" data-title="1.3 唇部动作检测">1.3 唇部动作检测</a></li>
                                                <li><a href="#96" data-title="1.4 背景检测和随机组合动作指令">1.4 背景检测和随机组合动作指令</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#107" data-title="2 实验结果与分析 ">2 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#109" data-title="2.1 样本库建立与参数设置">2.1 样本库建立与参数设置</a></li>
                                                <li><a href="#114" data-title="2.2 结果分析">2.2 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#121" data-title="3 结束语 ">3 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="&lt;b&gt;图1 活体检测整体流程&lt;/b&gt;"><b>图1 活体检测整体流程</b></a></li>
                                                <li><a href="#64" data-title="&lt;b&gt;图2 图像质量检测与校正效果&lt;/b&gt;"><b>图2 图像质量检测与校正效果</b></a></li>
                                                <li><a href="#68" data-title="&lt;b&gt;图3 人脸对齐后检测出的眼部区域&lt;/b&gt;"><b>图3 人脸对齐后检测出的眼部区域</b></a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;图4 不同阈值下滤波后的眼部图像&lt;/b&gt;"><b>图4 不同阈值下滤波后的眼部图像</b></a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;图5 唇部动作检测效果&lt;/b&gt;"><b>图5 唇部动作检测效果</b></a></li>
                                                <li><a href="#100" data-title="&lt;b&gt;图6 背景检测效果&lt;/b&gt;"><b>图6 背景检测效果</b></a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;图7 随机组合动作系统指示界面&lt;/b&gt;"><b>图7 随机组合动作系统指示界面</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;图8 自建样本库部分实验人脸展示&lt;/b&gt;"><b>图8 自建样本库部分实验人脸展示</b></a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;图9 CASIA-FASD真实人脸和伪装人脸样例&lt;/b&gt;"><b>图9 CASIA-FASD真实人脸和伪装人脸样例</b></a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;图10 本文算法各种动作检测的准确率&lt;/b&gt;"><b>图10 本文算法各种动作检测的准确率</b></a></li>
                                                <li><a href="#117" data-title="&lt;b&gt;图11 不同方法roc特征曲线对比&lt;/b&gt;"><b>图11 不同方法roc特征曲线对比</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;表1 不同方法的检测效果对比&lt;/b&gt;"><b>表1 不同方法的检测效果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" XU Y, LI Z, YANG J, et al.A survey of dictionary learning algorithms for face recognition[J].IEEE Access, 2017, 5:8502-8514." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Survey of Dictionary Learning Algorithms for Face Recognition">
                                        <b>[1]</b>
                                         XU Y, LI Z, YANG J, et al.A survey of dictionary learning algorithms for face recognition[J].IEEE Access, 2017, 5:8502-8514.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" WU L, XU Y, XU X, et al.A face liveness detection scheme to combining static and dynamic features[M].Berlin, Germany:Springer, 2016:628-636." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A face liveness detection scheme to combining static and dynamic features">
                                        <b>[2]</b>
                                         WU L, XU Y, XU X, et al.A face liveness detection scheme to combining static and dynamic features[M].Berlin, Germany:Springer, 2016:628-636.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" MOHAN K, CHANDRASEKHAR P, JILANI S A K.A combined HOG-LPQ with Fuz-SVM classifier for object face liveness detection[C]//Proceedings of International Conference on IoT in Social, Mobile, Analytics and Cloud.Washington D.C., USA:IEEE Press, 2017:531-537." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A combined HOG-LPQ with Fuz-SVM classifier for Object face Liveness Detection">
                                        <b>[3]</b>
                                         MOHAN K, CHANDRASEKHAR P, JILANI S A K.A combined HOG-LPQ with Fuz-SVM classifier for object face liveness detection[C]//Proceedings of International Conference on IoT in Social, Mobile, Analytics and Cloud.Washington D.C., USA:IEEE Press, 2017:531-537.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" YEH C H, CHANG H H.Face liveness detection with feature discrimination between sharpness and blurriness[C]//Proceedings of the 15th IAPR International Conference on Machine Vision Applications.Washington D.C., USA:IEEE Press, 2017:398-401." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face liveness detection with feature discrimination between sharpness and blurriness">
                                        <b>[4]</b>
                                         YEH C H, CHANG H H.Face liveness detection with feature discrimination between sharpness and blurriness[C]//Proceedings of the 15th IAPR International Conference on Machine Vision Applications.Washington D.C., USA:IEEE Press, 2017:398-401.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" SINGH M, ARORA A S.A robust anti-spoofing technique for face liveness detection with morphological operations[J].Optik-International Journal for Light and Electron Optics, 2017, 139 (4) :347-354." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A robust anti-spoofing technique for face liveness detection with morphological operations">
                                        <b>[5]</b>
                                         SINGH M, ARORA A S.A robust anti-spoofing technique for face liveness detection with morphological operations[J].Optik-International Journal for Light and Electron Optics, 2017, 139 (4) :347-354.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" LAKSHMINARAYANA N N, NARAYAN N, NAPP N, et al.A discriminative spatio-temporal mapping of face for liveness detection[C]//Proceedings of IEEE International Conference on Identity, Security and Behavior Analysis.Washington D.C., USA:IEEE Press, 2017:1-7." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A discriminative spatio-temporal mapping of face for liveness detection">
                                        <b>[6]</b>
                                         LAKSHMINARAYANA N N, NARAYAN N, NAPP N, et al.A discriminative spatio-temporal mapping of face for liveness detection[C]//Proceedings of IEEE International Conference on Identity, Security and Behavior Analysis.Washington D.C., USA:IEEE Press, 2017:1-7.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 任玉强, 田国栋, 周祥东, 等.高安全性人脸识别系统中的唇语识别算法研究[J].计算机应用研究, 2017, 34 (4) :1221-1225." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201704061&amp;v=Mjk2MTVxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N2xXN3JBTHo3U1pMRzRIOWJNcTQ5RFpZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         任玉强, 田国栋, 周祥东, 等.高安全性人脸识别系统中的唇语识别算法研究[J].计算机应用研究, 2017, 34 (4) :1221-1225.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" WANG Y, HAO X, HOU Y, et al.A new multispectral method for face liveness detection[C]//Proceedings of IAPR Asian Conference on Pattern Recognition.Washington D.C., USA:IEEE Press, 2013:922-926." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A New Multispectral Method for Face Liveness Detection">
                                        <b>[8]</b>
                                         WANG Y, HAO X, HOU Y, et al.A new multispectral method for face liveness detection[C]//Proceedings of IAPR Asian Conference on Pattern Recognition.Washington D.C., USA:IEEE Press, 2013:922-926.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" BOULKENAFET Z, KOMULAINEN J, HADID A.Face spoofing detection using colour texture analysis[J].IEEE Transactions on Information Forensics and Security, 2016, 11 (8) :1818-1830." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face spoofing detection using colour texture analysis">
                                        <b>[9]</b>
                                         BOULKENAFET Z, KOMULAINEN J, HADID A.Face spoofing detection using colour texture analysis[J].IEEE Transactions on Information Forensics and Security, 2016, 11 (8) :1818-1830.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" RAGHAVENDRA R, RAJA K B, VENKATESH S, et al.On the vulnerability of extended multispectral face recognition systems towards presentation attacks[C]//Proceedings of IEEE International Conference on Identity, Security and Behavior Analysis.Washington D.C., USA:IEEE Press, 2017:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the vulnerability of extended multispectral face recognition systems towards presentation attacks">
                                        <b>[10]</b>
                                         RAGHAVENDRA R, RAJA K B, VENKATESH S, et al.On the vulnerability of extended multispectral face recognition systems towards presentation attacks[C]//Proceedings of IEEE International Conference on Identity, Security and Behavior Analysis.Washington D.C., USA:IEEE Press, 2017:1-8.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" PAN G, SUN L, WU Z, et al.Eyeblink-based anti-spoofing in face recognition from a generic webcamera[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2007:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Eyeblink-based Anti-spoofing in Face Recognition from a Generic Webcamera">
                                        <b>[11]</b>
                                         PAN G, SUN L, WU Z, et al.Eyeblink-based anti-spoofing in face recognition from a generic webcamera[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2007:1-8.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" FENG L, PO L M, LI Y, et al.Face liveness detection using shearlet-based feature descriptors[EB/OL].[2018-01-05].http://www.ee.cityu.edu.hk/～lmpo/publications/2017_JEI_face_liveness.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face liveness detection using shearlet-based feature descriptors">
                                        <b>[12]</b>
                                         FENG L, PO L M, LI Y, et al.Face liveness detection using shearlet-based feature descriptors[EB/OL].[2018-01-05].http://www.ee.cityu.edu.hk/～lmpo/publications/2017_JEI_face_liveness.pdf.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" SINGH A K, JOSHI P, NANDI G C.Face recognition with liveness detection using eye and mouth movement[C]//Proceedings of International Conference on Signal Propagation and Computer Technology.Washington D.C., USA:IEEE Press, 2014:592-597." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face recognition with liveness detection using eye and mouth movement">
                                        <b>[13]</b>
                                         SINGH A K, JOSHI P, NANDI G C.Face recognition with liveness detection using eye and mouth movement[C]//Proceedings of International Conference on Signal Propagation and Computer Technology.Washington D.C., USA:IEEE Press, 2014:592-597.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" 曹瑜, 涂玲, 毋立芳.身份认证中灰度共生矩阵和小波分析的活体人脸检测算法[J].信号处理, 2014, 30 (7) :830-835." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXCN201407012&amp;v=MjM4MzdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N2xXN3JBUFRYSVlMRzRIOVhNcUk5RVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         曹瑜, 涂玲, 毋立芳.身份认证中灰度共生矩阵和小波分析的活体人脸检测算法[J].信号处理, 2014, 30 (7) :830-835.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" MEI L, YANG D, FENG Z, et al.WLD-TOP based algorithm against face spoofing attacks[M].Berlin, Germany:Springer, 2015:6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=WLD-TOP based algorithm against face spoofing attacks">
                                        <b>[15]</b>
                                         MEI L, YANG D, FENG Z, et al.WLD-TOP based algorithm against face spoofing attacks[M].Berlin, Germany:Springer, 2015:6.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" WILD P, RADU P, CHEN L, et al.Robust multimodal face and fingerprint fusion in the presence of spoofing attacks[J].Pattern Recognition, 2016, 50 (C) :17-25." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE947BDE1F9AE65336828BD9DC0AB5E74&amp;v=MDM3NjA1TjVod3JpM3hhQT1OaWZPZmNheEd0YSsyL3BFRXVKK2VYbzh6QlVWNGoxMU9ndnIyR0UxQ01DUk1MMmJDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         WILD P, RADU P, CHEN L, et al.Robust multimodal face and fingerprint fusion in the presence of spoofing attacks[J].Pattern Recognition, 2016, 50 (C) :17-25.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" NOBLE F K.Comparison of OpenCV’s feature detectors and feature matchers[C]//Proceedings of International Conference on Mechatronics and Machine Vision in Practice.Washington D.C., USA:IEEE Press, 2016:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Comparison of OpenCV&amp;#39;&amp;#39;s feature detectors and feature matchers">
                                        <b>[17]</b>
                                         NOBLE F K.Comparison of OpenCV’s feature detectors and feature matchers[C]//Proceedings of International Conference on Mechatronics and Machine Vision in Practice.Washington D.C., USA:IEEE Press, 2016:1-6.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" REN S, CAO X, WEI Y, et al.Face alignment at 3 000 FPS via regressing local binary features[C]//Proceedings of International Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2014:1685-1692." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face Alignment at 3000 FPS via Regressing Local Binary Features">
                                        <b>[18]</b>
                                         REN S, CAO X, WEI Y, et al.Face alignment at 3 000 FPS via regressing local binary features[C]//Proceedings of International Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2014:1685-1692.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" ZHANG Z, YAN J, LIU S, et al.A face anti-spoofing database with diverse attacks[C]//Proceedings of the 5th IAPR International Conference on Biometrics.Washington D.C., USA:IEEE Press, 2012:26-31." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A face anti-spoofing database with diverse attacks">
                                        <b>[19]</b>
                                         ZHANG Z, YAN J, LIU S, et al.A face anti-spoofing database with diverse attacks[C]//Proceedings of the 5th IAPR International Conference on Biometrics.Washington D.C., USA:IEEE Press, 2012:26-31.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" LIAO S, JAIN A K, LI S Z.A fast and accurate unconstrained face detector[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (2) :211-223." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A fast and accurate unconstrained face detector">
                                        <b>[20]</b>
                                         LIAO S, JAIN A K, LI S Z.A fast and accurate unconstrained face detector[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (2) :211-223.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" AKBULUT Y, SENGUR A, BUDAK U, et al.Deep learning based face liveness detection in videos[C]//Proceedings of International Artificial Intelligence and Data Processing Symposium.Washington D.C., USA:IEEE Press, 2017:1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep learning based face liveness detection in videos">
                                        <b>[21]</b>
                                         AKBULUT Y, SENGUR A, BUDAK U, et al.Deep learning based face liveness detection in videos[C]//Proceedings of International Artificial Intelligence and Data Processing Symposium.Washington D.C., USA:IEEE Press, 2017:1-4.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(03),256-261 DOI:10.19678/j.issn.1000-3428.0050353            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>面向VTM的交互式活体检测算法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E9%92%B0%E9%94%A1&amp;code=38808469&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马钰锡</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B0%AD%E5%8A%B1&amp;code=06295823&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">谭励</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%91%A3%E6%97%AD&amp;code=38808470&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">董旭</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BA%8E%E9%87%8D%E9%87%8D&amp;code=06296625&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">于重重</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E5%B7%A5%E5%95%86%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2%E9%A3%9F%E5%93%81%E5%AE%89%E5%85%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8C%97%E4%BA%AC%E5%B8%82%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0163176&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京工商大学计算机与信息工程学院食品安全大数据技术北京市重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为提升远程视频柜员机人脸识别登录系统的识别率和安全性, 将改进的眨眼检测、背景检测和随机组合动作指令相结合, 提出一种交互式活体检测算法。基于OpenCV级联分类器人脸检测和局部二值特征人脸对齐算法, 结合坐标比例和眼球色素变化改进眨眼检测。利用背景检测和随机组合动作指令抵御动态视频攻击, 加入图像质量检测与校正功能, 使系统在弱光、歪斜等环境影响下对活体人脸检测有较好的检测效果。在活体人脸数据库CASIA-FASD和自建样本库上进行实验, 结果表明, 该算法识别率达到97.67%, 与多光谱、卷积神经网络等检测算法相比性能有明显的提升。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B4%BB%E4%BD%93%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">活体检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人脸识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9C%A8%E7%9C%BC%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">眨眼检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%8C%E6%99%AF%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">背景检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%80%E9%83%A8%E4%BA%8C%E5%80%BC%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">局部二值特征;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    马钰锡 (1995—) , 男, 硕士研究生, 主研方向为计算机视觉、人工智能;;
                                </span>
                                <span>
                                    谭励, 教授、博士;;
                                </span>
                                <span>
                                    董旭, 硕士;;
                                </span>
                                <span>
                                    于重重, 教授、博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-30</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61702020);</span>
                                <span>北京市自然科学基金 (4172013);</span>
                    </p>
            </div>
                    <h1><b>Interactive Liveness Detection Algorithm for VTM</b></h1>
                    <h2>
                    <span>MA Yuxi</span>
                    <span>TAN Li</span>
                    <span>DONG Xu</span>
                    <span>YU Chongchong</span>
            </h2>
                    <h2>
                    <span>Beijing Key Laboratory of Big Data Technology for Food Safety, School of Computer and Information Engineering, Beijing Technology and Business University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to improve the recognition rate and security of the Video Teller Machine (VTM) face recognition login system, an interactive liveness detection algorithm that combines improved blink detection, background detection and random combined action instructions is proposed.Based on the OpenCV cascade classifier face detection and Local Binary Feature (LBF) face alignment algorithm, combining the coordinate proportion and the eye pigment change, the detection method is improved.Uses the background detection and the random combination action instruction to resist the dynamic video attack.Making use of the image quality detection and correction function, the system in weak light, skew and the other environmental condition has a good performance as well.Experiments are carried out on liveness face database CASIA-FASD and self-built sample library, the result shows that the recognition rate reaches 97.67%, which is obviously improved than multispectral, convolutional neural network, and the other existing detection algorithms.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=liveness%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">liveness detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=face%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">face recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=blink%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">blink detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=background%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">background detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Local%20Binary%20Feature%20(LBF)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Local Binary Feature (LBF) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-30</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="45" name="45" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="46">随着人脸识别技术日趋成熟, 其商业化应用愈加广泛。然而, 人脸极易通过照片、视频、人脸模型等方式进行复制, 假冒合法用户欺骗系统, 从而对远程视频柜员机 (Video Teller Machine, VTM) 人脸识别与认证系统的安全构成严重威胁<citation id="123" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。因此, 设计一种面向VTM的活体检测算法, 在VTM的人脸识别身份认证中加入活体检测技术非常必要。</p>
                </div>
                <div class="p1">
                    <p id="47">活体检测是一项判断提交的生物特征是否来自有生命个体的技术, 主要包括基于图像微纹理的方法<citation id="127" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>、基于多光谱技术的方法<citation id="128" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>和基于交互式面部动作检测的方法<citation id="124" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。基于图像微纹理的方法提取的特征维数大, 计算复杂度较高<citation id="125" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。基于多光谱技术的方法需要特殊的采集设备, 用户体验较差<citation id="126" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。因此, 目前投入市场应用的活体检测技术大多是基于交互式面部动作指令的判别, 例如支付宝、滴滴出行、百度文库等“刷脸登录”的方法, 都是以用户配合完成眨眼、摇头等动作实现活体检测。</p>
                </div>
                <div class="p1">
                    <p id="48">文献<citation id="129" type="reference">[<a class="sup">11</a>]</citation>通过视频流捕捉2个顺序且独立的脸部帧, 使用隐马尔可夫模型生成特征, 分析两帧中的眨眼变化来抵御攻击。文献<citation id="130" type="reference">[<a class="sup">12</a>]</citation>提出一种基于纹理分析和运动检测的框架, 利用堆叠的自动编码器和softmax分类器相连, 检测脸部的活跃度来验证活体。文献<citation id="131" type="reference">[<a class="sup">13</a>]</citation>通过harr分类器检测脸部宏观特征, 并分割出眼睛和嘴巴的区域, 利用主成分分析 (Principal Component Analysis, PCA) 方法对眼睛和嘴巴的变化进行活体检测。</p>
                </div>
                <div class="p1">
                    <p id="49">目前, 人脸识别系统在现实应用场景中主要面临二次翻拍照片人脸攻击、二次翻拍视频人脸攻击和三维人脸模型攻击3种攻击类型<citation id="132" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。现有的交互式活体检测方法并不能完全抵御这3种攻击。例如, 可以通过照片折叠、翻转等角度变化模拟指定动作, 或提前录制相应的视频进行认证, 达到欺骗系统、成功登录的目的。此外, 检测过程容易受到检测环境的限制, 例如, 光照强度、拍摄角度等, 均会给检测结果和系统性能带来一定的影响<citation id="133" type="reference"><link href="31" rel="bibliography" /><link href="33" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="50">针对上述方案存在的缺陷, 本文提出一种面向VTM改进的交互式活体检测算法, 通过眼球色素差与眼部特征点变化相结合的认证方法改进眨眼检测, 抵御静态照片的模拟攻击。采用随机组合动作指令和背景检测的方法, 抵御视频和3D模具的模拟攻击。加入图像质量检测与校正过程, 消除检测环境对结果的影响。在实现OpenCV级联分类器人脸检测<citation id="134" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>和基于局部二值特征 (Local Binary Feature, LBF) 人脸对齐<citation id="135" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>的基础上, 提高活体检测的健壮性。在公开活体人脸数据库CASIA-FASD<citation id="136" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>和自建样本库上进行实验, 以验证该算法的准确性和有效性。</p>
                </div>
                <h3 id="51" name="51" class="anchor-tag">1 检测算法具体步骤</h3>
                <div class="p1">
                    <p id="52">改进的交互式活体检测算法包括图像质量检测与校正、眨眼检测、唇部动作检测、背景检测等环节, 整体流程如图1所示。打开摄像头开始活体检测, 首先采用OpenCV内置的haar级联分类器对视频流进行人脸检测<citation id="137" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>, 然后采用基于LBF的机器学习算法进行人脸对齐<citation id="138" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>, 对采集到的人脸图片进行图像质量检测与校正, 调整亮度、角度等使其满足后续的检测过程, 最后按照随机组合动作指令进行改进的眨眼检测和唇部动作检测, 并执行背景检测。客户按照指令完成相应的动作, 如果背景检测合格, 则通过活体检测。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903043_053.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 活体检测整体流程" src="Detail/GetImg?filename=images/JSJC201903043_053.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 活体检测整体流程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903043_053.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="54" name="54">1.1 图像质量检测与校正</h4>
                <div class="p1">
                    <p id="55">对视频流中的每一帧图像进行人脸检测和对齐后, 首先要对采集到的人脸图像进行质量检测及校正。调整和优化人脸角度、区域亮度和对比度, 包括将人脸角度调整到正脸角度, 根据检测环境的光照强度把图像对比度和亮度调整到设定标准, 排除眼睑、眉毛等区域对后续眨眼检测的干扰等。图像质量检测与校正的步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="56"><b>步骤1</b> 采取仿射变换对人脸角度进行校正, 目标为人脸对齐后的68个关键点。通过式 (1) 进行仿射变换, 将原坐标 (<i>x</i>, <i>y</i>) 转换为校正后的新坐标 (<i>x</i>′, <i>y</i>′) , 然后根据新的坐标点得到校正后的图像。</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mo>[</mo><mrow><mtable><mtr><mtd columnalign="left"><msup><mi>x</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd columnalign="left"><msup><mi>y</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd columnalign="left"><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>m</mi><mn>0</mn><mn>0</mn></mtd><mtd><mi>m</mi><mn>0</mn><mn>1</mn></mtd><mtd><mi>m</mi><mn>0</mn><mn>2</mn></mtd></mtr><mtr><mtd><mi>m</mi><mn>1</mn><mn>0</mn></mtd><mtd><mi>m</mi><mn>1</mn><mn>1</mn></mtd><mtd><mi>m</mi><mn>1</mn><mn>2</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>x</mi></mtd></mtr><mtr><mtd columnalign="left"><mi>y</mi></mtd></mtr><mtr><mtd columnalign="left"><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mo>[</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>m</mi><mn>0</mn><mn>0</mn><mo>⋅</mo><mi>x</mi><mo>+</mo><mi>m</mi><mn>0</mn><mn>1</mn><mo>⋅</mo><mi>y</mi><mo>+</mo><mi>m</mi><mn>0</mn><mn>2</mn></mtd></mtr><mtr><mtd columnalign="left"><mi>m</mi><mn>1</mn><mn>0</mn><mo>⋅</mo><mi>x</mi><mo>+</mo><mi>m</mi><mn>1</mn><mn>1</mn><mo>⋅</mo><mi>y</mi><mo>+</mo><mi>m</mi><mn>1</mn><mn>2</mn></mtd></mtr><mtr><mtd columnalign="left"><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">具体过程如下:</p>
                </div>
                <div class="p1">
                    <p id="59">1) 根据人脸对齐后的人眼位置坐标计算两眼中心点, 并按照此中心点进行旋转。</p>
                </div>
                <div class="p1">
                    <p id="60">2) 计算旋转角度。当人脸摆正时, 双眼连线水平, 以此为基准计算当前两眼纵坐标差值与横坐标差值的比值, 再利用三角函数求出旋转角度。</p>
                </div>
                <div class="p1">
                    <p id="61"><b>步骤2</b> 采取基于像素点算子的方法增强图片的对比度和亮度。其基本思想是像素的逐点处理, 即输入图片像素值后进行某些全局信息或参数的处理, 再输出相应的像素值。线性点运算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="62"><i>g</i> (<i>x</i>) =<i>αf</i> (<i>x</i>) +<i>β</i>      (2) </p>
                </div>
                <div class="p1">
                    <p id="63">其中, 参数<i>α</i>和<i>β</i>分别称作增益参数和偏置参数, <i>α</i>控制图像的对比度, <i>β</i>控制图像的亮度, <i>f</i> (<i>x</i>) 表示源图像像素, <i>g</i> (<i>x</i>) 表示输出图像像素。最终调整效果如图2所示。</p>
                </div>
                <div class="area_img" id="64">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903043_064.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 图像质量检测与校正效果" src="Detail/GetImg?filename=images/JSJC201903043_064.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 图像质量检测与校正效果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903043_064.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="65" name="65">1.2 改进的眨眼检测</h4>
                <h4 class="anchor-tag" id="66" name="66">1.2.1 基于坐标比例变化的眨眼检测</h4>
                <div class="p1">
                    <p id="67">对输入视频流进行人脸检测和人脸对齐后, 分割出如图3所示的人眼区域特征点位置。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903043_068.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 人脸对齐后检测出的眼部区域" src="Detail/GetImg?filename=images/JSJC201903043_068.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 人脸对齐后检测出的眼部区域</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903043_068.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="69">根据各个特征点位置的变化可以估计人眼的状态。由于人的双眼对称, 以右眼为例, 将上下眼皮的特征点位置标号为1和3, 左右眼角的特征点位置标号为0和2, 如图3所示。通过式 (3) 计算眼睛的宽高比例, 判断当前帧中右眼的状态:</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo stretchy="false"> (</mo><mi>Ρ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mo stretchy="false">∥</mo><mi>Ρ</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">∥</mo></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71">其中, <i>R</i> (<i>P</i>) 为右眼的宽高比例, <i>P</i><sub><i>i</i></sub> (<i>x</i>) 和<i>P</i><sub><i>i</i></sub> (<i>y</i>) 分别为特征点<i>i</i>的<i>x</i>和<i>y</i>坐标值。根据眼睛宽高比的变化, 能够判断当前帧中眼睛的睁闭状态, 同理可以判断左眼的状态。</p>
                </div>
                <h4 class="anchor-tag" id="72" name="72">1.2.2 基于眼部区域色素差的眨眼检测</h4>
                <div class="p1">
                    <p id="73">检测到眼部区域后, 对眼部图像进行灰度化、二值化和中值滤波等形态学操作, 统计眼部图像中黑色像素的总和, 分析眼部状态变化。首先对眼部区域图像灰度化后做二值化处理, 得到黑白图像。由于人眼的眼珠像素比较深沉, 并且呈圆形, 因此选取一定尺寸的椭圆形结构元素对二值化后的图像进行闭运算, 可以消除图像中的小型黑洞和低亮度值的孤立点, 排除非眼珠区域对结果的干扰。其数学表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="74"><i>dst</i>=<i>close</i> (<i>src</i>, <i>element</i>) =<i>erode</i> (<i>dilate</i> (<i>src</i>, <i>element</i>) )      (4) </p>
                </div>
                <div class="p1">
                    <p id="76">其中, <i>dst</i>代表输出图像, <i>src</i>代表输入图像, <i>element</i>代表结构元素。</p>
                </div>
                <div class="p1">
                    <p id="77">根据VTM摄像头等硬件设备以及检测距离, 调整二值化函数中阈值<i>threshold</i>和闭运算中<i>kernel</i>值的大小, 尽可能地排除眼睑、眼角等干扰因素, 得到最佳的眼球二值化图像, 如图4 (c) 只含有眼珠的图像。不同阈值下滤波后的图像如图4所示。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903043_078.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同阈值下滤波后的眼部图像" src="Detail/GetImg?filename=images/JSJC201903043_078.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 不同阈值下滤波后的眼部图像</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903043_078.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="79">计算滤波后眼部图像的像素值, 统计每帧图像中眼球像素的总和, 分析其动态变化, 进而判断是否发生眨眼动作。基于眼部区域色素差变化的眨眼检测算法如下:</p>
                </div>
                <div class="p1">
                    <p id="80"><b>算法1</b> 基于眼部区域色素差的眨眼检测</p>
                </div>
                <div class="area_img" id="143">
                                <img alt="" src="Detail/GetImg?filename=images/JSJC201903043_14300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="92">基于坐标比例变化的眨眼检测可预防静态照片的晃动、翻转等攻击, 而基于眼部区域色素差的眨眼检测可预防静态照片的极限角度、折叠等模拟眨眼动作的攻击。活体认证时2种检测作为独立的线程并行检测, 结果进行“与”运算, 在不失速度与准确率的前提下能有效提高对静态照片攻击的防御性。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93">1.3 唇部动作检测</h4>
                <div class="p1">
                    <p id="94">唇部动作检测分为微笑检测和张嘴检测, 均是对唇部区域的动作识别与判断。由于这2种动作所取距离比例值变化非常明显, 其原理跟眨眼检测算法类似, 因此这里不再赘述。在下文的随机指令中, 可配合眨眼检测, 组成动作序列实现活体认证。唇部动作检测效果如图5所示。</p>
                </div>
                <div class="area_img" id="95">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903043_095.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 唇部动作检测效果" src="Detail/GetImg?filename=images/JSJC201903043_095.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 唇部动作检测效果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903043_095.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="96" name="96">1.4 背景检测和随机组合动作指令</h4>
                <div class="p1">
                    <p id="97">改进后的眨眼检测、微笑检测以及张嘴检测, 可有效抵御静态照片的各种角度、动作对VTM活体认证的攻击。针对视频和3D模具的攻击, 本文提出一种背景检测与随机动作指令相结合的方案。</p>
                </div>
                <h4 class="anchor-tag" id="98" name="98">1.4.1 背景检测</h4>
                <div class="p1">
                    <p id="99">在实际应用场景中, 由于VTM机的位置和摄像头角度固定, 检测的环境不变, 因此可提前采集检测环境的背景照片存入本地, 提取背景照片中的若干个关键点与当前视频中提取的背景图片的关键点做匹配算法, 根据检测环境复杂度设置匹配关键点个数的阈值, 以此预防用户在其他地方提前录制视频进行攻击。为了防止攻击视频的背景与实际检测背景有相似角点的匹配, 采用OpenCV中的Surf角点特征提取和Brute Force匹配。背景检测效果如图6所示。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903043_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 背景检测效果" src="Detail/GetImg?filename=images/JSJC201903043_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 背景检测效果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903043_100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="101" name="101">1.4.2 随机组合动作指令</h4>
                <div class="p1">
                    <p id="102">在传统的活体检测中, 系统发出的动作指令仅有摇头、眨眼等, 且顺序和过程固定。为防止用户已知动作顺序, 提前录制对应视频攻击系统, 在上述已实现的眨眼检测、微笑检测与张嘴检测的前提下, 设计3种动作的随机顺序组成随机组合动作指令, 具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="103">1) 设定一个时间范围, 在此范围内, 完成系统随机组合的动作, 例如左眼睁开, 右眼闭合→微笑;微笑→张嘴;张嘴→左右眼同时睁开等。每登录一次, 进行一次随机组合的动作指令。</p>
                </div>
                <div class="p1">
                    <p id="104">2) 根据实际业务流程的复杂程度, 制定复杂程度不同的组合指令, 例如3个动作或者4个及以上。在此认证过程中, VTM对人脸持续跟踪, 防止切换视频, 攻击系统。如果系统跟踪中断, 即检测不到人脸, 则认证失败, 检测中止。随机组合动作系统指示界面如图7所示。</p>
                </div>
                <div class="area_img" id="105">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903043_105.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 随机组合动作系统指示界面" src="Detail/GetImg?filename=images/JSJC201903043_105.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 随机组合动作系统指示界面</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903043_105.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="106">在VTM实际使用过程中, 系统会限制人脸识别登录次数。如果多次出现异常的检测结果, 会引起系统预警、人工防范等。上述背景检测和随机组合动作指令的协同审核, 可有效防止用户通过预先录制视频通过认证。</p>
                </div>
                <h3 id="107" name="107" class="anchor-tag">2 实验结果与分析</h3>
                <div class="p1">
                    <p id="108">本文实验平台为VTM, 型号:易时代ET-R100, OS:Windows 7, CPU:Intel (R) Core i3 3220, 内存:64 GB, GPU:NVIDIA Tesla K40 m×2, 显存:12 GB×2。</p>
                </div>
                <h4 class="anchor-tag" id="109" name="109">2.1 样本库建立与参数设置</h4>
                <div class="p1">
                    <p id="110">实验收集和建立了自建样本库和公开的活体人脸数据库CASIA-FASD这2个样本库, 每个样本库中都包含活体人脸照片和翻拍人脸照片。在自建样本库中采集200张活体人脸照片作为正样本库, 再利用罗技C920型号的摄像头进行翻拍操作, 包含对纸质照片的拍摄和视频录制两部分。在仿真过程中, 分别采用静态图片和动态视频模拟实际VTM场景进行活体认证攻击。制作样本库时保留人脸的朝向角度、光照强度、表情等不同状态, 从而真实地仿真出活体检测系统的现场环境状况, 最终的样本库包含400张人脸图像。样本库部分人脸图像如图8、图9所示。</p>
                </div>
                <div class="area_img" id="111">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903043_111.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 自建样本库部分实验人脸展示" src="Detail/GetImg?filename=images/JSJC201903043_111.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图8 自建样本库部分实验人脸展示</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903043_111.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903043_112.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 CASIA-FASD真实人脸和伪装人脸样例" src="Detail/GetImg?filename=images/JSJC201903043_112.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图9 CASIA-FASD真实人脸和伪装人脸样例</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903043_112.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="113">实验中VTM摄像头与检测区域的距离为1 m, 将眨眼检测中二值化函数的阈值<i>threshold</i>设为25, 闭运算中<i>kernel</i>值设为CV::Size (3, 3) , 坐标比例<i>R</i> (<i>P</i>) 变化大于0.7视为睁眼或闭眼, 背景检测中匹配点个数大于检测点总数的90%视为检测通过。</p>
                </div>
                <h4 class="anchor-tag" id="114" name="114">2.2 结果分析</h4>
                <div class="p1">
                    <p id="115">为验证算法在数据库中的准确性和优越性, 将本文算法与多光谱<citation id="139" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、局部二值模式 (Local Binary Patterns, LBP) <citation id="140" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、普通交互式检测<citation id="141" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、卷积神经网络 (Convolutional Neural Network, CNN) <citation id="142" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>等其他活体人脸检测方法进行比较, 对比各算法的识别率和检测时间。本文算法对定义内各个动作检测的准确率、不同算法的roc特征曲线如图10、图11所示。</p>
                </div>
                <div class="area_img" id="116">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903043_116.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 本文算法各种动作检测的准确率" src="Detail/GetImg?filename=images/JSJC201903043_116.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图10 本文算法各种动作检测的准确率</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903043_116.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903043_117.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 不同方法roc特征曲线对比" src="Detail/GetImg?filename=images/JSJC201903043_117.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图11 不同方法roc特征曲线对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903043_117.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="118">从图10可以看出, 本文算法对定义内的3种面部动作识别准确率均在98%以上, 说明算法对定义的面部动作均能做出有效识别。从图11可以看出, 相比于其他算法, 本文算法具有较好的性能, 其线下面积AUC最大, 达到96.72%, 对数据库中的人脸样本有较好的鉴别效果。</p>
                </div>
                <div class="p1">
                    <p id="119">表1为本文算法与其他算法在数据库中的检测效果对比。从表1可以看出, 针对照片攻击情况, 本文方法的检测正确率达97.67%, 比LBP、多光谱、CNN和普通交互式检测正确率分别提高16.14%、0.81%、3.77%、7.15%。针对视频攻击情况, 本文方法的检测正确率达到97.78%, 比LBP、多光谱、CNN和普通交互式检测的正确率分别提高20.09%、2.32%、5.18%、8.43%。通过对比可以看出, 在照片攻击时, 无论是相对传统的普通交互式检测方法, 还是目前流行的活体检测方法, 本文方法都具有更高的检测正确率。在视频攻击时, LBP、多光谱、CNN和普通交互式相对于照片攻击时正确率都有所下降, 其中LBP效果最差, 检测正确率下降18.84%, 而本文方法仍保持很高的检测正确率, 对照片攻击和视频攻击的抵御效果相当。在时效性上, 本文方法相比于普通交互式检测算法, 检测时间没有明显增大, 满足VTM应用环境高精度和实时性的要求。</p>
                </div>
                <div class="area_img" id="120">
                    <p class="img_tit"><b>表1 不同方法的检测效果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="120" border="1"><tr><td rowspan="2"><br />方法</td><td colspan="2"><br />正确率/%</td><td rowspan="2">检测时间<br />/ms</td></tr><tr><td><br />照片攻击</td><td>视频攻击</td></tr><tr><td>LBP方法</td><td>81.53</td><td>77.69</td><td>238</td></tr><tr><td><br />多光谱方法</td><td>96.86</td><td>95.46</td><td>428</td></tr><tr><td><br />CNN方法</td><td>93.90</td><td>92.60</td><td>367</td></tr><tr><td><br />普通交互式检测方法</td><td>90.52</td><td>89.35</td><td>424</td></tr><tr><td><br />本文方法</td><td>97.67</td><td>97.78</td><td>436</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="121" name="121" class="anchor-tag">3 结束语</h3>
                <div class="p1">
                    <p id="122">根据当前VTM人脸识别系统面临的问题及现有活体检测算法存在的缺陷, 本文提出一种面向VTM改进的交互式活体检测算法。该算法基于OpenCV级联分类器人脸检测和LBF人脸对齐算法, 有效结合了改进的眨眼检测、背景检测、随机组合动作指令等。模拟图片攻击和视频攻击实验, 结果表明, 本文方法的检测正确率与LBP、多光谱、CNN等方法相比均有所提升。尤其是对比普通交互式检测算法, 检测正确率提升8%左右, 表明该方法可有效抵抗静态照片和动态视频的模拟攻击, 能够满足VTM高精度和高安全性的要求。下一步将根据VTM用户的使用反馈来设计交互动作, 优化本文算法, 提高识别效率并改善交互体验。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Survey of Dictionary Learning Algorithms for Face Recognition">

                                <b>[1]</b> XU Y, LI Z, YANG J, et al.A survey of dictionary learning algorithms for face recognition[J].IEEE Access, 2017, 5:8502-8514.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A face liveness detection scheme to combining static and dynamic features">

                                <b>[2]</b> WU L, XU Y, XU X, et al.A face liveness detection scheme to combining static and dynamic features[M].Berlin, Germany:Springer, 2016:628-636.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A combined HOG-LPQ with Fuz-SVM classifier for Object face Liveness Detection">

                                <b>[3]</b> MOHAN K, CHANDRASEKHAR P, JILANI S A K.A combined HOG-LPQ with Fuz-SVM classifier for object face liveness detection[C]//Proceedings of International Conference on IoT in Social, Mobile, Analytics and Cloud.Washington D.C., USA:IEEE Press, 2017:531-537.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face liveness detection with feature discrimination between sharpness and blurriness">

                                <b>[4]</b> YEH C H, CHANG H H.Face liveness detection with feature discrimination between sharpness and blurriness[C]//Proceedings of the 15th IAPR International Conference on Machine Vision Applications.Washington D.C., USA:IEEE Press, 2017:398-401.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A robust anti-spoofing technique for face liveness detection with morphological operations">

                                <b>[5]</b> SINGH M, ARORA A S.A robust anti-spoofing technique for face liveness detection with morphological operations[J].Optik-International Journal for Light and Electron Optics, 2017, 139 (4) :347-354.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A discriminative spatio-temporal mapping of face for liveness detection">

                                <b>[6]</b> LAKSHMINARAYANA N N, NARAYAN N, NAPP N, et al.A discriminative spatio-temporal mapping of face for liveness detection[C]//Proceedings of IEEE International Conference on Identity, Security and Behavior Analysis.Washington D.C., USA:IEEE Press, 2017:1-7.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201704061&amp;v=MjM2OTc3dkpMejdTWkxHNEg5Yk1xNDlEWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk3bFc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 任玉强, 田国栋, 周祥东, 等.高安全性人脸识别系统中的唇语识别算法研究[J].计算机应用研究, 2017, 34 (4) :1221-1225.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A New Multispectral Method for Face Liveness Detection">

                                <b>[8]</b> WANG Y, HAO X, HOU Y, et al.A new multispectral method for face liveness detection[C]//Proceedings of IAPR Asian Conference on Pattern Recognition.Washington D.C., USA:IEEE Press, 2013:922-926.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face spoofing detection using colour texture analysis">

                                <b>[9]</b> BOULKENAFET Z, KOMULAINEN J, HADID A.Face spoofing detection using colour texture analysis[J].IEEE Transactions on Information Forensics and Security, 2016, 11 (8) :1818-1830.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the vulnerability of extended multispectral face recognition systems towards presentation attacks">

                                <b>[10]</b> RAGHAVENDRA R, RAJA K B, VENKATESH S, et al.On the vulnerability of extended multispectral face recognition systems towards presentation attacks[C]//Proceedings of IEEE International Conference on Identity, Security and Behavior Analysis.Washington D.C., USA:IEEE Press, 2017:1-8.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Eyeblink-based Anti-spoofing in Face Recognition from a Generic Webcamera">

                                <b>[11]</b> PAN G, SUN L, WU Z, et al.Eyeblink-based anti-spoofing in face recognition from a generic webcamera[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2007:1-8.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face liveness detection using shearlet-based feature descriptors">

                                <b>[12]</b> FENG L, PO L M, LI Y, et al.Face liveness detection using shearlet-based feature descriptors[EB/OL].[2018-01-05].http://www.ee.cityu.edu.hk/～lmpo/publications/2017_JEI_face_liveness.pdf.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face recognition with liveness detection using eye and mouth movement">

                                <b>[13]</b> SINGH A K, JOSHI P, NANDI G C.Face recognition with liveness detection using eye and mouth movement[C]//Proceedings of International Conference on Signal Propagation and Computer Technology.Washington D.C., USA:IEEE Press, 2014:592-597.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXCN201407012&amp;v=MDE2ODRZTEc0SDlYTXFJOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdsVzd2SlBUWEk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 曹瑜, 涂玲, 毋立芳.身份认证中灰度共生矩阵和小波分析的活体人脸检测算法[J].信号处理, 2014, 30 (7) :830-835.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=WLD-TOP based algorithm against face spoofing attacks">

                                <b>[15]</b> MEI L, YANG D, FENG Z, et al.WLD-TOP based algorithm against face spoofing attacks[M].Berlin, Germany:Springer, 2015:6.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE947BDE1F9AE65336828BD9DC0AB5E74&amp;v=MjMzNjR4S2s9TmlmT2ZjYXhHdGErMi9wRUV1SitlWG84ekJVVjRqMTFPZ3ZyMkdFMUNNQ1JNTDJiQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TjVod3JpMw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> WILD P, RADU P, CHEN L, et al.Robust multimodal face and fingerprint fusion in the presence of spoofing attacks[J].Pattern Recognition, 2016, 50 (C) :17-25.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Comparison of OpenCV&amp;#39;&amp;#39;s feature detectors and feature matchers">

                                <b>[17]</b> NOBLE F K.Comparison of OpenCV’s feature detectors and feature matchers[C]//Proceedings of International Conference on Mechatronics and Machine Vision in Practice.Washington D.C., USA:IEEE Press, 2016:1-6.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face Alignment at 3000 FPS via Regressing Local Binary Features">

                                <b>[18]</b> REN S, CAO X, WEI Y, et al.Face alignment at 3 000 FPS via regressing local binary features[C]//Proceedings of International Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2014:1685-1692.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A face anti-spoofing database with diverse attacks">

                                <b>[19]</b> ZHANG Z, YAN J, LIU S, et al.A face anti-spoofing database with diverse attacks[C]//Proceedings of the 5th IAPR International Conference on Biometrics.Washington D.C., USA:IEEE Press, 2012:26-31.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A fast and accurate unconstrained face detector">

                                <b>[20]</b> LIAO S, JAIN A K, LI S Z.A fast and accurate unconstrained face detector[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (2) :211-223.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep learning based face liveness detection in videos">

                                <b>[21]</b> AKBULUT Y, SENGUR A, BUDAK U, et al.Deep learning based face liveness detection in videos[C]//Proceedings of International Artificial Intelligence and Data Processing Symposium.Washington D.C., USA:IEEE Press, 2017:1-4.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201903043" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903043&amp;v=MjgxOTlBTHo3QmJiRzRIOWpNckk5Qlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N2xXN3I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
