<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130533397530000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201905042%26RESULT%3d1%26SIGN%3diyhY44%252fKnTSMgDcS%252fujgP0xJ%252b00%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201905042&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201905042&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201905042&amp;v=MjMxODI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTNtVjc3SUx6N0JiYkc0SDlqTXFvOUJab1FLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#37" data-title="1 多线索融合人脸活体检测 ">1 多线索融合人脸活体检测</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#39" data-title="1.1 金字塔LK光流">1.1 金字塔LK光流</a></li>
                                                <li><a href="#50" data-title="1.2 剪切波变换">1.2 剪切波变换</a></li>
                                                <li><a href="#63" data-title="1.3 卷积神经网络">1.3 卷积神经网络</a></li>
                                                <li><a href="#77" data-title="1.4 网络微调">1.4 网络微调</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#82" data-title="2 实验结果与分析 ">2 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#83" data-title="2.1 实验平台">2.1 实验平台</a></li>
                                                <li><a href="#85" data-title="2.2 实验数据库">2.2 实验数据库</a></li>
                                                <li><a href="#91" data-title="2.3 实验数据记录">2.3 实验数据记录</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#99" data-title="3 结束语 ">3 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#41" data-title="&lt;b&gt;图1 金字塔LK光流追踪算法流程&lt;/b&gt;"><b>图1 金字塔LK光流追踪算法流程</b></a></li>
                                                <li><a href="#57" data-title="&lt;b&gt;图2 基于剪切波的图像质量特征提取过程&lt;/b&gt;"><b>图2 基于剪切波的图像质量特征提取过程</b></a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;图3 卷积神经网络结构&lt;/b&gt;"><b>图3 卷积神经网络结构</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;图4 微调策略算法流程&lt;/b&gt;"><b>图4 微调策略算法流程</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;表1 不同方法在Replay-attack上性能对比&lt;/b&gt;"><b>表1 不同方法在Replay-attack上性能对比</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;表2 不同方法在CASIA-FASD上性能对比&lt;/b&gt;"><b>表2 不同方法在CASIA-FASD上性能对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" PAN Gang, SUN Lin, WU Zhaohui, et al.Eyeblink-based anti-spoofing in face recognition from a generic webcamera[C]//Proceedings of the 11th International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2007:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Eyelink-based Anti-spoofing in Face Recognition from a Generic Webcamera">
                                        <b>[1]</b>
                                         PAN Gang, SUN Lin, WU Zhaohui, et al.Eyeblink-based anti-spoofing in face recognition from a generic webcamera[C]//Proceedings of the 11th International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2007:1-8.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" KOLLREIDER K, FRONTHALER H, FARAJ M I, et al.Real-time face detection and motion analysis with application in “liveness” assessment[J].IEEE Transactions on Information Forensics and Security, 2007, 2 (3) :548-558" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-Time Face Detection and Motion Analysis With Application in “Liveness” Assessment">
                                        <b>[2]</b>
                                         KOLLREIDER K, FRONTHALER H, FARAJ M I, et al.Real-time face detection and motion analysis with application in “liveness” assessment[J].IEEE Transactions on Information Forensics and Security, 2007, 2 (3) :548-558
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" BAO Wei, LI Hong, LI Nan, et al.A liveness detection method for face recognition based on optical flow field[C]//Proceedings of International Conference on Image Analysis and Signal Processing.Washington D.C., USA:IEEE Press, 2009:233-236." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;A liveness detection method for face recognition based on optical flow field&amp;quot;">
                                        <b>[3]</b>
                                         BAO Wei, LI Hong, LI Nan, et al.A liveness detection method for face recognition based on optical flow field[C]//Proceedings of International Conference on Image Analysis and Signal Processing.Washington D.C., USA:IEEE Press, 2009:233-236.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 任安虎, 刘贝.基于Adaboost的人脸识别眨眼检测[J].计算机与数字工程, 2016, 44 (3) :521-524." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201603030&amp;v=MTY4NDBGckNVUkxPZVplUm9GeTNtVjc3SUx6N1lhYkc0SDlmTXJJOUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         任安虎, 刘贝.基于Adaboost的人脸识别眨眼检测[J].计算机与数字工程, 2016, 44 (3) :521-524.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" SINGH A K, JOSHI P, NANDI G C.Face recognition with liveness detection using eye and mouth movement[C]//Proceedings of International Conference on Signal Propagation and Computer Technology.Washington D.C., USA:IEEE Press, 2014:592-597." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face recognition with liveness detection using eye and mouth movement">
                                        <b>[5]</b>
                                         SINGH A K, JOSHI P, NANDI G C.Face recognition with liveness detection using eye and mouth movement[C]//Proceedings of International Conference on Signal Propagation and Computer Technology.Washington D.C., USA:IEEE Press, 2014:592-597.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" ANJOS A, CHAKKA M M, MARCEL S.Motion-based counter-measures to photo attacks in face recognition[J].IET Biometrics, 2014, 3 (3) :147-158" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Motion-based counter-measures to photo attacks in face recognition">
                                        <b>[6]</b>
                                         ANJOS A, CHAKKA M M, MARCEL S.Motion-based counter-measures to photo attacks in face recognition[J].IET Biometrics, 2014, 3 (3) :147-158
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" MAATTA J, HADID A, PIETIKAINEN M.Face spoofing detection from single images using micro-texture analysis[C]//Proceedings of International Joint Conference on Biometrics.Washington D.C., USA:IEEE Press, 2011:1-7." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face Spoofing Detection From Single Images Using MicroTexture Analysis">
                                        <b>[7]</b>
                                         MAATTA J, HADID A, PIETIKAINEN M.Face spoofing detection from single images using micro-texture analysis[C]//Proceedings of International Joint Conference on Biometrics.Washington D.C., USA:IEEE Press, 2011:1-7.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 方天红, 陈庆虎, 廖海斌, 等.融合纹理与形状的人脸加权特征[J].武汉大学学报 (信息科学版) , 2015, 40 (3) :321-326, 340." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WHCH201503006&amp;v=MTQxNTlJTWlYSVpyRzRIOVRNckk5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5M21WNzc=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         方天红, 陈庆虎, 廖海斌, 等.融合纹理与形状的人脸加权特征[J].武汉大学学报 (信息科学版) , 2015, 40 (3) :321-326, 340.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" KIM Y, NA J, YOON S, et al.Masked fake face detection using radiance measurements[J].Journal of the Optical Society of America A-Optics Image Science and Vision, 2009, 26 (4) :760-766." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Masked fake face detection using radiance measurements">
                                        <b>[9]</b>
                                         KIM Y, NA J, YOON S, et al.Masked fake face detection using radiance measurements[J].Journal of the Optical Society of America A-Optics Image Science and Vision, 2009, 26 (4) :760-766.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" ZHANG Zhiwei, YI Dong, LEI Zhen, et al.Face liveness detection by learning multispectral reflectance distributions[C]//Proceedings of IEEE International Conference on Automatic Face and Gesture Recognition and Workshops.Washington D.C., USA:IEEE Press, 2011:436-441." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face livenessdetection by learning multispectral reflectancedistributions">
                                        <b>[10]</b>
                                         ZHANG Zhiwei, YI Dong, LEI Zhen, et al.Face liveness detection by learning multispectral reflectance distributions[C]//Proceedings of IEEE International Conference on Automatic Face and Gesture Recognition and Workshops.Washington D.C., USA:IEEE Press, 2011:436-441.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" EASLEY G, LABATE D, LIM W Q.Sparse directional image representations using the discrete shearlet transform[J].Applied and Computational Harmonic Analysis, 2008, 25 (1) :25-46." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501147219&amp;v=MTQyMTZmYks3SHRETnFvOUVaZThJRG4wd29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxuSUpWMFFheEk9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         EASLEY G, LABATE D, LIM W Q.Sparse directional image representations using the discrete shearlet transform[J].Applied and Computational Harmonic Analysis, 2008, 25 (1) :25-46.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 许晓.基于深度学习的活体人脸检测算法研究[D].北京:北京工业大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016785574.nh&amp;v=MTE1NTR6cXFCdEdGckNVUkxPZVplUm9GeTNtVjc3SVZGMjZHTFN3RzlUTHE1RWJQSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         许晓.基于深度学习的活体人脸检测算法研究[D].北京:北京工业大学, 2016.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" KUTYNIOKG, LABATE D.Shearlets:multiscale analysis for multivariate data[M].[S.l.]:Birkh&#228;user Basel, 2012." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Shearlets:multiscale analysis for multivariate data">
                                        <b>[13]</b>
                                         KUTYNIOKG, LABATE D.Shearlets:multiscale analysis for multivariate data[M].[S.l.]:Birkh&#228;user Basel, 2012.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" CHINGOVSKA I, ANJOS A, MARCEL S.On the effectiveness of local binary patterns in face anti-spoofing[C]//Proceedings of International Conference of Biometrics Special Interest Group.Washington D.C., USA:IEEE Press, 2012:183-194." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the effectiveness of local binary patterns in face anti-spoofing">
                                        <b>[14]</b>
                                         CHINGOVSKA I, ANJOS A, MARCEL S.On the effectiveness of local binary patterns in face anti-spoofing[C]//Proceedings of International Conference of Biometrics Special Interest Group.Washington D.C., USA:IEEE Press, 2012:183-194.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" ZHANG Zhiwei, YAN Junjie, LIU Sifei, et al.A face antispoofing database with diverse attacks[C]//Proceedings of the 5th IAPR International Conference on Biometrics.Washington D.C., USA:IEEE Press, 2012:26-31." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A face antispoofing database with diverse attacks">
                                        <b>[15]</b>
                                         ZHANG Zhiwei, YAN Junjie, LIU Sifei, et al.A face antispoofing database with diverse attacks[C]//Proceedings of the 5th IAPR International Conference on Biometrics.Washington D.C., USA:IEEE Press, 2012:26-31.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(05),256-260 DOI:10.19678/j.issn.1000-3428.0050721            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于微调策略的多线索融合人脸活体检测</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E6%96%90&amp;code=38562392&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡斐</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%96%87%E7%95%85&amp;code=11192061&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">文畅</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B0%A2%E5%87%AF&amp;code=24384852&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">谢凯</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B4%BA%E5%BB%BA%E9%A3%9A&amp;code=10472956&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贺建飚</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E6%B1%9F%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0112354&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长江大学计算机科学学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E6%B1%9F%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0193746&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长江大学电子信息学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%8D%97%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中南大学信息科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为解决身份认证过程中可能会出现的打印攻击、视频重播攻击等安全问题, 提出一种多线索融合人脸活体检测方法。利用金字塔LK光流追踪视频帧并将其进行剪切波变换, 以获取图像质量特征, 通过卷积神经网络对数据集进行网络微调, 得到真假活体。在Print-attack数据库和CISIA数据库上进行实验, 结果表明, 与LFDNet方法相比, 该方法具有较高的人脸活体检测准确率, 可用于抵制欺骗攻击。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BE%AE%E8%B0%83%E7%AD%96%E7%95%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">微调策略;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%89%AA%E5%88%87%E6%B3%A2%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">剪切波变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%87%91%E5%AD%97%E5%A1%94LK%E5%85%89%E6%B5%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">金字塔LK光流;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E8%84%B8%E6%B4%BB%E4%BD%93%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人脸活体检测;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    胡斐 (1996—) , 男, 硕士研究生, 主研方向为信号处理、图像与视频处理;;
                                </span>
                                <span>
                                    *文畅 (通信作者) , 讲师;E-mail: wenchang2016paper@ 163. com;
                                </span>
                                <span>
                                    谢凯, 教授;;
                                </span>
                                <span>
                                    贺建飚, 副教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-03-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61272147);</span>
                    </p>
            </div>
                    <h1><b>Multi-cue Fusion Face Liveness Detection Based on Fine-tuning Strategy</b></h1>
                    <h2>
                    <span>HU Fei</span>
                    <span>WEN Chang</span>
                    <span>XIE Kai</span>
                    <span>HE Jianbiao</span>
            </h2>
                    <h2>
                    <span>School of Computer Science, Yangtze University</span>
                    <span>School of Electronic Information, Yangtze University</span>
                    <span>College of Information Science and Engineering, Central South University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To solve the security problems such as print attacks and video replay attacks that may occur during the authentication process, a multi-cue fusion method for detecting human faces is proposed.The pyramid Lucas-Kanade (LK) optical flow is used to track the video frame, and it is subjected to shear wave transform to obtain image quality features.The Convolutional Neural Network (CNN) is used to fine tune the data set to obtain true and false liveness bodies.Experiments on the Print-attack database and the CISIA database show that compared with the LFDNet method, this method has higher face liveness detection accuracy and can be applied to spoofing attacks resistance.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Neural%20Network%20(CNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Neural Network (CNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=fine-tuning%20strategy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">fine-tuning strategy;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=shear%20wave%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">shear wave transform;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=pyramid%20Lucas-Kanade%20(LK)%20optical%20flow&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">pyramid Lucas-Kanade (LK) optical flow;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=face%20liveness%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">face liveness detection;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-03-12</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="34">基于生物特征 (尤其是人脸) 的身份识别已被广泛应用于信息安全与身份认证领域, 而各种欺骗攻击手段也接踵而至, 企图破解各种认证方式。为能够检测出是否为本人操作获取相关权限并保障个人的信息安全, 开始对活体与欺骗攻击进行区别, 即活体检测。</p>
                </div>
                <div class="p1">
                    <p id="35">活体检测方法主要分为3类:运动信息分析, 纹理信息分析和人脸三维结构分析。运动信息分析如分析人脸的眨眼<citation id="101" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、张嘴<citation id="102" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、点头<citation id="103" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等动态特征, 文献<citation id="104" type="reference">[<a class="sup">4</a>]</citation>利用多层卷积神经网络 (Convolutional Neural Network, CNN) 提取眨眼信息进行活体检测。文献<citation id="105" type="reference">[<a class="sup">5</a>]</citation>采用多线索融合处理空间域和时间域的活体检测。文献<citation id="106" type="reference">[<a class="sup">6</a>]</citation>利用前后背景的光流相关性来进行活体检测。上述方法虽然对照片攻击有较好的检测效果, 但在面临高质量的视频攻击时则难以达到较高的精确度。纹理信息分析通过对三维活体人脸和照片成像后的差异性来提取纹理特征进行活体判断。文献<citation id="107" type="reference">[<a class="sup">7</a>]</citation>提出一种使用微纹理分析的方式进行活体检测, 但在图像质量较差时效果不佳。文献<citation id="108" type="reference">[<a class="sup">8</a>]</citation>将纹理特征结合人脸结构特征, 能够避免图像质量较差的缺陷, 但算法复杂度较大, 对时间要求高。人脸三维结构分析主要利用照片、屏幕作为二维平面, 人脸作为三维立体来进行活体检测。文献<citation id="109" type="reference">[<a class="sup">9</a>]</citation>提出三维人脸和二维平面光的反射不同的思想。文献<citation id="110" type="reference">[<a class="sup">10</a>]</citation>根据不同材料 (皮肤与非皮肤) 光反射曲线的不同来进行活体检测, 但需要额外的红外设备, 不易实现。</p>
                </div>
                <div class="p1">
                    <p id="36">基于以上研究, 本文提出一种多线索融合人脸活体检测方法。该方法采用金字塔LK光流追踪视频序列的运动信息, 利用剪切波变换<citation id="111" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>在多维数据中捕获异性特征, 并提取纹理特征, 通过卷积神经网络<citation id="112" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>进行微调, 以提高检测的准确率。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag">1 多线索融合人脸活体检测</h3>
                <div class="p1">
                    <p id="38">本文利用卷积神经网络提取视频序列中的运动信息以及图像质量信息, 通过训练网络判断活体人脸。从视频样本中提取一个10帧的连续视频序列, 将其利用金字塔LK光流追踪动态信息, 同时对第1帧进行剪切波变换, 最终把提取的光流特征和图像质量特征输入到卷积神经网络, 再使用Caffe框架进行微调, 使其具备判断是活体或非活体的能力。</p>
                </div>
                <h4 class="anchor-tag" id="39" name="39">1.1 金字塔LK光流</h4>
                <div class="p1">
                    <p id="40">光流是图像表面运动的速度, 由此推导出基于该模型的约束方程, 算法流程如图1所示。</p>
                </div>
                <div class="area_img" id="41">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905042_041.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 金字塔LK光流追踪算法流程" src="Detail/GetImg?filename=images/JSJC201905042_041.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 金字塔LK光流追踪算法流程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905042_041.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="42">在<i>t</i>时刻, 图像上的点<b><i>P</i></b>= (<i>x</i>, <i>y</i>) 的灰度值是<b><i>I</i></b> (<i>x</i>, <i>y</i>, <i>t</i>) , 在经过d<i>t</i>时间后, 与之匹配的灰度值变为<b><i>I</i></b>= (<i>x</i>+d<i>x</i>, <i>y</i>+d<i>y</i>, <i>t</i>+d<i>t</i>) 。当d<i>t</i>趋近于0时, 2点的灰度值不变, 如式 (1) 所示。</p>
                </div>
                <div class="p1">
                    <p id="43"><b><i>I</i></b>= (<i>x</i>+d<i>x</i>, <i>y</i>+d<i>y</i>, <i>t</i>+d<i>t</i>) =<b><i>I</i></b> (<i>x</i>, <i>y</i>, <i>t</i>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="44">当图像的灰度值随着<i>x</i>、<i>y</i>、<i>t</i>这3个变量变化时, 式 (1) 由泰勒级数展开为:</p>
                </div>
                <div class="p1">
                    <p id="45"><i>I</i><sub><i>x</i></sub><i>μ</i>+<i>I</i><sub><i>y</i></sub><i>ν</i>+<i>I</i><sub><i>t</i></sub>=0      (2) </p>
                </div>
                <div class="p1">
                    <p id="46">光流场基本方程的矢量形式可表示为:</p>
                </div>
                <div class="p1">
                    <p id="47">∇<b><i>I</i></b>·<i>ν</i><sup>T</sup><sub><i>m</i></sub>+<i>I</i><sub><i>t</i></sub>=0      (3) </p>
                </div>
                <div class="p1">
                    <p id="48">其中, ∇<b><i>I</i></b>= (<i>I</i><sub><i>x</i></sub>, <i>I</i><sub><i>y</i></sub>) 表示点<i>P</i>的图像梯度, <b><i>v</i></b><sub><i>m</i></sub>= (<i>u</i>, <i>v</i>) 表示点<i>P</i>的光流。式 (3) 为光流约束方程, 是基于梯度的所有光流计算方法的基础。本文利用金字塔LK光流法对视频序列帧进行跟踪, 水平方向<i>X</i>和垂直方向<i>Y</i>的位移由跟踪结果计算。根据式<mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo>=</mo><msqrt><mrow><mi>F</mi><msubsup><mrow></mrow><mi>y</mi><mn>2</mn></msubsup><mo>+</mo><mi>F</mi><msubsup><mrow></mrow><mi>x</mi><mn>2</mn></msubsup></mrow></msqrt></mrow></math></mathml>, 计算出两帧之间的位移幅值, 即动态特征, 将其作为卷积神经网络的输入。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50">1.2 剪切波变换</h4>
                <div class="p1">
                    <p id="51">将经过处理的一张二维图像输入, 复合扩张仿射系统<citation id="113" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>可表示为:</p>
                </div>
                <div class="p1">
                    <p id="52">SH<sub>∅</sub><b><i>f</i></b> (<i>a</i>, <i>s</i>, <i>t</i>) =〈<b><i>f</i></b>, ∅<sub><i>a</i>, <i>s</i>, <i>t</i></sub>〉, <i>a</i>&gt;0, <i>s</i>∈<i>R</i>, <b><i>t</i></b>∈<image href="images/JSJC201905042_053.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup>2</sup>      (4) </p>
                </div>
                <div class="p1">
                    <p id="54">其中, <b><i>f</i></b>为图像, ∅<sub><i>a</i>, <i>s</i>, <i>t</i></sub>为剪切波因子, 定义为</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>∅</mo><msub><mrow></mrow><mrow><mi>a</mi><mo>, </mo><mi>s</mi><mo>, </mo><mi>t</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Μ</mi><msub><mrow></mrow><mrow><mi>a</mi><mo>, </mo><mi>s</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow><msup><mrow></mrow><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mo>∅</mo><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Μ</mi><msubsup><mrow></mrow><mrow><mi>a</mi><mo>, </mo><mi>s</mi></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mi>x</mi><mo>-</mo><mi mathvariant="bold-italic">t</mi></mrow><mo>) </mo></mrow><mo>, </mo><mi mathvariant="bold-italic">Μ</mi><msub><mrow></mrow><mrow><mi>a</mi><mo>, </mo><mi>s</mi></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>s</mi></msub><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mi>a</mi></msub><mo>=</mo><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mi>a</mi></mtd><mtd><msqrt><mi>a</mi></msqrt><mi>s</mi></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><msqrt><mi>a</mi></msqrt></mtd></mtr></mtable></mrow><mo>) </mo></mrow><mo>, </mo><mrow><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mi>a</mi></msub><mo>=</mo></mrow><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mi>a</mi></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><msqrt><mi>a</mi></msqrt></mtd></mtr></mtable></mrow><mo>) </mo></mrow><mo>, </mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mi>s</mi></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>) </mo></mrow><mo>, </mo><mi mathvariant="bold-italic">A</mi><msub><mrow></mrow><mi>a</mi></msub></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">是各向异性扩散矩阵, <b><i>B</i></b><sub><i>s</i></sub>是剪切矩阵。剪切波变换具有较好的各向异性, 在不同的尺度、位置和方向上进行定义, 剪切波能够检测方向信息, 并解释多维函数的几何性质。从人脸图像的剪切波变换到不同的子带, 剪切过程如图2所示。</p>
                </div>
                <div class="area_img" id="57">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905042_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于剪切波的图像质量特征提取过程" src="Detail/GetImg?filename=images/JSJC201905042_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 基于剪切波的图像质量特征提取过程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905042_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="58">在图2中, 子带中的每个元素被定义为:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><mo stretchy="false"> (</mo><mi>a</mi><mo>, </mo><mi>s</mi><mo>, </mo><mi>b</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mo>∑</mo><mrow><mrow><mo>|</mo><mrow><mi>S</mi><mi>Η</mi><msub><mrow></mrow><mo>∅</mo></msub><mi mathvariant="bold-italic">f</mi><mo stretchy="false"> (</mo><mi>a</mi><mo>, </mo><mi>s</mi><mo>, </mo><mi>b</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow></mstyle></mrow><mrow><mi>m</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">其中, <i>a</i>=1, 2, …, <i>A</i>是规模指数 (不包括最粗的尺度) , <i>s</i>=1, 2, …, <i>S</i>是方向指数, <i>b</i>=1, 2, …, (<i>M</i>/<i>m</i>) <sup>2</sup>是每个子带的块索引, <i>M</i>是正方形图像的大小, <i>m</i>是每个灰色方块的大小, <i>SH</i><sub>∅</sub><i>f</i> (<i>a</i>, <i>s</i>, <i>b</i>) 为每个灰色方块的剪切波系数, 并在每一个灰色方块中进行了剪切系数的平均汇集, 集合的值被串联成一个对数非线性的矢量, 即:</p>
                </div>
                <div class="p1">
                    <p id="61"><b><i>SBIQF</i></b>=lb (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>N</i></sub>)      (6) </p>
                </div>
                <div class="p1">
                    <p id="62">其中, <i>N</i>=<i>A</i>×<i>S</i>× (<i>M</i>/<i>m</i>) <sup>2</sup>是红块的总和。</p>
                </div>
                <h4 class="anchor-tag" id="63" name="63">1.3 卷积神经网络</h4>
                <div class="p1">
                    <p id="64">传统算法需要手工设计特征, 卷积神经网络则不同, 需自行设计网络结构, 通过训练优化网络中的权重参数即可。本文使用改进<i>Alex</i>-<i>net</i>卷积神经网络, 结构如图3所示。卷积神经网络结构包括1个输入层、4个卷积层、1个全连接层和1个<i>Softmax</i>层<citation id="114" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。其中, 第1个卷积层和第2个卷积层共享权值, 均包含64个卷积核, 每个卷积核的大小是5×5, 第1个卷积层和第2个卷积层的后面分别是一个最大池化层, 最大池化层的大小是3×3, 第3个卷积层和第4个卷积层之间没有共享权值, 卷积层分别包含32个卷积核, 每个卷积核的大小为3×3, 全连接层由160个神经元组成, 这些神经元与第4个卷积层完全相连, 最后一层是<i>Softmax</i>层, 包括2个神经元, 这2个神经元对应于一张真实脸和一张假脸的二元分类的图像的概率分布。输入层的图像是32像素×32像素, 包含<i>RGB</i>的3个通道, 对该图像进行预处理后方可进行卷积神经网络处理。一个32像素×32像素的图像在4个角和1个中心的基础上被裁剪出5幅24像素×24像素的图像, 且5幅图像水平翻转。一幅图片被切割下来, 并被翻过来得到10张图片。图像数量增加, 即数据量增大, 1张24像素×24像素的图像通过第1个卷积层之后得到64张同样大小的图像块, 即特征图。在第1个混合池层之后, 获得64幅12像素×12像素的特征图。特征图的大小是原始数据的一半, 也就是说, 最大的聚合层减少了它的尺寸。特征向量的维数是原来的一半。在第2个卷积层和第2个最大池化层之后, 特征图大小变为原来的一半, 即6像素×6像素, 而第3个与第4个卷积层的后面没有最大池化层, 特征图大小不变。在全连接层之后, 一副32像素×32像素的图像有160维特征, <i>Softmax</i>层根据该特征估计概率分布。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905042_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 卷积神经网络结构" src="Detail/GetImg?filename=images/JSJC201905042_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 卷积神经网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905042_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="66">前向传播卷积层的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mi>max</mi></mrow><mo stretchy="false">{</mo><mn>0</mn><mo>, </mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></msub><mo>*</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">其中, <i>x</i><sub><i>i</i></sub>表示第<i>i</i>个输入, <i>y</i><sub><i>j</i></sub>表示第<i>j</i>个输出, <i>w</i><sub><i>i</i></sub><sub>, </sub><sub><i>j</i></sub>表示第<i>i</i>个输入和第<i>j</i>个输出之间的卷积核, 即权重参数, 符号*表示卷积运算, <i>b</i><sub><i>j</i></sub>是<i>j</i>输出的偏移量, 隐藏层使用的激活函数为整流线性单元 (ReLU函数) , 其公式为<i>f</i> (<i>x</i>) =max (0, <i>x</i>) 。最大池化层的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="69"><i>y</i><sub><i>j</i></sub>=max{<i>x</i><mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>k</mi></msubsup></mrow></math></mathml>}, <i>k</i>∈<i>D</i>      (8) </p>
                </div>
                <div class="p1">
                    <p id="71">其中, <i>D</i>表示第<i>i</i>个输入的非重叠局部区域, <i>y</i><sub><i>j</i></sub>是<i>D</i>中的最大值, 全连接层与第4个卷积层完全连通, 全连接层表示为:</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mrow><mi>max</mi></mrow><mo stretchy="false">{</mo><mn>0</mn><mo>, </mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>x</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>⋅</mo><mi>W</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">其中, <i>x</i><sub><i>i</i></sub>表示第4个卷积层的第<i>i</i>个输入, <i>y</i><sub><i>j</i></sub>表示全连接层的第<i>j</i>个输出, Softmax层的输出为<i>n</i>个值, 表示<i>n</i>类的概率分布。本文根据研究内容设计了2种输出类型, Softmax层表示为:</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mfrac><mrow><mtext>e</mtext><msup><mrow></mrow><mrow><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>j</mi></msub></mrow></msup></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mtext>e</mtext></mstyle><msup><mrow></mrow><mrow><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>j</mi></msub></mrow></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">其中, <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>x</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>⋅</mo><mi>w</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>表示全连接层的160维输出, y<sub>j</sub>表示<i>Softmax</i>层的输出。本文只有2个类, 且j值是2。</p>
                </div>
                <h4 class="anchor-tag" id="77" name="77">1.4 网络微调</h4>
                <div class="p1">
                    <p id="78">基于卷积神经网络的人脸检测算法本质上是一个二元分类问题。而对于卷积神经网络来说, 分类越多则对应的监控信号越强, 鲁棒性越好, 且无法从二元分类标记中直接提取相应特征。本文采用二进制分类对已训练的网络进行微调, 算法框图如图4所示。</p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905042_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 微调策略算法流程" src="Detail/GetImg?filename=images/JSJC201905042_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 微调策略算法流程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905042_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="80">本节图像分类包括1 000个类别, 在预训练网络中对应Softmax层神经元数量为1 000。经过训练的网络会对人脸数据进行实时微调。在微调之前, Softmax层的神经元数量应改为2个, 对应2个类别, 即活体和非活体。在微调后, 所有网络训练结束, 可以判断真假人脸。</p>
                </div>
                <div class="p1">
                    <p id="81">本节所使用的卷积神经网络结构基于Caffe框架。Caffe框架是一个常用的深度学习框架, 是基于C++/CUDA架构, 支持命令行、Python和MATLAB接口, 能够在CPU和GPU直接无缝切换, 适用于人脸活体检测。</p>
                </div>
                <h3 id="82" name="82" class="anchor-tag">2 实验结果与分析</h3>
                <h4 class="anchor-tag" id="83" name="83">2.1 实验平台</h4>
                <div class="p1">
                    <p id="84">本文采用Replay-attack数据库、CASIA-FASD数据库, 使用Caffe框架, 编程语言使用C++和python, 在基于VS2013开发的活体检测系统环境中对相关数据库进行测试。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85">2.2 实验数据库</h4>
                <div class="p1">
                    <p id="86">本文采用Replay-attack和CASIA-FASD这2种数据库, 具体描述如下:</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87">1) Replay-attack数据库</h4>
                <div class="p1">
                    <p id="88">Replay-attack数据库收集了1 200个真实拍摄的视频和50个用户的面部欺骗攻击视频<citation id="115" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。视频在2种光照条件下记录:第1种为受控的光照条件, 具有均匀的背景和人工照明;第2种为不利的光照条件, 具有复杂的背景和自然的照明。3种攻击包括在A4纸上打印的高分辨率照片、使用智能手机拍摄的视频呈现给摄像机、用平板电脑显示的高分辨率照片和视频展示给相机。2种支持条件包括手持攻击媒体和固定攻击媒体。在Replay-attack数据库中, 所有受试者分别被划分为3个非重叠子组, 分别为15个、15个和20个对象, 通过训练调整分类器的参数, 确定决策门槛, 最后进行测试, 评估分类性能。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89">2) CASIA-FASD数据库</h4>
                <div class="p1">
                    <p id="90">CASIA-FASD数据库包含来自50个客户端的600个短片<citation id="116" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 使用3种不同成像的数码相机来进行拍摄以及3种不同的欺骗攻击。这3种攻击包括照片、切割图片和视频。其中, 照片是指在铜质纸上印刷的脸部照片展示给摄像机, 通过扭曲的照片模拟面部动作, 切割图片是指眼睛区域与照片分割开来, 显示眼睛闪烁, 视频是指高质量的真实视频使用高分辨率的平板电脑显示。成像质量条件包括低质量、中等质量和高质量3种。CASIA-FASD数据库分为训练子集和测试子集, 分别有20个和30个独立的主题。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91">2.3 实验数据记录</h4>
                <div class="p1">
                    <p id="92">定义2种识别失败参数, 即误识率 (False Rejection Rate, FRR) 和拒识率 (False Acceptance Rate, FAR) , 其计算如下:</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>F</mi><mi>R</mi><mi>R</mi><mo>=</mo><mfrac><mtable columnalign="left"><mtr><mtd><mtext>已</mtext><mtext>拒</mtext><mtext>绝</mtext><mtext>但</mtext><mtext>实</mtext><mtext>际</mtext><mtext>为</mtext><mtext>活</mtext><mtext>体</mtext><mtext>的</mtext><mtext>人</mtext><mtext>脸</mtext><mtext>数</mtext></mtd></mtr><mtr><mtd></mtd></mtr></mtable><mrow><mtext>已</mtext><mtext>拒</mtext><mtext>绝</mtext><mtext>的</mtext><mtext>人</mtext><mtext>脸</mtext><mtext>总</mtext><mtext>数</mtext></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>F</mi><mi>A</mi><mi>R</mi><mo>=</mo><mfrac><mtable columnalign="left"><mtr><mtd><mtext>已</mtext><mtext>接</mtext><mtext>受</mtext><mtext>但</mtext><mtext>实</mtext><mtext>际</mtext><mtext>为</mtext><mtext>非</mtext><mtext>活</mtext><mtext>体</mtext><mtext>的</mtext><mtext>人</mtext><mtext>脸</mtext><mtext>数</mtext></mtd></mtr><mtr><mtd></mtd></mtr></mtable><mrow><mtext>已</mtext><mtext>接</mtext><mtext>受</mtext><mtext>的</mtext><mtext>人</mtext><mtext>脸</mtext><mtext>数</mtext></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">本文将式 (13) 作为其判断算法精度的依据, 与其他方法在Replay-attack和CASIA-FASD数据库上进行比较, 结果如表1、表2所示。</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mi>Τ</mi><mi>E</mi><mi>R</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mo stretchy="false"> (</mo><mi>F</mi><mi>A</mi><mi>R</mi><mo>+</mo><mi>F</mi><mi>R</mi><mi>R</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="96">
                    <p class="img_tit"><b>表1 不同方法在Replay-attack上性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="96" border="1"><tr><td><br />方法</td><td>准确率</td><td><i>HTER</i></td></tr><tr><td><br />DMD+LBP +SVM方法</td><td>—</td><td>0.000</td></tr><tr><td><br />AO+Random方法</td><td>—</td><td>0.750</td></tr><tr><td><br />lbp-top方法</td><td>98.750</td><td>8.510</td></tr><tr><td><br />Lbp+lda方法</td><td>—</td><td>13.870</td></tr><tr><td><br />HOOF+LDA (thresholding) 方法</td><td>—</td><td>4.380</td></tr><tr><td><br />HOOF+LDA (NN) 方法</td><td>—</td><td>1.250</td></tr><tr><td><br />LFDNet方法</td><td>97.699</td><td>3.380</td></tr><tr><td><br />CNN方法</td><td>—</td><td>2.100</td></tr><tr><td><br />n-LBPnet方法</td><td>—</td><td>0.017</td></tr><tr><td><br />本文方法</td><td>98.125</td><td>2.000</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="97">
                    <p class="img_tit"><b>表2 不同方法在CASIA-FASD上性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="97" border="1"><tr><td><br />方法</td><td>准确率</td><td><i>HTER</i></td></tr><tr><td><br />DMD+LBP +SVM方法</td><td>—</td><td>0.000</td></tr><tr><td><br />AO+Random方法</td><td>—</td><td>1.420</td></tr><tr><td><br />lbp-top方法</td><td>97.680</td><td>9.320</td></tr><tr><td><br />Lbp+lda方法</td><td>—</td><td>9.500</td></tr><tr><td><br />HOOF+LDA (thresholding) 方法</td><td>—</td><td>3.780</td></tr><tr><td><br />HOOF+LDA (NN) 方法</td><td>—</td><td>2.420</td></tr><tr><td><br />LFDNet方法</td><td>97.892</td><td>3.110</td></tr><tr><td><br />CNN方法</td><td>—</td><td>2.400</td></tr><tr><td><br />n-LBPnet方法</td><td>—</td><td>0.130</td></tr><tr><td><br />本文方法</td><td>98.891</td><td>1.750</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="98">经过上述对于不同方法在Replay-attack数据库和CASIA-FASD数据库上的准确率以及HTER值的比较, 可见, 本文方法准确率优于其他方法, 且泛化力大幅提升。</p>
                </div>
                <h3 id="99" name="99" class="anchor-tag">3 结束语</h3>
                <div class="p1">
                    <p id="100">本文提出一种基于微调策略的人脸活体检测方法。通过融合运动信息和图像质量信息, 提高人脸活体检测的泛化力, 利用卷积神经网络进行训练, 并采用网络微调技术判断真假活体。实验结果表明, 该方法相对其他方法具有较高的人脸活体检测准确度和泛化力。下一步可将动态纹理特征作为网络输入, 并将其应用到并行计算上。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Eyelink-based Anti-spoofing in Face Recognition from a Generic Webcamera">

                                <b>[1]</b> PAN Gang, SUN Lin, WU Zhaohui, et al.Eyeblink-based anti-spoofing in face recognition from a generic webcamera[C]//Proceedings of the 11th International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2007:1-8.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-Time Face Detection and Motion Analysis With Application in “Liveness” Assessment">

                                <b>[2]</b> KOLLREIDER K, FRONTHALER H, FARAJ M I, et al.Real-time face detection and motion analysis with application in “liveness” assessment[J].IEEE Transactions on Information Forensics and Security, 2007, 2 (3) :548-558
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;A liveness detection method for face recognition based on optical flow field&amp;quot;">

                                <b>[3]</b> BAO Wei, LI Hong, LI Nan, et al.A liveness detection method for face recognition based on optical flow field[C]//Proceedings of International Conference on Image Analysis and Signal Processing.Washington D.C., USA:IEEE Press, 2009:233-236.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201603030&amp;v=MjQ0MzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkzbVY3N0lMejdZYWJHNEg5Zk1ySTlHWkk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 任安虎, 刘贝.基于Adaboost的人脸识别眨眼检测[J].计算机与数字工程, 2016, 44 (3) :521-524.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face recognition with liveness detection using eye and mouth movement">

                                <b>[5]</b> SINGH A K, JOSHI P, NANDI G C.Face recognition with liveness detection using eye and mouth movement[C]//Proceedings of International Conference on Signal Propagation and Computer Technology.Washington D.C., USA:IEEE Press, 2014:592-597.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Motion-based counter-measures to photo attacks in face recognition">

                                <b>[6]</b> ANJOS A, CHAKKA M M, MARCEL S.Motion-based counter-measures to photo attacks in face recognition[J].IET Biometrics, 2014, 3 (3) :147-158
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face Spoofing Detection From Single Images Using MicroTexture Analysis">

                                <b>[7]</b> MAATTA J, HADID A, PIETIKAINEN M.Face spoofing detection from single images using micro-texture analysis[C]//Proceedings of International Joint Conference on Biometrics.Washington D.C., USA:IEEE Press, 2011:1-7.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WHCH201503006&amp;v=Mjc5NzJySTlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkzbVY3N0lNaVhJWnJHNEg5VE0=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 方天红, 陈庆虎, 廖海斌, 等.融合纹理与形状的人脸加权特征[J].武汉大学学报 (信息科学版) , 2015, 40 (3) :321-326, 340.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Masked fake face detection using radiance measurements">

                                <b>[9]</b> KIM Y, NA J, YOON S, et al.Masked fake face detection using radiance measurements[J].Journal of the Optical Society of America A-Optics Image Science and Vision, 2009, 26 (4) :760-766.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face livenessdetection by learning multispectral reflectancedistributions">

                                <b>[10]</b> ZHANG Zhiwei, YI Dong, LEI Zhen, et al.Face liveness detection by learning multispectral reflectance distributions[C]//Proceedings of IEEE International Conference on Automatic Face and Gesture Recognition and Workshops.Washington D.C., USA:IEEE Press, 2011:436-441.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501147219&amp;v=MzE0NjVlWnVIeWptVUxuSUpWMFFheEk9TmlmT2ZiSzdIdEROcW85RVplOElEbjB3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53Wg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> EASLEY G, LABATE D, LIM W Q.Sparse directional image representations using the discrete shearlet transform[J].Applied and Computational Harmonic Analysis, 2008, 25 (1) :25-46.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016785574.nh&amp;v=MzE4NjVMU3dHOVRMcTVFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5M21WNzdJVkYyNkc=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 许晓.基于深度学习的活体人脸检测算法研究[D].北京:北京工业大学, 2016.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Shearlets:multiscale analysis for multivariate data">

                                <b>[13]</b> KUTYNIOKG, LABATE D.Shearlets:multiscale analysis for multivariate data[M].[S.l.]:Birkhäuser Basel, 2012.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the effectiveness of local binary patterns in face anti-spoofing">

                                <b>[14]</b> CHINGOVSKA I, ANJOS A, MARCEL S.On the effectiveness of local binary patterns in face anti-spoofing[C]//Proceedings of International Conference of Biometrics Special Interest Group.Washington D.C., USA:IEEE Press, 2012:183-194.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A face antispoofing database with diverse attacks">

                                <b>[15]</b> ZHANG Zhiwei, YAN Junjie, LIU Sifei, et al.A face antispoofing database with diverse attacks[C]//Proceedings of the 5th IAPR International Conference on Biometrics.Washington D.C., USA:IEEE Press, 2012:26-31.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201905042" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201905042&amp;v=MjMxODI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTNtVjc3SUx6N0JiYkc0SDlqTXFvOUJab1FLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
