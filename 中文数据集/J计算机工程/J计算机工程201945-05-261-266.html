<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131349147957500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201905043%26RESULT%3d1%26SIGN%3d2EukZkmWdCajJDaDSsSJQnkuX3k%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201905043&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201905043&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201905043&amp;v=MTA0MjdlWmVSbkZ5cmtVTDdKTHo3QmJiRzRIOWpNcW85Qlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#44" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="1 微表情自动识别系统 ">1 微表情自动识别系统</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#49" data-title="1.1 微表情数据库">1.1 微表情数据库</a></li>
                                                <li><a href="#54" data-title="1.2 时空模式特征描述子">1.2 时空模式特征描述子</a></li>
                                                <li><a href="#61" data-title="1.3 信息增量特征选择">1.3 信息增量特征选择</a></li>
                                                <li><a href="#68" data-title="1.4 SVM分类器及核函数">1.4 SVM分类器及核函数</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#72" data-title="2 实验结果与分析 ">2 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#73" data-title="2.1 参数选择">2.1 参数选择</a></li>
                                                <li><a href="#77" data-title="2.2 结果分析">2.2 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="3 结束语 ">3 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#57" data-title="&lt;b&gt;图1 LBP描述子计算示例&lt;/b&gt;"><b>图1 LBP描述子计算示例</b></a></li>
                                                <li><a href="#59" data-title="&lt;b&gt;图2 特征提取示意图&lt;/b&gt;"><b>图2 特征提取示意图</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;表1 SMIC数据集上原特征向量和IG特征选择向量使用2种核函数的维数、时间以及分类识别准确率对比&lt;/b&gt;"><b>表1 SMIC数据集上原特征向量和IG特征选择向量使用2种核函数的维数、时间以及分类识别准确率对比</b></a></li>
                                                <li><a href="#80" data-title="&lt;b&gt;表2 2个数据集上原特征向量和IG特征选择向量的维数、时间以及直方图交叉核分类识别准确率对比&lt;/b&gt;"><b>表2 2个数据集上原特征向量和IG特征选择向量的维数、时间以及直方图交叉核分类识别准确率对比</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;表3 CASME2数据集上原特征向量和IG特征选择向量的维数、时间以及线性核、卡方核分类识别准确率对比&lt;/b&gt;"><b>表3 CASME2数据集上原特征向量和IG特征选择向量的维数、时间以及线性核、卡方核分类识别准确率对比</b></a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;图3 IG特征选择向量较原特征向量平均分类识别准确率提高的百分比&lt;/b&gt;"><b>图3 IG特征选择向量较原特征向量平均分类识别准确率提高的百分比</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;图4 IG特征选择向量维数占原特征向量维数的平均比例&lt;/b&gt;"><b>图4 IG特征选择向量维数占原特征向量维数的平均比例</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;图5 IG特征选择向量分类所需时间占原特征向量分类时间的平均比例&lt;/b&gt;"><b>图5 IG特征选择向量分类所需时间占原特征向量分类时间的平均比例</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="111">


                                    <a id="bibliography_1" title=" ROGIER A M.Communication without words[J].Tijdschrift Voor Ziekenverpleging, 1971, 24 (23) :1084-1085." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=[Communication without words]">
                                        <b>[1]</b>
                                         ROGIER A M.Communication without words[J].Tijdschrift Voor Ziekenverpleging, 1971, 24 (23) :1084-1085.
                                    </a>
                                </li>
                                <li id="113">


                                    <a id="bibliography_2" title=" 刘帅师, 田彦涛, 万川.基于Gabor多方向特征融合与分块直方图的人脸表情识别方法[J].自动化学报, 2011, 37 (12) :1455-1463." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201112006&amp;v=MDYxMDZPZVplUm5GeXJrVUw3SktDTGZZYkc0SDlETnJZOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         刘帅师, 田彦涛, 万川.基于Gabor多方向特征融合与分块直方图的人脸表情识别方法[J].自动化学报, 2011, 37 (12) :1455-1463.
                                    </a>
                                </li>
                                <li id="115">


                                    <a id="bibliography_3" title=" 李雅倩, 李颖杰, 李海滨, 等.融合全局与局部多样性特征的人脸表情识别[J].光学学报, 2014, 34 (5) :164-170." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201405027&amp;v=MTUzNjZHNEg5WE1xbzlIWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlya1VMN0pJalhUYkw=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         李雅倩, 李颖杰, 李海滨, 等.融合全局与局部多样性特征的人脸表情识别[J].光学学报, 2014, 34 (5) :164-170.
                                    </a>
                                </li>
                                <li id="117">


                                    <a id="bibliography_4" title=" 贲晛烨, 杨明强, 张鹏, 等.微表情自动识别综述[J].计算机辅助设计与图形学学报, 2014, 26 (9) :1385-1395." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201409001&amp;v=MTQ5MzZVTDdKTHo3QmFMRzRIOVhNcG85RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5cms=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         贲晛烨, 杨明强, 张鹏, 等.微表情自动识别综述[J].计算机辅助设计与图形学学报, 2014, 26 (9) :1385-1395.
                                    </a>
                                </li>
                                <li id="119">


                                    <a id="bibliography_5" title=" EKMAN P.Telling lies:clues to deceit in the marketplace, politics, and marriage (revised edition) [M].New York, USA:WW Norton and Company, 2009." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Telling lies:clues to deceit in the marketplace,politics,and marriage">
                                        <b>[5]</b>
                                         EKMAN P.Telling lies:clues to deceit in the marketplace, politics, and marriage (revised edition) [M].New York, USA:WW Norton and Company, 2009.
                                    </a>
                                </li>
                                <li id="121">


                                    <a id="bibliography_6" title=" EKMAN P.Darwin, deception, and facial expression[J].Annals of the New York Academy of Sciences, 2003, 1000 (1) :205-221." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001100638&amp;v=MDAxNDdIWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGQ0hsVWI3TElWOD1OaWZjYXJPNEh0SE5ybzlGWXVn&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         EKMAN P.Darwin, deception, and facial expression[J].Annals of the New York Academy of Sciences, 2003, 1000 (1) :205-221.
                                    </a>
                                </li>
                                <li id="123">


                                    <a id="bibliography_7" title=" 徐峰, 张军平.人脸微表情识别综述[J].自动化学报, 2017, 43 (3) :333-348." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201703002&amp;v=MDk1MzJGeXJrVUw3SktDTGZZYkc0SDliTXJJOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm4=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         徐峰, 张军平.人脸微表情识别综述[J].自动化学报, 2017, 43 (3) :333-348.
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_8" title=" EKMAN P.Micro expression training tool[M].San Francisco, USA:[s.n.], 2002." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Micro expression training tool">
                                        <b>[8]</b>
                                         EKMAN P.Micro expression training tool[M].San Francisco, USA:[s.n.], 2002.
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_9" title=" FRANK M G, HERBASZ M, SINUK K, et al.I see how you feel:training laypeople and professionals to recognize fleeting emotions[C]//Proceedings of the Annual Meeting of the International Communication Association.New York, USA:[s.n.], 2009:1-35." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=I see how you feel:Training laypeople and professionals to recognize fleeting emotions">
                                        <b>[9]</b>
                                         FRANK M G, HERBASZ M, SINUK K, et al.I see how you feel:training laypeople and professionals to recognize fleeting emotions[C]//Proceedings of the Annual Meeting of the International Communication Association.New York, USA:[s.n.], 2009:1-35.
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_10" title=" ZHAO Guoying, PIETIKAINEN M.Dynamic texture recognition using local binary patterns with an application to facial expressions[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 29 (6) :915-928." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dynamic Texture Recognition Using Local Binary Patterns with an Application to Facial Expressions">
                                        <b>[10]</b>
                                         ZHAO Guoying, PIETIKAINEN M.Dynamic texture recognition using local binary patterns with an application to facial expressions[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 29 (6) :915-928.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_11" title=" LI Xiaobai, HONG Xiaopeng, MOILANEN A, et al.Towards reading hidden emotions:a comparative study of spontaneous micro-expression spotting and recognition methods[J].IEEE Transactions on Affective Computing, 2018, 9 (4) :563-577." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Towards reading hidden emotions:a comparative study of spontaneous micro-expression spotting and recognition methods">
                                        <b>[11]</b>
                                         LI Xiaobai, HONG Xiaopeng, MOILANEN A, et al.Towards reading hidden emotions:a comparative study of spontaneous micro-expression spotting and recognition methods[J].IEEE Transactions on Affective Computing, 2018, 9 (4) :563-577.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_12" title=" LI Xiaobai, PFISTER T, HUANG Xiaohua, et al.A spontaneous micro-expression database:inducement, collection and baseline[C]//Proceedings of IEEE International Conference and Workshops on Automatic Face and Gesture Recognition.Washington D.C., USA:IEEE Press, 2013:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Spontaneous Micro-expression Database:Inducement,collection and baseline">
                                        <b>[12]</b>
                                         LI Xiaobai, PFISTER T, HUANG Xiaohua, et al.A spontaneous micro-expression database:inducement, collection and baseline[C]//Proceedings of IEEE International Conference and Workshops on Automatic Face and Gesture Recognition.Washington D.C., USA:IEEE Press, 2013:1-6.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_13" title=" PFISTER T, LI Xiaobai, ZHAO Guoying, et al.Recognising spontaneous facial micro-expressions[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2011:1449-1456." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recognizing spontaneous facial micro-expressions">
                                        <b>[13]</b>
                                         PFISTER T, LI Xiaobai, ZHAO Guoying, et al.Recognising spontaneous facial micro-expressions[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2011:1449-1456.
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_14" title=" YAN Wenjing, WU Qi, LIU Yongjin, et al.CASME database:a dataset of spontaneous micro-expressions collected from neutralized faces[C]//Proceedings of IEEE International Conference and Workshops on Automatic Face and Gesture Recognition.Washington D.C., USA:IEEE Press, 2013:1-7." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CASME database:a dataset of spontaneous micro-expressions collected from neutralized faces">
                                        <b>[14]</b>
                                         YAN Wenjing, WU Qi, LIU Yongjin, et al.CASME database:a dataset of spontaneous micro-expressions collected from neutralized faces[C]//Proceedings of IEEE International Conference and Workshops on Automatic Face and Gesture Recognition.Washington D.C., USA:IEEE Press, 2013:1-7.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_15" title=" OJALA T, HARWOOD I.A comparative study of texture measures with classification based on feature distributions[J].Pattern Recognition, 1996, 29 (1) :51-59." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600742093&amp;v=MjQ2NzVJSWw4WGF4TT1OaWZPZmJLN0h0RE5xWTlGWSs4TkRIVTZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         OJALA T, HARWOOD I.A comparative study of texture measures with classification based on feature distributions[J].Pattern Recognition, 1996, 29 (1) :51-59.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_16" title=" 刘丽, 谢毓湘, 魏迎梅, 等.局部二进制模式方法综述[J].中国图象图形学报, 2014, 19 (12) :1696-1720." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201412002&amp;v=MTc5MTE0TzN6cXFCdEdGckNVUkxPZVplUm5GeXJrVUw3SlB5cmZiTEc0SDlYTnJZOUZab1FLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         刘丽, 谢毓湘, 魏迎梅, 等.局部二进制模式方法综述[J].中国图象图形学报, 2014, 19 (12) :1696-1720.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_17" title=" 卢官明, 杨成, 杨文娟, 等.基于LBP-TOP特征的微表情识别[J].南京邮电大学学报 (自然科学版) , 2017 (6) :1-7." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJYD201706002&amp;v=MjI3MzN5cmtVTDdKS3lmU2FyRzRIOWJNcVk5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkY=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         卢官明, 杨成, 杨文娟, 等.基于LBP-TOP特征的微表情识别[J].南京邮电大学学报 (自然科学版) , 2017 (6) :1-7.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_18" title=" ZHAO Guoying, AHONEN T, MATAS J, et al.Rotation-invariant image and video description with local binary pattern features[J].IEEE Transactions on Image Processing, 2012, 21 (4) : feature selection method for text categorization by using information gain, principal component analysis and genetic algorithm[J].Knowledge-Based Systems, 2011, 24 (7) :1024-1032." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501719222&amp;v=MzE2Mjc3SHRETnFvOUVZK29HRG40N29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlsOFhheE09TmlmT2ZiSw==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         ZHAO Guoying, AHONEN T, MATAS J, et al.Rotation-invariant image and video description with local binary pattern features[J].IEEE Transactions on Image Processing, 2012, 21 (4) : feature selection method for text categorization by using information gain, principal component analysis and genetic algorithm[J].Knowledge-Based Systems, 2011, 24 (7) :1024-1032.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_20" title=" 刘先省, 周林, 杜晓玉.基于目标权重和信息增量的传感器管理方法[J].电子学报, 2005, 33 (9) :1683-1687." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU200509034&amp;v=MjA0MjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5cmtVTDdKSVRmVGU3RzRIdFRNcG85R1lJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         刘先省, 周林, 杜晓玉.基于目标权重和信息增量的传感器管理方法[J].电子学报, 2005, 33 (9) :1683-1687.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_21" title=" PIETIKAINEN M.Towards a practical lipreading system[C]//Proceedings of International Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2011:137-144." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Towards a practical lipreading system">
                                        <b>[21]</b>
                                         PIETIKAINEN M.Towards a practical lipreading system[C]//Proceedings of International Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2011:137-144.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(05),261-266 DOI:10.19678/j.issn.1000-3428.0052002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于信息增量特征选择的微表情识别方法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%BB%B6%E8%89%AF&amp;code=07202205&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张延良</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%A2%E5%86%B0&amp;code=38732548&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卢冰</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8D%97%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86%E4%B8%8E%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0026206&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河南理工大学物理与电子信息学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>基于LBP-TOP、HOG-TOP、HIGO-TOP特征描述子的微表情识别方法通常提取到的特征向量维度较高, 计算复杂度较大, 运行时间较长, 识别准确率较低。为此, 提出一种基于信息增量 (IG) 特征选择的识别方法。运用IG特征选择方法对高维度特征向量进行降维, 提高识别效率。运用支持向量机分类器的线性核、卡方核、直方图交叉核进行留一交叉验证, 以完成分类任务。在SMIC和CASME2数据集上进行实验, 结果表明, 经IG选择后, 特征向量在2个数据集上的识别准确率分别达到76.22%和73.68%, 分类所需时间分别缩短为原方法的3.67%和3.64%, 验证了该方法的有效性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BE%AE%E8%A1%A8%E6%83%85%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">微表情识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BF%A1%E6%81%AF%E5%A2%9E%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信息增量;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%8F%E8%BF%B0%E5%AD%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征描述子;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SVM%E5%88%86%E7%B1%BB%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SVM分类器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A0%B8%E5%87%BD%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">核函数;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张延良 (1979—) , 男, 副教授、博士, 主研方向为微表情识别、人工智能、信号处理、机器学习;E-mail: ylzhang@ hpu. edu. cn;
                                </span>
                                <span>
                                    卢冰, 硕士研究生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61571339);</span>
                                <span>网络与交换技术国家重点实验室开放课题 (SKLNST-2016-1-02);</span>
                                <span>河南理工大学博士基金 (B2012-100);</span>
                    </p>
            </div>
                    <h1><b>Micro-Expression Recognition Method Based on Information Gain Feature Selection</b></h1>
                    <h2>
                    <span>ZHANG Yanliang</span>
                    <span>LU Bing</span>
            </h2>
                    <h2>
                    <span>School of Physics and Electronic Information Engineering, Henan Polytechnic University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Micro-expression recognition method based on feature descriptor of LBP-TOP, HOG-TOP and HIGO-TOP usually extract feature vectors with high dimensions, and have high computation complexity, long running time and low recognition accuracy.Therefore, a recognition method based on Information Gain (IG) feature selection is proposed.The IG feature selection method is applied to reduce the dimensions of feature vectors and improve the recognition efficiency.The Leave-One-Subject-Out Cross Validation is performed for the micro-expression classification with linear kernel, chi-square kernel and histogram intersection kernel of Support Vector Machine (SVM) classifier.On the SMIC and CASME2 datasets, the recognition accuracy of feature vectors selected by IG achicves 76.22% and 73.68% respectively.And the time required for classification is only 3.67% and 3.64% of the original method.These results prove the effectiveness of the proposed method.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=micro-expression%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">micro-expression recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Information%20Gain%20(IG)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Information Gain (IG) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20descriptors&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature descriptors;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SVM%20classifier&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SVM classifier;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=kernel%20functions&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">kernel functions;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-07-03</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="44" name="44" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="45">表情是一种非言语行为, 能够展现人的情感。心理学家认为, “情感表达”由55%的表情、38%的声音和7%的语言组成<citation id="151" type="reference"><link href="111" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 这足以证明表情信息的巨大作用。在过去的几十年里, 人脸表情识别得到广泛的研究<citation id="153" type="reference"><link href="113" rel="bibliography" /><link href="115" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>, 其中大多以普通表情为研究对象。除了人脸普通表情外, 在心理抑制状态下, 面部肌肉不受控制而产生的微表情<citation id="152" type="reference"><link href="117" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 同样具有巨大的研究价值。</p>
                </div>
                <div class="p1">
                    <p id="46">微表情的持续时间较短, 一般为1/25 s～1/3 s, 且动作幅度非常小<citation id="157" type="reference"><link href="119" rel="bibliography" /><link href="121" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>。因此, 正确观测并识别微表情的难度较大<citation id="154" type="reference"><link href="123" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 用裸眼准确捕捉和识别微表情的成功率很低。文献<citation id="155" type="reference">[<a class="sup">8</a>]</citation>开发了微表情识别训练工具METT, 以提高对微表情的识别准确率。然而, 经过专业训练后, 其识别准确率仅达到47%<citation id="156" type="reference"><link href="127" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。近年来, 运用计算机视觉来自动识别微表情的方法受到越来越多的关注。</p>
                </div>
                <div class="p1">
                    <p id="47">特征提取是利用计算机视觉技术自动识别微表情的重要环节, 特征描述子LBP-TOP<citation id="158" type="reference"><link href="129" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、HOG-TOP<citation id="159" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、HIGO-TOP<citation id="160" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>是特征提取的常用方法。然而, 这些方法提取的特征向量维数较大, 识别时间较长, 识别准确率较低。由于大维数的特征向量中包含与微表情无关的特征分量, 因此正确分离无关分量, 只提取相关分量, 可提高计算机识别微表情的准确率。本文运用信息增益 (Information Gain, IG) 算法进行特征选择, 以各特征分量为分类系统提供的信息量作为特征选择的标准。利用SVM分类器的3种核函数实现留一交叉验证。</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag">1 微表情自动识别系统</h3>
                <h4 class="anchor-tag" id="49" name="49">1.1 微表情数据库</h4>
                <div class="p1">
                    <p id="50">微表情是人在试图掩饰自己情绪时产生的微小面部动作<citation id="161" type="reference"><link href="123" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。从严格意义上讲, 人们主观模拟的微小表情不能称为微表情, 因此微表情的诱导方式决定数据的可靠程度。</p>
                </div>
                <div class="p1">
                    <p id="51">微表情数据集SMIC<citation id="162" type="reference"><link href="133" rel="bibliography" /><link href="135" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>由芬兰奥卢大学建立, 其要求被试者观看有较大情绪波动的视频, 并且试图掩盖自己的情绪, 记录者在不观看视频的情况下观察被试者的表情。若记录者观察出被试者的面部表情, 则被试者就会得到惩罚。在这种诱导机制下, 获得了16个人的164个视频序列, 其微表情类别有积极、惊讶、消极3种, 视频序列数分别为70、51、43。</p>
                </div>
                <div class="p1">
                    <p id="52">微表情数据集CASME2<citation id="163" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>由中国科学院心理研究所建立, 采用类似的诱导机制来确保数据的可靠性。如果被试者成功抑制自己的面部表情并且不被记录者发现, 就会得到相应的奖励。该数据集由26个人的247个视频序列组成, 微表情类别分为高兴、厌恶、惊讶、压抑、其他5种, 视频序列数分别为32、64、25、27、99。</p>
                </div>
                <div class="p1">
                    <p id="53">其他数据集没有类似的诱导机制来保障数据的可靠性, 因此, 本文选用SMIC和CASME2数据集进行实验。</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54">1.2 时空模式特征描述子</h4>
                <div class="p1">
                    <p id="55">特征提取算法有很多, 早期的纹理分析采用局部二值模式 (Local Binary Pattern, LBP) <citation id="164" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>算法。目前, 该方法已成为纹理分类和人脸识别领域主要的特征提取方法之一<citation id="165" type="reference"><link href="141" rel="bibliography" /><link href="143" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="56">LBP描述子定义在中心像素及其周围矩形邻域上, 以中心像素的灰度值为阈值, 二值量化中心像素周围的邻域像素, 大于或等于中心像素值的编码为1, 小于则编码为0, 从而形成局部二进制模式, 如图1所示。以该二进制模式的左上角为起点, 按照顺时针方向进行串联, 得到一串二进制数字, 其对应的十进制数字能够唯一标识中心像素点。通过该方法, 图像中的每一个像素都可以用一个局部二进制模式来表示。</p>
                </div>
                <div class="area_img" id="57">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905043_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 LBP描述子计算示例" src="Detail/GetImg?filename=images/JSJC201905043_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 LBP描述子计算示例</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905043_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="58">文献<citation id="166" type="reference">[<a class="sup">10</a>]</citation>提出3个正交平面上的2维局部二值模式, 它是原始LBP静态纹理描述子在时空域的延伸, 如图2所示, 分别提取视频序列在<i>XY</i>、<i>XT</i>及<i>YT</i>3个正交平面的LBP特征。将每个正交平面上的特征向量进行串联, 组成LBP-TOP特征向量, 既考虑图像的局部纹理信息, 同时对视频随时间变化的情况进行描述。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905043_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 特征提取示意图" src="Detail/GetImg?filename=images/JSJC201905043_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 特征提取示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905043_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="60">然而, LBP-TOP的向量维数是3×2<sup><i>P</i></sup>, <i>P</i>是领域点的个数。为了改善LBP-TOP大维数计算的缺点, 提高识别效果, 本文采用均匀LBP-TOP描述子<citation id="167" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>, 其向量维数为3[<i>P</i> (<i>P</i>-1) +3]。而HOG-TOP、HIGO-TOP的向量维数均为3<i>P</i>。</p>
                </div>
                <h4 class="anchor-tag" id="61" name="61">1.3 信息增量特征选择</h4>
                <div class="p1">
                    <p id="62">信息增量<sup><a class="sup">[19]</a></sup>能评估特征分量间的差异, 为每个特征分量赋予不同的权重。权重越大, 该特征分量与其他分量间的差异就越大。信息熵的计算是确定信息增量的关键环节, 过程如下:</p>
                </div>
                <div class="p1">
                    <p id="63"><i>Entropy</i> (<i>S</i>) =-<i>p</i><sub>+</sub>lb <i>p</i><sub>+</sub>-<i>p</i><sub>-</sub>lb <i>p</i><sub>-</sub></p>
                </div>
                <div class="p1">
                    <p id="64">其中, -<i>p</i><sub>-</sub>和-<i>p</i><sub>+</sub>分别为分类错误和分类正确的概率。信息熵只描述特征分量的不确定性, 并不直接反映信息的多少。只有信息熵的变化才能产生信息, 该变化值即为信息增量<citation id="168" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="65">信息增量计算过程如下:</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mi>a</mi><mi>i</mi><mi>n</mi><mo stretchy="false"> (</mo><mi>S</mi><mo>, </mo><mi>F</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>E</mi><mi>n</mi><mi>t</mi><mi>r</mi><mi>o</mi><mi>p</mi><mi>y</mi><mo stretchy="false"> (</mo><mi>S</mi><mo stretchy="false">) </mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>v</mi><mo>∈</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mi>F</mi><msub><mrow></mrow><mi>m</mi></msub></mrow></munder><mrow><mfrac><mrow><mo stretchy="false">|</mo><mi>S</mi><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">|</mo></mrow><mrow><mo stretchy="false">|</mo><mi>S</mi><mo stretchy="false">|</mo></mrow></mfrac></mrow></mstyle><mi>E</mi><mi>n</mi><mi>t</mi><mi>r</mi><mi>o</mi><mi>p</mi><mi>y</mi><mo stretchy="false"> (</mo><mi>S</mi><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">其中, <i>valueF</i><sub><i>m</i></sub>是第<i>m</i>个特征值的集合, <i>F</i><sub><i>m</i></sub> (<i>m</i>=1, 2, …, <i>d</i>) 为所有微表情样本的集合, <i>S</i><sub><i>v</i></sub>为<i>F</i><sub><i>m</i></sub>第<i>v</i>个样本的子集, <i>S</i>是<i>F</i><sub><i>m</i></sub>的全部样本。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68">1.4 SVM分类器及核函数</h4>
                <div class="p1">
                    <p id="69">支持向量机 (Support Vector Machine, SVM) 是一种监督学习模型, 可用于数据分析、模式识别、分类和回归分析等, 它在解决小样本、非线性及高维模式的问题时, 具有很多优势。SVM的关键在于核函数, 采用不同的核函数会得到不同的分类结果。本文使用的核函数有线性核、卡方核、直方图交叉核。</p>
                </div>
                <div class="p1">
                    <p id="70">交叉验证 (Cross Validation, CV) 是用来验证分类器性能的一种统计分析方法。其基本思想是将样本数据集分成2个子集:一个用于训练分类器, 称为训练集;另一个用于验证分析分类器的有效性, 称为测试集。利用测试集来测试训练得到的分类器, 以此作为分类器的性能指标。常用的测试方法有简单交叉验证、K折交叉验证和留一交叉验证。</p>
                </div>
                <div class="p1">
                    <p id="71">留一交叉验证的样本利用率最高, 适合小样本的分类计算。因此, 本文使用留一交叉验证方法进行实验。每次选择一位受试者的所有视频序列作为测试样本, 其余<i>n</i>位受试者的所有视频序列作为训练样本, 重复<i>n</i>+1次实验, 并计算平均分类识别准确率。</p>
                </div>
                <h3 id="72" name="72" class="anchor-tag">2 实验结果与分析</h3>
                <h4 class="anchor-tag" id="73" name="73">2.1 参数选择</h4>
                <div class="p1">
                    <p id="74">微表情的发生时间较短, 标准相机在正常情况下提取到的微表情帧数较少, 不利于针对微表情识别的研究。文献<citation id="169" type="reference">[<a class="sup">11</a>]</citation>利用时间插值模型 (Temporal Interpolation Model, TIM) <citation id="170" type="reference"><link href="149" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>来扩展和标准化微表情视频序列, 处理后的视频序列用于微表情分类, 用时少, 效果好。本文采用TIM10对SMIC数据集和CASME2数据集进行预处理。</p>
                </div>
                <div class="p1">
                    <p id="75">SMIC数据集和CASME2数据集中的微表情视频序列按照参数 (<i>n</i>, <i>m</i>, <i>t</i>) 分为 (4, 4, 1) 、 (4, 4, 2) 、 (4, 4, 3) 、 (5, 5, 1) 、 (5, 5, 2) 、 (5, 5, 3) 、 (6, 6, 1) 、 (6, 6, 2) 、 (6, 6, 3) 9个分块, 在<i>XY</i>、<i>XT</i>和<i>YT</i> 3个正交面上分别采用均匀LBP<citation id="171" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、HOG、HIGO特征描述子, 按照半径<i>R</i>=1、邻域点<i>P</i>=8进行特征提取。将提取到的特征向量进行串联, 形成LBP-TOP、HOG-TOP、HIGO-TOP原特征向量。</p>
                </div>
                <div class="p1">
                    <p id="76">采用IG算法进行特征选择, 得到IG特征选择向量。采用留一交叉验证的方式进行微表情的分类实验, 其测试条件为Windows7操作系统、4 GB内存, 编程环境为Matlab 2016a。</p>
                </div>
                <h4 class="anchor-tag" id="77" name="77">2.2 结果分析</h4>
                <div class="p1">
                    <p id="78">表1～表3给出2个数据集上, 原特征向量和IG特征选择向量的维数、分类所需时间, 以及该特征维数下微表情识别的准确率。原<i>D</i>代表原特征向量的维数, <i>D</i>代表IG选择后的特征向量维数, <i>T</i>、<i>Acc</i>代表在该特征向量下分类所需的时间和分类识别准确率。</p>
                </div>
                <div class="area_img" id="79">
                                            <p class="img_tit">
                                                <b>表1 SMIC数据集上原特征向量和IG特征选择向量使用2种核函数的维数、时间以及分类识别准确率对比</b>
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905043_07900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201905043_07900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905043_07900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 SMIC数据集上原特征向量和IG特征选择向量使用2种核函数的维数、时间以及分类识别准确率对比" src="Detail/GetImg?filename=images/JSJC201905043_07900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="80">
                                            <p class="img_tit">
                                                <b>表2 2个数据集上原特征向量和IG特征选择向量的维数、时间以及直方图交叉核分类识别准确率对比</b>
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905043_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201905043_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905043_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 2个数据集上原特征向量和IG特征选择向量的维数、时间以及直方图交叉核分类识别准确率对比" src="Detail/GetImg?filename=images/JSJC201905043_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="81">
                                            <p class="img_tit">
                                                <b>表3 CASME2数据集上原特征向量和IG特征选择向量的维数、时间以及线性核、卡方核分类识别准确率对比</b>
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905043_08100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201905043_08100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905043_08100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 CASME2数据集上原特征向量和IG特征选择向量的维数、时间以及线性核、卡方核分类识别准确率对比" src="Detail/GetImg?filename=images/JSJC201905043_08100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="82">由表1～表3可以看出, 在SMIC数据集和CASME2数据集上, IG选择特征向量的最高识别准确率 (表2中加粗) 分别为76.22%和73.68%, 较原特征向量提高了42.04%和66.96%;其特征向量维数占原特征向量维数的比例均为3.66%;分类所需时间占原特征向量分类时间的比例分别为3.67%和3.64%。综上, 经IG选择后的特征向量, 其维数、分类时间较原特征向量大幅下降, 识别准确率大幅提高。</p>
                </div>
                <div class="p1">
                    <p id="83">为了从总体和平均2个角度分析IG特征选择方法的性能, 分别在SMIC数据集和CASME2数据集上, 对数据集、特征描述子、分类核函数不同的分块进行分类, 结果如图3～图5所示。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905043_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 IG特征选择向量较原特征向量平均分类识别准确率提高的百分比" src="Detail/GetImg?filename=images/JSJC201905043_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 IG特征选择向量较原特征向量平均分类识别准确率提高的百分比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905043_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905043_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 IG特征选择向量维数占原特征向量维数的平均比例" src="Detail/GetImg?filename=images/JSJC201905043_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 IG特征选择向量维数占原特征向量维数的平均比例</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905043_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905043_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 IG特征选择向量分类所需时间占原特征向量分类时间的平均比例" src="Detail/GetImg?filename=images/JSJC201905043_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 IG特征选择向量分类所需时间占原特征向量分类时间的平均比例</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905043_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="87">由图3～图5可知, 在SMIC数据集上, 采用线性核函数、LBP-TOP特征描述子时, IG特征选择后的维数和时间是原方法的9.00%和26.49%, 而平均识别准确率提高28.42%。在CASME2数据集上, 应用直方图交叉核函数、LBP-TOP特征描述子时, IG特征选择后的维数和时间是原方法的5.05%和4.04%, 而平均识别准确率提高57.68%。上述分析从总体和平均的角度证明IG特征选择方法的有效性。</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag">3 结束语</h3>
                <div class="p1">
                    <p id="89">本文提出一种基于IG特征选择的微表情识别分类方法, 通过IG选择对微表情特征进行降维、择优选取。利用SVM分类器的3种核函数实现留一交叉验证。实验结果表明, 该方法简单有效。在微表情SMIC和CASME2数据集上, 经IG选择后特征向量的识别准确率提高, 分类所需时间大幅缩短。下一步将寻找更好的特征选择算法, 提高微表情识别准确率。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="111">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=[Communication without words]">

                                <b>[1]</b> ROGIER A M.Communication without words[J].Tijdschrift Voor Ziekenverpleging, 1971, 24 (23) :1084-1085.
                            </a>
                        </p>
                        <p id="113">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201112006&amp;v=Mjk0NzBETnJZOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXJrVUw3SktDTGZZYkc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 刘帅师, 田彦涛, 万川.基于Gabor多方向特征融合与分块直方图的人脸表情识别方法[J].自动化学报, 2011, 37 (12) :1455-1463.
                            </a>
                        </p>
                        <p id="115">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201405027&amp;v=MjY3ODg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXJrVUw3SklqWFRiTEc0SDlYTXFvOUhZNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 李雅倩, 李颖杰, 李海滨, 等.融合全局与局部多样性特征的人脸表情识别[J].光学学报, 2014, 34 (5) :164-170.
                            </a>
                        </p>
                        <p id="117">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201409001&amp;v=MjcyMzFuRnlya1VMN0pMejdCYUxHNEg5WE1wbzlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 贲晛烨, 杨明强, 张鹏, 等.微表情自动识别综述[J].计算机辅助设计与图形学学报, 2014, 26 (9) :1385-1395.
                            </a>
                        </p>
                        <p id="119">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Telling lies:clues to deceit in the marketplace,politics,and marriage">

                                <b>[5]</b> EKMAN P.Telling lies:clues to deceit in the marketplace, politics, and marriage (revised edition) [M].New York, USA:WW Norton and Company, 2009.
                            </a>
                        </p>
                        <p id="121">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001100638&amp;v=MzE2MDZIbFViN0xJVjg9TmlmY2FyTzRIdEhOcm85Rll1Z0hZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZD&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> EKMAN P.Darwin, deception, and facial expression[J].Annals of the New York Academy of Sciences, 2003, 1000 (1) :205-221.
                            </a>
                        </p>
                        <p id="123">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201703002&amp;v=MDM1MzFuRnlya1VMN0pLQ0xmWWJHNEg5Yk1ySTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 徐峰, 张军平.人脸微表情识别综述[J].自动化学报, 2017, 43 (3) :333-348.
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Micro expression training tool">

                                <b>[8]</b> EKMAN P.Micro expression training tool[M].San Francisco, USA:[s.n.], 2002.
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=I see how you feel:Training laypeople and professionals to recognize fleeting emotions">

                                <b>[9]</b> FRANK M G, HERBASZ M, SINUK K, et al.I see how you feel:training laypeople and professionals to recognize fleeting emotions[C]//Proceedings of the Annual Meeting of the International Communication Association.New York, USA:[s.n.], 2009:1-35.
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dynamic Texture Recognition Using Local Binary Patterns with an Application to Facial Expressions">

                                <b>[10]</b> ZHAO Guoying, PIETIKAINEN M.Dynamic texture recognition using local binary patterns with an application to facial expressions[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 29 (6) :915-928.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Towards reading hidden emotions:a comparative study of spontaneous micro-expression spotting and recognition methods">

                                <b>[11]</b> LI Xiaobai, HONG Xiaopeng, MOILANEN A, et al.Towards reading hidden emotions:a comparative study of spontaneous micro-expression spotting and recognition methods[J].IEEE Transactions on Affective Computing, 2018, 9 (4) :563-577.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Spontaneous Micro-expression Database:Inducement,collection and baseline">

                                <b>[12]</b> LI Xiaobai, PFISTER T, HUANG Xiaohua, et al.A spontaneous micro-expression database:inducement, collection and baseline[C]//Proceedings of IEEE International Conference and Workshops on Automatic Face and Gesture Recognition.Washington D.C., USA:IEEE Press, 2013:1-6.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recognizing spontaneous facial micro-expressions">

                                <b>[13]</b> PFISTER T, LI Xiaobai, ZHAO Guoying, et al.Recognising spontaneous facial micro-expressions[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2011:1449-1456.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CASME database:a dataset of spontaneous micro-expressions collected from neutralized faces">

                                <b>[14]</b> YAN Wenjing, WU Qi, LIU Yongjin, et al.CASME database:a dataset of spontaneous micro-expressions collected from neutralized faces[C]//Proceedings of IEEE International Conference and Workshops on Automatic Face and Gesture Recognition.Washington D.C., USA:IEEE Press, 2013:1-7.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600742093&amp;v=MTE0Mzg5RlkrOE5ESFU2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSWw4WGF4TT1OaWZPZmJLN0h0RE5xWQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> OJALA T, HARWOOD I.A comparative study of texture measures with classification based on feature distributions[J].Pattern Recognition, 1996, 29 (1) :51-59.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201412002&amp;v=MDY3MzVGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlya1VMN0pQeXJmYkxHNEg5WE5yWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 刘丽, 谢毓湘, 魏迎梅, 等.局部二进制模式方法综述[J].中国图象图形学报, 2014, 19 (12) :1696-1720.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJYD201706002&amp;v=MjAxNTlKS3lmU2FyRzRIOWJNcVk5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5cmtVTDc=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 卢官明, 杨成, 杨文娟, 等.基于LBP-TOP特征的微表情识别[J].南京邮电大学学报 (自然科学版) , 2017 (6) :1-7.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501719222&amp;v=MjU4MjlMYklJbDhYYXhNPU5pZk9mYks3SHRETnFvOUVZK29HRG40N29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> ZHAO Guoying, AHONEN T, MATAS J, et al.Rotation-invariant image and video description with local binary pattern features[J].IEEE Transactions on Image Processing, 2012, 21 (4) : feature selection method for text categorization by using information gain, principal component analysis and genetic algorithm[J].Knowledge-Based Systems, 2011, 24 (7) :1024-1032.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU200509034&amp;v=MTc4NjNVUkxPZVplUm5GeXJrVUw3SklUZlRlN0c0SHRUTXBvOUdZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 刘先省, 周林, 杜晓玉.基于目标权重和信息增量的传感器管理方法[J].电子学报, 2005, 33 (9) :1683-1687.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Towards a practical lipreading system">

                                <b>[21]</b> PIETIKAINEN M.Towards a practical lipreading system[C]//Proceedings of International Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2011:137-144.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201905043" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201905043&amp;v=MTA0MjdlWmVSbkZ5cmtVTDdKTHo3QmJiRzRIOWpNcW85Qlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmF3cmhWVUU1ZkxoamhGOGFaaz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
