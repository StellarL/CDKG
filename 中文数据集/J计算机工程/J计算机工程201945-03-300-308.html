<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130640250118750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201903050%26RESULT%3d1%26SIGN%3dvT8%252b7Dtp3M%252fgFWh6N8XFzLtaihk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903050&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903050&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903050&amp;v=MTE2OTFvRnk3bVVyekpMejdCYmJHNEg5ak1ySTlBWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#56" data-title="2 GMP-CNN模型 ">2 GMP-CNN模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="2.1 输入层">2.1 输入层</a></li>
                                                <li><a href="#65" data-title="2.2 深度卷积结构">2.2 深度卷积结构</a></li>
                                                <li><a href="#100" data-title="2.3 点积层与输出层">2.3 点积层与输出层</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="3 GMP-CNN模型训练 ">3 GMP-CNN模型训练</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#119" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#120" data-title="4.1 情感分析数据集">4.1 情感分析数据集</a></li>
                                                <li><a href="#124" data-title="4.2 模型超参数设定">4.2 模型超参数设定</a></li>
                                                <li><a href="#129" data-title="4.3 词向量预训练">4.3 词向量预训练</a></li>
                                                <li><a href="#131" data-title="4.4 GMP-CNN模型结构设置">4.4 GMP-CNN模型结构设置</a></li>
                                                <li><a href="#134" data-title="4.5 结果分析">4.5 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#156" data-title="5 结束语 ">5 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="&lt;b&gt;图1 情感分类标注中并行结构的CNN模型&lt;/b&gt;"><b>图1 情感分类标注中并行结构的CNN模型</b></a></li>
                                                <li><a href="#60" data-title="&lt;b&gt;图2 GMP-CNN模型&lt;/b&gt;"><b>图2 GMP-CNN模型</b></a></li>
                                                <li><a href="#74" data-title="&lt;b&gt;图3 基于same卷积操作的卷积层&lt;/b&gt;"><b>图3 基于same卷积操作的卷积层</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;图4 分类模块&lt;/b&gt;"><b>图4 分类模块</b></a></li>
                                                <li><a href="#123" data-title="&lt;b&gt;表1 SSTb数据集划分结果&lt;/b&gt;"><b>表1 SSTb数据集划分结果</b></a></li>
                                                <li><a href="#127" data-title="&lt;b&gt;表2 GMP-CNN超参数设定&lt;/b&gt;"><b>表2 GMP-CNN超参数设定</b></a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;表3 实验模型结构设定&lt;/b&gt;"><b>表3 实验模型结构设定</b></a></li>
                                                <li><a href="#139" data-title="&lt;b&gt;图5 GMP-CNN与parallel-CNN模型训练时间对比&lt;/b&gt;"><b>图5 GMP-CNN与parallel-CNN模型训练时间对比</b></a></li>
                                                <li><a href="#140" data-title="&lt;b&gt;图6 GMP-CNN与parallel-CNN模型预测时间对比&lt;/b&gt;"><b>图6 GMP-CNN与parallel-CNN模型预测时间对比</b></a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;图7 GMP-CNN与parallel-CNN模型训练正确率对比 (二分类&lt;/b&gt;) "><b>图7 GMP-CNN与parallel-CNN模型训练正确率对比 (二分类</b>) </a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;图8 GMP-CNN与parallel-CNN模型训练正确率对比 (五分类&lt;/b&gt;) "><b>图8 GMP-CNN与parallel-CNN模型训练正确率对比 (五分类</b>) </a></li>
                                                <li><a href="#146" data-title="&lt;b&gt;表4 在SSTb数据集上不同模型分类标注正确率&lt;/b&gt; %"><b>表4 在SSTb数据集上不同模型分类标注正确率</b> %</a></li>
                                                <li><a href="#155" data-title="&lt;b&gt;表5 经模型训练后的词向量变化情况&lt;/b&gt;"><b>表5 经模型训练后的词向量变化情况</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" MEDHAT W, HASSAN A, KORASHY H.Sentiment analysis algorithms and applications:a survey[J].Ain Shams Engineering Journal, 2014, 5 (4) :1093-1113." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14061700305623&amp;v=Mjk0OThqbVVMbklKbDBWYVJJPU5pZk9mYks4SHRmTnFJOUZaK3NLQ240Nm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         MEDHAT W, HASSAN A, KORASHY H.Sentiment analysis algorithms and applications:a survey[J].Ain Shams Engineering Journal, 2014, 5 (4) :1093-1113.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                     KUBLER S, MCDONALD R, NIVRE J.Synthesis lectures on human language technologies[EB/OL].[2018-01-05].http://www.morganclaypool.com/doi/abs/10.2200/S00416ED1V01Y201204HLT016.</a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                     PANG B, LEE L, VAITHYANATHAN S, et al.Sentiment classification using machine learning techniques[C]//Procedings of Empirical Methods in Natural Language Processing.Philadelphia, USA:Association for Computational Linguistics, 2002:79-86.</a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" >
                                        <b>[4]</b>
                                     MA M, HUANG L, ZHOU B, et al.Dependency-based convolutional neural networks for sentence embedding[EB/OL].[2018-01-05].http://www.oalib.com/paper/4048778.</a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     SANTOS C N D, GATTIT M.Deep convolutional neural networks for sentiment analysis of short texts[C]//Proceeding of the 25th International Conference on Computational Linguistics.Dublin, Ireland:[s.n.], 2014:69-78.</a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 刘龙飞, 杨亮, 张绍武, 等.基于卷积神经网络的微博情感倾向性分析[J].中文信息学报, 2015, 29 (6) :159-165." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201506022&amp;v=MTY0NjVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdtVXJ6SUtDallmYkc0SDlUTXFZOUhab1FLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         刘龙飞, 杨亮, 张绍武, 等.基于卷积神经网络的微博情感倾向性分析[J].中文信息学报, 2015, 29 (6) :159-165.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     LEE G, JEONG J, SEO S, et al.Sentiment classification with word attention based on weakly supervised learning with a convolutional neural network[EB/OL].[2018-01-05].https://arxiv.org/abs/1709.09885.</a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                     SANTOS C N D, XIANG B, ZHOU B.Classifying relations by ranking with convolutional neural networks[J].Computer Science, 2015, 86:132-137.</a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     WANG L, CAO Z, MELO G, et al.Relation classification via multi-level attention CNNs[C]//Proceeding of the 54th Annual Meeting of the Association for Computational Linguistics.Philadelphia, USA:Association for Computational Linguistics, 2016:1298-1307.</a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" >
                                        <b>[10]</b>
                                     LIN Y, SHEN S, LIU Z, et al.Neural relation extraction with selective attention over instances[C]//Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.Philadelphia, USA:Association for Computational Linguistics, 2016:2124-2133.</a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     DONG L, WEI F, XU K, et al.Adaptive multi-compositionality for recursive neural network models[J].IEEE Transactions on Audio, Speech, and Language Processing, 2016, 24 (3) :422-431.</a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" >
                                        <b>[12]</b>
                                     BENGIO Y, DUCHARME R, VINCENT P, et al.A neural probabilistic language model[J].Journal of Machine Learning Research, 2003, 3 (6) :1137-1155.</a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                     KIM Y.Convolutional neural networks for sentence classification[C]//Proceedings of Empirical Methods in Natural Language Processing.Philadelphia, USA:Association for Computational Linguistics, 2014:1746-1751.</a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[C]//Proceedings of International Conference on Learning Representations.Washington D.C., USA:IEEE Press, 2015:1-7.</a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" >
                                        <b>[15]</b>
                                     HE K, ZHANG X, REN S, et al.Deep residual learning for image recognition[C]//Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2016:770-778.</a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     LIN M, CHEN Q, YAN S.Network in network[EB/OL].[2018-01-05].https://arxiv.org/abs/1312.4400.</a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     SRIVASTAVA N, HINTON G E, KRIZHEVSKY A, et al.Dropout:a simple way to prevent neural networks from overfitting[J].Journal of Machine Learning Research, 2014, 15 (1) :1929-1958.</a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" >
                                        <b>[18]</b>
                                     SOCHER R, PERELYGIN A, WU J Y, et al.Recursive deep models for semantic compositionality over a sentiment treebank[C]//Proceedings of Empirical Methods in Natural Language Processing.Philadelphia, USA:Association for Computational Linguistics, 2013:1631-1642.</a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" >
                                        <b>[19]</b>
                                     PENNINGTON J, SOCHER R, CHRISTOPHER D, et al.GloVe:global vectors for word representation[C]//Proceedings of Empirical Methods in Natural Language Processing.Philadelphia, USA:Association for Computational Linguistics, 2014:1532-1543.</a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" >
                                        <b>[20]</b>
                                     TANG D, QIN B, LIU T, et al.Aspect level sentiment classification with deep memory network[EB/OL].[2018-01-05].https://arxiv.org/abs/1605.08900.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(03),300-308 DOI:10.19678/j.issn.1000-3428.0050043            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于深度卷积神经网络模型的文本情感分类</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="javascript:;">周锦峰</a>
                                <a href="javascript:;">叶施仁</a>
                                <a href="javascript:;">王晖</a>
                </h2>
                    <h2>

                    <span>常州大学信息科学与工程学院</span>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为高效提取不同卷积层窗口的文本局部语义特征, 提出一种深度卷积神经网络 (CNN) 模型。通过堆叠多个卷积层, 提取不同窗口的局部语义特征。基于全局最大池化层构建分类模块, 对每个窗口的局部语义特征计算情感类别得分, 综合类别得分完成情感分类标注。实验结果表明, 与现有CNN模型相比, 该模型具有较快的文本情感分类速度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感分析;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB%E6%A0%87%E6%B3%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感分类标注;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%8D%E5%90%91%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">词向量;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    周锦峰 (1978—) , 男, 硕士, 主研方向为机器学习、自然语言处理;;
                                </span>
                                <span>
                                    叶施仁, 副教授、博士;;
                                </span>
                                <span>
                                    *王晖 (通信作者) , 讲师、博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61272367);</span>
                                <span>江苏省科技厅项目 (BY2015027-12);</span>
                    </p>
            </div>
                    <h1><b>Text Sentiment Classification Based on Deep Convolutional Neural Network Model</b></h1>
                    <h2>
                    <span>ZHOU Jinfeng</span>
                    <span>YE Shiren</span>
                    <span>WANG Hui</span>
            </h2>
                    <h2>
                    <span>School of Information Science and Engineering, Changzhou University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>This paper proposes a deep Convolutional Neural Network (CNN) model to efficiently extract the local semantic features of different convolutional layer windows for text.The model avoids manually specifying multiple window sizes and retains local semantic features of different windows by stacking a number of convolutional layers.Classification modules are built based on the Global Max Pooling (GMP) layer to calculate the category score for the local semantic features of each window.The model synthesizes these category scores to complete the sentiment classification annotation.Experimental results show that the model has faster text sentiment classification speed than that of other CNN models.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sentiment%20analysis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sentiment analysis;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sentiment%20classification%20annotation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sentiment classification annotation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Neural%20Network%20(CNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Neural Network (CNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=word%20vector&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">word vector;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-10</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="44">情感分析主要通过人类书写的文本分析和研究人的意见、情感、评价、态度和情绪, 是自然语言处理 (Natural Language Processing, NLP) 中最热门的研究领域之一, 并在数据挖掘、Web挖掘和文本挖掘等应用范畴得到广泛研究<citation id="158" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。例如, 分析电商平台上对已购商品的点评, 群众对政府新颁布的政策法规的讨论以及消费者对新产品或服务的反馈等。每天数以亿计的用户文本信息包含了丰富的用户观点和情感极性, 从中可以挖掘和分析出大量的知识和模式。</p>
                </div>
                <div class="p1">
                    <p id="45">深度学习为经典数据挖掘任务提供了新的手段。卷积神经网络 (Convolutional Neural Network, CNN) 是一种用于处理具有网状拓扑结构数据的深度神经网络 (Deep Neural Network, DNN) 。CNN通过卷积操作, 组合低层特征形成更加抽象的高层特征, 使模型能够针对目标问题, 自动学习特征。在文本情感分类应用中, CNN能够有效避免传统机器学习方法所面临的样本特征表达稀疏、计算复杂等问题<citation id="159" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="46">目前, 以CNN为基础的文本情感分类方法多数是通过学习文本的一种窗口或多种窗口局部语义信息, 然后提取文本最大语义特征进行情感划分。此类方法在文本情感分类标注领域已取得较好的效果。但是目前在文本情感分类标注领域<citation id="161" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>, 甚至在NLP的其他分类问题中<citation id="162" type="reference"><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>, 使用的CNN模型多数采用一个或多个卷积层并行的结构。CNN模型解决情感分类标注问题时, 为了充分捕捉语义的距离依赖<citation id="160" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 需要提取不同上下文窗口的局部语义信息, 增强情感分类能力。但是, 卷积层并行的CNN模型使用超参数设定有限种窗口大小, 而且随着窗口增加, 模型计算量会大幅增加, 训练效率和预测速度也随之降低。</p>
                </div>
                <div class="p1">
                    <p id="47">为提高模型计算效率, 本文提出一种应用于全局最大池化 (Global Max Pooling, GMP) 层的深度卷积神经网络 (GMP-CNN) 模型, 进行文本情感分类标注。堆叠的卷积层能够逐层深入地提取窗口更大、抽象度更高的局部语义特征。由特殊的卷积层和GMP层构成的分类模块为不同窗口的局部语义特征计算情感类别得分, 得到文本情感分类标注, 并采用斯坦福情感树库 (Stanford Sentiment Treebank, SSTb) 数据集以验证GMP-CNN模型情感分类标注的有效性。</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag">1 相关工作</h3>
                <div class="p1">
                    <p id="49">文献<citation id="163" type="reference">[<a class="sup">3</a>]</citation>采用朴素贝叶斯模型、最大熵模型和支持向量机模型对文本进行情感分类。此后, 以传统机器学习为核心的情感分析模型层出不穷。为提高分类正确率, 传统机器学习方法使用大量文本特征。随着特征变多, 训练样本在每个特征上的描述会变得稀疏, 机器学习的计算复杂性成倍增加。由于文本特征需要人工构造, 因此特征越多, 人工成本越大。</p>
                </div>
                <div class="p1">
                    <p id="50">文献<citation id="164" type="reference">[<a class="sup">12</a>]</citation>提出分布式表示词向量的概念, 从大量未标注的语料库中无监督地学习词向量, 通过向量空间上的相似度表示文本语义上的相似度。由词向量序列构成文本的原始表示形式将文本内容的处理简化为<i>K</i>维向量空间中的向量运算。分布式表示词向量的出现有效解决了DNN输入部分对人工的依赖, 并推动DNN发展出新模型用于文本情感分类。</p>
                </div>
                <div class="p1">
                    <p id="51">文献<citation id="165" type="reference">[<a class="sup">13</a>]</citation>将CNN应用在文本分类任务, 并通过实验证明基于CNN的文本分类模型能够获得比传统机器学习模型更高的正确率。文本情感分类标注任务也属于文本分类任务, 因此, 作者使用CNN模型完成情感分类标注任务。文献<citation id="166" type="reference">[<a class="sup">5</a>]</citation>基于单词的构造 (以构成单词的字母为单位) , 提出CharSCNN模型。以CNN为基础的CharSCNN模型, 采用2个并行的卷积层分别学习单词的构造特征和句子的局部语义特征, 充分体现CNN对文本局部特征的抽象和提取能力。该模型在短文本情感分类时展示了较好效果, 有效论证CNN模型在进行句子情感分类标注时的可行性。文献<citation id="167" type="reference">[<a class="sup">6</a>]</citation>在CharSCNN模型基础上, 并行多个卷积层, 学习多种窗口的文本局部特征。对于中文语料, 该模型有效地完成情感二分类标注任务。文献<citation id="168" type="reference">[<a class="sup">7</a>]</citation>使用Word2Vec、GloVe和FastText多种词向量形成CNN模型的多通道输入, 同时使用avg池化方法代替max池化方法, 对于英文和韩文影评语料, 均取得较好的标注正确率。目前, 多数用于情感分类标注任务的CNN模型, 在基础结构上类似于文献<citation id="169" type="reference">[<a class="sup">13</a>]</citation>提出的CNN模型, 具有以下特点:</p>
                </div>
                <div class="p1">
                    <p id="52">1) 与计算机视觉领域应用的深度CNN不同, 一般使用多种卷积层的并行结构, 或者只有一个卷积层。</p>
                </div>
                <div class="p1">
                    <p id="53">2) CNN卷积核的大小需要与词向量维度匹配, 这使得卷积核至少在一个维度上比较大。</p>
                </div>
                <div class="p1">
                    <p id="54">3) 通常使用全连接层作为分类器, 将卷积层学习到的语义特征表示映射到样本标记空间。</p>
                </div>
                <div class="p1">
                    <p id="55">尽管上述CNN模型在处理情感分类标注时, 特别是情感二分类标注任务, 应用效果良好, 但是此类模型存在2个问题:1) 受并行结构的限制, 多提取一种窗口类型的局部语义特征需要增加一种并行的卷积层, 模型在训练和预测过程中的计算量会大幅增加;2) 作为分类器的全连接层参数量过大, 特别是以多种窗口的局部语义特征向量作为输入的全连接层, 使模型的训练和预测计算量增大, 降低了模型速度, 还会造成过拟合。针对以上问题, 本文提出GMP-CNN模型对文本进行情感分类标注。</p>
                </div>
                <h3 id="56" name="56" class="anchor-tag">2 GMP-CNN模型</h3>
                <div class="p1">
                    <p id="57">如图1所示, 经典的CNN模型解决情感分类标注问题时, 通常采用多个池化层并行的结构。将一个句子或一段文本以某种形式 (例如词向量序列) 输入到并行结构CNN模型 (parallel-CNN) 的多个并行卷积层。经过卷积操作, 提取文本的局部抽象语义<citation id="170" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。最大池化层对该局部语义表示进行降维, 同时保留某一个级别的语义特征, 通常保留最大语义特征。串接层将这些语义特征向量拼接成一个文本特征向量。全连接层对该特征向量进行进一步抽象, 计算出情感分析结果。</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903050_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 情感分类标注中并行结构的CNN模型" src="Detail/GetImg?filename=images/JSJC201903050_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 情感分类标注中并行结构的CNN模型</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903050_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="59">文献<citation id="171" type="reference">[<a class="sup">14</a>]</citation>指出多个小核卷积层堆叠产生一个大核卷积层的感知野, 受此启发, 本文提出GMP-CNN模型用于文本情感分类标注。如图2所示, GMP-CNN模型通过堆叠多个卷积层, 可逐层提取窗口越来越大、抽象度越来越高的文本局部语义特征用于情感多分类标注。在GMP-CNN模型中, 将卷积层产生的局部语义特征矩阵输入下一个卷积层以及分类模块。在分类模块中, 为不同窗口的局部语义特征分别计算情感类别得分。GMP-CNN模型在点积层综合各分类模块产生的情感类别得分, 得到最终的文本情感分类标注。</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903050_060.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 GMP-CNN模型" src="Detail/GetImg?filename=images/JSJC201903050_060.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 GMP-CNN模型</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903050_060.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="61" name="61">2.1 输入层</h4>
                <div class="p1">
                    <p id="62">词向量是词的分布式表示, 将词表示为一个稠密低维度的向量, 包含一个词的语法和语义信息。给定由<i>n</i>个单词组成的一个文本样本{<i>wrd</i><sub>1</sub>, <i>wrd</i><sub>2</sub>, …, <i>wrd</i><sub><i>n</i></sub>}, 转换每个单词为其对应的<i>d</i><sup><i>wrd</i></sup>维词向量。设该样本中第<i>i</i>个单词<i>wrd</i><sub><i>i</i></sub>对应的词向量为<b><i>x</i></b><sub><i>i</i></sub>, <b><i>x</i></b><sub><i>i</i></sub>∈<image href="images/JSJC201903050_063.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>dwrd</i></sup>。该样本可以初始地表示成一个维度为<image href="images/JSJC201903050_064.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i><sup><i>wrd</i></sup>×<i>n</i></sup>的文本表示矩阵<b><i>S</i></b>=[<b><i>x</i></b><sub>1</sub>, <b><i>x</i></b><sub>2</sub>, …, <b><i>x</i></b><sub><i>n</i></sub>]。该初始表示矩阵作为GMP-CNN模型中第1个卷积层的输入。</p>
                </div>
                <h4 class="anchor-tag" id="65" name="65">2.2 深度卷积结构</h4>
                <div class="p1">
                    <p id="66"><i>CNN</i>模型通常使用不同的窗口对文本的词向量序列进行卷积操作, 提取局部语义特征。目前, 多数<i>CNN</i>模型以超参数方式设定单窗口大小<citation id="172" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>或多窗口大小<citation id="173" type="reference"><link href="13" rel="bibliography" /><link href="27" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">13</a>]</sup></citation>。通常指定的卷积窗口越多, 可以提取窗口种类越多的局部语义特征, 有助于完成情感分类标注任务。但由于超参数优化、网络规模和计算性能的限制, 预先能够指定的窗口种类有限。</p>
                </div>
                <div class="p1">
                    <p id="67">基于文献<citation id="174" type="reference">[<a class="sup">14</a>]</citation>的思想, <i>GMP</i>-<i>CNN</i>模型可以堆叠多个卷积层形成深度<i>CNN</i>模型。设模型有u层卷积层, 相比第k层卷积层, 第k+1层卷积层在第k层卷积层提取的局部语义特征基础上, 能提取窗口更大和抽象级别更高的语义特征。由于<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>k</mi><mo>∈</mo><mrow><mo>[</mo><mrow><mn>1</mn><mo>, </mo><mi>u</mi></mrow><mo>]</mo></mrow></mrow></math></mathml>, 因此如果<i>u</i>值足够大 (即堆叠层数足够多) , 则上下文窗口可以覆盖数据集中最长的文本长度, 相当于需要用一个大核的卷积层来捕捉语义的远距离依赖特征。因此, 使用小卷积核的卷积层堆叠产生一个大核的卷积层效果, 而且多个非线性操作代替一个单一的非线性 (或线性) 操作能使决策函数更具判别能力<citation id="175" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。GMP-CNN模型能产生大窗口的局部语义特征, 同时产生多种较小窗口的局部语义特征, 这些局部语义特征分别送至对应的分类模块进行分类计算。在超参数设定和调优方面, 只需为整个模型设定第1个卷积层的窗口大小<i>w</i>。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69">2.2.1 same卷积层</h4>
                <div class="p1">
                    <p id="70">在GMP-CNN模型中, 每个卷积层均执行窗口大小为<i>w</i>的same卷积操作。当卷积层输出通道数量与词向量维度相同时, same卷积操作可以确保每一层卷积层的输入矩阵与输出矩阵为同型矩阵, 方便深度堆叠卷积层。</p>
                </div>
                <div class="p1">
                    <p id="71">设第<i>k</i>层same卷积层有输入矩阵<b><i>P</i></b><sub><i>k</i></sub>=[<b><i>p</i></b><sub><i>k</i></sub><sub>, 1</sub>, <b><i>p</i></b><sub><i>k</i></sub><sub>, 2</sub>, …, <b><i>p</i></b><sub><i>k</i></sub><sub>, </sub><sub><i>n</i></sub>], <b><i>P</i></b><sub><i>k</i></sub>∈<image href="images/JSJC201903050_072.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i><sup><i>wrd</i></sup>×<i>n</i></sup>, <b><i>p</i></b><sub><i>k</i>, <i>i</i></sub>∈<image href="images/JSJC201903050_073.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i><sup><i>wrd</i></sup></sup>。如图3所示, <b><i>P</i></b><sub><i>k</i></sub>是第<i>k</i>-1层same卷积层的输出, 模型中第1层的same卷积层输入矩阵<b><i>P</i></b><sub>1</sub>=<b><i>S</i></b>。</p>
                </div>
                <div class="area_img" id="74">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903050_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 基于same卷积操作的卷积层" src="Detail/GetImg?filename=images/JSJC201903050_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 基于same卷积操作的卷积层</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903050_074.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="75">在进行same卷积计算时, 首先在<b><i>P</i></b><sub><i>k</i></sub>左右两端分别填充<i>w</i>-2个<b>0</b>向量, 形成矩阵<b><i>Q</i></b><sub><i>k</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Q</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mrow><mo>[</mo><mrow><mn>0</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mi>n</mi></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mn>0</mn></mrow><mo>]</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">其中, <b>0</b>向量维度为<image href="images/JSJC201903050_078.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i><sup><i>wrd</i></sup></sup>, <b><i>Q</i></b><sub><i>k</i></sub>∈<image href="images/JSJC201903050_079.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mrow><mi>d</mi><msup><mrow></mrow><mrow><mi>w</mi><mi>r</mi><mi>d</mi></mrow></msup><mo>×</mo><mrow><mo>[</mo><mrow><mi>n</mi><mo>+</mo><mn>2</mn><mo>*</mo><mrow><mo> (</mo><mrow><mi>w</mi><mo>-</mo><mn>2</mn></mrow><mo>) </mo></mrow></mrow><mo>]</mo></mrow></mrow></msup></mrow></math></mathml>。对<b><i>Q</i></b><sub><i>k</i></sub>进行卷积操作, 然后通过激活函数tanh, 计算得到第<i>k</i>层卷积层的局部语义特征矩阵<mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mrow><mo>[</mo><mrow><mi mathvariant="bold-italic">c</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mn>1</mn></mrow><mtext>Τ</mtext></msubsup><mo>, </mo><mi mathvariant="bold-italic">c</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mn>2</mn></mrow><mtext>Τ</mtext></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">c</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mi>n</mi></mrow><mtext>Τ</mtext></msubsup></mrow><mo>]</mo></mrow></mrow></math></mathml>, 其中<b><i>C</i></b><sub><i>k</i></sub>∈<image href="images/JSJC201903050_082.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i><sup><i>wrd</i></sup>×<i>n</i></sup>, 即基于窗口大小为 (<i>k</i>-1) (<i>w</i>-1) +<i>w</i>的局部语义特征矩阵。</p>
                </div>
                <div class="p1">
                    <p id="83">在进行same卷积层堆叠时, 相邻same卷积层相互衔接, 并没有加入池化层。这是因为池化层是降采样, 虽然保留某种显著特征, 但也会过早地丢弃其他特征信息。为使后继same卷积层在前层的基础上有效提取局部语义特征, GMP-CNN模型中相邻same卷积层之间没有增加任何形式的池化层。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84">2.2.2 分类模块</h4>
                <div class="p1">
                    <p id="85">受到<i>Anytime</i>-<i>Prediction</i>思想<citation id="176" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>和全局平均池化 (<i>Global Average Pooling</i>, <i>GAP</i>) 层<citation id="177" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的启发, 本文设计分类模块代替全连接层的功能, 如图4所示。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903050_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 分类模块" src="Detail/GetImg?filename=images/JSJC201903050_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 分类模块</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903050_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="87">GMP-CNN模型的分类模块包含2个层:输出通道数量与情感类别数量相同的卷积层和GMP层。将每层same卷积层的输出矩阵送入分类模块的卷积层中, 为每个类别生成一个类别特征矩阵, 然后GMP对类别特征矩阵应用全局最大池化操作, 产生一个类别得分向量。分类模块具体操作如下:</p>
                </div>
                <div class="p1">
                    <p id="88">1) 卷积层。第<i>k</i>层的局部语义特征矩阵<b><i>C</i></b><sub><i>k</i></sub>输入第<i>k</i>个分类模块的卷积层中, 产生类别特征矩阵<b><i>F</i></b><sub><i>k</i></sub>, <b><i>F</i></b><sub><i>k</i></sub>∈<image href="images/JSJC201903050_089.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mrow><mrow><mo>|</mo><mi>Τ</mi><mo>|</mo></mrow><mo>×</mo><mi>n</mi></mrow></msup></mrow></math></mathml>, 其中|<i>T</i>|是情感分类数量。该卷积层采用same卷积操作, 输出通道与情感分类数量相同。计算过程与same卷积计算过程类似。</p>
                </div>
                <div class="p1">
                    <p id="91">2) 全局最大池化层。将第<i>k</i>个分类模块的卷积层生成类别特征向量<b><i>F</i></b><sub><i>k</i></sub>输入全局最大池化模块后, 对<b><i>F</i></b><sub><i>k</i></sub>按类别求最大值, 即求各行的最大值, 产生类别得分向量<b><i>v</i></b><sub><i>k</i></sub>, <b><i>v</i></b><sub><i>k</i></sub>∈<image href="images/JSJC201903050_092.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mrow><mrow><mo>|</mo><mi>Τ</mi><mo>|</mo></mrow></mrow></msup></mrow></math></mathml>, 具体操作如下:</p>
                </div>
                <div class="p1">
                    <p id="94"><i>v</i><sub><i>k</i>, <i>t</i></sub>=max (<i>F</i><sub><i>k</i>, <i>t</i>, :</sub>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="95">其中, <i>v</i><sub><i>k</i>, <i>t</i></sub>表示基于窗口为 (<i>k</i>-1) (<i>w</i>-1) +<i>w</i>的局部语义特征, 得到第<i>t</i>类得分, <i>t</i>∈<i>T</i>。以<i>v</i><sub><i>k</i>, <i>t</i></sub>为基础, 形成<b><i>v</i></b><sub><i>k</i></sub>=[<i>v</i><sub><i>k</i>, 1</sub>, <i>v</i><sub><i>k</i>, 2</sub>, …, <i>v</i><sub><i>k</i>, |</sub><sub><i>T</i></sub><sub>|</sub>]。然后以<b><i>v</i></b><sub><i>k</i></sub>为基础, 形成文本类别得分矩阵<mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">V</mi><mo>=</mo><mrow><mo>[</mo><mrow><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mn>1</mn><mtext>Τ</mtext></msubsup><mo>, </mo><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mn>2</mn><mtext>Τ</mtext></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mi>u</mi><mtext>Τ</mtext></msubsup></mrow><mo>]</mo></mrow></mrow></math></mathml>, 其中<b><i>V</i></b>∈<image href="images/JSJC201903050_097.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mrow><mrow><mo>|</mo><mi>Τ</mi><mo>|</mo></mrow><mo>×</mo><mi>u</mi></mrow></msup></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="99">对于传统<i>CNN</i>模型, 由于全连接层像黑盒一样存在于卷积层和代价函数之间, 因此对于分类信息如何回传至卷积层的解释非常困难。<i>GMP</i>层加强了卷积层和代价函数之间的关联, 在理论上具有可解释性<citation id="178" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="100" name="100">2.3 点积层与输出层</h4>
                <div class="p1">
                    <p id="101">本文模型综合考虑基于各局部语义特征的类别得分, 计算出文本情感分类得分。由于各种局部语义特征的窗口大小和抽象级别不同, 因此不同类别得分对文本情感分类贡献不同。点积层对文本类别得分矩阵<b><i>V</i></b>按列进行加权求和计算, 得到文本的情感分类得分向量<b><i>scr</i>, <i>scr</i></b>∈<image href="images/JSJC201903050_102.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mrow><mrow><mo>|</mo><mi>Τ</mi><mo>|</mo></mrow></mrow></msup></mrow></math></mathml>, 计算过程如下:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>c</mi><mi>r</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>u</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">W</mi><mo>⋅</mo><mi mathvariant="bold-italic">V</mi></mrow><mo>) </mo></mrow></mrow></mstyle><msub><mrow></mrow><mrow><mi>t</mi><mo>, </mo><mi>i</mi></mrow></msub><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">其中, <i>scr</i><sub><i>t</i></sub>表示文本对第<i>t</i>类的得分, 以<i>scr</i><sub><i>t</i></sub>为基础形成<mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">s</mi><mi mathvariant="bold-italic">c</mi><mi mathvariant="bold-italic">r</mi><mo>=</mo><mrow><mo>[</mo><mrow><mi>s</mi><mi>c</mi><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>s</mi><mi>c</mi><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>s</mi><mi>c</mi><mi>r</mi><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>Τ</mi><mo>|</mo></mrow></mrow></msub></mrow><mo>]</mo></mrow><mo>, </mo><mi mathvariant="bold-italic">W</mi><mo>∈</mo></mrow></math></mathml><image href="images/JSJC201903050_107.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow></mrow><mrow><mrow><mo>|</mo><mi>Τ</mi><mo>|</mo></mrow><mo>×</mo><mi>u</mi></mrow></msup></mrow></math></mathml>是贡献权重矩阵。</p>
                </div>
                <div class="p1">
                    <p id="109">输出层对<b><i>scr</i></b>应用softmax函数将句子的情感分类得分转换为情感分类条件概率分布。句子对情感分类<i>t</i>的条件概率分布计算如下:</p>
                </div>
                <div class="p1">
                    <p id="110"><i>p</i> (<i>t</i>|<b><i>S</i></b>, <i>θ</i>) =e<sup><i>scr</i><sub><i>t</i></sub></sup><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mrow><mo>|</mo><mi>Τ</mi><mo>|</mo></mrow></mrow></munderover><mtext>e</mtext></mstyle><msup><mrow></mrow><mrow><mi>s</mi><mi>c</mi><mi>r</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <h3 id="112" name="112" class="anchor-tag">3 GMP-CNN模型训练</h3>
                <div class="p1">
                    <p id="113">GMP-CNN模型是通过最小化负对数似然函数进行训练。对式 (4) 取对数:</p>
                </div>
                <div class="p1">
                    <p id="114" class="code-formula">
                        <mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>ln</mi></mrow><mspace width="0.25em" /><mi>p</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">S</mi><mo>, </mo><mi mathvariant="bold-italic">θ</mi><mo stretchy="false">) </mo><mo>=</mo><mi>s</mi><mi>c</mi><mi>r</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mrow><mi>ln</mi></mrow><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mrow><mo>|</mo><mi>Τ</mi><mo>|</mo></mrow></mrow></munderover><mtext>e</mtext></mstyle><msup><mrow></mrow><mrow><mi>s</mi><mi>c</mi><mi>r</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msup></mrow><mo>) </mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="115">采用随机梯度下降 (Stochastic Gradient Descent, SGD) 算法最小化负对数似然函数, 得到:</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mrow><mo> (</mo><mi mathvariant="bold-italic">θ</mi><mo>) </mo></mrow><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mrow><mo> (</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>D</mi></mrow><mo>) </mo></mrow></mrow></munder><mo>-</mo></mstyle><mrow><mi>ln</mi></mrow><mspace width="0.25em" /><mi>p</mi><mrow><mo> (</mo><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi mathvariant="bold-italic">S</mi><msub><mrow></mrow><mi>i</mi></msub><mo>;</mo><mi mathvariant="bold-italic">θ</mi></mrow><mo>) </mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">其中, <i>D</i>代表训练语料, <b><i>S</i></b><sub><i>i</i></sub>、<i>y</i><sub><i>i</i></sub>表示训练语料的句子及其对应的情感标签, <i>θ</i>表示模型所有参数。</p>
                </div>
                <div class="p1">
                    <p id="118">过拟合是由训练数据集采样噪声产生, 并不是真实地存在于测试数据集<citation id="179" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>, 会降低模型的泛化能力。此外, SSTb数据集中长句训练集的样本数量较少, 在进行CNN模型训练时, 过拟合现象较容易发生。在训练过程中, GMP-CNN模型在输入层使用Dropout技术<citation id="180" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>, 并且模型中各全局池化层对整个网络在结构上做正则化处理<citation id="181" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 因此, 本文模型可有效防止过拟合, 明显降低泛化误差。</p>
                </div>
                <h3 id="119" name="119" class="anchor-tag">4 实验结果与分析</h3>
                <h4 class="anchor-tag" id="120" name="120">4.1 情感分析数据集</h4>
                <div class="p1">
                    <p id="121"><i>SSTb</i>数据集的语料内容来源于在线影评, 属于网络短文本<citation id="182" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。<i>SSTb</i>不仅有显式的情感实证概率, 而且影评相较其他正式类型的文本具有更加主观的表达, 因此选用<i>SSTb</i>论证<i>GMP</i>-<i>CNN</i>模型。<i>SSTb</i>包含11 845个句子和227 385个短语, 其中短语由句子的语法解析树产生, 本文实验只使用句子作为样本数据。数据集有句子和短语的情感实证概率。根据分类标准界限[0.0, 0.2]、 (0.2, 0.4]、 (0.4, 0.6]、 (0.6, 0.8]、 (0.8, 1.0], 情感实证概率可映射到五分类中, 即表达非常负面、负面、中性、正面、非常正面的情感。在忽略中性类后, 分类标准界限为[0, 0.4]、[0.6, 1.0], 将情感实证概率映射到二分类中, 即负面和正面情感。</p>
                </div>
                <div class="p1">
                    <p id="122">本文按上述标准分别为二分类和五分类划分出2套实验数据集。无论在二分类还是五分类实验数据集中, 均只包含句子, 不包含短语。由于二分类过滤了中性类样本, 因此过滤约20%的样本, SSTb数据集划分结果见表1。</p>
                </div>
                <div class="area_img" id="123">
                    <p class="img_tit"><b>表1 SSTb数据集划分结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="123" border="1"><tr><td><br />数据集</td><td>二分类</td><td>五分类</td></tr><tr><td><br />训练集</td><td>6 920</td><td>8 544</td></tr><tr><td><br />验证集</td><td>872</td><td>1 101</td></tr><tr><td><br />测试集</td><td>1 821</td><td>2 210</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="124" name="124">4.2 模型超参数设定</h4>
                <div class="p1">
                    <p id="125">若窗口每次处理范围包含一个词及其上下文, 则窗口大小值最小为3<citation id="183" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 因此GMP-CNN模型中卷积层窗口大小<i>w</i>设定为3。考虑到模型中每个卷积层的输出通道数量与词向量维度<i>d</i><sup><i>wrd</i></sup>相同, 不宜过低, 因此设定为100。在GMP-CNN模型的输入层执行Dropout操作, 参照文献<citation id="184" type="reference">[<a class="sup">17</a>]</citation>中的设置, 以<i>p</i><sub>in</sub>=0.5的概率随机保留输入单元。|<i>D</i>|为每个训练批次包含的样本数, 预先设定<mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow><mo>∈</mo><mrow><mo>{</mo><mrow><mn>1</mn><mn>6</mn><mo>, </mo><mn>3</mn><mn>2</mn><mo>, </mo><mn>6</mn><mn>4</mn><mo>, </mo><mn>1</mn><mn>2</mn><mn>8</mn></mrow><mo>}</mo></mrow></mrow></math></mathml>, SGD学习率<i>λ</i>为0.001, 通过验证集确定|<i>D</i>|为32。所有超参数设定值见表2。</p>
                </div>
                <div class="area_img" id="127">
                    <p class="img_tit"><b>表2 GMP-CNN超参数设定</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="127" border="1"><tr><td><br />参数</td><td>参数说明</td><td>参数值</td></tr><tr><td><br /><i>w</i></td><td>卷积层窗口大小</td><td>3</td></tr><tr><td><br /><i>d</i><sup><i>wrd</i></sup></td><td>词向量维度</td><td>100</td></tr><tr><td><br /><i>p</i><sub>in</sub></td><td>Dropout保留概率</td><td>0.5</td></tr><tr><td><br />|<i>D</i>|</td><td>每个批次包含的样本数</td><td>32</td></tr><tr><td><br /><i>λ</i></td><td>学习率</td><td>0.001</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="128">为验证GMP-CNN模型的有效性, 本文对一系列parallel-CNN模型进行实验。除卷积层窗口大小之外, 其他参数与表2中的设置相同, 另外parallel-CNN在全连接层的输入也执行Dropout操作, 随机保留输入单元概率为<i>p</i><sub>in</sub>。parallel-CNN的卷积层窗口大小设置为相同卷积层数量时GMP-CNN模型的等效窗口大小。</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129">4.3 词向量预训练</h4>
                <div class="p1">
                    <p id="130">实验选择GloVe算法<citation id="185" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>进行词向量预训练。由于Twitter与SSTb同属社交网络文本, Twitter语料库的词语空间分布接近于SSTb的词语空间分布, 因此本文使用Twitter语料库进行词向量预训练。在训练词向量后, 得到一个包括一百多万条目的单词表。对于SSTb中未出现在单词表中的单词, 使用在区间 (-0.01, 0.01) 中的均匀分布随机数进行初始化<citation id="186" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="131" name="131">4.4 GMP-CNN模型结构设置</h4>
                <div class="p1">
                    <p id="132">为实现实验结果的有效对比和论证, 在训练过程中对GMP-CNN模型的卷积层层数和词向量做不同设定, 见表3。</p>
                </div>
                <div class="area_img" id="133">
                    <p class="img_tit"><b>表3 实验模型结构设定</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="133" border="1"><tr><td><br />模型</td><td>说明</td></tr><tr><td><br />GMP-CNN-3-nostatic</td><td>堆叠3个卷积层, 词向量可训练</td></tr><tr><td><br />GMP-CNN-3-static</td><td>堆叠3个卷积层, 词向量不可训练</td></tr><tr><td><br />GMP-CNN-5-nostatic</td><td>堆叠5个卷积层, 词向量可训练</td></tr><tr><td><br />GMP-CNN-5-static</td><td>堆叠5个卷积层, 词向量不可训练</td></tr><tr><td><br />GMP-CNN-7-nostatic</td><td>堆叠7个卷积层, 词向量可训练</td></tr><tr><td><br />GMP-CNN-9-nostatic</td><td>堆叠9个卷积层, 词向量可训练</td></tr><tr><td><br />GMP-CNN-11-nostatic</td><td>堆叠11个卷积层, 词向量可训练</td></tr><tr><td><br />parallel-CNN-3</td><td>卷积窗口{3, 5, 7}, 词向量可训练</td></tr><tr><td><br />parallel-CNN-5</td><td>卷积窗口{3, 5, 7, 9, 11}, 词向量可训练</td></tr><tr><td><br />parallel-CNN-7</td><td>卷积窗口{3, 5, 7, 9, 11, 13, 15}, 词向量可训练</td></tr><tr><td><br />parallel-CNN-9</td><td>卷积窗口{3, 5, 7, 9, 11, 13, 15, 17, 19}, 词向量可训练</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="134" name="134">4.5 结果分析</h4>
                <div class="p1">
                    <p id="135">实验选用Intel I5-4200的CPU, 8 GB内存, 256 GB的SSD硬盘, Linux操作系统, 未使用GPU。实验开发和运行的操作系统环境是ubuntu 16.04, 在Anaconda集成环境中使用python3.5语言编写实验代码。实验模型的构建、训练和预测功能模块都是基于深度学习开源软件库TensorFlow r1.2。</p>
                </div>
                <div class="p1">
                    <p id="136">CharSCNN模型<citation id="187" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>是CNN应用在情感分类标注问题的经典模型, 采用2个相同大小窗口的并行卷积层分别提取单词的构造特征和句子的局部语义特征, 并在SSTb数据集上验证了该模型的有效性。因此, 为验证实验正确率及说明多窗口局部语义特征的重要性, 本文还将给出CharSCNN模型在SSTb数据集上的实验结果。</p>
                </div>
                <h4 class="anchor-tag" id="137" name="137">4.5.1 GMP-CNN训练与预测效率分析</h4>
                <div class="p1">
                    <p id="138">从图5、图6可以看出, 无论是情感二分类标注还是五分类标注, 随着卷积层增加, GMP-CNN的训练时间和预测时间是近似线性增长, 而parallel-CNN的训练时间和预测时间增长速率远大于GMP-CNN, 近似为指数增长, 主要原因为:1) 堆叠结构使得GMP-CNN模型计算得到某个大窗口的局部语义特征, 同时计算得到一系列较小窗口的局部语义特征, 因此GMP-CNN在卷积部分的计算量明显少于parallel-CNN。假设GMP-CNN卷积层窗口为3, 词向量维度为100, 卷积层的输出通道数量为100, 文本长度为20。在堆叠5层后, GMP-CNN取得{3, 5, 7, 9, 11}窗口的局部语义特征, 这5层卷积层共需进行5×[ (3×100) ×20]×100=3×10<sup>6</sup>次计算。对于parallel-CNN模型同样取得{3, 5, 7, 9, 11}窗口的局部语义特征, 需要进行[ (3+5+7+9+11) ×100×20]×100=7×10<sup>6</sup>次计算, GMP-CNN计算量大幅减少。2) GMP-CNN使用分类模块代替parallel-CNN中的全连接层, 分类判别的计算量远小于全连接层的计算量。</p>
                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903050_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 GMP-CNN与parallel-CNN模型训练时间对比" src="Detail/GetImg?filename=images/JSJC201903050_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 GMP-CNN与parallel-CNN模型训练时间对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903050_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="140">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903050_140.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 GMP-CNN与parallel-CNN模型预测时间对比" src="Detail/GetImg?filename=images/JSJC201903050_140.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 GMP-CNN与parallel-CNN模型预测时间对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903050_140.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="141">从图7、图8可以看出, 无论在情感二分类还是五分类标注训练过程中, 窗口大小相等的GMP-CNN模型和parallel-CNN模型的训练正确率收敛相似, 在相同训练批次, GMP-CNN模型的训练时间远比parallel-CNN模型要少, 因此GMP-CNN模型在训练效率上比parallel-CNN高很多, 从而认为其比大多数基于parallel-CNN基础结构的CNN模型训练效率高。</p>
                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903050_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 GMP-CNN与parallel-CNN模型训练正确率对比 (二分类)" src="Detail/GetImg?filename=images/JSJC201903050_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 GMP-CNN与parallel-CNN模型训练正确率对比 (二分类</b>)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903050_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="143">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903050_143.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 GMP-CNN与parallel-CNN模型训练正确率对比 (五分类)" src="Detail/GetImg?filename=images/JSJC201903050_143.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图8 GMP-CNN与parallel-CNN模型训练正确率对比 (五分类</b>)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903050_143.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="144" name="144">4.5.2 GMP-CNN情感分类标注正确率分析</h4>
                <div class="p1">
                    <p id="145">从表4可以看出, 当进行情感二分类标注任务时, 在词向量可以调整的情况下, 所有GMP-CNN模型正确率均大于CharSCNN模型, 特别是当卷积层达到11层时, 正确率比CharSCNN模型高1.8%。在进行情感五分类标注任务时, 当卷积层达到9层时, GMP-CNN模型开始优于CharSCNN模型, 当卷积层达到11层时, 正确率比CharSCNN模型高1.4%, 从而验证GMP-CNN模型应用于情感分类标注的有效性。</p>
                </div>
                <div class="area_img" id="146">
                    <p class="img_tit"><b>表4 在SSTb数据集上不同模型分类标注正确率</b> % <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="146" border="1"><tr><td><br />模型</td><td>二分类</td><td>五分类</td></tr><tr><td><br />GMP-CNN-3-nostatic</td><td>83.2</td><td>42.3</td></tr><tr><td><br />GMP-CNN-5-nostatic</td><td>83.5</td><td>42.5</td></tr><tr><td><br />GMP-CNN-7-nostatic</td><td>83.5</td><td>42.7</td></tr><tr><td><br />GMP-CNN-9-nostatic</td><td>83.8</td><td>43.6</td></tr><tr><td><br />GMP-CNN-11-nostatic</td><td>84.1</td><td>44.9</td></tr><tr><td><br />GMP-CNN-3-static</td><td>79.7</td><td>39.8</td></tr><tr><td><br />GMP-CNN-5-static</td><td>80.1</td><td>40.1</td></tr><tr><td><br />parallel-CNN-3</td><td>83.7</td><td>44.3</td></tr><tr><td><br />parallel-CNN-5</td><td>83.8</td><td>43.8</td></tr><tr><td><br />parallel-CNN-7</td><td>84.0</td><td>45.2</td></tr><tr><td><br />parallel-CNN-9</td><td>84.1</td><td>44.5</td></tr><tr><td><br />CharSCNN</td><td>82.3</td><td>43.5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="147">从表4还可看到, 无论是情感二分类还是五分类标注, parallel-CNN均优于CharSCNN。其原因为CharSCNN设定一种窗口大小的卷积层, 只能提取一种窗口的局部语义特征, 而多窗口的局部语义特征可以捕捉更多不同距离上的语义依赖性, 这种依赖性对判断文本整体情感分类影响较大, 特别是情感多分类标注任务。下文实例说明了在远距离上的语义依赖性对整个句子情感的影响:</p>
                </div>
                <div class="p1">
                    <p id="148"><b>实例1</b> at all clear what it’s trying to say and even if it were -- I doubt it.</p>
                </div>
                <div class="p1">
                    <p id="149"><b>实例2</b> at all clear what it’s trying to say and even if it were -- I doubt it would be all that interesting.</p>
                </div>
                <div class="p1">
                    <p id="150">可以看出, 实例2的负面情感程度比实例1弱一些, 因为doubt后面4个词距离上的all影响了其强烈程度, 从而影响全句负面情感的强烈程度。实例1的真实分类是负面, 而实例2的真实分类是中性。可见, parallel-CNN正确率虽然有时略高于GMP-CNN, 但总体上基本持平。</p>
                </div>
                <h4 class="anchor-tag" id="151" name="151">4.5.3 GMP-CNN卷积层层数对标注正确率的影响</h4>
                <div class="p1">
                    <p id="152">GMP-CNN随着卷积层层数增加, 二分类标注和五分类标注正确率总体提高, 由此认为正确率的提高主要是因为每增加一层卷积层, 就会抽取更大窗口的局部语义特征。虽然每增加一个卷积层, 也会增加一个分类模块, 使得整个模型规模增加, 带来过拟合的可能性, 但增加的GMP层具有结构上的正则化性<citation id="188" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 从而有效防止模型过拟合的发生。</p>
                </div>
                <h4 class="anchor-tag" id="153" name="153">4.5.4 词向量调整对标注正确率的影响</h4>
                <div class="p1">
                    <p id="154">根据表4中GMP-CNN-3-nostatic、GMP-CNN-3-static和GMP-CNN-5-nostatic、GMP-CNN-5-static实验对比可以看出, 对于分类正确率, 词向量在训练过程中是否可调整是非常重要的。预训练好的词向量保存词与词之间的通用语法关系, 但这种语法关系受限于训练词向量的语料库<citation id="189" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。同时, SSTb数据集中有一千多不存在于预训练词向量库中的词, 只用随机数代替。因此, 将词向量作为GMP-CNN训练参数, 在训练过程调整词向量。对于预训练好的词向量, 这种调整策略可以更好地反映SSTb数据集的词与词之间的语法关系。对于随机数代替的词向量, 该过程类似针对SSTb数据集的情感分类标注任务进行词向量训练。表5列举了在二分类标注任务中, GMP-CNN-7-nostatic训练2 000批次后, 词向量变化最大的前10个词, 可以看出这些词有以下特点:1) 情感极性强烈的词, 如worst、bad、unfortunately、powerful、problem、unpleasant;2) 在文中出现频率较高且能直接影响其他情感词的词, 如too;3) 本身有较多词意, 但在影评语境下突出某个词意的词, 如works、treat、worth。</p>
                </div>
                <div class="area_img" id="155">
                    <p class="img_tit"><b>表5 经模型训练后的词向量变化情况</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="155" border="1"><tr><td>排名</td><td>词语</td><td>新旧词向量的欧氏距离</td><td>出现频次</td></tr><tr><td>1</td><td>worst</td><td>1.95</td><td>53</td></tr><tr><td><br />2</td><td>too</td><td>1.91</td><td>449</td></tr><tr><td><br />3</td><td>bad</td><td>1.83</td><td>236</td></tr><tr><td><br />4</td><td>unfortunately</td><td>1.78</td><td>29</td></tr><tr><td><br />5</td><td>powerful</td><td>1.75</td><td>51</td></tr><tr><td><br />6</td><td>works</td><td>1.75</td><td>85</td></tr><tr><td><br />7</td><td>treat</td><td>1.71</td><td>24</td></tr><tr><td><br />8</td><td>problem</td><td>1.68</td><td>53</td></tr><tr><td><br />9</td><td>unpleasant</td><td>1.61</td><td>15</td></tr><tr><td><br />10</td><td>worth</td><td>1.56</td><td>98</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="156" name="156" class="anchor-tag">5 结束语</h3>
                <div class="p1">
                    <p id="157">本文提出一种多个卷积层堆叠的GMP-CNN模型。GMP-CNN模型能提取出包含多个抽象级别和多种窗口的局部语义特征。实验结果表明, 在文本情感分类标注任务中, 与其他CNN模型相比, GMP-CNN模型可有效提高训练效率、加快预测速度。下一步将研究更深层次的CNN模型在情感分类标注任务中的应用, 并综合不同窗口的局部特征, 提高GMP-CNN模型的情感分类标注正确率。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14061700305623&amp;v=Mjc0NDByUmRHZXJxUVRNbndaZVp1SHlqbVVMbklKbDBWYVJJPU5pZk9mYks4SHRmTnFJOUZaK3NLQ240Nm9CTVQ2VDRQUUgvaQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> MEDHAT W, HASSAN A, KORASHY H.Sentiment analysis algorithms and applications:a survey[J].Ain Shams Engineering Journal, 2014, 5 (4) :1093-1113.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                 KUBLER S, MCDONALD R, NIVRE J.Synthesis lectures on human language technologies[EB/OL].[2018-01-05].http://www.morganclaypool.com/doi/abs/10.2200/S00416ED1V01Y201204HLT016.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                 PANG B, LEE L, VAITHYANATHAN S, et al.Sentiment classification using machine learning techniques[C]//Procedings of Empirical Methods in Natural Language Processing.Philadelphia, USA:Association for Computational Linguistics, 2002:79-86.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" >
                                    <b>[4]</b>
                                 MA M, HUANG L, ZHOU B, et al.Dependency-based convolutional neural networks for sentence embedding[EB/OL].[2018-01-05].http://www.oalib.com/paper/4048778.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 SANTOS C N D, GATTIT M.Deep convolutional neural networks for sentiment analysis of short texts[C]//Proceeding of the 25th International Conference on Computational Linguistics.Dublin, Ireland:[s.n.], 2014:69-78.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201506022&amp;v=MTI3NjFyQ1VSTE9lWmVSb0Z5N21VcnpJS0NqWWZiRzRIOVRNcVk5SFpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 刘龙飞, 杨亮, 张绍武, 等.基于卷积神经网络的微博情感倾向性分析[J].中文信息学报, 2015, 29 (6) :159-165.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 LEE G, JEONG J, SEO S, et al.Sentiment classification with word attention based on weakly supervised learning with a convolutional neural network[EB/OL].[2018-01-05].https://arxiv.org/abs/1709.09885.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                 SANTOS C N D, XIANG B, ZHOU B.Classifying relations by ranking with convolutional neural networks[J].Computer Science, 2015, 86:132-137.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 WANG L, CAO Z, MELO G, et al.Relation classification via multi-level attention CNNs[C]//Proceeding of the 54th Annual Meeting of the Association for Computational Linguistics.Philadelphia, USA:Association for Computational Linguistics, 2016:1298-1307.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" >
                                    <b>[10]</b>
                                 LIN Y, SHEN S, LIU Z, et al.Neural relation extraction with selective attention over instances[C]//Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.Philadelphia, USA:Association for Computational Linguistics, 2016:2124-2133.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 DONG L, WEI F, XU K, et al.Adaptive multi-compositionality for recursive neural network models[J].IEEE Transactions on Audio, Speech, and Language Processing, 2016, 24 (3) :422-431.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" >
                                    <b>[12]</b>
                                 BENGIO Y, DUCHARME R, VINCENT P, et al.A neural probabilistic language model[J].Journal of Machine Learning Research, 2003, 3 (6) :1137-1155.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                 KIM Y.Convolutional neural networks for sentence classification[C]//Proceedings of Empirical Methods in Natural Language Processing.Philadelphia, USA:Association for Computational Linguistics, 2014:1746-1751.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[C]//Proceedings of International Conference on Learning Representations.Washington D.C., USA:IEEE Press, 2015:1-7.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" >
                                    <b>[15]</b>
                                 HE K, ZHANG X, REN S, et al.Deep residual learning for image recognition[C]//Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2016:770-778.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 LIN M, CHEN Q, YAN S.Network in network[EB/OL].[2018-01-05].https://arxiv.org/abs/1312.4400.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 SRIVASTAVA N, HINTON G E, KRIZHEVSKY A, et al.Dropout:a simple way to prevent neural networks from overfitting[J].Journal of Machine Learning Research, 2014, 15 (1) :1929-1958.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" >
                                    <b>[18]</b>
                                 SOCHER R, PERELYGIN A, WU J Y, et al.Recursive deep models for semantic compositionality over a sentiment treebank[C]//Proceedings of Empirical Methods in Natural Language Processing.Philadelphia, USA:Association for Computational Linguistics, 2013:1631-1642.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" >
                                    <b>[19]</b>
                                 PENNINGTON J, SOCHER R, CHRISTOPHER D, et al.GloVe:global vectors for word representation[C]//Proceedings of Empirical Methods in Natural Language Processing.Philadelphia, USA:Association for Computational Linguistics, 2014:1532-1543.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" >
                                    <b>[20]</b>
                                 TANG D, QIN B, LIU T, et al.Aspect level sentiment classification with deep memory network[EB/OL].[2018-01-05].https://arxiv.org/abs/1605.08900.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201903050" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903050&amp;v=MTE2OTFvRnk3bVVyekpMejdCYmJHNEg5ak1ySTlBWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="3" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
