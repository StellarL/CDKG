<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637128034948936250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201909029%26RESULT%3d1%26SIGN%3dapcecar4tsSV5jfu1KzHyLni%252fT8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201909029&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201909029&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201909029&amp;v=MjYzODJDVVJMT2VaZVJyRnkvaFdyL1BMejdCYmJHNEg5ak1wbzlIYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="1 二阶段特征选择方法 ">1 二阶段特征选择方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#45" data-title="1.1 初次筛选">1.1 初次筛选</a></li>
                                                <li><a href="#50" data-title="1.2 二次筛选">1.2 二次筛选</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#68" data-title="2 改进的mRMR特征选择方法 ">2 改进的mRMR特征选择方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="2.1 类差分度差值">2.1 类差分度差值</a></li>
                                                <li><a href="#78" data-title="2.2 改进的mRMR算法">2.2 改进的mRMR算法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#122" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#129" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="&lt;b&gt;图1 文本分类流程&lt;/b&gt;"><b>图1 文本分类流程</b></a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;表1 IMDB、康奈尔影评数据集的特征子集&lt;/b&gt;"><b>表1 IMDB、康奈尔影评数据集的特征子集</b></a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;图2 3种方法的准确率对比结果&lt;/b&gt;"><b>图2 3种方法的准确率对比结果</b></a></li>
                                                <li><a href="#131" data-title="&lt;b&gt;图3 3种方法的F1值对比结果&lt;/b&gt;"><b>图3 3种方法的F1值对比结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="170">


                                    <a id="bibliography_1" title=" PANDOVE D,GOEL S,RANI R.Systematic review of cluster high-dimensional and large datasets[J].ACM Transactions on Knowledge Discovery from Data,2018,12(2):1-68." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCMC9A4F802A4669E0321446318E4C4A44F&amp;v=Mjk4NDNqcEdjeENyYmxRYjdwQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TjFodzd5MndLOD1OaWZJWThDeGI5VzZwNDlIRmU4SkNuVk16eFVSNnp0NVRueg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         PANDOVE D,GOEL S,RANI R.Systematic review of cluster high-dimensional and large datasets[J].ACM Transactions on Knowledge Discovery from Data,2018,12(2):1-68.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_2" title=" SHANG Changxing,LI Min,FENG Shengzhong,et al.Feature selection via maximizing global information gain for text classification[J].Knowledge-Based Systems,2013,54(4):298-309." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600390941&amp;v=MTI1OTlQQlhnNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxySUoxb2RhaFU9TmlmT2ZiSzhIdERNcVk5RlorSQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         SHANG Changxing,LI Min,FENG Shengzhong,et al.Feature selection via maximizing global information gain for text classification[J].Knowledge-Based Systems,2013,54(4):298-309.
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_3" title=" ZHANG Xiaowen,CHEN Bingfeng.Probability variance CHI feature selection method for unbalanced data[EB/OL].[2018-02-20].http://adsabs.harvard.edu/abs/2017 AIPC.1864b0015Z." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Probability variance CHI feature selection method for unbalanced data">
                                        <b>[3]</b>
                                         ZHANG Xiaowen,CHEN Bingfeng.Probability variance CHI feature selection method for unbalanced data[EB/OL].[2018-02-20].http://adsabs.harvard.edu/abs/2017 AIPC.1864b0015Z.
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_4" title=" SUN Peng,WANG Lihua,XIA Qianchen.The keyword extraction of Chinese medical Web page based on WF-TF-IDF algorithm[C]//Proceedings of International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery.Washington D.C.,USA:IEEE Press,2017:193-198." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The keyword extraction of Chinese medical Web page based on WF-TF-IDF algorithm">
                                        <b>[4]</b>
                                         SUN Peng,WANG Lihua,XIA Qianchen.The keyword extraction of Chinese medical Web page based on WF-TF-IDF algorithm[C]//Proceedings of International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery.Washington D.C.,USA:IEEE Press,2017:193-198.
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_5" title=" 王露,龚红光.基于ReliefF+mRMR特征降维算法的多特征遥感图像分类[J].中国体视学与图像分析,2014(3):250-257." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZTSX201403007&amp;v=MDAzNTdyL1BQem5ZZHJHNEg5WE1ySTlGWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnkvaFc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         王露,龚红光.基于ReliefF+mRMR特征降维算法的多特征遥感图像分类[J].中国体视学与图像分析,2014(3):250-257.
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_6" title=" JAIN A K,DUIN P W.Statistical pattern recognition:a review[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2000,22(1):4-37." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Statistical pattern recognition: a review">
                                        <b>[6]</b>
                                         JAIN A K,DUIN P W.Statistical pattern recognition:a review[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2000,22(1):4-37.
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_7" title=" 和怡,朱小军,李登峰,等.基于模态分析和Relief算法的在线静态电压稳定特征选取方法[J].电力系统及自动化学报,2017,29(7):87-92." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLZD201707014&amp;v=MDc1NDdlWmVSckZ5L2hXci9QSVNIUmFyRzRIOWJNcUk5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         和怡,朱小军,李登峰,等.基于模态分析和Relief算法的在线静态电压稳定特征选取方法[J].电力系统及自动化学报,2017,29(7):87-92.
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_8" title=" MA Huiqin,HUANG Wenjiang,JING Yuanshu,et al.Remote sensing monitoring of wheat powdery mildew based on AdaBoost model combining mRMR algorithm[J].Transactions of the Chinese Society of Agricultural Engineering,2017,33(5):162-169." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201705024&amp;v=MDE2NzVoV3IvUEt6VE1lN0c0SDliTXFvOUhZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeS8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         MA Huiqin,HUANG Wenjiang,JING Yuanshu,et al.Remote sensing monitoring of wheat powdery mildew based on AdaBoost model combining mRMR algorithm[J].Transactions of the Chinese Society of Agricultural Engineering,2017,33(5):162-169.
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_9" title=" 卢中宁,张保威.一种基于改进TF-IDF函数的文本分类方法[J].河南师范大学学报(自然科学版),2012,40(6):158-160,174." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNSX201206043&amp;v=MTA3MDVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeS9oV3IvUExTUFlkckc0SDlQTXFZOUJaNFFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         卢中宁,张保威.一种基于改进TF-IDF函数的文本分类方法[J].河南师范大学学报(自然科学版),2012,40(6):158-160,174.
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_10" title=" XU Linbin,LIU Jun,ZHOU Wenli,et al,Adaptive naive Bayesian classifier for automatic classification of webpage from massive network data[C]//Proceedings of the 6th International Conference on Intelligent Human-machine Systems and Cybernetics.Washington D.C.,USA:IEEE Press,2014:127-130." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive naive Bayesian classifier for automatic classification of webpage from massive network data">
                                        <b>[10]</b>
                                         XU Linbin,LIU Jun,ZHOU Wenli,et al,Adaptive naive Bayesian classifier for automatic classification of webpage from massive network data[C]//Proceedings of the 6th International Conference on Intelligent Human-machine Systems and Cybernetics.Washington D.C.,USA:IEEE Press,2014:127-130.
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_11" title=" 任军,葛卫丽,陈家勇.一种基于类差分度的互信息特征选择方法[J].中国科技论文,2015(20):2386-2389." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKZX201520010&amp;v=MDg1MjF5YlJkckc0SDlUT3I0OUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeS9oV3IvUFA=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         任军,葛卫丽,陈家勇.一种基于类差分度的互信息特征选择方法[J].中国科技论文,2015(20):2386-2389.
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_12" title=" 王旭仁,马慧珍,冯安然,等.基于信息增益与主成分分析的网络入侵检测研究[J].计算机工程,2019,45(6):175-180." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201906028&amp;v=MjQ4MjBGckNVUkxPZVplUnJGeS9oV3IvUEx6N0JiYkc0SDlqTXFZOUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         王旭仁,马慧珍,冯安然,等.基于信息增益与主成分分析的网络入侵检测研究[J].计算机工程,2019,45(6):175-180.
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_13" title=" 胡颖.基于信息增益的文本特征选择方法[J].计算机与数字工程,2013,39(3):460-462." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201303040&amp;v=MDQ1ODdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnkvaFdyL1BMejdZYWJHNEg5TE1ySTlCWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         胡颖.基于信息增益的文本特征选择方法[J].计算机与数字工程,2013,39(3):460-462.
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_14" title=" 任永功,杨雪,杨荣杰,等.基于信息增益特征关联树的文本特征选择算法[J].计算机科学,2013,40(10):252-256." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201310055&amp;v=MTg1NzZxQnRHRnJDVVJMT2VaZVJyRnkvaFdyL1BMejdCYjdHNEg5TE5yNDlBWVlRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         任永功,杨雪,杨荣杰,等.基于信息增益特征关联树的文本特征选择算法[J].计算机科学,2013,40(10):252-256.
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_15" title=" 邹利东,潘耀忠,朱文泉,等.结合领域相关影响与最大相关最小冗余性特征选择的面向对象化检测[J].中国图象图形学报,2014,19(1):158-166." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201401020&amp;v=MTUyODVMT2VaZVJyRnkvaFdyL1BQeXJmYkxHNEg5WE1ybzlIWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         邹利东,潘耀忠,朱文泉,等.结合领域相关影响与最大相关最小冗余性特征选择的面向对象化检测[J].中国图象图形学报,2014,19(1):158-166.
                                    </a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_16" title=" 周奇年,张振浩,虚登彩.用于中文文本分类的基于类别区分词的特征选择方法[J].计算机应用与软件,2013,33(7):193-195." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201303053&amp;v=MDA1MDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckZ5L2hXci9QTHpUWlpMRzRIOUxNckk5QVo0UUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         周奇年,张振浩,虚登彩.用于中文文本分类的基于类别区分词的特征选择方法[J].计算机应用与软件,2013,33(7):193-195.
                                    </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_17" title=" 赵妍妍,秦兵,刘挺.文本情感分析[J].软件学报,2010,21(8):1834-1848." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201008009&amp;v=MjQ4OTgvUE55ZlRiTEc0SDlITXA0OUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeS9oV3I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         赵妍妍,秦兵,刘挺.文本情感分析[J].软件学报,2010,21(8):1834-1848.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(09),183-187+193 DOI:10.19678/j.issn.1000-3428.0051013            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于IG_CDmRMR的二阶段特征选择方法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E6%96%87%E5%B3%B0&amp;code=40420450&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱文峰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BA%8E%E8%88%92%E5%A8%9F&amp;code=13964825&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">于舒娟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%95%E4%BC%9F&amp;code=38816012&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">何伟</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E4%BA%AC%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%B8%8E%E5%85%89%E5%AD%A6%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0101257&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南京邮电大学电子与光学工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为提高特征提取方法的文本分类精确度,结合信息增益(IG)和改进的最大相关最小冗余(mRMR),提出一种IG＿CDmRMR二阶段文本特征选择方法。通过IG提取与类别相关性较强的特征集合,利用类差分度动态改变mRMR中特征与类别之间的互信息值权重,并筛选最优特征子集,从而得到文本分类结果。实验结果表明,与IG方法、IG＿mRMR方法相比,在特征数量相同的情况下,该方法可使准确率提升约2%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信息增益;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%80%E5%A4%A7%E7%9B%B8%E5%85%B3%E6%9C%80%E5%B0%8F%E5%86%97%E4%BD%99&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">最大相关最小冗余;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B1%BB%E5%B7%AE%E5%88%86%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">类差分度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征选择;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">文本分类;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    朱文峰(1994—),男,硕士研究生,主研方向为机器学习、自然语言处理;;
                                </span>
                                <span>
                                    于舒娟,副教授、硕士;;
                                </span>
                                <span>
                                    何伟,硕士研究生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-03-30</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61302155,61276429);</span>
                    </p>
            </div>
                    <h1><b>Two-stage Feature Selection Method Based on IG_CDmRMR</b></h1>
                    <h2>
                    <span>ZHU Wenfeng</span>
                    <span>YU Shujuan</span>
                    <span>HE Wei</span>
            </h2>
                    <h2>
                    <span>College of Electronic and Optical Engineering,Nanjing University of Posts and Telecommunications</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to improve the text classification accuracy of feature extraction method,combining with Information Gain(IG) and improved minimal Redundancy Maximal Relevance(mRMR),an IG＿CDmRMR two-stage text feature selection method is proposed.The IG is used to extract the feature set with strong correlation with the category.The class difference degree is used to dynamically change the weight of the mutual information value between the feature and the category in the mRMR,and the optimal feature subset is filtered to obtain the text categorization result.Experimental results show that compared with the IG method and the IG＿mRMR method,the accuracy of the proposed method is improved by about 2% with the same number of features.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Information%20Gain(IG)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Information Gain(IG);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=minimal%20Redundancy%20Maximal%20Relevance%20(mRMR)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">minimal Redundancy Maximal Relevance (mRMR);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=class%20difference%20degree&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">class difference degree;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20selection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature selection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=text%20categorization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">text categorization;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-03-30</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="38">随着信息技术的不断发展,网络上出现大量具有较高维度的包括文章、影评、垃圾邮件等文本数据。高维度能够使信息更加完整,但其对分类器的要求较高,还会产生维度灾难的问题<citation id="204" type="reference"><link href="170" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。因此,研究如何从海量文本数据中提取特征具有重要意义。</p>
                </div>
                <div class="p1">
                    <p id="39">文本的特征提取是指从经过分词、归一化和去停用词等预处理操作的文本中,选择最具代表性的特征词集合。通过特征子集的选择,从而达到降维的效果。特征维度的降低不仅提高了分类器的运算效率,还避免了因维度灾难造成分类效果降低的现象。因此,特征子集的选取直接影响了分类器的训练效率和分类精度。传统的特征词选取的方法有信息增益(Information Gain,IG)<citation id="205" type="reference"><link href="172" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>,文本词频(Document Frequency,DF), <i>χ</i><sup>2</sup>统计量(CHI)<citation id="206" type="reference"><link href="174" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>,词频-逆文本率(TF-IDF)<citation id="207" type="reference"><link href="176" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等。但传统的特征提取方法仅考虑了特征与文本类别以及文本类别之间的关系,并没有考虑特征词之间存在的冗余性。</p>
                </div>
                <div class="p1">
                    <p id="40">最大相关最小冗余(minimal Redundancy Maximal Relevance,mRMR)算法不仅考虑到特征与类别之间的关系,同时也考虑到特征之间的独立性。文献<citation id="208" type="reference">[<a class="sup">5</a>]</citation>利用ReliefF算法选择权重较大的特征,然后利用mRMR选择与目标类别最大相关且之间冗余性最小的特征子集。文献<citation id="209" type="reference">[<a class="sup">6</a>]</citation>通过mRMR选择特征子集。文献<citation id="210" type="reference">[<a class="sup">7</a>]</citation>引入权重因子<i>α</i>细化对特征相关性和冗余性的度量。文献<citation id="211" type="reference">[<a class="sup">8</a>]</citation>通过相关性分析(Correlation Analysis,CA)和mRMR这2种特征选择算法筛选出不同的特征变量,结果表明,mRMR筛选出的特征更具优势。文献<citation id="216" type="reference">[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</citation>使用mRMR算法进行特征子集的选择,保证了特征子集语义的完整,但生成特征子集的计算代价较大。为减小计算代价且不破坏语义完整性,文献<citation id="212" type="reference">[<a class="sup">9</a>]</citation>提出一种基于改进TF-IDF函数的文本分类方法。文献<citation id="213" type="reference">[<a class="sup">10</a>]</citation>验证了信息增益算法分类效果优于TF-IDF算法。文献<citation id="214" type="reference">[<a class="sup">11</a>]</citation>引入类差分度的概念,提出一种改进的互信息特征选择方法,利用类差分度解决互信息方法未考虑到的特征项与类别之间关系问题。文献<citation id="215" type="reference">[<a class="sup">12</a>]</citation>利用信息增益与主成分分析(Principal Component Analysis,PCA)相结合的方法对数据进行降维,提高检测率,但PCA具有一定的模糊性,不适用于区分不同的样本类。</p>
                </div>
                <div class="p1">
                    <p id="41">本文介绍传统的信息增益以及mRMR特征选择方法,引入类差分度对mRMR算法进行改进,提出IG_CDmRMR方法。在此基础上,使用IG、IG_mRMR以及IG_CDmRMR方法分别选择最优特征子集,从而得到文本分类结果。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag">1 二阶段特征选择方法</h3>
                <div class="p1">
                    <p id="43">文本分类流程如图1所示。其中,在特征选择过程中使用本文提出的IG_CDmRMR二阶段特征选择方法,利用IG初步筛选较优特征子集,使用改进的mRMR方法进行二阶段筛选,去除存在冗余的特征词,最终得到最优特征子集。</p>
                </div>
                <div class="area_img" id="44">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909029_044.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 文本分类流程" src="Detail/GetImg?filename=images/JSJC201909029_044.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 文本分类流程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909029_044.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="45" name="45">1.1 初次筛选</h4>
                <div class="p1">
                    <p id="46">信息增益通过计算待分类集合的熵与选定特征的条件熵之差来衡量特征对分类的重要程度,并筛选出最优的文本分类特征子集<citation id="217" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。在文本分类领域,通过计算某个特征词<i>w</i><sub><i>i</i></sub>在类别<i>C</i>中出现的文本数进行统计计算特征词<i>w</i><sub><i>i</i></sub>对类别<i>C</i>的贡献程度<citation id="218" type="reference"><link href="196" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>,即特征词<i>w</i><sub><i>i</i></sub>的信息增益值,其计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="47" class="code-formula">
                        <mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mi>G</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>t</mi><mi>m</mi></munderover><mi>Ρ</mi></mstyle><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mtext>l</mtext><mtext>b</mtext><mfrac><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="48" class="code-formula">
                        <mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>t</mi><mi>m</mi></munderover><mi>Ρ</mi></mstyle><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo><mtext>l</mtext><mtext>b</mtext><mfrac><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="49">其中,<i>m</i>表示文本类别总数,<i>C</i><sub><i>t</i></sub>表示第<i>t</i>类文本,<i>P</i>(<i>w</i><sub><i>i</i></sub>)表示特征词<i>w</i><sub><i>i</i></sub>在文本中出现的概率,<i>P</i>(<i>C</i><sub><i>t</i></sub>)表示第<i>t</i>类文本在总文本中出现的概率,<i>P</i>(<i>C</i><sub><i>t</i></sub>|<i>w</i><sub><i>i</i></sub>)表示文本中包含特征词<i>w</i><sub><i>i</i></sub>并且属于<i>C</i><sub><i>t</i></sub>类的条件概率,<mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo><mtext>表</mtext></mrow></math></mathml>示文本中不包含特征词<i>w</i><sub><i>i</i></sub>的文本概率,<mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo><mtext>表</mtext></mrow></math></mathml>示文本不包含特征词<i>w</i><sub><i>i</i></sub>时但属于<i>C</i><sub><i>t</i></sub>类的条件概率。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50">1.2 二次筛选</h4>
                <div class="p1">
                    <p id="51">在经过IG筛选的特征子集中,特征词之间仍存在冗余性,因此要对筛选的特征子集进行二次特征提取。mRMR算法是经典的基于空间搜索的过滤方法,使用互信息衡量特征之间的相关性与冗余度<citation id="219" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。最大相关表示特征与类别之间相关度大,即最大程度反映文本类别信息。最小冗余表示特征词之间相关度小,即特征词之间的冗余度小<citation id="220" type="reference"><link href="180" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="52">在二次特征筛选时,使用信息增益初步筛选获得的特征词集<i>D</i><sub>1</sub>={<i>w</i><sub>1</sub>,<i>w</i><sub>2</sub>,…,<i>w</i><sub><i>n</i></sub>},其中初步筛选的特征集合中包含<i>n</i>个特征词,在<i>D</i><sub>1</sub>的<i>n</i>个特征词中使用mRMR标准选取一个合适的特征子集<i>S</i>,<i>S</i>⊂<i>D</i><sub>1</sub>。</p>
                </div>
                <div class="p1">
                    <p id="53">mRMR算法中最大相关和最小冗余定义分别如式(2)和式(3)所示。</p>
                </div>
                <div class="p1">
                    <p id="54"><mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>max</mi></mrow><mtext> </mtext><mi>D</mi><mo stretchy="false">(</mo><mi>S</mi><mo>,</mo><mi>C</mi><mo stretchy="false">)</mo><mo>,</mo><mi>D</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mrow><mo>|</mo><mi>S</mi><mo>|</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>S</mi></mrow></munder><mi>Ι</mi></mstyle><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>;<i>C</i>)      (2)</p>
                </div>
                <div class="p1">
                    <p id="55"><mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>min</mi></mrow><mtext> </mtext><mi>R</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo>,</mo><mi>R</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mrow><mrow><mo>|</mo><mi>S</mi><mo>|</mo></mrow></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∈</mo><mi>S</mi></mrow></munder><mi>Ι</mi></mstyle><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>;<i>w</i><sub><i>j</i></sub>)      (3)</p>
                </div>
                <div class="p1">
                    <p id="56">其中,<mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi>S</mi><mo>|</mo></mrow></mrow></math></mathml>表示特征子集S已经存在的单词的个数,I(w<sub>i</sub>;C)表示特征词w<sub>i</sub>与文本类别C之间的互信息值,I(w<sub>i</sub>;w<sub>j</sub>)表示特征词w<sub>i</sub>与特征词w<sub>j</sub>之间的互信息值。</p>
                </div>
                <div class="p1">
                    <p id="57">由上述的2种约束条件产生<i>mRMR</i>,有:</p>
                </div>
                <div class="p1">
                    <p id="58"><i>max</i> ϕ(D,R),ϕ=D-R      (4)</p>
                </div>
                <div class="p1">
                    <p id="59">特征词与类别之间以及特征词与特征词之间的计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ι</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>;</mo><mi>C</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>t</mi><mi>m</mi></munderover><mrow><mrow><mo>[</mo><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo><mtext>l</mtext><mtext>b</mtext><mfrac><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo></mrow></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mrow><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo>,</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo><mtext>l</mtext><mtext>b</mtext><mfrac><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo>,</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">I(w<sub>i</sub>;w<sub>j</sub>)=P(w<sub>i</sub>,w<sub>j</sub>)<i>lb</i></p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo><mtext>l</mtext><mtext>b</mtext><mfrac><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo>,</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mtext>l</mtext><mtext>b</mtext><mfrac><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo>,</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo>,</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo><mtext>l</mtext><mtext>b</mtext><mfrac><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo>,</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">其中,<i>P</i>(<i>w</i><sub><i>i</i></sub>,<i>C</i><sub><i>t</i></sub>)表示<i>C</i><sub><i>t</i></sub>类中包含特征词<i>w</i><sub><i>i</i></sub>的文档概率,<mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo>,</mo><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>表示C<sub>t</sub>类中不包含特征词w<sub>i</sub>的文档概率,P(w<sub>i</sub>)表示包含特征词w<sub>i</sub>的文档概率,<mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo></mrow></math></mathml>表示不包含特征词<i>w</i><sub><i>i</i></sub>的文档概率,<i>P</i>(<i>C</i><sub><i>t</i></sub>)表示<i>C</i><sub><i>t</i></sub>类文档数占总文档数的概率,<i>P</i>(<i>w</i><sub><i>i</i></sub>,<i>w</i><sub><i>j</i></sub>)表示同时包含特征词<i>w</i><sub><i>i</i></sub>、<i>w</i><sub><i>j</i></sub>文档数占总文档数的概率,<mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>i</mi><mo>≠</mo><mi>j</mi><mo>,</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo></mrow></math></mathml>表示包含特征词w<sub>i</sub>但不包含特征词w<sub>j</sub>的文档数占总文档数的概率,<mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo>,</mo><mover accent="true"><mrow><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo></mrow></math></mathml>表示既不包含特征词<i>w</i><sub><i>i</i></sub>又不包含特征词<i>w</i><sub><i>j</i></sub>的文档数占总文档数的概率。</p>
                </div>
                <div class="p1">
                    <p id="66">文本数据包含大量的特征词,计算特征词之间的互信息值时,mRMR算法通常采用增量式搜索思想获得最优特征集合<i>S</i>。假设已经筛选出特征子集<i>S</i><sub><i>k</i></sub>-1,即特征子集里已经包含<i>k</i>-1个特征词,然后从剩余的特征词集合{<i>D</i><sub>1</sub>-<i>S</i><sub><i>k</i></sub>-1}中选择第<i>k</i>个特征词<citation id="221" type="reference"><link href="186" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,第<i>k</i>个特征词的选取计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>D</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></munder><mrow><mo>[</mo><mrow><mi>Ι</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>;</mo><mi>C</mi><mo stretchy="false">)</mo><mo>-</mo><mfrac><mn>1</mn><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></munder><mi>Ι</mi></mstyle><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>;</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="68" name="68" class="anchor-tag">2 改进的mRMR特征选择方法</h3>
                <div class="p1">
                    <p id="69">传统mRMR算法直接计算最大相关和最小冗余差值,难以准确选择相关性和冗余性的权重。文献<citation id="222" type="reference">[<a class="sup">7</a>]</citation>对mRMR算法的最大相关与最小冗余进行线性加权,并通过实验验证,当最大相关部分的权重为0.25时,分类精确度最高。因此,本文引入类差分度差值<i>α</i>,并动态设置最大相关部分的权重。</p>
                </div>
                <h4 class="anchor-tag" id="70" name="70">2.1 类差分度差值</h4>
                <div class="p1">
                    <p id="71">类差分度是指具有较强影响力的特征项应该集中出现在某一或某几类中,且在类别包含的文档中均匀分布<citation id="223" type="reference"><link href="200" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。类差分度将类间的离散度(<i>AC</i>)和类内特征项的耦合度(<i>DC</i>)结合,既考虑特征项在不同类文本中出现的频数,也考虑了特征项在同一类文本中分布的差异性。</p>
                </div>
                <div class="p1">
                    <p id="72">类间离散度表示特征词在各个类别文档中的分布情况,表征能力强的特征词集中出现在某一类文档中,而不会在所有类别文档中均匀分布。类间离散度的计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>C</mi><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></mfrac><mo stretchy="false">(</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mo stretchy="false">(</mo><mi>f</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mover accent="true"><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">其中,<i>m</i>表示文本所属类别数,<i>f</i><sub><i>t</i></sub>(<i>w</i><sub><i>i</i></sub>)表示在类别<i>C</i><sub><i>t</i></sub>中包含特征词<i>w</i><sub><i>i</i></sub>的文档数,<mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mo stretchy="true">¯</mo></mover></mrow></math></mathml>表示包含特征词w<sub>i</sub>的总文档在每个类别中的平均文档数。AC值越大,表明该特征词w<sub>i</sub>在对类别的区分能力越强。</p>
                </div>
                <div class="p1">
                    <p id="75">类内耦合度表示特征词在某类文档内部的分布情况,表征能力强的特征词在类内呈现均匀分布,不会集中出现在某几篇或者某一片文档之中。类间耦合度计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>p</mi><mi>n</mi></munderover><mrow><mo stretchy="false">(</mo><mi>g</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mover accent="true"><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false">)</mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">其中,DC<sub>t</sub>表示特征词w<sub>i</sub>在C<sub>t</sub>类中的类内耦合度值,n表示属于C<sub>t</sub>类的文档总数,<i>g</i><sub>p</sub>(w<sub>i</sub>)表示特征词w<sub>i</sub>在C<sub>t</sub>类第p篇文档中的词频数,<mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mo stretchy="true">¯</mo></mover></mrow></math></mathml>表示在<i>C</i><sub><i>t</i></sub>类所有文档中特征词<i>w</i><sub><i>i</i></sub>的平均词频数。<i>DC</i><sub><i>t</i></sub>值越小,表示该特征词对类别<i>C</i><sub><i>t</i></sub>的表征能力越强。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">2.2 改进的mRMR算法</h4>
                <div class="p1">
                    <p id="79">mRMR算法考虑了特征词对所有类别的互信息值,本文引入类差分度<i>β</i>的差值来细化互信息值。具体地,本文选取所有类别中类差分度<i>β</i>最大的2个值作差。差值越大,表示该特征只在某一类中类差分度较大,在其他类中类差分度较小,说明该特征只在某一类中集中出现,在其他类中出现频率较低,因此该特征能够唯一确定某一类,对该类的表征能力较强,对其他类的表征能力较弱。然而,差值越小,表示该特征至少在2个类中出现的频率相近,即特征不能确定类别,对类别的表征能力较弱。此外,引入差值后借助对数处理对其进行尺寸压缩。在不改变数据性质以及特征与类别之间相关性的基础上使数据更加平稳。其计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula"><mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>α</mi><mo>=</mo><mtext>l</mtext><mtext>b</mtext><mo stretchy="false">(</mo><mi>β</mi><msubsup><mrow></mrow><mrow><mi>max</mi></mrow><mn>1</mn></msubsup><mo>-</mo><mi>β</mi><msubsup><mrow></mrow><mrow><mi>max</mi></mrow><mn>2</mn></msubsup><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mi>λ</mi></mfrac></mrow></msup><mo>=</mo><mtext>l</mtext><mtext>b</mtext></mrow></math></mathml><mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mfrac><mrow><mi>A</mi><mi>C</mi></mrow><mrow><mi>D</mi><mi>C</mi><msubsup><mrow></mrow><mrow><mi>min</mi></mrow><mn>1</mn></msubsup></mrow></mfrac><mo>-</mo><mfrac><mrow><mi>A</mi><mi>C</mi></mrow><mrow><mi>D</mi><mi>C</mi><msubsup><mrow></mrow><mrow><mi>min</mi></mrow><mn>2</mn></msubsup></mrow></mfrac></mrow><mo>)</mo></mrow><mrow><mfrac><mn>1</mn><mi>λ</mi></mfrac></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="81">其中,<i>β</i><mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>max</mi></mrow><mn>1</mn></msubsup></mrow></math></mathml>=<i>AC</i>/<i>DC</i><mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>min</mi></mrow><mn>1</mn></msubsup></mrow></math></mathml>和<i>β</i><mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>max</mi></mrow><mn>2</mn></msubsup></mrow></math></mathml>=<i>AC</i>/<i>DC</i><mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>min</mi></mrow><mn>2</mn></msubsup></mrow></math></mathml>表示特征词w<sub>i</sub>在所有类别中最大的2个类的类差分度值,λ是一个常数,α表示类差分度差值,并对差值取对数。</p>
                </div>
                <div class="p1">
                    <p id="82">将上述类差分度引入<i>mRMR</i>方法,计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>D</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></munder><mrow><mo>[</mo><mrow><mi>α</mi><mi>Ι</mi><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>;</mo><mi>C</mi><mo stretchy="false">)</mo><mo>-</mo><mfrac><mn>1</mn><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></munder><mi>Ι</mi></mstyle><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>;</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">基于改进的<i>mRMR</i>特征词选择算法具体描述如下:</p>
                </div>
                <div class="p1">
                    <p id="85"><b>输入</b> 初次IG算法选择特征词集<i>igFeatureList</i>,按信息增益值降序排序,文档数据集<i>data</i>,最终所需的特征数<i>selectNum</i></p>
                </div>
                <div class="p1">
                    <p id="86"><b>输出</b> 最终选择特征词集合<i>selectFeature</i></p>
                </div>
                <div class="p1">
                    <p id="87">1.WordsClassMIDict//存放特征词与类别之间的互信//息值</p>
                </div>
                <div class="p1">
                    <p id="88">2.alpha//存放特征词的类差分度</p>
                </div>
                <div class="p1">
                    <p id="89">3.selectFeature//存放最终选择的特征词集合</p>
                </div>
                <div class="p1">
                    <p id="90">4.//计算特征词与类别之间互信息值,并降序排序,存//入WordsClassMIDict</p>
                </div>
                <div class="p1">
                    <p id="92">5.WordsClassMI=CalculateWordClassMI(data,igFeatureList)</p>
                </div>
                <div class="p1">
                    <p id="93">6.//计算每个特征词的类差分度,存入alpha</p>
                </div>
                <div class="p1">
                    <p id="94">7.Alpha=CalculateWordClassDiffDegree(data)</p>
                </div>
                <div class="p1">
                    <p id="95">8.//选择igFeatureList中信息增益值最高的特征词,存//入selectFeature</p>
                </div>
                <div class="p1">
                    <p id="97">9.selectFeature.append(igFeatureList[0])</p>
                </div>
                <div class="p1">
                    <p id="98">10.//创建一个字典存放特征词和最后一个选择的单词//的互信息值(MI_ij)的累加和</p>
                </div>
                <div class="p1">
                    <p id="100">11.for i in range(1,len(WordClassMIDict)):</p>
                </div>
                <div class="p1">
                    <p id="101">12.sumDict[WordClassDict[i]] = 0.0</p>
                </div>
                <div class="p1">
                    <p id="102">13.while(len(selectFeature) &lt;= selectNum):</p>
                </div>
                <div class="p1">
                    <p id="103">14.maxNum = 0.0</p>
                </div>
                <div class="p1">
                    <p id="104">15.for i in range(1,len(WordsClassMIDict)):</p>
                </div>
                <div class="p1">
                    <p id="105">16.word_i = WordsClassMIDict[i]</p>
                </div>
                <div class="p1">
                    <p id="106">17.Word_j=selectFeature[-1]</p>
                </div>
                <div class="p1">
                    <p id="107">18.//计算2个特征词之间的互信息值</p>
                </div>
                <div class="p1">
                    <p id="108">MI_ij=Calculate2WordsMI(word_i,word_j)</p>
                </div>
                <div class="p1">
                    <p id="109">19.sumDict[word_i] += MI_ij</p>
                </div>
                <div class="p1">
                    <p id="110">20.temp=alpha[word_i]×WordClassMI[word_i]- (sumDict[word_i]/len(selectFeature))</p>
                </div>
                <div class="p1">
                    <p id="111">21.if (temp &gt; maxNum):</p>
                </div>
                <div class="p1">
                    <p id="112">22.tempWord = word_i</p>
                </div>
                <div class="p1">
                    <p id="113">23.maxNum = temp</p>
                </div>
                <div class="p1">
                    <p id="114">24.//添加tempWord到selectFeature</p>
                </div>
                <div class="p1">
                    <p id="115">25.selectFeature.append(tempWord)</p>
                </div>
                <div class="p1">
                    <p id="116">26.//sumDict中移除tempWord</p>
                </div>
                <div class="p1">
                    <p id="117">27.sumDict.pop(tempWord)</p>
                </div>
                <div class="p1">
                    <p id="118">28.//特征词集合中移除tempWord</p>
                </div>
                <div class="p1">
                    <p id="119">29.WordClassMIDict.pop(tempWord)</p>
                </div>
                <div class="p1">
                    <p id="120">30.//返回最终的特征词集合</p>
                </div>
                <div class="p1">
                    <p id="121">31.return selectFeature</p>
                </div>
                <h3 id="122" name="122" class="anchor-tag">3 实验结果与分析</h3>
                <div class="p1">
                    <p id="123">为验证算法的分类效果,本文选取IMDB、康奈尔影评以及ling-spam垃圾邮件作为实验数据集。为保证语料的结构化,对语料库的停用词进行预处理,去掉标点符号及其他特殊字符。本文实验选取70%的数据作为训练集,30%作为测试集,分类器采用高斯核的支持向量机模型,实验平台使用Python3.6。</p>
                </div>
                <div class="p1">
                    <p id="124">本文利用信息增益、信息增益与最大相关最小冗余(IG_mRMR)以及信息增益与改进最大相关最小冗余(IG_CDmRMR)分别筛选出各自特征子集,并利用各自的特征子集对文本进行向量化处理。本文使用词频-逆文本数(TF-IDF)算法对文本进行向量化,并进行归一化处理,实验采用十折交叉验证方法,选择查准率(Precision)、召回率(Recall)以及F1值作为评价标准。</p>
                </div>
                <div class="p1">
                    <p id="125">本文使用IG、IG_mRMR、IG_CDmRMR这3种方法选取IMDB、康奈尔影评以及垃圾邮件数据集各自特征子集,且特征子集的维度为10～100(间隔10),其中,IMDB与康奈尔影评提取的特征子集结果如表1所示(选取前20维特征子集)。IMDB与康奈尔影评只分为积极与消极2种类型,根据文献<citation id="224" type="reference">[<a class="sup">17</a>]</citation>对文本情感的分析,评价词在文本情感中具有重要的作用,主要包括形容词、副词的情感词。从表1可以看出,IG、IG_mRMR、IG_CDmRMR提取的IMDB评价词语(加粗)分别有14个、15个、17个,提取康奈尔影评的评价词分别为16个、17个、18个。</p>
                </div>
                <div class="area_img" id="126">
                    <p class="img_tit"><b>表1 IMDB、康奈尔影评数据集的特征子集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="126" border="1"><tr><td><br />方法</td><td>IMDB</td><td>康奈尔影评</td></tr><tr><td>IG方法</td><td><b>bad,worst,waste,great,best,stupid,terrible</b>,minutes,<b>beautiful,worse,poor</b>,stewart,<b>awful</b>,flynn,<b>perfect,superb</b>,hitchcock,<b>wonderful</b>,doris,avoid</td><td><b>bad,worst,waste,lame,mess,awful</b>,world,<b>stupid,boring,dull,complex,great,solid</b>,also,<b>outstanding,quite</b>,maybe,<b>perfect,wonderfully</b>,perfor-mance</td></tr><tr><td><br />IG_mRMR方法</td><td><b>bad,worst,waste,great,stupid,best</b>,stewart,flynn,<b>terrible,beautiful</b>,minutes,<b>poor,superb,worse,awful</b>,madonna,<b>good</b>,bullock,<b>barker,wasted</b></td><td><b>bad,world,waste,worst,lame,awful,stupid,mess,complex,dull,great,outstanding,solid,boring,quite,perfect</b>,maybe,<b>wonderfully</b>,involve,also</td></tr><tr><td><br />IG_CDmRMR方法</td><td><b>bad,worst,waste,great,stupid,superb,mess,beautiful,terrible,worse,wasted,best,poor</b>,avoid,unless,<b>perfect,annoying,highly</b>,minutes,<b>wonderful</b></td><td><b>bad,waste,complex,lame,awful,worst,mess,outstanding,solid</b>,involve,<b>dull,laughable,stupid,wonderfully,painfully,flat,lifeless,allow</b>,maybe,<b>boring</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="127">为比较3种特征选择方法分类效果,本文选择数据集中10维～100维特征进行准确率增长性分析,对数据集中100维～1 000维特征进行F1值的稳定性分析,如图2和图3所示。从图2可以看出,随着特征维度的增加,3种特征提取方法最终分类准确率呈明显上升趋势。当最终分类准确率达到80%时,本文提出的IG_CDmRMR特征提取方法所需特征数量最少,比其他2种方法特征词数量减少5个～10个。当选择相同数量的特征子集时,本文提出的IG_CDmRMR方法准确率最高,比其他2种方法提升约2%。从图3可以看出,当特征维度达到一定维度(IMDB数据集是400维左右,康奈尔影评数据集是300维左右,垃圾邮件数据集是700维左右),能够准确地区分文本类别的大部分特征词,此时分类效果最佳。当继续增加筛选的特征子集的维度时,表征能力弱的特征词将被筛选进入特征子集,造成干扰,从而导致分类准确率下降。本文提出的IG_CDmRMR方法相比其他2种方法,其相同特征维度下F1值平均高出1个～2个百分点,正确分类文本数增加15篇～25篇。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909029_128.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 3种方法的准确率对比结果" src="Detail/GetImg?filename=images/JSJC201909029_128.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 3种方法的准确率对比结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909029_128.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="129" name="129" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="130">传统特征提取方法仅考虑特征与文本类别之间的相关性,忽略了特征词之间的冗余信息。因此,本文通过结合信息增益和改进的最大相关最小冗余,提出一种基于IG_CDmRMR两阶段的特征选择方法。利用IG和mRMR进行特征筛选,去除存在冗余的特征词,最终得到最优特征子集。实验结果表明,本文提出的特征词提取方法能够准确地选择合适的特征子集。后续将对该方法进行改进,进一步提高文本的分类准确率。</p>
                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909029_131.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 3种方法的F1值对比结果" src="Detail/GetImg?filename=images/JSJC201909029_131.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 3种方法的F1值对比结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909029_131.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="170">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCMC9A4F802A4669E0321446318E4C4A44F&amp;v=MTQ3Mzg4SkNuVk16eFVSNnp0NVRuempwR2N4Q3JibFFiN3BDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOMWh3N3kyd0s4PU5pZklZOEN4YjlXNnA0OUhGZQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> PANDOVE D,GOEL S,RANI R.Systematic review of cluster high-dimensional and large datasets[J].ACM Transactions on Knowledge Discovery from Data,2018,12(2):1-68.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600390941&amp;v=MjY4NDV5am1VTHJJSjFvZGFoVT1OaWZPZmJLOEh0RE1xWTlGWitJUEJYZzRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> SHANG Changxing,LI Min,FENG Shengzhong,et al.Feature selection via maximizing global information gain for text classification[J].Knowledge-Based Systems,2013,54(4):298-309.
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Probability variance CHI feature selection method for unbalanced data">

                                <b>[3]</b> ZHANG Xiaowen,CHEN Bingfeng.Probability variance CHI feature selection method for unbalanced data[EB/OL].[2018-02-20].http://adsabs.harvard.edu/abs/2017 AIPC.1864b0015Z.
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The keyword extraction of Chinese medical Web page based on WF-TF-IDF algorithm">

                                <b>[4]</b> SUN Peng,WANG Lihua,XIA Qianchen.The keyword extraction of Chinese medical Web page based on WF-TF-IDF algorithm[C]//Proceedings of International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery.Washington D.C.,USA:IEEE Press,2017:193-198.
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZTSX201403007&amp;v=MDg3NjJuWWRyRzRIOVhNckk5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckZ5L2hXci9QUHo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 王露,龚红光.基于ReliefF+mRMR特征降维算法的多特征遥感图像分类[J].中国体视学与图像分析,2014(3):250-257.
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Statistical pattern recognition: a review">

                                <b>[6]</b> JAIN A K,DUIN P W.Statistical pattern recognition:a review[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2000,22(1):4-37.
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLZD201707014&amp;v=MDQyNDllUnJGeS9oV3IvUElTSFJhckc0SDliTXFJOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 和怡,朱小军,李登峰,等.基于模态分析和Relief算法的在线静态电压稳定特征选取方法[J].电力系统及自动化学报,2017,29(7):87-92.
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201705024&amp;v=MjU5OTVIWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnkvaFdyL1BLelRNZTdHNEg5Yk1xbzk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> MA Huiqin,HUANG Wenjiang,JING Yuanshu,et al.Remote sensing monitoring of wheat powdery mildew based on AdaBoost model combining mRMR algorithm[J].Transactions of the Chinese Society of Agricultural Engineering,2017,33(5):162-169.
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNSX201206043&amp;v=MzA3NzFyRnkvaFdyL1BMU1BZZHJHNEg5UE1xWTlCWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 卢中宁,张保威.一种基于改进TF-IDF函数的文本分类方法[J].河南师范大学学报(自然科学版),2012,40(6):158-160,174.
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive naive Bayesian classifier for automatic classification of webpage from massive network data">

                                <b>[10]</b> XU Linbin,LIU Jun,ZHOU Wenli,et al,Adaptive naive Bayesian classifier for automatic classification of webpage from massive network data[C]//Proceedings of the 6th International Conference on Intelligent Human-machine Systems and Cybernetics.Washington D.C.,USA:IEEE Press,2014:127-130.
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKZX201520010&amp;v=MzAzODVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeS9oV3IvUFB5YlJkckc0SDlUT3I0OUVaSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 任军,葛卫丽,陈家勇.一种基于类差分度的互信息特征选择方法[J].中国科技论文,2015(20):2386-2389.
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201906028&amp;v=MjIyNzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnkvaFdyL1BMejdCYmJHNEg5ak1xWTlIYkk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 王旭仁,马慧珍,冯安然,等.基于信息增益与主成分分析的网络入侵检测研究[J].计算机工程,2019,45(6):175-180.
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201303040&amp;v=MjU4NjhIOUxNckk5QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckZ5L2hXci9QTHo3WWFiRzQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 胡颖.基于信息增益的文本特征选择方法[J].计算机与数字工程,2013,39(3):460-462.
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201310055&amp;v=MDk4Nzh0R0ZyQ1VSTE9lWmVSckZ5L2hXci9QTHo3QmI3RzRIOUxOcjQ5QVlZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 任永功,杨雪,杨荣杰,等.基于信息增益特征关联树的文本特征选择算法[J].计算机科学,2013,40(10):252-256.
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201401020&amp;v=Mjk5NzE0TzN6cXFCdEdGckNVUkxPZVplUnJGeS9oV3IvUFB5cmZiTEc0SDlYTXJvOUhaSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 邹利东,潘耀忠,朱文泉,等.结合领域相关影响与最大相关最小冗余性特征选择的面向对象化检测[J].中国图象图形学报,2014,19(1):158-166.
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201303053&amp;v=MDM3MTBSckZ5L2hXci9QTHpUWlpMRzRIOUxNckk5QVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 周奇年,张振浩,虚登彩.用于中文文本分类的基于类别区分词的特征选择方法[J].计算机应用与软件,2013,33(7):193-195.
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201008009&amp;v=MTQ1OThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnkvaFdyL1BOeWZUYkxHNEg5SE1wNDlGYlk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 赵妍妍,秦兵,刘挺.文本情感分析[J].软件学报,2010,21(8):1834-1848.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201909029" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201909029&amp;v=MjYzODJDVVJMT2VaZVJyRnkvaFdyL1BMejdCYmJHNEg5ak1wbzlIYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTg2cENpRHQrYkl2cFdneFdFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
