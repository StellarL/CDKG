<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637129054619962500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201908033%26RESULT%3d1%26SIGN%3d85ISCYA%252fNL55NDkPyNcrG2SLNbE%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201908033&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201908033&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201908033&amp;v=MDg5NzdCdEdGckNVUkxPZVplUnFGQ2psVmIzQUx6N0JiYkc0SDlqTXA0OUdaNFFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="1 循环神经网络 ">1 循环神经网络</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="1.1 简单的循环神经网络">1.1 简单的循环神经网络</a></li>
                                                <li><a href="#59" data-title="1.2 长短期记忆网络">1.2 长短期记忆网络</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#70" data-title="2 基于RNN的推荐算法 ">2 基于RNN的推荐算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#78" data-title="2.1 用户和电影状态">2.1 用户和电影状态</a></li>
                                                <li><a href="#91" data-title="2.2 评分预测">2.2 评分预测</a></li>
                                                <li><a href="#95" data-title="2.3 模型训练">2.3 模型训练</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#110" data-title="3.1 数据集描述">3.1 数据集描述</a></li>
                                                <li><a href="#113" data-title="3.2 实验设置">3.2 实验设置</a></li>
                                                <li><a href="#116" data-title="3.3 结果分析">3.3 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#137" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="&lt;b&gt;图1 RNN结构&lt;/b&gt;"><b>图1 RNN结构</b></a></li>
                                                <li><a href="#49" data-title="&lt;b&gt;图2 RNN时间线展开结构&lt;/b&gt;"><b>图2 RNN时间线展开结构</b></a></li>
                                                <li><a href="#61" data-title="&lt;b&gt;图3 LSTM结构&lt;/b&gt;"><b>图3 LSTM结构</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;图4 R-RNN模型结构&lt;/b&gt;"><b>图4 R-RNN模型结构</b></a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;表1 实验数据集的详细数据&lt;/b&gt;"><b>表1 实验数据集的详细数据</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;表2 1层隐藏层不同节点数自编码器对应的RMSE&lt;/b&gt;"><b>表2 1层隐藏层不同节点数自编码器对应的RMSE</b></a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;表3 3层隐藏层不同节点数自编码器对应的RMSE&lt;/b&gt;"><b>表3 3层隐藏层不同节点数自编码器对应的RMSE</b></a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;表4 5层隐藏层不同节点数自编码器对应的RMSE&lt;/b&gt;"><b>表4 5层隐藏层不同节点数自编码器对应的RMSE</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;表5 不同单元隐藏层和细胞状态节点数对应的RMSE&lt;/b&gt;"><b>表5 不同单元隐藏层和细胞状态节点数对应的RMSE</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;表6 各算法在不同数据集上的RMSE&lt;/b&gt;"><b>表6 各算法在不同数据集上的RMSE</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="157">


                                    <a id="bibliography_1" title=" BENNETT J, LANNING S.The netflix prize[C]//Proceedings of KDD Cup and Workshop.San Jose, USA:[s.n.], 2007:35." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The netflix prize">
                                        <b>[1]</b>
                                         BENNETT J, LANNING S.The netflix prize[C]//Proceedings of KDD Cup and Workshop.San Jose, USA:[s.n.], 2007:35.
                                    </a>
                                </li>
                                <li id="159">


                                    <a id="bibliography_2" title=" ZHAO Jingling, LI Yan, ZHANG Ye.A recommendation algorithm via developed random walk takes user’s preference and item’s genres[C]//Proceedings of 2017 International Conference on Information System and Data Mining.New York, USA:ACM Press, 2017:61-65." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A recommendation algorithm via developed random walk takes user&amp;#39;&amp;#39;s preference and item&amp;#39;&amp;#39;s genres">
                                        <b>[2]</b>
                                         ZHAO Jingling, LI Yan, ZHANG Ye.A recommendation algorithm via developed random walk takes user’s preference and item’s genres[C]//Proceedings of 2017 International Conference on Information System and Data Mining.New York, USA:ACM Press, 2017:61-65.
                                    </a>
                                </li>
                                <li id="161">


                                    <a id="bibliography_3" title=" MA Li, WANG Xingjun.An ensemble algorithm used in video recommendation system[C]//Proceedings of 2017 International Conference on Big Data Research.New York, USA:ACM Press, 2017:67-71." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An ensemble algorithm used in video recommendation system">
                                        <b>[3]</b>
                                         MA Li, WANG Xingjun.An ensemble algorithm used in video recommendation system[C]//Proceedings of 2017 International Conference on Big Data Research.New York, USA:ACM Press, 2017:67-71.
                                    </a>
                                </li>
                                <li id="163">


                                    <a id="bibliography_4" title=" KARATZOGLOU A, HIDASI B.Deep learning for recom-mender systems[C]//Proceedings of the 11th ACM Conference on Recommender Systems.New York, USA:ACM Press, 2017:396-397." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep learning for recom-mender systems">
                                        <b>[4]</b>
                                         KARATZOGLOU A, HIDASI B.Deep learning for recom-mender systems[C]//Proceedings of the 11th ACM Conference on Recommender Systems.New York, USA:ACM Press, 2017:396-397.
                                    </a>
                                </li>
                                <li id="165">


                                    <a id="bibliography_5" title=" 李卫疆, 齐静, 余正涛, 等.融合信任传播和奇异值分解的社会化推荐算法[J].计算机工程, 2017, 43 (8) :236-242." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201708041&amp;v=MjA0NzVCWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRkNqbFZiM0FMejdCYmJHNEg5Yk1wNDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         李卫疆, 齐静, 余正涛, 等.融合信任传播和奇异值分解的社会化推荐算法[J].计算机工程, 2017, 43 (8) :236-242.
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_6" title=" SALAKHUTDINOV R, MNIH A.Probabilistic matrix factorization[C]//Proceedings of Advances in Neural Information Processing Systems.[S.l.]:NIPS Inc., 2008:1257-1264." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Probabilistic matrix factorization">
                                        <b>[6]</b>
                                         SALAKHUTDINOV R, MNIH A.Probabilistic matrix factorization[C]//Proceedings of Advances in Neural Information Processing Systems.[S.l.]:NIPS Inc., 2008:1257-1264.
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_7" title=" 王锦坤, 姜元春, 孙见山, 等.考虑用户活跃度和项目流行度的基于项目最近邻的协同过滤算法[J].计算机科学, 2016, 43 (12) :158-162." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201612029&amp;v=MDA0Mjk5Zk5yWTlIYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRkNqbFZiM0FMejdCYjdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         王锦坤, 姜元春, 孙见山, 等.考虑用户活跃度和项目流行度的基于项目最近邻的协同过滤算法[J].计算机科学, 2016, 43 (12) :158-162.
                                    </a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_8" title=" BEUTEL A, AHMED A, SMOLA A J.ACCAMS:additive co-clustering to approximate matrices succinctly[C]//Proceedings of the 24th International Conference on World Wide Web.New York, USA:ACM Press, 2015:119-129." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accams:Additive co-clustering to approx-imate matrices succinctly">
                                        <b>[8]</b>
                                         BEUTEL A, AHMED A, SMOLA A J.ACCAMS:additive co-clustering to approximate matrices succinctly[C]//Proceedings of the 24th International Conference on World Wide Web.New York, USA:ACM Press, 2015:119-129.
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_9" title=" KOREN Y.Collaborative filtering with temporal dynamics[C]//Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM Press, 2009:447-456." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Collaborative filtering with temporal dynamics">
                                        <b>[9]</b>
                                         KOREN Y.Collaborative filtering with temporal dynamics[C]//Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM Press, 2009:447-456.
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_10" title=" 谭黎立, 聂瑞华, 梁军, 等.基于动态时间的个性化推荐模型[J].华南师范大学学报 (自然科学版) , 2017, 49 (3) :123-128." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNSF201703022&amp;v=MTM1NTdiM0FMU1BZYUxHNEg5Yk1ySTlIWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRkNqbFY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         谭黎立, 聂瑞华, 梁军, 等.基于动态时间的个性化推荐模型[J].华南师范大学学报 (自然科学版) , 2017, 49 (3) :123-128.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_11" title=" 李忠武, 王辉, 魏再超.基于推荐系统时间敏感的因子模型算法研究[J].电子商务.2017 (9) :55-56, 89." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKJ201709027&amp;v=MTE1MDhaZVJxRkNqbFZiM0FJVGZBWkxHNEg5Yk1wbzlIWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         李忠武, 王辉, 魏再超.基于推荐系统时间敏感的因子模型算法研究[J].电子商务.2017 (9) :55-56, 89.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_12" title=" DU K, SWAMY M N S.Recurrent neural networks[M].London, UK:Springer, 2014:337-353." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recurrent neural networks">
                                        <b>[12]</b>
                                         DU K, SWAMY M N S.Recurrent neural networks[M].London, UK:Springer, 2014:337-353.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_13" title=" 俞骋超.基于深度神经网络的用户会话推荐算法研究[D].杭州:浙江大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016063588.nh&amp;v=MDM3NDg2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2psVmIzQVZGMjZHTE8rSGRURXA1RWJQSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         俞骋超.基于深度神经网络的用户会话推荐算法研究[D].杭州:浙江大学, 2016.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_14" title=" 陆泽楠, 商玉林.基于LSTM神经网络模型的钢铁价格预测[J].科技视界, 2017 (13) :116-117." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KJSJ201713084&amp;v=MjAyMjBMaWZZWkxHNEg5Yk5ySTlOWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRkNqbFZiM0E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         陆泽楠, 商玉林.基于LSTM神经网络模型的钢铁价格预测[J].科技视界, 2017 (13) :116-117.
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_15" title=" ZENG Daojian, LIU Kang, LAI Siwei, et al.Relation classification via convolutional deep neural network[C]//Proceedings of COLING’14.Dublin, Ireland:[s.n.], 2014:2335-2344." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Relation Classification via Convolution al Deep Neural Network">
                                        <b>[15]</b>
                                         ZENG Daojian, LIU Kang, LAI Siwei, et al.Relation classification via convolutional deep neural network[C]//Proceedings of COLING’14.Dublin, Ireland:[s.n.], 2014:2335-2344.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_16" title=" SEDHAIN S, MENON A K, SANNER S, et al.Autorec:autoencoders meet collaborative filtering[C]//Proceedings of the 24th International Conference on World Wide Web.New York, USA:ACM Press, 2015:111-112." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Autorec:Autoencoders meet collaborative filtering">
                                        <b>[16]</b>
                                         SEDHAIN S, MENON A K, SANNER S, et al.Autorec:autoencoders meet collaborative filtering[C]//Proceedings of the 24th International Conference on World Wide Web.New York, USA:ACM Press, 2015:111-112.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_17" title=" 罗频捷, 温荷.基于改进BP神经网络的个性化推荐算法研究[J].四川理工学院学报 (自然科学版) , 2016, 29 (1) :39-43." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCQX201601010&amp;v=MjIxMjhaZVJxRkNqbFZiM0FOaTdhZHJHNEg5Zk1ybzlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         罗频捷, 温荷.基于改进BP神经网络的个性化推荐算法研究[J].四川理工学院学报 (自然科学版) , 2016, 29 (1) :39-43.
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_18" title=" 章敏敏, 徐和平, 王晓洁, 等.谷歌TensorFlow机器学习框架及应用[J].微型机与应用, 2017, 36 (10) :58-60." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201710017&amp;v=MTU1MDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRkNqbFZiM0FNalhCZDdHNEg5Yk5yNDlFWTRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         章敏敏, 徐和平, 王晓洁, 等.谷歌TensorFlow机器学习框架及应用[J].微型机与应用, 2017, 36 (10) :58-60.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(08),198-202+209 DOI:10.19678/j.issn.1000-3428.0051294            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于循环神经网络的推荐算法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%AB%98%E8%8C%82%E5%BA%AD&amp;code=09582808&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高茂庭</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E5%BD%AC%E6%BA%90&amp;code=39851623&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐彬源</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E6%B5%B7%E4%BA%8B%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0121742&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海海事大学信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>传统电影推荐算法多数基于用户和电影的静态属性进行推荐, 忽略了时间序列数据内在的时间和因果因素, 推荐质量不高。为此, 利用循环神经网络 (RNN) 在处理时间序列上的优势, 提出一种推荐算法R-RNN。采用2个长短期记忆网络分别挖掘用户和电影的潜在状态, 实现长距离的历史状态积累, 将用户状态和电影状态的内积作为最终评分。在IMDB和Netflix数据集及Netflix子集上的实验结果表明, 与基于概率矩阵分解、TimeSVD++及AutoRec算法相比, 该算法能够有效降低均方根误差, 并提高预测评分的准确度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">推荐算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">循环神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长短期记忆网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%B6%E9%97%B4%E5%8A%A8%E6%80%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">时间动态;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%BD%9C%E5%9C%A8%E7%8A%B6%E6%80%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">潜在状态;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    高茂庭 (1963—) , 男, 教授、博士, 主研方向为智能信息处理、数据库与信息系统;;
                                </span>
                                <span>
                                    徐彬源, 硕士研究生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-04-23</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61202022);</span>
                    </p>
            </div>
                    <h1><b>Recommendation Algorithm Based on Recurrent Neural Network</b></h1>
                    <h2>
                    <span>GAO Maoting</span>
                    <span>XU Binyuan</span>
            </h2>
                    <h2>
                    <span>Collage of Information Engineering, Shanghai Maritime University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The traditional movie recommendation algorithms mostly make recommendations based on the static attributes of users and movies, which ignores the inherent temporal and causal relationship in the time series data.The recommendation quality need to be improved.To this end, taking the advantage of Recurrent Neural Network (RNN) in processing time series, this paper proposes a recommendation algorithm R-RNN.Two Long-Short Term Memorys (LSTMs) are used to mine the potential status of users and films, long historical status accumulation is realized, and the prediction score is obtained by the inner product of the user status and the movie status.Experiments on IMDB and Netflix datasets and Netflix subsets show that compared with those of the probability matrix decomposition, TimeSVD++ and AutoRec algorithms, the algorithm can effectively reduce the root mean square error and improve the accuracy of the rating prediction.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=recommendation%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">recommendation algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Recurrent%20Neural%20Network%20(RNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Recurrent Neural Network (RNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Long-Short%20Term%20Memory%20(LSTM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Long-Short Term Memory (LSTM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=time%20dynamics&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">time dynamics;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=potential%20status&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">potential status;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-04-23</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="40">电影领域的现有推荐方法主要是在一组由用户、电影、时间戳和评分组成的元组中, 为用户、电影、时间戳这3个属性的选择性组合预测评分, 通过预测评分与实际评分的偏差来衡量推荐质量<citation id="193" type="reference"><link href="157" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。基于这些组合, 研究者提出不同的推荐算法<citation id="197" type="reference"><link href="159" rel="bibliography" /><link href="161" rel="bibliography" /><link href="163" rel="bibliography" /><link href="165" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>, 如基于概率矩阵分解 (Probabilistic Matrix Factorization, PMF) <citation id="194" type="reference"><link href="167" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、最近邻<citation id="195" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>和聚类<citation id="196" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>方法等。</p>
                </div>
                <div class="p1">
                    <p id="41">上述方法在一定程度上缓解了评分矩阵的稀疏性问题, 但其基于用户和电影的属性是固定的这一假设, 没有考虑到时间序列数据中固有的时间和因果关系。时间序列数据是一种数据属性随时间变化的高维数据类型, 反映了用户状态 (如用户兴趣) 和电影状态 (如电影流行度) 的动态变化。例如在日常生活中, 用户的喜好会随思想的成熟或生活方式的变化而转变, 对特定类型节目的兴趣也会有所减弱或加强。因此, 除了对时间动态建模外, 还需要克服用后见之明的方式预测评分, 满足因果关系的预测。传统推荐算法没有明确区分用户评分的时间先后顺序, 甚至使用未来评分估计当前评分, 这在统计分析中违反了因果关系。由于受到训练和测试数据混合分布的阻碍, 算法在未来预测方面遇到了挑战。研究显示, 通过建立时序模型, 利用时间序列数据, 能够根据当前趋势更准确地预测未来行为。</p>
                </div>
                <div class="p1">
                    <p id="42">文献<citation id="198" type="reference">[<a class="sup">9</a>]</citation>重点研究基于协同过滤的推荐系统的时间效应建模问题, 分析时间特征对协同过滤的影响, 认为用户随时间改变其评价习惯和偏好, 电影的流行度也在随时间而变化, 提出了TimeSVD++算法, 但该算法不能预测未来的行为。</p>
                </div>
                <div class="p1">
                    <p id="43">文献<citation id="199" type="reference">[<a class="sup">10</a>]</citation>建立一种基于动态时间的个性化推荐算法, 引入遗忘曲线来跟踪用户对资源偏好程度随时间变化情况, 能获取准确的用户偏好信息, 提高推荐质量。文献<citation id="200" type="reference">[<a class="sup">11</a>]</citation>考虑时间效应信息, 基于矩阵因子分解, 提出了基于推荐系统时间敏感因子的算法。上述算法利用时序数据在一定程度上提高了预测精度, 但只分析了用户的时间状态, 缺乏对物品时间状态的挖掘。</p>
                </div>
                <div class="p1">
                    <p id="44">本文提出基于循环神经网络 (Recurrent Neural Network, RNN) <citation id="202" type="reference"><link href="179" rel="bibliography" /><link href="181" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>的推荐算法R-RNN, 考虑到时间序列数据和现实中的因果关系, 严格按照评分发生的时间顺序划分数据集, 用2个长短期记忆网络 (Long-Short Term Memory, LSTM) <citation id="201" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>模型分别获取用户和电影的时间状态, 根据用户和电影的历史状态预测下一时刻的评分行为。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag">1 循环神经网络</h3>
                <h4 class="anchor-tag" id="46" name="46">1.1 简单的循环神经网络</h4>
                <div class="p1">
                    <p id="47">RNN通过网络中的循环结构记录时序数据的历史信息, 其特殊的结构特别适用于处理各种时序数据。与普通神经网络相比, RNN的隐藏层之间是相连的, 即当前时刻的输出不仅与当前输入有关, 还依赖于上一时刻隐藏层的输出, 其模型如图1所示。其中, 向量<b><i>x</i></b>表示输入数据, 向量<b><i>s</i></b>表示隐藏层的值, 向量<b><i>o</i></b>表示输出数据, <b><i>U</i></b>是输入层到隐藏层的权重矩阵, <b><i>V</i></b>是隐藏层到输出层的权重矩阵。RNN隐藏层的值<b><i>s</i></b>不仅取决于当前这次的输入<b><i>x</i></b>, 还依赖于上一次隐藏层的值<b><i>s</i></b>。权重矩阵<b><i>W</i></b>是隐藏层上一次的值作为这一次的输入的权重矩阵。将RNN按照时间线展开, 如图2所示。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908033_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 RNN结构" src="Detail/GetImg?filename=images/JSJC201908033_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 RNN结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908033_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="49">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908033_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 RNN时间线展开结构" src="Detail/GetImg?filename=images/JSJC201908033_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 RNN时间线展开结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908033_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="50">图2展开的网络为在<i>t</i>时刻, <b><i>z</i></b><sub><i>t</i></sub>是输入层的输入, <i>f</i><sub>1</sub>是隐藏层激活函数, <b><i>s</i></b><sub><i>t</i></sub>是隐藏层的输出, <i>g</i><sub>1</sub>是输出层激活函数, <b><i>o</i></b><sub><i>t</i></sub>是输出层的输出。关键一点是, <b><i>s</i></b><sub><i>t</i></sub>的值不仅取决于<b><i>z</i></b><sub><i>t</i></sub>, 还取决于<b><i>s</i></b><sub><i>t</i>-1</sub>。RNN的前向计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="51"><b><i>o</i></b><sub><i>t</i></sub>=<i>g</i><sub>1</sub> (<b><i>V</i></b>·<b><i>s</i></b><sub><i>t</i></sub>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="52"><b><i>s</i></b><sub><i>t</i></sub>=<i>f</i><sub>1</sub> (<b><i>U</i></b>·<b><i>z</i></b><sub><i>t</i></sub>+<b><i>W</i></b>·<b><i>s</i></b><sub><i>t</i>-1</sub>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="53">通过式 (1) 、式 (2) 的循环迭代, 可以得到:</p>
                </div>
                <div class="p1">
                    <p id="54"><b><i>o</i></b><sub><i>t</i></sub>=<i>g</i><sub>1</sub> (<b><i>Vs</i></b><sub><i>t</i></sub>) =</p>
                </div>
                <div class="p1">
                    <p id="55"><i>g</i><sub>1</sub> (<i>Vf</i><sub>1</sub> (<b><i>Uz</i></b><sub><i>t</i></sub>+<i>Ws</i><sub><i>t</i>-1</sub>) ) =</p>
                </div>
                <div class="p1">
                    <p id="56"><i>g</i><sub>1</sub> (<i>Vf</i><sub>1</sub> (<b><i>Uz</i></b><sub><i>t</i></sub>+<i>Wf</i><sub>1</sub> (<b><i>Uz</i></b><sub><i>t</i>-1</sub>+<b><i>Ws</i></b><sub><i>t</i>-2</sub>) ) ) =</p>
                </div>
                <div class="p1">
                    <p id="57"><i>g</i><sub>1</sub> (<i>Vf</i><sub>1</sub> (<b><i>Uz</i></b><sub><i>t</i></sub>+<i>Wf</i><sub>1</sub> (<b><i>Uz</i></b><sub><i>t</i>-1</sub>+<b><i>Wf</i></b><sub>1</sub> (<b><i>Uz</i></b><sub><i>t</i>-2</sub>+…) ) ) )      (3) </p>
                </div>
                <div class="p1">
                    <p id="58">由式 (3) 可以看出, 当前时刻包含了历史信息, 这说明RNN能够记忆历史信息。但传统的RNN总是用“覆写”的方式 (式 (2) ) 计算状态。根据求导的链式法则, 这种方式直接导致梯度被表示为连乘积的形式, 造成难以解决的梯度消失问题。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59">1.2 长短期记忆网络</h4>
                <div class="p1">
                    <p id="60">本文采用LSTM<citation id="203" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>来解决稳定性和梯度消失的问题。在LSTM中, 常规的神经元被存储单元代替, 每个存储单元由输入门、输出门、自有状态组成。存储单元中管理向单元移除或添加的结构叫门限, 包括遗忘门、输入门、输出门。门限由sigmoid激活函数和逐点乘法运算组成。前一个时间步长的隐藏状态被送到遗忘门、输入门和输出门。在前向计算过程中, 输入门学习何时激活让当前输入传入存储单元, 而输出门学习何时激活让当前隐藏层状态传出存储单元。LSTM结构如图3所示。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908033_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 LSTM结构" src="Detail/GetImg?filename=images/JSJC201908033_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 LSTM结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908033_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="62">LSTM状态更新满足以下公式:</p>
                </div>
                <div class="p1">
                    <p id="63"><b><i>f</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sup><i>f</i></sup>[<b><i>h</i></b><sub><i>t</i>-1</sub>, <b><i>z</i></b><sub><i>t</i></sub>]+<b><i>z</i></b><sup><i>f</i></sup>)      (4) </p>
                </div>
                <div class="p1">
                    <p id="64"><b><i>i</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sup><i>i</i></sup>[<b><i>h</i></b><sub><i>t</i>-1</sub>, <b><i>z</i></b><sub><i>t</i></sub>]+<b><i>b</i></b><sup><i>i</i></sup>)      (5) </p>
                </div>
                <div class="p1">
                    <p id="65"><b><i>o</i></b><sub><i>t</i></sub>=<i>σ</i> (<b><i>W</i></b><sup><i>o</i></sup>[<b><i>h</i></b><sub><i>t</i>-1</sub>, <b><i>z</i></b><sub><i>t</i></sub>]+<b><i>b</i></b><sup><i>o</i></sup>)      (6) </p>
                </div>
                <div class="p1">
                    <p id="66"><b><i>l</i></b><sub><i>t</i></sub>=tanh (<b><i>W</i></b><sup><i>l</i></sup>[<b><i>h</i></b><sub><i>t</i>-1</sub>, <b><i>z</i></b><sub><i>t</i></sub>]+<b><i>b</i></b><sup><i>l</i></sup>)      (7) </p>
                </div>
                <div class="p1">
                    <p id="67"><b><i>c</i></b><sub><i>t</i></sub>=<b><i>f</i></b><sub><i>t</i></sub>·<b><i>c</i></b><sub><i>t</i>-1</sub>+<b><i>i</i></b><sub><i>t</i></sub>·<b><i>l</i></b><sub><i>t</i></sub>      (8) </p>
                </div>
                <div class="p1">
                    <p id="68"><b><i>h</i></b><sub><i>t</i></sub>=<b><i>o</i></b><sub><i>t</i></sub>·tanh (<b><i>c</i></b><sub><i>t</i></sub>)      (9) </p>
                </div>
                <div class="p1">
                    <p id="69">其中, <b><i>f</i></b><sub><i>t</i></sub>、<b><i>i</i></b><sub><i>t</i></sub>和<b><i>o</i></b><sub><i>t</i></sub>别表示忘记门、输入门和输出门, 控制着信息如何流经这个序列, <b><i>l</i></b><sub><i>t</i></sub>表示当前输入<b><i>z</i></b><sub><i>t</i></sub>生成的候选数值, <b><i>c</i></b><sub><i>t</i></sub>表示隐藏层神经元状态, [<b><i>h</i></b><sub><i>t</i>-1</sub>, <b><i>z</i></b><sub><i>t</i></sub>]表示<i>t</i>-1时刻隐藏层的输出和<i>t</i>时刻的输入的连接向量, <b><i>W</i></b><sup><i>f</i></sup>和<b><i>b</i></b><sup><i>f</i></sup>表示忘记门的权重矩阵和偏置, <b><i>W</i></b><sup><i>i</i></sup>和<b><i>b</i></b><sup><i>i</i></sup>表示输入门的权重矩阵和偏置, <b><i>W</i></b><sup><i>o</i></sup>和<b><i>b</i></b><sup><i>o</i></sup>表示输出门的权重矩阵和偏置, <b><i>W</i></b><sup><i>l</i></sup>和<b><i>b</i></b><sup><i>l</i></sup>表示当前时刻输入数据生成当前单元状态值的权重矩阵和偏置。下文使用<b><i>h</i></b><sub><i>t</i></sub>=LSTM (<b><i>h</i></b><sub><i>t</i>-1</sub>, <b><i>z</i></b><sub><i>t</i></sub>) 来表示这些操作。</p>
                </div>
                <h3 id="70" name="70" class="anchor-tag">2 基于RNN的推荐算法</h3>
                <div class="p1">
                    <p id="71">用户的状态演变取决于用户先前评价过的电影。同样, 电影的状态演变依赖于在前一时间间隔中对其进行评分的用户。</p>
                </div>
                <div class="p1">
                    <p id="72">本文使用LSTM来捕获用户和电影的时间动态, 首先将用户对不同电影的评分按照时间戳进行划分, 作为用户向量输入, 对电影也采用类似的做法。但用户向量和电影向量都是高维稀疏的, 不利于模型的训练。为了有效地处理高维稀疏的输入向量, 使用自编码器的编码网络对序列数据进行预训练<citation id="204" type="reference"><link href="185" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 以达到数据降维的目的, 更利于模型的训练。通过这种方式, 整合过去的观察数据并以综合的方式预测未来的轨迹, 即将用户状态和电影状态做内积以实现评分预测。R-RNN模型的完整结构如图4所示。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908033_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 R-RNN模型结构" src="Detail/GetImg?filename=images/JSJC201908033_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 R-RNN模型结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908033_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="74">在推荐模型中, 为了处理时间动态, 添加2个时间索引, 即<i>u</i><sub><i>i</i>, <i>t</i></sub>和<i>m</i><sub><i>j</i>, <i>t</i></sub>, 分别表示用户<i>i</i>和电影<i>j</i>在时间步长<i>t</i>处的潜在状态。在LSTM基础上, 只需要定义更新函数, 根据用户和电影历史状态更新最新状态, 并预测评分:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover><mstyle mathsize="140%" displaystyle="true"><mi>r</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>t</mi></mrow></msub><mo>=</mo><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>t</mi></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>t</mi></mrow></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>g</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>t</mi></mrow></msub><mo>, </mo><mo stretchy="false">{</mo><mi>r</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>t</mi></mrow></msub><mo stretchy="false">}</mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>h</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>t</mi></mrow></msub><mo>, </mo><mo stretchy="false">{</mo><mi>r</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>t</mi></mrow></msub><mo stretchy="false">}</mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">其中, <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>r</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>t</mi></mrow></msub></mrow></math></mathml>表示在时间步长t处用户i对电影j的预测评分, r<sub>ij, t-1</sub>是在时间步长t-1处的实际评分。通过学习函数f, g和h, 可以直接推断新用户的状态, 而不需要进一步进行优化。本文解决优化问题来找到查找用户参数的函数, 而不是查找用户参数。这一点与文献<citation id="205" type="reference">[<a class="sup">16</a>]</citation>的自动编码器类似, 学习过去评分的编码函数。其创新之处在于, 学习一个函数, 它可以按顺序更新分数, 并且能够一次对一组评分进行前向预测。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">2.1 用户和电影状态</h4>
                <div class="p1">
                    <p id="79">给定<i>M</i>个电影, <i>N</i>个用户的数据集, <b><i>x</i></b><sub><i>i</i>, <i>t</i></sub>∈<image id="211" type="formula" href="images/JSJC201908033_21100.jpg" display="inline" placement="inline"><alt></alt></image><sup><i>M</i></sup> (<b><i>x</i></b><sub><i>j</i>, <i>t</i></sub>∈<image id="212" type="formula" href="images/JSJC201908033_21200.jpg" display="inline" placement="inline"><alt></alt></image><sup><i>N</i></sup>) 表示给定用户<i>i</i> (电影<i>j</i>) 在时间<i>t</i>的评分向量, <b><i>x</i></b><mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>t</mi></mrow><mi>j</mi></msubsup></mrow></math></mathml>表示给定用户i在时间步长t对电影j的评分, <b><i>x</i></b><mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>t</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>表示给定电影j在时间步长t处被用户i的评分, 则用户序列可以表示为{<b><i>x</i></b><sub><i>i</i>, 0</sub>, <b><i>x</i></b><sub><i>i</i>, 1</sub>, …, <b><i>x</i></b><sub><i>i</i>, <i>t</i></sub>}, 电影序列表示为{<b><i>x</i></b><sub><i>j</i>, 0</sub>, <b><i>x</i></b><sub><i>j</i>, 1</sub>, …, <b><i>x</i></b><sub><i>j</i>, <i>t</i></sub>}。但是组成这些序列的用户评分向量和电影评分向量是高维稀疏的, 直接用于LSTM网络的输入, 会导致模型根本无法训练, 需要对其进行数据降维处理。因此, 使用自编码器网络分别对用户向量和电影向量做预训练, 并分离出其中的编码网络以实现数据降维。</p>
                </div>
                <div class="p1">
                    <p id="84">自编码器对高维稀疏的用户向量和电影向量进行预训练的过程, 分为编码网络和解码网络2个部分。编码网络负责数据压缩, 解码网络负责数据恢复。解码网络的层数和编码网络的层数相同, 编码网络中各层的神经元个数逐层减少, 以捕捉高维输入数据中最重要的信息, 并实现数据降维。自编码器对用户向量和电影向量的编码过程如下:</p>
                </div>
                <div class="p1">
                    <p id="85"><b><i>y</i></b><sub><i>i</i>, <i>t</i></sub>=<b><i>W</i></b><sup>uencoder</sup>[<b><i>x</i></b><sub><i>i</i>, <i>t</i></sub>, <i>τ</i><sub><i>t</i></sub>, <i>τ</i><sub><i>t</i>-1</sub>]      (13) </p>
                </div>
                <div class="p1">
                    <p id="86"><b><i>y</i></b><sub><i>j</i>, <i>t</i></sub>=<b><i>W</i></b><sup>mencoder</sup>[<b><i>x</i></b><sub><i>j</i>, <i>t</i></sub>, <i>τ</i><sub><i>t</i></sub>, <i>τ</i><sub><i>t</i>-1</sub>]      (14) </p>
                </div>
                <div class="p1">
                    <p id="87">其中, <b><i>W</i></b><sup>uencoder</sup>和<b><i>W</i></b><sup>mencoder</sup>分别表示使用自编码器将用户和电影的高维稀疏向量向低维稠密向量的转换, <i>τ</i><sub><i>t</i></sub>表示wallclock, <b><i>y</i></b><sub><i>i</i>, <i>t</i></sub>和<b><i>y</i></b><sub><i>j</i>, <i>t</i></sub>是经过自编码器的编码过程后生成的低维稠密向量, 可以作为LSTM的直接输入, 以进一步得到用户时间状态<b><i>u</i></b><sub><i>i</i>, <i>t</i></sub>和电影时间状态<b><i>m</i></b><sub><i>j</i>, <i>t</i></sub>。因此, 可以得到以下公式:</p>
                </div>
                <div class="p1">
                    <p id="88"><b><i>u</i></b><sub><i>i</i>, <i>t</i></sub>=LSTM (<b><i>u</i></b><sub><i>i</i>, <i>t</i>-1</sub>, <b><i>y</i></b><sub><i>i</i>, <i>t</i></sub>)      (15) </p>
                </div>
                <div class="p1">
                    <p id="89"><b><i>m</i></b><sub><i>j</i>, <i>t</i></sub>=LSTM (<b><i>m</i></b><sub><i>j</i>, <i>t</i>-1</sub>, <b><i>y</i></b><sub><i>j</i>, <i>t</i></sub>)      (16) </p>
                </div>
                <div class="p1">
                    <p id="90">其中, <b><i>u</i></b><sub><i>i</i>, <i>t</i></sub>表示在时间步长<i>t</i>处用户<i>i</i>的状态, <b><i>m</i></b><sub><i>j</i>, <i>t</i></sub>表示在时间步长<i>t</i>处电影<i>j</i>的状态。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91">2.2 评分预测</h4>
                <div class="p1">
                    <p id="92">R-RNN算法根据用户状态和电影状态的内积作为评分的估计, 计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>r</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>t</mi></mrow></msub><mo>=</mo><mo>〈</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>t</mi></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>t</mi></mrow></msub><mo>〉</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">其中, &lt;, &gt;表示2个向量之间的内积。这种算法类似于潜在变量模型预测评分的方式, 如基于矩阵分解的推荐, 通过将原始评分矩阵分解成用户-特征矩阵和特征-项目矩阵, 得到用户和电影的潜在特征向量, 再利用2个矩阵还原原始评分矩阵, 并获得原始矩阵中的缺失评分。不同之处在于, R-RNN算法严格按照评分时间戳划分数据集, 并克服用后见之明的方式预测评分, 达到满足因果关系的预测, 结果更具说服力。</p>
                </div>
                <h4 class="anchor-tag" id="95" name="95">2.3 模型训练</h4>
                <div class="p1">
                    <p id="96">不同于传统推荐算法, 在预测时间内, R-RNN将最新的用户向量和电影向量作为输入, 并基于最新更新的状态进行预测。通过这种方式, 将过去评分带来的因果效应考虑在内。算法的优化目标是找到产生接近实际评分的预测评分的参数, 用<i>θ</i>表示算法中所有需要学习的参数, 即<b><i>W</i></b><sup>uencoder</sup>、<b><i>W</i></b><sup>mencoder</sup>、<b><i>W</i></b><sup><i>f</i></sup>、<b><i>b</i></b><sup><i>f</i></sup>、<b><i>W</i></b><sup><i>l</i></sup>、<b><i>b</i></b><sup><i>l</i></sup>、<b><i>W</i></b><sup><i>o</i></sup>、<b><i>b</i></b><sup><i>o</i></sup>、<b><i>W</i></b><sup><i>l</i></sup>、<b><i>b</i></b><sup><i>l</i></sup>。因此, R-RNN的目标函数如下:</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>θ</mi></munder></mrow><mtext> </mtext><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub></mrow></munder><mrow></mrow></mstyle></mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo stretchy="false"> (</mo><mi>r</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mo>, </mo><mi>t</mi></mrow></msub><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>r</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover><mi>i</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mi>t</mi></mrow></msub><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>R</mi><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">其中, <i>I</i><sub>train</sub>表示训练集中观察到的 (用户, 电影, 时间戳) 元组的集合, <i>R</i>是关于参数的L2正则化项, 以防止算法过拟合的问题。算法求解步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="99"><b>步骤1</b> 使用BP算法<citation id="206" type="reference"><link href="189" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>更新自编码器的权重参数<b><i>W</i></b><sup>uencoder</sup>、<b><i>W</i></b><sup>mencoder</sup>。</p>
                </div>
                <div class="p1">
                    <p id="100">1) 进行前馈传导计算, 得到自编码器各输出层的值。</p>
                </div>
                <div class="p1">
                    <p id="101">2) 计算输出层以及各隐藏层的传播误差。</p>
                </div>
                <div class="p1">
                    <p id="102">3) 计算最终各层权重参数的偏导数值。</p>
                </div>
                <div class="p1">
                    <p id="103">4) 使用梯度下降法求得自编码器参数的最优解。</p>
                </div>
                <div class="p1">
                    <p id="104"><b>步骤2</b> 使用BPTT算法更新LSTM单元中的权重参数<b><i>W</i></b><sup><i>f</i></sup>、<b><i>b</i></b><sup><i>f</i></sup>、<b><i>W</i></b><sup><i>l</i></sup>、<b><i>b</i></b><sup><i>l</i></sup>、<b><i>W</i></b><sup><i>o</i></sup>、<b><i>b</i></b><sup><i>o</i></sup>、<b><i>W</i></b><sup><i>l</i></sup>、<b><i>b</i></b><sup><i>l</i></sup>。</p>
                </div>
                <div class="p1">
                    <p id="105">1) 依次前向计算各个控制门<b><i>f</i></b><sub><i>t</i></sub>、<b><i>i</i></b><sub><i>t</i></sub>、<b><i>o</i></b><sub><i>t</i></sub>的输出, 状态<b><i>c</i></b><sub><i>t</i></sub>的更新, 输出<b><i>h</i></b><sub><i>t</i></sub>的计算。</p>
                </div>
                <div class="p1">
                    <p id="106">2) 分别计算输出门<b><i>o</i></b><sub><i>t</i></sub>、遗忘门<b><i>f</i></b><sub><i>t</i></sub>、输入门<b><i>i</i></b><sub><i>t</i></sub>以及细胞状态<b><i>c</i></b><sub><i>t</i></sub>的传播误差。</p>
                </div>
                <div class="p1">
                    <p id="107">3) 计算最终各层权重参数的梯度。</p>
                </div>
                <div class="p1">
                    <p id="108">4) 使用Adam算法求LSTM各参数最优解。</p>
                </div>
                <h3 id="109" name="109" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="110" name="110">3.1 数据集描述</h4>
                <div class="p1">
                    <p id="111">为了研究时间动态的有效性, 本文构建R-RNN算法, 并在Netflix比赛和IMDB数据集上评估该算法。IMDB数据集包含1998年7月—2013年9月收集的1 429 600个评分。完整的Netflix数据集 (记为Netflix) 包含1988年11月—2005年12月收集的100 400 000个评分, 其中包括2005年6月—2005年12月收集的15 800 000个评分的子集 (记为Netflix-6) 。每个数据点是一个时间戳粒度为1天的 (用户id, 项目id, 时间戳, 评分) 元组。根据时间分割数据以模拟需要预测未来评分的实际情况。整个数据集都被分割成训练集和测试集。详细数据如表1所示。</p>
                </div>
                <div class="area_img" id="112">
                    <p class="img_tit"><b>表1 实验数据集的详细数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="112" border="1"><tr><td>参数</td><td>IMDB</td><td>Netflix-6</td><td>Netflix</td></tr><tr><td>用户个数</td><td>440 800</td><td>311 300</td><td>477 400</td></tr><tr><td><br />项目个数</td><td>114 300</td><td>17 700</td><td>17 800</td></tr><tr><td><br />训练集<br />评分个数</td><td>1 400 000</td><td>13 700 000</td><td>98 100 000</td></tr><tr><td><br />测试集<br />评分个数</td><td>29 600</td><td>2 100 000</td><td>2 300 000</td></tr><tr><td>训练集<br />时间跨度</td><td>1998年7月—<br />2012年12月</td><td>2005年6月—<br />2005年11月</td><td>1999年12月—<br />2005年11月</td></tr><tr><td><br />测试集<br />时间跨度</td><td>2013年1月—<br />2013年9月</td><td>2005年12月</td><td>2005年12月</td></tr><tr><td><br />稀疏性</td><td>0.002 8%</td><td>0.28%</td><td>1.2%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="113" name="113">3.2 实验设置</h4>
                <div class="p1">
                    <p id="114">均方根误差 (Root Mean Squared Error, RMSE) 和平均绝对误差 (Mean Absolute Error, MAE) 均是度量预测误差的指标, 其中, RMSE对大误差比较敏感, MAE对小误差的积累比较敏感。由于RMSE加大了对预测不准的用户物品评分的惩罚, 对系统的测评更加苛刻, 本文选择RMSE评估算法精度。对于Netflix和IMDB数据集, 采用2个月的时间步长粒度, 对于Netflix-6数据集, 采用7天的时间步长粒度</p>
                </div>
                <div class="p1">
                    <p id="115">本文在Tensorflow<citation id="207" type="reference"><link href="191" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>开发框架上进行实验, 实验目的分为确定算法参数和算法有效性对比2种。其中, 实验1为了确定自编码器编码网络的层数及其节点数;实验2为了确定隐藏层和细胞状态维度;实验3为算法对比实验, 通过对比不同算法 (TimeSVD++、AutoRec、PMF) 预测评分的RMSE, 验证本文算法的有效性。</p>
                </div>
                <h4 class="anchor-tag" id="116" name="116">3.3 结果分析</h4>
                <div class="p1">
                    <p id="117">本文利用自编码器对原始序列数据进行降维, 在实验1中对不同层数不同神经元个数的自编码器网络进行测试。</p>
                </div>
                <div class="p1">
                    <p id="118">1) 测试只有1层隐藏层的自编码器, 节点数<i>n</i>为200、400、600、800、1 000。表2列出了1层隐藏层自编码器不同数据集在不同节点数下的RMSE。</p>
                </div>
                <div class="area_img" id="120">
                    <p class="img_tit"><b>表2 1层隐藏层不同节点数自编码器对应的RMSE</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="120" border="1"><tr><td><br />数据集</td><td colspan="2"><i>n</i>=200</td><td colspan="2"><i>n</i>=400</td><td colspan="2"><i>n</i>=600</td><td colspan="2"><i>n</i>=800</td><td colspan="2"><i>n</i>=1 000</td></tr><tr><td colspan="2"><br />IMDB</td><td colspan="2">1.352 6</td><td colspan="2">1.305 2</td><td colspan="2">1.269 0</td><td colspan="2">1.246 2</td><td>1.199 5</td></tr><tr><td colspan="2"><br />Netflix</td><td colspan="2">1.163 5</td><td colspan="2">1.118 0</td><td colspan="2">1.089 2</td><td colspan="2">1.059 0</td><td>1.030 6</td></tr><tr><td colspan="2"><br />Netflix-6</td><td colspan="2">1.235 6</td><td colspan="2">1.187 5</td><td colspan="2">1.156 7</td><td colspan="2">1.124 9</td><td>1.093 9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="121">由表2可知, 当隐藏层节点数为1 000时, 其RMSE值最小, 并且1层隐藏层自编码器的表现较差。</p>
                </div>
                <div class="p1">
                    <p id="122">2) 测试3层隐藏层自编码器的性能。其中, 第1层和第3层隐藏层节点数设置为1 000, 第2层节点数<i>n</i><sub>2</sub>为100、150、200、250、300。表3列出了3层隐藏层自编码器不同数据集在不同节点数下的RMSE。</p>
                </div>
                <div class="area_img" id="124">
                    <p class="img_tit"><b>表3 3层隐藏层不同节点数自编码器对应的RMSE</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="124" border="1"><tr><td><br />数据集</td><td><i>n</i><sub>2</sub>=100</td><td><i>n</i><sub>2</sub>=150</td><td><i>n</i><sub>2</sub>=200</td><td><i>n</i><sub>2</sub>=250</td><td><i>n</i><sub>2</sub>=300</td></tr><tr><td><br />IMDB</td><td>0.992 7</td><td>0.961 3</td><td>0.931 5</td><td>0.910 1</td><td>0.890 7</td></tr><tr><td><br />Netflix</td><td>0.880 2</td><td>0.858 6</td><td>0.832 9</td><td>0.809 6</td><td>0.796 3</td></tr><tr><td><br />Netflix-6</td><td>0.922 5</td><td>0.893 6</td><td>0.867 3</td><td>0.843 1</td><td>0.821 5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="125">由表3可知, 当第2层隐藏层的节点数为300时, 其RMSE值最小。</p>
                </div>
                <div class="p1">
                    <p id="126">3) 测试5层自编码器的性能。其中, 第1层和第5层隐藏层节点数设置为1 000, 第2层和第4层隐藏层节点数<i>n</i><sub>3</sub>设置为300, 第3层隐藏层节点数为10、20、30、40、50。表4列出了5层自编码器不同数据集在不同节点数下的RMSE。</p>
                </div>
                <div class="area_img" id="128">
                    <p class="img_tit"><b>表4 5层隐藏层不同节点数自编码器对应的RMSE</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="128" border="1"><tr><td><br />数据集</td><td><i>n</i><sub>3</sub>=10</td><td><i>n</i><sub>3</sub>=20</td><td><i>n</i><sub>3</sub>=30</td><td><i>n</i><sub>3</sub>=40</td><td><i>n</i><sub>3</sub>=50</td></tr><tr><td><br />IMDB</td><td>0.862 9</td><td>0.813 7</td><td>0.783 6</td><td>0.766 9</td><td>0.769 1</td></tr><tr><td><br />Netflix</td><td>0.772 4</td><td>0.735 8</td><td>0.710 2</td><td>0.681 3</td><td>0.683 1</td></tr><tr><td><br />Netflix-6</td><td>0.803 2</td><td>0.758 0</td><td>0.735 2</td><td>0.713 2</td><td>0.718 4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="129">由表4可知, 当第3层隐藏层的节点数为40时, 其RMSE值最小。</p>
                </div>
                <div class="p1">
                    <p id="130">根据上述实验确定自编码器的层数及节点数, 将其中的编码网络分离以实现数据降维, 编码网络的层数为3层, 每层节点数分别为1 000、300、40。</p>
                </div>
                <div class="p1">
                    <p id="131">本文利用实验2确定LSTM单元中隐藏层和细胞状态节点数<i>m</i>。表5列出了不同数据集在不同隐藏层和细胞状态的节点数下的RMSE。</p>
                </div>
                <div class="area_img" id="132">
                    <p class="img_tit"><b>表5 不同单元隐藏层和细胞状态节点数对应的RMSE</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="132" border="1"><tr><td><br />数据集</td><td><i>m</i>=10</td><td><i>m</i>=20</td><td><i>m</i>=30</td><td><i>m</i>=40</td><td><i>m</i>=50</td></tr><tr><td><br />IMDB</td><td>2.812 4</td><td>1.970 3</td><td>2.264 7</td><td>2.714 5</td><td>3.381 7</td></tr><tr><td><br />Netflix</td><td>1.683 5</td><td>0.922 4</td><td>1.187 6</td><td>1.578 3</td><td>2.160 8</td></tr><tr><td><br />Netflix-6</td><td>1.802 4</td><td>0.942 7</td><td>1.267 0</td><td>1.715 2</td><td>2.380 5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="133">由表5可知, 当节点数为20时, 其RMSE值最小。因此, LSTM单元隐藏层和细胞状态的节点数设置为20。</p>
                </div>
                <div class="p1">
                    <p id="134">实验3是本文R-RNN算法与其他推荐算法的对比实验, 其中包括PMF算法<citation id="208" type="reference"><link href="167" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、TimeSVD++算法<citation id="209" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、基于自编码器的推荐算法 (I-AutoRec和U-AutoRec) <citation id="210" type="reference"><link href="187" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。表6列出了各算法在不同数据集上的对比实验结果。</p>
                </div>
                <div class="area_img" id="135">
                    <p class="img_tit"><b>表6 各算法在不同数据集上的RMSE</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="135" border="1"><tr><td>数据集</td><td>PMF</td><td>I-AutoRec</td><td>U-AutoRec</td><td>TimeSVD++</td><td>R-RNN</td></tr><tr><td>IMDB</td><td>2.391 3</td><td>2.052 1</td><td>2.029 0</td><td>2.003 7</td><td>1.970 3</td></tr><tr><td><br />Netflix</td><td>0.925 2</td><td>0.936 4</td><td>0.964 7</td><td>0.927 5</td><td>0.922 4</td></tr><tr><td><br />Netflix-6</td><td>0.958 4</td><td>0.977 8</td><td>0.983 6</td><td>0.958 9</td><td>0.942 7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="136">从表6可以看出, 虽然其他算法在不同数据集上表现不同, 但是本文算法的RMSE都是最小的, 即其推荐质量最好。这说明本文算法具有较好的鲁棒性, 适用于不同的数据集。另外, PMF算法在IMDB数据集上的表现最差, 这再次证明了对时间动态建模的必要性。</p>
                </div>
                <h3 id="137" name="137" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="138">本文提出一种推荐算法R-RNN, 采用RNN的变种网络LSTM, 挖掘随时间变化的用户状态和电影状态, 并生成预测评分。在IMDB、Netflix及Netflix-6数据集中通过实验确定模型参数, 并与PFM、TimeSVD++及AutoRec算法进行对比, 结果表明, 本文算法鲁棒性最好, 预测评分最准确。本文仅将RNN用于推荐任务, 下一步尝试融合其他深度学习模型, 如多层感知机、卷积神经网络、深度语义相似性模型等, 整合不同的数据源以提高推荐精度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="157">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The netflix prize">

                                <b>[1]</b> BENNETT J, LANNING S.The netflix prize[C]//Proceedings of KDD Cup and Workshop.San Jose, USA:[s.n.], 2007:35.
                            </a>
                        </p>
                        <p id="159">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A recommendation algorithm via developed random walk takes user&amp;#39;&amp;#39;s preference and item&amp;#39;&amp;#39;s genres">

                                <b>[2]</b> ZHAO Jingling, LI Yan, ZHANG Ye.A recommendation algorithm via developed random walk takes user’s preference and item’s genres[C]//Proceedings of 2017 International Conference on Information System and Data Mining.New York, USA:ACM Press, 2017:61-65.
                            </a>
                        </p>
                        <p id="161">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An ensemble algorithm used in video recommendation system">

                                <b>[3]</b> MA Li, WANG Xingjun.An ensemble algorithm used in video recommendation system[C]//Proceedings of 2017 International Conference on Big Data Research.New York, USA:ACM Press, 2017:67-71.
                            </a>
                        </p>
                        <p id="163">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep learning for recom-mender systems">

                                <b>[4]</b> KARATZOGLOU A, HIDASI B.Deep learning for recom-mender systems[C]//Proceedings of the 11th ACM Conference on Recommender Systems.New York, USA:ACM Press, 2017:396-397.
                            </a>
                        </p>
                        <p id="165">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201708041&amp;v=MjEyNDF6N0JiYkc0SDliTXA0OUJaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2psVmIzQUw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 李卫疆, 齐静, 余正涛, 等.融合信任传播和奇异值分解的社会化推荐算法[J].计算机工程, 2017, 43 (8) :236-242.
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Probabilistic matrix factorization">

                                <b>[6]</b> SALAKHUTDINOV R, MNIH A.Probabilistic matrix factorization[C]//Proceedings of Advances in Neural Information Processing Systems.[S.l.]:NIPS Inc., 2008:1257-1264.
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201612029&amp;v=MTUwNjhIOWZOclk5SGJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZDamxWYjNBTHo3QmI3RzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 王锦坤, 姜元春, 孙见山, 等.考虑用户活跃度和项目流行度的基于项目最近邻的协同过滤算法[J].计算机科学, 2016, 43 (12) :158-162.
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accams:Additive co-clustering to approx-imate matrices succinctly">

                                <b>[8]</b> BEUTEL A, AHMED A, SMOLA A J.ACCAMS:additive co-clustering to approximate matrices succinctly[C]//Proceedings of the 24th International Conference on World Wide Web.New York, USA:ACM Press, 2015:119-129.
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Collaborative filtering with temporal dynamics">

                                <b>[9]</b> KOREN Y.Collaborative filtering with temporal dynamics[C]//Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM Press, 2009:447-456.
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNSF201703022&amp;v=MTI2NTFxRkNqbFZiM0FMU1BZYUxHNEg5Yk1ySTlIWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 谭黎立, 聂瑞华, 梁军, 等.基于动态时间的个性化推荐模型[J].华南师范大学学报 (自然科学版) , 2017, 49 (3) :123-128.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKJ201709027&amp;v=Mjk3MDRaTEc0SDliTXBvOUhZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2psVmIzQUlUZkE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 李忠武, 王辉, 魏再超.基于推荐系统时间敏感的因子模型算法研究[J].电子商务.2017 (9) :55-56, 89.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recurrent neural networks">

                                <b>[12]</b> DU K, SWAMY M N S.Recurrent neural networks[M].London, UK:Springer, 2014:337-353.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016063588.nh&amp;v=MjYyNDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZDamxWYjNBVkYyNkdMTytIZFRFcDVFYlBJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 俞骋超.基于深度神经网络的用户会话推荐算法研究[D].杭州:浙江大学, 2016.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KJSJ201713084&amp;v=MDYyNzMzenFxQnRHRnJDVVJMT2VaZVJxRkNqbFZiM0FMaWZZWkxHNEg5Yk5ySTlOWUlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 陆泽楠, 商玉林.基于LSTM神经网络模型的钢铁价格预测[J].科技视界, 2017 (13) :116-117.
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Relation Classification via Convolution al Deep Neural Network">

                                <b>[15]</b> ZENG Daojian, LIU Kang, LAI Siwei, et al.Relation classification via convolutional deep neural network[C]//Proceedings of COLING’14.Dublin, Ireland:[s.n.], 2014:2335-2344.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Autorec:Autoencoders meet collaborative filtering">

                                <b>[16]</b> SEDHAIN S, MENON A K, SANNER S, et al.Autorec:autoencoders meet collaborative filtering[C]//Proceedings of the 24th International Conference on World Wide Web.New York, USA:ACM Press, 2015:111-112.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCQX201601010&amp;v=MzE5NjVMT2VaZVJxRkNqbFZiM0FOaTdhZHJHNEg5Zk1ybzlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 罗频捷, 温荷.基于改进BP神经网络的个性化推荐算法研究[J].四川理工学院学报 (自然科学版) , 2016, 29 (1) :39-43.
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201710017&amp;v=MjM3NTgzQU1qWEJkN0c0SDliTnI0OUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnFGQ2psVmI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 章敏敏, 徐和平, 王晓洁, 等.谷歌TensorFlow机器学习框架及应用[J].微型机与应用, 2017, 36 (10) :58-60.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201908033" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201908033&amp;v=MDg5NzdCdEdGckNVUkxPZVplUnFGQ2psVmIzQUx6N0JiYkc0SDlqTXA0OUdaNFFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDYyTTc5ZU1kSFJvVW1uVU9FL1g5cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="2" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
