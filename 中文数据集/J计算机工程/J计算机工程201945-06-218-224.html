<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130386218895000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201906035%26RESULT%3d1%26SIGN%3dxk6sGfbVBodfPR22WiTeKdQ5WCI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201906035&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201906035&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201906035&amp;v=MDk4Njg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeW5sVmIvT0x6N0JiYkc0SDlqTXFZOUdZWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="1 相关知识 ">1 相关知识</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="1.1 聚类算法">1.1 聚类算法</a></li>
                                                <li><a href="#49" data-title="1.2 去冗余抽样算法">1.2 去冗余抽样算法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#61" data-title="2 基于聚类融合去冗余的改进欠抽样方法 ">2 基于聚类融合去冗余的改进欠抽样方法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#126" data-title="3 基于改进欠抽样的非平衡数据集分类预测 ">3 基于改进欠抽样的非平衡数据集分类预测</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#129" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#130" data-title="4.1 实验数据">4.1 实验数据</a></li>
                                                <li><a href="#133" data-title="4.2 实验设计">4.2 实验设计</a></li>
                                                <li><a href="#140" data-title="4.3 评价指标">4.3 评价指标</a></li>
                                                <li><a href="#150" data-title="4.4 结果分析">4.4 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#158" data-title="5 结束语 ">5 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#60" data-title="&lt;b&gt;图1 非平衡数据集样本分布&lt;/b&gt;"><b>图1 非平衡数据集样本分布</b></a></li>
                                                <li><a href="#76" data-title="&lt;b&gt;图2 多数类样本的数据分布&lt;/b&gt;"><b>图2 多数类样本的数据分布</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;图3 基于聚类融合去冗余的改进欠抽样方法流程&lt;/b&gt;"><b>图3 基于聚类融合去冗余的改进欠抽样方法流程</b></a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;图4 基于聚类融合去冗余的改进欠抽样方法流程&lt;/b&gt;"><b>图4 基于聚类融合去冗余的改进欠抽样方法流程</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;表1 数据集描述&lt;/b&gt;"><b>表1 数据集描述</b></a></li>
                                                <li><a href="#139" data-title="&lt;b&gt;表2 实验场景详情描述&lt;/b&gt;"><b>表2 实验场景详情描述</b></a></li>
                                                <li><a href="#152" data-title="&lt;b&gt;图5 3种场景的正类率比较结果&lt;/b&gt;"><b>图5 3种场景的正类率比较结果</b></a></li>
                                                <li><a href="#154" data-title="&lt;b&gt;图6 3种场景的准确率比较结果&lt;/b&gt;"><b>图6 3种场景的准确率比较结果</b></a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;图7 3种场景G-mean值的比较结果&lt;/b&gt;"><b>图7 3种场景G-mean值的比较结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 蔡艳艳, 宋晓东.针对非平衡数据分类的新型模糊SVM模型[J].西安电子科技大学学报 (自然科学版) , 2015, 42 (5) :120-124, 160." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDKD201505021&amp;v=MjA2ODhaZVJvRnlubFZiL0JQU25BYXJHNEg5VE1xbzlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         蔡艳艳, 宋晓东.针对非平衡数据分类的新型模糊SVM模型[J].西安电子科技大学学报 (自然科学版) , 2015, 42 (5) :120-124, 160.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 刘红岩, 陈剑, 陈国青.数据挖掘中的数据分类算法综述[J].清华大学学报 (自然科学版) , 2002, 42 (6) :727-730." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QHXB200206004&amp;v=MDY2MjR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnlubFZiL0JOQ1hUYkxHNEh0UE1xWTlGWUlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         刘红岩, 陈剑, 陈国青.数据挖掘中的数据分类算法综述[J].清华大学学报 (自然科学版) , 2002, 42 (6) :727-730.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 史岩, 李小民, 齐晓慧.一种新型欠采样的支持向量机非平衡数据故障诊断研究[J].计算机测量与控制, 2012, 20 (5) :1203-1204, 1235." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZCK201205016&amp;v=MjYzMTVxcUJ0R0ZyQ1VSTE9lWmVSb0Z5bmxWYi9CTHpmSVpiRzRIOVBNcW85RVlvUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         史岩, 李小民, 齐晓慧.一种新型欠采样的支持向量机非平衡数据故障诊断研究[J].计算机测量与控制, 2012, 20 (5) :1203-1204, 1235.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" CHAN P K, STOLFO S J.Toward scalable learning with non-uniform class and cost distributions:a case study in credit card fraud detection[C]//Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining.[S.l.]:AAAI Press, 1998:164-168." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Toward scalable learning with non-uniform class and costdistributions: a case study incredit card fraud detecti on">
                                        <b>[4]</b>
                                         CHAN P K, STOLFO S J.Toward scalable learning with non-uniform class and cost distributions:a case study in credit card fraud detection[C]//Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining.[S.l.]:AAAI Press, 1998:164-168.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" CHANG R F, WU WenJie, MOON W K, et al.Support vector machines for diagnosis of breast tumors on US images[J].Academic Radiology, 2003, 10 (2) :189-197." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501091848&amp;v=MTg1OTgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxuSUlWNFNhaHM9TmlmT2ZiSzdIdEROcW85RVpPSU9CSGd4b0JNVDZUNFBRSA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         CHANG R F, WU WenJie, MOON W K, et al.Support vector machines for diagnosis of breast tumors on US images[J].Academic Radiology, 2003, 10 (2) :189-197.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 杜春蕾, 张雪英, 李凤莲.改进的CART算法在煤层底板突水预测中的应用[J].工矿自动化, 2014, 40 (12) :52-56." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MKZD201412015&amp;v=MTgwMjlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5bmxWYi9CS0NiUmFyRzRIOVhOclk5RVlZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         杜春蕾, 张雪英, 李凤莲.改进的CART算法在煤层底板突水预测中的应用[J].工矿自动化, 2014, 40 (12) :52-56.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 张翕茜, 李凤莲, 张雪英, 等.基于代价敏感混合分裂策略的多决策树算法[J].计算机技术与应用, 2017, 43 (10) :128-136." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZJY201710032&amp;v=MTExMzh0R0ZyQ1VSTE9lWmVSb0Z5bmxWYi9CSVRmQmQ3RzRIOWJOcjQ5R1pvUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         张翕茜, 李凤莲, 张雪英, 等.基于代价敏感混合分裂策略的多决策树算法[J].计算机技术与应用, 2017, 43 (10) :128-136.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" SIERS M J, ISLAM M Z.Software defect prediction using a cost sensitive decision forest and voting, and a potential solution to the class imbalance problem[J].Information Systems, 2015, 51 (C) :62-71." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122600211100&amp;v=MTgzNTZhaHM9TmlmT2ZiSzlIOVBPcVk5Rlp1b09EWHc1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTG5JSVY0Uw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         SIERS M J, ISLAM M Z.Software defect prediction using a cost sensitive decision forest and voting, and a potential solution to the class imbalance problem[J].Information Systems, 2015, 51 (C) :62-71.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" XIA Xin, LO D, SHIHAB E, et al.ELBlocker:predicting blocking bugs with ensemble imbalance learning[J].Information and Software Technology, 2015, 61:93-106." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDD7D5A996C73D64A12184635E632B8C9&amp;v=MDczNTFoeGJpNXdLRT1OaWZPZmNmTUdhWEozb1pNWXBnSUR3Zy95MmNTNkQ1MVRIbmhxV2N6ZXJEbVRjbVdDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVONQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         XIA Xin, LO D, SHIHAB E, et al.ELBlocker:predicting blocking bugs with ensemble imbalance learning[J].Information and Software Technology, 2015, 61:93-106.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" KHANCHI S, HEYWOOD M I, ZINCIR-HEYWOOD A N.Properties of a GP active learning framework for streaming data with class imbalance[C]//Proceedings of the Genetic and Evolutionary Computation Conference.New York, USA:ACM Press, 2017:945-952." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Properties of a GP active learning framework for streaming data with class imbalance">
                                        <b>[10]</b>
                                         KHANCHI S, HEYWOOD M I, ZINCIR-HEYWOOD A N.Properties of a GP active learning framework for streaming data with class imbalance[C]//Proceedings of the Genetic and Evolutionary Computation Conference.New York, USA:ACM Press, 2017:945-952.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     CHAWLA N V, BOWYER K W, HALL L O, et al.SMOTE:synthetic minority over-sampling technique[J].Journal of Artificial Intelligence Research, 2002, 16 (1) :321-357.</a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" GARC&#205;A S, HERRERA F.Evolutionary under-sampling for classification with imbalanced datasets:proposals and taxonomy[J].Evolutionary Computation, 2014, 17 (3) :275-306." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500001057&amp;v=MTU2MzVTYWhzPU5pZkpaYks5SHRqTXFvOUZaT3NPREhrK29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxuSUlWNA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         GARC&#205;A S, HERRERA F.Evolutionary under-sampling for classification with imbalanced datasets:proposals and taxonomy[J].Evolutionary Computation, 2014, 17 (3) :275-306.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" BATISTA G E A P A, PRATI R C, MONARD M C.A study of the behavior of several methods for balancing machine learning training data[J].ACM SIGKDD Explorations Newsletter, 2004, 6 (1) :20-29." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM388195169BFE0E7494828A3B5E98AD35&amp;v=MjY5NDliaTV3S0U9TmlmSVk3Q3dGdERGcW81RGJabDVlWHhNeUJJYTdqZC9RQTdoM2hkQWNMcmxNYm1hQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TjVoeA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         BATISTA G E A P A, PRATI R C, MONARD M C.A study of the behavior of several methods for balancing machine learning training data[J].ACM SIGKDD Explorations Newsletter, 2004, 6 (1) :20-29.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" LAURIKKALA J.Improving identification of difficult small classes by balancing class distribution[C]//Proceedings of the 8th Conference on Artificial Intelligence Medicine.Berlin, Germany:Springer, 2001:63-66." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving Identification of Difficult Small Classes by Balancing Class Distribution">
                                        <b>[14]</b>
                                         LAURIKKALA J.Improving identification of difficult small classes by balancing class distribution[C]//Proceedings of the 8th Conference on Artificial Intelligence Medicine.Berlin, Germany:Springer, 2001:63-66.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" LIN Weichao, TSAI C F, HU Yahan, et al.Cluster-based undersampling in class-imbalanced data[J].Information Sciences, 2017, 409-410:17-26." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDFB713E40B45707321DAC87E21B62038&amp;v=MTQ5OTZOaWZPZmNmT2JOYk5yUHBCWkprTENYczV5QlVSNjBzTU8zZmwyUkEwQzdTV1JibVhDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVONWh4Ymk1d0tFPQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         LIN Weichao, TSAI C F, HU Yahan, et al.Cluster-based undersampling in class-imbalanced data[J].Information Sciences, 2017, 409-410:17-26.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" 史颖, 亓慧.一种去冗余抽样的非平衡数据分类方法[J].山西大学学报 (自然科学版) , 2017, 40 (2) :255-261." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SXDR201702008&amp;v=MDMwNDdlWmVSb0Z5bmxWYi9CTmpYUGZMRzRIOWJNclk5RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         史颖, 亓慧.一种去冗余抽样的非平衡数据分类方法[J].山西大学学报 (自然科学版) , 2017, 40 (2) :255-261.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" LI Fenglian, ZHANG Xueying, ZHANG Xiqian, et al.Cost-sensitive and hybrid attribute measure multi-decision tree over imbalanced data sets[J].Information Sciences, 2018, 422:242-256." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC58E726557DC023D6CA108DBF7BAB136&amp;v=MTMxNDdoeGJpNXdLRT1OaWZPZmNDOUZxVExyWWxBWWV4N2Yzdzd6R0lWbVU1OFNIZVczbVF5QzhQbVJMbVpDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVONQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         LI Fenglian, ZHANG Xueying, ZHANG Xiqian, et al.Cost-sensitive and hybrid attribute measure multi-decision tree over imbalanced data sets[J].Information Sciences, 2018, 422:242-256.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" BEYAN C, FISHER R.Classifying imbalanced data sets using similarity based hierarchical decomposition[J].Pattern Recognition, 2015, 48 (5) :1653-1672." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14121200017848&amp;v=MjY5MjBJVjRTYWhzPU5pZk9mYks4SDlQTnJZOUZaT29JQkhneG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxuSQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         BEYAN C, FISHER R.Classifying imbalanced data sets using similarity based hierarchical decomposition[J].Pattern Recognition, 2015, 48 (5) :1653-1672.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" RIVERA W A.Noise reduction a priori synthetic over-sampling for class imbalanced data sets[J].Information Sciences, 2017, 408 (C) :146-161." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1D6C57643828D7BD8076944F2A8B743F&amp;v=MDIwMzhsQlorTU5CQWcrdldJYjZqaDdRWHZtMmhCRWNjQ1RRYm5wQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TjVoeGJpNXdLRT1OaWZPZmJMTUdLTEpxSQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         RIVERA W A.Noise reduction a priori synthetic over-sampling for class imbalanced data sets[J].Information Sciences, 2017, 408 (C) :146-161.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(06),218-224 DOI:10.19678/j.issn.1000-3428.0050618            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>改进欠抽样方法及其在非平衡数据集分类中的应用</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%89%9B%E5%A3%AE&amp;code=39688654&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">牛壮</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%87%A4%E8%8E%B2&amp;code=08865293&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李凤莲</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E9%9B%AA%E8%8B%B1&amp;code=08872173&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张雪英</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%A8%8A%E5%AE%87%E5%AE%99&amp;code=40035033&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">樊宇宙</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%AD%8F%E9%91%AB&amp;code=38740247&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">魏鑫</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%AA%E5%8E%9F%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0077528&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">太原理工大学信息与计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>欠抽样方法在非平衡数据集分类时, 未充分考虑数据分布变化对分类结果造成的影响。为此, 提出一种基于聚类融合去冗余的改进欠抽样方法。采用聚类算法得到多数类样本高密度分布区域的聚类中心, 将多数类样本划分为不同子集, 通过计算各子集的相似度冗余系数对多数类样本进行去冗余删除, 以达到欠抽样的目的。对15个不同平衡率的数据集欠抽样后, 利用代价敏感混合属性多决策树模型进行分类。实验结果表明, 在不降低非平衡数据集分类准确率的前提下, 该方法能够提高少数类样本的正类率及预测模型的G-mean值。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E9%9B%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非平衡数据集;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聚类算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%AC%A0%E6%8A%BD%E6%A0%B7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">欠抽样;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8E%BB%E5%86%97%E4%BD%99&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">去冗余;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%86%B3%E7%AD%96%E6%A0%91%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多决策树预测模型;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    牛壮 (1991—) , 男, 硕士研究生, 主研方向为数据挖掘;;
                                </span>
                                <span>
                                    *李凤莲 (通信作者) , 教授、博士;E-mail: ghllfl@163.com;
                                </span>
                                <span>
                                    张雪英, 教授、博士、博士生导师;;
                                </span>
                                <span>
                                    樊宇宙, 硕士研究生。;
                                </span>
                                <span>
                                    魏鑫, 硕士研究生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-03-05</p>

                    <p>

                            <b>基金：</b>
                                                        <span>山西省自然科学基金 (201801D121138);</span>
                                <span>山西省重点研发计划 (201803D31045);</span>
                                <span>山西省科技重大专项 (20181102008);</span>
                    </p>
            </div>
                    <h1><b>Improved Under-sampling Method and Its Application in the Classification of Imbalanced Data Sets</b></h1>
                    <h2>
                    <span>NIU Zhuang</span>
                    <span>LI Fenglian</span>
                    <span>ZHANG Xueying</span>
                    <span>FAN Yuzhou</span>
                    <span>WEI Xin</span>
            </h2>
                    <h2>
                    <span>College of Information and Computer, Taiyuan University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The removal under-sampling method does not consider much the influence of data distribution changes on the classification results when the unbalanced data sets are classified, an improved under-sampling method based on clustering fusion and redundancy removal is proposed.The clustering algorithm is used to obtain the clustering centers of the high-density distribution regions of most samples.Most of the samples are divided into different subsets.The redundancy coefficients of each subset are calculated to de-redundantly delete most of the samples.After under-sampling the data sets with different balance rates, the cost-sensitive attribute hybrid strategy multi-decision tree prediction model is used for classification.Experimental results show that the proposed method can enable the prediction model to improve the positive rate of a few samples and the G-mean value of the prediction model under the premise of ensuring that the classification accuracy of the unbalanced data sets is not reduced.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=imbalanced%20data%20sets&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">imbalanced data sets;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=clustering%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">clustering algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=under-sampling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">under-sampling;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=redundancy%20removal&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">redundancy removal;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multi-decision%20tree%20prediction%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multi-decision tree prediction model;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-03-05</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="42">支持向量机<citation id="160" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、决策树和贝叶斯等算法<citation id="161" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>对平衡数据集分类预测效果较好, 但存在数据分布不平衡问题。以二分类问题为例, 其中一种样本所占的比例如果远大于另一种样本所占的比例, 则为非平衡数据集, 两种样本数之比称为不平衡率 (Imbalanced Rate, IR) , 如故障诊断<citation id="162" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、信用欺诈<citation id="163" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、医疗诊断<citation id="164" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等数据, 对数据集少数类样本预测错误通常会带来较大的经济损失, 甚至付出生命代价, 如煤矿突水<citation id="165" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>及瓦斯突出事故<citation id="166" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。因此, 如何提高非平衡数据集少数类的分类预测准确率是国内外的研究热点。</p>
                </div>
                <div class="p1">
                    <p id="43">目前, 常用的非平衡数据集分类预测方法包括抽样法、代价敏感法<citation id="167" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、集成学习法<citation id="168" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>及主动学习法<citation id="169" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>等。抽样法的基本原理是通过改变数据集的样本数量, 使IR尽可能降低, 其主要方法有过抽样<citation id="170" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和欠抽样<citation id="171" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 但过抽样方法容易造成分类器过拟合, 随机欠抽样方法则容易导致有用信息丢失<citation id="172" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。基于最近邻规则的欠抽样方法, 由于删除了类别边界的多数类样本, 导致在类别边界附近的数据样本分类效果较差<citation id="173" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。文献<citation id="174" type="reference">[<a class="sup">3</a>]</citation>提出一种基于距离条件最大熵的欠抽样算法, 通过限制多数类样本与少数类样本的距离, 以保留重要类别边界的样本。文献<citation id="175" type="reference">[<a class="sup">15</a>]</citation>提出基于聚类的欠抽样算法, 其主要思路是对多数类样本进行聚类, 用聚类算法获得的聚类中心来代替其周围的多数类样本, 以减少多数类样本数量。这种方法有效避免了类别边界样本误删除对分类结果的影响, 但是用聚类中心来代替其周围的数据样本, 会使聚类中心附近的数据样本丢失, 导致多数类样本的数据分布发生变化, 从而对分类的准确性产生影响。文献<citation id="176" type="reference">[<a class="sup">16</a>]</citation>提出去冗余抽样算法, 将多数类样本中相对于少数类样本冗余度较高的2个样本删除其中一个, 在尽量不改变多数类样本原始分布的基础上欠抽样, 但这种方法可能会造成多数类样本边界数据缺失, 影响分类准确率。</p>
                </div>
                <div class="p1">
                    <p id="44">本文在上述研究的基础上, 提出一种基于聚类融合去冗余的改进欠抽样方法。通过给出相似度冗余系数概念, 有效度量数据样本间的相似度, 对多数类样本进行聚类分析, 将多数类样本划分为不同子集, 使用相似度冗余系数对各子集进行去冗余欠抽样。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag">1 相关知识</h3>
                <div class="p1">
                    <p id="46">欠抽样是对非平衡数据集进行预处理的常用方法, 但在抽样过程中会造成输入样本的数据分布发生变化。为此, 本文提出一种基于聚类融合去冗余的改进欠抽样方法, 该方法通过对多数类样本进行聚类, 并对聚类后的样本子集进行去冗余抽样, 从而完成数据集的欠抽样。设待分析的二分类非平衡数据集为<i>S</i>, 其包含的多数类样本记为<i>S</i><sup>-</sup>, 对应样本数量为<i>m</i>, 少数类样本记为<i>S</i><sup>+</sup>, 其对应样本数量为<i>n</i>, <i>dist</i> (<i>A</i>, <i>B</i>) 表示<i>A</i>、<i>B</i>这2个样本之间的欧氏距离。其中, 多数类样本称为负类样本, 少数类样本称为正类样本。</p>
                </div>
                <h4 class="anchor-tag" id="47" name="47">1.1 聚类算法</h4>
                <div class="p1">
                    <p id="48">聚类算法作为一种无监督学习算法, 是数据挖掘领域中的一个重要算法。在对数据样本进行聚类时, 该算法按照样本之间的相似性将数据集划分为若干个样本子集, 以使相同子集内的样本相似性尽可能大, 而不同子集间样本相似性尽可能小。经典K-means聚类算法是以欧氏距离作为样本之间的相似性度量值进行聚类计算, 首先在数据集中随机选择<i>k</i>个样本作为初始聚类中心, 通过计算样本之间的欧氏距离, 把与聚类中心距离较近的样本划分为同一类, 然后计算同类各样本之间新的聚类中心, 通过迭代不断更新聚类中心, 直到聚类中心变化达到设定阈值, 得到最终的聚类中心。在本文所提出的基于聚类融合去冗余的改进欠抽样方法中, 使用K-means算法作为聚类算法。</p>
                </div>
                <h4 class="anchor-tag" id="49" name="49">1.2 去冗余抽样算法</h4>
                <div class="p1">
                    <p id="50">去冗余抽样算法主要是通过求解多数类样本中各样本间的冗余度, 以使具有较高冗余度的2个样本删除其中一个。冗余度是指多数类样本中距离少数类样本较远, 且彼此距离较近的2个样本<citation id="177" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。该算法可以在保持原始数据分布不变和保证类别边界附近的样本不被删除的前提下尽可能多删除多数类样本, 使数据集类别比趋于平衡。一个多数类样本到少数类样本的最小距离表示为:</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mi>i</mi><mi>n</mi><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi></mrow></munder><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>S</mi><msubsup><mrow></mrow><mi>i</mi><mo>-</mo></msubsup><mo>, </mo><mi>S</mi><msubsup><mrow></mrow><mi>j</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo>, </mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>m</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">任意2个多数类样本之间的冗余度表示为:</p>
                </div>
                <div class="p1">
                    <p id="53" class="code-formula">
                        <mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mo stretchy="false"> (</mo><mi>S</mi><msubsup><mrow></mrow><mi>i</mi><mo>-</mo></msubsup><mo>, </mo><mi>S</mi><msubsup><mrow></mrow><mi>j</mi><mo>-</mo></msubsup><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mfrac><mrow><mi>Μ</mi><mi>i</mi><mi>n</mi><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>S</mi><msubsup><mrow></mrow><mi>i</mi><mo>-</mo></msubsup><mo>, </mo><mi>S</mi><msubsup><mrow></mrow><mi>j</mi><mo>-</mo></msubsup><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo><mi>i</mi><mo>≠</mo><mi>j</mi></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>, </mo><mi>i</mi><mo>=</mo><mi>j</mi></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="54">当多数类样本<i>S</i><sub><i>i</i></sub><sup>-</sup>距离少数类样本的最小距离<i>MinD</i><sub><i>i</i></sub>一定时, 2个多数类样本<i>S</i><sup>-</sup><sub><i>i</i></sub>与<i>S</i><sup>-</sup><sub><i>j</i></sub>之间欧氏距离越小, 两者之间的冗余度<i>r</i> (<i>S</i><sup>-</sup><sub><i>i</i></sub>, <i>S</i><sup>-</sup><sub><i>j</i></sub>) 越大。去冗余抽样算法运行步骤具体描述如下:</p>
                </div>
                <div class="p1">
                    <p id="55"><b>步骤1</b> 根据式 (1) 计算<i>MinD</i><sub><i>i</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="56"><b>步骤2</b> 根据式 (2) 计算多数类样本之间的冗余度<i>r</i> (<i>S</i><sup>-</sup><sub><i>i</i></sub>, <i>S</i><sup>-</sup><sub><i>j</i></sub>) , 并组成冗余度矩阵<b><i>R</i></b>= (<i>r</i> (<i>s</i><sup>-</sup><sub><i>i</i></sub>, <i>s</i><sup>-</sup><sub><i>j</i></sub>) ) <sub><i>m</i></sub><sub>×</sub><sub><i>m</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="57"><b>步骤3</b> 在冗余度矩阵中删除冗余度最高值所对应的2个样本中的其中一个。</p>
                </div>
                <div class="p1">
                    <p id="58"><b>步骤4</b> 如果删除的样本没有达到预先设定的数量, 执行步骤3;否则算法结束。</p>
                </div>
                <div class="p1">
                    <p id="59">这种方法虽然保证了类别边界附近的样本 (少数类样本附近密集的多数类样本) 不被删除, 但是有可能将多数类样本边界样本被删除, 导致数据分布发生改变, 造成非平衡数据集分类准确率不高。例如, 将非平衡数据集ecoli_0_1_3_7_vs_2_4_5_6中包含的79个少数类和257个多数类的样本分布映射到二维平面中, 如图1所示, 椭圆中的星型点是部分多数类样本的边界样本, 当这些样本被删除时, 会使多数类样本的数据分布发生局部变化, 影响分类准确率。其中, ·表示少数类样本, ×表示多数类样本。图1 (a) 为原始数据样本分布。图1 (b) 为去冗余抽象算法<citation id="178" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>抽样后的数据分布, 从椭圆部分可以看出, 通过该算法进行欠抽样后, 椭圆部分所示的部分多数类边界样本被删除, 在这部分范围内样本分布发生了变化。图1 (c) 为使用本文方法抽样后的数据分布, 可以看出, 通过本文方法进行欠抽样后, 椭圆部分所示的部分多数类边界样本并没有被删除, 且在原始数据分布基本不变的情况下多数类冗余样本尽可能多的被删除。</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906035_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 非平衡数据集样本分布" src="Detail/GetImg?filename=images/JSJC201906035_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 非平衡数据集样本分布</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906035_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="61" name="61" class="anchor-tag">2 基于聚类融合去冗余的改进欠抽样方法</h3>
                <div class="p1">
                    <p id="62">基于聚类融合去冗余的改进欠抽样方法是在本文提出的相似度冗余系数的基础上, 对数据集进行聚类融合, 以去除多数类冗余样本的一种改进欠抽样方法。本文方法可将多数类冗余样本进行删除, 从而达到欠抽样的目的, 以降低非平衡数据集不平衡率, 提高预测模型对少数类的预测性能。</p>
                </div>
                <div class="p1">
                    <p id="63">2.1 相似度冗余系数</p>
                </div>
                <div class="p1">
                    <p id="64">为有效度量多数类样本间的相似度, 本文提出了相似度冗余系数概念。相似度冗余系数是指任意2个样本基于其聚类中心的相似度值, 相似度越高且距聚类中心越近的2个样本的相似度冗余系数 (<i>SimR</i>) 越小, 其定义如式 (3) 所示。</p>
                </div>
                <div class="p1">
                    <p id="65"><i>SimR</i><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow><mi>n</mi></msubsup></mrow></math></mathml>=<i>D</i><mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>·<i>dist</i> (<i>S</i><mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mo>-</mo><mi>n</mi></mrow></msubsup></mrow></math></mathml>, <i>S</i><mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mo>-</mo><mi>n</mi></mrow></msubsup></mrow></math></mathml>) , <i>i</i>=1, 2, …, <i>m</i>, </p>
                </div>
                <div class="p1">
                    <p id="70"><i>j</i>=1, 2, …, <i>m</i>      (3) </p>
                </div>
                <div class="p1">
                    <p id="71">其中, <i>D</i><mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>n</mi></msubsup></mrow></math></mathml>表示任意一个多数类样本i到其聚类中心的距离, dist (S<mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mo>-</mo><mi>n</mi></mrow></msubsup></mrow></math></mathml>, S<mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mo>-</mo><mi>n</mi></mrow></msubsup></mrow></math></mathml>) 表示任意2个多数类样本i、j间的欧氏距离。</p>
                </div>
                <div class="p1">
                    <p id="75">图2 (<i>a</i>) 为多数类样本在二维空间的分布, 利用聚类方法将方框、圆和三角形划分为3个不同子集, 通过相似度冗余系数找到同一子集中欧氏距离较小的冗余样本及其分布如空心方框、圆和三角形。图2 (<i>b</i>) 为删除其中冗余样本之后样本的分布, 与图2 (<i>a</i>) 相比, 删除3个子集中所有的空心图形样本后, 数据样本分布并未发生显著改变。</p>
                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906035_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 多数类样本的数据分布" src="Detail/GetImg?filename=images/JSJC201906035_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 多数类样本的数据分布</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906035_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="77">2.2 改进欠抽样方法</p>
                </div>
                <div class="p1">
                    <p id="78">本文提出的基于聚类融合去冗余的改进欠抽样方法, 是将聚类算法与去冗余算法进行有效融合, 在不改变多数类样本数据分布特性的前提下, 有效去除多数类样本中的冗余样本。</p>
                </div>
                <div class="p1">
                    <p id="79">本文对非平衡数据集中的多数类样本采用K-means算法进行聚类, 已有聚类融合算法在非平衡数据集的应用中, 是用聚类中心代替聚类集合中的所有样本, 使非平衡率接近1, 因此<i>K</i>值由少数类样本的数量决定。文献<citation id="179" type="reference">[<a class="sup">15</a>]</citation>提出基于聚类融合的欠抽样算法, 将多数类样本通过K-means聚类划分后的每一个样本集合作为一个样本子集, 为使多数类样本数量和少数类样本数量尽量趋于均衡, 可将聚类中心个数设置为少数类样本个数, 再采用本文算法对多数类样本子集进行去冗余欠抽样。为避免将样本数较少的子集中的样本过多删除而改变样本的分布规律, 本文设置了一个阈值<i>T</i>, 当样本子集中样本的数量小于阈值<i>T</i>时, 不进行去冗余操作, <i>T</i>的取值可根据聚类结果进行设置, 本文<i>T</i>的取值为5。在对其他样本子集进行去冗余操作时, 单次执行该算法可使非平衡率降低约<i>IR</i>/2, 当数据集的非平衡率较高时, 可通过设置迭代次数使非平衡率进一步降低至理想情况。</p>
                </div>
                <div class="p1">
                    <p id="80">由于在聚类中心附近的多数类样本相似度较高且数量较多, 因此可对多数类样本采用K-means聚类算法划分为多个多数类样本子集, 通过计算每个多数类样本子集各样本间的相似度冗余系数, 组成相似度冗余系数矩阵, 以将相似度冗余系数较小值所对应的2个样本中的一个删除。根据相似度冗余系数矩阵的变化, 将每个样本子集中的多数类冗余样本进行删除, 达到欠抽样的目的。通过这种方法, 可在保持原始数据分布不变的前提下, 既保证了类别边界附近的样本不被删除, 也使得多数类样本的边界样本得以保留。基于聚类融合去冗余的改进欠抽样方法流程如图3所示。</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906035_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 基于聚类融合去冗余的改进欠抽样方法流程" src="Detail/GetImg?filename=images/JSJC201906035_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 基于聚类融合去冗余的改进欠抽样方法流程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906035_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="82">多数类样本冗余度的度量采用本文提出的相似度冗余系数。该系数可有效度量多数类数据样本之间特征相近程度, 其值越小证明2个多数类样本之间的特征相近程度越高。</p>
                </div>
                <div class="p1">
                    <p id="83">基于聚类融合去冗余的改进欠抽样算法运行伪代码具体如下:</p>
                </div>
                <div class="p1">
                    <p id="84"><b>算法</b> 基于聚类融合去冗余的改进欠抽样算法</p>
                </div>
                <div class="p1">
                    <p id="85"><b>输入</b> 多数类样本集<i>S</i><sup>-</sup>, 少数类样本集<i>S</i><sup>+</sup>, 设置阈值<i>T</i>, 最大迭代次数<i>L</i></p>
                </div>
                <div class="p1">
                    <p id="86"><b>输出</b> 欠抽样后的多数类样本集<i>S</i><sup>-</sup><sub>0</sub></p>
                </div>
                <div class="p1">
                    <p id="87">1.对多数类样本集S<sup>-</sup>用K-means方法进行聚类, 其中聚类中心数的取值为少数类样本的数量n;</p>
                </div>
                <div class="p1">
                    <p id="88">2.把多数类样本集S<sup>-</sup>根据K-means聚类结果分为n个子集S<sup>-r</sup>, r=1, 2, …, n, 各子集样本数量为m<sub>r</sub>, r=1, 2, …, n, 且满足m=m<sub>1</sub>+m<sub>2</sub>+…+m<sub>n</sub>, 且初始化n个S<mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>为空的集合;</p>
                </div>
                <div class="p1">
                    <p id="90">设置l初值为1;</p>
                </div>
                <div class="p1">
                    <p id="91">当1≤l≤L时, 执行以下迭代:</p>
                </div>
                <div class="p1">
                    <p id="92">{</p>
                </div>
                <div class="p1">
                    <p id="93">设置r初值为1;</p>
                </div>
                <div class="p1">
                    <p id="94">当1≤r≤n时, 执行以下循环:</p>
                </div>
                <div class="p1">
                    <p id="95">{</p>
                </div>
                <div class="p1">
                    <p id="96">3.当m<sub>r</sub>≤T时, 令S<mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>=S<sup>-r</sup>, 执行步骤5;当m<sub>r</sub>&gt;T时, 执行步骤4。</p>
                </div>
                <div class="p1">
                    <p id="98">4.对多数类样本子集S<sup>-r</sup>, 进行去冗余删除操作, 具体描述如下:</p>
                </div>
                <div class="p1">
                    <p id="99">4.1计算子集S<sup>-r</sup>中各个样本S<mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>i</mtext><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>, i=1, 2, …, m<sub>r</sub>, 到本聚类中心S<mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mtext>r</mtext><mo stretchy="false">) </mo></mrow><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>的距离D<mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>i</mtext><mtext>r</mtext></msubsup></mrow></math></mathml>, D<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>i</mtext><mtext>r</mtext></msubsup></mrow></math></mathml>=dist (S<mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>i</mtext><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>, S<mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mtext>r</mtext><mo stretchy="false">) </mo></mrow><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>) , i=1, 2, …, m<sub>r</sub>, r=1, 2, …, n, dist表示2个多数类样本间的欧式距离。</p>
                </div>
                <div class="p1">
                    <p id="106">4.2计算S<sup>-r</sup>内任意2个样本间的相似度冗余系数SimR, 其求解公式如式 (3) 所示, 并构造得到相似度冗余系数矩阵, 共得到n个相似度冗余系数矩阵。</p>
                </div>
                <div class="p1">
                    <p id="107">4.3新建空集S<sub> (r) </sub>, 删除S<sup>-r</sup>, r=1, 2, …, n, 子集内冗余样本:</p>
                </div>
                <div class="p1">
                    <p id="108">4.3.1选择相似度冗余系数矩阵R<mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mtext>i</mtext><mo>, </mo><mtext>j</mtext><mo stretchy="false">) </mo></mrow><mtext>r</mtext></msubsup></mrow></math></mathml>中相似度冗余系数最小值所对应S<sup>-r</sup>中的2个样本S<mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>i</mtext><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>和S<mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>j</mtext><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>放入S<sub> (r) </sub>内, 然后把S<mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>i</mtext><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>、S<mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>j</mtext><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>中的任意一个从S<sub> (r) </sub>中删除;</p>
                </div>
                <div class="p1">
                    <p id="114">4.3.2把S<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>i</mtext><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>和S<mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>j</mtext><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>从S<sup>-r</sup>中删除;</p>
                </div>
                <div class="p1">
                    <p id="117">4.3.3将该相似度冗余系数矩阵中的第i行和第j行、第i列和第j列删除, 得到新的相似度冗余系数矩阵;</p>
                </div>
                <div class="p1">
                    <p id="118">4.3.4执行4.3.1, 直到该相似度冗余系数矩阵为空或者只剩一行一列, 然后将S<sub> (r) </sub>和删除了冗余样本的子集S<sup>-r</sup>合成新的样本子集S<mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>;</p>
                </div>
                <div class="p1">
                    <p id="120">5.r=r+1;</p>
                </div>
                <div class="p1">
                    <p id="121">}</p>
                </div>
                <div class="p1">
                    <p id="122">l=l+1;</p>
                </div>
                <div class="p1">
                    <p id="123">}</p>
                </div>
                <div class="p1">
                    <p id="124">6.将所有去冗余的样本子集S<mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow><mrow><mo>-</mo><mtext>r</mtext></mrow></msubsup></mrow></math></mathml>合成得到欠抽样后的多数类样本集合S<sup>-</sup><sub>0</sub>, 算法结束。</p>
                </div>
                <h3 id="126" name="126" class="anchor-tag">3 基于改进欠抽样的非平衡数据集分类预测</h3>
                <div class="p1">
                    <p id="127">在对非平衡数据集进行分类时, 较好的分类性能取决于对数据集合理的欠抽样预处理和分类性能较好的预测模型。本文采用基于代价敏感混合属性多决策树 (Cost-sensitive Hybrid Measure Attributes Selection Multi-Decision Tree, CHMDT) <citation id="180" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>模型作为分类器。该模型采用基于Gini指标与信息增益相融合的混合策略作为属性选择准则, 并将代价敏感因子融入属性选择阶段, 以使多数类和少数类样本被错分时赋予不同的误分代价, 从而提高少数类分类预测性能。多决策树模型采用基于Top-<i>N</i>的不同根节点多决策树建树方法, 其将属性的重要性按照Top-1到Top-<i>N</i>排序, 然后分别作为根节点进行建树。对非平衡数据集进行分类时, 与基于Gini指标的CART单决策树及基于信息增益的ID3单决策树算法相比, 基于代价敏感混合属性选择策略的多决策树预测模型可获得更高的少数类分类准确率, 并保证了预测器总体分类性能。基于聚类融合去冗余的改进欠抽样方法对非平衡数据集进行分类的流程如图4所示。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906035_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 基于聚类融合去冗余的改进欠抽样方法流程" src="Detail/GetImg?filename=images/JSJC201906035_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 基于聚类融合去冗余的改进欠抽样方法流程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906035_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="129" name="129" class="anchor-tag">4 实验结果与分析</h3>
                <h4 class="anchor-tag" id="130" name="130">4.1 实验数据</h4>
                <div class="p1">
                    <p id="131">为验证本文算法用于非平衡数据集分类时的效果, 使用15个不同非平衡率数据集进行实验, 实验数据选自UCI数据集和KEEL数据集, 如表1所示。其中, ecoli_0_1_3_7_vs_2_4_5_6是将Ecoli中第2、4、5、6类作为正类, 其他类作为负类;glass_1_2_3_4_6_7_vs_5是将Glass Identification中第5类作为正类, 其他类作为负类;yeast_0_1_2_vs_5_6_7是将Yeast数据集EM1、EXC、VAC作为正类, CYT、NUC、MIT作为负类;Steel_K_Scatch、Steel_Pastry、Steel_Dirtiness是把Steel Plates Faults数据集的K_Scatch、Pastry、Dirtiness分别作为正类, 其他的类作为负类, 这种将数据集转化为二分类的方法在非平衡数据集分类中应用广泛<citation id="181" type="reference"><link href="37" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="132">
                    <p class="img_tit"><b>表1 数据集描述</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="132" border="1"><tr><td>数据集<br />编号</td><td>数据集<br />名称</td><td>样本<br />总数</td><td>非平<br />衡率/%</td><td>属性数</td></tr><tr><td>1</td><td>ionosphere</td><td>351</td><td>1.79</td><td>34</td></tr><tr><td><br />2</td><td>ecoli_0_1_3_7_vs_2_4_5_6</td><td>336</td><td>3.36</td><td>7</td></tr><tr><td><br />3</td><td>glass_1_2_3_4_6_7_vs_5</td><td>214</td><td>15.46</td><td>9</td></tr><tr><td><br />4</td><td>yeast_0_1_2_vs_5_6_7</td><td>1 244</td><td>10.52</td><td>8</td></tr><tr><td><br />5</td><td>Steel_K_Scatch</td><td>1 491</td><td>9.22</td><td>27</td></tr><tr><td><br />6</td><td>Steel_Pastry</td><td>1 941</td><td>11.28</td><td>27</td></tr><tr><td><br />7</td><td>Steel_Dirtiness</td><td>1 941</td><td>34.29</td><td>27</td></tr><tr><td><br />8</td><td>yeast_1_4_5_8_vs_7</td><td>693</td><td>22.10</td><td>8</td></tr><tr><td><br />9</td><td>yeast_2_vs_8</td><td>482</td><td>23.10</td><td>8</td></tr><tr><td><br />10</td><td>yeast_1_2_8_9_vs_7</td><td>947</td><td>30.57</td><td>8</td></tr><tr><td><br />11</td><td>ecoli_0_1_3_7_vs_2_6</td><td>281</td><td>39.14</td><td>7</td></tr><tr><td><br />12</td><td>winequality_red_8_vs_6_7</td><td>855</td><td>46.50</td><td>11</td></tr><tr><td><br />13</td><td>shuttle_2_vs_5</td><td>3 316</td><td>66.67</td><td>9</td></tr><tr><td><br />14</td><td>yeast_2_vs_4</td><td>514</td><td>9.08</td><td>8</td></tr><tr><td><br />15</td><td>glass_0_1_6_vs_5</td><td>184</td><td>19.44</td><td>9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="133" name="133">4.2 实验设计</h4>
                <div class="p1">
                    <p id="134">本文采用十折交叉验证方法进行实验, 分类器采用基于代价敏感混合属性多决策树CHMDT模型。本文实验包括3种场景, 具体描述如下:</p>
                </div>
                <div class="p1">
                    <p id="135">1) 不采用欠抽样预处理方式, 仅使用CHMDT分类器模型对非平衡数据集进行分类。</p>
                </div>
                <div class="p1">
                    <p id="136">2) 采用文献<citation id="182" type="reference">[<a class="sup">16</a>]</citation>欠抽样算法对非平衡数据集进行预处理, 再利用CHMDT分类器模型对预处理后的非平衡数据集进行分类。</p>
                </div>
                <div class="p1">
                    <p id="137">3) 采用本文提出的欠抽样方法对非平衡数据集进行预处理, 再采用CHMDT分类器模型对预处理后的非平衡数据集进行分类。</p>
                </div>
                <div class="p1">
                    <p id="138">本文分别测试3种实验场景分类结果的真实正类率、准确率和几何平均值 (G-mean) 。实验场景设计编号详情如表2所示。</p>
                </div>
                <div class="area_img" id="139">
                    <p class="img_tit"><b>表2 实验场景详情描述</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="139" border="1"><tr><td><br />场景编号</td><td>场景描述</td></tr><tr><td><br />1</td><td>仅使用CHMDT分类预测模型</td></tr><tr><td><br />2</td><td>已有去冗余抽样算法+CHMDT分类预测模型</td></tr><tr><td><br />3</td><td>本文提出的去冗余抽样算法+CHMDT分类预测模型</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="140" name="140">4.3 评价指标</h4>
                <div class="p1">
                    <p id="141">本文采用真实正类率、准确率及几何平均值作为评价指标。其中, <i>N</i><sub>TP</sub>表示实际为正类, 而且被正确预测为正类的样本数, <i>N</i><sub>TN</sub>表示实际为负类, 且被正确预测为负类的样本数, <i>N</i><sub>FP</sub>表示实际为负类, 但被错误预测为正类的样本数, <i>N</i><sub>FN</sub>表示实际为正类, 但被错误预测为负类的样本数。具体分析如下:</p>
                </div>
                <div class="p1">
                    <p id="142">1) 真实正类率。真实正类率<i>TP</i><sub>rate</sub>反映分类预测器对少数类的预测性能, 其定义如式 (6) 所示。</p>
                </div>
                <div class="p1">
                    <p id="143" class="code-formula">
                        <mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><mi>Ρ</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>a</mtext><mtext>t</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Ν</mtext></mrow></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mtext>Ρ</mtext></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="144">其中, <i>N</i><sub>p</sub>为测试样本中少数类样本个数。正类率越大, 说明分类器对少数类的预测性能越好。</p>
                </div>
                <div class="p1">
                    <p id="145">2) 准确率。准确率<i>Acc</i><sub>rate</sub>用于分类器的总体性能评价, 其定义如式 (7) 所示, 准确率值越大, 表明分类器的整体预测性能越好。</p>
                </div>
                <div class="p1">
                    <p id="146" class="code-formula">
                        <mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>c</mi><mi>c</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>a</mtext><mtext>t</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ν</mtext></mrow></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mtext>Ρ</mtext></msub><mo>+</mo><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ν</mtext></mrow></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ν</mtext></mrow></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mtext>Ρ</mtext></msub><mo>+</mo><mi>Ν</mi><msub><mrow></mrow><mtext>Ν</mtext></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="147">3) 几何平均值。其计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="148" class="code-formula">
                        <mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo>=</mo><msqrt><mrow><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Ν</mtext></mrow></msub></mrow></mfrac><mo>×</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ν</mtext></mrow></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Ρ</mtext></mrow></msub><mo>+</mo><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>Τ</mtext><mtext>Ν</mtext></mrow></msub></mrow></mfrac></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="149">对非平衡数据集, 当多数类的样本与少数类样本的不平衡率越高时, 即使把所有少数类样本都误分为多数类, 分类器的总体预测准确率仍然较高, 因此仅仅采用准确率进行评价不合理。正类率可直接反映分类器对少数类的预测性能, 几何平均值是少数类准确率与多数类准确率积的开方。相对准确率, 几何平均值值可以更加合理的评价非平衡数据集的总体预测分类性能。</p>
                </div>
                <h4 class="anchor-tag" id="150" name="150">4.4 结果分析</h4>
                <div class="p1">
                    <p id="151">本文首先设置迭代次数为1, 然后对所有数据集进行去冗余抽样, 使非平衡率约为原来的1/2。图5给出3种场景正类率的比较结果。可以看出, 对数据集1, 由于其非平衡率较低, 场景3与其他2种场景的正类率相比提升并不突出;对数据集13, 场景3的正类率较实验场景2降低了3%, 由于数据集样本较少且非平衡率较高, 使得本文方法的场景3对其敏感度较低, 但与场景1相比, 正类率仍有提高;对数据集7、数据集9及数据集10来说, 本文方法的场景3较其他2种场景均有提高, 尤其是数据集7, 但场景2较场景1却有所降低;对其余数据集, 实验场景3的正类率均比实验场景1和实验场景2的正类率有不同程度的提升, 平均提高5%左右。实验结果表明, 本文方法通过对数据集欠抽样预处理, 其正类样本错分量减少, 且对非平衡数据集进行分类预测的正类率有所提高。</p>
                </div>
                <div class="area_img" id="152">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906035_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 3种场景的正类率比较结果" src="Detail/GetImg?filename=images/JSJC201906035_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 3种场景的正类率比较结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906035_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="153">图6给出3种实验场景准确率的比较。可以看出, 对多数数据集, 基于本文方法预处理之后的CHMDT预测模型准确率基本保持不变或略有提高, 但对数据集5和数据集13, 场景2、场景3与场景1相比, 其准确率均有所下降, 主要由于去冗余抽样算法和本文算法在抽样过程中过度删除多数类样本, 虽然增加了分类预测的正类率, 但降低了分类预测的负类率, 从而导致准确率有所降低。</p>
                </div>
                <div class="area_img" id="154">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906035_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 3种场景的准确率比较结果" src="Detail/GetImg?filename=images/JSJC201906035_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 3种场景的准确率比较结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906035_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="155">图7给出3种场景G-mean值的比较。从图7可以看出, 除数据集11和数据集13外, 与其他2种场景相比, 基于本文方法的场景3, 各个数据集的G-mean值均有所提高。虽然数据集5准确率有所下降, 但与其正类率的显著提升相比, 准确率的下降并不显著, 因此其G-mean值仍有显著提升, 从而验证了本文方法的有效性。</p>
                </div>
                <div class="area_img" id="156">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201906035_156.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 3种场景G-mean值的比较结果" src="Detail/GetImg?filename=images/JSJC201906035_156.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 3种场景G-mean值的比较结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201906035_156.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="157">综合分析, 采用本文提出的改进欠抽样方法, 可以有效提高对非平衡数据集的分类预测能力, 在保证总体预测性能基本不变前提下, 使少数类真实正类率得到显著提升, 并使分类预测结果的G-mean值得到了显著提高。</p>
                </div>
                <h3 id="158" name="158" class="anchor-tag">5 结束语</h3>
                <div class="p1">
                    <p id="159">本文针对已有方法对非平衡数据集少数类样本分类预测性能欠佳的情况, 提出一种基于聚类融合去冗余的欠抽样方法。该方法可在不改变原始数据分布的前提下, 删除非平衡数据集中冗余度高的多数类样本, 从而使非平衡数据集的不平衡率尽可能降低。在此基础上, 将15个不同平衡率数据集欠抽样处理后, 采用基于代价敏感属性混合选择策略多决策树预测模型进行分类预测。实验结果表明, 与已有欠抽样方法相比, 本文方法在在预测器准确率基本不变的前提下, 提高了少数类样本真实正类率及G-mean值。然而, 对于个别数据集, 本文方法在进行去冗余欠抽样时, 可能造成对多数类样本的过度删除, 从而降低分类器整体分类准确率, 因此, 研究并解决该问题是下一步的努力方向。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDKD201505021&amp;v=MjM3NzdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5bmxWYi9CUFNuQWFyRzRIOVRNcW85SFo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 蔡艳艳, 宋晓东.针对非平衡数据分类的新型模糊SVM模型[J].西安电子科技大学学报 (自然科学版) , 2015, 42 (5) :120-124, 160.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QHXB200206004&amp;v=MTMzOTNZOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeW5sVmIvQk5DWFRiTEc0SHRQTXE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 刘红岩, 陈剑, 陈国青.数据挖掘中的数据分类算法综述[J].清华大学学报 (自然科学版) , 2002, 42 (6) :727-730.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZCK201205016&amp;v=MTE0ODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnlubFZiL0JMemZJWmJHNEg5UE1xbzlFWW9RS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 史岩, 李小民, 齐晓慧.一种新型欠采样的支持向量机非平衡数据故障诊断研究[J].计算机测量与控制, 2012, 20 (5) :1203-1204, 1235.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Toward scalable learning with non-uniform class and costdistributions: a case study incredit card fraud detecti on">

                                <b>[4]</b> CHAN P K, STOLFO S J.Toward scalable learning with non-uniform class and cost distributions:a case study in credit card fraud detection[C]//Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining.[S.l.]:AAAI Press, 1998:164-168.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501091848&amp;v=MDA1OTltVUxuSUlWNFNhaHM9TmlmT2ZiSzdIdEROcW85RVpPSU9CSGd4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5ag==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> CHANG R F, WU WenJie, MOON W K, et al.Support vector machines for diagnosis of breast tumors on US images[J].Academic Radiology, 2003, 10 (2) :189-197.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MKZD201412015&amp;v=MjA4NTlHRnJDVVJMT2VaZVJvRnlubFZiL0JLQ2JSYXJHNEg5WE5yWTlFWVlRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 杜春蕾, 张雪英, 李凤莲.改进的CART算法在煤层底板突水预测中的应用[J].工矿自动化, 2014, 40 (12) :52-56.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZJY201710032&amp;v=MDM3MTRubFZiL0JJVGZCZDdHNEg5Yk5yNDlHWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 张翕茜, 李凤莲, 张雪英, 等.基于代价敏感混合分裂策略的多决策树算法[J].计算机技术与应用, 2017, 43 (10) :128-136.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122600211100&amp;v=MTk1OTE5SDlQT3FZOUZadW9PRFh3NW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxuSUlWNFNhaHM9TmlmT2ZiSw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> SIERS M J, ISLAM M Z.Software defect prediction using a cost sensitive decision forest and voting, and a potential solution to the class imbalance problem[J].Information Systems, 2015, 51 (C) :62-71.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDD7D5A996C73D64A12184635E632B8C9&amp;v=MDU1OThRMzVONWh4Ymk1d0tFPU5pZk9mY2ZNR2FYSjNvWk1ZcGdJRHdnL3kyY1M2RDUxVEhuaHFXY3plckRtVGNtV0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> XIA Xin, LO D, SHIHAB E, et al.ELBlocker:predicting blocking bugs with ensemble imbalance learning[J].Information and Software Technology, 2015, 61:93-106.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Properties of a GP active learning framework for streaming data with class imbalance">

                                <b>[10]</b> KHANCHI S, HEYWOOD M I, ZINCIR-HEYWOOD A N.Properties of a GP active learning framework for streaming data with class imbalance[C]//Proceedings of the Genetic and Evolutionary Computation Conference.New York, USA:ACM Press, 2017:945-952.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 CHAWLA N V, BOWYER K W, HALL L O, et al.SMOTE:synthetic minority over-sampling technique[J].Journal of Artificial Intelligence Research, 2002, 16 (1) :321-357.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500001057&amp;v=MTgzMjlSZEdlcnFRVE1ud1plWnVIeWptVUxuSUlWNFNhaHM9TmlmSlpiSzlIdGpNcW85RlpPc09ESGsrb0JNVDZUNFBRSC9pcg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> GARCÍA S, HERRERA F.Evolutionary under-sampling for classification with imbalanced datasets:proposals and taxonomy[J].Evolutionary Computation, 2014, 17 (3) :275-306.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM388195169BFE0E7494828A3B5E98AD35&amp;v=MDAzNDJ1SFlmT0dRbGZDcGJRMzVONWh4Ymk1d0tFPU5pZklZN0N3RnRERnFvNURiWmw1ZVh4TXlCSWE3amQvUUE3aDNoZEFjTHJsTWJtYUNPTnZGU2lXV3I3SklGcG1hQg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> BATISTA G E A P A, PRATI R C, MONARD M C.A study of the behavior of several methods for balancing machine learning training data[J].ACM SIGKDD Explorations Newsletter, 2004, 6 (1) :20-29.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving Identification of Difficult Small Classes by Balancing Class Distribution">

                                <b>[14]</b> LAURIKKALA J.Improving identification of difficult small classes by balancing class distribution[C]//Proceedings of the 8th Conference on Artificial Intelligence Medicine.Berlin, Germany:Springer, 2001:63-66.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDFB713E40B45707321DAC87E21B62038&amp;v=MTYwNjY3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU41aHhiaTV3S0U9TmlmT2ZjZk9iTmJOclBwQlpKa0xDWHM1eUJVUjYwc01PM2ZsMlJBMEM3U1dSYm1YQ09OdkZTaVdXcg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> LIN Weichao, TSAI C F, HU Yahan, et al.Cluster-based undersampling in class-imbalanced data[J].Information Sciences, 2017, 409-410:17-26.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SXDR201702008&amp;v=MDAwNzFNclk5RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5bmxWYi9CTmpYUGZMRzRIOWI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 史颖, 亓慧.一种去冗余抽样的非平衡数据分类方法[J].山西大学学报 (自然科学版) , 2017, 40 (2) :255-261.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC58E726557DC023D6CA108DBF7BAB136&amp;v=MjQ5MTBPR1FsZkNwYlEzNU41aHhiaTV3S0U9TmlmT2ZjQzlGcVRMcllsQVlleDdmM3c3ekdJVm1VNThTSGVXM21ReUM4UG1STG1aQ09OdkZTaVdXcjdKSUZwbWFCdUhZZg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> LI Fenglian, ZHANG Xueying, ZHANG Xiqian, et al.Cost-sensitive and hybrid attribute measure multi-decision tree over imbalanced data sets[J].Information Sciences, 2018, 422:242-256.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14121200017848&amp;v=MjE2NjRlcnFRVE1ud1plWnVIeWptVUxuSUlWNFNhaHM9TmlmT2ZiSzhIOVBOclk5RlpPb0lCSGd4b0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> BEYAN C, FISHER R.Classifying imbalanced data sets using similarity based hierarchical decomposition[J].Pattern Recognition, 2015, 48 (5) :1653-1672.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1D6C57643828D7BD8076944F2A8B743F&amp;v=MjUwNTltMmhCRWNjQ1RRYm5wQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TjVoeGJpNXdLRT1OaWZPZmJMTUdLTEpxSWxCWitNTkJBZyt2V0liNmpoN1FYdg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> RIVERA W A.Noise reduction a priori synthetic over-sampling for class imbalanced data sets[J].Information Sciences, 2017, 408 (C) :146-161.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201906035" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201906035&amp;v=MDk4Njg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeW5sVmIvT0x6N0JiYkc0SDlqTXFZOUdZWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQxQTZSZWp6VHBWMkMvWVdDaHZmUT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
