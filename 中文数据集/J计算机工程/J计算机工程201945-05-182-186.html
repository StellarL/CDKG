<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130530551905000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201905029%26RESULT%3d1%26SIGN%3dEZDhH6IMfjezjzfJs%252f9FlY1D0vg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201905029&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201905029&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201905029&amp;v=MjY3MTJxbzlIYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkzbVVyM0pMejdCYmJHNEg5ak0=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#36" data-title="1 卷积神经网络 ">1 卷积神经网络</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#41" data-title="1.1 卷积层">1.1 卷积层</a></li>
                                                <li><a href="#46" data-title="1.2 池化层">1.2 池化层</a></li>
                                                <li><a href="#54" data-title="1.3 反向传播">1.3 反向传播</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#60" data-title="2 改进的卷积神经网络 ">2 改进的卷积神经网络</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="2.1 改进的inception结构">2.1 改进的inception结构</a></li>
                                                <li><a href="#74" data-title="2.2 损失函数的最优选择">2.2 损失函数的最优选择</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#89" data-title="3.1 实验样本采集">3.1 实验样本采集</a></li>
                                                <li><a href="#92" data-title="3.2 字符识别">3.2 字符识别</a></li>
                                                <li><a href="#103" data-title="3.3 对比分析">3.3 对比分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#107" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#45" data-title="&lt;b&gt;图1 卷积层操作示意图&lt;/b&gt;"><b>图1 卷积层操作示意图</b></a></li>
                                                <li><a href="#53" data-title="&lt;b&gt;图2 池化层操作示意图&lt;/b&gt;"><b>图2 池化层操作示意图</b></a></li>
                                                <li><a href="#63" data-title="&lt;b&gt;图3 原始inception结构&lt;/b&gt;"><b>图3 原始inception结构</b></a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;图4 小卷积核inception结构&lt;/b&gt;"><b>图4 小卷积核inception结构</b></a></li>
                                                <li><a href="#71" data-title="&lt;b&gt;图5 基于小卷积核inception结构的CNN&lt;/b&gt;"><b>图5 基于小卷积核inception结构的CNN</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;表1 网络结构参数&lt;/b&gt;"><b>表1 网络结构参数</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;图6 实验样本图片&lt;/b&gt;"><b>图6 实验样本图片</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;图7 训练过程中的2种参数变化情况&lt;/b&gt;"><b>图7 训练过程中的2种参数变化情况</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;图8 字符分类识别结果&lt;/b&gt;"><b>图8 字符分类识别结果</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;图9 倾斜字符识别结果&lt;/b&gt;"><b>图9 倾斜字符识别结果</b></a></li>
                                                <li><a href="#100" data-title="&lt;b&gt;图10 被遮挡字符识别结果&lt;/b&gt;"><b>图10 被遮挡字符识别结果</b></a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;表2 不同方法字符识别性能对比&lt;/b&gt;"><b>表2 不同方法字符识别性能对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 单连平, 窦强.基于深度学习的海战场图像目标识别[J].指挥控制与仿真, 2019 (1) :1-5." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QBZH201901001&amp;v=MzE1NDRSTE9lWmVSb0Z5M21VcjNKTkMvUlpyRzRIOWpNcm85RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         单连平, 窦强.基于深度学习的海战场图像目标识别[J].指挥控制与仿真, 2019 (1) :1-5.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" ROUTRAY S, RAY A K, MISHRA C, et al.Efficient hybrid image denoising scheme based on SVM classification[J].Optik, 2018, 157:503-511." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9A6448A7C7BB2056C6002C568DD8933D&amp;v=MzAyNDBhQnVIWWZPR1FsZkNwYlEzNU41aHdidSt3cWs9TmlmT2ZickpHTlhJcC81Q0YreDlmbjQ1eWhCZzdEOTlTZ3pucWhwQkRicWRScm5yQ09OdkZTaVdXcjdKSUZwbQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         ROUTRAY S, RAY A K, MISHRA C, et al.Efficient hybrid image denoising scheme based on SVM classification[J].Optik, 2018, 157:503-511.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 余永维, 殷国富, 殷鹰, 等.基于深度学习网络的射线图像缺陷识别方法[J].仪器仪表学报, 2014, 35 (9) :2012-2018." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201409012&amp;v=MTYxMzBSb0Z5M21VcjNKUER6VGJMRzRIOVhNcG85RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         余永维, 殷国富, 殷鹰, 等.基于深度学习网络的射线图像缺陷识别方法[J].仪器仪表学报, 2014, 35 (9) :2012-2018.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" LECUN Y, BOTTOU L, BENGIO Y, et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gradient-based learning applied to document recognition">
                                        <b>[4]</b>
                                         LECUN Y, BOTTOU L, BENGIO Y, et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" KRIZHEVSKY A, SUTSKEVER I, HINTON G E.ImageNet classification with deep convolutional neural networks[C]//Proceedings of the 25th International Conference on Neural Information Processing Systems.New York, USA:ACM Press, 2012:1097-1105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">
                                        <b>[5]</b>
                                         KRIZHEVSKY A, SUTSKEVER I, HINTON G E.ImageNet classification with deep convolutional neural networks[C]//Proceedings of the 25th International Conference on Neural Information Processing Systems.New York, USA:ACM Press, 2012:1097-1105.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" SZEGEDY C, LIU Wei, JIA Yangqing, et al.Going deeper with convolutions[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">
                                        <b>[6]</b>
                                         SZEGEDY C, LIU Wei, JIA Yangqing, et al.Going deeper with convolutions[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:1-9.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" HUBEL D H, WIESEL T N.Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex[J].The Journal of Physiology, 1962, 160 (1) :106-154." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Receptive fields, binocular interaction and functional architecture in the cat&amp;#39;s visual cortex">
                                        <b>[7]</b>
                                         HUBEL D H, WIESEL T N.Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex[J].The Journal of Physiology, 1962, 160 (1) :106-154.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 肖志鹏, 王小华, 杨冰, 等.基于卷积神经网络的绘画图像分类研究[J].中国计量大学学报, 2017, 28 (2) :227-232." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGJL201702015&amp;v=MzE0ODVMT2VaZVJvRnkzbVVyM0pQeXJCWXJHNEg5Yk1yWTlFWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         肖志鹏, 王小华, 杨冰, 等.基于卷积神经网络的绘画图像分类研究[J].中国计量大学学报, 2017, 28 (2) :227-232.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" SZEGEDY C, VANHOUCKE V, IOFFE S, et al.Rethinking the inception architecture for computer vision[C]//Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2016:2818-2826." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rethinking the Inception Architecture for Computer Vision">
                                        <b>[9]</b>
                                         SZEGEDY C, VANHOUCKE V, IOFFE S, et al.Rethinking the inception architecture for computer vision[C]//Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2016:2818-2826.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" WILSON D R, MARTINEZ T R.The general inefficiency of batch training for gradient descent learning[J].Neural Networks, 2003, 16 (10) :1429-1451." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300070125&amp;v=MzA5MzQwVmFCTT1OaWZPZmJLN0h0RE9ySTlGWk93UERYNDhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMbklKVg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         WILSON D R, MARTINEZ T R.The general inefficiency of batch training for gradient descent learning[J].Neural Networks, 2003, 16 (10) :1429-1451.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" ZINKEVICH M, WEIMER M, SMOLA A J, et al.Parallelized stochastic gradient descent[EB/OL].[2017-12-25].http://martin.zinkevich.org/publica tions/nips20 10.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Parallelized stochastic gradient descent">
                                        <b>[11]</b>
                                         ZINKEVICH M, WEIMER M, SMOLA A J, et al.Parallelized stochastic gradient descent[EB/OL].[2017-12-25].http://martin.zinkevich.org/publica tions/nips20 10.pdf.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" KONECNY J, LIU Jie, RICHTARIK P, et al.Mini-batch semi-stochastic gradient descent in the proximal setting[J].IEEE Journal of Selected Topics in Signal Processing, 2016, 10 (2) :242-255." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mini-batch semi-stochastic gradient descent in the proximal setting">
                                        <b>[12]</b>
                                         KONECNY J, LIU Jie, RICHTARIK P, et al.Mini-batch semi-stochastic gradient descent in the proximal setting[J].IEEE Journal of Selected Topics in Signal Processing, 2016, 10 (2) :242-255.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" 刘立峰, 武奇生, 姚博彬.基于高斯尺度空间和SVM的桥梁裂缝检测研究[J].工业仪表与自动化装置, 2019 (1) :13-16, 114." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GYZD201901003&amp;v=MTg2NTJGeTNtVXIzSklqVFJhckc0SDlqTXJvOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm8=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         刘立峰, 武奇生, 姚博彬.基于高斯尺度空间和SVM的桥梁裂缝检测研究[J].工业仪表与自动化装置, 2019 (1) :13-16, 114.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" 胡翩翩, 曾碧卿.基于HS-BP神经网络的认知无线电频谱预测技术[J].计算机工程, 2017, 43 (7) :146-150, 155." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201707025&amp;v=MDgwMTE0TzN6cXFCdEdGckNVUkxPZVplUm9GeTNtVXIzSkx6N0JiYkc0SDliTXFJOUhZWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         胡翩翩, 曾碧卿.基于HS-BP神经网络的认知无线电频谱预测技术[J].计算机工程, 2017, 43 (7) :146-150, 155.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 邹冲, 蔡敦波, 赵娜, 等.基于SVM-LeNet模型融合的行人检测算法[J].计算机工程, 2017, 43 (5) :170-173." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201705028&amp;v=MDc5MTBSb0Z5M21VcjNKTHo3QmJiRzRIOWJNcW85SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         邹冲, 蔡敦波, 赵娜, 等.基于SVM-LeNet模型融合的行人检测算法[J].计算机工程, 2017, 43 (5) :170-173.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(05),182-186 DOI:10.19678/j.issn.1000-3428.0050060            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于改进CNN的铝轮毂背腔字符识别</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A8%8B%E6%B7%91%E7%BA%A2&amp;code=09314063&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">程淑红</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E6%96%8C&amp;code=17179528&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周斌</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%87%95%E5%B1%B1%E5%A4%A7%E5%AD%A6%E7%94%B5%E6%B0%94%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0022354&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">燕山大学电气工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>铝轮毂背腔字符分辨率较低、背景噪声较大, 对其进行识别时不易提取几何特征和纹理特征。为此, 提出一种基于改进卷积神经网络 (CNN) 的字符识别方法。在原始CNN的基础上引入改进的inception结构对网络构架进行优化, 以提升计算资源的利用率, 并在保持网络计算资源不变的前提下增加网络的宽度和深度, 降低字符识别时间。实验结果表明, 该方法训练准确率达99%以上, 识别准确率达98.5%, 识别效果优于支持向量机、BP神经网络等方法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=inception%E7%BB%93%E6%9E%84&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">inception结构;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BD%91%E7%BB%9C%E6%9E%84%E6%9E%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">网络构架;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%8C%E8%85%94%E5%AD%97%E7%AC%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">背腔字符;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">损失函数优化;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    程淑红 (1978—) , 女, 教授、博士, 主研方向为视觉检测、图像处理、水质监测;;
                                </span>
                                <span>
                                    *周斌 (通信作者) , 硕士研究生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61601400);</span>
                                <span>河北省博士后择优项目 (B2016003027);</span>
                    </p>
            </div>
                    <h1><b>Recognition of Characters in Aluminum Wheel Back Cavity Based on Improved Convolution Neural Network</b></h1>
                    <h2>
                    <span>CHENG Shuhong</span>
                    <span>ZHOU Bin</span>
            </h2>
                    <h2>
                    <span>School of Electrical Engineering, Yanshan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>It is difficult to extract geometric and texture features when recognizing the characters in the aluminium wheel back cavity because of its low resolution and strong background noise.Therefore, a character recognition method based on improved Convolution Neural Network (CNN) is proposed.On the basis of the original CNN, an improved inception structure is introduced to optimize the network architecture to improve the utilization of computing resources, increase the width and depth of the network and reduce the time of character recognition while keeping the network computing resources unchanged.Experimental results show that the training accuracy of this method is over 99% and the recognition accuracy is 98.5%, which is better than that of Support Vector Machine (SVM) and BP neural network.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolution%20Neural%20Network%20(CNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolution Neural Network (CNN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=inception%20structure&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">inception structure;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=network%20architecture&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">network architecture;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=back%20cavity%20character&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">back cavity character;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=optimization%20of%20loss%20function&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">optimization of loss function;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-10</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="34">目标识别是图像处理中重要的组成部分, 也是其主要的结果输出<citation id="109" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。在目标识别中, 字符识别占据很大比例。随着社会的日益发展, 新鲜事物层出不穷, 需要应用目标识别技术的领域逐渐扩展, 且应用的层次逐渐加深, 应用的场景趋于复杂化。因此, 简单的识别方法 (如模板匹配) 已无法满足目标识别的要求, 这对识别技术提出了新的挑战。基于此, 机器学习应运而生。文献<citation id="110" type="reference">[<a class="sup">2</a>]</citation>提出一种基于支持向量机 (Support Vector Machine, SVM) 分类的高效混合图像去噪方法。在该方法中, 输入噪声图像首先被划分成大量重叠的补丁, 然后根据尺度不变特征从每个补丁中提取局部特征, 用SVM分类后进行2种去噪, 最后再将2种去噪进行混合。该方法能够取得较好的去噪效果, 但耗时较多且特征提取较麻烦。为解决该问题, 研究人员开始致力于研究更便捷、智能的机器学习方法, 即人工神经网络和深度学习<citation id="111" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。文献<citation id="112" type="reference">[<a class="sup">4</a>]</citation>提出一种多层人工神经网络LeNet-5, 并利用反向传播算法对其进行训练。在此之后, 神经网络得到迅速发展。文献<citation id="113" type="reference">[<a class="sup">5</a>]</citation>提出一种深度卷积神经网络 (Convolution Neural Network, CNN) AlexNet, 其在LeNet的基础上调整网络架构并加深网络深度。AlexNet在2012年的ImageNet大赛上以明显优势夺得冠军。文献<citation id="114" type="reference">[<a class="sup">6</a>]</citation>提出一种针对图像分类的卷积神经网络google Net, 并建立inception结构, 其使用1×1、3×3和5×5的卷积核代替7×7的卷积核, 实验结果验证了该方法优异的分类性能。</p>
                </div>
                <div class="p1">
                    <p id="35">本文基于改进的inception结构建立一种卷积神经网络, 通过提取卷积特征对铝轮毂背腔字符进行分类识别, 以降低图片的低分辨率对识别结果的影响, 提高分类识别的精确度。</p>
                </div>
                <h3 id="36" name="36" class="anchor-tag">1 卷积神经网络</h3>
                <div class="p1">
                    <p id="37">CNN的基本结构主要包括2层<citation id="115" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="38">1) 卷积层。使用设计好的卷积核对图片进行卷积, 将卷积值加权并增加偏置, 再通过一个激活函数得到卷积层。</p>
                </div>
                <div class="p1">
                    <p id="39">2) 池化层, 也称下采样层。利用图像的局部相关性原理对图像进行自抽样, 从而降低数据处理量并保留有用信息。</p>
                </div>
                <div class="p1">
                    <p id="40">除上述2层外, CNN还包括全连接层和softmax分类层。这种网络结构能够降低反馈神经网络的复杂性, 因此, CNN得到了越来越多的关注。</p>
                </div>
                <h4 class="anchor-tag" id="41" name="41">1.1 卷积层</h4>
                <div class="p1">
                    <p id="42">卷积层操作即局部特征的提取过程。卷积层中含有多个卷积核, 卷积核对上一层特征图进行卷积以提取卷积特征, 同一个卷积核的权值共享, 不同的卷积核权值不同, 提取的特征也不同。卷积层计算公式如式 (1) 所示。</p>
                </div>
                <div class="p1">
                    <p id="43" class="code-formula">
                        <mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msubsup><mrow></mrow><mi>j</mi><mi>l</mi></msubsup><mo>=</mo><mi>f</mi><mtext> </mtext><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Μ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><mi>X</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mrow><mi>l</mi><mo>-</mo><mn>1</mn></mrow></msubsup><mo>*</mo><mi>k</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>l</mi></msubsup><mo>+</mo><mi>b</mi><msubsup><mrow></mrow><mi>j</mi><mi>l</mi></msubsup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="44">其中, <i>l</i>表示层数, <i>i</i>、 <i>j</i>表示特征图标签, <i>M</i><sub><i>j</i></sub>表示输入层的感受野, <i>X</i>表示特征图, <i>k</i>表示卷积核, <i>b</i>表示输出图的偏置。卷积层操作示意图如图1所示。</p>
                </div>
                <div class="area_img" id="45">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905029_045.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 卷积层操作示意图" src="Detail/GetImg?filename=images/JSJC201905029_045.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 卷积层操作示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905029_045.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="46" name="46">1.2 池化层</h4>
                <div class="p1">
                    <p id="47">在CNN的卷积过程中, 往往会因为卷积层的增加而导致数据处理量暴增, 这将大幅增加数据处理的难度和时间。为降低特征图分辨率, 减少特征维度, 本文在卷积层后增加一个池化层。输入的特征图在经过池化层后个数不变, 当池化层尺寸为<i>n</i>时, 输出的特征图是输入特征图的1/<i>n</i>。池化层计算公式如式 (2) 所示。</p>
                </div>
                <div class="p1">
                    <p id="48"><i>X</i><mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>l</mi></msubsup></mrow></math></mathml>=<i>f</i> (<i>β</i><sup><i>l</i></sup><sub><i>k</i></sub><i>down</i> (<i>X</i><mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mrow><mi>l</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>) +<i>b</i><mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>l</mi></msubsup></mrow></math></mathml>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="52">其中, <i>down</i> () 表示池化函数, <i>β</i>表示权重系数。最常见的池化方法有2种:平均值池化和最大值池化, 本文使用最大值池化。池化层操作示意图如图2所示。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905029_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 池化层操作示意图" src="Detail/GetImg?filename=images/JSJC201905029_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 池化层操作示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905029_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="54" name="54">1.3 反向传播</h4>
                <div class="p1">
                    <p id="55">反向传播是神经网络有监督学习中的一种常用方法, 其目的是不断更新卷积核权值, 使该值朝着有利于分类的方向变化<citation id="116" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。反向传播主要基于梯度下降法向训练误差减小的方向调整。误差平方和损失函数计算公式如式 (3) 所示。</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mtext> </mtext><msup><mrow></mrow><mi>Ν</mi></msup><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow></mrow></mstyle></mrow><mtext> </mtext><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>c</mi></munderover><mrow></mrow></mstyle></mrow><mo stretchy="false"> (</mo><mi>t</mi><msubsup><mrow></mrow><mi>k</mi><mi>n</mi></msubsup><mo>-</mo><mi>y</mi><msubsup><mrow></mrow><mi>k</mi><mi>n</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">其中, <i>N</i>表示样本数量, <i>c</i>表示类别数量, <i>E</i><sup><i>N</i></sup>表示样本总误差, <i>t</i><mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>n</mi></msubsup></mrow></math></mathml>表示与第n个样本相对应的第k维标签, y<mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>n</mi></msubsup></mrow></math></mathml>表示第n个样本对应输出中预测的第k个输出。</p>
                </div>
                <h3 id="60" name="60" class="anchor-tag">2 改进的卷积神经网络</h3>
                <h4 class="anchor-tag" id="61" name="61">2.1 改进的inception结构</h4>
                <div class="p1">
                    <p id="62">本文引入inception卷积层结构对整个CNN进行优化。inception的核心思想是使用局部最优的稀疏结构取代原有的全连接方式, 使用多层感知器对局部感知域进行计算, 以最大程度地避免冗余, 最终加快训练速度。原始inception结构如图3所示, 其采用1×1、3×3和5×5的卷积核以及3×3的最大池化来提取上一层的卷积特征, 这种结构的每个单元都单独接受上一层的输出为输入, 5×5的卷积核每次需要处理的数据量为5×5=25, 因此, 其完成整幅图片的卷积操作时计算量非常大。</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905029_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 原始inception结构" src="Detail/GetImg?filename=images/JSJC201905029_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 原始inception结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905029_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="64">为解决上述问题, 研究人员根据“network in network”的思想将输入的特征量进行拼接操作, 利用其非线性特性进行再取样和滤波, 并尝试将<i>n</i>×<i>n</i>的卷积核拆分成1×<i>n</i>和<i>n</i>×1的卷积核, 从而设计出适应于低分辨率图片的更小量级的inception网络结构<citation id="117" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。将5×5的卷积核拆分成2个3×3的卷积核, 其计算量为3×3+3×3=18, 计算消耗降低了1-18/25=28%;再将3×3的卷积核拆分成2个1×3和3×1的卷积核, 其计算量为3+3=6, 计算性能可以再次提升1-6/9≈33%。因此, 小卷积核结构能够大幅降低数据处理量, 减少训练时间。小卷积核inception网络结构如图4所示。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905029_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 小卷积核inception结构" src="Detail/GetImg?filename=images/JSJC201905029_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 小卷积核inception结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905029_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="66">若特征数据的输入尺寸为28×28×256, 共含96个5×5卷积核, 在卷积核前加入64个1×1卷积核, 则卷积核拆分后的运算复杂度如下:</p>
                </div>
                <div class="p1">
                    <p id="67">5×5卷积核为28<sup>2</sup>×1<sup>2</sup>×256×64+28<sup>2</sup>×5<sup>2</sup>×64×96≈1.3×10<sup>8</sup>。</p>
                </div>
                <div class="p1">
                    <p id="68">3×3卷积核为28<sup>2</sup>×1<sup>2</sup>×256×64+28<sup>2</sup>×3<sup>2</sup>×64×96×2≈1.0×10<sup>8</sup>。</p>
                </div>
                <div class="p1">
                    <p id="69">1×3和3×1卷积核为28<sup>2</sup>×1<sup>2</sup>×256×64+28<sup>2</sup>×3×64×96×2×2≈0.7×10<sup>8</sup>。</p>
                </div>
                <div class="p1">
                    <p id="70">因为铝轮毂背腔字符分辨率较低, 且小卷积核inception结构对数据的处理能力优于原始inception结构, 所以本文选用图4所示的inception结构设计CNN, 如图5所示。</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905029_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 基于小卷积核inception结构的CNN" src="Detail/GetImg?filename=images/JSJC201905029_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 基于小卷积核inception结构的CNN</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905029_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="72">改进后的inception结构具有良好的特征抽取能力, 可以将字符图像的特征信息抽取为数字特征, 并实现多分类, 最终识别出不同的字符。本文CNN网络结构参数如表1所示。</p>
                </div>
                <div class="area_img" id="73">
                    <p class="img_tit"><b>表1 网络结构参数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="73" border="1"><tr><td><br />类型</td><td>卷积核尺寸/步长</td><td>输入尺寸</td><td>注释</td></tr><tr><td><br />卷积</td><td>3×3/2</td><td>299×299×3</td><td>—</td></tr><tr><td><br />卷积</td><td>3×3/1</td><td>149×149×32</td><td>—</td></tr><tr><td><br />卷积</td><td>3×3/1</td><td>147×147×32</td><td>—</td></tr><tr><td><br />池化</td><td>3×3/2</td><td>147×147×64</td><td>—</td></tr><tr><td><br />卷积</td><td>3×3/1</td><td>73×73×64</td><td>—</td></tr><tr><td><br />卷积</td><td>3×3/2</td><td>71×71×80</td><td>—</td></tr><tr><td><br />卷积</td><td>3×3/1</td><td>35×35×192</td><td>—</td></tr><tr><td><br />inception模块</td><td>—</td><td>35×35×288</td><td>3组</td></tr><tr><td><br />inception模块</td><td>—</td><td>17×17×768</td><td>5组</td></tr><tr><td><br />inception模块</td><td>—</td><td>8×8×128</td><td>3组</td></tr><tr><td><br />池化</td><td>8×8/1</td><td>8×8×2 048</td><td>—</td></tr><tr><td><br />线性</td><td>—</td><td>1×1×2 048</td><td>概率</td></tr><tr><td><br />Softmax</td><td>—</td><td>1×1×1 000</td><td>分类输出</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="74" name="74">2.2 损失函数的最优选择</h4>
                <div class="p1">
                    <p id="75">目前, 在损失函数优化方面, 常用方法有批量梯度下降法 (Batch Gradient Descent, BGD) <citation id="118" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、随机梯度下降法 (Stochastic Gradient Descent, SGD) <citation id="119" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>等。这些方法一般将线性回归函数假设如下:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><msub><mrow></mrow><mi>θ</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mi>θ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77"><i>θ</i><sub><i>i</i></sub>:<mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mi>θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>α</mi><mfrac><mrow><mo>∂</mo><mtext> </mtext></mrow><mrow><mo>∂</mo><mtext> </mtext><mi>θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mi>J</mi><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="79">其中, <i>x</i><sub><i>i</i></sub>表示样本特征<i>x</i>的第<i>i</i>个元素, <i>θ</i><sub><i>i</i></sub>表示权重参数, <i>α</i>表示步长, 用于控制<i>θ</i>每次向使损失函数<i>J</i> (<i>θ</i>) 变小方向迭代时的变化幅度。对于BGD方法而言, 其对应的损失函数如式 (5) 所示。</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>m</mi></mrow></mfrac><mtext> </mtext><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false">[</mo></mstyle><mi>h</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">其中, <i>h</i><sub><i>θ</i></sub> (<i>x</i><sub><i>i</i></sub>) 为假设函数, <i>y</i><sub><i>i</i></sub>为样本输出<i>y</i>的第<i>i</i>个元素, <i>m</i>为样本数目。</p>
                </div>
                <div class="p1">
                    <p id="82">对<i>θ</i><sub><i>j</i></sub>求导可得:</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mo>∂</mo><mtext> </mtext><mi>J</mi><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo></mrow><mrow><mo>∂</mo><mtext> </mtext><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mtext> </mtext><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow></mrow></mstyle></mrow><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>h</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mi>x</mi><mtext> </mtext><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><msup><mi>θ</mi><mo>′</mo></msup><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mi>θ</mi><msub><mrow></mrow><mi>j</mi></msub><mo>+</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mtext> </mtext><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow></mrow></mstyle></mrow><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>h</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mi>x</mi><mtext> </mtext><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">SGD方法对应的损失函数如式 (8) 所示。</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><msub><mrow></mrow><mi>θ</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mtext> </mtext><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></mstyle><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>h</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mtext> </mtext><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow></mrow></mstyle></mrow><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi><mtext> </mtext><mo stretchy="false"> (</mo><mi>θ</mi><mo>, </mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中, <i>cost</i> (<i>θ</i>, (<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>) ) 表示每个样本的损失函数。</p>
                </div>
                <div class="p1">
                    <p id="87">BGD方法在更新每一个参数时都使用到所有的样本, 其优点是可以找到全局最优解, 缺点是数据量庞大, 易导致训练速度减慢。SGD方法通过部分样本进行迭代更新, 但是其噪音较多, 使得该方法每次迭代的优化方向不确定。因此, 本文在上述2种方法的基础上, 实现一种小批量梯度下降法<citation id="120" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。该方法随机选取一定数量的样本进行更新, 其设计思想是初始化参数值并迭代更新这些参数使目标函数不断变小, 即在训练过程中, 使用验证集周期性地测试效果, 如果效果较好, 将其保存起来, 如果多次迭代后分类效果几乎没有提升, 则停止迭代。</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="89" name="89">3.1 实验样本采集</h4>
                <div class="p1">
                    <p id="90">本文实验样本取自环形光源照射下的铝轮毂背腔图片, 通过对原始图片进行预处理、区域定位以及字符分割后, 得到需要识别的样本字符, 如图6所示。</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905029_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 实验样本图片" src="Detail/GetImg?filename=images/JSJC201905029_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 实验样本图片</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905029_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="92" name="92">3.2 字符识别</h4>
                <div class="p1">
                    <p id="93">本文采集11 050幅字符图片作为训练样本, 5 300幅字符图片作为测试样本。网络训练次数为5 000, 最终训练准确率达100%, 验证准确率达97%, 测试准确率达98.5%, 交叉熵为0.005。图7所示为本文方法的训练准确率与训练损失率的对比关系。</p>
                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905029_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 训练过程中的2种参数变化情况" src="Detail/GetImg?filename=images/JSJC201905029_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 训练过程中的2种参数变化情况</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905029_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="95">由图7可以看出, 本文神经网络训练效果较好, 在训练次数约为1 000时, 训练准确率和损失率基本达到较好的水平, 且该训练结果基本保持稳定直至训练完成。</p>
                </div>
                <div class="p1">
                    <p id="96">本文用置信度来表示字符的分类识别结果, 置信度越大, 说明待检测字符越接近分类目标。在本次实验中, 每类字符的2组分类识别置信度统计结果如图8所示。由图8可以看出, 每组字符的分类置信度最大值选项都为待检测字符的真值, 虽然某些字符干扰项与真值相差不大, 但仍然能够将两者区分开。因此, 在进行字符识别时选取置信度最大的分类选项, 能够提高字符识别的准确率。</p>
                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905029_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 字符分类识别结果" src="Detail/GetImg?filename=images/JSJC201905029_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图8 字符分类识别结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905029_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="98">此外, 本文还对具有不同倾斜角度的字符以及存在部分遮挡的字符进行识别, 结果如图9、图10所示。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905029_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 倾斜字符识别结果" src="Detail/GetImg?filename=images/JSJC201905029_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图9 倾斜字符识别结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905029_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905029_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 被遮挡字符识别结果" src="Detail/GetImg?filename=images/JSJC201905029_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图10 被遮挡字符识别结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905029_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="101">在图9中, 包括有一定倾斜角度的图片和倒置的图片。由图9可以看出, 具有一定倾斜角度字符的识别置信度都大于0.9, 识别效果非常好, 而倒置图片的置信度存在小于0.9的值, 尽管如此, 但是大部分字符的识别置信度与其他字符相比相差较大, 因此, 大部分字符仍能够被正确地识别出。其中, 倒置字符识别准确率较低的是“6”和“9”, 因为标准印刷体字符的“6”和“9”在倒置之后与另一个数字相同, 所以在倒置识别中会出现混淆的情况。但是, 本文方法在进行字符分割时会考虑这种情况, 即在分割时会矫正偏差较大的字符, 因此, 在正常的字符识别中, 不会出现“6”和“9”混淆的情形。</p>
                </div>
                <div class="p1">
                    <p id="102">由图10可以看出, 运用本文方法时, 被遮挡字符的识别置信度虽然没有正常字符高, 但是其中每个字符仍然能够被准确地识别出来。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103">3.3 对比分析</h4>
                <div class="p1">
                    <p id="104">为进一步分析各方法的分类性能, 使用SVM<citation id="121" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、BP神经网络<citation id="122" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、LeNet-5卷积神经网络<citation id="123" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>以及本文方法进行字符识别对比实验, 结果如表2所示。其中, 训练时间表示每张图片的计算时间。</p>
                </div>
                <div class="area_img" id="105">
                    <p class="img_tit"><b>表2 不同方法字符识别性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="105" border="1"><tr><td><br />方法</td><td>训练时间/s</td><td>识别时间/s</td><td>识别准确率/%</td></tr><tr><td><br />SVM</td><td>0.01</td><td>0.023</td><td>90.65</td></tr><tr><td><br />BP神经网络</td><td>0.04</td><td>0.011</td><td>91.20</td></tr><tr><td><br />LeNet-5</td><td>0.11</td><td>0.080</td><td>95.70</td></tr><tr><td><br />本文方法</td><td>1.80</td><td>0.800</td><td>98.50</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="106">从表2可以看出, 本文方法虽然时间消耗较高, 但是其识别准确率具有较大优势, 即更加适合于铝轮毂背腔字符的识别。</p>
                </div>
                <h3 id="107" name="107" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="108">本文使用改进的inception结构构建一种卷积神经网络, 通过提取卷积特征解决铝轮毂背腔字符分辨率低、背景噪声大等问题, 最终完成该类字符的分类识别。实验结果验证了该网络结构在铝轮毂背腔字符识别领域的可行性与有效性。但是, 在本文分类实验中还存在个别字符分类置信度较低的情况, 解决该问题将是下一步的研究方向。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QBZH201901001&amp;v=MjE1MTlHRnJDVVJMT2VaZVJvRnkzbVVyM0pOQy9SWnJHNEg5ak1ybzlGWllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 单连平, 窦强.基于深度学习的海战场图像目标识别[J].指挥控制与仿真, 2019 (1) :1-5.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9A6448A7C7BB2056C6002C568DD8933D&amp;v=MDg4NTQ0NXloQmc3RDk5U2d6bnFocEJEYnFkUnJuckNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU41aHdidSt3cWs9TmlmT2ZickpHTlhJcC81Q0YreDlmbg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> ROUTRAY S, RAY A K, MISHRA C, et al.Efficient hybrid image denoising scheme based on SVM classification[J].Optik, 2018, 157:503-511.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201409012&amp;v=MDM4ODBGckNVUkxPZVplUm9GeTNtVXIzSlBEelRiTEc0SDlYTXBvOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 余永维, 殷国富, 殷鹰, 等.基于深度学习网络的射线图像缺陷识别方法[J].仪器仪表学报, 2014, 35 (9) :2012-2018.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gradient-based learning applied to document recognition">

                                <b>[4]</b> LECUN Y, BOTTOU L, BENGIO Y, et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">

                                <b>[5]</b> KRIZHEVSKY A, SUTSKEVER I, HINTON G E.ImageNet classification with deep convolutional neural networks[C]//Proceedings of the 25th International Conference on Neural Information Processing Systems.New York, USA:ACM Press, 2012:1097-1105.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">

                                <b>[6]</b> SZEGEDY C, LIU Wei, JIA Yangqing, et al.Going deeper with convolutions[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:1-9.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Receptive fields, binocular interaction and functional architecture in the cat&amp;#39;s visual cortex">

                                <b>[7]</b> HUBEL D H, WIESEL T N.Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex[J].The Journal of Physiology, 1962, 160 (1) :106-154.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGJL201702015&amp;v=MDY3NjRSTE9lWmVSb0Z5M21VcjNKUHlyQllyRzRIOWJNclk5RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 肖志鹏, 王小华, 杨冰, 等.基于卷积神经网络的绘画图像分类研究[J].中国计量大学学报, 2017, 28 (2) :227-232.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rethinking the Inception Architecture for Computer Vision">

                                <b>[9]</b> SZEGEDY C, VANHOUCKE V, IOFFE S, et al.Rethinking the inception architecture for computer vision[C]//Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2016:2818-2826.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300070125&amp;v=MTQ2OTNiSzdIdERPckk5RlpPd1BEWDQ4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTG5JSlYwVmFCTT1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> WILSON D R, MARTINEZ T R.The general inefficiency of batch training for gradient descent learning[J].Neural Networks, 2003, 16 (10) :1429-1451.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Parallelized stochastic gradient descent">

                                <b>[11]</b> ZINKEVICH M, WEIMER M, SMOLA A J, et al.Parallelized stochastic gradient descent[EB/OL].[2017-12-25].http://martin.zinkevich.org/publica tions/nips20 10.pdf.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mini-batch semi-stochastic gradient descent in the proximal setting">

                                <b>[12]</b> KONECNY J, LIU Jie, RICHTARIK P, et al.Mini-batch semi-stochastic gradient descent in the proximal setting[J].IEEE Journal of Selected Topics in Signal Processing, 2016, 10 (2) :242-255.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GYZD201901003&amp;v=MTYxNThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkzbVVyM0pJalRSYXJHNEg5ak1ybzlGWjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 刘立峰, 武奇生, 姚博彬.基于高斯尺度空间和SVM的桥梁裂缝检测研究[J].工业仪表与自动化装置, 2019 (1) :13-16, 114.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201707025&amp;v=MjIzMzBiTXFJOUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTNtVXIzSkx6N0JiYkc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 胡翩翩, 曾碧卿.基于HS-BP神经网络的认知无线电频谱预测技术[J].计算机工程, 2017, 43 (7) :146-150, 155.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201705028&amp;v=MjQ0NDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5M21VcjNKTHo3QmJiRzRIOWJNcW85SGJJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 邹冲, 蔡敦波, 赵娜, 等.基于SVM-LeNet模型融合的行人检测算法[J].计算机工程, 2017, 43 (5) :170-173.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201905029" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201905029&amp;v=MjY3MTJxbzlIYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkzbVVyM0pMejdCYmJHNEg5ak0=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
