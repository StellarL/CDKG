<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637128892888738750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201908014%26RESULT%3d1%26SIGN%3dbu3LHKD3mF%252bVKde4Krf%252fha0r%252b64%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201908014&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201908014&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201908014&amp;v=MDcwMjk5ak1wNDlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRnkvZ1c3ck9MejdCYmJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#50" data-title="2 数据处理过程 ">2 数据处理过程</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="2.1 数据标准化">2.1 数据标准化</a></li>
                                                <li><a href="#64" data-title="2.2 特征选择">2.2 特征选择</a></li>
                                                <li><a href="#68" data-title="2.3 数据分类">2.3 数据分类</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#71" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#72" data-title="3.1 数据集">3.1 数据集</a></li>
                                                <li><a href="#74" data-title="3.2 实验过程">3.2 实验过程</a></li>
                                                <li><a href="#87" data-title="3.3 实验结果">3.3 实验结果</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="&lt;b&gt;图1 软件缺陷报告严重性预测流程&lt;/b&gt;"><b>图1 软件缺陷报告严重性预测流程</b></a></li>
                                                <li><a href="#90" data-title="&lt;b&gt;表1 不同向量化特征表示方法的预测效果比较&lt;/b&gt;"><b>表1 不同向量化特征表示方法的预测效果比较</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;图2 不同向量化特征表示方法的AUROC结果&lt;/b&gt;"><b>图2 不同向量化特征表示方法的AUROC结果</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;表2 不同向量化特征表示方法对应不同分类算法的预测结果比较&lt;/b&gt;"><b>表2 不同向量化特征表示方法对应不同分类算法的预测结果比较</b></a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;表3 Eclipse项目特征词IG评分前20名的结果&lt;/b&gt;"><b>表3 Eclipse项目特征词IG评分前20名的结果</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;图3 IG选择不同特征数量对应的AUROC结果&lt;/b&gt;"><b>图3 IG选择不同特征数量对应的AUROC结果</b></a></li>
                                                <li><a href="#102" data-title="&lt;b&gt;图4 IG和CHI选择不同特征数量对应的AUROC结果&lt;/b&gt;"><b>图4 IG和CHI选择不同特征数量对应的AUROC结果</b></a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;表4 不同T01系数对严重性预测结果的影响&lt;/b&gt;"><b>表4 不同T01系数对严重性预测结果的影响</b></a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;图5 使用LDA处理的数据在MNB算法中的分类效果&lt;/b&gt;"><b>图5 使用LDA处理的数据在MNB算法中的分类效果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="131">


                                    <a id="bibliography_1" title=" NI Chao, LIU Wangshu, CHEN Xiang, et al.A cluster based feature selection method for cross-project software defect prediction[J].Journal of Computer Science and Technology, 2017, 32 (6) :1090-1107." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD3E8C6DBA968466ABBB43BA447BE3409E&amp;v=MTU0OThHUVJiUHFDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOeGh3NzIzeGE0PU5qN0JhckRORnFMSzIvMDBiZTBIQ0hvL3ZtUmhtRHQrT2c3bXFCVkhETA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         NI Chao, LIU Wangshu, CHEN Xiang, et al.A cluster based feature selection method for cross-project software defect prediction[J].Journal of Computer Science and Technology, 2017, 32 (6) :1090-1107.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_2" title=" RYU D, JIANG J I, BAIK J.A hybrid instance selection using nearest-neighbor for cross-project defect prediction[J].Journal of Computer Science and Technology, 2015, 30 (5) :969-980." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A hybrid instance selection using nearest-neighbor for cross-project defect prediction">
                                        <b>[2]</b>
                                         RYU D, JIANG J I, BAIK J.A hybrid instance selection using nearest-neighbor for cross-project defect prediction[J].Journal of Computer Science and Technology, 2015, 30 (5) :969-980.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_3" title=" XUAN Jifeng, JIANG He, REN Zhiwei, et al.Automatic BUG triage using semi-supervised text classifica-tion[C]//Proceedings of the 22nd International Conference on Software Engineering and Knowledge Engineering.Washington D.C., USA:IEEE Press, 2010:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic Bug Triage using Semi-Supervised Text Classification">
                                        <b>[3]</b>
                                         XUAN Jifeng, JIANG He, REN Zhiwei, et al.Automatic BUG triage using semi-supervised text classifica-tion[C]//Proceedings of the 22nd International Conference on Software Engineering and Knowledge Engineering.Washington D.C., USA:IEEE Press, 2010:1-9.
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_4" title=" LAWRENCE F L, SHARMA S K, SISODIA M S.Network intrusion detection by using feature reduction technique[J].International Journal of Advanced Research in Computer Science and Electronics Engineering, 2012, 1 (1) :27-32." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Network Intrusion detection by using Feature Reduction Technique">
                                        <b>[4]</b>
                                         LAWRENCE F L, SHARMA S K, SISODIA M S.Network intrusion detection by using feature reduction technique[J].International Journal of Advanced Research in Computer Science and Electronics Engineering, 2012, 1 (1) :27-32.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_5" title=" STRATE J D, LAPLANTE P A.A literature review of research in software defect reporting[J].IEEE Transactions on Reliability, 2013, 62 (2) :444-454." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Literature Review of Research in Software Defect Reporting">
                                        <b>[5]</b>
                                         STRATE J D, LAPLANTE P A.A literature review of research in software defect reporting[J].IEEE Transactions on Reliability, 2013, 62 (2) :444-454.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_6" title=" WANG Jie, PLATANIOTIS K, LU J, et al.Kernel quadratic discriminant analysis for small sample size problem[J].Pattern Recognition, 2008, 41 (5) :1528-1538." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738969&amp;v=MTE2MDFycVFUTW53WmVadUh5am1VTHZJSjFzY2J4UT1OaWZPZmJLN0h0RE5xWTlGWStnSEJYb3dvQk1UNlQ0UFFIL2lyUmRHZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         WANG Jie, PLATANIOTIS K, LU J, et al.Kernel quadratic discriminant analysis for small sample size problem[J].Pattern Recognition, 2008, 41 (5) :1528-1538.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_7" title=" MATTER D, KUHN A, NIERSTRASZ O.Assigning BUG reports using a vocabulary-based expertise model of developers[C]//Proceedings of the 6th IEEE International Working Conference on Mining Software Repositories.Washington D.C., USA:IEEE Press, 2009:131-140." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Assigning bug reports using a vocabulary-based expertise model of developers">
                                        <b>[7]</b>
                                         MATTER D, KUHN A, NIERSTRASZ O.Assigning BUG reports using a vocabulary-based expertise model of developers[C]//Proceedings of the 6th IEEE International Working Conference on Mining Software Repositories.Washington D.C., USA:IEEE Press, 2009:131-140.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_8" title=" ZIOU D, HAMRI T, BOUTEMEDJET S.A hybrid probabilistic framework for content-based image retrieval with feature weighting[J].Pattern Recognition, 2009, 42 (7) :1511-1519." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738881&amp;v=MDE2ODlMdklKMXNjYnhRPU5pZk9mYks3SHRETnFZOUZZK2dIQkhRNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         ZIOU D, HAMRI T, BOUTEMEDJET S.A hybrid probabilistic framework for content-based image retrieval with feature weighting[J].Pattern Recognition, 2009, 42 (7) :1511-1519.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_9" title=" MENZIES T, MARCUS A.Automated severity assessment of software defect reports[C]//Proceedings of IEEE International Conference on Software.New York, USA:ACM Press, 2015:1-12." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automated severity assessment of software defect reports">
                                        <b>[9]</b>
                                         MENZIES T, MARCUS A.Automated severity assessment of software defect reports[C]//Proceedings of IEEE International Conference on Software.New York, USA:ACM Press, 2015:1-12.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_10" title=" LAMKAN A, DEMEYER S, SOETENS Q D, et al.Comparing mining algorithms for predicting the severity of a reported BUG[C]//Proceedings of European Conference on Software.New York, USA:ACM Press, 2011:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Comparing mining algorithms for predicting the severity of a reported BUG">
                                        <b>[10]</b>
                                         LAMKAN A, DEMEYER S, SOETENS Q D, et al.Comparing mining algorithms for predicting the severity of a reported BUG[C]//Proceedings of European Conference on Software.New York, USA:ACM Press, 2011:1-8.
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_11" title=" 黄小亮, 郁抒思, 关佶红.基于LDA主题模型的软件缺陷分派方法[J].计算机工程, 2011, 37 (21) :46-48." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201121018&amp;v=MTY1OTlHRnJDVVJMT2VaZVJxRnkvZ1c3ck9MejdCYmJHNEg5RE9ybzlFYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         黄小亮, 郁抒思, 关佶红.基于LDA主题模型的软件缺陷分派方法[J].计算机工程, 2011, 37 (21) :46-48.
                                    </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_12" title=" ZHANG Tao, CHEN Jiachi, YANG G, et al.Towards more accurate severity prediction and fixer recommendation of software BUGs[J].Journal of Systems and Software, 2016, 117 (C) :166-184." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Towards more accurate severity prediction and fixer recommendation of software bugs">
                                        <b>[12]</b>
                                         ZHANG Tao, CHEN Jiachi, YANG G, et al.Towards more accurate severity prediction and fixer recommendation of software BUGs[J].Journal of Systems and Software, 2016, 117 (C) :166-184.
                                    </a>
                                </li>
                                <li id="155">


                                    <a id="bibliography_13" title=" SHOKRIPOUR R, KASIRUN Z M, ZAMANI S, et al.Automatic BUG assignment using information extraction methods[C]//Proceedings of International Conference on Advanced Computer Science Applications and Technologies.Washington D.C., USA:IEEE Press, 2012:144-149." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic Bug Assignment Using Information Extraction Methods">
                                        <b>[13]</b>
                                         SHOKRIPOUR R, KASIRUN Z M, ZAMANI S, et al.Automatic BUG assignment using information extraction methods[C]//Proceedings of International Conference on Advanced Computer Science Applications and Technologies.Washington D.C., USA:IEEE Press, 2012:144-149.
                                    </a>
                                </li>
                                <li id="157">


                                    <a id="bibliography_14" title=" SHOKRIPOUR R, ANVIK J, KASIRUN Z M, et al.Why so complicated?simple term filtering and weighting for location-based BUG report assignment recommendation[C]//Proceedings of the 10th International Workshopon Mining Software Repositories.Washington D.C., USA:IEEE Press, 2013:2-11." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Why so Complicated?Simple Term Filtering and Weighting for Location-based Bug Report Assignment Recommendation">
                                        <b>[14]</b>
                                         SHOKRIPOUR R, ANVIK J, KASIRUN Z M, et al.Why so complicated?simple term filtering and weighting for location-based BUG report assignment recommendation[C]//Proceedings of the 10th International Workshopon Mining Software Repositories.Washington D.C., USA:IEEE Press, 2013:2-11.
                                    </a>
                                </li>
                                <li id="159">


                                    <a id="bibliography_15" title=" LIU Wenjie, WANG Shanshan, CHEN Xin, et al.Predicting the severity of BUG reports based on feature selection[J].International Journal of Software Engineering and Knowledge Engineering, 2018, 28 (4) :537-558." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Predicting the severity of bug reports based on feature selection">
                                        <b>[15]</b>
                                         LIU Wenjie, WANG Shanshan, CHEN Xin, et al.Predicting the severity of BUG reports based on feature selection[J].International Journal of Software Engineering and Knowledge Engineering, 2018, 28 (4) :537-558.
                                    </a>
                                </li>
                                <li id="161">


                                    <a id="bibliography_16" title=" 张肖, 王利明.一种半监督继承学习软件缺陷预测方法[J].小型微型计算机系统, 2018, 39 (10) :2138-2145." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201810003&amp;v=MDk0ODBQVFhjZHJHNEg5bk5yNDlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRnkvZ1c3ck8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         张肖, 王利明.一种半监督继承学习软件缺陷预测方法[J].小型微型计算机系统, 2018, 39 (10) :2138-2145.
                                    </a>
                                </li>
                                <li id="163">


                                    <a id="bibliography_17" title=" 史小婉, 马于涛.一种基于文本分类和评分机制的软件缺陷分配方法[J].计算机科学, 2018, 45 (11) :193-198." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201811032&amp;v=MjA1MjI3QmI3RzRIOW5Ocm85R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5L2dXN3JPTHo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         史小婉, 马于涛.一种基于文本分类和评分机制的软件缺陷分配方法[J].计算机科学, 2018, 45 (11) :193-198.
                                    </a>
                                </li>
                                <li id="165">


                                    <a id="bibliography_18" title=" 任胜兵, 廖湘荡.基于代价敏感支持向量机的软件缺陷预测研究[J].计算机工程与科学, 2018, 40 (10) :1787-1795." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201810011&amp;v=MjIxMDR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRnkvZ1c3ck9MejdCWmJHNEg5bk5yNDlFWllRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         任胜兵, 廖湘荡.基于代价敏感支持向量机的软件缺陷预测研究[J].计算机工程与科学, 2018, 40 (10) :1787-1795.
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_19" title=" 路永和, 李焰锋.改进TF-IDF算法的文本特征项权值计算方法[J].图书情报工作, 2013, 57 (3) :90-95." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TSQB201303018&amp;v=MTY2NDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRnkvZ1c3ck9NVDdhYkxHNEg5TE1ySTlFYklRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         路永和, 李焰锋.改进TF-IDF算法的文本特征项权值计算方法[J].图书情报工作, 2013, 57 (3) :90-95.
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_20" title=" 孙小兵, 周澄, 杨辉, 等.面向软件安全性缺陷的开发者推荐方法[J].软件学报, 2018, 29 (8) :2294-2305." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201808010&amp;v=MDM0ODVMRzRIOW5NcDQ5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5L2dXN3JPTnlmVGI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         孙小兵, 周澄, 杨辉, 等.面向软件安全性缺陷的开发者推荐方法[J].软件学报, 2018, 29 (8) :2294-2305.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(08),80-85 DOI:10.19678/j.issn.1000-3428.0053297            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于特征选择的软件缺陷报告严重性评估</b></span>
 <span class="shoufa"></span>                                     </h1>

                <div class="btn-downloads  btn-downloads-new">

                        <a class="read read-btn-special" target="_blank" href=http://x.cnki.net/search/common/testlunbo?dbcode=CJFD&amp;tablename=CJFDLAST2019&amp;filename=JSJC201908014&amp;filesourcetype=1><i class="i-btn i-care"></i>精读</a>
                    <div class="read-btn-l">
                        <a class="caj" target="_blank" href="http://kns.cnki.net/kns/download.aspx?filename=yNUeaxmbNdnZyJzaVZUUpxGaJVXZRJ1KnpFOJ9mNKdEavU2LMpXMIJGdnhXetN3VzUXMPVFWqVmSi5kdv8UdKNndTdDZ5MzMPFlZxhmYrV2N2MmRVdXbEZUaVV1YZJ3UvwUQrNWMK9ESrVEW5kjMCRTZalFdvsyZ&tablename=CJFDLAST2019"><i class="i-btn i-caj"></i> CAJ下载</a>
                        <a class="pdf" target="_blank" href="http://kns.cnki.net/kns/download.aspx?filename=yNUeaxmbNdnZyJzaVZUUpxGaJVXZRJ1KnpFOJ9mNKdEavU2LMpXMIJGdnhXetN3VzUXMPVFWqVmSi5kdv8UdKNndTdDZ5MzMPFlZxhmYrV2N2MmRVdXbEZUaVV1YZJ3UvwUQrNWMK9ESrVEW5kjMCRTZalFdvsyZ&tablename=CJFDLAST2019&dflag=pdfdown"><i class="i-btn i-pdf"></i>PDF下载</a>

                        <p>永久保存本文,请下载至本地</p>
                    </div>

                </div>
            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E6%96%87%E6%9D%B0&amp;code=11011672&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘文杰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B1%9F%E8%B4%BA&amp;code=06528056&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">江贺</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%A7%E8%BF%9E%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%BD%AF%E4%BB%B6%E5%AD%A6%E9%99%A2&amp;code=0222286&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大连理工大学软件学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对Bugzilla缺陷跟踪系统的Eclipse项目软件缺陷报告数据集, 使用特征选择和机器学习算法对向量化的原始数据进行特征降维、权重优化等处理, 得到数据维度较低的优化数据集, 并采用分类算法评估软件缺陷报告严重程度。通过对4种特征选择算法及4种机器学习算法处理结果的交叉对比表明, 使用信息增益特征选择算法对原始数据集进行特征优化, 并结合多项式贝叶斯算法对优化数据集进行训练与测试, 可使软件缺陷报告严重性预测的AUROC值提高至0.767。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">开源软件;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BD%AF%E4%BB%B6%E7%BC%BA%E9%99%B7%E6%8A%A5%E5%91%8A&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">软件缺陷报告;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征选择;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%A5%E9%87%8D%E6%80%A7%E8%AF%84%E4%BC%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">严重性评估;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BF%AE%E5%A4%8D%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">修复率;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    刘文杰 (1979—) , 男, 工程师、硕士, 主研方向为软件测试、网络工程;E-mail: liuwj@ dlut. edu. cn;
                                </span>
                                <span>
                                    江贺, 教授、博士、博士生导师。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金“超启发式算法的多视角分析及应用研究” (61175062);</span>
                    </p>
            </div>
                    <h1><b>Severity Assessment of Software Defect Reports Based on Feature Selection</b></h1>
                    <h2>
                    <span>LIU Wenjie</span>
                    <span>JIANG He</span>
            </h2>
                    <h2>
                    <span>School of Software Technology, Dalian University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To address the datasets of Eclipse project software defect reports of Bugzilla defect tracking system, feature selection and machine learning algorithms are used to perform feature dimension reduction and weight optimization on vectorized original data to obtain optimized dataset with lower data dimension, and classification algorithms are used to evaluate the severity of software defect reports.The cross-comparison results of the four feature selection algorithms and the four machine learning algorithm results show that the Information Gain (IG) feature selection algorithm is used to perform feature optimization on the original dataset, and the optimized dataset is trained and tested by using the Multinamial Naive Bayes (MNB) algorithm.The AUROC value of the severity prediction of software defect reports can be increased to 0.767.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=opensource%20software&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">opensource software;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=software%20defect%20report&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">software defect report;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20selection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature selection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=severity%20assessment&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">severity assessment;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=repair%20rate&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">repair rate;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-03</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="44">软件缺陷修复是软件版本更新以及软件服务的关键内容, 因此对软件缺陷修复过程的控制成为开源软件面临的主要问题<citation id="171" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。大量软件使用软件缺陷报告跟踪系统进行软件缺陷信息的记录, 通过对软件缺陷报告的分析, 可以直观呈现软件缺陷的产生、修复等过程<citation id="172" type="reference"><link href="133" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="45">在此过程中, 对软件缺陷进行优先级分类, 成为软件缺陷报告研究的重要方向<citation id="173" type="reference"><link href="135" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。一般来说, 优先级主要分为4类:需要尽快恢复, 在下一个产品发布之前修复, 可以延期修复和不需要修复<citation id="174" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。但由于优先级排序过程只能反映当前软件缺陷在当前数据集中的优先级, 因此软件缺陷报告严重性以及严重性评估成为主要的研究方向。该属性是软件缺陷报告的众多属性之一, 会贯穿缺陷报告的生命周期, 准确的软件缺陷报告严重性能够决定该缺陷的修复率、解决时长、持有者等重要属性<citation id="175" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。同时, 该属性也会影响软件缺陷的优先级分类。</p>
                </div>
                <div class="p1">
                    <p id="46">软件缺陷报告严重性程度主要包括blockers、critical、major、normal、minor、trivial、enhancement等级别。其中, blockers、critical、major、normal级别被认为是严重性程度较高的, 对应的缺陷报告被称为severe报告, minor、trivial、enhancement被认为是较低级别, 对应的缺陷报告被称为no-severe报告。对于软件缺陷报告严重性分类方法, 通常会针对解决时长、修复率、持有者等特征进行评价。在缺陷报告评估过程中, 需要针对2类严重性分类进行原始数据的特征优化过程, 实现严重性分类与特征子集的严格匹配, 从而通过机器学习方法, 得到较为准确的预测结果。本文针对Bugzilla缺陷跟踪系统的Eclipse项目的软件缺陷报告数据, 结合机器学习算法和主题模型算法对软件缺陷报告严重程度进行评估。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag">1 相关工作</h3>
                <div class="p1">
                    <p id="48">通过文本分类对软件缺陷报告进行自动分类是相关研究的主要方法。使用分类器对软件缺陷报告的数据进行训练与测试, 在准确率、召回率等方面的性能指标都有待提高<citation id="176" type="reference"><link href="141" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。文献<citation id="177" type="reference">[<a class="sup">7</a>]</citation>基于top-1算法使缺陷预测准确率达到33.6%。文献<citation id="178" type="reference">[<a class="sup">8</a>]</citation>通过词条选择方法进行文本挖掘来解决软件缺陷分类问题。文献<citation id="179" type="reference">[<a class="sup">9</a>]</citation>结合SEVERIS方法与RIPPER方法, 针对缺陷严重性的相关文本数据进行预测。文献<citation id="180" type="reference">[<a class="sup">10</a>]</citation>通过文本挖掘方法对软件缺陷报告的分类问题进行研究, 并对缺陷报告的严重性属性进行分析, 同时对比多个机器学习算法的严重性属性预测准确率, 认为多项式贝叶斯 (Multinomial Naive Bayes, MNB) 算法的效果更好。文献<citation id="181" type="reference">[<a class="sup">11</a>]</citation>通过LDA主题模型的方法, 从软件缺陷类别角度, 对软件缺陷进行分类研究。文献<citation id="182" type="reference">[<a class="sup">12</a>]</citation>利用改进的CP算法以及改进的REP算法, 对软件缺陷报告严重性程度进行预测, 并取得了较好的实验效果。</p>
                </div>
                <div class="p1">
                    <p id="49">本文利用特征选择算法对原始数据集进行特征优化, 并通过主题模型的方法对原始特征子集进行降维处理, 能够有效提高分类学习模型在软件缺陷报告严重性预测过程中的准确率。</p>
                </div>
                <h3 id="50" name="50" class="anchor-tag">2 数据处理过程</h3>
                <h4 class="anchor-tag" id="51" name="51">2.1 数据标准化</h4>
                <div class="p1">
                    <p id="52">在软件缺陷报告数据获取过程中, 原始数据一般都是碎片化的文本数据, 无法直接进行分类处理<citation id="183" type="reference"><link href="155" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。因此, 需要对原始数据进行预处理, 并同时对特征数据优化处理, 从而提高分类准确率。如图1所示, 在此过程需要选择合适的向量化方法、特征选择算法、机器学习算法<citation id="184" type="reference"><link href="157" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 其中向量化过程需要对数据进行标准化处理, 主要包括数据属性标准化、数据缩放、数据量纲界定等内容。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908014_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 软件缺陷报告严重性预测流程" src="Detail/GetImg?filename=images/JSJC201908014_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 软件缺陷报告严重性预测流程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908014_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="54">数据标准化的主要方法<citation id="185" type="reference"><link href="159" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>具体如下:</p>
                </div>
                <div class="p1">
                    <p id="55">1) 分词:该过程包括将一个大的文本字符串分成一组标记, 一个分词过程对应于一个周期。在此期间, 需要过滤所有没有意义的符号, 从而减少符号对分词效果的影响, 同时修正全部词语的大小写问题。</p>
                </div>
                <div class="p1">
                    <p id="56">2) 停止词删除:软件缺陷报告的文本表意过程中会大量使用连接词, 并通过动词、介词和其他语言结构 (如“the”“in”和“that”) 建立句子。这些术语经常出现在缺陷报告的描述中, 导致数据维数提高, 降低分类算法性能, 因此需要删除已知的停止词。</p>
                </div>
                <div class="p1">
                    <p id="57">3) 词干提取:词干提取的步骤旨在减少每个词的变种形式, 使该变种形式回归到单一的词根表示。每个词可以表达不同的形式, 但仍携带相同的特定信息。例如, 术语“computerized”“computerize”“computation”都有同一个词干“computer”。词干提取算法使用类似于porter stemmer的方法, 对每个术语的基本形式进行转换。</p>
                </div>
                <div class="p1">
                    <p id="58">每一个文档由<i>n</i>个属性 (词) 的矢量表示, 当数据集中有<i>m</i>个文档, 相当于有<i>m</i>个长度为<i>n</i>的矢量, 可以用<i>m</i>×<i>n</i>的矩阵来表示所有文档, 即矢量空间模型<citation id="186" type="reference"><link href="161" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。对每一个文档矢量的词语值进行表示, 主要方法如下:</p>
                </div>
                <div class="p1">
                    <p id="59">1) 二进制布尔运算 (T01) 表示法:文档矢量中每一个词的值需在{0, 1}中取出, 0表示某个词在文档中不存在, 1表示存在。该方法处理的数据集适用于朴素贝叶斯算法。</p>
                </div>
                <div class="p1">
                    <p id="60">2) 词频 (Term Frequency, TF) 表示法:该方法类似二进制表示法, 但是需要统计一个词的值在文档中出现的次数。该方法处理的数据集适用于贝叶斯多项式算法。</p>
                </div>
                <div class="p1">
                    <p id="61">3) 词频-逆向文件频率 (Term Frequency Inverse Document Frequency, TF-IDF) 表示法:相对于词频表示法, 还有逆文档频率表示方法, 用于处理特殊项, 并表示词语的特征或重要性。如果一个词出现在多个文档中, 那么其重要性就要相应降低。对于词<i>t</i><sub><i>i</i></sub>的逆文档频率定义为<mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>i</mi><mi>d</mi><mi>f</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mi>lg</mi></mrow><mfrac><mrow><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow></mrow><mrow><mi>D</mi><mi>F</mi></mrow></mfrac></mrow></math></mathml>, 其中, <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow></mrow></math></mathml>表示文档总数, <i>DF</i>表示全部文档中词<i>t</i><sub><i>i</i></sub>出现的次数, <i>tf</i><sub><i>i</i>, <i>j</i></sub>-<i>idf</i><sub><i>i</i></sub>表示<i>t</i><sub><b><i>i</i></b></sub>的值, <i>tf</i>-<i>idf</i><sub><i>i</i>, <i>j</i></sub>=<i>tf</i><sub><i>i</i>, <i>j</i></sub>×<i>idf</i><sub><i>i</i></sub>, 其中, <i>tf</i><sub><i>i</i>, <i>j</i></sub>表示词语<i>t</i><sub><b><i>i</i></b></sub>在当前文档中出现的频率, 词语<i>t</i><sub><b><i>i</i></b></sub>在整个文本集中的重要性通过总文件数除以含有该词语的文本数量取对数得到。基于以上2个结果的乘积可以得到TF-IDF值。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64">2.2 特征选择</h4>
                <div class="p1">
                    <p id="65">在数据分类处理过程中, 数据特征是重要的因素<citation id="187" type="reference"><link href="163" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。由于特征维度会严重影响数据处理效率和准确性, 因此在数据分类过程前需要进行特征优化处理。在软件缺陷报告严重性评估研究中, 采用特征优化方法的主要目的是提高机器学习效率以及严重性预测的准确率, 避免维数灾难问题。</p>
                </div>
                <div class="p1">
                    <p id="66">软件缺陷报告严重性评估过程中采用的特征优化方法一般都以特征选择算法为主。通过对给定的待优化目标数据集的分析, 明确特征间的关系。使用特征选择算法, 按照现有特征对数据集的影响进行排序, 筛选对后续机器学习过程影响较大的特征, 精简特征子集, 完成对大规模数据的预处理, 从而提高数据集在分类过程中的精度, 提高机器学习算法的效率<citation id="188" type="reference"><link href="165" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="67">特征选择算法的一般过程包括:特征子集确定, 子集属性排序, 噪声特征剔除以及有效性验证。其中, 特征子集确定及子集属性排序过程需要通过特征空间搜索方法确定搜索方向以及搜索策略, 噪声剔除过程需要参考评估结果作进一步确定<citation id="189" type="reference"><link href="167" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。常用的特征选择算法包括相关性特征选择 (Correlation-based Feature Selection, CFS) 算法、词频 (TF) 表示算法、信息增益 (Information Gain, IG) 算法、互信息 (Mutual Information, MI) 算法、词频-逆向文件频率 (TF-IDF) 算法、相关系数 (Correlation Coefficient, CC) 算法和卡方检验 (CHI) 算法等。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68">2.3 数据分类</h4>
                <div class="p1">
                    <p id="69">软件缺陷报告严重性评估过程中采用的数据分类方法需要通过对缺陷报告数据集的学习, 使分类器能够对待处理数据集的严重性进行准确预测, 并根据描述信息设计相应的分类模型, 通过现有数据对分类模型的训练和测试确认模型效率并对未知样本进行预测。用于训练和测试模型的数据集分别被称为训练集和测试集<citation id="190" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>。本文实验采用的机器学习算法包括K最近邻 (K-Nearest Neighbor, KNN) 算法、朴素贝叶斯 (Naive Bayes, NB) 算法、特征多项式 (Characteristic Polynomial, CP) 算法、支持向量机 (Support Vector Machine, SVM) 算法、MNB算法。</p>
                </div>
                <div class="p1">
                    <p id="70">在分类过程中, 将数据集定义为训练集、训练子集、特征集、属性集、测试集, 它们共同描述了数据集在机器学习过程中的全部状态。在分类模型建立过程中, 需要把训练集输入模型, 经过训练后导出数据分类。当训练结束后, 将测试集作为输入, 导出测试结果, 输出测试集中每个样本的预测结果。在本文实验中, 针对软件缺陷报告数据集的特点, 构造训练集和测试集, 分别进行分类模型构造和模型性能检验。同时, 通过输出的预测结果与已有的真实结果数据进行比对, 得出分类算法的各类评价指标。</p>
                </div>
                <h3 id="71" name="71" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="72" name="72">3.1 数据集</h4>
                <div class="p1">
                    <p id="73">本文实验数据集选择Bugzilla软件跟踪系统的Eclipse项目数据集。Eclipse的使用者主要是程序开发人员, 因此Eclipse的缺陷报告具有更高的可参考性, 并且更具代表性。由于报告者的职业特征, 因此对不同问题的描述可能更加相似。本文实验采用的数据集为2001年—2017年的Eclipse缺陷报告, 该数据集主要包括no-severe报告10 975个, severe报告33 112个, 其中, no-severe类别中出现频率前30的特征词为dialog、view、editor、file、error、page、prefer、project、type、new、select、eclip、javadoc、name、work、code、show、java、miss、set、text、wizard、chang、task、message、method、class、button、wrong、menu, severe类别中出现频率前30的特征词为eclip、file、error、project、work、editor、view、fail、npe、java、build、test、open、creat、except、report、new、crash、problem、updat、org、plugin、import、run、compil、class、cau、set、gener、chang。</p>
                </div>
                <h4 class="anchor-tag" id="74" name="74">3.2 实验过程</h4>
                <div class="p1">
                    <p id="75">实验过程具体如下:</p>
                </div>
                <h4 class="anchor-tag" id="76" name="76">1) 向量化过程</h4>
                <div class="p1">
                    <p id="77">实验选择从缺陷报告的“summary”字段中提取特征用于严重性预测。“summary”字段是对该缺陷报告的总结性描述, 而“description”可能会包含更多相关性较小的词句, 产生噪声数据干扰判断结果。</p>
                </div>
                <div class="p1">
                    <p id="78">在软件缺陷报告处理过程中, 提取“summary”数据并对其进行特征向量化处理。然后采用特征选择方法对特征进行优化处理。将优化的数据集进行机器学习和测试, 并对比分析其性能差异。向量化特征表示方法采用二进制布尔运算 (T01) 、词频表示 (TF) 、文档频率表示 (DF) 、词频-逆向文件频率 (TF-IDF) , 特征选择算法采用互信息 (MI) 、统计相关性 (SD) 、信息增益 (IG) 、卡方检验 (CHI) 、相关系数 (CC) 。</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79">2) 训练和测试</h4>
                <div class="p1">
                    <p id="80">根据数据集特点, 本文实验使用K折交叉验证算法, 将待测试数据集随机分割成<i>K</i>份, 训练过程中每次取1份子集作为测试集, 其他<i>K</i>-1份子集作为训练集。通过<i>K</i>次重复训练和测试后, 得到错分数据集次数和原始数据集的比值作为分类误差。该过程中交叉使用数据子集进行训练和测试, 多次验证实验数据, 得到相对较优的实验结果。<i>K</i>取值为10, 机器学习算法采用MNB、NB、SVM。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81">3) 性能度量</h4>
                <div class="p1">
                    <p id="82">本文采用准确率、召回率、F值等3种指标对算法性能进行评估, 计算公式分别为<mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac></mrow></math></mathml>、<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac></mrow></math></mathml>、<mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mn>1</mn><mo>=</mo><mfrac><mrow><mn>2</mn><mo>×</mo><mi>Ρ</mi><mo>×</mo><mi>R</mi></mrow><mrow><mi>Ρ</mi><mo>+</mo><mi>R</mi></mrow></mfrac></mrow></math></mathml>。实验中的每个文档被称为一个实例。其中, TP表示正确预测为类别c的实例数量, FP表示错误预测为类别c的实例数量, FN表示错误预测为不是类别c的实例数量, TN表示正确预测为非类别c的实例数量。</p>
                </div>
                <div class="p1">
                    <p id="86">在本文实验中, 选择在软件缺陷报告严重性评估领域普遍采用的<i>ROC</i>曲线下面积 (<i>Area Under the Curve</i>, <i>AUC</i>) 进行度量, 称为<i>AUROC</i>。<i>AUROC</i>能更精确度量不同实验的性能结果, 当<i>AUROC</i>值越接近于1时, 表明分类及预测效果越好;当<i>AUROC</i>值越接近于0.5时, 说明该分类结果与随机分类结果一致, 预测结果较差。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87">3.3 实验结果</h4>
                <h4 class="anchor-tag" id="88" name="88">3.3.1 不同向量化特征表示方法的对比</h4>
                <div class="p1">
                    <p id="89">在特征向量化过程中, 将处理过的文本特征以4种形式表示:1) T01方法, 即0代表该特征在缺陷报告中不出现, 1代表该特征在缺陷报告中出现;2) TF方法, 即某特征在缺陷报告中出现的次数;3) DF方法, 即特征出现的频率;4) TF-IDF方法, 即文档逆频率。针对这4种不同的表现形式, 实验在分类过程中使用IG特征选择算法、MNB分类算法, 取相同特征数 (全部特征) 的基础上进行对比, 结果如表1所示。如图2所示的实验结果表明, 采用T01表示法提取向量化特征得到的实验效果最好。</p>
                </div>
                <div class="area_img" id="90">
                    <p class="img_tit"><b>表1 不同向量化特征表示方法的预测效果比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="90" border="1"><tr><td><br />向量化特征表示方法</td><td>AUROC值</td><td>特征数</td></tr><tr><td><br />T01</td><td>0.767 0</td><td>199</td></tr><tr><td><br />TF</td><td>0.765 3</td><td>215</td></tr><tr><td><br />DF</td><td>0.763 9</td><td>197</td></tr><tr><td><br />TF-IDF</td><td>0.762 1</td><td>202</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908014_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同向量化特征表示方法的AUROC结果" src="Detail/GetImg?filename=images/JSJC201908014_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 不同向量化特征表示方法的AUROC结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908014_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="92" name="92">3.3.2 不同分类算法的对比</h4>
                <div class="p1">
                    <p id="93">由于实验的主要目的是通过特征选择算法对数据集进行优化处理, 分析特征选择算法对软件缺陷报告严重性预测性能的影响, 因此实验中选择分类效果最好的分类算法进行训练与测试。实验对MNB算法和NB算法在严重性预测中的使用效果进行对比。基于不同向量化表示方法的实验结果, 选择T01向量化特征表示方法、相同数量的特征 (全部特征) 以及不同的分类算法进行实验。由表2实验结果可以看出, 针对实验数据集, MNB算法得到的结果最好, 准确率、召回率、F值分别为42.88%、43.13%、49.97%。</p>
                </div>
                <div class="area_img" id="94">
                    <p class="img_tit"><b>表2 不同向量化特征表示方法对应不同分类算法的预测结果比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="94" border="1"><tr><td rowspan="2">分类<br />算法</td><td colspan="3"><br />T01方法</td><td colspan="3"><br />TF方法</td><td colspan="3"><br />DF方法</td><td colspan="3"><br />TF-IDF方法</td></tr><tr><td><br />准确率</td><td>召回率</td><td>F值</td><td><br />准确率</td><td>召回率</td><td>F值</td><td><br />准确率</td><td>召回率</td><td>F值</td><td><br />准确率</td><td>召回率</td><td>F值</td></tr><tr><td><br />MNB</td><td>43.13</td><td>49.97</td><td>42.88</td><td>28.47</td><td>51.52</td><td>35.15</td><td>43.51</td><td>50.34</td><td>42.82</td><td>51.53</td><td>36.66</td><td>41.11</td></tr><tr><td><br />NB</td><td>40.56</td><td>44.06</td><td>41.64</td><td>41.61</td><td>27.24</td><td>28.98</td><td>41.71</td><td>46.20</td><td>42.91</td><td>27.64</td><td>29.50</td><td>41.29</td></tr><tr><td><br />SVM</td><td>26.66</td><td>51.51</td><td>35.09</td><td>26.66</td><td>51.51</td><td>35.09</td><td>26.66</td><td>51.51</td><td>35.09</td><td>51.51</td><td>35.09</td><td>26.66</td></tr><tr><td><br />KNN</td><td>39.96</td><td>30.83</td><td>31.82</td><td>38.92</td><td>24.46</td><td>25.00</td><td>42.71</td><td>23.86</td><td>24.04</td><td>22.84</td><td>22.88</td><td>38.85</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="95" name="95">3.3.3 IG特征选择算法</h4>
                <div class="p1">
                    <p id="96">根据原始数据向量化结果, 在对数据集进行机器学习和测试前, 对向量化的数据集进行特征优化处理。实验中使用IG特征选择算法对向量化数据进行特征优化处理。基于前期实验结果, 所有特征数量为312个, 使用T01向量化特征表示方法、MNB分类算法以及IG、CHI特征选择算法, 并比较特征选择对结果的影响。</p>
                </div>
                <div class="p1">
                    <p id="97">实验中使用IG特征选择算法对所有特征进行评分, 然后按评分高低对特征进行排序, 表3给出Eclipse项目IG评分前20名的特征词。根据IG特征选择结果, 选择特征数量为1的递增方式, 依次提取IG评分最高的特征。使用T01表示方法及MNB分类算法对特征数据进行训练与测试。随着特征数量的增加, 分类结果的AUROC变化情况如图3所示。实验结果表明, 当提取前199个特征时AUROC值最大为0.767, 也就是此时分类效果最好, 并且当取到前100个特征时, AUROC值为0.756。</p>
                </div>
                <div class="area_img" id="98">
                    <p class="img_tit"><b>表3 Eclipse项目特征词IG评分前20名的结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="98" border="1"><tr><td><br />排名</td><td>IG评分</td><td>特征</td></tr><tr><td><br />1</td><td>0.010 504</td><td>jdt</td></tr><tr><td><br />2</td><td>0.008 000</td><td>differ</td></tr><tr><td><br />3</td><td>0.007 331</td><td>creat</td></tr><tr><td><br />4</td><td>0.006 474</td><td>null</td></tr><tr><td><br />5</td><td>0.004 986</td><td>edit</td></tr><tr><td><br />6</td><td>0.004 946</td><td>preview</td></tr><tr><td><br />7</td><td>0.004 491</td><td>web</td></tr><tr><td><br />8</td><td>0.004 183</td><td>paramet</td></tr><tr><td><br />9</td><td>0.003 992</td><td>failur</td></tr><tr><td><br />10</td><td>0.003 863</td><td>call</td></tr><tr><td><br />11</td><td>0.003 341</td><td>execut</td></tr><tr><td><br />12</td><td>0.003 302</td><td>repositori</td></tr><tr><td><br />13</td><td>0.003 255</td><td>remot</td></tr><tr><td><br />14</td><td>0.003 048</td><td>ignor</td></tr><tr><td><br />15</td><td>0.003 041</td><td>method</td></tr><tr><td><br />16</td><td>0.002 887</td><td>help</td></tr><tr><td><br />17</td><td>0.002 631</td><td>compar</td></tr><tr><td><br />18</td><td>0.002 595</td><td>navig</td></tr><tr><td><br />19</td><td>0.002 482</td><td>gener</td></tr><tr><td><br />20</td><td>0.002 390</td><td>chang</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908014_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 IG选择不同特征数量对应的AUROC结果" src="Detail/GetImg?filename=images/JSJC201908014_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 IG选择不同特征数量对应的AUROC结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908014_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="100" name="100">3.3.4 不同特征选择算法的对比</h4>
                <div class="p1">
                    <p id="101">实验中使用IG和CHI特征选择算法分别对总的特征数据集进行处理, 结果如图4所示。实验结果表明, 在当前数据集中IG和CHI特征选择算法结果基本相同。</p>
                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908014_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 IG和CHI选择不同特征数量对应的AUROC结果" src="Detail/GetImg?filename=images/JSJC201908014_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 IG和CHI选择不同特征数量对应的AUROC结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908014_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="103" name="103">3.3.5 向量化特征的T01系数添加</h4>
                <div class="p1">
                    <p id="104">对于T01特征向量化表示方法, 使用IG特征选择算法及MNB分类算法, 并添加不同T01系数, AUROC结果如表4所示。当特征数不变且T01系数从1～20变化时, T01系数为20的AUROC效果最好, 但各T01系数的实验效果差距不明显。</p>
                </div>
                <div class="area_img" id="105">
                    <p class="img_tit"><b>表4 不同T01系数对严重性预测结果的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="105" border="1"><tr><td><br />T01系数</td><td>AUROC值</td><td>特征数</td></tr><tr><td><br />1</td><td>0.763 9</td><td>197</td></tr><tr><td><br />2</td><td>0.764 2</td><td>197</td></tr><tr><td><br />10</td><td>0.764 3</td><td>197</td></tr><tr><td><br />15</td><td>0.764 3</td><td>197</td></tr><tr><td><br />20</td><td>0.764 3</td><td>197</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="106" name="106">3.3.6 在特征选择中使用的主题模型</h4>
                <div class="p1">
                    <p id="107">对待处理数据集进行基于主题模型的分类训练, 将词语和主题分类到2个子集中, 得出“词语-主题”和“主题-文档”数据子集, 得到文档表达的主题。通过分析主题模型对隐含主题数据增加主题, 并将文档表达为<i>m</i><sub>topic</sub>= (<i>z</i><sub>1</sub>, <i>z</i><sub>2</sub>…, <i>z</i><sub><i>n</i></sub>) , 其中<i>z</i><sub><i>j</i></sub>表示第<i>j</i>个主题在文档中出现的次数。将主题数定义为建模维度, 需要通过衡量主题数目变化的影响来确定。当困惑度最小时, 主题数目最佳, 训练效果较好。当前LDA模型应用较广泛, 也有较多用于文本分类方面的研究。与单纯使用分类学习算法相比, 将LDA与传统机器学习算法相结合进行文本分类, 通过特征降维可使准确率提高5%。使用LDA主题模型方法定义不同主题数, 用MNB算法进行学习和训练, 分类结果AUROC随主题数的变化情况如图5所示。当主题数取64时, 分类效果最好, AUROC约为0.732 5。对数据进行向量化处理并选取前300个特征, 使用主题模型LDA方法对特征进行优化处理, 利用MNB对处理过的数据集进行训练与测试。</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201908014_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 使用LDA处理的数据在MNB算法中的分类效果" src="Detail/GetImg?filename=images/JSJC201908014_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 使用LDA处理的数据在MNB算法中的分类效果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201908014_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="109" name="109" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="110">软件缺陷报告的严重性评估能够影响缺陷修复过程中的解决时长、修复率、持有者等属性, 是软件缺陷报告研究的重点内容。本文根据特征选择算法对Eclipse软件缺陷报告数据进行严重性分类研究, 在软件缺陷报告的准确率、召回率等方面进行重点分析。通过实验可知, 使用特征选择算法对特征进行优化处理后的数据集, 在严重性预测方面的效果优于未进行特征选择的数据集。对比不同的特征选择算法处理的数据集, 严重性预测结果基本相同。使用T01向量化方法、IG特征选择算法、MNB机器学习算法的组合能够得到最好的严重性预测效果。下一步可将软件缺陷报告数据集扩展至更多开源项目中, 验证向量化特征表示方法、特征选择及机器学习算法的最佳组合预测效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="131">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD3E8C6DBA968466ABBB43BA447BE3409E&amp;v=MTM2ODZPR1FsZkNwYlEzNU54aHc3MjN4YTQ9Tmo3QmFyRE5GcUxLMi8wMGJlMEhDSG8vdm1SaG1EdCtPZzdtcUJWSERMR1FSYlBxQ09OdkZTaVdXcjdKSUZwbWFCdUhZZg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> NI Chao, LIU Wangshu, CHEN Xiang, et al.A cluster based feature selection method for cross-project software defect prediction[J].Journal of Computer Science and Technology, 2017, 32 (6) :1090-1107.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A hybrid instance selection using nearest-neighbor for cross-project defect prediction">

                                <b>[2]</b> RYU D, JIANG J I, BAIK J.A hybrid instance selection using nearest-neighbor for cross-project defect prediction[J].Journal of Computer Science and Technology, 2015, 30 (5) :969-980.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic Bug Triage using Semi-Supervised Text Classification">

                                <b>[3]</b> XUAN Jifeng, JIANG He, REN Zhiwei, et al.Automatic BUG triage using semi-supervised text classifica-tion[C]//Proceedings of the 22nd International Conference on Software Engineering and Knowledge Engineering.Washington D.C., USA:IEEE Press, 2010:1-9.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Network Intrusion detection by using Feature Reduction Technique">

                                <b>[4]</b> LAWRENCE F L, SHARMA S K, SISODIA M S.Network intrusion detection by using feature reduction technique[J].International Journal of Advanced Research in Computer Science and Electronics Engineering, 2012, 1 (1) :27-32.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Literature Review of Research in Software Defect Reporting">

                                <b>[5]</b> STRATE J D, LAPLANTE P A.A literature review of research in software defect reporting[J].IEEE Transactions on Reliability, 2013, 62 (2) :444-454.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738969&amp;v=MTQ5OTVpclJkR2VycVFUTW53WmVadUh5am1VTHZJSjFzY2J4UT1OaWZPZmJLN0h0RE5xWTlGWStnSEJYb3dvQk1UNlQ0UFFILw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> WANG Jie, PLATANIOTIS K, LU J, et al.Kernel quadratic discriminant analysis for small sample size problem[J].Pattern Recognition, 2008, 41 (5) :1528-1538.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Assigning bug reports using a vocabulary-based expertise model of developers">

                                <b>[7]</b> MATTER D, KUHN A, NIERSTRASZ O.Assigning BUG reports using a vocabulary-based expertise model of developers[C]//Proceedings of the 6th IEEE International Working Conference on Mining Software Repositories.Washington D.C., USA:IEEE Press, 2009:131-140.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738881&amp;v=MDEwNzh2SUoxc2NieFE9TmlmT2ZiSzdIdEROcVk5RlkrZ0hCSFE0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> ZIOU D, HAMRI T, BOUTEMEDJET S.A hybrid probabilistic framework for content-based image retrieval with feature weighting[J].Pattern Recognition, 2009, 42 (7) :1511-1519.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automated severity assessment of software defect reports">

                                <b>[9]</b> MENZIES T, MARCUS A.Automated severity assessment of software defect reports[C]//Proceedings of IEEE International Conference on Software.New York, USA:ACM Press, 2015:1-12.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Comparing mining algorithms for predicting the severity of a reported BUG">

                                <b>[10]</b> LAMKAN A, DEMEYER S, SOETENS Q D, et al.Comparing mining algorithms for predicting the severity of a reported BUG[C]//Proceedings of European Conference on Software.New York, USA:ACM Press, 2011:1-8.
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201121018&amp;v=Mjg1NTQvZ1c3ck9MejdCYmJHNEg5RE9ybzlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRnk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 黄小亮, 郁抒思, 关佶红.基于LDA主题模型的软件缺陷分派方法[J].计算机工程, 2011, 37 (21) :46-48.
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Towards more accurate severity prediction and fixer recommendation of software bugs">

                                <b>[12]</b> ZHANG Tao, CHEN Jiachi, YANG G, et al.Towards more accurate severity prediction and fixer recommendation of software BUGs[J].Journal of Systems and Software, 2016, 117 (C) :166-184.
                            </a>
                        </p>
                        <p id="155">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic Bug Assignment Using Information Extraction Methods">

                                <b>[13]</b> SHOKRIPOUR R, KASIRUN Z M, ZAMANI S, et al.Automatic BUG assignment using information extraction methods[C]//Proceedings of International Conference on Advanced Computer Science Applications and Technologies.Washington D.C., USA:IEEE Press, 2012:144-149.
                            </a>
                        </p>
                        <p id="157">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Why so Complicated?Simple Term Filtering and Weighting for Location-based Bug Report Assignment Recommendation">

                                <b>[14]</b> SHOKRIPOUR R, ANVIK J, KASIRUN Z M, et al.Why so complicated?simple term filtering and weighting for location-based BUG report assignment recommendation[C]//Proceedings of the 10th International Workshopon Mining Software Repositories.Washington D.C., USA:IEEE Press, 2013:2-11.
                            </a>
                        </p>
                        <p id="159">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Predicting the severity of bug reports based on feature selection">

                                <b>[15]</b> LIU Wenjie, WANG Shanshan, CHEN Xin, et al.Predicting the severity of BUG reports based on feature selection[J].International Journal of Software Engineering and Knowledge Engineering, 2018, 28 (4) :537-558.
                            </a>
                        </p>
                        <p id="161">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201810003&amp;v=MDY5ODBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5L2dXN3JPUFRYY2RyRzRIOW5OcjQ5Rlo0UUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 张肖, 王利明.一种半监督继承学习软件缺陷预测方法[J].小型微型计算机系统, 2018, 39 (10) :2138-2145.
                            </a>
                        </p>
                        <p id="163">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201811032&amp;v=MTUyNzVxcUJ0R0ZyQ1VSTE9lWmVScUZ5L2dXN3JPTHo3QmI3RzRIOW5Ocm85R1pvUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 史小婉, 马于涛.一种基于文本分类和评分机制的软件缺陷分配方法[J].计算机科学, 2018, 45 (11) :193-198.
                            </a>
                        </p>
                        <p id="165">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201810011&amp;v=MjcwNDNVUkxPZVplUnFGeS9nVzdyT0x6N0JaYkc0SDluTnI0OUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 任胜兵, 廖湘荡.基于代价敏感支持向量机的软件缺陷预测研究[J].计算机工程与科学, 2018, 40 (10) :1787-1795.
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TSQB201303018&amp;v=MDExMTh0R0ZyQ1VSTE9lWmVScUZ5L2dXN3JPTVQ3YWJMRzRIOUxNckk5RWJJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> 路永和, 李焰锋.改进TF-IDF算法的文本特征项权值计算方法[J].图书情报工作, 2013, 57 (3) :90-95.
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201808010&amp;v=MDQwMTlPTnlmVGJMRzRIOW5NcDQ5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVScUZ5L2dXN3I=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 孙小兵, 周澄, 杨辉, 等.面向软件安全性缺陷的开发者推荐方法[J].软件学报, 2018, 29 (8) :2294-2305.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->

            <div class="btn-downloads">
                <span>
                    <a class="caj" target="_blank" href="http://kns.cnki.net/kns/download.aspx?filename=yNUeaxmbNdnZyJzaVZUUpxGaJVXZRJ1KnpFOJ9mNKdEavU2LMpXMIJGdnhXetN3VzUXMPVFWqVmSi5kdv8UdKNndTdDZ5MzMPFlZxhmYrV2N2MmRVdXbEZUaVV1YZJ3UvwUQrNWMK9ESrVEW5kjMCRTZalFdvsyZ&tablename=CJFDLAST2019">CAJ下载</a>
                    <a class="pdf" target="_blank" href="http://kns.cnki.net/kns/download.aspx?filename=yNUeaxmbNdnZyJzaVZUUpxGaJVXZRJ1KnpFOJ9mNKdEavU2LMpXMIJGdnhXetN3VzUXMPVFWqVmSi5kdv8UdKNndTdDZ5MzMPFlZxhmYrV2N2MmRVdXbEZUaVV1YZJ3UvwUQrNWMK9ESrVEW5kjMCRTZalFdvsyZ&tablename=CJFDLAST2019&dflag=pdfdown">PDF下载</a>
                </span>
                <p>永久保存本文,请下载至本地</p>
            </div>


    </div>

        <input id="fileid" type="hidden" value="JSJC201908014" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201908014&amp;v=MDcwMjk5ak1wNDlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJxRnkvZ1c3ck9MejdCYmJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9xck9nSjc1VXR3SDJsaTcyc24rQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
            <a class="icon" id="copytext" target="_blank" href="http://x.cnki.net/search/common/testlunbo?dbcode=CJFD&amp;tablename=CJFDLAST2019&amp;filename=JSJC201908014&amp;filesourcetype=1">划线</a>
            <a class="icon" id="copytext" target="_blank" href="http://x.cnki.net/search/common/testlunbo?dbcode=CJFD&amp;tablename=CJFDLAST2019&amp;filename=JSJC201908014&amp;filesourcetype=1">笔记</a>
            <a class="icon" id="copytext" target="_blank" href="http://x.cnki.net/search/common/testlunbo?dbcode=CJFD&amp;tablename=CJFDLAST2019&amp;filename=JSJC201908014&amp;filesourcetype=1">文摘</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
