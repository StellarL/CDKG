<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637128048089248750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201909045%26RESULT%3d1%26SIGN%3dyJk3%252f85JRp7rqnC70lH31HD0R5E%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201909045&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201909045&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201909045&amp;v=MDQ3NTFNcG85QllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckZ5N21Vci9KTHo3QmJiRzRIOWo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#55" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#58" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="1.1 基于词匹配的方法">1.1 基于词匹配的方法</a></li>
                                                <li><a href="#61" data-title="1.2 基于深度学习的方法">1.2 基于深度学习的方法</a></li>
                                                <li><a href="#63" data-title="1.3 注意力机制">1.3 注意力机制</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#68" data-title="2 MA-CNN模型 ">2 MA-CNN模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#69" data-title="2.1 问题定义">2.1 问题定义</a></li>
                                                <li><a href="#73" data-title="2.2 模型构建">2.2 模型构建</a></li>
                                                <li><a href="#112" data-title="2.3 训练方法">2.3 训练方法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#119" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#120" data-title="3.1 实验流程">3.1 实验流程</a></li>
                                                <li><a href="#127" data-title="3.2 实验数据">3.2 实验数据</a></li>
                                                <li><a href="#131" data-title="3.3 实验环境">3.3 实验环境</a></li>
                                                <li><a href="#134" data-title="3.4 评价指标">3.4 评价指标</a></li>
                                                <li><a href="#138" data-title="3.5 词向量训练">3.5 词向量训练</a></li>
                                                <li><a href="#140" data-title="3.6 超参数设置与训练">3.6 超参数设置与训练</a></li>
                                                <li><a href="#145" data-title="3.7 结果分析">3.7 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#167" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#75" data-title="&lt;b&gt;图1 MA-CNN模型架构&lt;/b&gt;"><b>图1 MA-CNN模型架构</b></a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;表1 实验数据样例&lt;/b&gt;"><b>表1 实验数据样例</b></a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;表2 本文实验环境&lt;/b&gt;"><b>表2 本文实验环境</b></a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;表3 卷积核层数不同时的结果对比&lt;/b&gt;"><b>表3 卷积核层数不同时的结果对比</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;表4 卷积核个数不同时的结果对比&lt;/b&gt;"><b>表4 卷积核个数不同时的结果对比</b></a></li>
                                                <li><a href="#152" data-title="&lt;b&gt;表5 3种模型的实验结果对比&lt;/b&gt;"><b>表5 3种模型的实验结果对比</b></a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;表6 match-score 3种不同策略的结果对比&lt;/b&gt;"><b>表6 match-score 3种不同策略的结果对比</b></a></li>
                                                <li><a href="#160" data-title="&lt;b&gt;表7 本文模型与8种传统模型的结果对比&lt;/b&gt;"><b>表7 本文模型与8种传统模型的结果对比</b></a></li>
                                                <li><a href="#164" data-title="&lt;b&gt;表8 本文模型与4种RNN模型的结果对比&lt;/b&gt;"><b>表8 本文模型与4种RNN模型的结果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="214">


                                    <a id="bibliography_1" title=" KANG Longbiao,HU Baotian,WU Xiangping,et al.A short texts matching method using shallow features and deep features[C]//Proceedings of Natural Language Processing and Chinese Computing.Berlin,Germany:Springer,2014:150-159." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;A short texts matching method using shallow features and deep features,&amp;quot;">
                                        <b>[1]</b>
                                         KANG Longbiao,HU Baotian,WU Xiangping,et al.A short texts matching method using shallow features and deep features[C]//Proceedings of Natural Language Processing and Chinese Computing.Berlin,Germany:Springer,2014:150-159.
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_2" title=" WANG Hao,LU Zhengdong,LI Hang,et al.A dataset for research on short-text conversations[C]//Proceedings of Conference on Empirical Methods in Natural Language Processing.Stroudsburg,USA:Association for Computational Linguistics,2013:935-945." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Dataset for Research on Short-Text Conversation">
                                        <b>[2]</b>
                                         WANG Hao,LU Zhengdong,LI Hang,et al.A dataset for research on short-text conversations[C]//Proceedings of Conference on Empirical Methods in Natural Language Processing.Stroudsburg,USA:Association for Computational Linguistics,2013:935-945.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_3" title=" KENTER T,RIJKE M D.Short text similarity with word embeddings[C]//Proceedings of ACM International on Conference on Information and Knowledge Management.New York,USA:ACM Press,2015:1411-1420." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Short Text Similarity with Word Embeddings">
                                        <b>[3]</b>
                                         KENTER T,RIJKE M D.Short text similarity with word embeddings[C]//Proceedings of ACM International on Conference on Information and Knowledge Management.New York,USA:ACM Press,2015:1411-1420.
                                    </a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_4" title=" JIJKOUN V,RIJKE M D.Recognizing textual entailment using lexical similarity [EB/OL].[2018-07-01].http://u.cs.biu.ac.il/～nlp/RTE1/Proceedings/jijkoun_and_de_rijke.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recognizing textual entailment using lexical similarity">
                                        <b>[4]</b>
                                         JIJKOUN V,RIJKE M D.Recognizing textual entailment using lexical similarity [EB/OL].[2018-07-01].http://u.cs.biu.ac.il/～nlp/RTE1/Proceedings/jijkoun_and_de_rijke.pdf.
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_5" title=" ISLAM A,INKPEN D.Semantic text similarity using corpus-based word similarity and string similarity [J].ACM Transactions on Knowledge Discovery from Data,2008,2(2):1-25." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000093166&amp;v=MjM1OTZOaWZJWTdLN0h0ak5yNDlGWk9JTURYby9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMcklKbDBWYWhJPQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         ISLAM A,INKPEN D.Semantic text similarity using corpus-based word similarity and string similarity [J].ACM Transactions on Knowledge Discovery from Data,2008,2(2):1-25.
                                    </a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_6" title=" KUSNER M J,SUN Yu,KOLKIN N I,et al.From word embeddings to document distances[C]//Proceedings of the 32nd International Conference on Machine Learning.New York,USA:ACM Press,2015:957-966." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=From word embeddings to document distances">
                                        <b>[6]</b>
                                         KUSNER M J,SUN Yu,KOLKIN N I,et al.From word embeddings to document distances[C]//Proceedings of the 32nd International Conference on Machine Learning.New York,USA:ACM Press,2015:957-966.
                                    </a>
                                </li>
                                <li id="226">


                                    <a id="bibliography_7" title=" RUMELHART D E,HINTON G E,WILLIAMS R J.Learning representations by back-propagating errors[J].Nature,1986,323(6088):399-421." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning representations by back-propagating errors">
                                        <b>[7]</b>
                                         RUMELHART D E,HINTON G E,WILLIAMS R J.Learning representations by back-propagating errors[J].Nature,1986,323(6088):399-421.
                                    </a>
                                </li>
                                <li id="228">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                     MIKOLOV T,CHEN Kai,CORRADO G,et al.Efficient estimation of word representations in vector space[EB/OL].[2018-07-01].https://arxiv.org/abs/1301.3781.</a>
                                </li>
                                <li id="230">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     MIKOLOV T,SUTSKEVER I,CHEN Kai,et al.Distributed representations of words and phrases and their compositionality[C]//Proceedings of the 26th International Conference on Neural Information Processing Systems.New York,USA:ACM Press,2013:3111-3119.</a>
                                </li>
                                <li id="232">


                                    <a id="bibliography_10" title=" BARONI M,DINU G,KRUSZEWSKI G.Don’t count,predict! a systematic comparison of context-counting vs.context-predicting semantic vectors[C]//Proceedings of Meeting of the Association for Computational Linguistics.Stroudsburg,USA:Association for Computational Linguistics,2014:238-247." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Don&amp;#39;&amp;#39;t count,predict!A systematic comparison of context-counting vs.context-predicting semantic vectors">
                                        <b>[10]</b>
                                         BARONI M,DINU G,KRUSZEWSKI G.Don’t count,predict! a systematic comparison of context-counting vs.context-predicting semantic vectors[C]//Proceedings of Meeting of the Association for Computational Linguistics.Stroudsburg,USA:Association for Computational Linguistics,2014:238-247.
                                    </a>
                                </li>
                                <li id="234">


                                    <a id="bibliography_11" title=" 黄江平,姬东鸿.基于句子语义距离的释义识别研究[J].四川大学学报(工程科学版),2016,48(6):202-207." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCLH201606028&amp;v=MTM5NTlHRnJDVVJMT2VaZVJyRnk3bVVyL0lOaTdIWnJHNEg5Zk1xWTlIYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         黄江平,姬东鸿.基于句子语义距离的释义识别研究[J].四川大学学报(工程科学版),2016,48(6):202-207.
                                    </a>
                                </li>
                                <li id="236">


                                    <a id="bibliography_12" title=" 高云龙,左万利,王英,等.基于稀疏自学习卷积神经网络的句子分类模型[J].计算机研究与发展,2018,55(1):179-187." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201801016&amp;v=MDM1MzdyL0lMeXZTZExHNEg5bk1ybzlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnk3bVU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         高云龙,左万利,王英,等.基于稀疏自学习卷积神经网络的句子分类模型[J].计算机研究与发展,2018,55(1):179-187.
                                    </a>
                                </li>
                                <li id="238">


                                    <a id="bibliography_13" title=" 张琦,彭志平.融合注意力机制和CNN-GRNN模型的读者情绪预测[J].计算机工程与应用,2018,54(13):168-174." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201813027&amp;v=Mjg5NTA1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnk3bVVyL0lMejdNYWJHNEg5bk5ySTlIWTRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         张琦,彭志平.融合注意力机制和CNN-GRNN模型的读者情绪预测[J].计算机工程与应用,2018,54(13):168-174.
                                    </a>
                                </li>
                                <li id="240">


                                    <a id="bibliography_14" title=" CHEN Kai,WANG Jiang,CHEN Liangchieh,et al.ABC-CNN:an attention based convolutional neural network for visual question answering[EB/OL].[2018-07-01].https://arxiv.org/pdf/1511.05960.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ABC-CNN:an attention based convolutional neural network for visual question answering">
                                        <b>[14]</b>
                                         CHEN Kai,WANG Jiang,CHEN Liangchieh,et al.ABC-CNN:an attention based convolutional neural network for visual question answering[EB/OL].[2018-07-01].https://arxiv.org/pdf/1511.05960.pdf.
                                    </a>
                                </li>
                                <li id="242">


                                    <a id="bibliography_15" title=" XIAO Tianjun,XU Yichong,YANG Kuiyuan,et al.The application of two-level attention models in deep convolutional neural network for fine-grained image classification[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C.,USA:IEEE Press,2015:842-850." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The application of two-level attention models in deep convolutional neural network for fine-grained image classification">
                                        <b>[15]</b>
                                         XIAO Tianjun,XU Yichong,YANG Kuiyuan,et al.The application of two-level attention models in deep convolutional neural network for fine-grained image classification[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C.,USA:IEEE Press,2015:842-850.
                                    </a>
                                </li>
                                <li id="244">


                                    <a id="bibliography_16" title=" 徐俊.基于视觉的文本生成方法研究[D].合肥:中国科学技术大学,2018." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1018088263.nh&amp;v=MzA1MzlJVkYyNkZyT3dGdFBLckpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckZ5N21Vci8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         徐俊.基于视觉的文本生成方法研究[D].合肥:中国科学技术大学,2018.
                                    </a>
                                </li>
                                <li id="246">


                                    <a id="bibliography_17" title=" 李青山.基于注意力选择机制的图像分割与场景理解[D].上海:上海交通大学,2012." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1012018441.nh&amp;v=MjEwNzNwRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeTdtVXIvSVZGMjZITE81RnRYSXI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         李青山.基于注意力选择机制的图像分割与场景理解[D].上海:上海交通大学,2012.
                                    </a>
                                </li>
                                <li id="248">


                                    <a id="bibliography_18" title=" CAO Chunshui,LIU Xianming,YANG Yi,et al.Look and think twice:capturing top-down visual attention with feedback convolutional neural networks[C]//Proceedings of 2015 IEEE International Conference on Computer Vision.Washington D.C.,USA:IEEE Press,2015:2956-2964." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Look and think twice:capturing top-down visual attention with feedback convolutional neural networks">
                                        <b>[18]</b>
                                         CAO Chunshui,LIU Xianming,YANG Yi,et al.Look and think twice:capturing top-down visual attention with feedback convolutional neural networks[C]//Proceedings of 2015 IEEE International Conference on Computer Vision.Washington D.C.,USA:IEEE Press,2015:2956-2964.
                                    </a>
                                </li>
                                <li id="250">


                                    <a id="bibliography_19" title=" BAHDANAU D,CHO K,BENGIO Y.Neural machine trans-lation by jointly learning to align and translate[EB/OL].[2018-07-01].https://arxiv.org/pdf/140 9.0473v6.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">
                                        <b>[19]</b>
                                         BAHDANAU D,CHO K,BENGIO Y.Neural machine trans-lation by jointly learning to align and translate[EB/OL].[2018-07-01].https://arxiv.org/pdf/140 9.0473v6.pdf.
                                    </a>
                                </li>
                                <li id="252">


                                    <a id="bibliography_20" title=" 刘宇鹏,马春光,张亚楠.深度递归的层次化机器翻译模型[J].计算机学报,2017,40(4):861-871." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201704006&amp;v=MTYxOTFyRnk3bVVyL0lMejdCZHJHNEg5Yk1xNDlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         刘宇鹏,马春光,张亚楠.深度递归的层次化机器翻译模型[J].计算机学报,2017,40(4):861-871.
                                    </a>
                                </li>
                                <li id="254">


                                    <a id="bibliography_21" title=" BOWMAN S R,POTTS C,MANNING C D.Recursive neural networks can learn logical semantics[EB/OL].[2018-07-01].https://arxiv.org/pdf/1406.1827.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recursive neural networks can learn logical semantics">
                                        <b>[21]</b>
                                         BOWMAN S R,POTTS C,MANNING C D.Recursive neural networks can learn logical semantics[EB/OL].[2018-07-01].https://arxiv.org/pdf/1406.1827.pdf.
                                    </a>
                                </li>
                                <li id="256">


                                    <a id="bibliography_22" title=" ROCKT&#196;SCHEL T,GREFENSTETTE E,HERMANN K M,et al.Reasoning about entailment with neural attention[EB/OL].[2018-07-01].https://arxiv.org/pdf/1509.06664.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reasoning about entailment with neural attention">
                                        <b>[22]</b>
                                         ROCKT&#196;SCHEL T,GREFENSTETTE E,HERMANN K M,et al.Reasoning about entailment with neural attention[EB/OL].[2018-07-01].https://arxiv.org/pdf/1509.06664.pdf.
                                    </a>
                                </li>
                                <li id="258">


                                    <a id="bibliography_23" title=" 冯兴杰,张志伟,史金钏.基于卷积神经网络和注意力模型的文本情感分析[J].计算机应用研究,2018,35(5):1434-1436." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201805034&amp;v=MjcwNDRSTE9lWmVSckZ5N21Vci9JTHo3U1pMRzRIOW5NcW85R1lJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                         冯兴杰,张志伟,史金钏.基于卷积神经网络和注意力模型的文本情感分析[J].计算机应用研究,2018,35(5):1434-1436.
                                    </a>
                                </li>
                                <li id="260">


                                    <a id="bibliography_24" title=" YIN WENPENG,KANN K,YU Mo,et al.Comparative study of cnn and rnn for natural language processing[EB/OL].[2018-07-01].https://arxiv.org/pdf/1702.01923.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Comparative study of cnn and rnn for natural language processing">
                                        <b>[24]</b>
                                         YIN WENPENG,KANN K,YU Mo,et al.Comparative study of cnn and rnn for natural language processing[EB/OL].[2018-07-01].https://arxiv.org/pdf/1702.01923.pdf.
                                    </a>
                                </li>
                                <li id="262">


                                    <a id="bibliography_25" title=" KIM Y.Convolutional neural networks for sentence classification[EB/OL].[2018-07-01].https://arxiv.org/pdf/1408.5882.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">
                                        <b>[25]</b>
                                         KIM Y.Convolutional neural networks for sentence classification[EB/OL].[2018-07-01].https://arxiv.org/pdf/1408.5882.pdf.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(09),284-290 DOI:10.19678/j.issn.1000-3428.0052098            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于多注意力CNN的问题相似度计算模型</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%86%AF%E5%85%B4%E6%9D%B0&amp;code=10637446&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">冯兴杰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E4%B9%90&amp;code=40425751&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张乐</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%BE%E4%BA%91%E6%B3%BD&amp;code=40418484&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曾云泽</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E6%B0%91%E8%88%AA%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0029470&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国民航大学计算机科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在智能客服问答系统中,用户所提问句具有咨询意图复杂、上下文相关性弱以及口语化等特点,导致问句相似度计算的准确率不高,出现答非所问的情况。提出一种基于卷积神经网络的相似度计算模型MA-CNN。通过2个不同的注意力机制,同时关注词汇间的语义信息和句子间的整体语义信息,提高智能客服对问题的理解能力。实验结果表明,与基于词向量和基于循环神经网络的模型相比,MA-CNN模型对问句的辨识能力更强,其<i>F</i>1值最高可达0.501。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">智能客服;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">文本相似度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%8D%E8%AF%AD%E8%AF%AD%E4%B9%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">词语语义;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%A5%E5%AD%90%E8%AF%AD%E4%B9%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">句子语义;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">注意力机制;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    冯兴杰(1969—),男,教授、博士,主研方向为智能信息处理、智能算法;E-mail:xwjxt@ sict. ac. cn;
                                </span>
                                <span>
                                    *张乐(通信作者),硕士研究生。;
                                </span>
                                <span>
                                    曾云泽,硕士研究生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-13</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金青年科学基金(61301245,61201414);</span>
                                <span>赛尔网络下一代互联网技术创新项目(NGII20160605);</span>
                    </p>
            </div>
                    <h1><b>Question Similarity Calculation Model Based on Multi-Attention CNN</b></h1>
                    <h2>
                    <span>FENG Xingjie</span>
                    <span>ZHANG Le</span>
                    <span>ZENG Yunze</span>
            </h2>
                    <h2>
                    <span>College of Computer Science and Technology,Civil Aviation University of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In the intelligent customer service question-answering system,the questions asked by users are characterized by complex consultation intention,weak contextual relevance,and serious colloquialization.As a result,the accuracy of question similarity calculation is not high and irrelevant answer occurs.In order to solve these problems,a similarity calculation model MA-CNN based on Convolutional Neural Network(CNN) is proposed.Focusing on the semantic information between words and the overall semantic information between sentences through two different attention mechanisms,the problem understanding ability of the intelligent customer service can be improved.Experimental results show that,compared with the models based on word vector and Recurrent Neural Network(RNN),the MA-CNN model has stronger ability to identify questions,and its <i>F</i>1 value can reach up to 0.501.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=intelligent%20customer%20service&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">intelligent customer service;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=text%20similarity&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">text similarity;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=semantic%20of%20words&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">semantic of words;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=semantic%20of%20sentence&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">semantic of sentence;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Neural%20Network%20(CNN)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Neural Network (CNN);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=attention%20mechanism&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">attention mechanism;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-07-13</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="55" name="55" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="56">随着互联网技术的发展和智能设备的普及,人们的社交方式及应用软件的功能更加多样化。传统人工客服难以保证客户的体验感,因此基于语音智能处理技术的智能客服应运而生。在回答问题的过程中,智能客服根据用户给定的问题匹配数据库中相似问题的答案。由于用户所提问题具有咨询意图复杂、上下文相关性弱、问题多样、指代缺失、口语化严重等特点,智能客服对问句的理解受到很大的制约,导致其不能准确地返回对应的答案,极大地影响了用户的体验感。</p>
                </div>
                <div class="p1">
                    <p id="57">用户所提问题偏向口语化且长度较短,尽管问题的用词和句式极其相似,但是其语义逻辑却大相径庭。例如,存在3个待辨识的句子<i>p</i>、<i>r</i><sub>0</sub>、<i>r</i><sub>1</sub>。其中,<i>p</i>表示用户提出的问题“蚂蚁花呗临时额度可以分期吗?”,<i>r</i><sub>0</sub>表示是语义相同的相似问题1 “蚂蚁花呗的临时额度到期了,还可以继续分期付款吗?”,<i>r</i><sub>1</sub>表示是语义不同的相似问题2“蚂蚁花呗分期提前还款收费用吗?”。在以往的研究中<citation id="264" type="reference"><link href="214" rel="bibliography" /><link href="216" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>,当<i>p</i>、<i>r</i><sub>0</sub>、<i>r</i><sub>1</sub>含有相同词语“蚂蚁花呗”“分期”且有相似词语“额度”“付款”“收费”时,往往将<i>r</i><sub>0</sub>、<i>r</i><sub>1</sub>判断为正例,实际上<i>r</i><sub>0</sub>是正例而<i>r</i><sub>1</sub>是负例。分类发生错误的主要原因在于,这些方法将用户提出的问题<i>p</i>与相似问题<i>r</i>单独进行考虑,且只在词语层次进行相似度匹配,忽略了2个句子在特定语义环境下的相互作用。为在关注词级信息的同时综合考虑问题语句的上下文信息,进一步提高对句式相似、口语化严重的问句的辨识准确率,本文提出一种基于多注意力机制的卷积神经网络模型(Multi-Attention Convolutional Neural Network,MA-CNN)。</p>
                </div>
                <h3 id="58" name="58" class="anchor-tag">1 相关工作</h3>
                <h4 class="anchor-tag" id="59" name="59">1.1 基于词匹配的方法</h4>
                <div class="p1">
                    <p id="60">词匹配技术是在自然语言处理(Natural Language Processing,NLP)中判断2个用词相同、句式相似的问题是否语义相同的一种经典方法<citation id="265" type="reference"><link href="218" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。文献<citation id="266" type="reference">[<a class="sup">4</a>]</citation>利用词汇重叠方法计算“文本-假设”之间的有向语义相似性,文献<citation id="267" type="reference">[<a class="sup">5</a>]</citation>提出文本相似度算法,其核心是获取最大公共字符串等。由于上述方法都是简单地根据相同词语进行匹配,不能理解、应用词语的语义信息,因此不能有效检测出语义相同而用词不同的情况<citation id="268" type="reference"><link href="224" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。例如,给定2个句子:“今天天气很糟糕,已经开始下雨了。”“今天风雨交加、电闪雷鸣。”这2句话说的都是天气不好且正在下雨,但由于没有出现相同的词语,基于词匹配的技术不再适用。</p>
                </div>
                <h4 class="anchor-tag" id="61" name="61">1.2 基于深度学习的方法</h4>
                <div class="p1">
                    <p id="62">使用深度学习来辨识2个句子的相似度是目前常用的方法,其关键在于构建有效的词语层面和句子层面的特征表达。文献<citation id="269" type="reference">[<a class="sup">7</a>]</citation>使用分布式词向量表示方法进行建模,将每个词映射为一个固定长度的向量,并将其视为高维词向量空间的一个点,通过向量间的距离度量词汇间的相似性。文献<citation id="274" type="reference">[<a class="sup">8</a>,<a class="sup">9</a>]</citation>基于分布式词向量的概念提出Word2Vec技术,其已在很多NLP任务中取得了成功<citation id="270" type="reference"><link href="232" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。例如,文献<citation id="271" type="reference">[<a class="sup">11</a>]</citation>在Word2Vec词向量的基础上,通过句子变换矩阵来度量句子间的语义距离。然而,上述方法忽略了句子间的潜在特征,为了更准确地刻画出句子的语义特征,文献<citation id="272" type="reference">[<a class="sup">12</a>]</citation>基于稀疏自学习卷积神经网络,通过动态捕获句子各潜在特征的有效关联来进一步构建句子的向量表达,该方法取得了较好的效果。文献<citation id="273" type="reference">[<a class="sup">13</a>]</citation>通过卷积神经网络(Convolutional Neural Network,CNN)提取句子不同粒度的<i>n</i>-gram信息,使用门控循环单元(Gated Recurrent Unit,GRU)来集成句子的特征,在考虑词语层次信息的同时,综合句子的整体特征,以进一步提高识别准确率。</p>
                </div>
                <h4 class="anchor-tag" id="63" name="63">1.3 注意力机制</h4>
                <div class="p1">
                    <p id="64">结合注意力机制的CNN在图像领域已取得较多成果,例如,视觉问题回答<citation id="275" type="reference"><link href="240" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、图像分类<citation id="276" type="reference"><link href="242" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、图像字幕生成<citation id="277" type="reference"><link href="244" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>、图像分割<citation id="278" type="reference"><link href="246" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>、物体检测<citation id="279" type="reference"><link href="248" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>等。随后,很多基于注意力机制的循环神经网络模型(Recurrent Neural Network,RNN)的相关研究在NLP领域展开。例如:文献<citation id="283" type="reference">[<a class="sup">19</a>,<a class="sup">20</a>]</citation>将该技术用于机器翻译、文本重构;文献<citation id="280" type="reference">[<a class="sup">21</a>]</citation>使用时间递归神经网络在数据集SICK上进行语义推理;文献<citation id="281" type="reference">[<a class="sup">22</a>]</citation>将基于注意力机制的长短期记忆网络(Long Short-Term Memory,LSTM)进行文本语义推理。然而,目前多数相关研究是处理长序列问题的Seq2Seq模型,对于长度极短的问句,这些方法并不是最佳解决方案。同时,在以往研究中发现,CNN相比LSTM更具有优势。例如,文献<citation id="284" type="reference">[<a class="sup">19</a>,<a class="sup">20</a>]</citation>使用LSTM对整个句子进行编码,然后结合注意力机制,其丢失了部分词语及短语的信息;而文献<citation id="282" type="reference">[<a class="sup">23</a>]</citation>利用CNN的卷积特性来提取短语信息,其对于短文本的情感分析取得较好的效果。为了利用注意力机制更好地处理智能客服的短文本问句,本文提出基于注意力机制的CNN模型,其主要基于以下3点考虑:</p>
                </div>
                <div class="p1">
                    <p id="65">1)CNN能通过卷积核整合局部词语之间的语义关系,得到短语级别的信息,以更好地学习短语级别的注意力矩阵。</p>
                </div>
                <div class="p1">
                    <p id="66">2)尽管LSTM能将文本编码成结合上下文信息的向量表达,但其结构较复杂,训练模型的时间复杂度更高<citation id="285" type="reference"><link href="260" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="67">3)用户所提的问题语句通常较短,能供模型利用的上下文信息较少,擅长解决长序依赖问题的LSTM并不能充分发挥其优势。</p>
                </div>
                <h3 id="68" name="68" class="anchor-tag">2 MA-CNN模型</h3>
                <h4 class="anchor-tag" id="69" name="69">2.1 问题定义</h4>
                <div class="p1">
                    <p id="70">给定数据集<i>D</i>,其中,句子1的集合为<i>T</i>={<i>t</i><sub>1</sub>,<i>t</i><sub>2</sub>,…,<i>t</i><sub><i>m</i></sub>},句子2的集合为<i>K</i>={<i>k</i><sub>1</sub>,<i>k</i><sub>2</sub>,…,<i>k</i><sub><i>m</i></sub>},这2个句子的标签集合为<i>Y</i>={<i>y</i><sub>1</sub>,<i>y</i><sub>2</sub>,…,<i>y</i><sub><i>m</i></sub>},<i>y</i><sub><i>i</i></sub>∈{0,1}。MA-CNN模型的任务是判断(<i>t</i><sub><i>i</i></sub>,<i>k</i><sub><i>i</i></sub>)中的2个句子是否语义相同,如果相同则输出<i>y</i><sub><i>i</i></sub>=1,否则输出<i>y</i><sub><i>i</i></sub>=0。模型最终的目标函数如下:</p>
                </div>
                <div class="p1">
                    <p id="71"><i>p</i>(<i>Y</i>|<i>K</i>,<i>T</i>)=argmax <i>f</i>(<i>Y</i>|<i>K</i>,<i>T</i>;<i>θ</i>)      (1)</p>
                </div>
                <div class="p1">
                    <p id="72">其中,<i>f</i>表示本文模型,<i>θ</i>为模型中的参数集合。式(1)表示在给定句子对集合(<i>K</i>,<i>T</i>)的情况下,模型最大化其标签集合<i>Y</i>的概率。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73">2.2 模型构建</h4>
                <div class="p1">
                    <p id="74">图1所示为本文MA-CNN模型的结构示意图。由图1可知,MA-CNN模型基于2个并行的卷积神经网络来对问题<i>p</i>和问题<i>r</i>进行处理,其中,左边网络主要负责问题<i>p</i>,右边网络主要负责问题<i>r</i>。在进行卷积操作之前,使用注意力-1对问题<i>p</i>和问题<i>r</i>进行处理,使2个问题句子对应的Word2Vec词向量产生交互,进而捕捉其词级关系。在进行卷积操作之后,分别得到2个问题的整体抽象表达,再运用注意力-2使其产生交互,整合2个问题句子的整体语义信息。通过注意力-1、注意力-2的处理,MA-CNN模型能够捕捉2个问题之间的词级关系,同时结合两者的整体语义信息。最后,由2个并行网络分别得到问题<i>p</i>和问题<i>r</i>的向量表达<i><b>a</b></i>、<i><b>b</b></i>,将<i><b>a</b></i>、<i><b>b</b></i>、<mathml id="169"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">a</mi><mo>-</mo><mi mathvariant="bold-italic">b</mi></mrow><mo>|</mo></mrow></mrow></math></mathml>、<i><b>a</b></i>*<i><b>b</b></i>这4个向量进行拼接,其中,<mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">a</mi><mo>-</mo><mi mathvariant="bold-italic">b</mi></mrow><mo>|</mo></mrow></mrow></math></mathml>表示剔除2个问题相同的部分,保留相异的部分,<i><b>a</b></i>*<i><b>b</b></i>表示进行一次交互。将拼接结果放入logistic回归模型中,判断问题<i>p</i>和问题<i>r</i>的语义是否一致,如果一致则输出1,否则输出0,得到语义分类结果。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201909045_075.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 MA-CNN模型架构" src="Detail/GetImg?filename=images/JSJC201909045_075.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 MA-CNN模型架构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201909045_075.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="76" name="76">2.2.1 输入层</h4>
                <div class="p1">
                    <p id="77">将每个句子截取为固定长度<i>s</i>,不足长度的补0,本文模型的<i>s</i>值取40,用Word2Vec训练好的词向量进行映射,将每个句子表示为<i>d</i>×<i>s</i>维的向量,其中,<i>d</i>是词向量的维度,本文<i>d</i>值取256。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">2.2.2 词向量+注意力-1</h4>
                <div class="p1">
                    <p id="79">在词向量中加入注意力-1,主要是考虑2个句子在嵌入层词语之间的交互信息。假设<i><b>A</b></i><sup>1</sup>∈<image href="images/JSJC201909045_171.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>s</i></sup>×<i>s</i>表示2个句子注意力-1的特征矩阵,则<i><b>A</b></i><sup>1</sup>可以通过向量矩阵的单元匹配方式获得。矩阵<i><b>A</b></i><sup>1</sup>的第<i>i</i>行代表句子1第<i>i</i>个单元对句子2的注意力,矩阵<i><b>A</b></i><sup>1</sup>的第<i>j</i>列代表句子2第<i>j</i>个单元对句子1的注意力。假设<i><b>F</b></i><sub>0,</sub><i>r</i>∈<image href="images/JSJC201909045_172.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>×<i>s</i>代表句子1的词向量矩阵,<i><b>F</b></i><sub>1,</sub><i>r</i>∈<image href="images/JSJC201909045_173.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>×<i>s</i>代表句子2的词向量矩阵,则矩阵<i><b>A</b></i><sup>1</sup>的计算过程如下:</p>
                </div>
                <div class="p1">
                    <p id="80"><i><b>A</b></i><mathml id="174"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mn>1</mn></msubsup></mrow></math></mathml>=match-score(<i><b>F</b></i><sub>0,</sub><i>r</i>[:,<i>i</i>],<i><b>F</b></i><sub>1,</sub><i>r</i>[:,<i>j</i>])      (2)</p>
                </div>
                <div class="p1">
                    <p id="81">其中,match-score有欧几里得距离、余弦距离、点积3种策略可供选择,具体如下:</p>
                </div>
                <h4 class="anchor-tag" id="82" name="82">1)欧几里得距离</h4>
                <div class="p1">
                    <p id="83">match-score(<i><b>x</b></i>,<i>y</i>)=1/(1+|<i><b>x</b></i>-<i><b>y</b></i>|)      (3)</p>
                </div>
                <div class="p1">
                    <p id="84">其中,<i><b>x</b></i>、<i><b>y</b></i>分别表示句子1和句子2,是2个长度相等的一维特征向量。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85">2)余弦距离</h4>
                <div class="p1">
                    <p id="86">match-score(<i><b>x</b></i>,<i>y</i>)=1/(1+cos(<i><b>x</b></i>,<i>y</i>))      (4)</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87">3)点乘</h4>
                <div class="p1">
                    <p id="88">match-score(<i><b>x</b></i>,<i>y</i>)=1/(1+<i><b>x</b></i>·<i>y</i>)      (5)</p>
                </div>
                <div class="p1">
                    <p id="89">使用不同的match-score策略会对MA-CNN模型产生不同的影响。</p>
                </div>
                <div class="p1">
                    <p id="90">在得到注意力特征矩阵<i><b>A</b></i><sup>1</sup>后,将<i><b>A</b></i><sup>1</sup>与原句的词向量矩阵相乘,得到加入注意力后的向量表达。其中,<i><b>F</b></i><sub>0,</sub><i>a</i>表示句子1加入注意力后的向量表达,<i><b>F</b></i><sub>1,</sub><i>a</i>表示句子2加入注意力后的向量表达,计算过程如下:</p>
                </div>
                <div class="p1">
                    <p id="91"><i><b>F</b></i><sub>0,</sub><i>a</i>=<i><b>F</b></i><sub>0,</sub><i>r</i>·(<i><b>A</b></i><sup>1</sup>)<sup>T</sup>      (6)</p>
                </div>
                <div class="p1">
                    <p id="92"><i><b>F</b></i><sub>1,</sub><i>a</i>=<i><b>F</b></i><sub>1,</sub><i>r</i>·<i><b>A</b></i><sup>1</sup>      (7)</p>
                </div>
                <div class="p1">
                    <p id="93">句子新的向量表达<i><b>F</b></i><sub>0,</sub><i>a</i>、<i><b>F</b></i><sub>1,</sub><i>a</i>经过卷积层产生更高级的特征图。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94">2.2.3 卷积层</h4>
                <div class="p1">
                    <p id="95">卷积层由若干个尺寸固定的卷积核组成,通过卷积操作可实现参数共享,避免过拟合,提高训练速度,计算过程如下:</p>
                </div>
                <div class="p1">
                    <p id="96"><i>c</i><sub><i>i</i></sub>=<i>f</i>(<i>W</i>·<i><b>x</b></i><sub><i>i</i></sub>:<i>i</i>+<i>w</i>-1+<i>b</i>)      (8)</p>
                </div>
                <div class="p1">
                    <p id="97">其中,<i>c</i><sub><i>i</i></sub>表示输入的特征经过卷积后对应的第<i>i</i>个特征值,<i>f</i>表示非线性激活函数,本文使用常用的Relu函数,<i>W</i>表示滤波器的权重,<i>w</i>表示卷积核窗口大小,<i><b>x</b></i><sub><i>i</i></sub>:<i>i</i>+<i>w</i>-1表示句中第<i>i</i>个特征图到第<i>i</i>+<i>w</i>-1个特征图的向量表达,<i>b</i>表示偏置。采用多个卷积核进行训练,第<i>i</i>个卷积核的卷积结果为<i><b>C</b></i><sub><i>i</i></sub>,如下:</p>
                </div>
                <div class="p1">
                    <p id="98"><i><b>C</b></i><sub><i>i</i></sub>=[<i>c</i><sub>1</sub>,<i>c</i><sub>2</sub>,…,<i>c</i><sub><i>n</i></sub>-<i>w</i>+1]      (9)</p>
                </div>
                <div class="p1">
                    <p id="99">合并多个卷积核的结果可以得到经过卷积后第<i>i</i>个句子的卷积输出<i><b>F</b></i><mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>r</mi></mrow><mi>c</mi></msubsup></mrow></math></mathml>∈<image href="images/JSJC201909045_176.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>×(<i>s</i><sub><i>i</i></sub>+<i>w</i>-1),<i>d</i>为卷积核的个数,<i><b>F</b></i><mathml id="177"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>r</mi></mrow><mi>c</mi></msubsup></mrow></math></mathml>的计算如下:</p>
                </div>
                <div class="p1">
                    <p id="100"><i><b>F</b></i><mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>r</mi></mrow><mi>c</mi></msubsup></mrow></math></mathml>=[<i><b>C</b></i><sub>1</sub>,<i><b>C</b></i><sub>2</sub>,…,<i><b>C</b></i><sub><i>n</i></sub>-<i>w</i>+1]      (10)</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101">2.2.4 卷积层+注意力-2</h4>
                <div class="p1">
                    <p id="102">在卷积操作后加入注意力-2,通过注意力-2对卷积层的输出添加不同的权重,使得MA-CNN模型能够更好地辨识句子1和句子2。</p>
                </div>
                <div class="p1">
                    <p id="103">假设注意力-2的矩阵为<i><b>A</b></i><sup>2</sup>∈<image href="images/JSJC201909045_179.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>s</i></sup>×<i>s</i>,<i>a</i><sub>0,</sub><i>j</i>=∑<i><b>A</b></i><sup>2</sup>[<i>j</i>,:]表示句子1中第<i>j</i>个单元的注意力权重,一个卷积核覆盖的区域为1个单元。<i>a</i><sub>1,</sub><i>j</i>=∑<i><b>A</b></i><sup>2</sup>[:,<i>j</i>]表示句子2中第<i>j</i>个单元的注意力权重。<i><b>F</b></i><mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>r</mi></mrow><mi>c</mi></msubsup></mrow></math></mathml>∈<image href="images/JSJC201909045_181.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>×(<i>s</i><sub><i>i</i></sub>+<i>w</i>-1)是句子<i>i</i>的卷积输出。第<i>j</i>列的特征<i><b>F</b></i><mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>r</mi></mrow><mi>p</mi></msubsup></mrow></math></mathml>∈<image href="images/JSJC201909045_183.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>×<i>s</i><sub><i>i</i></sub>由以下特征生成:</p>
                </div>
                <div class="p1">
                    <p id="104"><i><b>F</b></i><mathml id="184"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>r</mi></mrow><mi>p</mi></msubsup></mrow></math></mathml>[:,<mathml id="185"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>j</mi><mo stretchy="false">]</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mi>j</mi><mo>:</mo><mi>j</mi><mo>+</mo><mi>w</mi></mrow></munder><mi>a</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>k</mi></mrow></msub><mo>⋅</mo><mi mathvariant="bold-italic">F</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>r</mi></mrow><mi>c</mi></msubsup></mrow></math></mathml>[:,<i>k</i>],<i>j</i>=1,2,…,<i>s</i><sub><i>i</i></sub>      (11)</p>
                </div>
                <div class="p1">
                    <p id="105">其中,<i><b>F</b></i><mathml id="186"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>r</mi></mrow><mi>p</mi></msubsup></mrow></math></mathml>∈<image href="images/JSJC201909045_187.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>×<i>s</i><sub><i>i</i></sub>表示对卷积层加入注意力-2之后的输出。将<i><b>F</b></i><mathml id="188"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>r</mi></mrow><mi>p</mi></msubsup></mrow></math></mathml>输入到下一层,继续进行上卷积+注意力-2操作,如果是最后一层,则进行池化操作,依次在完成卷积后对卷积输入结果加注意力的操作。</p>
                </div>
                <h4 class="anchor-tag" id="106" name="106">2.2.5 池化层</h4>
                <div class="p1">
                    <p id="107">非线性池化的方式有很多,例如平均池化、最小池化、最大池化等。本文采用平均池化的方式对最后一层卷积层的输出进行处理,从而得到每个句子的向量表达。对于不是最后一层的卷积输出,则按照一定的步长进行平均池化,然后继续进行卷积操作。</p>
                </div>
                <h4 class="anchor-tag" id="108" name="108">2.2.6 全连接层</h4>
                <div class="p1">
                    <p id="109">经过卷积操作之后,得到2个句子的抽象表达向量<i><b>a</b></i>和<i><b>b</b></i>,进行如下操作后将其输入全连接层:</p>
                </div>
                <div class="p1">
                    <p id="110"><i>m</i>=[<i><b>a</b></i>,<i>b</i>,<i>a</i>-<i><b>b</b></i>,<i>a</i>*<i><b>b</b></i>]      (12)</p>
                </div>
                <div class="p1">
                    <p id="111">其中,<mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">a</mi><mo>-</mo><mi mathvariant="bold-italic">b</mi></mrow><mo>|</mo></mrow></mrow></math></mathml>使得<i>MA</i>-<i>CNN</i>模型能够关<citation id="286" type="reference"><link href="216" rel="bibliography" />注2</citation>个问题相异的细节,<i><b>a</b></i>*<i><b>b</b></i>能够在抽象的语义空间中进一步考虑2个问题句子的语言含义,充分结合其整体的语义关系。</p>
                </div>
                <h4 class="anchor-tag" id="112" name="112">2.3 训练方法</h4>
                <div class="p1">
                    <p id="113">本模型损失函数设置为在训练样本上的负对数似然函数<i>L</i>(<i>θ</i>),计算过程式如下:</p>
                </div>
                <div class="p1">
                    <p id="114"><i>L</i>(<i>θ</i>)=-lb <i>P</i>(<i>D</i>|<i>θ</i>)      (13)</p>
                </div>
                <div class="p1">
                    <p id="115">其中,<i>θ</i>为模型参数,<i>D</i>表示整个训练集。<i>P</i>(<i>D</i>|<i>θ</i>)表示在参数为<i>θ</i>时,模型在训练集上的似然。本模型是一个二分类问题,标签为1的概率为<i>P</i><sub><i>θ</i></sub>(<i>s</i>)=lb <i>P</i>(<i>y</i>=1|<i>x</i>=<i>s</i>;<i>θ</i>),标签为0的概率为1-<i>P</i><sub><i>θ</i></sub>(<i>s</i>),则有如下公式:</p>
                </div>
                <div class="p1">
                    <p id="116"><mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>l</mtext><mtext>b</mtext><mtext> </mtext><mi>Ρ</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">|</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow></mrow></munderover><mi>y</mi></mstyle><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>⋅</mo><mtext>l</mtext><mtext>b</mtext><mtext> </mtext><mi>Ρ</mi><mo stretchy="false">(</mo><mi>y</mi><mo>=</mo><mn>1</mn><mo stretchy="false">|</mo><mi>x</mi><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>;<i>θ</i>)+</p>
                </div>
                <div class="p1">
                    <p id="117">(1-<i>y</i><sub><i>si</i></sub>)·lb <i>P</i>(<i>y</i>=0|<i>x</i>=<i>s</i><sub><i>i</i></sub>;<i>θ</i>)      (14)</p>
                </div>
                <div class="p1">
                    <p id="118">其中,标签<i>y</i><sub><i>si</i></sub>取值为0或1,取值为0表示2个句子语义不同,取值为1则表示2个句子语义相同。为了使损失函数最小化,本文采用Adam算法对模型进行优化。为了防止过拟合,利用L2正则化对全局网络进行约束,同时,在全连接层与卷积层引入神经元随机失活机制,每次迭代随机放弃一些训练完成的参数。</p>
                </div>
                <h3 id="119" name="119" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="120" name="120">3.1 实验流程</h4>
                <div class="p1">
                    <p id="121">本文实验流程具体分为如下5个步骤:</p>
                </div>
                <div class="p1">
                    <p id="122"><b>步骤1</b> 通过结巴分词与停用词过滤,得到分词之后的结果。</p>
                </div>
                <div class="p1">
                    <p id="123"><b>步骤2</b> 过滤掉词频小于5的词,建立词典。</p>
                </div>
                <div class="p1">
                    <p id="124"><b>步骤3</b> 利用Word2Vec技术训练得到词向量。</p>
                </div>
                <div class="p1">
                    <p id="125"><b>步骤4</b> 将2个句子截断到长度40,不足40的补0,将截断后所对应的词向量输入模型中进行分类。</p>
                </div>
                <div class="p1">
                    <p id="126"><b>步骤5</b> 对模型的分类结果进行评估。</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127">3.2 实验数据</h4>
                <div class="p1">
                    <p id="128">本文实验数据来自某公司真实客服数据,共100 000个问题对,其中正负样本比为1∶4,句子平均长度为15,最大长度为97。实验数据样例如表1所示,标签0表示2个句子意思不同,标签1表示2个句子意思相同。</p>
                </div>
                <div class="area_img" id="129">
                    <p class="img_tit"><b>表1 实验数据样例</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="129" border="1"><tr><td><br />问题1</td><td>问题2</td><td>标签</td></tr><tr><td><br />花呗收钱码手续费</td><td>如何开通收钱码花呗收钱</td><td>0</td></tr><tr><td><br />借呗,怎么借不了钱</td><td>我借呗开通了,为什么借不了钱</td><td>1</td></tr><tr><td><br />花呗怎么样分期付款</td><td>花呗分期利息怎么算</td><td>0</td></tr><tr><td><br />怎么提高借呗</td><td>借呗怎么可以涨额度呀</td><td>1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="130">由表1数据可知,负样本并不是毫无关系的2个句子,而是句式、用词极其相似但语义不同的句子,且这些数据都是用户的提问语句,具有咨询意图复杂、上下文相关性弱、问题多样、指代缺失、口语化严重等特点。在该数据集上进行实验,模型的识别难度增加,更能验证本文MA-CNN模型的有效性。</p>
                </div>
                <h4 class="anchor-tag" id="131" name="131">3.3 实验环境</h4>
                <div class="p1">
                    <p id="132">本文实验环境的具体信息见表2。</p>
                </div>
                <div class="area_img" id="133">
                    <p class="img_tit"><b>表2 本文实验环境</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="133" border="1"><tr><td><br />软硬件</td><td>配置</td></tr><tr><td><br />CPU</td><td>Intel(R) Xeon(R) CPU E5-46070</td></tr><tr><td><br />CPU频率/GHz</td><td>2.20</td></tr><tr><td><br />核心数</td><td>24</td></tr><tr><td><br />内存/GB</td><td>32</td></tr><tr><td><br />操作系统</td><td>Ubuntu 16.04.3 LTS</td></tr><tr><td><br />开发环境</td><td>Anaconda 4.3.0</td></tr><tr><td><br />深度学习框架</td><td>Keras 2.1.5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="134" name="134">3.4 评价指标</h4>
                <div class="p1">
                    <p id="135">本文实验采用精确率(<i>precision</i>)、召回率(<i>recall</i>)、<i>F</i>1值作为评价指标,其计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="136" class="code-formula">
                        <mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>t</mi><mi>p</mi></mrow><mrow><mi>t</mi><mi>p</mi><mo>+</mo><mi>f</mi><mi>p</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>t</mi><mi>p</mi></mrow><mrow><mi>t</mi><mi>p</mi><mo>+</mo><mi>f</mi><mi>n</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>F</mi><mn>1</mn><mo>=</mo><mfrac><mrow><mn>2</mn><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>⋅</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="137">其中,<i>tp</i>表示真正例数量,<i>fp</i>表示假正例数量,<i>fn</i>表示假反例数量。</p>
                </div>
                <h4 class="anchor-tag" id="138" name="138">3.5 词向量训练</h4>
                <div class="p1">
                    <p id="139">本文使用Gemsim开源的Word2Vec工具对训练语料进行词向量训练,Word2Vec采用CBOW模型,上下文窗口大小设置为5,最小词频设置为3,词向量维度大小设为256,采样值大小设为0.001。对于不在词典中的词、补长的词,则采用随机初始化方式进行表示。</p>
                </div>
                <h4 class="anchor-tag" id="140" name="140">3.6 超参数设置与训练</h4>
                <div class="p1">
                    <p id="141">在本文的网络结构中,Batch size设置为128,激活函数采用Relu,学习率设为0.005,Dropout比率设为0.5。根据Adam优化方法的经验值<citation id="287" type="reference"><link href="262" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>,1层～3层卷积核窗口大小分别取3、4、5,模型层数与卷积核个数通过5折交叉验证得到。实验epoch初始值设置为20,下文中的epoch值表示取得最佳<i>F</i>1值时所对应的训练轮数,卷积核层数、个数不同时的实验结果分别如表3、表4所示。</p>
                </div>
                <div class="area_img" id="142">
                    <p class="img_tit"><b>表3 卷积核层数不同时的结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="142" border="1"><tr><td>卷积核层数</td><td>参数个数</td><td>epoch</td><td>精确率</td><td>召回率</td><td><i>F</i>1值</td></tr><tr><td>1</td><td>1 140 487</td><td>9</td><td>0.319</td><td>0.746</td><td>0.447</td></tr><tr><td><br />2</td><td>1 798 407</td><td>12</td><td>0.412</td><td>0.637</td><td>0.501</td></tr><tr><td><br />3</td><td>2 325 255</td><td>13</td><td>0.391</td><td>0.668</td><td>0.493</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="143">
                    <p class="img_tit"><b>表4 卷积核个数不同时的结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="143" border="1"><tr><td>卷积核个数</td><td>参数个数</td><td>epoch</td><td>精确率</td><td>召回率</td><td><i>F</i>1值</td></tr><tr><td>64</td><td>590 343</td><td>9</td><td>0.390</td><td>0.650</td><td>0.168</td></tr><tr><td><br />128</td><td>911 111</td><td>9</td><td>0.375</td><td>0.713</td><td>0.492</td></tr><tr><td><br />256</td><td>1 798 407</td><td>12</td><td>0.412</td><td>0.637</td><td>0.501</td></tr><tr><td><br />512</td><td>4 556 039</td><td>2</td><td>0.371</td><td>0.663</td><td>0.476</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="144">由表3可知,2层效果比1层好,3层与2层的差别不大,但是考虑到3层参数比2层多很多,有过拟合的风险,所以认为最佳层数为2层。由表4可知,卷积核个数为128、256时的效果差不多,但是256个卷积核所对应的模型参数为1 798 407,其参数量约为128个卷积核模型的2倍,这不仅需要更多的迭代次数,而且存在过拟合的风险,因此认为128个卷积核时效果较好。综合表3、表4的分析结果,本文MA-CNN模型均采用2层结构、卷积核个数为128个。</p>
                </div>
                <h4 class="anchor-tag" id="145" name="145">3.7 结果分析</h4>
                <h4 class="anchor-tag" id="146" name="146">3.7.1 有效性验证</h4>
                <div class="p1">
                    <p id="147">本文对3种不同模型的实验结果进行对比,具体如下:</p>
                </div>
                <div class="p1">
                    <p id="148">1)No-Att模型:不加注意力机制。</p>
                </div>
                <div class="p1">
                    <p id="149">2)Att-1模型:在词嵌入过程中加入注意力-1的操作。</p>
                </div>
                <div class="p1">
                    <p id="150">3)Att-1-2模型:在词嵌入注意力-1的同时,在卷积层之后加入注意力-2的操作。</p>
                </div>
                <div class="p1">
                    <p id="151">表5给出这3种模型的实验结果对比。</p>
                </div>
                <div class="area_img" id="152">
                    <p class="img_tit"><b>表5 3种模型的实验结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="152" border="1"><tr><td>模型</td><td>参数个数</td><td>epoch</td><td>精确率</td><td>召回率</td><td><i>F</i>1值</td></tr><tr><td><br />No-Att</td><td>1 384 199</td><td>13</td><td>0.308</td><td>0.681</td><td>0.424</td></tr><tr><td><br />Att-1</td><td>1 796 359</td><td>13</td><td>0.394</td><td>0.579</td><td>0.469</td></tr><tr><td><br />Att-1-2</td><td>1 798 407</td><td>12</td><td>0.412</td><td>0.637</td><td>0.501</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="153">如上文可知,注意力-1的主要作用是考虑词语层面的信息,通过标签的正确引导,减小用户问句中错别字及不规范表达的权重。注意力-2侧重于捕捉2个问题句子间潜在的关联特征,在标签的指导下减小指代缺失短语的权重,从而解决指代缺失的问题。结合表5进行分析,No-Att模型的精确率、召回率、<i>F</i>1值均低于加入注意力机制的Att-1、Att-1-2模型,证明了注意力机制的有效性。其中,Att-1-2模型的<i>F</i>1值为0.501,与Att-1模型的<i>F</i>1值相比提升了6.82%。这是因为Att-1-2模型通过卷积层前后2次注意力机制,既能捕捉词语层次之间的交互信息,又能提取到整体语义信息,而Att-1模型只能捕获词语层次之间的交互信息,未能透彻地理解整个问题句子的含义。从另一个角度来分析,Att-1-2模型拥有更多的参数供激活函数以更复杂的非线性方式来表达语义信息,从而取得较好的结果。</p>
                </div>
                <h4 class="anchor-tag" id="154" name="154">3.7.2 match-score对模型的影响</h4>
                <div class="p1">
                    <p id="155">在生成注意力矩阵<i><b>A</b></i><sup>1</sup>的阶段,共有余弦相似度、点乘、欧几里得距离3种策略。本文分别对这3种策略进行对比实验,结果如表6所示。</p>
                </div>
                <div class="area_img" id="156">
                    <p class="img_tit"><b>表6 match-score 3种不同策略的结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="156" border="1"><tr><td>策略</td><td>参数个数</td><td>epoch</td><td>精确率</td><td>召回率</td><td><i>F</i>1值</td></tr><tr><td>欧几里得距离</td><td>1 798 407</td><td>3</td><td>0.179</td><td>1.000</td><td>0.304</td></tr><tr><td><br />点乘</td><td>1 798 407</td><td>12</td><td>0.438</td><td>0.561</td><td>0.492</td></tr><tr><td><br />余弦相似度</td><td>1 798 407</td><td>3</td><td>0.412</td><td>0.637</td><td>0.501</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="157">从表6可以看出,使用欧几里得距离训练3轮就可以得到该策略对应最佳的<i>F</i>1值,但是时间复杂度较高。使用点乘策略训练12轮,得到的<i>F</i>1值能比欧几里得距离策略提高61%。同时,余弦相似度策略在轮数、精确率、召回率、<i>F</i>1值方面均优于点乘和欧几里得距离策略,因此,本文使用余弦相似度策略进行实验。</p>
                </div>
                <h4 class="anchor-tag" id="158" name="158">3.7.3 与传统模型的对比</h4>
                <div class="p1">
                    <p id="159">传统模型通常先将问题<i>p</i>和问题<i>r</i>分别通过词向量映射求平均得到2个一维向量<i><b>P</b></i>和<i><b>R</b></i>。然后通过不同的向量相似度公式计算<i><b>P</b></i>和<i><b>R</b></i>的相似度<i>S</i>,<i>S</i>∈[0,1]。相似度<i>S</i>越接近于0,表明问题<i>p</i>和问题<i>r</i>越不相似;S越接近于1,表明问题<i>p</i>和问题<i>r</i>越相似。本文将8种采用不同相似度公式的传统模型与MA-CNN模型进行对比,结果如表7所示。</p>
                </div>
                <div class="area_img" id="160">
                    <p class="img_tit"><b>表7 本文模型与8种传统模型的结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="160" border="1"><tr><td>模型</td><td>精确率</td><td>召回率</td><td><i>F</i>1值</td></tr><tr><td><br />minkowski</td><td>0.141</td><td>0.118</td><td>0.128</td></tr><tr><td><br />euclidean</td><td>0.141</td><td>0.118</td><td>0.128</td></tr><tr><td><br />cos</td><td>0.150</td><td>0.191</td><td>0.168</td></tr><tr><td><br />braycurtis</td><td>0.162</td><td>0.549</td><td>0.250</td></tr><tr><td><br />编辑距离</td><td>0.165</td><td>0.807</td><td>0.274</td></tr><tr><td><br />cityblock</td><td>0.176</td><td>0.909</td><td>0.296</td></tr><tr><td><br />jaccard</td><td>0.179</td><td>0.960</td><td>0.302</td></tr><tr><td><br />canberra</td><td>0.179</td><td>0.960</td><td>0.302</td></tr><tr><td><br />MA-CNN</td><td>0.412</td><td>0.637</td><td>0.501</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="161">由表7可知,在8个传统模型中,表现最优的是jaccard和canberra模型,其<i>F</i>1值均达到0.302,但是与本文MA-CNN模型相比,<i>F</i>1值降低了65.89%,MA-CNN模型具有明显优势。该结果再次表明,传统模型只关注词语层次之间的关系,无法有效识别相似度较高的2个句子。相反,基于深度学习的MA-CNN模型通过多角度的注意力机制,能够整合词语之间、句子之间的关系,学习到深度的语义信息,可更好地辨识2个句子间的语义相关性,进而准确地识别出2个句式相似、口语化严重的句子是否语义相同。</p>
                </div>
                <h4 class="anchor-tag" id="162" name="162">3.7.4 与RNN模型的对比</h4>
                <div class="p1">
                    <p id="163">本文还将MA-CNN模型与4种不同的RNN模型进行对比,其中Batch size设置为128,激活函数采用Relu,学习率设为0.005,Dropout的比率设为0.5,RNN的隐层单元数为150,实验结果如表8所示。</p>
                </div>
                <div class="area_img" id="164">
                    <p class="img_tit"><b>表8 本文模型与4种RNN模型的结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="164" border="1"><tr><td><br />模型</td><td>精确率</td><td>召回率</td><td><i>F</i>1值</td></tr><tr><td><br />Si-LSTM</td><td>0.200</td><td>0.002</td><td>0.003</td></tr><tr><td><br />Si-GRU</td><td>0.269</td><td>0.514</td><td>0.353</td></tr><tr><td><br />Bi-LSTM</td><td>0.309</td><td>0.411</td><td>0.353</td></tr><tr><td><br />Bi-GRU</td><td>0.337</td><td>0.518</td><td>0.408</td></tr><tr><td><br />MA-CNN</td><td>0.412</td><td>0.637</td><td>0.501</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="165">由表8可知,单向RNN模型不如双向RNN模型,这是因为双向结构可以从2个不同的角度挖掘文本内在信息。从整体上来看,LSTM模型不如GRU模型,这是因为GRU模型的参数较少,更能避免过拟合现象。</p>
                </div>
                <div class="p1">
                    <p id="166">在这4种RNN模型中,表现最佳的是双向GRU模型Bi-GRU,其<i>F</i>1值达到0.408,但是与MA-CNN模型的<i>F</i>1值相比低了22.79%。这一结果再次表明,由于智能客服问答系统中的问句大多是短文本,没有足够长的文本供RNN模型充分发挥其记忆特性,因此采用基于CNN结构的MA-CNN模型比采用RNN模型效果更佳。</p>
                </div>
                <h3 id="167" name="167" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="168">本文基于多注意力机制建立深度学习模型MA-CNN,综合考虑2个句子间词语层次、句子级别的深层语义信息,帮助智能客服多层次、多角度、多粒度地理解用户所提问句,从而减少答非所问的情况。实验结果表明,MA-CNN模型能够有效提高对问句的辨识能力,融入多注意力机制存在其合理性。下一步将使用跨语言的数据集,并在注意力机制上做相应的调整,以增强MA-CNN模型的泛化能力,使其能够在跨语言数据集上同样取得较好的效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="214">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;A short texts matching method using shallow features and deep features,&amp;quot;">

                                <b>[1]</b> KANG Longbiao,HU Baotian,WU Xiangping,et al.A short texts matching method using shallow features and deep features[C]//Proceedings of Natural Language Processing and Chinese Computing.Berlin,Germany:Springer,2014:150-159.
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Dataset for Research on Short-Text Conversation">

                                <b>[2]</b> WANG Hao,LU Zhengdong,LI Hang,et al.A dataset for research on short-text conversations[C]//Proceedings of Conference on Empirical Methods in Natural Language Processing.Stroudsburg,USA:Association for Computational Linguistics,2013:935-945.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Short Text Similarity with Word Embeddings">

                                <b>[3]</b> KENTER T,RIJKE M D.Short text similarity with word embeddings[C]//Proceedings of ACM International on Conference on Information and Knowledge Management.New York,USA:ACM Press,2015:1411-1420.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recognizing textual entailment using lexical similarity">

                                <b>[4]</b> JIJKOUN V,RIJKE M D.Recognizing textual entailment using lexical similarity [EB/OL].[2018-07-01].http://u.cs.biu.ac.il/～nlp/RTE1/Proceedings/jijkoun_and_de_rijke.pdf.
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000093166&amp;v=MDU0NzA0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMcklKbDBWYWhJPU5pZklZN0s3SHRqTnI0OUZaT0lNRFhvL29CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> ISLAM A,INKPEN D.Semantic text similarity using corpus-based word similarity and string similarity [J].ACM Transactions on Knowledge Discovery from Data,2008,2(2):1-25.
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=From word embeddings to document distances">

                                <b>[6]</b> KUSNER M J,SUN Yu,KOLKIN N I,et al.From word embeddings to document distances[C]//Proceedings of the 32nd International Conference on Machine Learning.New York,USA:ACM Press,2015:957-966.
                            </a>
                        </p>
                        <p id="226">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning representations by back-propagating errors">

                                <b>[7]</b> RUMELHART D E,HINTON G E,WILLIAMS R J.Learning representations by back-propagating errors[J].Nature,1986,323(6088):399-421.
                            </a>
                        </p>
                        <p id="228">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                 MIKOLOV T,CHEN Kai,CORRADO G,et al.Efficient estimation of word representations in vector space[EB/OL].[2018-07-01].https://arxiv.org/abs/1301.3781.
                            </a>
                        </p>
                        <p id="230">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 MIKOLOV T,SUTSKEVER I,CHEN Kai,et al.Distributed representations of words and phrases and their compositionality[C]//Proceedings of the 26th International Conference on Neural Information Processing Systems.New York,USA:ACM Press,2013:3111-3119.
                            </a>
                        </p>
                        <p id="232">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Don&amp;#39;&amp;#39;t count,predict!A systematic comparison of context-counting vs.context-predicting semantic vectors">

                                <b>[10]</b> BARONI M,DINU G,KRUSZEWSKI G.Don’t count,predict! a systematic comparison of context-counting vs.context-predicting semantic vectors[C]//Proceedings of Meeting of the Association for Computational Linguistics.Stroudsburg,USA:Association for Computational Linguistics,2014:238-247.
                            </a>
                        </p>
                        <p id="234">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCLH201606028&amp;v=MjIwNTA1NE8zenFxQnRHRnJDVVJMT2VaZVJyRnk3bVVyL0lOaTdIWnJHNEg5Zk1xWTlIYklRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 黄江平,姬东鸿.基于句子语义距离的释义识别研究[J].四川大学学报(工程科学版),2016,48(6):202-207.
                            </a>
                        </p>
                        <p id="236">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201801016&amp;v=MTQ4Mjc0SDluTXJvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeTdtVXIvSUx5dlNkTEc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 高云龙,左万利,王英,等.基于稀疏自学习卷积神经网络的句子分类模型[J].计算机研究与发展,2018,55(1):179-187.
                            </a>
                        </p>
                        <p id="238">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201813027&amp;v=MDE2NjZPZVplUnJGeTdtVXIvSUx6N01hYkc0SDluTnJJOUhZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 张琦,彭志平.融合注意力机制和CNN-GRNN模型的读者情绪预测[J].计算机工程与应用,2018,54(13):168-174.
                            </a>
                        </p>
                        <p id="240">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ABC-CNN:an attention based convolutional neural network for visual question answering">

                                <b>[14]</b> CHEN Kai,WANG Jiang,CHEN Liangchieh,et al.ABC-CNN:an attention based convolutional neural network for visual question answering[EB/OL].[2018-07-01].https://arxiv.org/pdf/1511.05960.pdf.
                            </a>
                        </p>
                        <p id="242">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The application of two-level attention models in deep convolutional neural network for fine-grained image classification">

                                <b>[15]</b> XIAO Tianjun,XU Yichong,YANG Kuiyuan,et al.The application of two-level attention models in deep convolutional neural network for fine-grained image classification[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C.,USA:IEEE Press,2015:842-850.
                            </a>
                        </p>
                        <p id="244">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1018088263.nh&amp;v=MTQ5MzVtVXIvSVZGMjZGck93RnRQS3JKRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeTc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 徐俊.基于视觉的文本生成方法研究[D].合肥:中国科学技术大学,2018.
                            </a>
                        </p>
                        <p id="246">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1012018441.nh&amp;v=MDM1MTE0TzN6cXFCdEdGckNVUkxPZVplUnJGeTdtVXIvSVZGMjZITE81RnRYSXJwRWJQSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 李青山.基于注意力选择机制的图像分割与场景理解[D].上海:上海交通大学,2012.
                            </a>
                        </p>
                        <p id="248">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Look and think twice:capturing top-down visual attention with feedback convolutional neural networks">

                                <b>[18]</b> CAO Chunshui,LIU Xianming,YANG Yi,et al.Look and think twice:capturing top-down visual attention with feedback convolutional neural networks[C]//Proceedings of 2015 IEEE International Conference on Computer Vision.Washington D.C.,USA:IEEE Press,2015:2956-2964.
                            </a>
                        </p>
                        <p id="250">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">

                                <b>[19]</b> BAHDANAU D,CHO K,BENGIO Y.Neural machine trans-lation by jointly learning to align and translate[EB/OL].[2018-07-01].https://arxiv.org/pdf/140 9.0473v6.pdf.
                            </a>
                        </p>
                        <p id="252">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201704006&amp;v=MjE0ODRkckc0SDliTXE0OUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnJGeTdtVXIvSUx6N0I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 刘宇鹏,马春光,张亚楠.深度递归的层次化机器翻译模型[J].计算机学报,2017,40(4):861-871.
                            </a>
                        </p>
                        <p id="254">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recursive neural networks can learn logical semantics">

                                <b>[21]</b> BOWMAN S R,POTTS C,MANNING C D.Recursive neural networks can learn logical semantics[EB/OL].[2018-07-01].https://arxiv.org/pdf/1406.1827.pdf.
                            </a>
                        </p>
                        <p id="256">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reasoning about entailment with neural attention">

                                <b>[22]</b> ROCKTÄSCHEL T,GREFENSTETTE E,HERMANN K M,et al.Reasoning about entailment with neural attention[EB/OL].[2018-07-01].https://arxiv.org/pdf/1509.06664.pdf.
                            </a>
                        </p>
                        <p id="258">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201805034&amp;v=MjI5MTN5N21Vci9JTHo3U1pMRzRIOW5NcW85R1lJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b> 冯兴杰,张志伟,史金钏.基于卷积神经网络和注意力模型的文本情感分析[J].计算机应用研究,2018,35(5):1434-1436.
                            </a>
                        </p>
                        <p id="260">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Comparative study of cnn and rnn for natural language processing">

                                <b>[24]</b> YIN WENPENG,KANN K,YU Mo,et al.Comparative study of cnn and rnn for natural language processing[EB/OL].[2018-07-01].https://arxiv.org/pdf/1702.01923.pdf.
                            </a>
                        </p>
                        <p id="262">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">

                                <b>[25]</b> KIM Y.Convolutional neural networks for sentence classification[EB/OL].[2018-07-01].https://arxiv.org/pdf/1408.5882.pdf.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201909045" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201909045&amp;v=MDQ3NTFNcG85QllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSckZ5N21Vci9KTHo3QmJiRzRIOWo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU4rdTgranNhVWF6RlJDekN5TVU4dz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
