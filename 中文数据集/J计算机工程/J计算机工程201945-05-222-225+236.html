<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130530914717500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201905036%26RESULT%3d1%26SIGN%3d6uULFafxJty6DpTzpwrzA2M1ehY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201905036&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201905036&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201905036&amp;v=MTI5ODdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkzbFdyL0lMejdCYmJHNEg5ak1xbzlHWW9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#39" data-title="1 相关知识 ">1 相关知识</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#40" data-title="1.1 自编码器">1.1 自编码器</a></li>
                                                <li><a href="#48" data-title="1.2 稀疏编码">1.2 稀疏编码</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#60" data-title="2 无监督的稀疏哈希图像检索算法 ">2 无监督的稀疏哈希图像检索算法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#99" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#100" data-title="3.1 实验环境">3.1 实验环境</a></li>
                                                <li><a href="#106" data-title="3.2 结果分析">3.2 结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#108" data-title="&lt;b&gt;表1 CIFAR-10数据集上不同算法平均准确率对比&lt;/b&gt;"><b>表1 CIFAR-10数据集上不同算法平均准确率对比</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;表2 YouTube Faces数据集上不同算法平均准确率对比&lt;/b&gt;"><b>表2 YouTube Faces数据集上不同算法平均准确率对比</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;图1 CIFAR-10数据集上不同算法查准率-召回率曲线对比结果&lt;/b&gt;"><b>图1 CIFAR-10数据集上不同算法查准率-召回率曲线对比结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" ZHENG Zhaohui, WU Xiaoyun, SRIHARI R, et al.Feature selection for text categorization on imbalanced data[J].ACM SIGKDD Explorations Newsletter, 2004, 6 (1) :80-89." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000085402&amp;v=MTExMDJNS0NIdzdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMbklKVjRkYWhJPU5pZklZN0s3SHRqTnI0OUZaTw==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         ZHENG Zhaohui, WU Xiaoyun, SRIHARI R, et al.Feature selection for text categorization on imbalanced data[J].ACM SIGKDD Explorations Newsletter, 2004, 6 (1) :80-89.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 杨定中, 陈心浩.基于投影残差量化哈希的近似最近邻搜索[J].计算机工程, 2015, 41 (12) :161-165, 170." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201512031&amp;v=MjczMDk5VE5yWTlHWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkzbFdyL0lMejdCYmJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         杨定中, 陈心浩.基于投影残差量化哈希的近似最近邻搜索[J].计算机工程, 2015, 41 (12) :161-165, 170.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 柯圣财, 赵永威, 李弼程, 等.基于卷积神经网络和监督核哈希的图像检索方法[J].电子学报, 2017, 45 (1) :157-163." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201701022&amp;v=MzExMTR6cXFCdEdGckNVUkxPZVplUm9GeTNsV3IvSUlUZlRlN0c0SDliTXJvOUhab1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         柯圣财, 赵永威, 李弼程, 等.基于卷积神经网络和监督核哈希的图像检索方法[J].电子学报, 2017, 45 (1) :157-163.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" LIU Wei, MU Cun, KUMAR S, et al.Discrete graph hashing[C]//Proceedings of the 27th International Conference on Neural Information Processing Systems.Cambridge, USA:MIT Press, 2014:3419-3427." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discrete graph hashing">
                                        <b>[4]</b>
                                         LIU Wei, MU Cun, KUMAR S, et al.Discrete graph hashing[C]//Proceedings of the 27th International Conference on Neural Information Processing Systems.Cambridge, USA:MIT Press, 2014:3419-3427.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 赵文星.变系数部分线性模型的统计推断[D].南京:南京信息工程大学, 2015." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015639681.nh&amp;v=MTk3ODFyQ1VSTE9lWmVSb0Z5M2xXci9JVkYyNkc3VzdGOWZFcnBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         赵文星.变系数部分线性模型的统计推断[D].南京:南京信息工程大学, 2015.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" XU Jun, XIANG Lei, LIU Qinshan, et al.Stacked sparse autoencoder for nuclei detection on breast cancer histopathology images[J].IEEE Transactions on Medical Imaging, 2015, 35 (1) :119-130." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stacked Sparse Auto Encoder (SSAE)for nuclei detection on breast cancer histopathology images">
                                        <b>[6]</b>
                                         XU Jun, XIANG Lei, LIU Qinshan, et al.Stacked sparse autoencoder for nuclei detection on breast cancer histopathology images[J].IEEE Transactions on Medical Imaging, 2015, 35 (1) :119-130.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" LI Hongmin, LIU Hanchao, JI Xiangyang, et al.CIFAR10-DVS:an event-stream dataset for object classification [EB/OL].[2018-02-05].https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5447775/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CIFAR10-DVS:an event-stream dataset for object classification">
                                        <b>[7]</b>
                                         LI Hongmin, LIU Hanchao, JI Xiangyang, et al.CIFAR10-DVS:an event-stream dataset for object classification [EB/OL].[2018-02-05].https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5447775/.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" WOLF L, HASSNER T, MAOZ I.Face recognition in unconstrained videos with matched background similarity[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2011:529-534." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face recognition in unconstrained videos with matched background similarity">
                                        <b>[8]</b>
                                         WOLF L, HASSNER T, MAOZ I.Face recognition in unconstrained videos with matched background similarity[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2011:529-534.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" JIANG Qingyuan, LI Wujun.Scalable graph hashing with feature transformation[C]//Proceedings of the 24th International Conference on Artificial Intelligence.[S.l.]:AAAI Press, 2015:2248-2254." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scalable graph hashing with feature transformation">
                                        <b>[9]</b>
                                         JIANG Qingyuan, LI Wujun.Scalable graph hashing with feature transformation[C]//Proceedings of the 24th International Conference on Artificial Intelligence.[S.l.]:AAAI Press, 2015:2248-2254.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" LIONG V E, LU Jiwen, WANG Gang, et al.Deep hashing for compact binary codes learning[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:2475-2483." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep hashing for compact binary codes learning">
                                        <b>[10]</b>
                                         LIONG V E, LU Jiwen, WANG Gang, et al.Deep hashing for compact binary codes learning[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:2475-2483.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" MCJUNKIN M C.Precision and recall in title keyword searches[J].Information Technology and Libraries, 1995, 14 (3) :161-171." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Precision and recall in title keyword searches">
                                        <b>[11]</b>
                                         MCJUNKIN M C.Precision and recall in title keyword searches[J].Information Technology and Libraries, 1995, 14 (3) :161-171.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" ABADI M, BARHAM P, CHEN Jianmin, et al.TensorFlow:a system for large-scale machine learning[C]//Proceedings of the 12th USENIX conference on Operating Systems Design and Implementation.Berkeley, USA:USENIX Association, 2016:265-283." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensorflow:A system for large-scale machine learning">
                                        <b>[12]</b>
                                         ABADI M, BARHAM P, CHEN Jianmin, et al.TensorFlow:a system for large-scale machine learning[C]//Proceedings of the 12th USENIX conference on Operating Systems Design and Implementation.Berkeley, USA:USENIX Association, 2016:265-283.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" 钟川, 陈军.基于精确欧氏局部敏感哈希的改进协同过滤推荐算法[J].计算机工程, 2017, 34 (2) :74-78." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201702013&amp;v=MjM4MjI3QmJiRzRIOWJNclk5RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5M2xXci9JTHo=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         钟川, 陈军.基于精确欧氏局部敏感哈希的改进协同过滤推荐算法[J].计算机工程, 2017, 34 (2) :74-78.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" WEISS Y, TORRALBA A, FERGUS R.Spectral Hashing[C]//Proceedings of the 21st International Conference on Neural Information Processing Systems.[S.l.]:Curran Associates Inc., 2008:1753-1760." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spectral hashing">
                                        <b>[14]</b>
                                         WEISS Y, TORRALBA A, FERGUS R.Spectral Hashing[C]//Proceedings of the 21st International Conference on Neural Information Processing Systems.[S.l.]:Curran Associates Inc., 2008:1753-1760.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" HE Kaiming, WEN Fang, SUN Jian.K-means hashing:an affinity-preserving quantization method for learning binary compact codes[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2013:2938-2945." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=K-means Hashing:An affinity-preserving quantization method for learning binary compact codes">
                                        <b>[15]</b>
                                         HE Kaiming, WEN Fang, SUN Jian.K-means hashing:an affinity-preserving quantization method for learning binary compact codes[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2013:2938-2945.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" GONG Yunchao, LAZEBNIK S, GORDO A, et al.Iterative quantization:a procrustean approach to learning binary codes for large-scale image retrieval[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (12) :2916-2929." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Iterative Quantization:A Procrustean Approach to Learning Binary Codes for Large-Scale Image Retrieval">
                                        <b>[16]</b>
                                         GONG Yunchao, LAZEBNIK S, GORDO A, et al.Iterative quantization:a procrustean approach to learning binary codes for large-scale image retrieval[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (12) :2916-2929.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(05),222-225+236 DOI:10.19678/j.issn.1000-3428.0050653            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于稀疏自编码的无监督图像哈希算法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BB%A3%E4%BA%9A%E5%85%B0&amp;code=39275165&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">代亚兰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%95%E6%9C%97&amp;code=09032049&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">何朗</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E6%A8%9F%E7%81%BF&amp;code=10152432&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄樟灿</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E6%B1%89%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E7%90%86%E5%AD%A6%E9%99%A2&amp;code=0065699&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武汉理工大学理学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>哈希方法因快速及低内存的特点广泛应用于大规模图像检索中, 但在哈希函数构造过程中对数据稀疏性缺乏研究。为此, 提出一种无监督稀疏自编码的图像哈希算法。在哈希函数的学习过程中加入稀疏构造过程和自动编码器, 利用稀疏自编码的KL差异对哈希码进行稀疏约束, 以增强局部保持映射过程中的判别性。在CIFAR-10数据集和YouTube Faces数据集上进行实验, 结果表明, 该算法平均准确率优于DH算法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">哈希算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像检索;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A8%80%E7%96%8F%E8%87%AA%E7%BC%96%E7%A0%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">稀疏自编码;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%A0%E7%9B%91%E7%9D%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">无监督;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=KL%E5%B7%AE%E5%BC%82&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">KL差异;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    代亚兰 (1992—) , 女, 硕士研究生, 主研方向为图像检索、模式识别;;
                                </span>
                                <span>
                                    何朗, 副教授、博士;;
                                </span>
                                <span>
                                    黄樟灿, 教授、博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-03-07</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61672391);</span>
                    </p>
            </div>
                    <h1><b>Unsupervised Image Hashing Algorithm Based on Sparse-autoencoder</b></h1>
                    <h2>
                    <span>DAI Yalan</span>
                    <span>HE Lang</span>
                    <span>HUANG Zhangcan</span>
            </h2>
                    <h2>
                    <span>School of Science, Wuhan University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The hash method is widely used in large-scale image retrieval due to its fast and low memory characteristics, but it lacks research on data sparsity in the construction of hash functions.To this end, an unsupervised sparse self-encoding image hash algorithm is proposed.In the learning process of the hash function, a sparse construction process and an automatic encoder are added, and the hash code is sparsely constrained by the Kullback-Leibler (KL) divergence of the sparse-auto encoder to enhance the discriminability in the local preservation mapping process.Experiments on the CIFAR-10 datasets and YouTube Faces datasets show that the average accuracy of the algorithm is better than the DH algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hash%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hash algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20retrieval&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image retrieval;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sparse-autoencoder&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sparse-autoencoder;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=unsupervised&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">unsupervised;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Kullback-Leibler%20(KL)%20divergence&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Kullback-Leibler (KL) divergence;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-03-07</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="36">高维数据处理广泛应用于模式识别、数据挖掘等领域<citation id="114" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。随着互联网技术的发展, 图像的数量呈现大规模增长。因此, 研究从高维数据中选择具有代表性的图像特征子集和消除不相关特征具有重要意义。</p>
                </div>
                <div class="p1">
                    <p id="37">针对在监督哈希的实际应用中数据集过大、可用标签数量不足等问题<citation id="116" type="reference"><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>, 国内外学者提出无监督哈希算法。当原始相邻数据映射为哈希码时, 使相邻数据映射为相似哈希码的概率大, 不相邻的数据映射为相邻的哈希概率小, 同时在大数据集中寻找相邻元素的问题转化为在小数据集中寻找相邻元素的问题, 且减小了计算负荷。哈希编码将特征由连续值域映射到离散值域。因此, 哈希函数的优化过程是一个多项式复杂程度的非确定性问题 (Non-deterministic Polynomial, NP) <citation id="115" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 但如何构造一个有效且精度高的哈希函数是面临的难题。</p>
                </div>
                <div class="p1">
                    <p id="38">为弥补数据稀疏结构的不足, 本文提出一种基于稀疏自编码的图像哈希函数学习算法。通过KL (Kullback-Leibler) 差异<citation id="117" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>对哈希码进行稀疏约束以增强局部保持映射过程中的判别性, 同时降低哈希码在自编码器中带来的量化误差。</p>
                </div>
                <h3 id="39" name="39" class="anchor-tag">1 相关知识</h3>
                <h4 class="anchor-tag" id="40" name="40">1.1 自编码器</h4>
                <div class="p1">
                    <p id="41">自动编码器由编码器和解码器2个部分组成<citation id="118" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。在编码器部分, 将无标签样本作为列向量<b><i>x</i></b>的输入, 则自编码器的隐藏层激活函数为:</p>
                </div>
                <div class="p1">
                    <p id="42"><b><i>y</i></b>=<i>A</i> (<b><i>Wx</i></b>+<b><i>bias</i></b>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="43">其中, <i>A</i>是一个大于-1小于1的非线性函数, 例如tanh或sigmoid函数, <b><i>W</i></b>为自编码器编码部分的权重, <b><i>bias</i></b>为自编码器的偏置参数, 且和<b><i>x</i></b>具有同样维度的列向量。在解码部分, 对自编码器的隐藏层激活函数<b><i>y</i></b>进行重构<b><i>x</i></b>′, 并使得<b><i>x</i></b>′与<b><i>x</i></b>尽可能相似, 有:</p>
                </div>
                <div class="p1">
                    <p id="44"><b><i>x</i></b>′=<i>A</i> (<b><i>W</i></b>′<b><i>y</i></b>+<b><i>bias</i></b>′)      (2) </p>
                </div>
                <div class="p1">
                    <p id="45">其中, <b><i>W</i></b>′为自编码器解码部分的权重, <b><i>bias</i></b>′为自编码器解码部分的偏置参数, <b><i>W</i></b>满足<b><i>W</i></b>′=<b><i>W</i></b><sup>T</sup>。目标函数采用平均重构误差<i>D</i>可表示为:</p>
                </div>
                <div class="p1">
                    <p id="46">min <i>D</i>=‖<b><i>x</i></b>-<b><i>x</i></b>′‖<sup>2</sup>      (3) </p>
                </div>
                <div class="p1">
                    <p id="47"><i>D</i>越小, 输出与输入值越相近, 编码器对<b><i>x</i></b>进行重构效果就越好, 且在编码过程中保留样本的主要信息及特征。</p>
                </div>
                <h4 class="anchor-tag" id="48" name="48">1.2 稀疏编码</h4>
                <div class="p1">
                    <p id="49">通过自编码器, 哈希函数能够解决在优化求解时难度较大的问题, 但自编码器只能保存样本的特征信息, 不能实现图像检索。稀疏约束在自动编码器上能使其不仅学到样本的特征表达, 还能学到复制的非线性函数。稀疏性约束是指在激活函数为<i>sigmoid</i>函数时, 当神经元的输出接近1时认为它被激活, 而输出接近0时认为它被抑制, 使得神经元多数时间处于抑制状态<citation id="119" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。同理, 若假设的神经元的激活函数是<i>tanh</i>函数, 当神经元输出为-1时, 神经元被抑制。</p>
                </div>
                <div class="p1">
                    <p id="50">为使大部分神经元处于被抑制状态, 数据的数据集X将分解为多个基元的线性组合, 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">X</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi mathvariant="bold-italic">α</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">其中, <b><i>X</i></b>∈<image href="images/JSJC201905036_053.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>n</i></sup>, 在一般情况下<i>k</i>远远大于<i>n</i>, 其基组合才能更容易学到输入数据内在的结构和特征。在常见算法中, 如PCA算法, 由于基向量数量少, 因此分解后可以得到唯一确定的系数<i>a</i>。在稀疏编码中, 基向量数<i>k</i>远远大于目标向量维数<i>n</i>, 其分解系数<i>a</i>不能唯一确定, 以达到约束的目的。稀疏编码算法的来源便是对系数<i>a</i>进行约束, 其编码函数表达式为:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>α</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msubsup><mi>θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mspace width="0.25em" /><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow></mrow></mstyle></mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>α</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msubsup><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>S</mi></mstyle><mo stretchy="false"> (</mo><mi>α</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">前一项表达式为输入样本向量和经过自编码器后的重构向量之间的误差, 最小的误差即目标函数, 该项使即算法获得一个线性拟合式。后一项是惩罚项, 即稀疏项。<i>S</i> (<i>α</i><mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>) 作为分解稀疏的稀疏惩罚函数, 在<i>α</i><mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>大于0时, 对其进行“惩罚”, 使<b><i>X</i></b>的稀疏有更多的0。常量<i>λ</i>控制稀疏性惩罚因子的权重, 即控制误差量和稀疏项之间的相对程度。在分解系数中, 只有少数系数远远大于0, 其他系数全为0。因此, 必须防止将系数<i>α</i><mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>减到很小的同时将每个基的值增加到很大, 第1项的代价值基本保持不变, 而第2项的稀疏惩罚依旧很小。基于上述分析, 限制<i>φ</i>为一个有限空间, 即‖<i>φ</i>‖<sup>2</sup>&lt;<i>C</i>, 其中, <i>C</i>是常量。综上, 完整的包含约束系统的系数编码函数表达式为:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>α</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msubsup><mi>θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mspace width="0.25em" /><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow></mrow></mstyle></mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>α</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msubsup><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>S</mi></mstyle><mo stretchy="false"> (</mo><mi>α</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">φ</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>&lt;</mo><mi>C</mi><mo>, </mo><mo>∀</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>k</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h3 id="60" name="60" class="anchor-tag">2 无监督的稀疏哈希图像检索算法</h3>
                <div class="p1">
                    <p id="61">为得到紧凑的哈希码, 本文所提出的稀疏自编码哈希算法利用稀疏自编码对哈希码进行稀疏约束, 因此增强了局部特征并保持映射过程中的判别性。同时, 为得到更精确的哈希码, 需适当控制哈希码的量化误差。</p>
                </div>
                <div class="p1">
                    <p id="62">稀疏自动编码器由编码器和解码器2个部分组成。在编码器部分, 函数h (<b><i>x</i></b><sub><i>i</i></sub>) 将输入的<i>d</i>维列向量<b><i>x</i></b>映射到<i>k</i>维空间, 即将<b><i>X</i></b>∈<image href="images/JSJC201905036_063.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>映射得到特征向量<b><i>X</i></b>∈<image href="images/JSJC201905036_064.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>k</i></sup>, 其中<i>k</i>&lt;<i>d</i>。同理, 解码部分<i>f</i> (<b><i>z</i></b>) 将<i>k</i>维向量<b><i>z</i></b>映射<i>d</i>维空间<image href="images/JSJC201905036_065.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>去重构<b><i>x</i></b>。</p>
                </div>
                <div class="p1">
                    <p id="66">假设<b><i>x</i></b><sub><i>i</i></sub>是第<i>i</i>个样本, <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><mo>=</mo><mrow><mrow><mo>{</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>}</mo></mrow></mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup></mrow></math></mathml>是N个无标签的样本。由于样本在输入前h (<b><i>x</i></b><sub><i>i</i></sub>) 是连续的实值, 为了获得二进制哈希码得到样本特征, 经过自动编码器的阈值函数为:</p>
                </div>
                <div class="p1">
                    <p id="68"><i>a</i>=sign (<i>h</i> (<b><i>x</i></b><sub><i>i</i></sub>) ) =sign (<i>h</i><sub><i>j</i></sub> (<b><i>x</i></b><sub><i>i</i></sub>) ) , <i>j</i>=1, 2, …, <i>K</i>      (7) </p>
                </div>
                <div class="p1">
                    <p id="69">其中, <i>h</i> (<b><i>x</i></b><sub><i>i</i></sub>) 表示输入数据经过自动编码器的编码部分后, 即样本向量<b><i>x</i></b><sub><i>i</i></sub>在稀疏自编码器的隐藏层的特征向量的第<i>j</i>个值, sign为符号函数, 当<i>h</i> (<b><i>x</i></b><sub><i>i</i></sub>) &gt;0时, sign <i>h</i> (<b><i>x</i></b><sub><i>i</i></sub>) =1, 神经元被激活;否则sign <i>h</i> (<b><i>x</i></b><sub><i>i</i></sub>) =-1, 神经元被抑制。自动编码器的激活函数将特征向量由连续值变成离散的值。</p>
                </div>
                <div class="p1">
                    <p id="70">解码部分与编码部分同理, <b><i>f</i></b> (<b><i>z</i></b>) 映射<b><i>z</i></b>到<image href="images/JSJC201905036_071.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>空间去重构<b><i>x</i></b>, 为学习理想的哈希函数<i>h</i>, 目标函数为编码器的输入值与解码器输出值的均方误差, 可表示为:</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Φ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">式 (8) 是样本和隐藏层特征向量的最小均方误差, 目的是对相似的点在编码时保持相似性。由于优化一个离散的非光滑的函数是NP问题, 而<b><i>a</i></b><sub><i>i</i></sub>是经过编码部分求得的<i>k</i>维二进制离散哈希码, 需要解码层将离散哈希码再次变回连续值来求解, 于是采用隐藏层的输出值<i>h</i> (<b><i>x</i></b><sub><i>i</i></sub>) 作为解码层的输入, 目标函数变为:</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Φ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">f</mi><mo stretchy="false"> (</mo><mi>h</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">式 (9) 为目标函数样本<i>x</i>和解码器输出的最小均方误差, 而在得到连续值来解决NP问题的同时, 离散的二进制码松弛到连续输入值的过程中产生了不可控的量化误差。引用L2范数控制量化误差, 则目标函数变为原先的均方误差加上L2范数, 有:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Φ</mi><msub><mrow></mrow><mn>3</mn></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">f</mi><mo stretchy="false"> (</mo><mi>h</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>μ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>h</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">其中, <i>μ</i>是控制量化误差的权重参数, ‖·‖<sub>2</sub>是L2范数。</p>
                </div>
                <div class="p1">
                    <p id="78">在目标函数中加上稀疏约束来增强局部保持映射过程中的判别性, 根据式 (4) 稀疏编码器的隐藏层第<i>j</i>个单元的平均激活值为:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>ρ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">[</mo></mstyle><mi>h</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">其中, <i>h</i><sub><i>j</i></sub> (<b><i>x</i></b><sub><i>i</i></sub>) 表示在给定输入样本向量为<b><i>x</i></b><sub><i>i</i></sub>时, 自编码神经网络隐藏神经元<i>j</i>的激活度。由于稀疏限制, 隐藏神经元的平均激活度要尽可能小, 为使哈希层的所有单元的平均激活值<i>ρ</i>接近于0, 采用KL距离作为一项额外的惩罚因子, 有:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mi>L</mi><mo stretchy="false"> (</mo><mi>ρ</mi><mo stretchy="false">∥</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>ρ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>ρ</mi><mrow><mi>lg</mi></mrow><mfrac><mi>ρ</mi><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>ρ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>ρ</mi><mo stretchy="false">) </mo><mrow><mi>lg</mi></mrow><mfrac><mrow><mn>1</mn><mo>-</mo><mi>ρ</mi></mrow><mrow><mn>1</mn><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>ρ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">其中, <i>j</i>依次代表隐藏层中的每一个神经元, 并且<mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mi>L</mi><mo stretchy="false"> (</mo><mi>ρ</mi><mo stretchy="false">∥</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>ρ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>的值随着ρ与<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>ρ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>的差距增大而单调递增, 当<mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><mo>=</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>ρ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>时, <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mi>L</mi><mo stretchy="false"> (</mo><mi>ρ</mi><mo stretchy="false">∥</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>ρ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mn>0</mn></mrow></math></mathml>。通过结合式 (12) 和式 (10) 的<i>Φ</i><sub>3</sub>, 得到整体的目标函数为:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Φ</mi><msub><mrow></mrow><mn>4</mn></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">f</mi><mo stretchy="false"> (</mo><mi>h</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>μ</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>h</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>γ</mi><mi>Κ</mi><mi>L</mi><mo stretchy="false"> (</mo><mi>ρ</mi><mo stretchy="false">∥</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>ρ</mi></mstyle><mrow><mspace width="0.25em" /><mo>^</mo></mrow></mover></mrow><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">其中, <i>k</i>是隐藏层中隐藏神经元的数量, <i>γ</i>为控制稀疏性的参数。</p>
                </div>
                <div class="p1">
                    <p id="89">传统的哈希方法在经过GIST特征训练之后, 连续值的输出被用作哈希码的松弛处理。经过稀疏自动编码器, 通过对连续输出应用阈值函数来获得哈希码。但是, 该方法的缺陷是收敛速度很慢, 且带来较大的量化误差。同时, 符号函数不可微分, 难以反向传播损失函数的梯度。由于欧几里得空间与汉明空间之间的差异, 如果完全忽略二元约束, 那么会导致次优哈希码。本文方法将符号函数直接应用在自动编码器的解码器输出之后, 严格限制输出为二元变量, 保持二进制码的离散性, 同时利用随机梯度下降法有助于算法的快速收敛, 并得到最优权重值。同时学习的二进制码使成对标签的似然性尽可能大, 相似的样本在映射到汉明空间后的哈希码也相似, 不相似的样本汉明距离较大。同时考虑哈希码学习过程中的量化误差, 利用L2范数使量化误差尽可能小, 从而得到更好的哈希码。基于GIST特征的稀疏自编码的哈希算法如算法1所示。</p>
                </div>
                <div class="p1">
                    <p id="90"><b>算法1</b> 基于GIST特征的稀疏自编码的哈希算法</p>
                </div>
                <div class="p1">
                    <p id="91"><b>输入</b><i>N</i>个无标签的样本<mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><mo>=</mo><mrow><mrow><mo>{</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>}</mo></mrow></mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="93"><b>输出</b> 均方误差最小值, 并且得到最优权重为<i>W</i>={<i>W</i><sub>SABA</sub>, <i>W</i><sub>DH</sub>, <i>W</i><sub>PCA</sub>, <i>W</i><sub>LSH</sub>, <i>W</i><sub>SH</sub>, <i>W</i><sub>KMH</sub>}</p>
                </div>
                <div class="p1">
                    <p id="94">1.样本经过自编码器阈值函数, 得到离散的0-1码</p>
                </div>
                <div class="p1">
                    <p id="95">2.以连续的隐藏层输出值h<sub>j</sub> (x<sub>i</sub>) 代替0-1码</p>
                </div>
                <div class="p1">
                    <p id="96">3.最小均方误差加上L2范数</p>
                </div>
                <div class="p1">
                    <p id="97">4.加上稀疏约束, 并得到Φ<sub>4</sub></p>
                </div>
                <div class="p1">
                    <p id="98">5.利用随机梯度下降法求取最优权重</p>
                </div>
                <h3 id="99" name="99" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="100" name="100">3.1 实验环境</h4>
                <div class="p1">
                    <p id="101">本文实验分别在CIFAR-10<citation id="120" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>和YouTube Faces<citation id="121" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>2个数据集进行图像检索算法精度验证, 这2个数据集由于开源、样本数量大等特点, 在评价算法的图像检索性能时被多数学者使用<citation id="122" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。其中, CIFAR-10数据集是由飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船以及卡车十类图像各6 000幅组成的60 000张彩色图片的数据集。而YouTube Faces数据集是由1 595个人组成的621 126张人脸的图像数据集。根据文献<citation id="123" type="reference">[<a class="sup">7</a>,<a class="sup">8</a>]</citation>, 本文实验在CIFAR-10数据集中随机抽出1 000张作为测试集, 其余59 000张图片作为训练集。在YouTubeFaces数据集中, 本文实验将65个人中每个人选取100张人脸作为测试集, 其余作为训练样本。</p>
                </div>
                <div class="p1">
                    <p id="102">根据文献<citation id="124" type="reference">[<a class="sup">10</a>]</citation>, 本文实验评价指标是信息检索实验中的常用指标平均准确率 (Mean Average Precision, MAP) , 及召回率-查准率曲线 (Precision Rate-Recall Rate Curve, PRC) <citation id="125" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。其中, MAP是指平均精度的平均值。设第<i>i</i>张图片的检索精度是<i>P</i><sub><i>i</i></sub>%, 则所有样本图片检索精度的平均值为:</p>
                </div>
                <div class="p1">
                    <p id="103" class="code-formula">
                        <mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mi>A</mi><mi>Ρ</mi><mo>=</mo><mfrac><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mi>%</mi></mrow><mi>n</mi></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="104">本文实验的CIFAR-10数据集实验中取<i>n</i>=59 000。在PRC中, 召回率是指系统检索到的相关文件数量除以系统所有相关的文件总数, 查准率是指系统检索到的相关文件数除以系统所有检索到的文件总数, 一般情况下, 两者成反比。</p>
                </div>
                <div class="p1">
                    <p id="105">本文所提出的模型使用开源库Tensorflow<citation id="126" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>来实现, 实验环境为 GeForce GTX Titan X GPU, 中央处理器为Intel (R) Core i7-5930K 3.50 GHz, 内存为64 GB, 操作系统为 Ubuntu 14.04。</p>
                </div>
                <h4 class="anchor-tag" id="106" name="106">3.2 结果分析</h4>
                <div class="p1">
                    <p id="107">为测量本文所提出的<i>SABA</i>哈希算法检索性能, 在<i>CIFAR</i>-10数据集和<i>YouTube Faces</i>数据集中采用深度哈希 (<i>Deep Hashing</i>, <i>DH</i>) <citation id="127" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、局部敏感哈希 (<i>Locality Sensitive Hashing</i>, <i>LSH</i>) <citation id="128" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、谱哈希 (<i>Spectral Hashing</i>, <i>SH</i>) <citation id="129" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、<i>K</i>平均哈希 (<i>K</i>-<i>Means Hashing</i>, <i>KMH</i>) <citation id="130" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>以及基于主成分分析的迭代量化哈希 (<i>Principal Components Analysis</i>-<i>Iterative Quantization</i><i>Hashing</i>, <i>PCA</i>-<i>ITQ</i>) <citation id="131" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>这5种无监督哈希算法进行对比实验, 如表1、表2所示, 分别表示不同哈希码长度 (H) 在2个数据集上的检索结果。可以看出:1) 除表2中的<i>SH</i>算法以外, 其他无监督哈希算法的<i>MAP</i>变化趋势随编码位数的增加而加大。2) 在特定的编码位数上, 本文算法的平均检索精度要比其他无监督哈希算法高。综上, 本文具有稀疏约束的自编码器可以提高传统无监督哈希方法的检索精度, 并且<i>L</i>2范数可以有效控制量化误差。因此, 本文算法可以有效地学习哈希函数, 并且精度优于其他无监督哈希方法。</p>
                </div>
                <div class="area_img" id="108">
                    <p class="img_tit"><b>表1 CIFAR-10数据集上不同算法平均准确率对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"> %</p>
                    <table id="108" border="1"><tr><td>算法</td><td><i>H</i>=16</td><td><i>H</i>=24</td><td><i>H</i>=32</td><td><i>H</i>=48</td><td><i>H</i>=64</td></tr><tr><td>本文算法</td><td>18.04</td><td>18.64</td><td>19.02</td><td>19.43</td><td>19.86</td></tr><tr><td><br />DH算法</td><td>16.17</td><td>16.41</td><td>16.62</td><td>16.86</td><td>16.96</td></tr><tr><td><br />LSH算法</td><td>12.55</td><td>13.02</td><td>13.76</td><td>14.44</td><td>15.07</td></tr><tr><td><br />SH算法</td><td>12.95</td><td>13.66</td><td>14.09</td><td>13.98</td><td>13.89</td></tr><tr><td><br />KMH算法</td><td>13.59</td><td>13.78</td><td>13.93</td><td>14.44</td><td>14.46</td></tr><tr><td><br />PCA-ITQ算法</td><td>15.67</td><td>15.86</td><td>16.20</td><td>16.44</td><td>16.64</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="109">
                    <p class="img_tit"><b>表2 YouTube Faces数据集上不同算法平均准确率对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"> %</p>
                    <table id="109" border="1"><tr><td>算法</td><td><i>H</i>=16</td><td><i>H</i>=24</td><td><i>H</i>=32</td><td><i>H</i>=48</td><td><i>H</i>=64</td></tr><tr><td>本文算法</td><td>31.32</td><td>31.66</td><td>31.87</td><td>32.07</td><td>32.32</td></tr><tr><td><br />DH算法</td><td>28.50</td><td>29.06</td><td>29.25</td><td>29.92</td><td>30.44</td></tr><tr><td><br />LSH算法</td><td>5.56</td><td>6.08</td><td>6.64</td><td>7.12</td><td>7.77</td></tr><tr><td><br />SH算法</td><td>14.35</td><td>14.73</td><td>15.12</td><td>16.24</td><td>16.86</td></tr><tr><td><br />KMH算法</td><td>20.61</td><td>20.94</td><td>21.53</td><td>21.91</td><td>22.42</td></tr><tr><td><br />PCA-ITQ算法</td><td>27.54</td><td>28.06</td><td>28.84</td><td>29.04</td><td>29.61</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="110">图1表示在CIFAR-10数据集上32 bit编码下的查准率-召回率曲线, 可以看出:1) 随着召唤率的增加, 所有算法的查准率均会减少, 即查准率与召回率近似成反比。2) 本文算法的PRC曲线与横纵轴围成的曲线面积最大, 其反映平均检索精度的大小。综上, 本文基于稀疏自编码的哈希算法在PRC指标下均优于其他对比算法, 与表2结果相吻合。</p>
                </div>
                <div class="area_img" id="111">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201905036_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 CIFAR-10数据集上不同算法查准率-召回率曲线对比结果" src="Detail/GetImg?filename=images/JSJC201905036_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 CIFAR-10数据集上不同算法查准率-召回率曲线对比结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201905036_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="112" name="112" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="113">本文提出一种无监督稀疏自编码哈希图像检索算法。该算法从稀疏编码增强局部映射过程中的判别性出发, 将稀疏自动编码器与哈希方法相结合, 解决了哈希码的离散性导致的优化困难问题, 并减少输入输出的量化误差。实验结果验证了本文算法的有效性。下一步研究如何将该算法应用到深度神经网络中, 以解决浅层特征语义信息不充分问题。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000085402&amp;v=MTA0ODhaT01LQ0h3N29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxuSUpWNGRhaEk9TmlmSVk3SzdIdGpOcjQ5Rg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> ZHENG Zhaohui, WU Xiaoyun, SRIHARI R, et al.Feature selection for text categorization on imbalanced data[J].ACM SIGKDD Explorations Newsletter, 2004, 6 (1) :80-89.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201512031&amp;v=MTYwOTFOclk5R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5M2xXci9JTHo3QmJiRzRIOVQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 杨定中, 陈心浩.基于投影残差量化哈希的近似最近邻搜索[J].计算机工程, 2015, 41 (12) :161-165, 170.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201701022&amp;v=MDM1NzVxcUJ0R0ZyQ1VSTE9lWmVSb0Z5M2xXci9JSVRmVGU3RzRIOWJNcm85SFpvUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 柯圣财, 赵永威, 李弼程, 等.基于卷积神经网络和监督核哈希的图像检索方法[J].电子学报, 2017, 45 (1) :157-163.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discrete graph hashing">

                                <b>[4]</b> LIU Wei, MU Cun, KUMAR S, et al.Discrete graph hashing[C]//Proceedings of the 27th International Conference on Neural Information Processing Systems.Cambridge, USA:MIT Press, 2014:3419-3427.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015639681.nh&amp;v=MTM2MzdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5M2xXci9JVkYyNkc3VzdGOWZFcnBFYlA=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 赵文星.变系数部分线性模型的统计推断[D].南京:南京信息工程大学, 2015.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stacked Sparse Auto Encoder (SSAE)for nuclei detection on breast cancer histopathology images">

                                <b>[6]</b> XU Jun, XIANG Lei, LIU Qinshan, et al.Stacked sparse autoencoder for nuclei detection on breast cancer histopathology images[J].IEEE Transactions on Medical Imaging, 2015, 35 (1) :119-130.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CIFAR10-DVS:an event-stream dataset for object classification">

                                <b>[7]</b> LI Hongmin, LIU Hanchao, JI Xiangyang, et al.CIFAR10-DVS:an event-stream dataset for object classification [EB/OL].[2018-02-05].https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5447775/.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face recognition in unconstrained videos with matched background similarity">

                                <b>[8]</b> WOLF L, HASSNER T, MAOZ I.Face recognition in unconstrained videos with matched background similarity[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2011:529-534.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scalable graph hashing with feature transformation">

                                <b>[9]</b> JIANG Qingyuan, LI Wujun.Scalable graph hashing with feature transformation[C]//Proceedings of the 24th International Conference on Artificial Intelligence.[S.l.]:AAAI Press, 2015:2248-2254.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep hashing for compact binary codes learning">

                                <b>[10]</b> LIONG V E, LU Jiwen, WANG Gang, et al.Deep hashing for compact binary codes learning[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:2475-2483.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Precision and recall in title keyword searches">

                                <b>[11]</b> MCJUNKIN M C.Precision and recall in title keyword searches[J].Information Technology and Libraries, 1995, 14 (3) :161-171.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensorflow:A system for large-scale machine learning">

                                <b>[12]</b> ABADI M, BARHAM P, CHEN Jianmin, et al.TensorFlow:a system for large-scale machine learning[C]//Proceedings of the 12th USENIX conference on Operating Systems Design and Implementation.Berkeley, USA:USENIX Association, 2016:265-283.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201702013&amp;v=Mjc4MTZxQnRHRnJDVVJMT2VaZVJvRnkzbFdyL0lMejdCYmJHNEg5Yk1yWTlFWjRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 钟川, 陈军.基于精确欧氏局部敏感哈希的改进协同过滤推荐算法[J].计算机工程, 2017, 34 (2) :74-78.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spectral hashing">

                                <b>[14]</b> WEISS Y, TORRALBA A, FERGUS R.Spectral Hashing[C]//Proceedings of the 21st International Conference on Neural Information Processing Systems.[S.l.]:Curran Associates Inc., 2008:1753-1760.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=K-means Hashing:An affinity-preserving quantization method for learning binary compact codes">

                                <b>[15]</b> HE Kaiming, WEN Fang, SUN Jian.K-means hashing:an affinity-preserving quantization method for learning binary compact codes[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2013:2938-2945.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Iterative Quantization:A Procrustean Approach to Learning Binary Codes for Large-Scale Image Retrieval">

                                <b>[16]</b> GONG Yunchao, LAZEBNIK S, GORDO A, et al.Iterative quantization:a procrustean approach to learning binary codes for large-scale image retrieval[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (12) :2916-2929.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201905036" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201905036&amp;v=MTI5ODdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnkzbFdyL0lMejdCYmJHNEg5ak1xbzlHWW9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VNZjJWbHVQbXRmcGxDWVVPcjBMVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
