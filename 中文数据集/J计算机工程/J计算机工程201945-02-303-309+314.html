<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131279376993750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201902050%26RESULT%3d1%26SIGN%3dw1sBEOh6%252f2n0UHyC9kI1jKNL80s%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902050&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902050&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902050&amp;v=MDAwNDFyQ1VSTE9lWmVSbkZ5amtXcnJMTHo3QmJiRzRIOWpNclk5QVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#67" data-title="0概述 ">0概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#72" data-title="1 文本特征空间模型 ">1 文本特征空间模型</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="2 改进差分进化的两阶段特征选择算法 ">2 改进差分进化的两阶段特征选择算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#88" data-title="2.1 高相关性特征子集构建">2.1 高相关性特征子集构建</a></li>
                                                <li><a href="#102" data-title="2.2 基于DE的特征提取">2.2 基于DE的特征提取</a></li>
                                                <li><a href="#135" data-title="2.3 两阶段特征选择算法">2.3 两阶段特征选择算法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#143" data-title="3 仿真结果与分析 ">3 仿真结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#144" data-title="3.1 数据来源及评价指标">3.1 数据来源及评价指标</a></li>
                                                <li><a href="#154" data-title="3.2 收敛性对比">3.2 收敛性对比</a></li>
                                                <li><a href="#157" data-title="3.3 参数设置">3.3 参数设置</a></li>
                                                <li><a href="#166" data-title="3.4 TV与MM结合的有效性验证">3.4 TV与MM结合的有效性验证</a></li>
                                                <li><a href="#170" data-title="3.5 改进DE算法的有效性验证">3.5 改进DE算法的有效性验证</a></li>
                                                <li><a href="#174" data-title="3.6 不同特征选择算法的聚类效果对比">3.6 不同特征选择算法的聚类效果对比</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#186" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="图1 特征空间模型构建">图1 特征空间模型构建</a></li>
                                                <li><a href="#87" data-title="图2 改进差分进化的两阶段特征选择算法框架">图2 改进差分进化的两阶段特征选择算法框架</a></li>
                                                <li><a href="#148" data-title="表1 实验数据集">表1 实验数据集</a></li>
                                                <li><a href="#156" data-title="图3 2种算法收敛曲线对比结果">图3 2种算法收敛曲线对比结果</a></li>
                                                <li><a href="#161" data-title="图4 参数F和CR对聚类准确率的影响">图4 参数F和CR对聚类准确率的影响</a></li>
                                                <li><a href="#165" data-title="图5 参数δ对聚类准确率的影响">图5 参数δ对聚类准确率的影响</a></li>
                                                <li><a href="#168" data-title="图6 在过滤阶段各算法聚类准确率对比结果">图6 在过滤阶段各算法聚类准确率对比结果</a></li>
                                                <li><a href="#172" data-title="图7 4种算法聚类准确率对比结果">图7 4种算法聚类准确率对比结果</a></li>
                                                <li><a href="#179" data-title="图8 不同特征选择算法准确率对比结果">图8 不同特征选择算法准确率对比结果</a></li>
                                                <li><a href="#184" data-title="图1 0 不同特征选择算法F1值对比结果">图1 0 不同特征选择算法F1值对比结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="35">


                                    <a id="bibliography_1" title="YANG Y, PEDERSEN J O.A comparative study on feature selection in text categorization[C]//Proceedings of the 14th International Conference on Machine Learning.San Francisco, USA:Morgan Kaufmann Publishers Inc., 1997:412-420." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Comparative Study on Feature Selection in Text Categorization">
                                        <b>[1]</b>
                                        YANG Y, PEDERSEN J O.A comparative study on feature selection in text categorization[C]//Proceedings of the 14th International Conference on Machine Learning.San Francisco, USA:Morgan Kaufmann Publishers Inc., 1997:412-420.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_2" title="LIU T, LIU S, CHEN Z, et al.An evaluation on feature selection for text clustering[C]//Proceedings of the20th International Conference on Machine Learning.[S.l.]:AAAI Press, 2003:488-495." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Evaluation on Feature Selection for Text Clustering">
                                        <b>[2]</b>
                                        LIU T, LIU S, CHEN Z, et al.An evaluation on feature selection for text clustering[C]//Proceedings of the20th International Conference on Machine Learning.[S.l.]:AAAI Press, 2003:488-495.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_3" title="LIU L, KANG J, YU J, et al.A comparative study on unsupervised feature selection methods for text clustering[C]//Proceedings of IEEE International Conference on Natural Language Processing and Knowledge Engineering.Washington D.C., USA:IEEE Press, 2005:597-601." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A comparative study on unsupervised feature selection methods for text clustering">
                                        <b>[3]</b>
                                        LIU L, KANG J, YU J, et al.A comparative study on unsupervised feature selection methods for text clustering[C]//Proceedings of IEEE International Conference on Natural Language Processing and Knowledge Engineering.Washington D.C., USA:IEEE Press, 2005:597-601.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_4" title="FERREIRA A J, FIGUEIREDO M A T.Efficient feature selection filters for high-dimensional data[J].Pattern Recognition Letters, 2012, 33 (13) :1794-1804." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300413182&amp;v=MTg0NjdHZXJxUVRNbndaZVp1SHlqbVVMYklJRjhkYnhFPU5pZk9mYks3SHRET3JJOUZZT29NRFhRN29CTVQ2VDRQUUgvaXJSZA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        FERREIRA A J, FIGUEIREDO M A T.Efficient feature selection filters for high-dimensional data[J].Pattern Recognition Letters, 2012, 33 (13) :1794-1804.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_5" title="UYSAL A K, GUNAL S.Text classification using genetic algorithm oriented latent semantic features[J].Expert Systems with Applications, 2014, 41 (13) :5938-5947." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14061700212063&amp;v=MDYzMzRmTnFJOUZadW9OREhvNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGOGRieEU9TmlmT2ZiSzhIdA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        UYSAL A K, GUNAL S.Text classification using genetic algorithm oriented latent semantic features[J].Expert Systems with Applications, 2014, 41 (13) :5938-5947.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_6" title="MORADI P, ROSTAMI M.Integration of graph clustering with ant colony optimization for feature selection[J].Knowledge-Based Systems, 2015, 84:144-161." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1E2F3289975FD1481BDDCBB690A97EEB&amp;v=MjY1MDBmYkxOSEtmUHJZZE1iZXdLZWdnNHl4NFNtRXNKT3cyUXFoczFDTHVUTU0vdENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5GaHhMbTJ4YXM9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        MORADI P, ROSTAMI M.Integration of graph clustering with ant colony optimization for feature selection[J].Knowledge-Based Systems, 2015, 84:144-161.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_7" title="ZAHRAN B M, KANAAN G.Text feature selection using particle swarm optimization algorithm[J].World Applied Sciences Journal, 2009, 7:69-74." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Text Feature Selection Using ParticleSwarm Optimization Algorithm">
                                        <b>[7]</b>
                                        ZAHRAN B M, KANAAN G.Text feature selection using particle swarm optimization algorithm[J].World Applied Sciences Journal, 2009, 7:69-74.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_8" title="STORN R, PRICE K.Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces[J].Journal of Global Optimization, 1997, 11 (4) :341-359.309" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002859935&amp;v=MTkxNjlYcVJyeG94Y01IN1I3cWVidWR0RkNIbFU3N0JKVjA9Tmo3QmFyTzRIdEhPcDRwTWJlZ0tZM2s1ekJkaDRqOTlT&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        STORN R, PRICE K.Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces[J].Journal of Global Optimization, 1997, 11 (4) :341-359.309
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_9" title="ZHAO Z, YANG J, HU Z, et al.A differential evolution algorithm with self-adaptive strategy and control parameters based on symmetric Latin hypercube design for unconstrained optimization problems[J].European Journal of Operational Research, 2016, 250 (1) :30-45." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122600543142&amp;v=MTU3MjRZZThNRFhnN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGOGRieEU9TmlmT2ZiSzlIOVBPcVk5Rg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        ZHAO Z, YANG J, HU Z, et al.A differential evolution algorithm with self-adaptive strategy and control parameters based on symmetric Latin hypercube design for unconstrained optimization problems[J].European Journal of Operational Research, 2016, 250 (1) :30-45.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_10" title="姜凯, 苑金海.融合差分进化和SOM的组合文本聚类算法[J].计算机与现代化, 2015 (5) :13-16." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYXH201505003&amp;v=MTE0NzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqa1dyckxMelRUWnJHNEg5VE1xbzlGWjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        姜凯, 苑金海.融合差分进化和SOM的组合文本聚类算法[J].计算机与现代化, 2015 (5) :13-16.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_11" title="樊东辉, 王治和, 陈建华, 等.基于DF算法改进的文本聚类特征选择算法[J].兰州文理学院学报 (自然科学版) , 2012, 26 (1) :51-54." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJB201201015&amp;v=MjkzNThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqa1dyckxJalhCYkxHNEg5UE1ybzlFWVk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        樊东辉, 王治和, 陈建华, 等.基于DF算法改进的文本聚类特征选择算法[J].兰州文理学院学报 (自然科学版) , 2012, 26 (1) :51-54.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_12" title="BHARTI K K, SINGH P K.A two-stage unsupervised dimension reduction method for text clustering[C]//Proceedings of the 7th International Conference on BioInspired Computing:Theories and Applications.Berlin, Germany:Springer, 2013:529-542." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A two-stage unsupervised dimension reduction method for text clustering">
                                        <b>[12]</b>
                                        BHARTI K K, SINGH P K.A two-stage unsupervised dimension reduction method for text clustering[C]//Proceedings of the 7th International Conference on BioInspired Computing:Theories and Applications.Berlin, Germany:Springer, 2013:529-542.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_13" title="AGRAWAL R, GEHRKE J, GUNOPULOS D, et al.Automatic subspace clustering of high dimensional data for data mining applications[C]//Proceedings of ACMSIGMOD International Conference on Management of Data.New York, USA:ACM Press, 1998:94-105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic subspace clustering of high dimensional data for data mining applications">
                                        <b>[13]</b>
                                        AGRAWAL R, GEHRKE J, GUNOPULOS D, et al.Automatic subspace clustering of high dimensional data for data mining applications[C]//Proceedings of ACMSIGMOD International Conference on Management of Data.New York, USA:ACM Press, 1998:94-105.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_14" title="BHARTI K K, SINGH P K.Hybrid dimension reduction by integrating feature selection with feature extraction method for text clustering[J].Expert Systems with Applications, 2015, 42 (6) :3105-3114." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESAFB0E02C32426F329A34EBF8ED8A30BF&amp;v=MjY5NjJMT2JORzVyNDAyWitrTERucFB6QlFhbXp4NVBRMlVwR2RCY2NPWFJjanBDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh4TG0yeGFzPU5pZk9mYw==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        BHARTI K K, SINGH P K.Hybrid dimension reduction by integrating feature selection with feature extraction method for text clustering[J].Expert Systems with Applications, 2015, 42 (6) :3105-3114.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_15" title="ZORARPACI E, ZEL S A.A hybrid approach of differential evolution and artificial bee colony for feature selection[J].Expert Systems with Applications, 2016, 62:91-103." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A hybrid approach of differential evolution and artificial bee colony for feature selection">
                                        <b>[15]</b>
                                        ZORARPACI E, ZEL S A.A hybrid approach of differential evolution and artificial bee colony for feature selection[J].Expert Systems with Applications, 2016, 62:91-103.
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_16" title="QIN A K, HUANG V L, SUGANTHAN P N.Differential evolution algorithm with strategy adaptation for global numerical optimization[J].IEEE Transactions on Evolutionary Computation, 2009, 13 (2) :398-417." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Differential evolution algorithm with strategy adaptation for global numerical optimization">
                                        <b>[16]</b>
                                        QIN A K, HUANG V L, SUGANTHAN P N.Differential evolution algorithm with strategy adaptation for global numerical optimization[J].IEEE Transactions on Evolutionary Computation, 2009, 13 (2) :398-417.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(02),303-309+314 DOI:10.19678/j.issn.1000-3428.0049701            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于差分进化的两阶段文本特征选择算法</span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%82%96%E6%99%93%E4%B8%BD&amp;code=06458813&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">肖晓丽</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E7%91%B6&amp;code=38617599&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴瑶</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E9%94%A1%E7%8E%B2&amp;code=38617600&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周锡玲</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BB%96%E5%8D%93%E5%87%A1&amp;code=29033299&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">廖卓凡</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E6%B2%99%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E9%80%9A%E4%BF%A1%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0175884&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长沙理工大学计算机与通信工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E6%B2%99%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E7%BB%BC%E5%90%88%E4%BA%A4%E9%80%9A%E8%BF%90%E8%BE%93%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%99%BA%E8%83%BD%E5%A4%84%E7%90%86%E6%B9%96%E5%8D%97%E7%9C%81%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长沙理工大学综合交通运输大数据智能处理湖南省重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为降低文本特征空间维度, 提高数据挖掘处理数据的效率, 提出两阶段文本特征选择算法。结合方差和平均中位数2种方法构建高相关性的特征子集进行初步降维, 并将其作为差分进化算法的初始特征种群。利用特征词的累计词频和文档频率设计适应度函数, 将多个特征差向量和局部最优特征引入变异操作中, 增加特征子集的扰动性, 加快差分进化算法的收敛速度, 获得最优特征子集。在WebKB和Reuters-21578数据集上进行实验, 结果表明, 该算法在准确率、召回率和F1值上均优于TDM5、MADAC等算法, 能够降低文本特征空间的维度, 提高文本聚类效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B7%E5%90%88%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">混合特征选择;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%99%8D%E7%BB%B4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">降维;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B7%AE%E5%88%86%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">差分进化算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%96%B9%E5%B7%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">方差;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B9%B3%E5%9D%87%E4%B8%AD%E4%BD%8D%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">平均中位数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%96%87%E6%9C%AC%E8%81%9A%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">文本聚类;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    肖晓丽 (1965—) , 女, 教授, 主研方向为数据挖掘、网络安全、移动通信、数据库;
;
                                </span>
                                <span>
                                    吴瑶, 硕士研究生E-mail: wyao726@ 163. com;
;
                                </span>
                                <span>
                                    周锡玲, 硕士;
;
                                </span>
                                <span>
                                    廖卓凡, 博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2017-12-14</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61402056);</span>
                    </p>
            </div>
                    <h1>Two-stage Text Feature Selection Algorithm Based on Differential Evolution</h1>
                    <h2>
                    <span>XIAO Xiaoli</span>
                    <span>WU Yao</span>
                    <span>ZHOU Xiling</span>
                    <span>LIAO Zhuofan</span>
            </h2>
                    <h2>
                    <span>College of Computer and Communication Engineering, Changsha University of Science and Technology</span>
                    <span>Hunan Provincial Key Laboratory of Intelligent Processing of Big Data on Transportation, Changsha University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to reduce the text feature space dimension and improve the efficiency of data mining processing data, a two-stage text feature selection algorithm is proposed. By combining the variance and the mean median to construct a high-correlation feature subset, the initial dimension reduction is performed as the initial feature population of the differential evolution algorithm. Then the differential evolution algorithm is improved. By using the cumulative word frequency of the feature words and the document frequency to design the fitness function, multiple feature difference vectors and local optimal features are introduced into the mutation operation, which increases the perturbation of the feature subset and accelerates the differential evolution algorithm. The convergence speed is obtained to obtain the optimal feature subset. Simulation experiments on the WebKB and Reuters-21578 datasets show that the algorithm can improve the clustering accuracy, recall rate and F1 value based on the effective reduction of the text feature space dimension.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hybrid%20feature%20selection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hybrid feature selection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dimension%20reduction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dimension reduction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Differential%20Evolutionary%20(DE)%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Differential Evolutionary (DE) algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=variance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">variance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=mean%20median&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">mean median;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=text%20clustering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">text clustering;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2017-12-14</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="67" name="67" class="anchor-tag">0概述</h3>
                <div class="p1">
                    <p id="68">文本挖掘是一种从文本数据中抽取有用信息的计算机处理技术, 但文本特征的高维性质给文本挖掘带来较大困难。因此, 研究有效的特征选择算法对文本挖掘具有重要的意义。</p>
                </div>
                <div class="p1">
                    <p id="69">特征选择是从原始高维特征空间选择一个低维子集并保留足够的信息, 主要有过滤和封装2种方法。过滤是基于统计的方法分析特征重要性, 从而筛选特征子集, 其代表方法有文档频率 (Document Frequency, DF) <citation id="206" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、单词贡献度 (Term Contribution, TC) <citation id="207" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、方差 (Term Variance, TV) <citation id="208" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等。文献<citation id="209" type="reference">[<a class="sup">4</a>]</citation>提出平均绝对差 (Mean Absolute Difference, MAD) 和平均中位数 (Mean-Median, MM) 用于高维数据的降维。过滤方法简单且计算效率高, 但选择出的特征子集精度较低。封装是利用学习结果作为衡量特征子集的标准。该方法依赖于特定的模型且计算成本高, 常用随机搜索方法来减少时间消耗, 如遗传算法<citation id="210" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、蚁群优化算法<citation id="211" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、粒子群优化算法<citation id="212" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>等。文献<citation id="213" type="reference">[<a class="sup">8</a>]</citation>提出差分进化算法 (Differential Evolution, DE) , 该算法具有受控参数少、鲁棒性强等优点。文献<citation id="214" type="reference">[<a class="sup">9</a>]</citation>提出具有自适应策略和控制参数的DE算法, 用于解决无约束优化问题。文献<citation id="215" type="reference">[<a class="sup">10</a>]</citation>提出一种改进的DE和SOM相结合的文档聚类算法, 封装方法精度较高, 但效率较低。</p>
                </div>
                <div class="p1">
                    <p id="70">近年来, 国内外学者在特征选择领域利用混合方法进行降维。文献<citation id="218" type="reference">[<a class="sup">11</a>]</citation>利用熵函数与DF混合的特征选择方法 (即ECDF) 筛选特征子集。文献<citation id="219" type="reference">[<a class="sup">12</a>]</citation>提出MAD与绝对余弦结合的两阶段方法 (MADAC) 寻找最优特征子集。文献<citation id="220" type="reference">[<a class="sup">13</a>]</citation>提出基于信息熵和领域分析的加权特征选择算法。文献<citation id="216" type="reference">[<a class="sup">14</a>]</citation>结合TV与DF提出TDM5算法, 通过改进并操作获取最优特征子集。文献<citation id="217" type="reference">[<a class="sup">15</a>]</citation>提出一种人工蜂群优化方法与DE结合的混合特征选择算法。</p>
                </div>
                <div class="p1">
                    <p id="71">针对单阶段特征选择算法的不足以及DE算法收敛速度较慢的问题, 本文提出一种基于改进DE的两阶段文本特征选择算法。该算法在过滤阶段使用TV及MM分别计算特征相关评分值, 将各自评分值靠前的特征进行融合, 得到高相关性特征子集, 实现特征的初步降维。封装阶段采用改进的DE算法提取最优特征子集进一步降维。改进的DE算法利用文档频率和累积特征词频率构建适应度函数, 合理地评价特征子集, 并在变异操作中引入局部最优特征及多个差向量策略, 加快算法的收敛速度, 提高算法的全局搜索能力。</p>
                </div>
                <h3 id="72" name="72" class="anchor-tag">1 文本特征空间模型</h3>
                <div class="p1">
                    <p id="73">由于给定的文本集合无法被计算机直接处理, 因此使用之前需要进行预处理, 其处理包括停用词过滤及特征空间模型的建立。</p>
                </div>
                <div class="p1">
                    <p id="74">1) 停用词过滤</p>
                </div>
                <div class="p1">
                    <p id="75">本文根据停用词表 (http://jmlr.org/papers/volume5/lew is04a/a11-smart-stop-list/english.stop) 过滤文本集合中的停用词, 将剩下的词汇作为文本集合的特征词集T, 即T={t<sub>1</sub>, t<sub>2</sub>, …, t<sub>n</sub>}。</p>
                </div>
                <div class="p1">
                    <p id="78">2) 特征空间模型构建</p>
                </div>
                <div class="p1">
                    <p id="79">本文用T表示向量空间模型 (Vector Space Model, VSM) , 使用词频乘以反文档频率 (TF (d, t) ×IDF (d, t) ) 来计算特征权值w<sub>d, t</sub>, TF (d, t) 和IDF (d, t) 计算公式为:</p>
                </div>
                <div class="area_img" id="80">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902050_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="82">其中, z<sub>d, t</sub>表示特征词t在文本d中出现的次数, <image id="188" type="formula" href="images/JSJC201902050_18800.jpg" display="inline" placement="inline"><alt></alt></image>表示在文本d中所有特征词出现次数之和, m表示文本集合中的文本总数, z表示包含特征词t的文本数目, z+1是为了保证分母不为0。</p>
                </div>
                <div class="p1">
                    <p id="83">定义文本集合中的每个文本d (1≤d≤m) 映射为空间中的一个行向量, 由文本特征词 (t<sub>1</sub>, t<sub>2</sub>, …, t<sub>n</sub>) 构成, 文本d由特征权重向量 (w<sub>d, 1</sub>, w<sub>d, 2</sub>, …, w<sub>d, n</sub>) 表示。含有n个特征词的文本d的特征权重向量用X (d) = (w<sub>d, 1</sub>, w<sub>d, 2</sub>, …, w<sub>d, n</sub>) 表示, 其中, w<sub>d, t</sub>表示文本d中特征词t的权重值。向量空间模型构建过程如图1所示。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902050_08400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 特征空间模型构建" src="Detail/GetImg?filename=images/JSJC201902050_08400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 特征空间模型构建  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902050_08400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="85" name="85" class="anchor-tag">2 改进差分进化的两阶段特征选择算法</h3>
                <div class="p1">
                    <p id="86">特征选择本质上为一个寻优过程, 本文提出一种基于差分进化的两阶段文本特征选择算法, 主要框架如图2所示, 通过该算法提取最优特征子集。过滤阶段使用TV及MM过滤不相关特征, 构建高相关性特征子集, 实现初步降维。封装阶段利用改进的DE算法获取最优特征子集, 进一步降低特征空间维度。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902050_08700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 改进差分进化的两阶段特征选择算法框架" src="Detail/GetImg?filename=images/JSJC201902050_08700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 改进差分进化的两阶段特征选择算法框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902050_08700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="88" name="88">2.1 高相关性特征子集构建</h4>
                <div class="p1">
                    <p id="89">在过滤阶段, 仅靠单一的过滤方法进行特征选择, 存在部分重要特征滤除的现象。TV方法能够准确地反映特征的类别区分能力, 选择出具有类别信息的特征, 但会忽略特征之间的相关性。MM方法可以选择出具有相关性的特征, 因此将两者方法结合, 优势互补扩大特征的选择范围, 从而更加精确地选择出有用的特征, 提高特征选择的准确性。因此, 本文结合TV及MM 2种方法筛选高相关性特征, 实现特征的初步降维。</p>
                </div>
                <div class="p1">
                    <p id="90">1) TV方法</p>
                </div>
                <div class="p1">
                    <p id="91">TV是基于特征与其平均值的差值来为每个特征分配相关性评分值<citation id="221" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 可用于选择具有鉴别类信息的特征。计算公式为:</p>
                </div>
                <div class="area_img" id="92">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902050_09200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="93">其中, X<sub>d, t</sub>是文本d中的特征词t的值, <image id="189" type="formula" href="images/JSJC201902050_18900.jpg" display="inline" placement="inline"><alt></alt></image>表示特征词t的平均值, 其计算公式为:</p>
                </div>
                <div class="area_img" id="94">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902050_09400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="95">2) M M方法</p>
                </div>
                <div class="p1">
                    <p id="96">M M是根据平均值和中间值之间的绝对差来为每个特征分配相关性评分值<citation id="222" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 可用于选择具有相关性信息的特征。计算公式如式 (5) 所示。</p>
                </div>
                <div class="area_img" id="97">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902050_09700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="98">其中, median (X<sub>t</sub>) 表示特征词t的中间值。</p>
                </div>
                <div class="p1">
                    <p id="99">3) 高相关性特征子集构建</p>
                </div>
                <div class="p1">
                    <p id="100">设S是原始文本集合, 经过停用词过滤后得到特征集合, 表示为T={t<sub>1</sub>, t<sub>2</sub>, …, t<sub>n</sub>}。根据式 (3) 得到特征的相关性分值, 并将T中的特征按照其分值进行降序排列, 选出前q个相关性高的特征组成特征子集, 表示为FS<sub>1</sub>={a<sub>1</sub>, a<sub>2</sub>, …, a<sub>q</sub>}, a<sub>i</sub>∈T。同理, 通过式 (5) 计算相关性分值及排序筛选得到特征子集FS<sub>2</sub>={b<sub>1</sub>, b<sub>2</sub>, …, b<sub>p</sub>}, b<sub>i</sub>∈T。使用合并操作将FS<sub>1</sub>和FS<sub>2</sub>融合得到高相关性特征子集FS<sub>3</sub>, 可表示为:</p>
                </div>
                <div class="area_img" id="101">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902050_10100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="102" name="102">2.2 基于DE的特征提取</h4>
                <div class="p1">
                    <p id="103">DE算法是基于群体差异的启发式随机搜索算法, 通过进行变异、交叉、选择操作, 不断迭代计算, 对比每一个个体的适应度值, 按照优胜劣汰的方式选择个体, 引导搜索过程向最优解逼近。</p>
                </div>
                <div class="p1">
                    <p id="104">在封装阶段, 本文利用改进DE算法过滤冗余特征, 提取最优特征子集, 进一步降低特征空间维度。</p>
                </div>
                <h4 class="anchor-tag" id="105" name="105">2.2.1 初始化特征种群</h4>
                <div class="p1">
                    <p id="106">将式 (6) 所得的高相关性特征子集FS<sub>3</sub>作为DE算法的初始特征种群<image id="190" type="formula" href="images/JSJC201902050_19000.jpg" display="inline" placement="inline"><alt></alt></image>, 其中, x<sub>i</sub><sup>g</sup>表示第g次迭代的第i个特征向量, <image id="191" type="formula" href="images/JSJC201902050_19100.jpg" display="inline" placement="inline"><alt></alt></image><image id="191" type="formula" href="images/JSJC201902050_19101.jpg" display="inline" placement="inline"><alt></alt></image>表示每个特征向量均有D个特征, <image id="192" type="formula" href="images/JSJC201902050_19200.jpg" display="inline" placement="inline"><alt></alt></image>代表第g代第i个特征向量中的第j个特征。初始化种群规模NP、空间维数D、变异因子F、交叉因子CR和最大迭代次数G。</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107">2.2.2 适应度函数设计</h4>
                <div class="p1">
                    <p id="108">适应度函数用于评价特征子集的优劣, 在选择下一代子集中具有至关重要的作用。特征子集的筛选过程是通过对比适应度值的大小, 将适应度值小的特征子集遗传到下一代。特征子集中特征词的重要程度与其在文本中出现的次数成正比, 与其在文本集合中出现的频率成反比。因此, 本文将特征词的累计词频与文档频率进行加权计算来得到特征子集的适应度值。适应度函数可表示为:</p>
                </div>
                <div class="area_img" id="109">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902050_10900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="110">其中, δ是设定的阈值, 其作用是调节特征词的累计词频和文档频率对特征重要度的权衡, δ∈[0, 1]。∑TF (d, x) 表示特征词x的累积词频, 其计算如式 (8) 所示。DF<sub>x</sub>表示特征词x的文档频率, 其计算如式 (9) 所示。</p>
                </div>
                <div class="area_img" id="111">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902050_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="112" name="112">2.2.3 变异操作</h4>
                <div class="p1">
                    <p id="113">DE算法的核心是变异操作。变异操作可理解为一种局部搜索操作, 其形式是基向量与一个加权的差向量相加, 基向量引导种群进化的方向, 充当局部搜索的中心, 差向量起到随机扰动的作用, 决定局部搜索范围。但由于基向量是从种群中随机挑选, 使得种群的进化方向不够集中, 导致算法的收敛速度较慢, 搜索效率较低。为此, 本文对DE算法的变异操作进行改进。</p>
                </div>
                <div class="p1">
                    <p id="114">在当前特征种群中, 以局部最优特征向量<image id="193" type="formula" href="images/JSJC201902050_19300.jpg" display="inline" placement="inline"><alt></alt></image>作为基向量, 用来引导特征种群的进化方向, 使得特征向量围绕在最优特征向量附近进行搜索, 加快算法的收敛速度, 优化算法的迭代次数。文献<citation id="223" type="reference">[<a class="sup">16</a>]</citation>表明2个差向量策略比单个差向量具有更好的扰动性, 能提高算法的搜索能力。因此, 本文引入局部最优特征向量<image id="194" type="formula" href="images/JSJC201902050_19400.jpg" display="inline" placement="inline"><alt></alt></image>与随机向量x<sub>α</sub><sup>g</sup>的差向量, 记作<image id="195" type="formula" href="images/JSJC201902050_19500.jpg" display="inline" placement="inline"><alt></alt></image>, 增加特征的扰动性, 从而避免陷入局部最优, 提高算法的全局搜索能力。改进后的变异特征向量<image id="196" type="formula" href="images/JSJC201902050_19600.jpg" display="inline" placement="inline"><alt></alt></image>中的变异特征可表示为:</p>
                </div>
                <div class="area_img" id="115">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902050_11500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="116">其中, <image id="197" type="formula" href="images/JSJC201902050_19700.jpg" display="inline" placement="inline"><alt></alt></image>表示当前种群中最优特征向量, <image id="198" type="formula" href="images/JSJC201902050_19800.jpg" display="inline" placement="inline"><alt></alt></image><image id="198" type="formula" href="images/JSJC201902050_19801.jpg" display="inline" placement="inline"><alt></alt></image>是特征种群中随机选择的3个特征向量, 并且i≠α≠β≠λ, <image id="199" type="formula" href="images/JSJC201902050_19900.jpg" display="inline" placement="inline"><alt></alt></image><image id="199" type="formula" href="images/JSJC201902050_19901.jpg" display="inline" placement="inline"><alt></alt></image>分别为特征向量<image id="200" type="formula" href="images/JSJC201902050_20000.jpg" display="inline" placement="inline"><alt></alt></image>的第j个特征。F为变异因子, 取值范围为[0, 2]。</p>
                </div>
                <h4 class="anchor-tag" id="117" name="117">2.2.4 交叉操作</h4>
                <div class="p1">
                    <p id="118">由变异特征向量v<sub>i</sub><sup>g</sup>和父代特征向量x<sub>i</sub><sup>g</sup>进行交叉操作, 交换v<sub>i</sub><sup>g</sup>和x<sub>i</sub><sup>g</sup>的部分特征产生试验特征向量u<sub>i</sub><sup>g</sup>, 使得携带有用信息的特征能继续遗传, 从而提高特征种群的多样性。试验特征向量<image id="201" type="formula" href="images/JSJC201902050_20100.jpg" display="inline" placement="inline"><alt></alt></image><image id="201" type="formula" href="images/JSJC201902050_20101.jpg" display="inline" placement="inline"><alt></alt></image>的计算方法如式 (11) 所示。</p>
                </div>
                <div class="area_img" id="119">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902050_11900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="120">其中, rand[0, 1]是区间[0, 1]中的随机数, CR为交叉因子, CR∈[0, 1]。CR的值越大, 发生交叉的概率越大。jrand是[1, D]中随机选择的一个整数, 保证u<sub>i</sub><sup>g</sup>至少要从v<sub>i</sub><sup>g</sup>中获得一个特征, 确保试验特征向量与父代特征向量的差异性。</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121">2.2.5 选择操作</h4>
                <div class="p1">
                    <p id="122">本文采用“贪婪”选择策略来决定是父代特征向量x<sub>i</sub><sup>g</sup>还是试验特征向量u<sub>i</sub><sup>g</sup>传递给下一代X (g+1) 。根据适应度函数获得x<sub>i</sub><sup>g</sup>与u<sub>i</sub><sup>g</sup>的适应度值, 比较两者的适应度值大小, 若x<sub>i</sub><sup>g</sup>对应的适应值较小, 则选择特征向量x<sub>i</sub><sup>g</sup>, 反之选择特征向量u<sub>i</sub><sup>g</sup>。选择操作计算公式为:</p>
                </div>
                <div class="area_img" id="123">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902050_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="124">其中, fitness (x) 为适应度函数。</p>
                </div>
                <h4 class="anchor-tag" id="125" name="125">2.2.6 改进的DE算法步骤</h4>
                <div class="p1">
                    <p id="126">本文通过设定有效的适应度函数, 并改进DE算法的变异操作, 以加快算法的收敛速度。具体算法步骤描述如下:</p>
                </div>
                <div class="p1">
                    <p id="127">输入高相关性特征集FS<sub>3</sub></p>
                </div>
                <div class="p1">
                    <p id="128">输出最优特征子集X<sub>best</sub></p>
                </div>
                <div class="p1">
                    <p id="129">步骤1种群和参数初始化。将FS<sub>3</sub>表示为特征种群规模NP、空间维数为D的二维矩阵X (g) , 初始化最大迭代次数G、变异因子F、交叉因子CR和阈值δ且令g=1。</p>
                </div>
                <div class="p1">
                    <p id="130">步骤2获取特征子集的适应度值。利用式 (7) 获得每个特征向量的适应度值fitness (X<sub>i</sub> (g) ) , 并选择最小适应度值的特征向量设为当前种群的最优特征向量X<sub>best</sub> (g) 。</p>
                </div>
                <div class="p1">
                    <p id="131">步骤3变异操作。在第g代种群X (g) 中随机选取3个互不相同的特征向量<image id="202" type="formula" href="images/JSJC201902050_20200.jpg" display="inline" placement="inline"><alt></alt></image>, 根据式 (10) , 对种群中的特征向量进行变异操作, 产生变异特征向量v<sub>i</sub><sup>g</sup>。</p>
                </div>
                <div class="p1">
                    <p id="132">步骤4交叉操作。将变异特征向量v<sub>i</sub><sup>g</sup>和父代特征向量x<sub>i</sub><sup>g</sup>进行交叉操作, 由式 (11) 得试验特征向量u<sub>i</sub><sup>g</sup>。</p>
                </div>
                <div class="p1">
                    <p id="133">步骤5选择操作。按照式 (12) 执行选择操作, 产生第g+1代的特征向量X (g+1) 。</p>
                </div>
                <div class="p1">
                    <p id="134">步骤6如果当前进化迭代次数g=G, 则算法结束并输出最优特征向量X<sub>best</sub>, 即为最优特征子集;否则, 令g=g+1并转到步骤2。</p>
                </div>
                <h4 class="anchor-tag" id="135" name="135">2.3 两阶段特征选择算法</h4>
                <div class="p1">
                    <p id="136">本文通过改进差分进化算法得到特征的最优子集, 进一步降低文本特征空间的维度。基于差分进化的两阶段文本特征选择算法步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="137">输入文本集合S</p>
                </div>
                <div class="p1">
                    <p id="138">输出最优特征子集X<sub>best</sub></p>
                </div>
                <div class="p1">
                    <p id="139">步骤1对集合S中的特征词进行预处理, 即过滤停用词, 将剩下的特征词作为S的特征词集, 表示为T, 其中, T={t<sub>1</sub>, t<sub>2</sub>, …, t<sub>n</sub>}。</p>
                </div>
                <div class="p1">
                    <p id="140">步骤2文本特征空间模型的建立。使用VSM表示特征集合T, 得到特征权重二维矩阵X (d) , 并利用TF-IDF计算每个特征的权重值w<sub>d, t</sub>, 其中, d∈[1, m], t∈[1, n]。</p>
                </div>
                <div class="p1">
                    <p id="141">步骤3过滤阶段。构建高相关性特征子集FS<sub>3</sub>, 按照式 (3) 和式 (5) 分别计算每个特征词的相关性评分值, 分别对相关性评分值进行降序排列并按比例各自选出相关性评分值靠前的特征, 得到特征子集FS<sub>1</sub>和FS<sub>2</sub>, 将两组所得的子集按式 (6) 进行并集, 得到高相关性特征子集FS<sub>3</sub>。</p>
                </div>
                <div class="p1">
                    <p id="142">步骤4封装阶段。获取最优特征子集X<sub>best</sub>, 将FS<sub>3</sub>表示为种群规模NP、空间维数为D的二维矩阵X (g) 作为本文改进的DE算法的初始种群, 按照第2.2.6节中的算法步骤不断进行迭代计算, 最终获取最优特征子集X<sub>best</sub>。</p>
                </div>
                <h3 id="143" name="143" class="anchor-tag">3 仿真结果与分析</h3>
                <h4 class="anchor-tag" id="144" name="144">3.1 数据来源及评价指标</h4>
                <div class="p1">
                    <p id="145">本文使用的数据和评价指标具体分析如下:</p>
                </div>
                <div class="p1">
                    <p id="146">1) 数据来源</p>
                </div>
                <div class="p1">
                    <p id="147">为了验证本文算法的有效性, 采用2个常用的公开数据集WebKB (即W) 和数据集Reuters-21578 (即R) 从中随机抽取部分文本进行聚类的实验对比。表1列出数据集的名称及其相关信息。在实验中, 随机选取每个数据集中1/3的数据作为测试集, 其余为训练集。</p>
                </div>
                <div class="area_img" id="148">
                                            <p class="img_tit">
                                                表1 实验数据集
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902050_14800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201902050_14800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902050_14800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 实验数据集" src="Detail/GetImg?filename=images/JSJC201902050_14800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="149">2) 评价指标</p>
                </div>
                <div class="p1">
                    <p id="150">为验证本文算法的有效性, 通过以下方式进行验证:将选择的最优特征子集应用于文本聚类中, 用文本聚类的指标间接反映特征选择算法的有效性。</p>
                </div>
                <div class="p1">
                    <p id="151">本文采用在聚类中常用的3个评价指标来衡量算法:准确率 (Precision) , 召回率 (Recall) 和F1值 (F1) 。准确率指聚类结果的正确性, 衡量的是文档聚类的查准率, 其值越大, 表示聚类结果的准确性越高。召回率指聚类结果的完整性, 衡量的是文档聚类的查全率, 其值越大, 表示聚类结果的完整性越好。F1测度综合考虑了准确率和召回率, 能较为全面地评估算法的好坏, 其值越大, 代表聚类效果越好。3个参数指标的数学表达式如下:</p>
                </div>
                <div class="area_img" id="152">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902050_15200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="153">其中, TP指聚在一类的2个文档被正确分类的文本个数, FP指不该放在一类的文档被错误放在一类的文本个数, FN指不该分开的文档被错误分开的文本个数。</p>
                </div>
                <h4 class="anchor-tag" id="154" name="154">3.2 收敛性对比</h4>
                <div class="p1">
                    <p id="155">为验证本文改进的DE算法比原始DE算法收敛速度快, 将2种算法收敛曲线进行对比, 结果如图3所示。从图3可以看出, 改进的DE算法的求解速度明显快于原始DE算法, 能在较少的迭代次数下求出更精确的解。本文在原DE算法的变异操作中引入局部最优特征向量<image id="203" type="formula" href="images/JSJC201902050_20300.jpg" display="inline" placement="inline"><alt></alt></image>, 以当前特征种群的最优特征向量<image id="204" type="formula" href="images/JSJC201902050_20400.jpg" display="inline" placement="inline"><alt></alt></image>为基向量能够加快收敛速度, 并通过<image id="205" type="formula" href="images/JSJC201902050_20500.jpg" display="inline" placement="inline"><alt></alt></image>引导的随机差向量增加扰动性, 继承性加强, 使得优秀的特征有较多的机会遗传至下一代。</p>
                </div>
                <div class="area_img" id="156">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902050_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 2种算法收敛曲线对比结果" src="Detail/GetImg?filename=images/JSJC201902050_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 2种算法收敛曲线对比结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902050_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="157" name="157">3.3 参数设置</h4>
                <div class="p1">
                    <p id="158">本文参数设置具体分析如下:</p>
                </div>
                <div class="p1">
                    <p id="159">1) 参数F和CR的选择</p>
                </div>
                <div class="p1">
                    <p id="160">变异因子F和交叉因子CR对DE算法的收敛性能和寻优结果具有十分重要的作用。在本文改进的DE算法中, 取变异因子F={0.4, 0.5, 0.6, 0.7, 0.8, 0.9}、交叉因子CR={0.2, 0.4, 0.6, 0.8, 1}进行实验分析。通过调整F和CR值进行聚类准确率的比较, 同时特征种群规模NP大小设置为8, 其终止条件是最大遗传迭代次数G为100。实验结果如图4所示。</p>
                </div>
                <div class="area_img" id="161">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902050_16100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 参数F和CR对聚类准确率的影响" src="Detail/GetImg?filename=images/JSJC201902050_16100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 参数F和CR对聚类准确率的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902050_16100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="162">从图4可以看出, 针对不同的变异因子F值, 聚类准确率随着F值的增大呈现先上升后下降的趋势。当F=0.5时, 准确率值最大。当F值相同的情况下, 准确率值随着交叉因子CR值的增大而增大, 说明了CR值越大, 聚类准确率越高。当F=0.5、CR=1时, 准确率最大, 聚类效果最好。因此, 本文DE算法中的变异因子F值设为0.5, 交叉因子CR值设为1。</p>
                </div>
                <div class="p1">
                    <p id="163">2) δ的选择</p>
                </div>
                <div class="p1">
                    <p id="164">本文适应度函数计算由特征词的累计词频与文档频率2部分构成, 参数δ作为平衡因子调节这两部分的权重。由于δ∈[0, 1], 每次增加0.1在数据集R上进行实验获取δ对聚类效果的影响, 实验结果如图5所示。从图5可以看出, 聚类准确率随着δ的增大先上升后下降。当δ值为0.2时, 准确率最大, 表明此时聚类效果最佳。因此, 本文δ的取值为0.2。</p>
                </div>
                <div class="area_img" id="165">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902050_16500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 参数δ对聚类准确率的影响" src="Detail/GetImg?filename=images/JSJC201902050_16500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 参数δ对聚类准确率的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902050_16500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="166" name="166">3.4 TV与MM结合的有效性验证</h4>
                <div class="p1">
                    <p id="167">为验证本文算法在过滤阶段将TV与MM方法结合的有效性, 将本文过滤阶段 (TV+MM) 进行特征选择与TV算法以及MM算法进行对比实验。在数据集R进行特征选择, 再将选择出的最优特征子集分别进行K-means聚类, 实验结果如图6所示。</p>
                </div>
                <div class="area_img" id="168">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902050_16800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 在过滤阶段各算法聚类准确率对比结果" src="Detail/GetImg?filename=images/JSJC201902050_16800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 在过滤阶段各算法聚类准确率对比结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902050_16800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="169">图6显示本文的过滤阶段将TV与MM结合算法、TV算法、MM算法的准确率情况。从图6可以看出, 将TV与MM进行结合后的算法准确率比单一的MM算法、TV算法都高, 说明两者结合选择出的特征涵盖信息更为全面, 可提高特征选择的准确性。</p>
                </div>
                <h4 class="anchor-tag" id="170" name="170">3.5 改进DE算法的有效性验证</h4>
                <div class="p1">
                    <p id="171">为验证本文改进DE算法的有效性, 将改进DE算法、原始DE算法、TV+MM+原始DE算法及TV+MM+改进DE算法在数据集R上进行对比实验, 将选择出的最优特征子集分别进行K-means聚类, 4种算法的聚类准确率实验结果如图7所示。</p>
                </div>
                <div class="area_img" id="172">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902050_17200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 4种算法聚类准确率对比结果" src="Detail/GetImg?filename=images/JSJC201902050_17200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 4种算法聚类准确率对比结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902050_17200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="173">从图7可以看出, 在不同的特征维度下, TV+M M+改进DE算法比TV+M M+原始DE算法的准确率高, 改进DE算法的准确率比原始DE算法高。2组对比实验说明改进的DE算法能有效提高聚类效果。</p>
                </div>
                <h4 class="anchor-tag" id="174" name="174">3.6 不同特征选择算法的聚类效果对比</h4>
                <div class="p1">
                    <p id="175">本文算法与TV、TC<citation id="224" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、ECDF<citation id="225" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、MADAC<citation id="226" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、TDM5<citation id="227" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>算法进行对比实验。其中, 前两者是单一的特征选择算法, 后三者为混合特征选择方法。</p>
                </div>
                <div class="p1">
                    <p id="176">将上述算法分别在数据集W和数据集R进行特征选择, 提取最优特征子集, 然后通过K-means聚类算法来验证本文算法的有效性。为了使结果更为可靠, 每组实验进行10次, 结果取平均值进行分析。</p>
                </div>
                <div class="p1">
                    <p id="177">1) 准确率对比</p>
                </div>
                <div class="p1">
                    <p id="178">图8表示各特征选择算法在不同数据集上的聚类准确率。从图8可以看出, 各特征选择算法在特征数量减少后, 依然具有较好的聚类效果, 并且混合特征选择方法的准确率普遍高于单一的特征选择算法, 同时, 本文算法在2个数据集上都具有较高的准确率。随着特征数量的增加, 聚类准确率会呈现先上升后下降的趋势。在数据集W上, 本文算法在特征数量为240左右, 准确率为最高峰, 而其他算法在特征数为450左右时准确率最高, 表明本算法能用更少的特征达到聚类的最佳效果;在数据集R上, 本文算法和TDM5算法在特征数为250左右时取得最高值, 而其他特征算法在特征数为330左右时准确率为高峰值。在特征数量相同的情况下, 本文算法的准确率优于其他特征选择算法, 且在获取准确率高峰值的特征数量均小于其他算法。综上所述, 本文算法能使用较少的特征数量, 获得较好的聚类效果。</p>
                </div>
                <div class="area_img" id="179">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902050_17900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同特征选择算法准确率对比结果" src="Detail/GetImg?filename=images/JSJC201902050_17900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同特征选择算法准确率对比结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902050_17900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="180">2) 召回率对比</p>
                </div>
                <div class="p1">
                    <p id="181">图9所示为各特征选择算法在不同特征数量下的召回率。从图9可以看出, 混合特征选择方法的召回率高于单一特征选择算法。在数据集W上, 本文算法和其他混合特征选择方法各有优势, 但都高于TC与TV算法。本文算法选择较小的特征数时, 召回率比较低, 说明在封装阶段去除冗余特征时可能会将极少具有鉴别类别信息的特征过滤掉。而在相对特征维数较高的数据集R上, 本文算法的召回率明显比其他5种特征选择算法高。因此, 本文算法更适用于高维数据集的特征筛选, 但特征的类间区分能力有待提高。</p>
                </div>
                <div class="p1">
                    <p id="182">3) F1值对比</p>
                </div>
                <div class="p1">
                    <p id="183">图10所示为各特征选择算法在不同特征数量下的F1值对比结果。F1值是一项综合性评价指标, 综合考虑准确率和召回率2种指标, 能更好的评价聚类效果。本文算法在2个数据集上的F1值比其他5种算法的高。因此, 本文算法能够以较少的特征数量获得较高的F1值, 在降低特征维数的同时保证聚类的准确性。</p>
                </div>
                <div class="area_img" id="184">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902050_18400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 0 不同特征选择算法F1值对比结果" src="Detail/GetImg?filename=images/JSJC201902050_18400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 0 不同特征选择算法F1值对比结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902050_18400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="185">综上, 本文算法不仅能降低特征空间的维度, 而且能够获得较好的聚类效果。</p>
                </div>
                <h3 id="186" name="186" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="187">本文提出基于差分进化的两阶段文本特征选择算法。在过滤阶段, 结合TV和MM 2种过滤方法进行特征选择, 扩大蕴涵重要特征信息的选择范围, 提高特征选择的准确性, 得到高相关性特征子集, 并实现初步降维。在封装阶段, 使用改进的DE算法过滤冗余特征, 获取最优的特征子集, 进一步降低特征空间子集的维度。实验结果表明, 本文算法在准确率、召回率和F1值上都优于其他同类算法, 具有较好的文本聚类效果。下一步将研究如何提高类间区分度, 以改进特征选择算法的聚类效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="35">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Comparative Study on Feature Selection in Text Categorization">

                                <b>[1]</b>YANG Y, PEDERSEN J O.A comparative study on feature selection in text categorization[C]//Proceedings of the 14th International Conference on Machine Learning.San Francisco, USA:Morgan Kaufmann Publishers Inc., 1997:412-420.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Evaluation on Feature Selection for Text Clustering">

                                <b>[2]</b>LIU T, LIU S, CHEN Z, et al.An evaluation on feature selection for text clustering[C]//Proceedings of the20th International Conference on Machine Learning.[S.l.]:AAAI Press, 2003:488-495.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A comparative study on unsupervised feature selection methods for text clustering">

                                <b>[3]</b>LIU L, KANG J, YU J, et al.A comparative study on unsupervised feature selection methods for text clustering[C]//Proceedings of IEEE International Conference on Natural Language Processing and Knowledge Engineering.Washington D.C., USA:IEEE Press, 2005:597-601.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300413182&amp;v=MjQ0NjRIeWptVUxiSUlGOGRieEU9TmlmT2ZiSzdIdERPckk5RllPb01EWFE3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>FERREIRA A J, FIGUEIREDO M A T.Efficient feature selection filters for high-dimensional data[J].Pattern Recognition Letters, 2012, 33 (13) :1794-1804.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14061700212063&amp;v=MDU3MDVGOGRieEU9TmlmT2ZiSzhIdGZOcUk5Rlp1b05ESG82b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>UYSAL A K, GUNAL S.Text classification using genetic algorithm oriented latent semantic features[J].Expert Systems with Applications, 2014, 41 (13) :5938-5947.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1E2F3289975FD1481BDDCBB690A97EEB&amp;v=MjgxNDVMbTJ4YXM9TmlmT2ZiTE5IS2ZQcllkTWJld0tlZ2c0eXg0U21Fc0pPdzJRcWhzMUNMdVRNTS90Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZoeA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>MORADI P, ROSTAMI M.Integration of graph clustering with ant colony optimization for feature selection[J].Knowledge-Based Systems, 2015, 84:144-161.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Text Feature Selection Using ParticleSwarm Optimization Algorithm">

                                <b>[7]</b>ZAHRAN B M, KANAAN G.Text feature selection using particle swarm optimization algorithm[J].World Applied Sciences Journal, 2009, 7:69-74.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002859935&amp;v=MjMyODF1ZHRGQ0hsVTc3QkpWMD1OajdCYXJPNEh0SE9wNHBNYmVnS1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVi&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>STORN R, PRICE K.Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces[J].Journal of Global Optimization, 1997, 11 (4) :341-359.309
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122600543142&amp;v=MTY4MjdQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGOGRieEU9TmlmT2ZiSzlIOVBPcVk5RlllOE1EWGc3b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>ZHAO Z, YANG J, HU Z, et al.A differential evolution algorithm with self-adaptive strategy and control parameters based on symmetric Latin hypercube design for unconstrained optimization problems[J].European Journal of Operational Research, 2016, 250 (1) :30-45.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYXH201505003&amp;v=MDk5NjF6VFRackc0SDlUTXFvOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeWprV3JyTEw=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>姜凯, 苑金海.融合差分进化和SOM的组合文本聚类算法[J].计算机与现代化, 2015 (5) :13-16.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJB201201015&amp;v=MDA0OTFNcm85RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5amtXcnJMSWpYQmJMRzRIOVA=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>樊东辉, 王治和, 陈建华, 等.基于DF算法改进的文本聚类特征选择算法[J].兰州文理学院学报 (自然科学版) , 2012, 26 (1) :51-54.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A two-stage unsupervised dimension reduction method for text clustering">

                                <b>[12]</b>BHARTI K K, SINGH P K.A two-stage unsupervised dimension reduction method for text clustering[C]//Proceedings of the 7th International Conference on BioInspired Computing:Theories and Applications.Berlin, Germany:Springer, 2013:529-542.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic subspace clustering of high dimensional data for data mining applications">

                                <b>[13]</b>AGRAWAL R, GEHRKE J, GUNOPULOS D, et al.Automatic subspace clustering of high dimensional data for data mining applications[C]//Proceedings of ACMSIGMOD International Conference on Management of Data.New York, USA:ACM Press, 1998:94-105.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESAFB0E02C32426F329A34EBF8ED8A30BF&amp;v=MDI5OTV2RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh4TG0yeGFzPU5pZk9mY0xPYk5HNXI0MDJaK2tMRG5wUHpCUWFteng1UFEyVXBHZEJjY09YUmNqcENPTg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>BHARTI K K, SINGH P K.Hybrid dimension reduction by integrating feature selection with feature extraction method for text clustering[J].Expert Systems with Applications, 2015, 42 (6) :3105-3114.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A hybrid approach of differential evolution and artificial bee colony for feature selection">

                                <b>[15]</b>ZORARPACI E, ZEL S A.A hybrid approach of differential evolution and artificial bee colony for feature selection[J].Expert Systems with Applications, 2016, 62:91-103.
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Differential evolution algorithm with strategy adaptation for global numerical optimization">

                                <b>[16]</b>QIN A K, HUANG V L, SUGANTHAN P N.Differential evolution algorithm with strategy adaptation for global numerical optimization[J].IEEE Transactions on Evolutionary Computation, 2009, 13 (2) :398-417.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201902050" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902050&amp;v=MDAwNDFyQ1VSTE9lWmVSbkZ5amtXcnJMTHo3QmJiRzRIOWpNclk5QVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
