<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130634411212500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201903032%26RESULT%3d1%26SIGN%3dE9JhpxoXrmpzp02GIxa17GvfvVc%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903032&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903032&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903032&amp;v=MjQ4MjRSTE9lWmVSb0Z5N2xVcjNQTHo3QmJiRzRIOWpNckk5R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#41" data-title="1 问题定义 ">1 问题定义</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="1.1 相关概念及定义">1.1 相关概念及定义</a></li>
                                                <li><a href="#52" data-title="1.2 轨迹恢复">1.2 轨迹恢复</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#56" data-title="2 轨迹恢复集成方法 ">2 轨迹恢复集成方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="2.1 数据预处理">2.1 数据预处理</a></li>
                                                <li><a href="#67" data-title="2.2 个体分类器训练">2.2 个体分类器训练</a></li>
                                                <li><a href="#83" data-title="2.3 分类器集成">2.3 分类器集成</a></li>
                                                <li><a href="#88" data-title="2.4 算法伪代码流程">2.4 算法伪代码流程</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#127" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#128" data-title="3.1 数据集">3.1 数据集</a></li>
                                                <li><a href="#135" data-title="3.2 实验分析">3.2 实验分析</a></li>
                                                <li><a href="#156" data-title="3.3 实验对比">3.3 实验对比</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#159" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="&lt;b&gt;表1 本文符号定义&lt;/b&gt;"><b>表1 本文符号定义</b></a></li>
                                                <li><a href="#48" data-title="&lt;b&gt;图1 轨迹示意图&lt;/b&gt;"><b>图1 轨迹示意图</b></a></li>
                                                <li><a href="#58" data-title="&lt;b&gt;图2 轨迹恢复集成算法框架&lt;/b&gt;"><b>图2 轨迹恢复集成算法框架</b></a></li>
                                                <li><a href="#63" data-title="&lt;b&gt;图3 3种由不同时间稀疏程度轨迹组成的连接轨迹&lt;/b&gt;"><b>图3 3种由不同时间稀疏程度轨迹组成的连接轨迹</b></a></li>
                                                <li><a href="#69" data-title="&lt;b&gt;图4 LSTM网络结构&lt;/b&gt;"><b>图4 LSTM网络结构</b></a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;表2 训练集、样本集和个体分类器&lt;/b&gt;"><b>表2 训练集、样本集和个体分类器</b></a></li>
                                                <li><a href="#131" data-title="&lt;b&gt;表3 测试集&lt;/b&gt;"><b>表3 测试集</b></a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;图5&lt;/b&gt; “&lt;b&gt;稀疏适中+稀疏适中”分布的个体分类器准确性比较结果&lt;/b&gt;"><b>图5</b> “<b>稀疏适中+稀疏适中”分布的个体分类器准确性比较结果</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;图6&lt;/b&gt; “&lt;b&gt;较密集+较稀疏”分布的个体分类器准确性比较结果&lt;/b&gt;"><b>图6</b> “<b>较密集+较稀疏”分布的个体分类器准确性比较结果</b></a></li>
                                                <li><a href="#146" data-title="&lt;b&gt;表4 在不同大小样本集、不同分布下个体分类器数目表&lt;/b&gt;"><b>表4 在不同大小样本集、不同分布下个体分类器数目表</b></a></li>
                                                <li><a href="#147" data-title="&lt;b&gt;图7 在“稀疏适中+稀疏适中”分布下的强分类器准确性比较结果&lt;/b&gt;"><b>图7 在“稀疏适中+稀疏适中”分布下的强分类器准确性比较结果</b></a></li>
                                                <li><a href="#148" data-title="&lt;b&gt;图8 在“较密集+较稀疏”分布下的强分类器准确性比较结果&lt;/b&gt;"><b>图8 在“较密集+较稀疏”分布下的强分类器准确性比较结果</b></a></li>
                                                <li><a href="#151" data-title="&lt;b&gt;图9 在不同大小样本集下2种分布结合形成的强分类器准确性比较结果&lt;/b&gt;"><b>图9 在不同大小样本集下2种分布结合形成的强分类器准确性比较结果</b></a></li>
                                                <li><a href="#154" data-title="&lt;b&gt;图10 在不同大小样本集下个体分类器准确性比较结果&lt;/b&gt;"><b>图10 在不同大小样本集下个体分类器准确性比较结果</b></a></li>
                                                <li><a href="#158" data-title="&lt;b&gt;图11 3种算法准确性对比结果&lt;/b&gt;"><b>图11 3种算法准确性对比结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" SHANG S, GUO D, LIU J, et al.Human mobility prediction and unobstructed route planning in public transport networks[C]//Proceedings of the 15th International Conference on Mobile Data Management.Washington, D.C., USA:IEEE Computer Society, 2014:43-48." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Human mobility prediction and unobstructed route planning in public transport networks">
                                        <b>[1]</b>
                                         SHANG S, GUO D, LIU J, et al.Human mobility prediction and unobstructed route planning in public transport networks[C]//Proceedings of the 15th International Conference on Mobile Data Management.Washington, D.C., USA:IEEE Computer Society, 2014:43-48.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" WU G, DING Y, LI Y, et al.Mining spatio-temporal reachable regions over massive trajectory data[C]//Proceedings of the 33rd International Conference on Data Engineering.Washington D.C., USA:IEEE Press, 2017:1283-1294." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mining Spatio-Temporal Reachable Regions over Massive Trajectory Data">
                                        <b>[2]</b>
                                         WU G, DING Y, LI Y, et al.Mining spatio-temporal reachable regions over massive trajectory data[C]//Proceedings of the 33rd International Conference on Data Engineering.Washington D.C., USA:IEEE Press, 2017:1283-1294.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" SIQUEIRA F D L, PLENTZ P D M, PIERI E R D.Semantic trajectory applied to the navigation of autonomous mobile robots[C]//Proceedings of the 13th International Conference of Computer Systems and Applications.Washington D.C., USA:IEEE Press, 2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semantic trajectory applied to the navigation of autonomous mobile robots">
                                        <b>[3]</b>
                                         SIQUEIRA F D L, PLENTZ P D M, PIERI E R D.Semantic trajectory applied to the navigation of autonomous mobile robots[C]//Proceedings of the 13th International Conference of Computer Systems and Applications.Washington D.C., USA:IEEE Press, 2017.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" BHUNIA A K, BHOWMICK A, BHUNIA A K, et al.Handwriting trajectory recovery using end-to-end deep encoder-decoder network [EB/OL].[2017-12-05].https://arxiv.org/ftp/arxiv/papers/1801/1801.07211. pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Handwriting trajectory recovery using end-to-end deep encoder-decoder network">
                                        <b>[4]</b>
                                         BHUNIA A K, BHOWMICK A, BHUNIA A K, et al.Handwriting trajectory recovery using end-to-end deep encoder-decoder network [EB/OL].[2017-12-05].https://arxiv.org/ftp/arxiv/papers/1801/1801.07211. pdf.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" NOUBIGH Z, KHERALLAH M.A survey on handwriting recognition based on the trajectory recovery technique[C]//Proceedings of International Workshop on Arabic Script Analysis and Recognition.Washington D.C., USA:IEEE Press, 2017:69-73." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A survey on handwriting recognition based on the trajectory recovery technique">
                                        <b>[5]</b>
                                         NOUBIGH Z, KHERALLAH M.A survey on handwriting recognition based on the trajectory recovery technique[C]//Proceedings of International Workshop on Arabic Script Analysis and Recognition.Washington D.C., USA:IEEE Press, 2017:69-73.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" LI X, SHU W, LI M, et al.Performance evaluation of vehicle-based mobile sensor networks for traffic monitoring[J].IEEE Transactions on Vehicular Technology, 2009, 58 (4) :1647-1653." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Performance evaluation of vehicle-based mobile sensor networks for traffic monitoring">
                                        <b>[6]</b>
                                         LI X, SHU W, LI M, et al.Performance evaluation of vehicle-based mobile sensor networks for traffic monitoring[J].IEEE Transactions on Vehicular Technology, 2009, 58 (4) :1647-1653.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" TONG C, CHEN H, QI X, et al.A framework for bus trajectory extraction and missing data recovery for data sampled from the internet[J].Sensors, 2017, 17 (2) :342." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A framework for bus trajectory extraction and missing data recovery for data sampled from the internet">
                                        <b>[7]</b>
                                         TONG C, CHEN H, QI X, et al.A framework for bus trajectory extraction and missing data recovery for data sampled from the internet[J].Sensors, 2017, 17 (2) :342.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" WU H, XUE M, CAO J, et al.Fuzzy trajectory linking[C]//Proceedings of the 32nd International Conference on Data Engineering.Washington D.C., USA:IEEE Press, 2016:859-870." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fuzzy trajectory linking">
                                        <b>[8]</b>
                                         WU H, XUE M, CAO J, et al.Fuzzy trajectory linking[C]//Proceedings of the 32nd International Conference on Data Engineering.Washington D.C., USA:IEEE Press, 2016:859-870.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 梁天新, 杨小平, 王良, 等.记忆神经网络的研究与发展[J].软件学报, 2017, 28 (11) :2905-2924." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201711009&amp;v=MTkwOTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdsVXIzT055ZlRiTEc0SDliTnJvOUZiWVE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         梁天新, 杨小平, 王良, 等.记忆神经网络的研究与发展[J].软件学报, 2017, 28 (11) :2905-2924.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 韩冬煦, 常宝宝.中文分词模型的领域适应性方法[J].计算机学报, 2015, 38 (2) :272-281." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201502005&amp;v=MjgzNDg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdsVXIzT0x6N0Jkckc0SDlUTXJZOUZZWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         韩冬煦, 常宝宝.中文分词模型的领域适应性方法[J].计算机学报, 2015, 38 (2) :272-281.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" KACHERGIS G, YU C, SHIFFRIN R M.A bootstrapping model of frequency and context effects in word learning[J].Cognitive Science, 2016, 41 (3) :590-622." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A bootstrapping model of frequency and context effects in word learning">
                                        <b>[11]</b>
                                         KACHERGIS G, YU C, SHIFFRIN R M.A bootstrapping model of frequency and context effects in word learning[J].Cognitive Science, 2016, 41 (3) :590-622.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" ZHAO Y, YANG R, CHEVALIER G, et al.Applying deep bidirectional LSTM and mixture density network for basketball trajectory prediction[J].Optik, 2018, 158:266-272." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Applying deep bidirectional LSTM and mixture density network for basketball trajectory prediction">
                                        <b>[12]</b>
                                         ZHAO Y, YANG R, CHEVALIER G, et al.Applying deep bidirectional LSTM and mixture density network for basketball trajectory prediction[J].Optik, 2018, 158:266-272.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" ZHOU Z H.Ensemble methods:foundations and algorithms[M].[S.l.]:CRC Press, 2012:68-70." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ensemble methods:foundations and algorithms">
                                        <b>[13]</b>
                                         ZHOU Z H.Ensemble methods:foundations and algorithms[M].[S.l.]:CRC Press, 2012:68-70.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" 付忠良.通用集成学习算法的构造[J].计算机研究与发展, 2013, 50 (4) :861-872." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201304025&amp;v=MTA1NDBGckNVUkxPZVplUm9GeTdsVXIzT0x5dlNkTEc0SDlMTXE0OUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         付忠良.通用集成学习算法的构造[J].计算机研究与发展, 2013, 50 (4) :861-872.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 李凯, 崔丽娟.集成学习算法的差异性及性能比较[J].计算机工程, 2008, 34 (6) :35-37." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC200806014&amp;v=MjY1MTdyM09MejdCYmJHNEh0bk1xWTlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk3bFU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         李凯, 崔丽娟.集成学习算法的差异性及性能比较[J].计算机工程, 2008, 34 (6) :35-37.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" T-Drive trajectory data sample[EB/OL].[2017-12-05].http://research.microsoft.com/apps/pubs/?id=152883." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=T-Drive trajectory data sample">
                                        <b>[16]</b>
                                         T-Drive trajectory data sample[EB/OL].[2017-12-05].http://research.microsoft.com/apps/pubs/?id=152883.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(03),188-196+201 DOI:10.19678/j.issn.1000-3428.0050177            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于RNN集成学习的个人轨迹恢复方法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%B2%81%E5%BC%BA&amp;code=10081231&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鲁强</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E6%AD%86%E7%90%A6&amp;code=38854968&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘歆琦</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%9F%B3%E6%B2%B9%E5%A4%A7%E5%AD%A6(%E5%8C%97%E4%BA%AC)%E7%9F%B3%E6%B2%B9%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%8C%97%E4%BA%AC%E5%B8%82%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0093802&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国石油大学(北京)石油数据挖掘北京市重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>从多个轨迹数据库中连接并恢复出较为完整的个人轨迹对出行推荐和移动导航具有重要的意义。基于个人轨迹恢复, 提出RNN集成学习方法。定义个人轨迹恢复的形式化模型, 利用轨迹点数目采样模式将每个训练库划分为多个训练子库, 并采用RNN网络模型描述个人轨迹的可拼接程度, 使用集成学习方法构建多个RNN网络, 以达到恢复个人轨迹的目的。实验结果表明, 该方法可以较好地捕获轨迹时空连续性特征, 实现个人轨迹恢复。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BD%A8%E8%BF%B9%E6%81%A2%E5%A4%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">轨迹恢复;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BD%A8%E8%BF%B9%E6%8B%BC%E6%8E%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">轨迹拼接;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">集成学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=RNN%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">RNN网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    鲁强 (1977—) , 男, 副教授、博士, 主研方向为空间数据挖掘、演化计算;;
                                </span>
                                <span>
                                    刘歆琦, 硕士研究生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-18</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61402532);</span>
                                <span>中国石油大学 (北京) 青年基础科研基金 (01JB0415);</span>
                    </p>
            </div>
                    <h1><b>Personal Trajectory Recovery Method Based on RNN Ensemble Learning</b></h1>
                    <h2>
                    <span>LU Qiang</span>
                    <span>LIU Xinqi</span>
            </h2>
                    <h2>
                    <span>Beijing Key Lab of Petroleum Data Mining, China University of Petroleum</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Connecting and restoring a relatively complete personal trajectory from multiple trajectory databases is important for travel recommendations and mobile navigation.Based on personal trajectory recovery, an integrated learning method for RNN is proposed.By defining a formal model of personal trajectory recovery, each training library is divided into multiple training sub-libraries by using the track point number sampling mode, and an RNN network model is used to describe the splicing degree of the personal trajectory.An integrated learning method is used to construct multiple RNN networks to achieve the goal of restoring personal trajectories.Experimental results show that this method can capture the temporal and spatial continuity of the trajectory and realize the personal trajectory recovery.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=trajectory%20recovery&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">trajectory recovery;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=trajectory%20splicing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">trajectory splicing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=ensemble%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">ensemble learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=RNN%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">RNN network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-18</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="36">随着卫星导航的发展以及具有定位功能设备的广泛使用, 信息系统能够捕获个体出行轨迹, 并将其存入数据库中。个人轨迹恢复是在多个轨迹数据库中寻找可能与某条轨迹属于同一人的轨迹, 进而将它们连接以恢复较完整的个人轨迹。因此, 如何从多个数据库中恢复较为完整的个人轨迹, 对出行推荐<citation id="162" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>和移动导航<citation id="161" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等领域具有重要意义。</p>
                </div>
                <div class="p1">
                    <p id="37">在工作日期间, Bob每天早上8:00—8:30从A地点乘坐地铁到达B地点, 此轨迹存储在地铁旅客出入站数据库中, 轨迹ID为公交卡号。然后Bob从B地点骑共享单车到C地点上班, 此轨迹存储在单车行驶轨迹库中, 轨迹ID为手机号码。</p>
                </div>
                <div class="p1">
                    <p id="38">由于每个库中个体移动轨迹ID并不相同, 因此很难在多个库中通过比较轨迹ID方式进行个人轨迹恢复。通过分析个人出行记录发现, 每个人的日常出行模式符合一定规律。例如Bob在工作日的移动路线、时间几乎相同, 因此可以通过分析对比不同数据库中的轨迹是否符合时空连续性来判断这些轨迹是否属于同一人。然而, 对个人轨迹时空连续性进行量化定义存在难点:不同库存储的轨迹采样点频率不同, 例如地铁轨迹与共享单车轨迹时间稀疏程度相差较大, 导致轨迹特征不同, 很难通过单一模型准确捕捉不同库的轨迹特征;相同库中每条轨迹的分布也不同, 例如, 根据交通拥堵环境和驾驶人员习惯不同, 出租车轨迹采样点会表现出不同的数据分布;不同库中的轨迹数据会在一定时间和地点范围内出现重复, 不能判断部分重合的轨迹是否属于一人。</p>
                </div>
                <div class="p1">
                    <p id="39">目前, 轨迹恢复主要是还原轨迹中部分缺失点, 例如手写字符的轨迹恢复<citation id="164" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>, 其利用编码-解码器网络基于图像提取手写轨迹连续性特征, 但图像中不包含轨迹点间时间信息。文献<citation id="165" type="reference">[<a class="sup">6</a>,<a class="sup">7</a>]</citation>分别利用隐马尔可夫模型 (基于覆盖轨迹点的基站间的转移概率) 、路网拓扑结构和路径插值方法估计缺失采样点, 以还原轨迹序列。这些方法都是在一个库中还原轨迹缺失点, 没有考虑来自多个库的个人轨迹分布不同、特征差异大等问题。个人轨迹恢复问题关注轨迹点间时空连续性, 文献<citation id="163" type="reference">[<a class="sup">8</a>]</citation>根据轨迹连接的时空特性, 使用<i>α</i>-filter 和Naïve-Bayes-matching方法判断轨迹能否连接。但是此方法是在具有全样本数据集的基础上统计时空特性, 未覆盖不在数据集的其他特征样本, 其泛化效果较差。</p>
                </div>
                <div class="p1">
                    <p id="40">本文提出基于RNN集成学习的个人轨迹恢复方法, 将个人轨迹标注库进行预处理, 得到不同分布类型的多个轨迹训练集, 针对每个训练集使用LSTM<citation id="166" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>网络提取轨迹序列的时空连续特征, 通过集成学习方法将多个预训练的LSTM网络融合, 以达到捕获和识别不同特征的个人轨迹目的。</p>
                </div>
                <h3 id="41" name="41" class="anchor-tag">1 问题定义</h3>
                <div class="p1">
                    <p id="42">本文符号定义如表1所示。</p>
                </div>
                <div class="area_img" id="43">
                    <p class="img_tit"><b>表1 本文符号定义</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="43" border="1"><tr><td><br />符号</td><td colspan="2">定义</td></tr><tr><td><br /><i>p</i></td><td colspan="2">采样点<i>p</i>=&lt;标识符<i>id</i>, 时间戳<i>t</i>, 地理坐标<i>loc</i>&gt;</td></tr><tr><td><br /><i>tr</i><sub><i>k</i></sub></td><td colspan="2"><i>tr</i><sub><i>k</i></sub>=&lt;<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, …, <i>p</i><sub><i>n</i></sub>&gt;</td></tr><tr><td><br /><i>DB</i><sub><i>n</i></sub></td><td colspan="2">轨迹数据库<i>n</i></td></tr><tr><td><br /><i>con</i>&lt;<i>tr</i><sub><i>i</i></sub>, <i>tr</i><sub><i>j</i></sub>&gt;</td><td colspan="2">轨迹<i>tr</i><sub><i>i</i></sub>和<i>tr</i><sub><i>j</i></sub>全部采样点组成的时间顺序序列</td></tr><tr><td><br /><i>td</i> (<i>a</i>, <i>b</i>) </td><td colspan="2"><i>td</i> (<i>a</i>, <i>b</i>) =<i>a</i>.<i>t</i>-<i>b</i>.<i>t</i> 相邻点的时间差</td></tr><tr><td><br /><i>ld</i> (<i>a</i>, <i>b</i>) </td><td colspan="2">相邻两点<i>a</i>、<i>b</i>的欧氏距离</td></tr><tr><td><br /><i>TLDseq</i> (<i>con</i>&lt;<i>tr</i><sub><i>i</i></sub>, <i>tr</i><sub><i>j</i></sub>&gt;) </td><td colspan="2">轨迹<i>tr</i><sub><i>i</i></sub>和<i>tr</i><sub><i>j</i></sub>采样点间时间距离差序列</td></tr><tr><td><br /><i>Label</i></td><td colspan="2">不同库轨迹是否属于同一人的标志</td></tr><tr><td><br /><i>DU</i></td><td colspan="2">由稀疏适中轨迹和稀疏适中轨迹组成的连接轨迹数据集</td></tr><tr><td><br /><i>DL</i></td><td colspan="2">由较密集轨迹和较稀疏轨迹组成的连接轨迹数据集</td></tr><tr><td colspan="2"><br /><i>DU</i><sub><i>m</i>, <i>t</i></sub></td><td><i>DU</i><sub><i>m</i>, <i>t</i></sub>={<i>TLDseq</i><sub>1</sub>, <i>TLDseq</i><sub>2</sub>, …, <i>TLDseq</i><sub><i>m</i></sub>}是第<i>t</i>个使用Bootstrapping方法从<i>DU</i>集中得到的包含<i>m</i>条时间距离差序列 (由连接轨迹转换得到) 的样本集, <i>m</i>表示该样本集大小</td></tr><tr><td colspan="2"><br /><i>DL</i><sub><i>m</i>′, <i>t</i>′</sub></td><td><i>DL</i><sub><i>m</i>′, <i>t</i>′</sub>定义类似<i>DU</i><sub><i>m</i>, <i>t</i></sub>, 是从<i>DL</i>集中得到的第<i>t</i>′个包含<i>m</i>′条时间距离差序列的样本集</td></tr><tr><td colspan="2"><br /><i>label</i><sub><i>TLDseqi</i></sub></td><td>第<i>i</i>条时间距离差序列是否由不同库中属于同一人的轨迹组成的连接轨迹转换的标志</td></tr><tr><td colspan="2"><br /><i>LabelU</i><sub><i>m</i>, <i>t</i></sub></td><td><i>LabelU</i><sub><i>m</i>, <i>t</i></sub>={<i>label</i><sub><i>TLDseq</i>1</sub>, <i>label</i><sub><i>TLDseq</i>2</sub>, …, <i>label</i><sub><i>TLDseqm</i></sub>}是样本集<i>DU</i><sub><i>m</i>, <i>t</i></sub>的标签集</td></tr><tr><td colspan="2"><br /><i>LabelL</i><sub><i>m</i>′, <i>t</i>′</sub></td><td><i>LabelL</i><sub><i>m</i>′, <i>t</i>′</sub>定义类似<i>LabelU</i><sub><i>m</i>, <i>t</i></sub>, 是样本集<i>DL</i><sub><i>m</i>′, <i>t</i>′</sub>的标签集</td></tr><tr><td colspan="2"><br /><i>MU</i><sub><i>m</i>, <i>t</i></sub></td><td>表示使用LSTM网络训练样本集<i>DU</i><sub><i>m</i>, <i>t</i></sub>得到的个体分类器</td></tr><tr><td colspan="2"><br /><i>ML</i><sub><i>m</i>′, <i>t</i>′</sub></td><td><i>ML</i><sub><i>m</i>′, <i>t</i>′</sub>定义类似<i>MUm</i>, <i>t</i>, 训练样本集<i>DL</i><sub><i>m</i>′, <i>t</i>′</sub>得到的个体分类器</td></tr><tr><td colspan="2"><br /><i>SU</i><sub><i>m</i>, {<i>t</i>1, <i>t</i>2, …}</sub></td><td><i>SU</i><sub><i>m</i>, {<i>t</i>1, <i>t</i>2, …}</sub>={<i>MU</i><sub><i>m</i>, <i>t</i>1 </sub>, <i>MU</i><sub><i>m</i>, <i>t</i>2 </sub>, …}, 是集成<i>MU</i><sub><i>m</i>, <i>t</i>1</sub>, <i>MU</i><sub><i>m</i>, <i>t</i>2</sub>等多个个体分类器形成的强分类器</td></tr><tr><td colspan="2"><br /><i>SL</i><sub><i>m</i>′, {<i>t</i>1′, <i>t</i>2′, …}</sub></td><td><i>SL</i><sub><i>m</i>′, {<i>t</i>1′, <i>t</i>2′, …}</sub>={<i>ML</i><sub><i>m</i>′, <i>t</i>1′</sub>, <i>ML</i><sub><i>m</i>′, <i>t</i>2′</sub>, …}, 定义类似<i>SU</i><sub><i>m</i>, {<i>t</i>1, <i>t</i>2, …}</sub></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="44" name="44">1.1 相关概念及定义</h4>
                <div class="p1">
                    <p id="45"><b>定义1</b> 采样点<i>p</i>=&lt;<i>id</i>, <i>t</i>, <i>loc</i>&gt;, 一个采样点中包含该移动物体的唯一标识符<i>id</i>、时间戳<i>t</i>和物体地理位置<i>loc</i>, <i>loc</i>一般包含经度和纬度信息, 一个采样点通常是一次刷卡记录或GPS记录。</p>
                </div>
                <div class="p1">
                    <p id="46"><b>定义2</b> 轨迹<i>tr</i><sub><i>k</i></sub>=&lt;<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, …, <i>p</i><sub><i>n</i></sub>&gt;由<i>n</i>个具有时间顺序的采样点组成, 其中, <i>p</i><sub><i>i</i></sub>.<i>id</i>=<i>p</i><sub><i>j</i></sub>.<i>id</i>=<i>k</i>, <i>i</i>、<i>j</i>∈{1, 2, …, <i>n</i>}。</p>
                </div>
                <div class="p1">
                    <p id="47"><b>定义3</b> 连接轨迹<i>con</i>&lt;<i>tr</i><sub><i>i</i></sub>, <i>tr</i><sub><i>j</i></sub>&gt;=&lt;<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, …, <i>p</i><sub><i>i</i></sub>, …, <i>p</i><sub><i>m</i>+<i>n</i></sub>&gt;, <i>p</i><sub><i>i</i></sub>∈<i>tr</i><sub><i>i</i></sub>或<i>tr</i><sub><i>j</i></sub>, <i>p</i><sub>1</sub>.<i>t</i>&lt;<i>p</i><sub>2</sub>.<i>t</i>&lt;…&lt;<i>p</i><sub><i>i</i></sub>.<i>t</i>&lt;<i>p</i><sub><i>i</i>+1</sub>.<i>t</i>&lt;…&lt;<i>p</i><sub><i>m</i>+<i>n</i></sub>.<i>t</i>, <i>tr</i><sub><i>i</i></sub>∈<i>DB</i><sub>1</sub>且<i>tr</i><sub><i>j</i></sub>∉<i>DB</i><sub>1</sub>。如图1所示, 4条轨迹来自不同库, 分别为<i>tr</i><sub><i>a</i></sub>、<i>tr</i><sub><i>b</i></sub>、<i>tr</i><sub><i>c</i></sub>和<i>tr</i><sub><i>d</i></sub>。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903032_048.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 轨迹示意图" src="Detail/GetImg?filename=images/JSJC201903032_048.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 轨迹示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903032_048.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="49">由于轨迹时空连续信息与采样点之间的距离相关, 因此定义<i>td</i>和<i>ld</i>函数分别表示采样点时间距离和空间距离, 进而将<i>con</i>&lt;<i>tr</i><sub><i>i</i></sub>, <i>tr</i><sub><i>j</i></sub>&gt;转换时间距离差序列<i>TLDseq</i>。</p>
                </div>
                <div class="p1">
                    <p id="50"><b>定义4</b> 时间距离差序列<i>TLDseq</i> (<i>con</i>&lt;<i>tr</i><sub><i>i</i></sub>, <i>tr</i><sub><i>j</i></sub>&gt;) =&lt; (0, 0) , (<i>tdv</i><sub>1</sub>, <i>ldv</i><sub>1</sub>) , (<i>tdv</i><sub>2</sub>, <i>ldv</i><sub>2</sub>) , …, (<i>tdv</i><sub><i>i</i></sub>, <i>ldv</i><sub><i>i</i></sub>) , …, (<i>tdv</i><sub><i>m</i></sub><sub>+</sub><sub><i>n</i></sub>, <i>ldv</i><sub><i>m</i></sub><sub>+</sub><sub><i>n</i></sub>) &gt;, 相邻点时间差<i>tdv</i><sub><i>i</i></sub>=<i>td</i> (<i>p</i><sub><i>i</i></sub>, <i>p</i><sub><i>i</i>-1</sub>) =<i>p</i><sub><i>i</i></sub>.<i>t</i>-<i>p</i><sub><i>i</i>-1</sub>.<i>t</i>, 相邻点距离差<i>ldv</i><sub><i>i</i></sub>=<i>ld</i> (<i>p</i><sub><i>i</i></sub>, <i>p</i><sub><i>i</i>-1</sub>) , 其中<i>ld</i>是欧式距离函数。</p>
                </div>
                <div class="p1">
                    <p id="51"><b>定义5</b> 时间稀疏程度评估函数<i>fre</i>=|<i>tr</i><sub><i>i</i></sub>|/<i>td</i> (<i>tr</i><sub><i>i</i></sub>.<i>p</i><sub>1</sub>, <i>tr</i><sub><i>i</i></sub>.<i>p</i><sub><i>n</i></sub>) , 其中, |<i>tr</i><sub><i>i</i></sub>|是轨迹<i>tr</i><sub><i>i</i></sub>的采样点数目, <i>td</i> (<i>tr</i><sub><i>i</i></sub>.<i>p</i><sub>1</sub>, <i>tr</i><sub><i>i</i></sub>.<i>p</i><sub><i>n</i></sub>) 表示该条轨迹最后一个采样点与第一个采样点的时间差, 即<i>tr</i><sub><i>i</i></sub>的时间长度, <i>fre</i>是轨迹时间稀疏程度, 代表每小时采样点数目。</p>
                </div>
                <h4 class="anchor-tag" id="52" name="52">1.2 轨迹恢复</h4>
                <div class="p1">
                    <p id="53">本文中轨迹恢复问题是根据存在于数据库<i>DB</i><sub><i>n</i></sub>中的一条轨迹<i>tr</i><sub><i>i</i></sub>, 从其他数据库中寻找到与<i>tr</i><sub><i>i</i></sub>最可能连接在一起的轨迹<i>tr</i><sub><i>j</i></sub>, 即找到满足式 (1) 的轨迹<i>tr</i><sub><i>j</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext></mrow></mstyle><mrow><mi>t</mi><mi>r</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><mo stretchy="false"> (</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Τ</mi><mi>L</mi><mi>D</mi><mi>s</mi><mi>e</mi><mi>q</mi><mo stretchy="false"> (</mo><mi>c</mi><mi>o</mi><mi>n</mi><mo>&lt;</mo><mi>t</mi><mi>r</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>t</mi><mi>r</mi><msub><mrow></mrow><mi>j</mi></msub><mo>&gt;</mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">其中, <i>tr</i><sub><i>i</i></sub>∈<i>DB</i><sub><i>n</i></sub>, <i>tr</i><sub><i>j</i></sub>∉<i>DB</i><sub><i>n</i></sub>, <i>P</i>表示<i>tr</i><sub><i>i</i></sub>和<i>tr</i><sub><i>j</i></sub>连接在一起形成时间距离差序列的概率。在图1中, <i>tr</i><sub><i>a</i></sub>、<i>tr</i><sub><i>b</i></sub>、<i>tr</i><sub><i>c</i></sub>、<i>tr</i><sub><i>d</i></sub>属于不同的数据库, 当寻找<i>tr</i><sub><i>a</i></sub>的可拼接轨迹时, <i>tr</i><sub><i>a</i></sub>与<i>tr</i><sub><i>c</i></sub>较多的点在时间维度重叠, <i>tr</i><sub><i>a</i></sub>与<i>tr</i><sub><i>d</i></sub>连接点空间距离较远, 而<i>tr</i><sub><i>a</i></sub>与<i>tr</i><sub><i>b</i></sub>连接后的轨迹分布更密集、均匀, 并且<i>P</i> (<i>TLDseq</i> (<i>con</i>&lt;<i>tr</i><sub><i>a</i></sub>, <i>tr</i><sub><i>b</i></sub>&gt;) ) 最大, 因此最可能与<i>tr</i><sub><i>a</i></sub>连接的轨迹是<i>tr</i><sub><i>b</i></sub>, 轨迹<i>tr</i><sub><i>a</i></sub>和<i>tr</i><sub><i>b</i></sub>最可能属于同一个人。</p>
                </div>
                <h3 id="56" name="56" class="anchor-tag">2 轨迹恢复集成方法</h3>
                <div class="p1">
                    <p id="57">为较好地捕捉轨迹特征, 本文提出一种基于RNN的轨迹恢复集成方法, 具体框架如图2所示。首先, 对数据进行预处理, 通过轨迹时间稀疏程度评估函数, 将原始轨迹划分为多种类型, 如较稀疏的轨迹、较密集的轨迹和稀疏适中的轨迹, 将不同时间稀疏程度的轨迹按时间顺序连接形成新的数据集, 再使用Bootstrapping方法进行随机采样得到多个样本集, 样本集中的每个样本是由连接轨迹转换形成的时间距离差序列, 其包含采样点之间的时间长度和空间距离。然后, 使用RNN训练多个样本集, 得到多个个体分类器, 以捕获个人轨迹的时空连续特征。最后, 使用简单平均策略将多个个体分类器集成, 形成一个强分类器, 捕获和识别不同特征的个人轨迹。</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903032_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 轨迹恢复集成算法框架" src="Detail/GetImg?filename=images/JSJC201903032_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 轨迹恢复集成算法框架</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903032_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="59" name="59">2.1 数据预处理</h4>
                <div class="p1">
                    <p id="60">由于不同源的轨迹采样点频率不同, 导致轨迹特征相差较大。例如, 地铁轨迹由出入站点的刷卡数据组成, 其采样点较稀疏且采样点时间差很大。出租车轨迹是GPS数据, 一条轨迹会包含几百个点甚至几千个点且采样点密集。为捕获不同轨迹特征, 使用时间稀疏程度评估函数将原始轨迹按时间稀疏程度进行划分, 得到不同类型的时序序列。</p>
                </div>
                <div class="p1">
                    <p id="61">时间稀疏程度评估函数如第1.1节定义5。通过设置阈值<i>θ</i><sub>1</sub>和<i>θ</i><sub>2</sub>, 对轨迹时间稀疏程度进行分类。<i>fre</i>&gt;<i>θ</i><sub>1</sub>为较密集的轨迹, 表示在短时间段内产生大量采样点, 例如出租车轨迹;<i>fre</i>&lt;<i>θ</i><sub>2</sub>为较稀疏的轨迹, 表示在长时间段内采样点较少, 例如地铁轨迹;<i>θ</i><sub>2</sub>&lt;<i>fre</i>&lt;<i>θ</i><sub>1</sub>为稀疏适中的轨迹, 例如步行轨迹。使用时间稀疏程度评估函数将属于不同库的轨迹划分成不同类型, 它们蕴含着不同的轨迹特征。在轨迹恢复问题中, 为捕获多种轨迹的时空连续特征, 将来自不同库中属于同一个人的轨迹输入到LSTM网络中。</p>
                </div>
                <div class="p1">
                    <p id="62">图3所示为3种由不同时间稀疏程度轨迹组成的连接轨迹。较密集轨迹和较密集轨迹组成的连接轨迹如图3 (a) 所示, 较容易出现短时间内频繁交替的轨迹点, 这种交替现象在现实生活中几乎不会出现, 因为很少有人会在一段时间内频繁地更改出行方式, 例如骑很短时间的自行车后坐很短时间的出租车又骑很短时间的自行车。现实中应该是骑一段时间自行车再坐一段时间出租车, 两段轨迹不会在短时间内频繁交替。因此, 不考虑较密集轨迹和较密集轨迹组成的连接轨迹。当连接轨迹由较密集轨迹和较稀疏轨迹或稀疏适中轨迹和稀疏适中轨迹组成时, 分布如图3 (b) 、图3 (c) 所示, 例如, 一个人先走一段路, 然后乘坐公共汽车, 再下车走一段路, 这2种轨迹可以拼接, 可能属于同一个人;或者是一个人走一段路, 然后骑一段自行车, 又走一段路, 这 2种轨迹也可能属于同一个人。</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903032_063.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 3种由不同时间稀疏程度轨迹组成的连接轨迹" src="Detail/GetImg?filename=images/JSJC201903032_063.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 3种由不同时间稀疏程度轨迹组成的连接轨迹</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903032_063.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="64">本文轨迹恢复算法主要针对图3 (b) 和图3 (c) 这2种情况。由于这2种分布的轨迹具有不同特征, 无法使用一个分类器得到2种分布的数据特征, 因此针对这2种分布情况单独训练分类器。</p>
                </div>
                <div class="p1">
                    <p id="65">在图2步骤1中, 由稀疏适中轨迹和稀疏适中轨迹组成连接轨迹数据集<i>DU</i>, 由较密集轨迹和较稀疏轨迹组成连接轨迹数据集<i>DL</i>。由于完整数据集较大, 使用LSTM网络训练的速度较慢, 因此使用Bootstrapping方法<citation id="167" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>对<i>DU</i>、<i>DL</i>采样, 并将得到的连接轨迹转化为时间距离差序列, 以获得多个样本集<i>DU</i><sub><i>m</i>, 1</sub>, <i>DU</i><sub><i>m</i>, 2</sub>, …, <i>DU</i><sub><i>m</i>, <i>T</i></sub>, <i>DL</i><sub><i>m</i>′, 1</sub>, <i>DL</i><sub><i>m</i>′, 2</sub>, …, <i>DL</i><sub><i>m</i>′, <i>T</i>′</sub>。</p>
                </div>
                <div class="p1">
                    <p id="66">Bootstrapping方法随机取样, 样本集仍含有完整数据集的特征, Bootstrapping方法允许从给定的训练集中返回重复的样本, 即在选择样本时, 可以重新选择已选择过的样本再次添加到训练集中。例如, 原始数据集只有3个样本{<i>tr</i><sub>1</sub>, <i>tr</i><sub>2</sub>, <i>tr</i><sub>3</sub>}, 可生成包含5个样本的样本集, 如{<i>tr</i><sub>1</sub>, <i>tr</i><sub>2</sub>, <i>tr</i><sub>3</sub>, <i>tr</i><sub>2</sub>, <i>tr</i><sub>1</sub>}或{<i>tr</i><sub>3</sub>, <i>tr</i><sub>3</sub>, <i>tr</i><sub>3</sub>, <i>tr</i><sub>2</sub>, <i>tr</i><sub>1</sub>}。</p>
                </div>
                <h4 class="anchor-tag" id="67" name="67">2.2 个体分类器训练</h4>
                <div class="p1">
                    <p id="68">由于轨迹是由时序点组成的, 传统的神经网络难以处理时间相关信息, 无法较好地捕获时间序列特征, 因此使用能够处理时序序列的RNN提取轨迹特征。每条轨迹是一个由数百或数千个点组成的长序列, 它们之间存在依赖关系, 更适合使用LSTM网络<citation id="168" type="reference"><link href="19" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">12</a>]</sup></citation>来提取时空连续特征, 并且包括轨迹点间的相互关系信息。网络结构如图4所示。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903032_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 LSTM网络结构" src="Detail/GetImg?filename=images/JSJC201903032_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 LSTM网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903032_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="70">假设训练集为<i>X</i>, 一条长度为<i>Len</i>的时间距离差序列<i>x</i><sub><i>i</i></sub>={<i>x</i><sup> (<i>t</i>) </sup><mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>L</mi><mi>e</mi><mi>n</mi></mrow></msubsup></mrow></math></mathml>}, 其中<i>x</i><sup> (<i>t</i>) </sup>为连接轨迹转换的时间距离差序列的一个点, 可以得到每个序列<i>x</i><sub><i>i</i></sub>的隐层输出<b><i>h</i></b> (<i>x</i><sub><i>i</i></sub>) =[<b><i>h</i></b><sub>1</sub>, <b><i>h</i></b><sub>2</sub>, …, <b><i>h</i></b><sub><i>t</i></sub>], <b><i>h</i></b> (<i>x</i><sub><i>i</i></sub>) ∈<image href="images/JSJC201903032_072.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i>×<i>t</i></sup>, 其中<b><i>h</i></b><sub><i>t</i></sub>∈<image href="images/JSJC201903032_073.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>d</i></sup>, <i>d</i>为LSTM单元输出向量的维度。<b><i>h</i></b><sub><i>t</i></sub>计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="74"><b><i>h</i></b><sub><i>t</i></sub>=<i>g</i> (<b><i>W</i></b>·<i>x</i><sub> (<i>t</i>) </sub>+<b><i>U</i></b>·<b><i>h</i></b><sub><i>t</i>-1</sub>+<b><i>b</i></b>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="75">隐层输出表示式 (1) 中时间差序列<i>TLDseq</i> (<i>con</i>&lt;<i>tr</i><sub><i>i</i></sub>, <i>tr</i><sub><i>j</i></sub>&gt;) 的拼接特征。为解决轨迹拼接的二分类问题, 使用sigmoid函数将LSTM隐层输出向量<b><i>h</i></b> (<i>x</i><sub><i>i</i></sub>) 映射为可拼接概率<i>p</i>, 即将拼接特征值映射为可拼接概率。</p>
                </div>
                <div class="p1">
                    <p id="76"><i>p</i>=<i>sigmoid</i> (<b><i>V</i></b>·<b><i>h</i></b> (<i>x</i><sub><i>i</i></sub>) +<b><i>c</i></b>) , <i>p</i>∈[0, 1]      (3) </p>
                </div>
                <div class="p1">
                    <p id="77">其中, <b><i>W</i>、<i>V</i>、<i>U</i></b>是权重矩阵, <b><i>W</i></b>表示从输入到隐藏层的连接, <b><i>V</i></b>表示从隐藏层到输出层的连接, <b><i>b</i></b>和<b><i>c</i></b>是偏移向量, <i>g</i>和<i>sigmod</i>是激活函数, 且<i>sigmoid</i> (<i>a</i>) =1/ (1+exp (<i>a</i>) ) 。</p>
                </div>
                <div class="p1">
                    <p id="78">在训练时使用对数损失函数, 全体样本的损失为:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo>-</mo></mstyle><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mi>ln</mi></mrow><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>-</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mi>ln</mi></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>p</mi><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">其中, <i>p</i>为预测值, <i>y</i>为实际值, <i>m</i>为总样本数。训练LSTM使用mini-batch随机梯度下降优化参数<b><i>W</i>、<i>V</i>、<i>b</i>、<i>c</i></b>, 以减少训练集损失。</p>
                </div>
                <div class="p1">
                    <p id="81">在预训练个体分类器时, 采用留一验证方法训练多个双层LSTM网络。LSTM网络输入数据的格式为 (<i>nb</i>_<i>sample</i>, <i>time</i>_<i>steps</i>, <i>input</i>_<i>dim</i>) , 其中, <i>nb</i>_<i>sample</i>表示该分类器的训练样本数, <i>time</i>_<i>steps</i>表示输入序列的长度, 即为时间距离差序列<i>TLDseq</i>的长度<i>Len</i>, <i>input</i>_<i>dim</i>表示<i>x</i><sup> (<i>t</i>) </sup>的维度, 且值为2, 即时间、空间2个维度。隐层使用2个LSTM层, 其单元个数分别为128、32。最后使用<i>sigmoid</i>函数输出可拼接概率<i>p</i>。</p>
                </div>
                <div class="p1">
                    <p id="82">LSTM网络中蕴含着连接轨迹的时间维度特征与空间维度特征, 因此可以较好地表示轨迹时空连续性, 有利于解决轨迹恢复问题。</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83">2.3 分类器集成</h4>
                <div class="p1">
                    <p id="84">为融合不同分布的轨迹特征, 将不同数据集下预训练获得的<i>LSTM</i>网络作为个体分类器, 通过简单平均结合策略<citation id="169" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>将这些个体分类器集成在一起, 建立集成学习模型<citation id="170" type="reference"><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>, 以更好地捕获和识别不同特征的个人轨迹, 如图2中步骤3所示。</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mi>Τ</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mi>h</mi></mstyle><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中, x<sub>i</sub>为时间距离差序列, T是2种分布全部个体分类器的数量, h<sub>t</sub> (x<sub>i</sub>) 表示每个个体分类器的输出值, H (x<sub>i</sub>) 表示输出的最终值。</p>
                </div>
                <div class="p1">
                    <p id="87">使用这种集成方法得到的强分类器性能优于单个分类器, 并且其使用多个小样本数据预集训练多个弱分类器, 以提高训练速度。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88">2.4 算法伪代码流程</h4>
                <div class="p1">
                    <p id="89">根据上述算法步骤, 构建基于<i>RNN</i>的轨迹恢复集成方法, 如算法1所示。算法的输入包括含有M条较密集轨迹和较稀疏轨迹组成的连接轨迹数据集DL, 其为“较密集+较稀疏”分布;含有M′条稀疏适中轨迹和稀疏适中轨迹组成的连接轨迹数据集DU, 其为“稀疏适中+稀疏适中”分布;对应包含每条连接轨迹label的标签集LabelL和LabelU。具体分析如下:</p>
                </div>
                <div class="p1">
                    <p id="90">1) 该算法首先进行数据预处理, 得到不同分布的多个样本集, 使用<i>Bootstrapping</i>方法产生DU库对应的T个样本集。其中, 第4行表示产生一个在1～M 之间的随机整数r, 第5行将连接轨迹con<sub>r</sub>转为时间距离差序列TLDseq<sub>r</sub>, 第6行将TLDseq<sub>r</sub>放入样本集, 其对应的label放入标签集, 直到样本集中含有m个TLDseq序列。使用T次<i>Bootstrapping</i>方法后, 得到T个包含m条时间距离差序列的样本集DU<sub>m, 1</sub>, DU<sub>m, 2</sub> , …, DU<sub>m, T</sub>。第10行～第16行与第1行～第7行类似, 使用<i>Bootstrapping</i>方法产生DL库对应的T′个包含m′条时间距离差序列的样本集DL<sub>m</sub><sub>′</sub><sub>, 1</sub>, DL<sub>m</sub><sub>′</sub><sub>, 2</sub>, …, DL<sub>m</sub><sub>′</sub><sub>, T</sub><sub>′</sub>。</p>
                </div>
                <div class="p1">
                    <p id="91">2) 获得数据后, 预训练个体分类器。在“稀疏适中+稀疏适中”分布中, 第8行使用在数据预处理阶段生成的时间距离差序列的样本集DU<sub>m, t</sub>和标签集LabelU<sub>m, t</sub>训练双层<i>LSTM</i>网络模型, 模型的详细信息见第2.2节。在“较密集+较稀疏”分布中, 与第8行类似, 第17行使用DL<sub>m</sub><sub>′</sub><sub>, t</sub><sub>′</sub>和LabelL<sub>m</sub><sub>′</sub><sub>, t</sub><sub>′</sub>训练个体分类器, 得到2种分布的个体分类器为h<sub>1</sub>, h<sub>2</sub>, …, h<sub>T+T</sub><sub>′</sub>。</p>
                </div>
                <div class="p1">
                    <p id="92">3) 在预训练后, 通过简单平均结合策略进行集成, 如第19行所示。其中, 使用简单平均结合方法将多个个体分类器 (h<sub>1</sub>, h<sub>2</sub>, …, h<sub>T+T</sub><sub>′</sub>) 集成为强分类器H。</p>
                </div>
                <div class="p1">
                    <p id="93"><b>算法1</b> 轨迹恢复集成</p>
                </div>
                <div class="area_img" id="173">
                                <img alt="" src="Detail/GetImg?filename=images/JSJC201903032_17300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="116">使用轨迹恢复集成算法获得轨迹之间是否可拼接的模型<i>H</i>后, 通过轨迹恢复匹配算法来找到最有可能与查询轨迹属于同一人的轨迹。通过对模型<i>H</i>计算出查询轨迹与其它库轨迹组成的<i>N</i>条连接轨迹的可拼接概率进行排序, 如算法2所示。第2行～第5行使用集成后的模型<i>H</i>计算<i>N</i>条连接轨迹的可拼接概率, 放入集合<i>predictVal</i>中, 第6行对<i>predictVal</i>中全部值排序, 其复杂度为<i>O</i> (<i>n</i>ln <i>n</i>) , 第7行找到排名在前<i>K</i>名的轨迹, 这些轨迹就是最有可能与查询轨迹属于同一人的轨迹, 即对于一条查询轨迹, 使用训练好的模型<i>H</i>, 找到最有可能和它属于同一人的<i>K</i>条轨迹。</p>
                </div>
                <div class="p1">
                    <p id="117"><b>算法2</b> 轨迹恢复匹配</p>
                </div>
                <div class="area_img" id="174">
                                <img alt="" src="Detail/GetImg?filename=images/JSJC201903032_17400.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="174">
                                <img alt="" src="Detail/GetImg?filename=images/JSJC201903032_17401.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="127" name="127" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="128" name="128">3.1 数据集</h4>
                <div class="p1">
                    <p id="129">实验采用T-Driver数据集<citation id="171" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。该数据集包含2008年2月2日—2008年2月8日北京市10 357个出租车的轨迹。首先, 将它分为训练数据源TRAIN (8 000条轨迹) 和测试数据源TEST (2 000条轨迹) 。其次, 由于数据集TRAIN和TEST属于同一个库, 轨迹的时间稀疏程度相似, 为得到不同时间稀疏程度的库, 重新采样TRAIN和TEST中轨迹, 即新轨迹中采样点包含原轨迹中每小时的<i>N</i>个采样点, <i>N</i>等于原轨迹每小时采样点数乘以<i>fre</i>。例如, 原轨迹第一个小时共有100个采样点, <i>fre</i>=0.2, 则新轨迹第一小时包含20个采样点。采样后新数据集作为多个库数据, 表2、表3给出<i>TRA</i><sub>1</sub>、<i>TRA</i><sub>2</sub>、<i>TRA</i><sub>3</sub>、<i>TRA</i><sub>4</sub>、<i>TE</i><sub>1</sub>、<i>TE</i><sub>2</sub>、<i>TE</i><sub>3</sub>、<i>TE</i><sub>4</sub> 8个库。</p>
                </div>
                <div class="area_img" id="130">
                    <p class="img_tit"><b>表2 训练集、样本集和个体分类器</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="130" border="1"><tr><td>训练集</td><td>时间稀<br />疏度<i>fre</i></td><td>库</td><td>样本<br />集大小</td><td colspan="9">样本集及对应的个体分类器</td></tr><tr><td rowspan="8"><i>DL</i></td><td rowspan="4"><br />0.2</td><td rowspan="4"><i>TRA</i><sub>1</sub></td><td rowspan="2"><br />1 024</td><td><br /><i>DL</i><sub>1 024</sub><sub>, </sub><sub>1</sub></td><td><i>DL</i><sub>1 024</sub><sub>, </sub><sub>2</sub></td><td><i>DL</i><sub>1 024</sub><sub>, </sub><sub>3</sub></td><td><i>DL</i><sub>1 024</sub><sub>, </sub><sub>4</sub></td><td><i>DL</i><sub>1 024</sub><sub>, </sub><sub>5</sub></td><td><i>DL</i><sub>1 024</sub><sub>, </sub><sub>6</sub></td><td><i>DL</i><sub>1 024</sub><sub>, </sub><sub>7</sub></td><td><i>DL</i><sub>1 024</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td><br /><i>ML</i><sub>1 024</sub><sub>, </sub><sub>1</sub></td><td><i>ML</i><sub>1 024</sub><sub>, </sub><sub>2</sub></td><td><i>ML</i><sub>1 024</sub><sub>, </sub><sub>3</sub></td><td><i>ML</i><sub>1 024</sub><sub>, </sub><sub>4</sub></td><td><i>ML</i><sub>1 024</sub><sub>, </sub><sub>5</sub></td><td><i>ML</i><sub>1 024</sub><sub>, </sub><sub>6</sub></td><td><i>ML</i><sub>1 024</sub><sub>, </sub><sub>7</sub></td><td><i>ML</i><sub>1 024</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td rowspan="2"><br />2 048</td><td><br /><i>DL</i><sub>2 048</sub><sub>, </sub><sub>1</sub></td><td><i>DL</i><sub>2 048</sub><sub>, </sub><sub>2</sub></td><td><i>DL</i><sub>2 048</sub><sub>, </sub><sub>3</sub></td><td><i>DL</i><sub>2 048</sub><sub>, </sub><sub>4</sub></td><td><i>DL</i><sub>2 048</sub><sub>, </sub><sub>5</sub></td><td><i>DL</i><sub>2 048</sub><sub>, </sub><sub>6</sub></td><td><i>DL</i><sub>2 048</sub><sub>, </sub><sub>7</sub></td><td><i>DL</i><sub>2 048</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td><br /><i>ML</i><sub>2 048</sub><sub>, </sub><sub>1</sub></td><td><i>ML</i><sub>2 048</sub><sub>, </sub><sub>2</sub></td><td><i>ML</i><sub>2 048</sub><sub>, </sub><sub>3</sub></td><td><i>ML</i><sub>2 048</sub><sub>, </sub><sub>4</sub></td><td><i>ML</i><sub>2 048</sub><sub>, </sub><sub>5</sub></td><td><i>ML</i><sub>2 048</sub><sub>, </sub><sub>6</sub></td><td><i>ML</i><sub>2 048</sub><sub>, </sub><sub>7</sub></td><td><i>ML</i><sub>2 048</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td rowspan="4"><br />0.8</td><td rowspan="4"><i>TRA</i><sub>4</sub></td><td rowspan="2"><br />4 096</td><td><br /><i>DL</i><sub>4 096</sub><sub>, </sub><sub>1</sub></td><td><i>DL</i><sub>4 096</sub><sub>, </sub><sub>2</sub></td><td><i>DL</i><sub>4 096</sub><sub>, </sub><sub>3</sub></td><td><i>DL</i><sub>4 096</sub><sub>, </sub><sub>4</sub></td><td><i>DL</i><sub>4 096</sub><sub>, </sub><sub>5</sub></td><td><i>DL</i><sub>4 096</sub><sub>, </sub><sub>6</sub></td><td><i>DL</i><sub>4 096</sub><sub>, </sub><sub>7</sub></td><td><i>DL</i><sub>4 096</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td><br /><i>ML</i><sub>4 096</sub><sub>, </sub><sub>1</sub></td><td><i>ML</i><sub>4 096</sub><sub>, </sub><sub>2</sub></td><td><i>ML</i><sub>4 096</sub><sub>, </sub><sub>3</sub></td><td><i>ML</i><sub>4 096</sub><sub>, </sub><sub>4</sub></td><td><i>ML</i><sub>4 096</sub><sub>, </sub><sub>5</sub></td><td><i>ML</i><sub>4 096</sub><sub>, </sub><sub>6</sub></td><td><i>ML</i><sub>4 096</sub><sub>, </sub><sub>7</sub></td><td><i>ML</i><sub>4 096</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td rowspan="2"><br />8 192</td><td colspan="2"><br /><i>DL</i><sub>8 192, 1</sub></td><td colspan="2"><i>DL</i><sub>8 192</sub><sub>, </sub><sub>2</sub></td><td colspan="2"><i>DL</i><sub>8 192</sub><sub>, </sub><sub>3</sub></td><td colspan="2"><i>DL</i><sub>8 192</sub><sub>, </sub><sub>4</sub></td><td></td></tr><tr><td colspan="2"><br /><i>ML</i><sub>8 192, 1</sub></td><td colspan="2"><i>ML</i><sub>8 192</sub><sub>, </sub><sub>2</sub></td><td colspan="2"><i>ML</i><sub>8 192</sub><sub>, </sub><sub>3</sub></td><td colspan="2"><i>ML</i><sub>8 192</sub><sub>, </sub><sub>4</sub></td><td></td></tr><tr><td rowspan="8"><i>DU</i></td><td rowspan="4"><br />0.4</td><td rowspan="4"><i>TRA</i><sub>2</sub></td><td rowspan="2"><br />1 024</td><td><br /><i>DU</i><sub>1 024</sub><sub>, </sub><sub>1</sub></td><td><i>DL</i><sub>1 024</sub><sub>, </sub><sub>2</sub></td><td><i>DU</i><sub>1 024</sub><sub>, </sub><sub>3</sub></td><td><i>DU</i><sub>1 024</sub><sub>, </sub><sub>4</sub></td><td><i>DU</i><sub>1 024</sub><sub>, </sub><sub>5</sub></td><td><i>DU</i><sub>1 024</sub><sub>, </sub><sub>6</sub></td><td><i>DU</i><sub>1 024</sub><sub>, </sub><sub>7</sub></td><td><i>DU</i><sub>1 024</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td><br /><i>MU</i><sub>1 024</sub><sub>, </sub><sub>1</sub></td><td><i>MU</i><sub>1 024</sub><sub>, </sub><sub>2</sub></td><td><i>MU</i><sub>1 024</sub><sub>, </sub><sub>3</sub></td><td><i>MU</i><sub>1 024</sub><sub>, </sub><sub>4</sub></td><td><i>MU</i><sub>1 024</sub><sub>, </sub><sub>5</sub></td><td><i>MU</i><sub>1 024</sub><sub>, </sub><sub>6</sub></td><td><i>MU</i><sub>1 024</sub><sub>, </sub><sub>7</sub></td><td><i>MU</i><sub>1 024</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td rowspan="2"><br />2 048</td><td><br /><i>DU</i><sub>2 048</sub><sub>, </sub><sub>1</sub></td><td><i>DU</i><sub>2 048</sub><sub>, </sub><sub>2</sub></td><td><i>DU</i><sub>2 048</sub><sub>, </sub><sub>3</sub></td><td><i>DU</i><sub>2 048</sub><sub>, </sub><sub>4</sub></td><td><i>DU</i><sub>2 048</sub><sub>, </sub><sub>5</sub></td><td><i>DU</i><sub>2 048</sub><sub>, </sub><sub>6</sub></td><td><i>DU</i><sub>2 048</sub><sub>, </sub><sub>7</sub></td><td><i>DU</i><sub>2 048</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td><br /><i>MU</i><sub>2 048</sub><sub>, </sub><sub>1</sub></td><td><i>MU</i><sub>2 048</sub><sub>, </sub><sub>2</sub></td><td><i>MU</i><sub>2 048</sub><sub>, </sub><sub>3</sub></td><td><i>MU</i><sub>2 048</sub><sub>, </sub><sub>4</sub></td><td><i>MU</i><sub>2 048</sub><sub>, </sub><sub>5</sub></td><td><i>MU</i><sub>2 048</sub><sub>, </sub><sub>6</sub></td><td><i>MU</i><sub>2 048</sub><sub>, </sub><sub>7</sub></td><td><i>MU</i><sub>2 048</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td rowspan="4"><br />0.6</td><td rowspan="4"><i>TRA</i><sub>3</sub></td><td rowspan="2"><br />4 096</td><td><br /><i>DU</i><sub>4 096</sub><sub>, </sub><sub>1</sub></td><td><i>DU</i><sub>4 096</sub><sub>, </sub><sub>2</sub></td><td><i>DU</i><sub>4 096, 3</sub></td><td><i>DU</i><sub>4 096</sub><sub>, </sub><sub>4</sub></td><td><i>DU</i><sub>4 096</sub><sub>, </sub><sub>5</sub></td><td><i>DU</i><sub>4 096</sub><sub>, </sub><sub>6</sub></td><td><i>DU</i><sub>4 096</sub><sub>, </sub><sub>7</sub></td><td><i>DU</i><sub>4 096</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td><br /><i>MU</i><sub>4 096</sub><sub>, </sub><sub>1</sub></td><td><i>MU</i><sub>4 096</sub><sub>, </sub><sub>2</sub></td><td><i>MU</i><sub>4 096, 3</sub></td><td><i>MU</i><sub>4 096</sub><sub>, </sub><sub>4</sub></td><td><i>MU</i><sub>4 096</sub><sub>, </sub><sub>5</sub></td><td><i>MU</i><sub>4 096</sub><sub>, </sub><sub>6</sub></td><td><i>MU</i><sub>4 096</sub><sub>, </sub><sub>7</sub></td><td><i>MU</i><sub>4 096</sub><sub>, </sub><sub>8</sub></td><td></td></tr><tr><td rowspan="2"><br />8 192</td><td colspan="2"><br /><i>DU</i><sub>8 192</sub><sub>, </sub><sub>1</sub></td><td colspan="2"><i>DU</i><sub>8 192</sub><sub>, </sub><sub>2</sub></td><td colspan="2"><i>DU</i><sub>8 192</sub><sub>, </sub><sub>3</sub></td><td colspan="2"><i>DU</i><sub>8 192</sub><sub>, </sub><sub>4</sub></td><td></td></tr><tr><td colspan="2"><br /><i>MU</i><sub>8 192</sub><sub>, </sub><sub>1</sub></td><td colspan="2"><i>MU</i><sub>8 192</sub><sub>, </sub><sub>2</sub></td><td colspan="2"><i>MU</i><sub>8 192</sub><sub>, </sub><sub>3</sub></td><td colspan="2"><i>MU</i><sub>8 192</sub><sub>, </sub><sub>4</sub></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="131">
                    <p class="img_tit"><b>表3 测试集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="131" border="1"><tr><td><br />测试集</td><td>时间稀疏度<i>fre</i></td><td>库</td></tr><tr><td rowspan="2"><br /><i>D</i><sub><i>test</i>1</sub> (200 000条) </td><td><br />0.2</td><td><i>TE</i><sub>1</sub></td></tr><tr><td><br />0.8</td><td><i>TE</i><sub>2</sub></td></tr><tr><td rowspan="2"><br /><i>D</i><sub><i>test</i>2</sub> (200 000条) </td><td><br />0.4</td><td><i>TE</i><sub>3</sub></td></tr><tr><td><br />0.6</td><td><i>TE</i><sub>4</sub></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="132">将<i>TRA</i><sub>1</sub>与<i>TRA</i><sub>4</sub>中轨迹连接成“较密集+较稀疏”分布的训练集<i>DL</i>, 将<i>TRA</i><sub>2</sub>与<i>TRA</i><sub>3</sub>中轨迹连接成“稀疏适中+稀疏适中”分布的训练集<i>DU</i>。<i>DL</i>和<i>DU</i>中均包含8 000条属于同一人的连接轨迹和8 000条不属于同一人的连接轨迹。</p>
                </div>
                <div class="p1">
                    <p id="133">使用bootstrapping方法获得<i>DL</i>与<i>DU</i>的样本集, 训练每个样本集得到对应的个体分类器。其中, <i>DL</i><sub>2 048</sub><sub>, </sub><sub>2</sub>表示从<i>DL</i>集中得到的第2个包含2 048个时间距离差序列的样本集, <i>ML</i><sub>2 048</sub><sub>, </sub><sub>2</sub>表示训练<i>DL</i><sub>2 048</sub><sub>, </sub><sub>2</sub>得到的分类器。</p>
                </div>
                <div class="p1">
                    <p id="134">在测试时, 在<i>TE</i><sub>1</sub>中随机选择100条轨迹作为查询轨迹与<i>TE</i><sub>4</sub>连接, 得到“较密集+较稀疏”分布的连接轨迹测试集<i>Dtest</i><sub>1</sub>;在<i>TE</i><sub>2</sub>中随机选择100条轨迹作为查询轨迹与<i>TE</i><sub>3</sub>连接, 得到“稀疏适中+稀疏适中”分布的连接轨迹测试集<i>Dtest</i><sub>2</sub>。表3中<i>Dtest</i><sub>1</sub>表示<i>TE</i><sub>1</sub>中100条查询轨迹和<i>TE</i><sub>4</sub>中2 000条轨迹组成的100×2 000条连接轨迹。</p>
                </div>
                <h4 class="anchor-tag" id="135" name="135">3.2 实验分析</h4>
                <div class="p1">
                    <p id="136">针对每个查询轨迹, 使用训练的到的模型<i>H</i>计算此轨迹与其它库<i>Q</i>中每条轨迹组成的连接轨迹的可拼接概率<i>P</i>, 排序可得到可拼接轨迹的排名。使用<i>Precision</i>评估算法的准确性, 定义如下:</p>
                </div>
                <div class="p1">
                    <p id="137" class="code-formula">
                        <mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false"> (</mo><mi>Κ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mo stretchy="false"> (</mo><mi>Q</mi><mo>, </mo><mi>t</mi><mi>o</mi><mi>p</mi><mi>Κ</mi><mo stretchy="false">) </mo></mrow><mi>Ν</mi></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="138">其中, <i>K</i>表示目标轨迹<i>tr</i><sub><i>p</i></sub>的可拼接轨迹在其他库<i>Q</i>中的排名, <i>topK</i>代表可拼接轨迹在前<i>K</i>名, 例如一条轨迹的可拼接轨迹在<i>Q</i>中排序后的位置是8, 那么该可拼接轨迹在排名前10, <i>number</i> (<i>Q</i>, <i>topK</i>) 表示满足其可拼接轨迹在<i>Q</i>的前<i>K</i>名中的条件的查询轨迹数目, <i>N</i>为查询轨迹总数, 则<i>Precision</i> (<i>K</i>) 表示全部<i>N</i>条查询轨迹中, 有<i>m</i>条查询轨迹的可拼接轨迹在其它库<i>Q</i>的前<i>K</i>名中, 且<i>Precision</i> (<i>K</i>) 值越大表示算法准确性越高。</p>
                </div>
                <div class="p1">
                    <p id="139">每条查询轨迹对应的其他库|<i>Q</i>|=2 000, 随机找到可拼接轨迹的概率是1/2 000, 可拼接轨迹在排名前20中的概率为20/2 000, 可见, 随机查找找到可拼接轨迹的概率非常低。</p>
                </div>
                <h4 class="anchor-tag" id="140" name="140">3.2.1 样本集大小相同</h4>
                <div class="p1">
                    <p id="141">由于使用随机采样方法得到样本集, 因此在样本集大小相同、训练模型结构相同的情况下, 个体分类器的效果不同, 如图5、图6所示, 分别表示测试集<i>D</i><sub><i>test</i>1</sub>, <i>D</i><sub><i>test</i>2</sub>在多个个体分类器下的<i>Precision</i> (<i>K</i>) 值。“稀疏适中+稀疏适中”分布下个体分类器如图5 (a) 所示, 当样本集大小<i>m</i>=1 024时, <i>MU</i><sub>1 024</sub><sub>, </sub><sub>5</sub>和<i>MU</i><sub>1 024</sub><sub>, </sub><sub>8</sub>的准确率高于其他分类器;当排名<i>K</i>为1时, <i>MU</i><sub>1 024</sub><sub>, </sub><sub>3</sub>和<i>MU</i><sub>1 024</sub><sub>, </sub><sub>7</sub>优于<i>MU</i><sub>1 024</sub><sub>, </sub><sub>4</sub>, 而当排名<i>K</i>为50和100时, <i>MU</i><sub>1 024</sub><sub>, </sub><sub>4</sub>更优。如图5 (b) 所示, 当样本集大小<i>m</i>=2 048且排名<i>K</i>为1时, <i>MU</i><sub>2 048</sub><sub>, </sub><sub>5</sub>准确率高于其他分类器, 但当排名<i>K</i>&gt;1时, <i>MU</i><sub>2 048</sub><sub>, </sub><sub>8</sub>的准确率高于<i>MU</i><sub>2 048</sub><sub>, </sub><sub>5</sub>;当排名<i>K</i>小于10时, <i>MU</i><sub>2 048</sub><sub>, </sub><sub>7</sub>比其他5个分类器更准确, 但当排名<i>K</i>&gt;10时, <i>MU</i><sub>2 048</sub><sub>, </sub><sub>7</sub>的准确性显著降低。当样本集大小<i>m</i>=4 096, 8 192时, 也出现了类似现象。不同的分类器在不同排名<i>K</i>时效果不同, 一个分类器不会在所有排名<i>K</i>下都最优, 因此, 不能仅使用一个分类器。</p>
                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903032_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 “稀疏适中+稀疏适中”分布的个体分类器准确性比较结果" src="Detail/GetImg?filename=images/JSJC201903032_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5</b> “<b>稀疏适中+稀疏适中”分布的个体分类器准确性比较结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903032_142.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="143">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903032_143.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 “较密集+较稀疏”分布的个体分类器准确性比较结果" src="Detail/GetImg?filename=images/JSJC201903032_143.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6</b> “<b>较密集+较稀疏”分布的个体分类器准确性比较结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903032_143.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="144" name="144">3.2.2 不同数目个体分类器集成</h4>
                <div class="p1">
                    <p id="145">使用结合策略集成个体分类器, 形成强分类器, 其准确率一般较高, 但并非集成越多个体分类器效果越好。在相同样本集下, 每次增加需要训练的个体分类器数目, 实验效果如图7、图8所示。从图7 (a) 可以看出, 随着个体分类器数目的增加, <i>Precision</i> (<i>K</i>) 也增加, 但当加入<i>MU</i><sub>1 024</sub><sub>, </sub><sub>6</sub>后, 排名20和排名50的准确性下降。在图7 (b) 中, 加入<i>MU</i><sub>2 048</sub><sub>, </sub><sub>6</sub>后, 排名1和排名20的准确性明显下降, 当<i>m</i>=4 096时, 也出现了相似情况。从图8 (a) 可以看出, 加入<i>ML</i><sub>1 024, 8</sub>后, 排名1、排名5、排名10、排名20的准确性均降低, 只有排名50和排名100的准确性略有增加。在图8 (c) 中, 加入<i>ML</i><sub>4 096, 5</sub>、<i>ML</i><sub>4 096, 6</sub>、<i>ML</i><sub>4 096, 7</sub>、<i>ML</i><sub>4 096, 8</sub>, 排名<i>K</i>的准确性均没有变化, 增加个体分类器几乎没有提高准确性。因此, 并不是个体分类器数量越多准确性越高, 过多的个体分类器会导致强分类器性能下降。因此, 有必要限制个体分类器的数目, 避免由过多的个体分类器引起性能下降。同时, 样本集的大小也会影响个体分类器的数量。对于大小不同的样本集需要选择不同数量的个体分类器, 2种分布在不同大小样本集下的个体分类器数目如表4所示。</p>
                </div>
                <div class="area_img" id="146">
                    <p class="img_tit"><b>表4 在不同大小样本集、不同分布下个体分类器数目表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="146" border="1"><tr><td>样本集<br />大小<br /><i>m</i></td><td>“稀疏适中+<br />稀疏适中”分布<br />个体分类器数目</td><td>“较密集+较<br />稀疏”分布个体<br />分类器数目</td><td>组成强分类<br />器的个体<br />分类器数目</td></tr><tr><td>1 024</td><td>7</td><td>7</td><td>7+7</td></tr><tr><td><br />2 048</td><td>7</td><td>7</td><td>7+7</td></tr><tr><td><br />4 096</td><td>4</td><td>4</td><td>4+4</td></tr><tr><td><br />8 192</td><td>4</td><td>4</td><td>4+4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="147">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903032_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 在“稀疏适中+稀疏适中”分布下的强分类器准确性比较结果" src="Detail/GetImg?filename=images/JSJC201903032_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 在“稀疏适中+稀疏适中”分布下的强分类器准确性比较结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903032_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="148">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903032_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 在“较密集+较稀疏”分布下的强分类器准确性比较结果" src="Detail/GetImg?filename=images/JSJC201903032_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图8 在“较密集+较稀疏”分布下的强分类器准确性比较结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903032_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="149" name="149">3.2.3 2种分布分类器集成</h4>
                <div class="p1">
                    <p id="150">结合2种分布, 强分类器的值是多个个体分类器预测值的平均值。集成得到的强分类器优于单一分布分类器, 并且同时具有2种分布特征, 如图9所示。从图9可以看出, 强分类器在大多数情况下比任何一种分布的分类器效果更好。仅样本集大小<i>m</i>=1 024, 强分类器在排名1和排名5的准确性低于“较密集+较稀疏”分布的分类器。</p>
                </div>
                <div class="area_img" id="151">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903032_151.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 在不同大小样本集下2种分布结合形成的强分类器准确性比较结果" src="Detail/GetImg?filename=images/JSJC201903032_151.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图9 在不同大小样本集下2种分布结合形成的强分类器准确性比较结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903032_151.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="152" name="152">3.2.4 样本集大小不同</h4>
                <div class="p1">
                    <p id="153">样本集大小与模型性能相关, 在2种分布下, 分别在各种大小样本集中选择一个最佳性能个体分类器进行比较, 如图10所示。在“稀疏适中+稀疏适中”分布下, 选择<i>MU</i><sub>1 024, 5</sub>、<i>MU</i><sub>2 048, 8</sub>、<i>MU</i><sub>4 096, 4</sub>、<i>MU</i><sub>8 192, 2</sub>, 在“较密集+较稀疏”分布下, 选择<i>ML</i><sub>1 024, 5</sub>、<i>ML</i><sub>2 048, 5</sub>、<i>ML</i><sub>4 096, 2</sub>、<i>ML</i><sub>8 192, 4</sub>。从图10可以看出, 随着样本集大小的增加, 模型准确性逐渐提高。当<i>m</i>=4 096时, 模型最优, 样本集大小继续增加时, 准确性反而降低, 这表明并非样本集越大越好。在2种分布下, 集成样本集大小为4 096的8个个体分类器。</p>
                </div>
                <div class="area_img" id="154">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903032_154.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 在不同大小样本集下个体分类器准确性比较结果" src="Detail/GetImg?filename=images/JSJC201903032_154.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图10 在不同大小样本集下个体分类器准确性比较结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903032_154.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="155">综上, 集成学习方法显著提高了寻找可拼接轨迹的概率, <i>m</i>=4 096的8个个体分类器集成的强分类器的<i>Precision</i> (100) =0.98, 这表明100条查询轨迹中98条的可拼接轨迹在其他库Q的前100名中。</p>
                </div>
                <h4 class="anchor-tag" id="156" name="156">3.3 实验对比</h4>
                <div class="p1">
                    <p id="157">本节使用3.2节中的数据集, 分别在本文方法、非集成学习方法和Naive-Bayes-matching方法<citation id="172" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>上进行实验, 结果如图11所示。在训练阶段, 本文方法和非集成方法均只训练了32 768条轨迹 (“稀疏适中+稀疏适中”和“较密集+较稀疏”2种分布, 样本集大小为4 096, 共8个个体分类器) , 包括来自相同出租车的2种分布下共16 384条轨迹 (正例) 和来自不同出租车的16 384条轨迹 (负例) 。但Naive-Bayes-matching算法训练了4 000 000条轨迹, 其中包括2 000条相同出租车轨迹 (正例) 和2 000×1 999=3 998 000个不同出租车轨迹 (负例) 。从图11可以看出, 本文方法在提取轨迹特征方面明显优于其他2种方法。</p>
                </div>
                <div class="area_img" id="158">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903032_158.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 3种算法准确性对比结果" src="Detail/GetImg?filename=images/JSJC201903032_158.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图11 3种算法准确性对比结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903032_158.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="159" name="159" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="160">本文提出一种基于RNN的集成学习轨迹恢复方法, 用于在多个不同数据库中识别属于同一个体的轨迹。首先对轨迹数据进行预处理, 利用轨迹时间稀疏程度评估函数把原始轨迹划分为多种类型, 将不同时间稀疏程度的轨迹按时间顺序连接形成新的数据集, 再使用bootstrapping方法进行随机采样得到多个样本集。然后使用LSTM网络训练样本集, 得到个体分类器, 以捕获轨迹的时空连续特征。在此基础上, 通过使用简单平均策略将多个个体分类器集成形成强分类器, 以捕获和识别不同特征的个人轨迹。实验结果表明, 该方法能较好地捕获轨迹时空连续性特征, 进而恢复个人轨迹。本文在集成个体分类器时仅使用简单平均方法, 未对数据进行训练, 下一步将使用其他结合策略集成个体分类器。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Human mobility prediction and unobstructed route planning in public transport networks">

                                <b>[1]</b> SHANG S, GUO D, LIU J, et al.Human mobility prediction and unobstructed route planning in public transport networks[C]//Proceedings of the 15th International Conference on Mobile Data Management.Washington, D.C., USA:IEEE Computer Society, 2014:43-48.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mining Spatio-Temporal Reachable Regions over Massive Trajectory Data">

                                <b>[2]</b> WU G, DING Y, LI Y, et al.Mining spatio-temporal reachable regions over massive trajectory data[C]//Proceedings of the 33rd International Conference on Data Engineering.Washington D.C., USA:IEEE Press, 2017:1283-1294.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semantic trajectory applied to the navigation of autonomous mobile robots">

                                <b>[3]</b> SIQUEIRA F D L, PLENTZ P D M, PIERI E R D.Semantic trajectory applied to the navigation of autonomous mobile robots[C]//Proceedings of the 13th International Conference of Computer Systems and Applications.Washington D.C., USA:IEEE Press, 2017.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Handwriting trajectory recovery using end-to-end deep encoder-decoder network">

                                <b>[4]</b> BHUNIA A K, BHOWMICK A, BHUNIA A K, et al.Handwriting trajectory recovery using end-to-end deep encoder-decoder network [EB/OL].[2017-12-05].https://arxiv.org/ftp/arxiv/papers/1801/1801.07211. pdf.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A survey on handwriting recognition based on the trajectory recovery technique">

                                <b>[5]</b> NOUBIGH Z, KHERALLAH M.A survey on handwriting recognition based on the trajectory recovery technique[C]//Proceedings of International Workshop on Arabic Script Analysis and Recognition.Washington D.C., USA:IEEE Press, 2017:69-73.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Performance evaluation of vehicle-based mobile sensor networks for traffic monitoring">

                                <b>[6]</b> LI X, SHU W, LI M, et al.Performance evaluation of vehicle-based mobile sensor networks for traffic monitoring[J].IEEE Transactions on Vehicular Technology, 2009, 58 (4) :1647-1653.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A framework for bus trajectory extraction and missing data recovery for data sampled from the internet">

                                <b>[7]</b> TONG C, CHEN H, QI X, et al.A framework for bus trajectory extraction and missing data recovery for data sampled from the internet[J].Sensors, 2017, 17 (2) :342.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fuzzy trajectory linking">

                                <b>[8]</b> WU H, XUE M, CAO J, et al.Fuzzy trajectory linking[C]//Proceedings of the 32nd International Conference on Data Engineering.Washington D.C., USA:IEEE Press, 2016:859-870.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201711009&amp;v=MzE5MDZPZVplUm9GeTdsVXIzT055ZlRiTEc0SDliTnJvOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 梁天新, 杨小平, 王良, 等.记忆神经网络的研究与发展[J].软件学报, 2017, 28 (11) :2905-2924.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201502005&amp;v=MTY0NjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N2xVcjNPTHo3QmRyRzRIOVRNclk5RllZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 韩冬煦, 常宝宝.中文分词模型的领域适应性方法[J].计算机学报, 2015, 38 (2) :272-281.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A bootstrapping model of frequency and context effects in word learning">

                                <b>[11]</b> KACHERGIS G, YU C, SHIFFRIN R M.A bootstrapping model of frequency and context effects in word learning[J].Cognitive Science, 2016, 41 (3) :590-622.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Applying deep bidirectional LSTM and mixture density network for basketball trajectory prediction">

                                <b>[12]</b> ZHAO Y, YANG R, CHEVALIER G, et al.Applying deep bidirectional LSTM and mixture density network for basketball trajectory prediction[J].Optik, 2018, 158:266-272.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ensemble methods:foundations and algorithms">

                                <b>[13]</b> ZHOU Z H.Ensemble methods:foundations and algorithms[M].[S.l.]:CRC Press, 2012:68-70.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201304025&amp;v=MjA5MjRSTE9lWmVSb0Z5N2xVcjNPTHl2U2RMRzRIOUxNcTQ5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 付忠良.通用集成学习算法的构造[J].计算机研究与发展, 2013, 50 (4) :861-872.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC200806014&amp;v=MDY0NzdyM09MejdCYmJHNEh0bk1xWTlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk3bFU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 李凯, 崔丽娟.集成学习算法的差异性及性能比较[J].计算机工程, 2008, 34 (6) :35-37.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=T-Drive trajectory data sample">

                                <b>[16]</b> T-Drive trajectory data sample[EB/OL].[2017-12-05].http://research.microsoft.com/apps/pubs/?id=152883.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201903032" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903032&amp;v=MjQ4MjRSTE9lWmVSb0Z5N2xVcjNQTHo3QmJiRzRIOWpNckk5R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
