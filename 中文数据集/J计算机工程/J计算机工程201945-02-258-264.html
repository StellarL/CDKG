<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131280466368750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201902043%26RESULT%3d1%26SIGN%3dtYWGkzUE1Z93yHdNvD6IncPaSpw%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902043&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902043&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902043&amp;v=MDg3NzVCWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqa1ZiekpMejdCYmJHNEg5ak1yWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#71" data-title="0概述 ">0概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#75" data-title="1 SAMF跟踪算法 ">1 SAMF跟踪算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="1.1 SAMF跟踪">1.1 SAMF跟踪</a></li>
                                                <li><a href="#88" data-title="1.2 自适应尺度估计与模型更新">1.2 自适应尺度估计与模型更新</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#93" data-title="2 改进的SAMF跟踪器 ">2 改进的SAMF跟踪器</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#94" data-title="2.1 最大响应搜索方法优化">2.1 最大响应搜索方法优化</a></li>
                                                <li><a href="#103" data-title="2.2 重检测及模型更新策略">2.2 重检测及模型更新策略</a></li>
                                                <li><a href="#109" data-title="2.3 跟踪算法流程">2.3 跟踪算法流程</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#120" data-title="3 实验与结果分析 ">3 实验与结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#126" data-title="3.1 阈值设置分析">3.1 阈值设置分析</a></li>
                                                <li><a href="#130" data-title="3.2 图像分块数量分析">3.2 图像分块数量分析</a></li>
                                                <li><a href="#134" data-title="3.3 参数设置与评价指标">3.3 参数设置与评价指标</a></li>
                                                <li><a href="#139" data-title="3.4 对比实验结果与分析">3.4 对比实验结果与分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#147" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#105" data-title="图1 重检测过程分块示意图">图1 重检测过程分块示意图</a></li>
                                                <li><a href="#125" data-title="表1 5种跟踪算法异同">表1 5种跟踪算法异同</a></li>
                                                <li><a href="#129" data-title="图2 Girl2序列响应最大值曲线">图2 Girl2序列响应最大值曲线</a></li>
                                                <li><a href="#132" data-title="表2 不同分块数量下的检测速度">表2 不同分块数量下的检测速度</a></li>
                                                <li><a href="#141" data-title="图3 跟踪精度曲线">图3 跟踪精度曲线</a></li>
                                                <li><a href="#144" data-title="图4 5种算法跟踪截图">图4 5种算法跟踪截图</a></li>
                                                <li><a href="#146" data-title="表3 跟踪算法的检测速度">表3 跟踪算法的检测速度</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="37">


                                    <a id="bibliography_1" title="尹宏鹏, 陈波, 柴毅, 等.基于视觉的目标检测与跟踪综述[J].自动化学报, 2016, 42 (10) :1466-1489." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201610002&amp;v=MTUzMjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5amtWYnpKS0NMZlliRzRIOWZOcjQ5RlpvUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        尹宏鹏, 陈波, 柴毅, 等.基于视觉的目标检测与跟踪综述[J].自动化学报, 2016, 42 (10) :1466-1489.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_2" title="黄凯奇, 陈晓棠, 康运锋, 等.智能视频监控技术综述[J].计算机学报, 2015, 20 (6) :1093-1118." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201506001&amp;v=MDU3NTBSbkZ5amtWYnpKTHo3QmRyRzRIOVRNcVk5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        黄凯奇, 陈晓棠, 康运锋, 等.智能视频监控技术综述[J].计算机学报, 2015, 20 (6) :1093-1118.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_3" title="BOLME D S, BEVERIDGE J R, DRAPER B A, et al.Visual object tracking using adaptive correlation filters[C]//Proceedings of Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2010:2544-2550." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual object tracking using adaptive correlation filters">
                                        <b>[3]</b>
                                        BOLME D S, BEVERIDGE J R, DRAPER B A, et al.Visual object tracking using adaptive correlation filters[C]//Proceedings of Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2010:2544-2550.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_4" title="HENRIQUES J F, RUI C, MARTINS P, et al.Exploiting the circulant structure of tracking-by-detection with kernels[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2012:702-715." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of tracking-by-detection with kernels">
                                        <b>[4]</b>
                                        HENRIQUES J F, RUI C, MARTINS P, et al.Exploiting the circulant structure of tracking-by-detection with kernels[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2012:702-715.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_5" title="HENRIQUES J F, CASEIRO R, MARTINS P, et al.Highspeed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (3) :583." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-speed tracking with kernelized correlation filters">
                                        <b>[5]</b>
                                        HENRIQUES J F, CASEIRO R, MARTINS P, et al.Highspeed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (3) :583.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_6" title="DANELLJAN M, KHAN F S, FELSBERG M, et al.Adaptive color attributes for real-time visual tracking[C]//Proceedings of Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2014:1090-1097." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive Color Attributes for Real-Time Visual Tracking">
                                        <b>[6]</b>
                                        DANELLJAN M, KHAN F S, FELSBERG M, et al.Adaptive color attributes for real-time visual tracking[C]//Proceedings of Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2014:1090-1097.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_7" title="徐玉龙, 王家宝, 李阳, 等.融合颜色特征的尺度自适应相关跟踪[J].计算机应用研究, 2017, 34 (3) :945-948." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201703072&amp;v=MTE5OTBSbkZ5amtWYnpKTHo3U1pMRzRIOWJNckk5Q1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        徐玉龙, 王家宝, 李阳, 等.融合颜色特征的尺度自适应相关跟踪[J].计算机应用研究, 2017, 34 (3) :945-948.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_8" title="马晓楠, 刘晓利, 李银伢.自适应尺度的快速相关滤波跟踪算法[J].计算机辅助设计与图形学学报, 2017, 29 (3) :450-458." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201703007&amp;v=MjExMTFuRnlqa1ZiekpMejdCYUxHNEg5Yk1ySTlGWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        马晓楠, 刘晓利, 李银伢.自适应尺度的快速相关滤波跟踪算法[J].计算机辅助设计与图形学学报, 2017, 29 (3) :450-458.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_9" title="张雷, 王延杰, 孙宏海, 等.采用核相关滤波器的自适应尺度目标跟踪[J].光学精密工程, 2016, 24 (2) :448-459." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201602026&amp;v=MTI1NDk5Zk1yWTlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqa1ZiekpJalhCWTdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        张雷, 王延杰, 孙宏海, 等.采用核相关滤波器的自适应尺度目标跟踪[J].光学精密工程, 2016, 24 (2) :448-459.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_10" title="DANELLJAN M, HGER G, FAHAD S K, et al.Accurate scale estimation for robust visual tracking[C]//Proceedings of British Machine Vision Conference.Guildford, UK:BMVAPress, 2014:1-11." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accurate scale estimation for robust visual tracking">
                                        <b>[10]</b>
                                        DANELLJAN M, HGER G, FAHAD S K, et al.Accurate scale estimation for robust visual tracking[C]//Proceedings of British Machine Vision Conference.Guildford, UK:BMVAPress, 2014:1-11.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_11" title="李珑, 刘凯, 李玲.基于目标检测的时空上下文跟踪算法[J].计算机工程, 2018, 44 (9) :263-268, 273." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201809043&amp;v=MTg5MzlHRnJDVVJMT2VaZVJuRnlqa1ZiekpMejdCYmJHNEg5bk1wbzlCWjRRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        李珑, 刘凯, 李玲.基于目标检测的时空上下文跟踪算法[J].计算机工程, 2018, 44 (9) :263-268, 273.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_12" title="MA C, YANG X, ZHANG C, et al.Long-term correlation tracking[C]//Proceedings of Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:5388-5396." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Long-term correlation tracking">
                                        <b>[12]</b>
                                        MA C, YANG X, ZHANG C, et al.Long-term correlation tracking[C]//Proceedings of Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:5388-5396.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_13" title="MUELLER M, SMITH N, GHANEM B.Context-aware correlation filter tracking[C]//Proceedings of IEEEConference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2017:1387-1395." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Context-Aware Correlation Filter Tracking">
                                        <b>[13]</b>
                                        MUELLER M, SMITH N, GHANEM B.Context-aware correlation filter tracking[C]//Proceedings of IEEEConference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2017:1387-1395.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_14" title="GALOOGAHI H K, FAGG A, LUCEY S.Learning background-aware correlation filters for visual tracking[EB/OL].[2017-10-10].https://arxiv.org/abs/1703.04590." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning background-aware correlation filters for visual tracking">
                                        <b>[14]</b>
                                        GALOOGAHI H K, FAGG A, LUCEY S.Learning background-aware correlation filters for visual tracking[EB/OL].[2017-10-10].https://arxiv.org/abs/1703.04590.
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_15" title="WANG M, LIU Y, HUANG Z.Large margin object tracking with circulant feature maps[EB/OL].[2017-10-10].https://arxiv.org/abs/1703.05020v2." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Large margin object tracking with circulant feature maps">
                                        <b>[15]</b>
                                        WANG M, LIU Y, HUANG Z.Large margin object tracking with circulant feature maps[EB/OL].[2017-10-10].https://arxiv.org/abs/1703.05020v2.
                                    </a>
                                </li>
                                <li id="67">


                                    <a id="bibliography_16" title="LI Y, ZHU J.A scale adaptive kernel correlation filter tracker with feature integration[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2014:254-265." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A scale adaptive kernel correlation filter tracker with feature integration">
                                        <b>[16]</b>
                                        LI Y, ZHU J.A scale adaptive kernel correlation filter tracker with feature integration[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2014:254-265.
                                    </a>
                                </li>
                                <li id="69">


                                    <a id="bibliography_17" title="WU Y, LIM J, YANG M H.Online object tracking:a benchmark[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2013:2411-2418." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Online object tracking:A benchmark">
                                        <b>[17]</b>
                                        WU Y, LIM J, YANG M H.Online object tracking:a benchmark[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2013:2411-2418.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(02),258-264 DOI:10.19678/j.issn.1000-3428.0049232            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">改进的SAMF目标跟踪算法</span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%A4%A7%E6%B9%98&amp;code=27902116&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李大湘</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E7%8E%B2%E9%A3%8E&amp;code=38477559&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴玲风</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%A8%9C&amp;code=28236834&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李娜</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E9%A2%96&amp;code=27749588&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘颖</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1698419&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安邮电大学通信与信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在基于视觉的目标跟踪过程中, 当目标被遮挡时, 跟踪算法精度往往下降。针对该问题, 在SAMF跟踪算法基础上, 提出一种基于图像分块重检测的改进算法。通过寻找最佳目标位置的方法优化SAMF算法, 提高目标跟踪的准确率。利用图像分块及样本逐一测试的方法设计重检测模块, 当目标因遮挡而无法稳定跟踪时, 启动重检测模块, 根据重检测后的最大响应值找出目标中心点, 并引入模型自动更新策略对目标位置进行更新, 避免出现跟踪漂移的现象。采用9个目标跟踪标准测试集进行对比实验, 结果表明, 该算法较SAMF算法平均距离精度提高了38%, 且优于KCF、CN、CSK等其他目标跟踪算法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标跟踪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B8%E5%85%B3%E6%BB%A4%E6%B3%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">相关滤波;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%87%8D%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">重检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%81%AE%E6%8C%A1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">遮挡;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A8%A1%E5%9E%8B%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">模型更新策略;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李大湘 (1974—) , 男, 副教授, 主研方向为刑侦图像检索、机器识别;
;
                                </span>
                                <span>
                                    *吴玲风 (通信作者) , 硕士研究生;
;
                                </span>
                                <span>
                                    李娜, 博士;
;
                                </span>
                                <span>
                                    刘颖, 教授、博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2017-11-08</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61571361);</span>
                                <span>陕西省国际合作交流项目 (2017KW-013);</span>
                                <span>西安邮电大学研究生创新基金 (CXJJ2017004);</span>
                    </p>
            </div>
                    <h1>Improved SAMF Object Tracking Algorithm</h1>
                    <h2>
                    <span>LI Daxiang</span>
                    <span>WU Lingfeng</span>
                    <span>LI Na</span>
                    <span>LIU Ying</span>
            </h2>
                    <h2>
                    <span>School of Communication and Information Engineering, Xi'an University of Posts and Telecommunications</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In visual tracking, the accuracy of the tracking algorithms often declines when the object is occluded. In order to solve this problem, an improved SAMF algorithm based on re-detection is proposed in this paper. Firstly, the SAMF algorithm is optimized using the method of locating the object position to improve the accuracy of tracking. Secondly, a re-detection module is designed and added into the procedure of tracking. When the object is occluded, it cannot be tracked stably. Therefore, the re-detection module is started, and the object is found by using the maximum response value. At last, an automatic updating strategy for the appearance model is introduced to avoid the tracking drift. The proposed algorithm is compared with other tracking methods on nine video sequences. Experimental results show that the average distance precision of the proposed algorithm is improved by 38% compared with SAMF algorithm, and is superior to other tracking algorithms such as KCF, CN and CSK.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=object%20tracking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">object tracking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=correlation%20filtering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">correlation filtering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=re-detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">re-detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=occlusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">occlusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=model%20update%20strategy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">model update strategy;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2017-11-08</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="71" name="71" class="anchor-tag">0概述</h3>
                <div class="p1">
                    <p id="72">运动目标跟踪是在连续的视频序列中, 基于感兴趣目标的有关特征确定目标的位置<citation id="174" type="reference"><link href="37" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>, 在智能监控、视频检索、交通监控和车辆导航等方面具有重要的研究意义和应用价值。目前, 大多数跟踪算法只能进行场景较为单一的目标跟踪, 无法在多种复杂场景下鲁棒跟踪, 目标跟踪技术的研究重点依然在于如何解决遮挡、平面外旋转、光照变化及背景相似等问题, 以便提高跟踪精度。</p>
                </div>
                <div class="p1">
                    <p id="73">近年来, 相关滤波器在目标跟踪性能和计算速度上的出色表现, 使之成为当前的研究热点, 相关跟踪的算法也层出不穷。文献<citation id="175" type="reference">[<a class="sup">3</a>]</citation>首次将M OSSE滤波器用于目标跟踪, 并提出基于峰值旁瓣比检测遮挡。文献<citation id="176" type="reference">[<a class="sup">4</a>,<a class="sup">5</a>]</citation>将HOG特征用于核相关滤波器, 利用循环矩阵和离散傅里叶变换有效解决了训练数据的冗余问题, 计算量大大减少, 提高了跟踪性能。文献<citation id="177" type="reference">[<a class="sup">6</a>]</citation>用颜色属性扩展了CSK跟踪器, 为彩色视频帧的跟踪提供了卓越的性能。文献<citation id="178" type="reference">[<a class="sup">7</a>]</citation>在KCF跟踪器的基础上融合了颜色空间HSV特征, 该算法对彩色视频的目标跟踪效果较好, 但无法处理长时间大范围目标遮挡及大幅度目标旋转。文献<citation id="179" type="reference">[<a class="sup">8</a>]</citation>引入对数极坐标变换, 解决了目标的尺度变化问题, 而目标一旦出现面外旋转、严重遮挡和较大形变时, 该算法无法达到预期效果。文献<citation id="183" type="reference">[<a class="sup">9</a>,<a class="sup">10</a>]</citation>利用两个单独的滤波器分别用于平移和尺度估计, 实现自适应尺度的目标跟踪。文献<citation id="180" type="reference">[<a class="sup">11</a>]</citation>通过多次连续蒙特卡罗采样得到最优目标区域, 并利用子块遮挡比例自适应调节学习速率, 解决了时空上下文跟踪易漂移且对遮挡敏感的问题。LCT<citation id="181" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>算法利用随机蕨重新检测因遮挡而跟丢的目标, 可以实现长期跟踪, 但缺点是跟踪速度较慢。文献<citation id="184" type="reference">[<a class="sup">13</a>,<a class="sup">14</a>]</citation>有效利用更多背景信息提出了一种背景感知CF跟踪器, 提高了应对显著外观变化和背景杂波等场景的鲁棒性。文献<citation id="182" type="reference">[<a class="sup">15</a>]</citation>将结构化SVM与CF结合, 同时还提出一种多峰目标检测技术, 避免了相似物体和背景干扰。尽管, 基于KCF跟踪器有许多改进算法, 也取得了一定成果, 但目标遮挡问题仍然是众多挑战之一。</p>
                </div>
                <div class="p1">
                    <p id="74">为解决KCF跟踪器固定模板大小的问题, SAM F<citation id="185" type="reference"><link href="67" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>算法增加尺度估计, 并采用HOG特征和颜色名 (Color Name, CN) 特征的融合多特征, 跟踪性能整体进一步提高, 其不足之处在于无法处理遮挡、变形和平面外旋转。当目标发生遮挡而导致跟踪失败时, SAMF算法没有目标重检测模块。本文在SAM F跟踪器的基础上, 优化了寻找输出响应最大值所对应的最佳尺度估计和目标最佳中心点位置的方法, 并提出利用图像分块重检测的思想, 对分块后的图像块逐一进行相关滤波, 找出最大响应值的位置, 更新当前帧的目标中心点位置。此外引入模型更新策略, 目标正常跟踪则正常更新模型, 当目标开始遮挡时, 更新缓慢甚至停止更新模型, 防止产生模型的错误累积。</p>
                </div>
                <h3 id="75" name="75" class="anchor-tag">1 SAMF跟踪算法</h3>
                <div class="p1">
                    <p id="76">SAM F跟踪是基于特征融合的自适应尺度核相关跟踪的简称, 是目前跟踪效果较好的算法之一。跟踪算法是在KCF算法的基础上融合了CN特征, 充分利用视频帧的颜色信息, 提高了目标跟踪的鲁棒性。</p>
                </div>
                <h4 class="anchor-tag" id="77" name="77">1.1 SAMF跟踪</h4>
                <div class="p1">
                    <p id="78">SAM F跟踪的主要部分可以分为分类器训练、模型更新和自适应尺度估计。SAMF跟踪器主要是利用初始帧信息训练一个模型, 后续帧通过模型匹配找到目标的最佳预测位置, 在新的位置重新训练模型, 并引入模型更新策略, 控制整个跟踪过程的模型更新速度, 如此循环直至图像序列最后一帧。</p>
                </div>
                <div class="p1">
                    <p id="79">SAM F跟踪器在目标中心点选取目标及其部分背景区域作为搜索窗口, 得到图像块x, 其大小为M×N, 对其所有的循环移位图像块x<sub>m, n</sub> (m∈{0, 1, …, M-1}, n∈{0, 1, …, N-1}) , 对样本进行高斯函数标记, 得到y (m, n) , 分类器训练为:</p>
                </div>
                <div class="area_img" id="80">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902043_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="81">其中, ⊙表示元素点积, ω为分类器系数, φ为核映射空间, λ≥0表示正则化参数。</p>
                </div>
                <div class="p1">
                    <p id="82">利用离散傅里叶变换在频域简化上式并求解, 求得最优解为w=<sup>m</sup>∑, <sup>n</sup>α (m, n) φ (x<sub>m, n</sub>) , 系数α为:</p>
                </div>
                <div class="area_img" id="83">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902043_08300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="84">其中, y是样本标签, 文中上标<image id="149" type="formula" href="images/JSJC201902043_14900.jpg" display="inline" placement="inline"><alt></alt></image>均表示频域运算, <image id="150" type="formula" href="images/JSJC201902043_15000.jpg" display="inline" placement="inline"><alt></alt></image>表示训练样本的自相关高斯核输出。</p>
                </div>
                <div class="p1">
                    <p id="85">利用循环矩阵的特性将回归函数f (z) 对角化后得到:</p>
                </div>
                <div class="area_img" id="86">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902043_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="87">其中, z表示测试样本, <image id="151" type="formula" href="images/JSJC201902043_15100.jpg" display="inline" placement="inline"><alt></alt></image>表示测试样本与模型训练样本之间的互相关高斯核输出。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88">1.2 自适应尺度估计与模型更新</h4>
                <div class="p1">
                    <p id="89">为了更好应对目标的尺度变化而能够自适应跟踪目标, SAMF跟踪器将模板尺寸固定为s<sub>T</sub>= (s<sub>x</sub>, s<sub>y</sub>) , 并定义尺度因子S={t<sub>1</sub>, t<sub>2</sub>, …t<sub>p</sub>}。以上一帧的目标位置为中心, 分别选取p个不同尺度的图像块大小为{t<sub>i</sub>s<sub>T </sub>t<sub>i</sub>∈S}, 然后统一调整为模板尺寸, 再进行特征提取, 通过相关滤波器找出最大响应值maxy<sub>s</sub>^及目标的最佳尺度, 估计目标中心点的最佳位置。</p>
                </div>
                <div class="p1">
                    <p id="90">采用加权更新当前帧 (第t帧) 模型, 即目标外观模板<image id="152" type="formula" href="images/JSJC201902043_15200.jpg" display="inline" placement="inline"><alt></alt></image>和系数<image id="153" type="formula" href="images/JSJC201902043_15300.jpg" display="inline" placement="inline"><alt></alt></image>, 如下所示:</p>
                </div>
                <div class="area_img" id="91">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902043_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="92">其中, η为学习速率, 取值范围为0&lt;η&lt;0.1, 值越大表明所占权重越大, z是在更新后的目标位置重新采样的训练样本, <image id="154" type="formula" href="images/JSJC201902043_15400.jpg" display="inline" placement="inline"><alt></alt></image>表示z的自相关高斯核输出, <image id="155" type="formula" href="images/JSJC201902043_15500.jpg" display="inline" placement="inline"><alt></alt></image>分别表示当前帧和上一帧更新后的目标匹配模板, <image id="156" type="formula" href="images/JSJC201902043_15600.jpg" display="inline" placement="inline"><alt></alt></image><image id="156" type="formula" href="images/JSJC201902043_15601.jpg" display="inline" placement="inline"><alt></alt></image>分别表示当前帧和上一帧更新后的系数。</p>
                </div>
                <h3 id="93" name="93" class="anchor-tag">2 改进的SAMF跟踪器</h3>
                <h4 class="anchor-tag" id="94" name="94">2.1 最大响应搜索方法优化</h4>
                <div class="p1">
                    <p id="95">假设跟踪目标尺寸为W×H, 图像的搜索窗大小为M×N, 其汉明窗大小为<image id="157" type="formula" href="images/JSJC201902043_15700.jpg" display="inline" placement="inline"><alt></alt></image> (搜索窗按4×4分块) , 频域响应为<image id="158" type="formula" href="images/JSJC201902043_15800.jpg" display="inline" placement="inline"><alt></alt></image>维矩阵, 本文算法优化了SAMF算法如何根据得到的最大响应值的点, 寻找所对应的最佳尺度估计和目标最佳中心点位置, 具体优化过程为:</p>
                </div>
                <div class="p1">
                    <p id="96">1) 找出频域响应矩阵里的最大响应的第一个点, 得到其行和列的索引值分别是vert与tmp, 即在第vert行。</p>
                </div>
                <div class="p1">
                    <p id="97">2) 确定尺度方向szid, 计算所在二维矩阵中的列数horiz:</p>
                </div>
                <div class="area_img" id="98">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902043_09800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="99">3) 判断是否为最后一列的特殊情况, 若<image id="159" type="formula" href="images/JSJC201902043_15900.jpg" display="inline" placement="inline"><alt></alt></image><image id="159" type="formula" href="images/JSJC201902043_15901.jpg" display="inline" placement="inline"><alt></alt></image>, 则:</p>
                </div>
                <div class="area_img" id="100">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902043_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="101">4) 根据尺度因子t<sub>szid</sub>求出当前目标最佳尺度optsz及最佳中心点位置pos:</p>
                </div>
                <div class="area_img" id="102">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902043_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="103" name="103">2.2 重检测及模型更新策略</h4>
                <div class="p1">
                    <p id="104">当目标发生遮挡时, 应启动重检测模块, 防止目标模型的累积错误越来越大而导致跟踪失败。本文提出了利用图像分块重检测的思想, 将整幅图像按照搜索窗尺寸进行分块 (分块过程见图1) , 对于每一个图像块Q<sub>i</sub>, i∈{1, 2, …, q}都看作是测试样本, 分别与模型进行相关性计算, 其中找出的最大响应值的点就是目标中心点的候选位置。</p>
                </div>
                <div class="area_img" id="105">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902043_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 重检测过程分块示意图" src="Detail/GetImg?filename=images/JSJC201902043_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 重检测过程分块示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902043_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="106">根据最大响应值<image id="160" type="formula" href="images/JSJC201902043_16000.jpg" display="inline" placement="inline"><alt></alt></image>的变化, 设定一个阈值T<sub>r</sub>用来判断目标是否发生遮挡。当<image id="161" type="formula" href="images/JSJC201902043_16100.jpg" display="inline" placement="inline"><alt></alt></image>时, 目标正常进行跟踪。当<image id="162" type="formula" href="images/JSJC201902043_16200.jpg" display="inline" placement="inline"><alt></alt></image>时, 则认为目标已经开始出现较大遮挡, 此时需要对目标重新检测, 找出q个置信图中的一个最大响应值<image id="163" type="formula" href="images/JSJC201902043_16300.jpg" display="inline" placement="inline"><alt></alt></image>, 还应判断其与阈值T<sub>t</sub> (T<sub>t</sub>&gt;T<sub>r</sub>) 的大小。只有当<image id="164" type="formula" href="images/JSJC201902043_16400.jpg" display="inline" placement="inline"><alt></alt></image><image id="164" type="formula" href="images/JSJC201902043_16401.jpg" display="inline" placement="inline"><alt></alt></image>时, 才准确找到了目标中心点所在位置并进行位置更新, 否则认为目标还处于遮挡状态, 暂且以上一帧的位置信息更新目标位置, 忽略目标被遮挡期间的一小段运动轨迹。</p>
                </div>
                <div class="area_img" id="107">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902043_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="108">为了避免因遮挡、旋转、光照变化等情况影响模型更新训练, 出现跟踪漂移现象, 本文算法引入模型更新策略控制模型更新的快慢, 目的在于减小目标模型的累积错误。设定一个阈值T<sub>s</sub> (T<sub>s</sub>&gt;T<sub>r</sub>) , 当<image id="165" type="formula" href="images/JSJC201902043_16500.jpg" display="inline" placement="inline"><alt></alt></image>时, 正常更新当前帧 (第t帧) 的模型参数<image id="166" type="formula" href="images/JSJC201902043_16600.jpg" display="inline" placement="inline"><alt></alt></image>, 一旦不满足条件, 则认为此时的目标区域存在不确定性, 不予以更新。</p>
                </div>
                <h4 class="anchor-tag" id="109" name="109">2.3 跟踪算法流程</h4>
                <div class="p1">
                    <p id="110">本文增加了分块重检测模块并且引入模型更新策略防止模板漂移, 能够很好地解决部分遮挡或全遮挡问题, 有效实现长期目标跟踪, 具体算法步骤为:</p>
                </div>
                <div class="p1">
                    <p id="111">输入第一帧图像并初始化目标</p>
                </div>
                <div class="p1">
                    <p id="112">输出所有序列每帧中目标的中心点位置pos<sub>t</sub></p>
                </div>
                <div class="p1">
                    <p id="113">1) 对第t帧图像的搜索区域进行特征提取, 利用式 (2) 、式 (3) 训练相关滤波器。</p>
                </div>
                <div class="p1">
                    <p id="114">2) 根据p个尺度因子分别计算出p个响应值<image id="168" type="formula" href="images/JSJC201902043_16800.jpg" display="inline" placement="inline"><alt></alt></image>, 找出<image id="169" type="formula" href="images/JSJC201902043_16900.jpg" display="inline" placement="inline"><alt></alt></image>所对应的目标位置pos<sub>i</sub>。</p>
                </div>
                <div class="p1">
                    <p id="115">3) 判断<image id="167" type="formula" href="images/JSJC201902043_16700.jpg" display="inline" placement="inline"><alt></alt></image>是否成立。如果成立, 则认为目标发生遮挡, 需要启动重检测模块, 否则转到步骤5。</p>
                </div>
                <div class="p1">
                    <p id="116">4) 按照搜索窗尺寸大小将当前整幅图像划分为若干个图像块 (互不重叠分块, 最后剩余的像素区域有重叠分块, 如图1所示) , 分别计算出其响应值<image id="170" type="formula" href="images/JSJC201902043_17000.jpg" display="inline" placement="inline"><alt></alt></image>, 判断<image id="171" type="formula" href="images/JSJC201902043_17100.jpg" display="inline" placement="inline"><alt></alt></image>是否成立, 如果成立, 则认为目标已被重新捕获, 利用<image id="172" type="formula" href="images/JSJC201902043_17200.jpg" display="inline" placement="inline"><alt></alt></image>所对应的位置pos<sub>new</sub>更新目标位置, 否则认为目标处于遮挡状态, 仅以上一帧的位置pos<sub>t-1</sub>更新目标位置。</p>
                </div>
                <div class="p1">
                    <p id="117">5) 判断<image id="173" type="formula" href="images/JSJC201902043_17300.jpg" display="inline" placement="inline"><alt></alt></image>是否成立。如果成立, 则利用式 (4) 更新模型, 否则不对模型进行更新。</p>
                </div>
                <div class="p1">
                    <p id="118">6) 判断视频帧是否达到帧尾。如果是, 则结束跟踪算法, 否则处理第t+1帧图像, 重复步骤1～步骤6。</p>
                </div>
                <div class="p1">
                    <p id="119">文献<citation id="186" type="reference">[<a class="sup">5</a>]</citation>对式 (2) 的计算效率进行了说明, 时间复杂度O (ρlbρ) 近似为线性, ρ表示算法的迭代次数。本文算法的运算时间增加了尺度估计和重检测, 总的时间复杂度为O (p+2q+ρlbρ) , 其中, 尺度估计的时间复杂度为O (p) , p表示尺度因子数量, 重检测模块的时间复杂度为O (q) , q表示图像块数量。</p>
                </div>
                <h3 id="120" name="120" class="anchor-tag">3 实验与结果分析</h3>
                <div class="p1">
                    <p id="121">实验借助MATLAB R2014b软件平台在Intel (R) Xeon (R) CPU E3-1220 v3@3.10 GHz CPU, 8.00 GB内存的台式计算机上调试运行。</p>
                </div>
                <div class="p1">
                    <p id="124">从OTB<citation id="187" type="reference"><link href="69" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>提供的数据集中选出9组具有挑战性的视频序列 (Bird2, Box, Coke, Freeman4, Girl2, Liquor, Soccer, Tiger1, Tiger2) 进行测试, 包括尺度变化、光照变化、遮挡、旋转和快速运动等多种复杂的情况, 并对实验结果进行分析。为了保证数据的公正客观, 实验中所用的对比跟踪算法的代码均由作者在其论文里公开的网站上获得, 各种算法的异同点如表1所示。</p>
                </div>
                <div class="area_img" id="125">
                                            <p class="img_tit">
                                                表1 5种跟踪算法异同
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902043_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201902043_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902043_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 5种跟踪算法异同" src="Detail/GetImg?filename=images/JSJC201902043_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="126" name="126">3.1 阈值设置分析</h4>
                <div class="p1">
                    <p id="127">图2以Girl2序列为例, 给出了本文算法重检测模块未启动时在每一帧的响应最大值, 其值大小表征目标跟踪结果的可信度, 可信度越高说明跟踪结果越精确。由图2可知, 在第100帧前后范围内, 响应值突然急剧减小, 低于一定阈值, 有很大可能性在该范围内目标经历遮挡导致跟踪失败 (图1为第107帧的目标真实情况, 小女孩几乎已经完全被遮挡) 。尽管随后响应值会继续增大, 但由于此后的跟踪框在一个非目标区域并且位置保持不变, 此时的响应最大值已经没有实际意义。因此, 根据目标即将开始进入遮挡状态时的某一响应值设置阈值, 可以有效启动重检测模块, 本文阈值设定T<sub>r</sub>=0.32, T<sub>s</sub>=0.30。</p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902043_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 Girl2序列响应最大值曲线" src="Detail/GetImg?filename=images/JSJC201902043_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 Girl2序列响应最大值曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902043_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="130" name="130">3.2 图像分块数量分析</h4>
                <div class="p1">
                    <p id="131">为说明图像分块的数量对算法性能的影响, 同时, 也进行了按照目标尺寸以及目标区域扩展padding分别取0.5和1.0时的不同搜索区域尺寸分块的对比实验, 实验结果表明对跟踪精度并无影响。表2列出了4个数据集按不同尺寸分块的检测速度。</p>
                </div>
                <div class="area_img" id="132">
                                            <p class="img_tit">
                                                表2 不同分块数量下的检测速度
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902043_13200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201902043_13200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                <p class="img_note"> (frame·s<sup>-1</sup>) </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902043_13200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 不同分块数量下的检测速度" src="Detail/GetImg?filename=images/JSJC201902043_13200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="133">以上结果表明, 分块尺寸越小, 反而速度越慢。这是由于分块尺寸变小, 图像块数量相应增加, 需要作相关操作次数也增加。搜索窗是目标的2.5倍大小, 不同数据集的图像与目标大小不一, 分块尺寸过大, 极有可能超过原始图像尺寸, 从而无法分块。因此, 将padding取1.5, 对图像按照搜索窗尺寸进行分块, 跟踪性能最佳。</p>
                </div>
                <h4 class="anchor-tag" id="134" name="134">3.3 参数设置与评价指标</h4>
                <div class="p1">
                    <p id="135">目标区域扩展取padding=1.5, 正则化参数取λ=10<sup>-4</sup>, 学习速率取η=0.01, 尺度因子预设为S={1.000, 0.985, 0.990, 0.995, 1.005, 1.010, 1.015}, 阈值T<sub>r</sub>取0.32, 阈值T<sub>s</sub>取0.30。</p>
                </div>
                <div class="p1">
                    <p id="138">跟踪性能采用文献<citation id="188" type="reference">[<a class="sup">17</a>]</citation>中使用的距离精度作为评价指标。此外考虑到实时性, 本文还采用帧率衡量跟踪算法的速度。距离精度定义为中心位置误差小于某个固定阈值的视频帧数与总帧数的百分比, 通常阈值取20 pixel。</p>
                </div>
                <h4 class="anchor-tag" id="139" name="139">3.4 对比实验结果与分析</h4>
                <div class="p1">
                    <p id="140">图3为实验数据集跟踪结果的距离精度曲线, 图例中还给出了每种算法的以20 pixel为阈值的距离精度。整体来看, 图形呈“S”型曲线增长, 大约在阈值取25 pixel～30 pixel时, 距离精度增长趋于平缓, 由此可见阈值应为20 pixel左右。从图3中可以看出, 本文算法的距离精度在9个测试数据集中均达到最优或次最优, 能够有效应对多种挑战, 提高了跟踪准确率。取其平均值作比较, 与SAMF相比, 本文算法的平均距离精度提高了38%, 相比KCF、CN、CSK分别提高了28.3%、26.2%、62.4%。</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902043_14100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 跟踪精度曲线" src="Detail/GetImg?filename=images/JSJC201902043_14100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 跟踪精度曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902043_14100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="142">由表1可知, 仅本文算法具有重检测模块, 其余4种算法均不可以在目标遮挡或跟丢时重新进行目标检测, 然而所有测试视频集均存在目标遮挡场景。例如, 在Box视频中目标只经历了一次遮挡, 从遮挡开始发生到目标完全重新回到视野历经了近50 frame图像, 除了本文算法可以鲁棒跟踪, 且跟踪精度达到0.915, 远远高于SAMF算法0.401的结果, 其他算法均无法应对遮挡。因此, 本文算法的重检测模块可以有效应对目标发生遮挡的场景。然而针对Liquor视频中目标多次被遮挡, 且存在相似背景干扰, 跟踪结果的距离精度也从0.440提高到0.744。因此, 本文算法能够有效处理目标旋转、尺度变化、光照变化和全遮挡等多种复杂场景, 但暂时无法应对背景相似干扰等情况。</p>
                </div>
                <div class="p1">
                    <p id="143">图4为5种算法对Box、Girl2、Liquor视频的跟踪截图。在Box视频中目标从第446帧开始经历遮挡, 第461帧已经处于完全被遮挡状态, 在此期间, CN、CSK和SAMF算法先后对目标跟踪失败, 本文算法由于重检测目标区域存在不确定性, 没有予以更新位置。第488帧目标重新回到视野, KCF算法也无法继续跟踪目标, 本文算法重新检测到目标并开始正常跟踪, 而其他4种算法均无再捕获目标机制, 此时将彻底无法重新对目标进行跟踪。在此后的较长一段时间里, 目标频繁发生旋转, 本文算法依然能够稳健跟踪目标。在Girl2视频中的目标分别经历了全局遮挡、旋转、尺度变化等情况, 第105帧目标出现一点遮挡, 此时所有算法正常跟踪, 随后遮挡严重, KCF与CSK算法跟踪失败, SAMF算法与本文算法尚能准确跟踪目标。第110帧时目标已经完全被遮挡, SAMF算法开始出现漂移。第120帧目标完全出现, 其他算法均已跟丢目标, 将遮挡物误认为是目标而对其跟踪, 出现严重偏差, 只有本文算法一直准确跟踪目标, 直到目标离开遮挡, 重新进入视线后继续跟踪。在Liquor视频中的目标前后发生视野不足、多次遮挡以及旋转等情况, 第392帧目标部分离开视野, 所有算法能够正常跟踪目标。第506帧时目标第一次经历完全遮挡, 随着遮挡物的移开, CSK算法跟丢目标, 其余4种算法都能正常对目标跟踪。第774帧时目标再次被遮挡, SAM F和KCF算法对目标跟踪失败, 第778帧目标重新出现时, 只有本文算法与CN算法依然鲁棒跟踪目标。实验结果表明, 本文算法提出的重检测模块在目标发生遮挡时能够起到抗遮挡作用, 跟踪性能得到有效提高。其他视频跟踪截图, 限于篇幅, 本文不作进一步描述, 读者可通过OSID码查看。</p>
                </div>
                <div class="area_img" id="144">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902043_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 5种算法跟踪截图" src="Detail/GetImg?filename=images/JSJC201902043_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 5种算法跟踪截图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902043_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="145">表3为5种跟踪算法的帧率对9个视频的检测速度。由表1和表3可知, KCF和CN算法分别采用HOG特征和融合灰度特征与CN特征的多特征描述目标外观, 平均处理速度分别为182.60 frame/s和176.47 frame/s, 而CSK算法直接利用原始像素对目标外观进行描述, 从而运行速度最快, 平均帧率能够达到360.52 frame/s。本文算法与SAMF算法均采用HOG特征与CN特征的融合特征描述目标, 并且能够自适应尺度估计, 因此计算量大, 处理速度较慢。此外, 本文算法提出了分块重检测目标, 防止目标跟丢发生跟踪漂移, 当重检测机制启动时, 运算时间成本增加 (与图像块数量有关, 分块数量越多, 所需时间越多) , 速度最慢, 为11.55 frame/s。因此, 本文算法在提高了跟踪准确率的同时以牺牲时间为代价。</p>
                </div>
                <div class="area_img" id="146">
                                            <p class="img_tit">
                                                表3 跟踪算法的检测速度
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902043_14600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201902043_14600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                <p class="img_note"> (frame·s-1) </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902043_14600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 跟踪算法的检测速度" src="Detail/GetImg?filename=images/JSJC201902043_14600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h3 id="147" name="147" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="148">本文提出一种基于图像分块重检测的改进算法, 优化了最大响应搜索方法, 并引入模型自动更新策略。实验结果表明, 本文算法平均距离精度为0.886, 而SAM F仅为0.506。相比之下, 本文算法较大幅度提高了目标跟踪的精度, 能够有效处理目标遮挡问题, 在光照变化、遮挡、运动模糊和旋转等复杂场景下能够实现鲁棒的目标跟踪。下一步将利用目标的时空上下文信息并同时考虑其纹理特征, 有效判别前景区域和相似背景, 进一步提高跟踪效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="37">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201610002&amp;v=MjgyNjJMZlliRzRIOWZOcjQ5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5amtWYnpKS0M=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>尹宏鹏, 陈波, 柴毅, 等.基于视觉的目标检测与跟踪综述[J].自动化学报, 2016, 42 (10) :1466-1489.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201506001&amp;v=MTkzNzdiekpMejdCZHJHNEg5VE1xWTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqa1Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>黄凯奇, 陈晓棠, 康运锋, 等.智能视频监控技术综述[J].计算机学报, 2015, 20 (6) :1093-1118.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual object tracking using adaptive correlation filters">

                                <b>[3]</b>BOLME D S, BEVERIDGE J R, DRAPER B A, et al.Visual object tracking using adaptive correlation filters[C]//Proceedings of Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2010:2544-2550.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploiting the circulant structure of tracking-by-detection with kernels">

                                <b>[4]</b>HENRIQUES J F, RUI C, MARTINS P, et al.Exploiting the circulant structure of tracking-by-detection with kernels[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2012:702-715.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-speed tracking with kernelized correlation filters">

                                <b>[5]</b>HENRIQUES J F, CASEIRO R, MARTINS P, et al.Highspeed tracking with kernelized correlation filters[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37 (3) :583.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive Color Attributes for Real-Time Visual Tracking">

                                <b>[6]</b>DANELLJAN M, KHAN F S, FELSBERG M, et al.Adaptive color attributes for real-time visual tracking[C]//Proceedings of Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2014:1090-1097.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201703072&amp;v=MTkxNThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqa1ZiekpMejdTWkxHNEg5Yk1ySTlDWm8=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>徐玉龙, 王家宝, 李阳, 等.融合颜色特征的尺度自适应相关跟踪[J].计算机应用研究, 2017, 34 (3) :945-948.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201703007&amp;v=MjU2NzBSbkZ5amtWYnpKTHo3QmFMRzRIOWJNckk5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>马晓楠, 刘晓利, 李银伢.自适应尺度的快速相关滤波跟踪算法[J].计算机辅助设计与图形学学报, 2017, 29 (3) :450-458.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201602026&amp;v=MzI2NTVIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqa1ZiekpJalhCWTdHNEg5Zk1yWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>张雷, 王延杰, 孙宏海, 等.采用核相关滤波器的自适应尺度目标跟踪[J].光学精密工程, 2016, 24 (2) :448-459.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accurate scale estimation for robust visual tracking">

                                <b>[10]</b>DANELLJAN M, HGER G, FAHAD S K, et al.Accurate scale estimation for robust visual tracking[C]//Proceedings of British Machine Vision Conference.Guildford, UK:BMVAPress, 2014:1-11.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201809043&amp;v=MTI4OTBSbkZ5amtWYnpKTHo3QmJiRzRIOW5NcG85Qlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>李珑, 刘凯, 李玲.基于目标检测的时空上下文跟踪算法[J].计算机工程, 2018, 44 (9) :263-268, 273.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Long-term correlation tracking">

                                <b>[12]</b>MA C, YANG X, ZHANG C, et al.Long-term correlation tracking[C]//Proceedings of Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:5388-5396.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Context-Aware Correlation Filter Tracking">

                                <b>[13]</b>MUELLER M, SMITH N, GHANEM B.Context-aware correlation filter tracking[C]//Proceedings of IEEEConference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2017:1387-1395.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning background-aware correlation filters for visual tracking">

                                <b>[14]</b>GALOOGAHI H K, FAGG A, LUCEY S.Learning background-aware correlation filters for visual tracking[EB/OL].[2017-10-10].https://arxiv.org/abs/1703.04590.
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Large margin object tracking with circulant feature maps">

                                <b>[15]</b>WANG M, LIU Y, HUANG Z.Large margin object tracking with circulant feature maps[EB/OL].[2017-10-10].https://arxiv.org/abs/1703.05020v2.
                            </a>
                        </p>
                        <p id="67">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A scale adaptive kernel correlation filter tracker with feature integration">

                                <b>[16]</b>LI Y, ZHU J.A scale adaptive kernel correlation filter tracker with feature integration[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2014:254-265.
                            </a>
                        </p>
                        <p id="69">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Online object tracking:A benchmark">

                                <b>[17]</b>WU Y, LIM J, YANG M H.Online object tracking:a benchmark[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Computer Society, 2013:2411-2418.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201902043" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902043&amp;v=MDg3NzVCWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqa1ZiekpMejdCYmJHNEg5ak1yWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
