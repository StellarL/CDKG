<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131276570900000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201902029%26RESULT%3d1%26SIGN%3d7lFdWrb3QptrWkjK9Pq0nyH3wzo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902029&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201902029&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902029&amp;v=MjIzNTdCdEdGckNVUkxPZVplUm5GeWprVUx2S0x6N0JiYkc0SDlqTXJZOUhiWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#115" data-title="0概述 ">0概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#118" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#119" data-title="1.1 径向基函数神经网络">1.1 径向基函数神经网络</a></li>
                                                <li><a href="#135" data-title="1.2 Lasso线性问题">1.2 Lasso线性问题</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#148" data-title="2 基于Lasso稀疏学习的RBF神经网络 ">2 基于Lasso稀疏学习的RBF神经网络</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#150" data-title="2.1 RBF神经网络目标优化和参数学习">2.1 RBF神经网络目标优化和参数学习</a></li>
                                                <li><a href="#158" data-title="2.2 收缩参数确定">2.2 收缩参数确定</a></li>
                                                <li><a href="#160" data-title="2.3 算法步骤">2.3 算法步骤</a></li>
                                                <li><a href="#166" data-title="2.4 多分类策略">2.4 多分类策略</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#168" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#169" data-title="3.1 实验设置">3.1 实验设置</a></li>
                                                <li><a href="#177" data-title="3.2 评价标准">3.2 评价标准</a></li>
                                                <li><a href="#181" data-title="3.3 真实数据集实验">3.3 真实数据集实验</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#188" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#121" data-title="图1 径向基函数神经网络基本结构">图1 径向基函数神经网络基本结构</a></li>
                                                <li><a href="#183" data-title="表1 UCI真实数据集">表1 UCI真实数据集</a></li>
                                                <li><a href="#185" data-title="表2 真实数据集上各模型的分类精度比较">表2 真实数据集上各模型的分类精度比较</a></li>
                                                <li><a href="#187" data-title="表3 真实数据集中各模型所采用的隐节点数目">表3 真实数据集中各模型所采用的隐节点数目</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="59">


                                    <a id="bibliography_1" title="LIU G P.Nonlinear identification and control[J].Industrial Robot, 2002, 29 (5) :469-470." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinear identification and control">
                                        <b>[1]</b>
                                        LIU G P.Nonlinear identification and control[J].Industrial Robot, 2002, 29 (5) :469-470.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_2" title="DUFOUR P, BHARTIYA S, DHURJATI P S, et al.Neural network-based software sensor:training set design and application to a continuous pulp digester[J].Control Engineering Practice, 2005, 13 (2) :135-143." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501444953&amp;v=MTc5MDVYazZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklJRjhYYmhBPU5pZk9mYks3SHRETnFvOUVZTzhMQg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        DUFOUR P, BHARTIYA S, DHURJATI P S, et al.Neural network-based software sensor:training set design and application to a continuous pulp digester[J].Control Engineering Practice, 2005, 13 (2) :135-143.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_3" title="FORTUNA L, GRAZIANI S, XIBILIA M G.Soft sensors for product quality monitoring in debutanizer distillation columns[J].Control Engineering Practice, 2005, 13 (4) :499-508." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501444925&amp;v=MjM4ODlYNDhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklJRjhYYmhBPU5pZk9mYks3SHRETnFvOUVZTzhMQg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        FORTUNA L, GRAZIANI S, XIBILIA M G.Soft sensors for product quality monitoring in debutanizer distillation columns[J].Control Engineering Practice, 2005, 13 (4) :499-508.
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_4" title="GONZAGA J C B, MELEIRO L A C, KIANG C, et al.ANNbased soft-sensor for real-time process monitoring and control of an industrial polymerization process[J].Computers and Chemical Engineering, 2009, 33 (1) :43-49." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600163545&amp;v=MTg0MzlOcVk5RlplME1DWGc4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSUY4WGJoQT1OaWZPZmJLN0h0RA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        GONZAGA J C B, MELEIRO L A C, KIANG C, et al.ANNbased soft-sensor for real-time process monitoring and control of an industrial polymerization process[J].Computers and Chemical Engineering, 2009, 33 (1) :43-49.
                                    </a>
                                </li>
                                <li id="67">


                                    <a id="bibliography_5" title="RANI A, SINGH V, GUPTA J R P.Development of soft sensor for neural network based control of distillation column[J].ISA Transactions, 2013, 52 (3) :438-449." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900094844&amp;v=MDk3NTFUNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklJRjhYYmhBPU5pZk9mYks3SHRUTXBvOUZaT0lMQkhnOW9CTQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        RANI A, SINGH V, GUPTA J R P.Development of soft sensor for neural network based control of distillation column[J].ISA Transactions, 2013, 52 (3) :438-449.
                                    </a>
                                </li>
                                <li id="69">


                                    <a id="bibliography_6" title="RODGER J A.A fuzzy nearest neighbor neural network statistical model for predicting demand for natural gas and energy cost savings in public buildings[J].Expert Systems with Applications, 2014, 41 (4) :1813-1829." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESBD9A5F88F4F7EA4DD101C021F4E3F83C&amp;v=MjQzODJmT2ZjSE1GNkRKMllkTkV1OTVDd2xJeTJKbjZ6OThPMy9ncldReERMSGlUYm5zQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZoeExtOHhLbz1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        RODGER J A.A fuzzy nearest neighbor neural network statistical model for predicting demand for natural gas and energy cost savings in public buildings[J].Expert Systems with Applications, 2014, 41 (4) :1813-1829.
                                    </a>
                                </li>
                                <li id="71">


                                    <a id="bibliography_7" title="YAN W.Toward automatic time-series forecasting using neural networks[J].IEEE Transactions on Neural Networks and Learning Systems, 2012, 23 (7) :1028-1039." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Toward Automatic Time-Series Forecasting Using Neural Networks">
                                        <b>[7]</b>
                                        YAN W.Toward automatic time-series forecasting using neural networks[J].IEEE Transactions on Neural Networks and Learning Systems, 2012, 23 (7) :1028-1039.
                                    </a>
                                </li>
                                <li id="73">


                                    <a id="bibliography_8" title="ZHANG J, MARTIN E B, MORRIS A J, et al.Inferential estimation of polymer quality using stacked neural networks[J].Computers and Chemical Engineering, 1997, 21 (Suppl) :1037-1039." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600165019&amp;v=Mjg2NTlQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGOFhiaEE9TmlmT2ZiSzdIdEROcVk5RlplMEtESDB3b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        ZHANG J, MARTIN E B, MORRIS A J, et al.Inferential estimation of polymer quality using stacked neural networks[J].Computers and Chemical Engineering, 1997, 21 (Suppl) :1037-1039.
                                    </a>
                                </li>
                                <li id="75">


                                    <a id="bibliography_9" title="王士同.神经模糊系统及其应用[M].北京:北京航空航天大学出版社, 1998." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=0007810127330999&amp;v=MDk5Mjl0RE9xSXhHWk9JR0JSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZadTl1RkN2c1U3L0pJMW9XVlYyN0didTVI&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        王士同.神经模糊系统及其应用[M].北京:北京航空航天大学出版社, 1998.
                                    </a>
                                </li>
                                <li id="77">


                                    <a id="bibliography_10" title="DING Shifei, MA Gang, SHI Zhongzhi.A rough RBFneural network based on weighted regularized extreme learning machine[J].Neural Processing Letters, 2014, 40 (3) :245-260." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14111100002550&amp;v=MTIwNTRzTkNYazVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklJRjhYYmhBPU5qN0Jhcks4SDlETnJvOUZaTw==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        DING Shifei, MA Gang, SHI Zhongzhi.A rough RBFneural network based on weighted regularized extreme learning machine[J].Neural Processing Letters, 2014, 40 (3) :245-260.
                                    </a>
                                </li>
                                <li id="79">


                                    <a id="bibliography_11" title="WU Jiansheng, LONG Jin, LIU Mingzhe.Evolving RBFneural networks for rainfall prediction using hybrid particle swarm optimization and genetic algorithm[J].Neurocomputing, 2015, 148 (2) :136-142." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESF63EEB0860AA5E103A645F2E70508B1F&amp;v=MDYzMjZPR1FsZkNwYlEzNU5GaHhMbTh4S289TmlmT2ZjVytIYVM1M1k5Tll1dCtmWGxNemhZUW16bDVUUW5nMlJVMWZMS2NON3ZwQ09OdkZTaVdXcjdKSUZwbWFCdUhZZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        WU Jiansheng, LONG Jin, LIU Mingzhe.Evolving RBFneural networks for rainfall prediction using hybrid particle swarm optimization and genetic algorithm[J].Neurocomputing, 2015, 148 (2) :136-142.
                                    </a>
                                </li>
                                <li id="81">


                                    <a id="bibliography_12" title="NIROS A D, TSEKOURAS G E, TSOLAKIS D, et al.Hierarchical fuzzy clustering in conjunction with particle swarm optimization to efficiently design RBF neural networks[J].Journal of Intelligent and Robotic Systems, 2015, 78 (1) :105-125." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hierarchical\sfuzzy clustering in conjunction with particle swarm optimization to efficiently design RBF neural networks">
                                        <b>[12]</b>
                                        NIROS A D, TSEKOURAS G E, TSOLAKIS D, et al.Hierarchical fuzzy clustering in conjunction with particle swarm optimization to efficiently design RBF neural networks[J].Journal of Intelligent and Robotic Systems, 2015, 78 (1) :105-125.
                                    </a>
                                </li>
                                <li id="83">


                                    <a id="bibliography_13" title="NIROSA D, TSEKOURAS G E.A novel training algorithm for RBF neural network using a hybrid fuzzy clustering approach[J].Fuzzy Sets and Systems, 2012, 193 (9) :62-84." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300670264&amp;v=MzEwODZET3JJOUZZdXdQRG5vOW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGOFhiaEE9TmlmT2ZiSzdIdA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        NIROSA D, TSEKOURAS G E.A novel training algorithm for RBF neural network using a hybrid fuzzy clustering approach[J].Fuzzy Sets and Systems, 2012, 193 (9) :62-84.
                                    </a>
                                </li>
                                <li id="85">


                                    <a id="bibliography_14" title="张江滨, 邓赵红, 王士同.模糊子空间聚类的径向基函数神经网络建模[J].计算机科学与探索, 2015, 9 (12) :1513-1522." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201512011&amp;v=MjAyMDJDVVJMT2VaZVJuRnlqa1VMdktMalhmZmJHNEg5VE5yWTlFWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        张江滨, 邓赵红, 王士同.模糊子空间聚类的径向基函数神经网络建模[J].计算机科学与探索, 2015, 9 (12) :1513-1522.
                                    </a>
                                </li>
                                <li id="87">


                                    <a id="bibliography_15" title="TIBSHIRANI R.Regression shrinkage and selection via the Lasso[J].Journal of the Royal Statistical Society, 1996, 58 (1) :267-288." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Regression shrinkage and selection via the lasso">
                                        <b>[15]</b>
                                        TIBSHIRANI R.Regression shrinkage and selection via the Lasso[J].Journal of the Royal Statistical Society, 1996, 58 (1) :267-288.
                                    </a>
                                </li>
                                <li id="89">


                                    <a id="bibliography_16" title="ZOU Hui.The adaptive Lasso and its oracle properties[J].Journal of the American Statistical Association, 2012, 101 (476) :1418-1429." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800006312&amp;v=MTM4ODJmT3A0OUZaT3NKRDMwN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGOFhiaEE9TmpuQmFySzdIdA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        ZOU Hui.The adaptive Lasso and its oracle properties[J].Journal of the American Statistical Association, 2012, 101 (476) :1418-1429.
                                    </a>
                                </li>
                                <li id="91">


                                    <a id="bibliography_17" title="RADCHENKOP, JAMES G M.Improved variable selection with forward-Lasso adaptive shrinkage[J].Annals of Applied Statistics, 2011, 5 (1) :427-448." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=IMPROVED VARIABLE SELECTION WITH FORWARD-LASSO ADAPTIVE SHRINKAGE">
                                        <b>[17]</b>
                                        RADCHENKOP, JAMES G M.Improved variable selection with forward-Lasso adaptive shrinkage[J].Annals of Applied Statistics, 2011, 5 (1) :427-448.
                                    </a>
                                </li>
                                <li id="93">


                                    <a id="bibliography_18" title="HUANG Guangbin, ZHU Qinyu, SIEW C K.Extreme learning machine:theory and applications[J].Neurocomputing, 2006, 70 (1-3) :489-501." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501913101&amp;v=MDc0MDdYYmhBPU5pZk9mYks3SHRETnFvOUViZW9NRFh3NG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGOA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        HUANG Guangbin, ZHU Qinyu, SIEW C K.Extreme learning machine:theory and applications[J].Neurocomputing, 2006, 70 (1-3) :489-501.
                                    </a>
                                </li>
                                <li id="95">


                                    <a id="bibliography_19" title="HUANG Guangbin.Learning capability and storage capacity of two-hidden-layer feedforward networks[J].IEEE Transactions on Neural Networks, 2003, 14 (2) :274-281." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning capability and storage capacity of two-hidden-layer feedforward networks">
                                        <b>[19]</b>
                                        HUANG Guangbin.Learning capability and storage capacity of two-hidden-layer feedforward networks[J].IEEE Transactions on Neural Networks, 2003, 14 (2) :274-281.
                                    </a>
                                </li>
                                <li id="97">


                                    <a id="bibliography_20" title="ZHANG Rong, DENG Zhaohong, WANG Shitong, et al.Robust single hidden layer feed-forward neural networks modeling for small datasets[J].Control and Decision, 2012, 27 (9) :1308-1312." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201209006&amp;v=MjIyOTMzenFxQnRHRnJDVVJMT2VaZVJuRnlqa1VMdktMamZTYmJHNEg5UE1wbzlGWW9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                        ZHANG Rong, DENG Zhaohong, WANG Shitong, et al.Robust single hidden layer feed-forward neural networks modeling for small datasets[J].Control and Decision, 2012, 27 (9) :1308-1312.
                                    </a>
                                </li>
                                <li id="99">


                                    <a id="bibliography_21" title="SANG Qingbing, DENG Zhaohong, WANG Shitong, et al.ε-insensitive criterion and structure risk based radius-basis-function neural-network modeling[J].Journal of Electronics and Information Technology, 2012, 34 (6) :1414-1419." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201206025&amp;v=MjA4MDBGckNVUkxPZVplUm5GeWprVUx2S0lUZlNkckc0SDlQTXFZOUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                        SANG Qingbing, DENG Zhaohong, WANG Shitong, et al.ε-insensitive criterion and structure risk based radius-basis-function neural-network modeling[J].Journal of Electronics and Information Technology, 2012, 34 (6) :1414-1419.
                                    </a>
                                </li>
                                <li id="101">


                                    <a id="bibliography_22" title="NIE F, HUANG H, CAI X, et al.Efficient and robust feature selection via joint2, 1-norms minimization[C]//Proceedings of Conference on Neural Information Processing Systems.Vancouver, Canada:Curran Associates, Inc., 2010:1813-1821." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient and robust feature selection via joint2,1-norms minimization">
                                        <b>[22]</b>
                                        NIE F, HUANG H, CAI X, et al.Efficient and robust feature selection via joint2, 1-norms minimization[C]//Proceedings of Conference on Neural Information Processing Systems.Vancouver, Canada:Curran Associates, Inc., 2010:1813-1821.
                                    </a>
                                </li>
                                <li id="103">


                                    <a id="bibliography_23" title="BEZDEK J C, EHRLICH R, FULL W.FCM:the fuzzy C-means clustering algorithm[J].Computers and Geosciences, 1984, 10 (2) :191-203." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=FCM: The fuzzy c -means clustering algorithm">
                                        <b>[23]</b>
                                        BEZDEK J C, EHRLICH R, FULL W.FCM:the fuzzy C-means clustering algorithm[J].Computers and Geosciences, 1984, 10 (2) :191-203.
                                    </a>
                                </li>
                                <li id="105">


                                    <a id="bibliography_24" title="LOCKLEY S W, EVANS E E, SCHEER F, et al.Shortwavelength sensitivity for the direct effects of light on alertness, vigilance, and the waking electroencephalogram in humans[J].Sleep, 2006, 29 (2) :161-168." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Short-wavelength sensitivity for the direct effects of light on alertness, vigilance, and the waking electroencephalogram in humans">
                                        <b>[24]</b>
                                        LOCKLEY S W, EVANS E E, SCHEER F, et al.Shortwavelength sensitivity for the direct effects of light on alertness, vigilance, and the waking electroencephalogram in humans[J].Sleep, 2006, 29 (2) :161-168.
                                    </a>
                                </li>
                                <li id="107">


                                    <a id="bibliography_25" title="DEBENER S, ULLSPERGER M, SIEGEL M, et al.Trialbytrial coupling of concurrent electroencephalogram and functional magnetic resonance imaging identifies the dynamics of performance monitoring[J].The Journal of Neuroscience, 2005, 25 (50) :11730-11737." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Trial-by-Trial Coupling of Concurrent Electroencephalogram and Functional Magnetic Resonance Imaging Identifies the Dynamics of Performance Monitoring">
                                        <b>[25]</b>
                                        DEBENER S, ULLSPERGER M, SIEGEL M, et al.Trialbytrial coupling of concurrent electroencephalogram and functional magnetic resonance imaging identifies the dynamics of performance monitoring[J].The Journal of Neuroscience, 2005, 25 (50) :11730-11737.
                                    </a>
                                </li>
                                <li id="109">


                                    <a id="bibliography_26" title="YUN Z, QUAN Z, CAIXIN S, et al.RBF neural network and ANFIS-based short-term load forecasting approach in real-time price environment[J].IEEE Transactions on Power Systems, 2008, 23 (3) :853-858." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=RBF Neural Network and ANFIS-Based Short-Term Load Forecasting Approach in Real-Time Price Environment">
                                        <b>[26]</b>
                                        YUN Z, QUAN Z, CAIXIN S, et al.RBF neural network and ANFIS-based short-term load forecasting approach in real-time price environment[J].IEEE Transactions on Power Systems, 2008, 23 (3) :853-858.
                                    </a>
                                </li>
                                <li id="111">


                                    <a id="bibliography_27" title="WU T T, LANGE K.Coordinate descent algorithms for Lasso penalized regression[J].Annals of Applied Statistics, 2008, 2 (1) :224-244." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Coordinate descent algorithms for lasso penalized regression">
                                        <b>[27]</b>
                                        WU T T, LANGE K.Coordinate descent algorithms for Lasso penalized regression[J].Annals of Applied Statistics, 2008, 2 (1) :224-244.
                                    </a>
                                </li>
                                <li id="113">


                                    <a id="bibliography_28" title="DENG Z, CHOI K S, JIANG Y, et al.Generalized hidden-mapping ridge regression, knowledge-leveraged inductive transfer learning for neural networks, fuzzy systems and kernel methods[J].IEEE Transactions on Cybernetics, 2014, 44 (12) :2585." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generalized hidden-mapping ridge pegression,knowledge-leveraged inductive transfer learning for neural networks,fuzzy systems and kernel methods">
                                        <b>[28]</b>
                                        DENG Z, CHOI K S, JIANG Y, et al.Generalized hidden-mapping ridge regression, knowledge-leveraged inductive transfer learning for neural networks, fuzzy systems and kernel methods[J].IEEE Transactions on Cybernetics, 2014, 44 (12) :2585.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(02),173-177 DOI:10.19678/j.issn.1000-3428.0048910            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于Lasso稀疏学习的径向基函数神经网络模型</span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B4%94%E6%99%A8&amp;code=38478376&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">崔晨</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%93%E8%B5%B5%E7%BA%A2&amp;code=07779386&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邓赵红</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%A3%AB%E5%90%8C&amp;code=07780257&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王士同</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B1%9F%E5%8D%97%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%97%E5%AA%92%E4%BD%93%E5%AD%A6%E9%99%A2&amp;code=0074200&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">江南大学数字媒体学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>传统径向基函数 (RBF) 神经网络模型使用完整的隐含层节点进行模型构建时, 会因缺乏隐含层节点抽取机制而使得受训模型的泛化性能下降, 导致模型更加复杂。为此, 提出一种改进的RBF神经网络模型。通过Lasso稀疏约束对隐含层节点和输出层连接权值进行稀疏表示, 去除冗余和不相关隐含层节点的同时保留重要的隐含层节点, 并使用交叉验证和网格搜索确定收缩参数以优化模型分类性能。实验结果表明, 与现有RBF神经网络模型相比, 该模型具有更低的计算复杂度和更高的分类精度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数据挖掘;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Lasso%E7%A8%80%E7%96%8F%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Lasso稀疏学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BE%84%E5%90%91%E5%9F%BA%E5%87%BD%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">径向基函数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%B6%E7%BC%A9%E5%8F%82%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">收缩参数;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    崔晨 (1991—) , 女, 硕士研究生, 主研方向为智能建模及应用;
;
                                </span>
                                <span>
                                    邓赵红, 教授、博士;
;
                                </span>
                                <span>
                                    王士同, 教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2017-10-11</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61772239, 61403247);</span>
                                <span>国家重点研发计划 (2016YFB0800803);</span>
                                <span>江苏省杰出青年基金 (BK20140001);</span>
                    </p>
            </div>
                    <h1>Radial Basis Function Neural Network Model Based on Lasso Sparse Learning</h1>
                    <h2>
                    <span>CUI Chen</span>
                    <span>DENG Zhaohong</span>
                    <span>WANG Shitong</span>
            </h2>
                    <h2>
                    <span>School of Digital Media, Jiangnan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The traditional Radial Basis Function (RBF) neural network model uses all hidden layer nodes to construct the model. In this case, the generalization performance of traditional RBF neural network model is degraded because of the lackness of the effective hidden layer nodes extraction mechanism, which will easily leads to more complicated of model.In order to solve this problem, this paper proposes an improved RBF neural network model. It realizes sparse representation of hidden layer nodes and output layer connection weights by Lasso sparse constraint to remove redundant and uncorrelated hidden layer nodes, and retain important hidden layer nodes. The shrinkage parameter are determined by Cross Validation (CV) and grid search, so as to optimize model classification performance. Experimental results show that RBF neural network model based on Lasso sparse learning can not only reduce the calculation complexity of the model, but also improve the classification accuracy compared with existing RBF neural network model.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=data%20mining&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">data mining;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Lasso%20sparse%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Lasso sparse learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Radial%20Basis%20Function%20(RBF)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Radial Basis Function (RBF) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=shrinkage%20parameter&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">shrinkage parameter;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2017-10-11</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="115" name="115" class="anchor-tag">0概述</h3>
                <div class="p1">
                    <p id="116">人工神经网络 (Artificial Neural Network, ANN) 在机器学习<citation id="211" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、模式识别<citation id="215" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、优化组合<citation id="216" type="reference"><link href="63" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、非线性回归<citation id="217" type="reference"><link href="65" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等领域应用广泛。ANN是常用于描述复杂<citation id="218" type="reference"><link href="67" rel="bibliography" /><link href="69" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>、非线性<citation id="219" type="reference"><link href="71" rel="bibliography" /><link href="73" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>过程的高级算法。径向基函数神经网络 (Radial Basis Function Neural Network, RBF-NN) <citation id="220" type="reference"><link href="75" rel="bibliography" /><link href="77" rel="bibliography" /><link href="79" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>由输入层、隐含层和输出层组成。RBF-NN首先使用聚类方法<citation id="221" type="reference"><link href="81" rel="bibliography" /><link href="83" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>构造初始化的神经网络模型, 得到初始化的网络模型后进行参数训练。如果使用RBF-NN处理高维非线性问题, 那么需要更多的隐含层节点, 这将导致RBF-NN的复杂性更高。通过变量选择技术可以提高预测精度, 降低模型的复杂性。文献<citation id="222" type="reference">[<a class="sup">14</a>]</citation>引入模糊子空间聚类对输入层的输入特征进行抽取。而这些方法都是针对输入层的输入变量进行特征选择, 并没有对神经网络隐含层节点进行选择。文献<citation id="212" type="reference">[<a class="sup">15</a>]</citation>提出一种新的线性回归方法, 对变量进行选择和压缩, 称为Lasso。该方法通过对系数的绝对值之和加上界限来最小化通常的平方误差之和。类似于子集选择, 该方法可以产生可解释的模型, 而它也表现出岭回归的稳定性。另外, 在文献<citation id="213" type="reference">[<a class="sup">16</a>]</citation>中, 使用自适应Lasso的权重惩罚不同的系数。文献<citation id="214" type="reference">[<a class="sup">17</a>]</citation>通过将Lasso与前向选择相结合, 提出一种前向Lasso方法, 可用于线性回归和广义线性模型领域。通过上述内容可知, Lasso可以有效解决线性问题, 并且可以对变量进行压缩和选择, 因此, 本文引入Lasso对RBF-NN隐含层节点和输出节点的连接权值进行参数学习。</p>
                </div>
                <div class="p1">
                    <p id="117">极限学习机 (Extreme Learning Machine, ELM) 是一种泛化的单隐层前馈神经网络<citation id="225" type="reference"><link href="93" rel="bibliography" /><link href="95" rel="bibliography" /><sup>[<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation>。本文使用文献<citation id="226" type="reference">[<a class="sup">20</a>,<a class="sup">21</a>]</citation>中的学习策略, 将RBF-NN函数与隐含层节点到输出节点的连接权值的参数学习分开处理, 进而提出基于Lasso稀疏学习的RBF神经网络模型 (RBF-NN-Lasso) 。通过Lasso稀疏约束使得隐含层节点和输出层连接权值进行稀疏表示, 去除冗余和不相关的隐含层节点, 同时保证选择重要的隐含层节点<citation id="223" type="reference"><link href="101" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>。本文算法首先使用模糊C均值聚类 (Fuzzy C-Means, FCM) <citation id="224" type="reference"><link href="103" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>对原始数据集进行处理, 然后使用Lasso训练隐含层和输出层的连接权值, 从而去除冗余的隐节点。</p>
                </div>
                <h3 id="118" name="118" class="anchor-tag">1 相关工作</h3>
                <h4 class="anchor-tag" id="119" name="119">1.1 径向基函数神经网络</h4>
                <div class="p1">
                    <p id="120">RBF-NN是具有3层网络拓扑结构的神经网络, 其基本结构如图1所示<citation id="227" type="reference"><link href="105" rel="bibliography" /><link href="107" rel="bibliography" /><sup>[<a class="sup">24</a>,<a class="sup">25</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902029_12100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 径向基函数神经网络基本结构" src="Detail/GetImg?filename=images/JSJC201902029_12100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 径向基函数神经网络基本结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902029_12100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="122">径向基函数的定义如下:</p>
                </div>
                <div class="area_img" id="123">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902029_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="190">其中, <image id="191" type="formula" href="images/JSJC201902029_19100.jpg" display="inline" placement="inline"><alt></alt></image>为输入向量, w<sub>j</sub>表示隐含层到输出层的连接权值, <image id="192" type="formula" href="images/JSJC201902029_19200.jpg" display="inline" placement="inline"><alt></alt></image>, j=1, 2, …, M为隐含层的第j个节点的中心, y (x<sub>i</sub>) 表示第i个输入神经元连接第j个隐藏层节点的输出, Φ表示径向基函数。RBF-NN中常采用高斯函数作为径向基函数<citation id="233" type="reference"><link href="109" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>, 为了便于进行理论分析, 其形式可表示为:</p>
                </div>
                <div class="area_img" id="127">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902029_12700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="128">其中, δ<sub>j</sub>为宽度值, 参数c<sub>j</sub>和δ<sub>j</sub>都能通过经典的聚类方法或其他方法得到。参数c<sub>j</sub>和δ<sub>j</sub>可通过如下公式进行估计:</p>
                </div>
                <div class="area_img" id="129">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902029_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="130">其中, c<sub>j</sub>=[c<sub>j</sub><sup>1</sup>, c<sub>j</sub><sup>2</sup>, …, c<sub>j</sub><sup>d</sup>], δ<sub>j</sub>=[δ<sub>j</sub><sup>1</sup>, δ<sub>j</sub><sup>2</sup>, …, δ<sub>j</sub><sup>d</sup>], u<sub>ij</sub>是第i个样本属于第j类的隶属度, h为人工可调的尺度参数。</p>
                </div>
                <div class="p1">
                    <p id="131">在上述径向基函数神经网络模型中, 需要学习的参数有3种, 即隐层中心点c<sub>j</sub>、径向基函数宽度值δ<sub>j</sub>、隐层到输出层的连接权值w<sub>j</sub>。</p>
                </div>
                <div class="p1">
                    <p id="132">RBF＿NN的处理过程为:数据x从输入层到输出层经过某种映射Φ, 然后得到输出值y, 将上述映射关系简化为:</p>
                </div>
                <div class="area_img" id="133">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902029_13300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="134">其中, w是式 (1) 中连接权值w<sub>j</sub>的向量, x<sub>g</sub>是输入向量x映射后的值。</p>
                </div>
                <h4 class="anchor-tag" id="135" name="135">1.2 Lasso线性问题</h4>
                <div class="p1">
                    <p id="136">线性回归问题的模型为:</p>
                </div>
                <div class="area_img" id="137">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902029_13700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="138">其中, x<sub>1</sub>, x<sub>2</sub>, …, x<sub>d</sub>是d个输入变量, y是响应变量, w={w<sub>1</sub>, w<sub>2</sub>, …, w<sub>d</sub>}是系数。</p>
                </div>
                <div class="p1">
                    <p id="193">假设<image id="194" type="formula" href="images/JSJC201902029_19400.jpg" display="inline" placement="inline"><alt></alt></image>是输入数据矩阵, 每一列都是候选输入变量, <image id="195" type="formula" href="images/JSJC201902029_19500.jpg" display="inline" placement="inline"><alt></alt></image>代表响应变量向量。给定d个输入变量x<sub>1</sub>, x<sub>2</sub>, …, x<sub>d</sub>, 则响应y被预测为:</p>
                </div>
                <div class="area_img" id="142">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902029_14200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="143">使用普通最小二乘 (Ordinary Least Squares, OLS) 法估计<image id="196" type="formula" href="images/JSJC201902029_19600.jpg" display="inline" placement="inline"><alt></alt></image>, 通过最小化残差平方和得到:</p>
                </div>
                <div class="area_img" id="144">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902029_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="145">通过引入一个额外惩罚项可得到Lasso算法, 表示为:</p>
                </div>
                <div class="area_img" id="146">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902029_14600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="147">其中, <image id="197" type="formula" href="images/JSJC201902029_19700.jpg" display="inline" placement="inline"><alt></alt></image>称为Lasso惩罚, λ是非负参数。该算法使<image id="198" type="formula" href="images/JSJC201902029_19800.jpg" display="inline" placement="inline"><alt></alt></image>值随参数λ增加而连续收缩到0。若λ足够大, 则系数<image id="199" type="formula" href="images/JSJC201902029_19900.jpg" display="inline" placement="inline"><alt></alt></image>精确地收缩为0, 意味着所有变量都被消除。当选择合适的λ时, 就会达到变量稀疏的目的。由于偏差方差的折中, 因此这些收缩常会提高预测精度<citation id="228" type="reference"><link href="87" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <h3 id="148" name="148" class="anchor-tag">2 基于Lasso稀疏学习的RBF神经网络</h3>
                <div class="p1">
                    <p id="149">在使用FCM处理原始数据生成径向基函数后, 对隐含层到输出层连接权值进行参数学习。为了降低RBF神经网络的复杂性, 在隐含层到输出层连接权值参数求解中引入Lasso稀疏学习, 从而对隐含层节点进行抽取, 降低神经网络模型的复杂性。</p>
                </div>
                <h4 class="anchor-tag" id="150" name="150">2.1 RBF神经网络目标优化和参数学习</h4>
                <div class="p1">
                    <p id="151">为降低RBF神经网络模型的复杂性, 利用Lasso线性问题求解隐含层到输出层连接权值w, 得到待优化的目标函数为:</p>
                </div>
                <div class="area_img" id="152">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902029_15200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="200">其中, λ是非负参数。当λ足够大时, 式 (10) 的任意解<image id="201" type="formula" href="images/JSJC201902029_20100.jpg" display="inline" placement="inline"><alt></alt></image>都精确收缩为0。当选择合适的λ时, 既可以提高分类精度, 又可以对隐含层节点进行选择, 达到降低模型复杂性的目的。</p>
                </div>
                <div class="p1">
                    <p id="155">式 (8) 是一个典型的Lasso线性问题, 可以使用坐标下降<citation id="229" type="reference"><link href="111" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>求解, w的第s个元素的更新规则如下:</p>
                </div>
                <div class="area_img" id="156">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902029_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="157">其中, sgn (.) 是符号函数, <image id="202" type="formula" href="images/JSJC201902029_20200.jpg" display="inline" placement="inline"><alt></alt></image>的解析解, 若<image id="203" type="formula" href="images/JSJC201902029_20300.jpg" display="inline" placement="inline"><alt></alt></image>, 则<image id="204" type="formula" href="images/JSJC201902029_20400.jpg" display="inline" placement="inline"><alt></alt></image><image id="204" type="formula" href="images/JSJC201902029_20401.jpg" display="inline" placement="inline"><alt></alt></image>, 否则等于0。对于式 (11) 采用循环迭代, 直到w收敛为止。</p>
                </div>
                <h4 class="anchor-tag" id="158" name="158">2.2 收缩参数确定</h4>
                <div class="p1">
                    <p id="159">收缩参数λ的选择是所提模型的关键组成部分, 因为参数选择会显著影响算法性能。当λ很大时, Lasso会提供一个空的模型, 所有的隐含层节点都会删除。当λ→0时, Lasso线性问题就是标准的OLS评估。为选择最佳的参数λ, 提出模型在域[λ<sub>lb</sub>, λ<sub>ub</sub>]内执行枚举搜索, 其中, λ<sub>lb</sub>为0, λ<sub>ub</sub>是一个足够大的值, 以确保<image id="205" type="formula" href="images/JSJC201902029_20500.jpg" display="inline" placement="inline"><alt></alt></image>的所有取值等于0。通过网格搜索和交叉验证 (Cross Validation, CV) 策略, 根据分类精度选择合适的值。</p>
                </div>
                <h4 class="anchor-tag" id="160" name="160">2.3 算法步骤</h4>
                <div class="p1">
                    <p id="161">算法RBF-NN-Lasso算法</p>
                </div>
                <div class="p1">
                    <p id="162">步骤1设置RBF-NN的网络层数M, 使用FCM得到类中心c<sub>j</sub>, 宽度值δ<sub>j</sub>。</p>
                </div>
                <div class="p1">
                    <p id="163">步骤2设置参数λ, 利用交叉验证得到测试集和训练数据。</p>
                </div>
                <div class="p1">
                    <p id="164">步骤3通过式 (11) 得到连接权值w。</p>
                </div>
                <div class="p1">
                    <p id="165">步骤4通过上述学习获得映射后的数据x<sub>g</sub>和连接权值w, 从而得到算法模型, 算法结束。</p>
                </div>
                <h4 class="anchor-tag" id="166" name="166">2.4 多分类策略</h4>
                <div class="p1">
                    <p id="167">虽然多分类策略通常用于处理回归任务, 但对于分类问题也同样适用。在处理分类任务时, 通常采用一种简单的策略, 利用回归模型逼近类标。一旦回归模型训练结束, 使用训练得到的模型对测试集进行预测, 并且将与模型输出最接近的类标作为测试样本的类标。但回归模型用于分类时更广泛采用的策略是把多分类问题转化为多输出回归问题, 具体过程参考文献<citation id="230" type="reference">[<a class="sup">28</a>]</citation>。</p>
                </div>
                <h3 id="168" name="168" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="169" name="169">3.1 实验设置</h4>
                <div class="p1">
                    <p id="170">为体现RBF-NN-Lasso模型的优势, 本节选取采用FCM构建隐含层节点的传统RBF-NN (FCM-RBF-NN) <citation id="232" type="reference"><link href="79" rel="bibliography" /><link href="81" rel="bibliography" /><link href="83" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>, 极限学习机 (Extreme Learning Machine, ELM) <citation id="231" type="reference"><link href="93" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>和Matlab自带的RBF-NN (Newrbe-RBF-NN) 这3个模型作为实验对比模型。实验采用多分类策略处理分类任务, 使用网格搜索技术对参数进行调优。参数设置具体如下:</p>
                </div>
                <div class="p1">
                    <p id="171">1) FCM-RBF-NN模型。隐含层数M=30, 核参数δ∈{1e-5, 1e-4, …, 1e5}, 可调节参数h∈{2<sup>-10</sup>, 2<sup>-9</sup>, …, 2<sup>10</sup>}。</p>
                </div>
                <div class="p1">
                    <p id="173">2) ELM模型。隐含层数M=30, 可调节参数h∈{0.5, 1, 2, 3, 4, 5, 10, 15}。</p>
                </div>
                <div class="p1">
                    <p id="174">3) New rbe-RBF-NN模型。步长s=0.5。</p>
                </div>
                <div class="p1">
                    <p id="175">4) RBF-NN-Lasso模型。隐含层数M=30, 可调节参数h∈{2<sup>-10</sup>, 2<sup>-9</sup>, …, 2<sup>10</sup>}, 收缩参数λ∈{0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2}。</p>
                </div>
                <div class="p1">
                    <p id="176">本文采用网格寻优和5折交叉验证策略确定收缩参数。最终以“均值±方差”的形式给出分类测试精度。</p>
                </div>
                <h4 class="anchor-tag" id="177" name="177">3.2 评价标准</h4>
                <div class="p1">
                    <p id="178">本文使用准确率 (accuracy) 进行性能度量:</p>
                </div>
                <div class="area_img" id="179">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JSJC201902029_17900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="180">其中, <image id="206" type="formula" href="images/JSJC201902029_20600.jpg" display="inline" placement="inline"><alt></alt></image>是样本点x<sub>n</sub>的类标签, <image id="207" type="formula" href="images/JSJC201902029_20700.jpg" display="inline" placement="inline"><alt></alt></image>是样本点x<sub>n</sub>的预测标签, N是样本点个数。若<image id="208" type="formula" href="images/JSJC201902029_20800.jpg" display="inline" placement="inline"><alt></alt></image>, 则<image id="209" type="formula" href="images/JSJC201902029_20900.jpg" display="inline" placement="inline"><alt></alt></image><image id="209" type="formula" href="images/JSJC201902029_20901.jpg" display="inline" placement="inline"><alt></alt></image>;否则<image id="210" type="formula" href="images/JSJC201902029_21000.jpg" display="inline" placement="inline"><alt></alt></image>。准确率越高, 分类性能越好。</p>
                </div>
                <h4 class="anchor-tag" id="181" name="181">3.3 真实数据集实验</h4>
                <div class="p1">
                    <p id="182">本文使用8组UCI真实数据集, 数据集属性信息见表1。</p>
                </div>
                <div class="area_img" id="183">
                                            <p class="img_tit">
                                                表1 UCI真实数据集
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902029_18300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201902029_18300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902029_18300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 UCI真实数据集" src="Detail/GetImg?filename=images/JSJC201902029_18300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="184">表2描述了本文模型与对比模型在8组数据集上的分类性能。由表2可知, 本文模型在所有数据集上的分类精度均高于对比模型的分类精度。</p>
                </div>
                <div class="area_img" id="185">
                                            <p class="img_tit">
                                                表2 真实数据集上各模型的分类精度比较
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902029_18500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201902029_18500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902029_18500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 真实数据集上各模型的分类精度比较" src="Detail/GetImg?filename=images/JSJC201902029_18500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="186">表3描述了在真实数据集实验中, 各模型所采用的隐节点数目。由表3可知, FCM-RBF-NN和ELM在求解隐含层到输出层的连接权值时, 对权值未进行抽取, 所以在训练网络模型时使用了全部的隐节点。而RBF-NN-Lasso在隐含层到输出层连接权值求解中引入Lasso稀疏学习, 通过得到w的稀疏解对隐含层节点进行抽取, 降低了模型的复杂性。New rbe-RBF-NN的隐节点数目等于训练样本的个数, 表3中未对Newrbe-RBF-NN进行隐节点数目比较。本文处理的是多分类问题, 而回归模型用于分类时更广泛采用的策略是把多分类问题转化为多输出回归问题 (也可视为多个单输出回归问题) 。所以, 对于n类分类问题, 可构造n个单输出回归模型。由于本文模型需要对每个单输出回归模型隐含层节点数目进行约减, 因此对于不同类别对应的回归模型的隐层节点数量可能不同。综上所述, 通过在隐含层到输出层连接权值求解中引入Lasso稀疏学习, 可以对隐含层节点进行抽取, 降低模型复杂性, 还可以进一步提高分类精度和模型鲁棒性。在表3中, 第2列～第4列括号内的数值分别表示类别1、类别2及类别3所对应的单输出RBF神经网络所包含的隐层节点数目。</p>
                </div>
                <div class="area_img" id="187">
                                            <p class="img_tit">
                                                表3 真实数据集中各模型所采用的隐节点数目
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201902029_18700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJC201902029_18700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201902029_18700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 真实数据集中各模型所采用的隐节点数目" src="Detail/GetImg?filename=images/JSJC201902029_18700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h3 id="188" name="188" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="189">本文在径向基函数神经网络模型中引入Lasso算法抽取隐含层节点, 保留了重要的隐含层节点。实验结果表明, 该算法不仅可降低模型复杂度, 而且进一步提高了模型的分类精度。本文主要针对分类任务进行研究, 然而采用RBF神经网络模型处理回归任务时, 也会因缺乏隐含层节点抽取机制而使得受训模型的泛化性能下降, 导致模型更加复杂, 因此, 如何将Lasso稀疏学习模型引入到回归模型中降低模型复杂度是下一步研究的主要内容。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="59">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinear identification and control">

                                <b>[1]</b>LIU G P.Nonlinear identification and control[J].Industrial Robot, 2002, 29 (5) :469-470.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501444953&amp;v=MjAxMTlJSUY4WGJoQT1OaWZPZmJLN0h0RE5xbzlFWU84TEJYazZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>DUFOUR P, BHARTIYA S, DHURJATI P S, et al.Neural network-based software sensor:training set design and application to a continuous pulp digester[J].Control Engineering Practice, 2005, 13 (2) :135-143.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501444925&amp;v=MDg3MDFoQT1OaWZPZmJLN0h0RE5xbzlFWU84TEJYNDhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklJRjhYYg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>FORTUNA L, GRAZIANI S, XIBILIA M G.Soft sensors for product quality monitoring in debutanizer distillation columns[J].Control Engineering Practice, 2005, 13 (4) :499-508.
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600163545&amp;v=MjI3MTNpZk9mYks3SHRETnFZOUZaZTBNQ1hnOG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGOFhiaEE9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>GONZAGA J C B, MELEIRO L A C, KIANG C, et al.ANNbased soft-sensor for real-time process monitoring and control of an industrial polymerization process[J].Computers and Chemical Engineering, 2009, 33 (1) :43-49.
                            </a>
                        </p>
                        <p id="67">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900094844&amp;v=MTAyODFvOUZaT0lMQkhnOW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGOFhiaEE9TmlmT2ZiSzdIdFRNcA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>RANI A, SINGH V, GUPTA J R P.Development of soft sensor for neural network based control of distillation column[J].ISA Transactions, 2013, 52 (3) :438-449.
                            </a>
                        </p>
                        <p id="69">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESBD9A5F88F4F7EA4DD101C021F4E3F83C&amp;v=MDI5NzU4TzMvZ3JXUXhETEhpVGJuc0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5GaHhMbTh4S289TmlmT2ZjSE1GNkRKMllkTkV1OTVDd2xJeTJKbjZ6OQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>RODGER J A.A fuzzy nearest neighbor neural network statistical model for predicting demand for natural gas and energy cost savings in public buildings[J].Expert Systems with Applications, 2014, 41 (4) :1813-1829.
                            </a>
                        </p>
                        <p id="71">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Toward Automatic Time-Series Forecasting Using Neural Networks">

                                <b>[7]</b>YAN W.Toward automatic time-series forecasting using neural networks[J].IEEE Transactions on Neural Networks and Learning Systems, 2012, 23 (7) :1028-1039.
                            </a>
                        </p>
                        <p id="73">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600165019&amp;v=MDk2OTJyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklJRjhYYmhBPU5pZk9mYks3SHRETnFZOUZaZTBLREgwd29CTVQ2VDRQUUgvaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>ZHANG J, MARTIN E B, MORRIS A J, et al.Inferential estimation of polymer quality using stacked neural networks[J].Computers and Chemical Engineering, 1997, 21 (Suppl) :1037-1039.
                            </a>
                        </p>
                        <p id="75">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=0007810127330999&amp;v=MDcwMzQvSkkxb1dWVjI3R2J1NUh0RE9xSXhHWk9JR0JSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZadTl1RkN2c1U3&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>王士同.神经模糊系统及其应用[M].北京:北京航空航天大学出版社, 1998.
                            </a>
                        </p>
                        <p id="77">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14111100002550&amp;v=MzA0ODRDWGs1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSUY4WGJoQT1OajdCYXJLOEg5RE5ybzlGWk9zTg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>DING Shifei, MA Gang, SHI Zhongzhi.A rough RBFneural network based on weighted regularized extreme learning machine[J].Neural Processing Letters, 2014, 40 (3) :245-260.
                            </a>
                        </p>
                        <p id="79">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESF63EEB0860AA5E103A645F2E70508B1F&amp;v=MjExNDJmQ3BiUTM1TkZoeExtOHhLbz1OaWZPZmNXK0hhUzUzWTlOWXV0K2ZYbE16aFlRbXpsNVRRbmcyUlUxZkxLY043dnBDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>WU Jiansheng, LONG Jin, LIU Mingzhe.Evolving RBFneural networks for rainfall prediction using hybrid particle swarm optimization and genetic algorithm[J].Neurocomputing, 2015, 148 (2) :136-142.
                            </a>
                        </p>
                        <p id="81">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hierarchical\sfuzzy clustering in conjunction with particle swarm optimization to efficiently design RBF neural networks">

                                <b>[12]</b>NIROS A D, TSEKOURAS G E, TSOLAKIS D, et al.Hierarchical fuzzy clustering in conjunction with particle swarm optimization to efficiently design RBF neural networks[J].Journal of Intelligent and Robotic Systems, 2015, 78 (1) :105-125.
                            </a>
                        </p>
                        <p id="83">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300670264&amp;v=MTg5NThqbVVMYklJRjhYYmhBPU5pZk9mYks3SHRET3JJOUZZdXdQRG5vOW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>NIROSA D, TSEKOURAS G E.A novel training algorithm for RBF neural network using a hybrid fuzzy clustering approach[J].Fuzzy Sets and Systems, 2012, 193 (9) :62-84.
                            </a>
                        </p>
                        <p id="85">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201512011&amp;v=MDE3NTZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeWprVUx2S0xqWGZmYkc0SDlUTnJZOUU=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>张江滨, 邓赵红, 王士同.模糊子空间聚类的径向基函数神经网络建模[J].计算机科学与探索, 2015, 9 (12) :1513-1522.
                            </a>
                        </p>
                        <p id="87">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Regression shrinkage and selection via the lasso">

                                <b>[15]</b>TIBSHIRANI R.Regression shrinkage and selection via the Lasso[J].Journal of the Royal Statistical Society, 1996, 58 (1) :267-288.
                            </a>
                        </p>
                        <p id="89">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800006312&amp;v=MjU0MTF3WmVadUh5am1VTGJJSUY4WGJoQT1Oam5CYXJLN0h0Zk9wNDlGWk9zSkQzMDdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbg==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>ZOU Hui.The adaptive Lasso and its oracle properties[J].Journal of the American Statistical Association, 2012, 101 (476) :1418-1429.
                            </a>
                        </p>
                        <p id="91">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=IMPROVED VARIABLE SELECTION WITH FORWARD-LASSO ADAPTIVE SHRINKAGE">

                                <b>[17]</b>RADCHENKOP, JAMES G M.Improved variable selection with forward-Lasso adaptive shrinkage[J].Annals of Applied Statistics, 2011, 5 (1) :427-448.
                            </a>
                        </p>
                        <p id="93">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501913101&amp;v=MjQ2NDdQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUlGOFhiaEE9TmlmT2ZiSzdIdEROcW85RWJlb01EWHc0b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>HUANG Guangbin, ZHU Qinyu, SIEW C K.Extreme learning machine:theory and applications[J].Neurocomputing, 2006, 70 (1-3) :489-501.
                            </a>
                        </p>
                        <p id="95">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning capability and storage capacity of two-hidden-layer feedforward networks">

                                <b>[19]</b>HUANG Guangbin.Learning capability and storage capacity of two-hidden-layer feedforward networks[J].IEEE Transactions on Neural Networks, 2003, 14 (2) :274-281.
                            </a>
                        </p>
                        <p id="97">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201209006&amp;v=MDQ3NDBMamZTYmJHNEg5UE1wbzlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnlqa1VMdks=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b>ZHANG Rong, DENG Zhaohong, WANG Shitong, et al.Robust single hidden layer feed-forward neural networks modeling for small datasets[J].Control and Decision, 2012, 27 (9) :1308-1312.
                            </a>
                        </p>
                        <p id="99">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201206025&amp;v=MDgyMjJmU2RyRzRIOVBNcVk5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5amtVTHZLSVQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b>SANG Qingbing, DENG Zhaohong, WANG Shitong, et al.ε-insensitive criterion and structure risk based radius-basis-function neural-network modeling[J].Journal of Electronics and Information Technology, 2012, 34 (6) :1414-1419.
                            </a>
                        </p>
                        <p id="101">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient and robust feature selection via joint2,1-norms minimization">

                                <b>[22]</b>NIE F, HUANG H, CAI X, et al.Efficient and robust feature selection via joint2, 1-norms minimization[C]//Proceedings of Conference on Neural Information Processing Systems.Vancouver, Canada:Curran Associates, Inc., 2010:1813-1821.
                            </a>
                        </p>
                        <p id="103">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=FCM: The fuzzy c -means clustering algorithm">

                                <b>[23]</b>BEZDEK J C, EHRLICH R, FULL W.FCM:the fuzzy C-means clustering algorithm[J].Computers and Geosciences, 1984, 10 (2) :191-203.
                            </a>
                        </p>
                        <p id="105">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Short-wavelength sensitivity for the direct effects of light on alertness, vigilance, and the waking electroencephalogram in humans">

                                <b>[24]</b>LOCKLEY S W, EVANS E E, SCHEER F, et al.Shortwavelength sensitivity for the direct effects of light on alertness, vigilance, and the waking electroencephalogram in humans[J].Sleep, 2006, 29 (2) :161-168.
                            </a>
                        </p>
                        <p id="107">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Trial-by-Trial Coupling of Concurrent Electroencephalogram and Functional Magnetic Resonance Imaging Identifies the Dynamics of Performance Monitoring">

                                <b>[25]</b>DEBENER S, ULLSPERGER M, SIEGEL M, et al.Trialbytrial coupling of concurrent electroencephalogram and functional magnetic resonance imaging identifies the dynamics of performance monitoring[J].The Journal of Neuroscience, 2005, 25 (50) :11730-11737.
                            </a>
                        </p>
                        <p id="109">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=RBF Neural Network and ANFIS-Based Short-Term Load Forecasting Approach in Real-Time Price Environment">

                                <b>[26]</b>YUN Z, QUAN Z, CAIXIN S, et al.RBF neural network and ANFIS-based short-term load forecasting approach in real-time price environment[J].IEEE Transactions on Power Systems, 2008, 23 (3) :853-858.
                            </a>
                        </p>
                        <p id="111">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Coordinate descent algorithms for lasso penalized regression">

                                <b>[27]</b>WU T T, LANGE K.Coordinate descent algorithms for Lasso penalized regression[J].Annals of Applied Statistics, 2008, 2 (1) :224-244.
                            </a>
                        </p>
                        <p id="113">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generalized hidden-mapping ridge pegression,knowledge-leveraged inductive transfer learning for neural networks,fuzzy systems and kernel methods">

                                <b>[28]</b>DENG Z, CHOI K S, JIANG Y, et al.Generalized hidden-mapping ridge regression, knowledge-leveraged inductive transfer learning for neural networks, fuzzy systems and kernel methods[J].IEEE Transactions on Cybernetics, 2014, 44 (12) :2585.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201902029" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201902029&amp;v=MjIzNTdCdEdGckNVUkxPZVplUm5GeWprVUx2S0x6N0JiYkc0SDlqTXJZOUhiWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmE1Yy9WeVdIeHJGV1pCK3VXND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
