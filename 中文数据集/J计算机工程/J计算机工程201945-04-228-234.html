<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130615284337500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201904038%26RESULT%3d1%26SIGN%3dXPwVSWXtCKLanVrEuwa1al4v77g%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201904038&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201904038&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201904038&amp;v=MDYxNzBSb0Z5L2dVcnpBTHo3QmJiRzRIOWpNcTQ5R2JJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#39" data-title="1 基于HI与ADMM的深度图像增强 ">1 基于HI与ADMM的深度图像增强</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#40" data-title="1.1 SD全局优化模型">1.1 SD全局优化模型</a></li>
                                                <li><a href="#47" data-title="1.2 基于HI与ADMM的模型求解">1.2 基于HI与ADMM的模型求解</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#73" data-title="2 实验设计 ">2 实验设计</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#74" data-title="2.1 实验数据">2.1 实验数据</a></li>
                                                <li><a href="#79" data-title="2.2 性能指标与参数设置">2.2 性能指标与参数设置</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#84" data-title="3 实验结果与分析 ">3 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#85" data-title="3.1 &lt;i&gt;Middlebury&lt;/i&gt;合成数据集">3.1 <i>Middlebury</i>合成数据集</a></li>
                                                <li><a href="#93" data-title="3.2 GRAZ数据集">3.2 GRAZ数据集</a></li>
                                                <li><a href="#97" data-title="3.3 真实Kinect数据集">3.3 真实Kinect数据集</a></li>
                                                <li><a href="#100" data-title="3.4 算法复杂性分析">3.4 算法复杂性分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="4 结束语 ">4 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#88" data-title="&lt;b&gt;表1 模拟TOF数据集的定量评估结果&lt;/b&gt;"><b>表1 模拟TOF数据集的定量评估结果</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;图1 模拟TOF数据集的实验结果&lt;/b&gt;"><b>图1 模拟TOF数据集的实验结果</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;表2 模拟Kinect数据集的定量评估结果&lt;/b&gt;"><b>表2 模拟Kinect数据集的定量评估结果</b></a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;图2 模拟Kinect数据集的实验结果&lt;/b&gt;"><b>图2 模拟Kinect数据集的实验结果</b></a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;表3 GRAZ数据集的定量评估结果&lt;/b&gt;"><b>表3 GRAZ数据集的定量评估结果</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;图3 GRAZ数据集的实验结果&lt;/b&gt;"><b>图3 GRAZ数据集的实验结果</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;图4 真实Kinect数据集的实验结果&lt;/b&gt;"><b>图4 真实Kinect数据集的实验结果</b></a></li>
                                                <li><a href="#102" data-title="&lt;b&gt;表4 SD-MM和SD-ADMM算法的综合性能比较结果&lt;/b&gt;"><b>表4 SD-MM和SD-ADMM算法的综合性能比较结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 谭志国, 欧建平, 张军, 等.一种层析深度图像去噪算法[J].光学学报, 2017, 37 (5) :94-100." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201705011&amp;v=MTM5NTJPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L2dVcnpBSWpYVGJMRzRIOWJNcW85RVpZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         谭志国, 欧建平, 张军, 等.一种层析深度图像去噪算法[J].光学学报, 2017, 37 (5) :94-100.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 刘俊毅.彩色图像引导的深度图像增强[D].杭州:浙江大学, 2014." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014162856.nh&amp;v=MjYwNzJPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L2dVcnpBVkYyNkdySytITm5KcVpFYlBJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         刘俊毅.彩色图像引导的深度图像增强[D].杭州:浙江大学, 2014.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 刘金荣, 李淳其, 欧阳建权, 等.基于联合双边滤波的深度图像增强算法[J].计算机工程, 2014, 40 (3) :249-252." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201403053&amp;v=MDE4OTE0TzN6cXFCdEdGckNVUkxPZVplUm9GeS9nVXJ6QUx6N0JiYkc0SDlYTXJJOUFaNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         刘金荣, 李淳其, 欧阳建权, 等.基于联合双边滤波的深度图像增强算法[J].计算机工程, 2014, 40 (3) :249-252.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" ZHANG Q, SHEN X, XU L, et al.Rolling guidance filter[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2014:815-830." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rolling guidance filter">
                                        <b>[4]</b>
                                         ZHANG Q, SHEN X, XU L, et al.Rolling guidance filter[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2014:815-830.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" HE K, SUN J, TANG X.Guided image filtering[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (6) :1397-1409." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Guided image filtering">
                                        <b>[5]</b>
                                         HE K, SUN J, TANG X.Guided image filtering[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (6) :1397-1409.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" DIEBEL J, THRUN S.An application of Markov random fields to range sensing[EB/OL]. (2006-07-11) [2018-02-17].https://arxiv.org/abs/1302.5589." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An application of Markov random fields to range sensing">
                                        <b>[6]</b>
                                         DIEBEL J, THRUN S.An application of Markov random fields to range sensing[EB/OL]. (2006-07-11) [2018-02-17].https://arxiv.org/abs/1302.5589.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" GONG X J, LIU J Y, ZHOU W H, et al.Guided depth enhancement via a fast marching method[J].Image and Vision Computing, 2013, 31 (10) :695-703." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600233516&amp;v=MjYyMzdMbklKMXNWYVJvPU5pZk9mYks4SHRETXFZOUZadWdNQ1gwL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         GONG X J, LIU J Y, ZHOU W H, et al.Guided depth enhancement via a fast marching method[J].Image and Vision Computing, 2013, 31 (10) :695-703.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" HAM B, CHO M, PONCE J.Robust image filtering using joint static and dynamic guidance[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:4823-4831." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust image filtering using joint static and dynamic guidance">
                                        <b>[8]</b>
                                         HAM B, CHO M, PONCE J.Robust image filtering using joint static and dynamic guidance[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:4823-4831.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" XIAO J, NG M K P, YANG Y F.On the convergence of nonconvex minimization methods for image recovery[J].IEEE Transactions on Image Processing, 2015, 24 (5) :1587-1598." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the convergence of nonconvex minimization methods for image recovery">
                                        <b>[9]</b>
                                         XIAO J, NG M K P, YANG Y F.On the convergence of nonconvex minimization methods for image recovery[J].IEEE Transactions on Image Processing, 2015, 24 (5) :1587-1598.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" KIM Y, HAM B, OH C, et al.Structure selective depth superresolution for RGB-D cameras[J].IEEE Transactions on Image Processing, 2016, 25 (11) :5227-5238." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Structure selective depth superresolution for RGB-D cameras">
                                        <b>[10]</b>
                                         KIM Y, HAM B, OH C, et al.Structure selective depth superresolution for RGB-D cameras[J].IEEE Transactions on Image Processing, 2016, 25 (11) :5227-5238.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 丁锋, 杨家本.大系统的递阶辨识[J].自动化学报, 1999, 25 (5) :647-654." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO199905010&amp;v=MTgwOTdCdEdGckNVUkxPZVplUm9GeS9nVXJ6QUtDTGZZYkt4RjlqTXFvOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         丁锋, 杨家本.大系统的递阶辨识[J].自动化学报, 1999, 25 (5) :647-654.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" PARIKH N, BOYD S.Proximal algorithms[J].Founda-tions and Trends in Optimization, 2013, 1 (3) :127-239." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Proximal algorithms">
                                        <b>[12]</b>
                                         PARIKH N, BOYD S.Proximal algorithms[J].Founda-tions and Trends in Optimization, 2013, 1 (3) :127-239.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" YANG J, YE X, LI K, et al.Color-guided depth recovery from RGB-D data using an adaptive autoregressive model[J].IEEE Transactions on Image Processing, 2014, 23 (8) :3443-3458." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Color-guided depth recovery from RGB-D data using an adaptive autoregressive model">
                                        <b>[13]</b>
                                         YANG J, YE X, LI K, et al.Color-guided depth recovery from RGB-D data using an adaptive autoregressive model[J].IEEE Transactions on Image Processing, 2014, 23 (8) :3443-3458.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" FERSTL D, REINBACHER C, RANFTL R, et al.Image guided depth upsampling using anisotropic total generalized variation[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2013:993-1000." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image guided depth upsampling using anisotropic total generalized variation">
                                        <b>[14]</b>
                                         FERSTL D, REINBACHER C, RANFTL R, et al.Image guided depth upsampling using anisotropic total generalized variation[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2013:993-1000.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" SONG S, LICHTENBERG S P, XIAO J A.RGB-D:a RGB-D scene understanding benchmark suite[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sun RGB-D:A RGB-D scene understanding benchmark suite">
                                        <b>[15]</b>
                                         SONG S, LICHTENBERG S P, XIAO J A.RGB-D:a RGB-D scene understanding benchmark suite[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:1-6.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" SHEN X, ZHOU C, XU L, et al.Mutual-structure for joint filtering[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2015:3406-3414." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mutual-Structure for Joint Filtering">
                                        <b>[16]</b>
                                         SHEN X, ZHOU C, XU L, et al.Mutual-structure for joint filtering[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2015:3406-3414.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(04),228-234 DOI:10.19678/j.issn.1000-3428.0050656            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于递阶辨识与交替方向乘子法的深度图像增强</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%B7%83&amp;code=11456297&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张跃</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E5%90%AF%E5%85%B5&amp;code=10647868&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱启兵</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E6%95%8F&amp;code=07779495&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄敏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%B5%A9&amp;code=23146935&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李浩</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B1%9F%E5%8D%97%E5%A4%A7%E5%AD%A6%E8%BD%BB%E5%B7%A5%E8%BF%87%E7%A8%8B%E5%85%88%E8%BF%9B%E6%8E%A7%E5%88%B6%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0074200&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">江南大学轻工过程先进控制教育部重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对主流传感器采集的深度图像存在深度信息区域缺失、噪声等图像质量问题, 提出一种基于SD全局优化模型的深度图像增强算法。采用非凸函数对SD全局优化模型平滑项进行建模, 使其对异常值具有较强的鲁棒性。使用基于递阶辨识 (HI) 的交替方向乘子法求解SD全局优化模型, 将目标函数分解成多个子目标函数, 并对每个子目标函数通过HI思想进行逐个求解, 降低求解复杂度。实验结果表明, 该算法在加快收敛速度的同时, 能有效去除图像噪声及抑制深度伪影。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BD%A9%E8%89%B2%E5%BC%95%E5%AF%BC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">彩色引导;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度图像增强;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%A8%E5%B1%80%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">全局优化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E5%87%B8%E5%87%BD%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非凸函数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%80%92%E9%98%B6%E8%BE%A8%E8%AF%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">递阶辨识;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%A4%E6%9B%BF%E6%96%B9%E5%90%91%E4%B9%98%E5%AD%90%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">交替方向乘子法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张跃 (1992—) , 女, 硕士研究生, 主研方向为深度图像处理, E-mail:zhangyue123q@163.com;;
                                </span>
                                <span>
                                    *朱启兵 (通信作者) , 教授;;
                                </span>
                                <span>
                                    黄敏, 教授;;
                                </span>
                                <span>
                                    李浩, 硕士研究生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-03-07</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61772240);</span>
                                <span>江苏省政策引导类计划 (产学研合作) -前瞻性联合研究项目 (BY2016022-32);</span>
                                <span>江苏省研究生科研与实践创新计划项目 (SJCX17_0508);</span>
                    </p>
            </div>
                    <h1><b>Depth Image Enhancement Based on Hierarchical Identification and Alternating Direction Multiplier Method</b></h1>
                    <h2>
                    <span>ZHANG Yue</span>
                    <span>ZHU Qibing</span>
                    <span>HUANG Min</span>
                    <span>LI Hao</span>
            </h2>
                    <h2>
                    <span>Key Laboratory of Advanced Process Control for Light Industry, Ministry of Education, Jiangnan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Because the depth image acquired by the mainstream sensor has image quality problems such as missing depth information area and noise, a depth image enhancement algorithm based on Static/Dynamic (SD) global optimization model is proposed.The SD global optimization model smoothing term is modeled by non-convex functions, which makes it more robust to outliers.The Alternating Direction Multiplier Method (ADMM) based on Hierarchical Identification (HI) is used to solve the SD global optimization model.The method decomposes the objective function into multiple sub-objective functions, and solves each sub-objective function one by one through the HI idea to reduce the complexity of the solution.Experimental results show that the proposed algorithm can effectively remove image noise and suppress depth artifacts while speeding up convergence.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=color%20guided&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">color guided;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=depth%20image%20enhancement&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">depth image enhancement;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=global%20optimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">global optimization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=non-convex%20function&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">non-convex function;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Hierarchical%20Identification%20(HI)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Hierarchical Identification (HI) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Alternating%20Direction%20Multiplier%20Method%20(ADMM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Alternating Direction Multiplier Method (ADMM) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-03-07</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="36">在深度图像中, 深度值表示场景中物体到传感器的距离, 场景中物体的三维结构信息在人体姿态估计、目标检测等领域都有广泛的应用前景。然而, 通过飞行时间 (Time of Flight, TOF) 、结构光等深度传感器获得的深度图像通常存在干扰引起的噪声或空洞、大面积信息丢失等问题。因此, 研究深度图像增强问题, 即如何对深度图像通过一系列处理得到一幅高质量的深度图像有着重要的意义<citation id="105" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="37">近年来, 深度图像的增强引起国内外研究学者的关注。如何快速获得高质量的深度图已成为深度图像研究领域的重要课题。为能获得高质量的深度图像, 国内外研究学者提出利用与深度图像校准的彩色图像作为引导以得到高质量深度图像的算法。现有基于彩色图像引导的深度图增强方法可分为2类<citation id="106" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。一类是基于局部滤波的图像增强方法, 主要通过引导图像局部窗口内的权重函数对输入图像进行滤波, 从而将引导图像的结构传送到输入图像。文献<citation id="107" type="reference">[<a class="sup">3</a>]</citation>提出联合双边滤波算法。该算法利用深度图像的空间距离权值和彩色图像的灰度权值进行深度像素估计。文献<citation id="108" type="reference">[<a class="sup">4</a>]</citation>提出滚动引导滤波器 (Rolling Guidance Filter, RGF) 算法, 通过尺度空间滤波器控制细节平滑。文献<citation id="109" type="reference">[<a class="sup">5</a>]</citation>提出基于边缘保留算子的引导图像滤波 (Guided Image Filtering, GIF) 算法。该算法通过线性回归估计出线性关系的参数, 最终得到滤波结果, 解决了双边滤波中容易出现的梯度扭曲问题。虽然局部滤波能够快速增强图像, 有效去除噪声, 但鲁棒性较低且未考虑深度图像中物体边界的准确性问题。另一类基于全局优化的深度图像增强方法, 主要是通过马尔科夫约束对图像进行整体求解, 达到深度图像增强的效果。文献<citation id="110" type="reference">[<a class="sup">6</a>]</citation>提出将图像中像素点间的颜色相似性引申为马尔科夫随机场中的平滑项, 最终通过求解马尔科夫随机场所构建的能量最优解得到深度图像增强的结果。文献<citation id="111" type="reference">[<a class="sup">7</a>]</citation>基于马尔科夫随机场摸型引入更多约束, 利用复杂先验模型克服传统马尔科夫随机场模型的不足, 模型复杂化可以使深度图像增强效果变优, 但对算法普适性有一定影响。虽然全局优化能有效提高深度图像质量, 但是该方法对异常值不稳定, 不能较好处理浓度边缘的锯齿状伪影。</p>
                </div>
                <div class="p1">
                    <p id="38">针对彩色引导深度图增强方法的全局优化问题, 文献<citation id="112" type="reference">[<a class="sup">8</a>]</citation>提出一种彩色引导的SD (Static/Dynamic) 全局优化模型。利用鲁棒非凸函数对模型平滑项进行建模, 使该模型对于异常值和其他环境因素具有较强的鲁棒性, 并且可以处理来自不同传感器的数据, 但是利用优化最小化 (Majorize Minimization, MM) 算法求解该优化模型, 存在收敛速度慢、复杂度高等问题。因此, 本文引入快速交替方向乘子法 (Alternating Direction Multiplier Method, ADMM) , 并结合递阶辨识 (Hierarchical Identification, HI) 思想求解非凸优化问题<citation id="113" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 使得该模型能够在快速收敛的同时获得高质量的深度图像。</p>
                </div>
                <h3 id="39" name="39" class="anchor-tag">1 基于HI与ADMM的深度图像增强</h3>
                <h4 class="anchor-tag" id="40" name="40">1.1 SD全局优化模型</h4>
                <div class="p1">
                    <p id="41">本文利用文献<citation id="114" type="reference">[<a class="sup">8</a>]</citation>中提出的SD非凸优化模型进行深度增强, 其中静态引导是利用彩色图像权重函数调制输入图像。在优化期间, 引导信号是固定的, 可以反映输入图像本身的内部属性;动态引导是从增强的输入图像中重复获得加权函数, 在每次迭代过程中都会被更新直到收敛。</p>
                </div>
                <div class="p1">
                    <p id="42">设 <b><i>f</i></b>是双线性插值输入的深度图像, <b><i>g</i></b>是彩色图像, <b><i>u</i></b>是输出的深度图像。深度图像增强的非凸优化目标函数模型定义如下:</p>
                </div>
                <div class="p1">
                    <p id="43" class="code-formula">
                        <mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mi>c</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">f</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>λ</mi><mi>E</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="44">其中, <i>Ω</i>是输入图像的所有坐标。式 (1) 由平滑项参数<i>λ</i>平衡数据项和平滑项, 等式右边第1项 (数据项) 有助于解决输出图像与输入图像之间的相似特征问题, 其中<i>c</i><sub><i>i</i></sub>≥0是输入图像的置信度, 如果输入图像在<i>i</i>处的像素有效, 则将<i>c</i><sub><i>i</i></sub>设置为1;否则为0。由于本文利用双线性差值的方法获得输入图像, 因此<i>c</i><sub><i>i</i></sub>全为1。等式右边第2项 (平滑项) 使得输出图像和引导图像具有相似结构。平滑项具体如下:</p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mrow></mrow></mstyle></mrow><mtext> </mtext><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></munder><mrow></mrow></mstyle></mrow><mi>Φ</mi><msub><mrow></mrow><mi>μ</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mi>Ψ</mi><msub><mrow></mrow><mi>υ</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">其中, <i>i</i>或<i>j</i>是像素索引, <i>N</i><sub><i>D</i></sub> (<i>i</i>) 是像素<i>i</i>的邻域, 它是以<i>i</i>为中心、 (2<i>r</i><sub><i>d</i></sub>+1) × (2<i>r</i><sub><i>d</i></sub>+1) 的方块, <i>Φ</i><sub><i>μ</i></sub>是彩色图像中相邻像素之间的强度差的权重函数, <i>Φ</i><sub><i>μ</i></sub> (<i>x</i>) =exp (-<i>μx</i><sup>2</sup>) , <i>Ψ</i><sub><i>υ</i></sub>是鲁棒非凸函数, <i>Ψ</i><sub><i>υ</i></sub>= (1-<i>Φ</i><sub><i>υ</i></sub> (<i>x</i>) ) /<i>υ</i>, 该函数作为一个鲁棒调节器, 使联合图像增强对异常值具有鲁棒性<citation id="115" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, <i>μ</i>、<i>υ</i>是控制平滑带宽。</p>
                </div>
                <h4 class="anchor-tag" id="47" name="47">1.2 基于HI与ADMM的模型求解</h4>
                <div class="p1">
                    <p id="48">式 (1) 是一个全局非凸优化模型, 可以利用<i>MM</i>算法求解<citation id="116" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。由于<i>MM</i>算法在求解过程中会产生一系列不均匀的病态拉普拉斯矩阵, 因此导致<i>MM</i>算法求解过程收敛困难, 且计算量大<citation id="117" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。为解决上述问题, 本文引入<i>ADMM</i>, 并结合<i>HI</i>思想求解非凸优化问题。<i>ADMM</i>是一种交替求解的方式, 通过不断分解目标函数, 进而逐个求解以降低计算复杂度, 加快算法收敛性。</p>
                </div>
                <div class="p1">
                    <p id="49">本文提出的<i>SD</i>全局优化模型结合<i>ADMM</i>求解算法 (<i>SD</i>-<i>ADMM</i>) 的具体步骤如下:1) 找到目标函数的等效目标函数, 将复杂单目标函数转化为简单多变量目标函数;2) 将简单多变量目标函数分解为多个子目标函数;3) 对多个子目标函数进行逐个优化求解并重复该步骤最终获得最优解。</p>
                </div>
                <div class="p1">
                    <p id="50">将式 (1) 等效为带约束的全局目标函数:</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>u</mi><mo>, </mo><mi>z</mi></mrow></munder></mrow><mtext> </mtext><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>ε</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><mo>, </mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">) </mo></mrow></mstyle><mrow><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mi>z</mi><mo>=</mo><mi>u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>u</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder></mrow><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mi>c</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">f</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>λ</mi><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mrow></mrow></mstyle></mrow><mtext> </mtext><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></munder><mrow></mrow></mstyle></mrow><mi>Φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mi>Ψ</mi><msub><mrow></mrow><mi>υ</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">其中, 引入约束变量<b><i>z</i></b><sub><i>i</i></sub>=<b><i>u</i></b><sub><i>i</i></sub>-<b><i>u</i></b><sub><i>j</i></sub>, 再采用增强拉格朗日 (Augmented Lagrangian, AL) 方法近似式 (3) 中的问题:</p>
                </div>
                <div class="p1">
                    <p id="53" class="code-formula">
                        <mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><msub><mrow></mrow><mrow><mtext>A</mtext><mtext>L</mtext></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><mo>, </mo><mi mathvariant="bold-italic">z</mi><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mi>c</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">f</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>λ</mi><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mrow></mrow></mstyle></mrow><mtext> </mtext><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></munder><mrow></mrow></mstyle></mrow><mo stretchy="false">[</mo><mi>Φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mi>Ψ</mi><msub><mrow></mrow><mi>υ</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mfrac><mi>β</mi><mn>2</mn></mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">γ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">其中, <i>γ</i>是增强拉格朗日乘数, <i>β</i>是惩罚参数。基于ADMM, 式 (4) 可以分解成3个关于<b><i>u</i></b><sub><i>i</i></sub>、<b><i>z</i></b><sub><i>i</i></sub>、<i>γ</i><sub><i>i</i></sub>的子目标函数 (式 (5) ) , 并通过对3个子目标函数的迭代求解实现全局目标函数的优化求解。</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mi>u</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mi>c</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">f</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo></mtd></mtr><mtr><mtd columnalign="left"><mtext> </mtext><mtext> </mtext><mspace width="0.25em" /><mi>λ</mi><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mrow></mrow></mstyle></mrow><mtext> </mtext><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></munder><mrow></mrow></mstyle></mrow><mfrac><mi>β</mi><mn>2</mn></mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi mathvariant="bold-italic">z</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo>-</mo><mi mathvariant="bold-italic">γ</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr><mtr><mtd columnalign="left"><mi mathvariant="bold-italic">z</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mi>z</mi></munder></mrow><mtext> </mtext><mi>λ</mi><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mrow></mrow></mstyle></mrow><mtext> </mtext><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></munder><mrow></mrow></mstyle></mrow><mo stretchy="false">[</mo><mi>Φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mi>Ψ</mi><msub><mrow></mrow><mi>υ</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd columnalign="left"><mtext> </mtext><mtext> </mtext><mspace width="0.25em" /><mfrac><mi>β</mi><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">γ</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mtd></mtr><mtr><mtd columnalign="left"><mi mathvariant="bold-italic">γ</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mi mathvariant="bold-italic">γ</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo>-</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mi mathvariant="bold-italic">z</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">如式 (5) 中的第1个公式所示, 在求解 (<i>t</i>+1) 时刻的<b><i>u</i></b><sub><i>i</i></sub>时, 将<b><i>z</i></b><sub><i>i</i></sub>、<i>γ</i><sub><i>i</i></sub>作为固定值 (分别表示<i>t</i>时刻的迭代值) 。然而, 利用ADMM求解<b><i>u</i></b><sub><i>i</i></sub>时, 子目标函数中包含关联未知参数向量<b><i>u</i></b><sub><i>j</i></sub>使得迭代计算难以进行。因此, 本文利用HI思想解决该问题, 即在求解 (<i>t</i>+1) 时刻的<b><i>u</i></b><sub><i>i</i></sub>时, 使用<i>t</i>时刻的求解值<b><i>u</i></b><sub><i>i</i></sub>的邻域像素代替子目标函数的未知参数<b><i>u</i></b><sub><i>j</i></sub> (<i>j</i>≠<i>i</i>) <citation id="118" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 使<b><i>u</i></b><sub><i>j</i></sub>作为固定值, 因此输出图像子目标函数 (式 (5) 中的第1个公式) 转化为:</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mi>u</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mi mathvariant="bold-italic">c</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">f</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>λ</mi><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mrow></mrow></mstyle></mrow><mtext> </mtext><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></munder><mrow></mrow></mstyle></mrow><mfrac><mi>β</mi><mn>2</mn></mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup><mo>-</mo><mi mathvariant="bold-italic">z</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo>-</mo><mi mathvariant="bold-italic">γ</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">最小化式 (6) 求得输出图像<b><i>u</i></b>为:</p>
                </div>
                <div class="p1">
                    <p id="60"> (2<b><i>C</i></b>+<i>λβΛ</i>) <b><i>u</i></b><sup><i>t</i>+1</sup>=2<b><i>Cf</i></b>+<i>λβ</i> (<b><i>u</i></b><sup>0</sup>+<b><i>z</i></b><sup><i>t</i></sup>+<i>γ</i><sup><i>t</i></sup>)      (7) </p>
                </div>
                <div class="p1">
                    <p id="61">其中, <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mn>0</mn></msup><mo>=</mo><mrow><mo stretchy="false">[</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></munder><mi mathvariant="bold-italic">u</mi></mstyle><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup><mo stretchy="false">]</mo></mrow><msub><mrow></mrow><mrow><mi>Μ</mi><mo>×</mo><mn>1</mn></mrow></msub></mrow></math></mathml>是t时刻输出图像<b><i>u</i></b>的邻域像素矩阵, <b><i>f</i></b>=[<b><i>f</i></b><sub><i>i</i></sub>]<sub><i>M</i>×1</sub>、<b><i>g</i></b>=[<b><i>g</i></b><sub><i>i</i></sub>]<sub><i>M</i>×1</sub>、<b><i>u</i></b>=[<b><i>u</i></b><sub><i>i</i></sub>]<sub><i>M</i>×1</sub>分别是输入图像、彩色图像、输出图像的向量, <b><i>z</i></b>=[<b><i>z</i></b><sub><i>i</i></sub>]<sub><i>M</i>×1</sub>、<i>γ</i>=[<i>γ</i><sub><i>i</i></sub>]<sub><i>M</i>×1</sub>分别是约束变量、增强拉格朗日乘数, <i>M</i>是输出图像的像素总数, <b><i>C</i></b>=diag ([<i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>, …, <i>c</i><sub><i>M</i></sub>]) , <i>Λ</i>是单位矩阵。</p>
                </div>
                <div class="p1">
                    <p id="63">同理, 如式 (5) 中的第2个公式所示, 在求解 (<i>t</i>+1) 时刻的<b><i>z</i></b><sub><i>i</i></sub>时, 将<b><i>u</i></b><sub><i>i</i></sub>、<i>γ</i><sub><i>i</i></sub>作为固定值 (分别表示为<i>t</i>+1、<i>t</i>时刻的迭代值) 。由于变量<b><i>u</i></b><sub><i>i</i></sub>不是待求值, 因此将<b><i>u</i></b><sub><i>j</i></sub>也作为固定值 (<i>t</i>+1时刻的<b><i>u</i></b><sub><i>i</i></sub>的邻域像素值) 。然后利用ADMM求解约束变量子目标函数, 令<mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ω</mi></mrow></munder><mrow></mrow></mstyle></mrow><mtext> </mtext><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></munder><mrow></mrow></mstyle></mrow><mi>Φ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mi>Ψ</mi><msub><mrow></mrow><mi>υ</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>, 在<i>τ</i><sub><i>i</i></sub>=<b><i>u</i></b><mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>-<b><i>u</i></b><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>-<i>γ</i><mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup></mrow></math></mathml>处对h (<b><i>z</i></b><sub><i>i</i></sub>) 进行泰勒展开<i>h</i> (<b><i>z</i></b><sub><i>i</i></sub>) =<i>h</i> (<i>τ</i><sub><i>i</i></sub>) +<i>h</i>′ (<i>τ</i><sub><i>i</i></sub>) (<b><i>z</i></b><sub><i>i</i></sub>-<i>τ</i><sub><i>i</i></sub>) , 并定义<i>τ</i><sub><i>i</i></sub>处的近端算子<citation id="119" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>:<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mtext> </mtext><mi>x</mi><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">τ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mrow><mo>[</mo><mrow><mi>λ</mi><msup><mi>h</mi><mo>′</mo></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">τ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mfrac><mrow><mi>λ</mi><mi>β</mi></mrow><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">τ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>]</mo></mrow></mrow></math></mathml>, 由此求得约束变量<b><i>z</i></b>为:</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">z</mi><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Λ</mi><mo>-</mo><mfrac><mn>2</mn><mi>β</mi></mfrac><mi mathvariant="bold-italic">W</mi></mrow><mo>) </mo></mrow><mi mathvariant="bold-italic">τ</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">其中, <i>τ</i>=[<i>τ</i><sub><i>i</i></sub>]<sub><i>M</i>×1</sub>是近端算子向量, <b><i>W</i></b>=<b><i>W</i></b><sub><i>g</i></sub>。<b><i>W</i></b><sub><i>τ</i></sub>, <b><i>W</i></b><sub><i>g</i></sub>=[<i>w</i><sup><i>g</i></sup><sub><i>i</i>, <i>j</i></sub>]<sub><i>M</i>×<i>M</i></sub>是彩色图像权重矩阵, <b><i>W</i></b><sub><i>τ</i></sub>=[<i>w</i><sup><i>g</i></sup><sub><i>τ</i></sub>]<sub><i>M</i>×<i>M</i></sub>是图像在<i>τ</i>处的亲和矩阵, 。是矩阵的点乘运算。<i>w</i><mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow><mi>g</mi></msubsup></mrow></math></mathml>=exp (-<i>μ</i> (<b><i>g</i></b><sub><i>i</i></sub>-<b><i>g</i></b><sub><i>j</i></sub>) <sup>2</sup>) , <i>w</i><sub><i>τ</i></sub>=exp (-<i>υτ</i><sup>2</sup>) 。</p>
                </div>
                <div class="p1">
                    <p id="72">最后逐个对式 (7) 、式 (8) 、式 (5) 中的第3个公式进行迭代优化, 直到达到迭代次数<i>t</i>或‖<b><i>u</i></b><sup><i>t</i>+1</sup>-<b><i>u</i></b><sup><i>t</i></sup>‖≤<i>θ</i>时停止迭代, 输出高质量深度图像<b><i>u</i></b>, 其中<i>θ</i>是固定常数。</p>
                </div>
                <h3 id="73" name="73" class="anchor-tag">2 实验设计</h3>
                <h4 class="anchor-tag" id="74" name="74">2.1 实验数据</h4>
                <div class="p1">
                    <p id="75">目前, 深度图像可以通过2种途径获得:一种是基于<i>TOF</i>传感器采集的深度图像, 此类图像存在大量随机噪声;另一种是基于<i>Kinect</i>传感器采集的深度图像, 此类图像存在深度缺失等图像质量问题<citation id="120" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。为证明本文算法可以处理来自不同传感器的数据, 采用以下数据集进行算法验证:</p>
                </div>
                <div class="p1">
                    <p id="76">1) <i>Middlebury</i>合成数据集<citation id="121" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。<i>Middlebury</i>数据集提供6种彩色图像 (<i>Art</i>、<i>Books</i>、<i>Dolls</i>、<i>Laundry</i>、<i>Moebius</i>、<i>Reindeer</i>) 和地面真实深度图像 (1 376像素×1 088像素) 。为模拟2种主流传感器的成像特点: (1) 对<i>Middlebury</i>数据集提供的6种地面真实深度图像进行下采样 (×8) , 并添加方差为25的高斯噪声获得含噪低分辨率图像, 即模拟<i>TOF</i>数据集。 (2) 将<i>Middlebury</i>数据集提供的6种地面真实深度图像沿深度不连续性产生结构缺失, 在平坦区域产生随机缺失, 即获得模拟的<i>Kinect</i>深度图 (690像素×555像素) 。</p>
                </div>
                <div class="p1">
                    <p id="77">2) <i>GRAZ</i>数据集。<i>GRAZ</i>数据集<citation id="122" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>由<i>TOF</i>传感器获得3种彩色图像 (<i>Books</i>、<i>Devil</i>、<i>Shark</i>, 810像素×610像素) 及其对应的低分辨率深度图像 (160像素×120像素) 。该数据集还提供了来自高精度结构光扫描仪采集的地面真实深度图像并能进行定量评估。</p>
                </div>
                <div class="p1">
                    <p id="78">3) 真实<i>Kinect</i>数据集。本文采用由<i>NYU RGB</i>-<i>D</i>数据集<citation id="123" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提供的<i>Kinect v</i>1传感器采集的彩色图像 (<i>Bookcase</i>、<i>Table</i>、<i>Character</i>) 和深度图像 (640像素×480像素) 以及由<i>SUN RGBD</i>数据集<citation id="124" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提供的<i>Kinect v</i>2传感器采集的彩色图像 (<i>Desk</i>、<i>Office</i>、<i>Sofa</i>) 和深度图像 (730像素×530像素) 。</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79">2.2 性能指标与参数设置</h4>
                <div class="p1">
                    <p id="80"><i>SD</i>-<i>ADMM</i>算法包含5个参数, 其中, 平滑带宽μ=10、υ=10, 惩罚参数β=2, 邻域r<sub>d</sub>=10, 根据图像含噪声量进行适当调整平滑项参数λ。本文研究并比较多种算法, <i>SD</i>-<i>MM</i>算法的参数设置为平滑带宽μ=10、υ=10, 邻域r<sub>d</sub>=8;滚动滤波算法的参数设置参照文献<citation id="125" type="reference">[<a class="sup">4</a>]</citation>;引导图像滤波算法的参数设置参照文献<citation id="126" type="reference">[<a class="sup">5</a>]</citation>;<i>MRF</i>算法参数设置参照文献<citation id="127" type="reference">[<a class="sup">6</a>]</citation>;各向异性总广义变化 (<i>Anisotropic Total Generalized Variation</i>, <i>ATGV</i>) 滤波算法的参数设置参照文献<citation id="128" type="reference">[<a class="sup">14</a>]</citation>;<i>Shen</i>算法参数设置参照文献<citation id="129" type="reference">[<a class="sup">16</a>]</citation>。</p>
                </div>
                <div class="p1">
                    <p id="81">本文采用不良像素匹配率 (<i>Bad Matching Percentage</i>, <i>BMP</i>) <citation id="130" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>和峰值信噪比 (<i>Peak Signal to Noise Ratio</i>, <i>PSNR</i>) 进行定量评估。<i>BMP</i>和<i>PSNR</i>分别定义为:</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>B</mi><mi>Μ</mi><mi>Ρ</mi><mo>=</mo><mfrac><mn>1</mn><mi>Μ</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mo stretchy="false">[</mo></mstyle><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><mo>&gt;</mo><mi>δ</mi><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><mi>S</mi><mi>Ν</mi><mi>R</mi><mo>=</mo><mn>1</mn><mn>0</mn><mtext> </mtext><mrow><mi>lg</mi></mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mn>2</mn><mn>5</mn><mn>5</mn><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mo stretchy="false"> (</mo><mfrac><mn>1</mn><mi>Μ</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>i</mi><mi>Μ</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo></mrow></mfrac></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">其中, <b><i>u</i></b><sub><i>i</i></sub>和<b><i>o</i></b><sub><i>i</i></sub>分别表示滤波后的深度图像和地面真实深度图像在<i>i</i>处的像素值, <i>δ</i>是深度误差的阈值, 合成数据集中阈值<i>δ</i>=2, 真实数据集中阈值<i>δ</i>=10, [·]表示若条件为真, 则为1;否则为0。</p>
                </div>
                <h3 id="84" name="84" class="anchor-tag">3 实验结果与分析</h3>
                <h4 class="anchor-tag" id="85" name="85">3.1 <i>Middlebury</i>合成数据集</h4>
                <div class="p1">
                    <p id="86"><i>Middlebury</i>合成数据集主要包括:</p>
                </div>
                <div class="p1">
                    <p id="87">1) 模拟<i>TOF</i>数据集。本文利用模拟<i>TOF</i>数据集测试彩色引导深度增强算法。表1给出以<i>BMP</i>和<i>PSNR</i>表示的增强深度图的定量评估结果, 表明<i>MM</i>和<i>ADMM</i>求解该优化模型具有较低的<i>BMP</i>和较高的<i>PSNR</i>, 证明了彩色引导深度增强非凸优化模型的可行性。如图1所示, 虽然<i>MM</i>具有较好的<i>PSNR</i>定量评估结果, 但<i>MM</i>在迭代过程中会出现边缘模糊而无法精确定位的问题。相反地, <i>ADMM</i>能有效去除图像噪声并保持深度连续性。</p>
                </div>
                <div class="area_img" id="88">
                    <p class="img_tit"><b>表1 模拟TOF数据集的定量评估结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="88" border="1"><tr><td rowspan="2"><br />算法</td><td colspan="6"><br />不良像素匹配率 (<i>δ</i>=2) /%</td><td colspan="6"><br />峰值信噪比/dB</td></tr><tr><td><br />Art</td><td>Books</td><td>Dolls</td><td>Laund</td><td>Moebi</td><td>Reind</td><td><br />Art</td><td>Books</td><td>Dolls</td><td>Laund</td><td>Moebi</td><td>Reind</td></tr><tr><td>Bilinear</td><td>52.118</td><td>47.145</td><td>17.405</td><td>49.197</td><td>47.709</td><td>47.747</td><td>31.383</td><td>35.811</td><td>36.466</td><td>34.237</td><td>36.102</td><td>33.492</td></tr><tr><td><br />GIF</td><td>47.955</td><td>42.145</td><td>42.568</td><td>44.406</td><td>42.700</td><td>42.872</td><td>31.549</td><td>36.541</td><td>37.147</td><td>34.709</td><td>36.880</td><td>33.898</td></tr><tr><td><br />RGF</td><td>45.209</td><td>38.537</td><td>39.269</td><td>41.531</td><td>39.325</td><td>37.693</td><td>31.441</td><td>36.835</td><td>37.482</td><td>34.640</td><td>37.192</td><td>34.011</td></tr><tr><td><br />ATGV</td><td>45.930</td><td>40.206</td><td>40.821</td><td>42.080</td><td>40.862</td><td>41.248</td><td>31.942</td><td>36.891</td><td>37.466</td><td>35.110</td><td>37.233</td><td>34.009</td></tr><tr><td><br />MRF</td><td>45.693</td><td>38.953</td><td>39.670</td><td>41.954</td><td>39.765</td><td>40.005</td><td>31.196</td><td>36.711</td><td>37.416</td><td>34.640</td><td>37.114</td><td>33.695</td></tr><tr><td><br />Shen</td><td>48.406</td><td>42.896</td><td>43.253</td><td>44.909</td><td>43.523</td><td>43.550</td><td>31.746</td><td>36.502</td><td>37.098</td><td>34.804</td><td>36.811</td><td>34.057</td></tr><tr><td><br />SD-MM</td><td>37.217</td><td>22.577</td><td>24.320</td><td>28.884</td><td>24.749</td><td>24.858</td><td>30.206</td><td>37.498</td><td>38.660</td><td>34.372</td><td>37.820</td><td>33.479</td></tr><tr><td><br />SD-ADMM</td><td>36.633</td><td>21.385</td><td>26.116</td><td>27.130</td><td>24.406</td><td>23.254</td><td>30.704</td><td>37.589</td><td>38.258</td><td>34.618</td><td>37.821</td><td>34.061</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904038_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 模拟TOF数据集的实验结果" src="Detail/GetImg?filename=images/JSJC201904038_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 模拟TOF数据集的实验结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904038_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="90">2) 模拟Kinect数据集。本文利用模拟Kinect数据集测试了深度图像增强算法。表2显示了本文深度图像增强算法与现有算法的定量评估结果, 由此可知本文深度图像增强算法获得了最低的不匹配像素率, 验证了其对Kinect深度图像增强的有效性。图2显示引导图像滤波算法GIF算法<citation id="131" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>和Shen联合结构滤波算法<citation id="132" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>只适用于小区域深度不连续, 而对于大面积的深度丢失效果不佳。虽然ATGV<citation id="133" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、MRF<citation id="134" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>算法能正确恢复缺失区域, 但过增强造成了深度模糊。由表2可知, SD-MM具有更好的PSNR定量评估结果, 同样过增强造成了深度边缘的模糊和缺失, 相反地, 本文提出的SD-ADMM算法能较好处理深度缺失和深度连续性问题。</p>
                </div>
                <div class="area_img" id="91">
                    <p class="img_tit"><b>表2 模拟Kinect数据集的定量评估结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="91" border="1"><tr><td rowspan="2"><br />算法</td><td colspan="6"><br />不良像素匹配率 (<i>δ</i>=2) /%</td><td colspan="6"><br />峰值信噪比/dB</td></tr><tr><td><br />Art</td><td>Books</td><td>Dolls</td><td>Laund</td><td>Moebi</td><td>Reind</td><td><br />Art</td><td>Books</td><td>Dolls</td><td>Laund</td><td>Moebi</td><td>Reind</td></tr><tr><td>GIF</td><td>8.282</td><td>9.901</td><td>12.450</td><td>12.427</td><td>12.752</td><td>11.657</td><td>21.182</td><td>20.757</td><td>20.930</td><td>21.554</td><td>20.833</td><td>20.055</td></tr><tr><td><br />RGF</td><td>7.415</td><td>7.590</td><td>9.628</td><td>10.073</td><td>9.249</td><td>7.818</td><td>19.088</td><td>19.242</td><td>19.200</td><td>19.950</td><td>19.215</td><td>18.588</td></tr><tr><td><br />ATGV</td><td>8.283</td><td>7.710</td><td>8.480</td><td>9.390</td><td>9.383</td><td>8.635</td><td>28.265</td><td>25.662</td><td>26.434</td><td>25.128</td><td>26.556</td><td>25.608</td></tr><tr><td><br />MRF</td><td>19.080</td><td>7.994</td><td>9.833</td><td>13.455</td><td>10.757</td><td>11.150</td><td>28.920</td><td>26.677</td><td>28.174</td><td>28.304</td><td>27.190</td><td>26.887</td></tr><tr><td><br />Shen</td><td>6.535</td><td>6.884</td><td>9.161</td><td>8.259</td><td>8.886</td><td>7.870</td><td>19.465</td><td>19.385</td><td>19.407</td><td>20.064</td><td>19.449</td><td>18.723</td></tr><tr><td><br />SD-MM</td><td>6.070</td><td>6.413</td><td>6.274</td><td>6.828</td><td>7.755</td><td>7.310</td><td>29.027</td><td>26.735</td><td>28.248</td><td>28.732</td><td>27.282</td><td>27.078</td></tr><tr><td><br />SD-ADMM</td><td>4.599</td><td>4.501</td><td>6.259</td><td>6.482</td><td>6.510</td><td>6.184</td><td>29.266</td><td>26.627</td><td>28.122</td><td>29.122</td><td>27.136</td><td>26.631</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904038_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 模拟Kinect数据集的实验结果" src="Detail/GetImg?filename=images/JSJC201904038_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 模拟Kinect数据集的实验结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904038_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="93" name="93">3.2 GRAZ数据集</h4>
                <div class="p1">
                    <p id="94">本文在GRAZ数据集上测试了深度图增强算法。表3显示了本文算法与其他算法在不良像素匹配率和峰值信噪比方面的定量比较结果。由此可知, 多数算法都能较好地增强深度图像, 但由图3可以看出多数算法不能有效去除均匀区域的噪声。ATGV<citation id="135" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>算法在相关彩色图像纹理丰富的区域 (例如杯子的底部、书的边缘) 引入了深度伪影。相比之下, SD-ADMM算法可抑制传感器噪声, 并保持深度不连续性, 避免了MM求解算法造成的深度边缘模糊问题。</p>
                </div>
                <div class="area_img" id="95">
                    <p class="img_tit"><b>表3 GRAZ数据集的定量评估结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="95" border="1"><tr><td rowspan="2"><br />算法</td><td colspan="3"><br />不良像素匹配率 (<i>δ</i>=10) /%</td><td colspan="4"><br />峰值信噪比/dB</td></tr><tr><td><br />Books</td><td>Devil</td><td>Shark</td><td><br />Books</td><td colspan="2">Devil</td><td>Shark</td></tr><tr><td>Bilinear</td><td>28.285</td><td>26.562</td><td>30.503</td><td>12.465</td><td>13.053</td><td colspan="2">11.966</td></tr><tr><td><br />GIF</td><td>27.806</td><td>25.317</td><td>29.545</td><td>12.484</td><td>13.066</td><td colspan="2">11.986</td></tr><tr><td><br />RGF</td><td>28.006</td><td>24.071</td><td>30.321</td><td>12.496</td><td>13.072</td><td colspan="2">11.970</td></tr><tr><td><br />ATGV</td><td>27.627</td><td>24.649</td><td>28.673</td><td>12.478</td><td>13.066</td><td colspan="2">11.982</td></tr><tr><td><br />MRF</td><td>28.035</td><td>25.890</td><td>30.042</td><td>12.476</td><td>13.060</td><td colspan="2">11.977</td></tr><tr><td><br />Shen</td><td>27.525</td><td>25.269</td><td>28.972</td><td>12.479</td><td>13.065</td><td colspan="2">11.976</td></tr><tr><td><br />SD-MM</td><td>27.845</td><td>25.189</td><td>29.611</td><td>12.489</td><td>13.067</td><td colspan="2">11.990</td></tr><tr><td><br />SD-ADMM</td><td>27.477</td><td>24.716</td><td>28.668</td><td>12.491</td><td>13.078</td><td colspan="2">12.015</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904038_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 GRAZ数据集的实验结果" src="Detail/GetImg?filename=images/JSJC201904038_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 GRAZ数据集的实验结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904038_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="97" name="97">3.3 真实Kinect数据集</h4>
                <div class="p1">
                    <p id="98">本文采用Kinect v1和Kinect v2数据集捕获的2种深度图进行定性分析, 如图4所示。由于原始深度图像包含许多噪声, 并且不完全对准相应的彩色图像, 因此多数算法不适合处理配准滤波。SD-MM算法能有效去除图像噪声但过度的平滑导致图像边缘模糊, 不利于边界的提取。ATGV<citation id="136" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>算法不能恢复深度图像中存在边缘大面积深度缺失的情况。相比之下, 即使存在异常值和丢失数据的现象, SD-ADMM算法仍能有效去除噪声且保持边缘平滑。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201904038_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 真实Kinect数据集的实验结果" src="Detail/GetImg?filename=images/JSJC201904038_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 真实Kinect数据集的实验结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201904038_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="100" name="100">3.4 算法复杂性分析</h4>
                <div class="p1">
                    <p id="101">实验发现SD-MM通常需要10次迭代进行深度图像增强, SD-ADMM需要30次迭代进行深度图像增强。可见, SD-MM比SD-ADMM的迭代次数更少, 但是SD-ADMM迭代的总体计算时间小于SD-MM迭代的总体计算时间。表4中给出了SD-MM、SD-ADMM这2种深度增强算法的平均计算时间。</p>
                </div>
                <div class="area_img" id="102">
                    <p class="img_tit"><b>表4 SD-MM和SD-ADMM算法的综合性能比较结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="102" border="1"><tr><td>算法</td><td>数据集</td><td>迭代次数</td><td>时间/s</td><td>不良像素匹配率/%</td><td>峰值信噪比/dB</td></tr><tr><td rowspan="3">SD-MM</td><td><br />模拟TOF数据集 (1 088像素×1 376像素) </td><td rowspan="3">10</td><td><br />194.596</td><td>27.101</td><td>35.343</td></tr><tr><td><br />模拟Kinect数据集 (690像素×555像素) </td><td><br />56.252</td><td>6.775</td><td>27.850</td></tr><tr><td><br />GRAZ数据集 (810像素×610像素) </td><td><br />75.281</td><td>27.548</td><td>12.515</td></tr><tr><td rowspan="3">SD-ADMM</td><td><br />模拟TOF数据集 (1 088像素×1 376像素) </td><td rowspan="3">30</td><td><br /> 38.998</td><td>26.487</td><td>35.508</td></tr><tr><td><br />模拟Kinect数据集 (690像素×555像素) </td><td><br />16.138</td><td>5.755</td><td>27.817</td></tr><tr><td><br />GRAZ数据集 (810像素×610像素) </td><td><br />20.272</td><td>26.954</td><td>12.528</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="103" name="103" class="anchor-tag">4 结束语</h3>
                <div class="p1">
                    <p id="104">由于深度传感器受硬件条件限制和周围环境的影响, 其获得的深度图像存在较多图像质量问题。本文提出彩色引导深度增强全局优化模型。该模型可以处理彩色和深度图像之间的结构差异, 解决深度渗色和纹理复制伪像问题。通过结合递阶辨识思想并引入快速交替方向乘子法求解该优化模型, 加快求解速度。实验结果表明, SD-ADMM算法能够在快速收敛的同时有效去除噪声及保持良好的边缘平滑特性。下一步将对SD-ADMM算法中的参数进行精确设置, 以提升其在真实TOF深度数据集中的视觉效果。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201705011&amp;v=MDQ5OTQ5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5L2dVcnpBSWpYVGJMRzRIOWJNcW8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 谭志国, 欧建平, 张军, 等.一种层析深度图像去噪算法[J].光学学报, 2017, 37 (5) :94-100.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014162856.nh&amp;v=Mjk0Mjg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeS9nVXJ6QVZGMjZHcksrSE5uSnFaRWJQSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 刘俊毅.彩色图像引导的深度图像增强[D].杭州:浙江大学, 2014.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201403053&amp;v=MDYyMzVnVXJ6QUx6N0JiYkc0SDlYTXJJOUFaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeS8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 刘金荣, 李淳其, 欧阳建权, 等.基于联合双边滤波的深度图像增强算法[J].计算机工程, 2014, 40 (3) :249-252.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rolling guidance filter">

                                <b>[4]</b> ZHANG Q, SHEN X, XU L, et al.Rolling guidance filter[C]//Proceedings of European Conference on Computer Vision.Berlin, Germany:Springer, 2014:815-830.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Guided image filtering">

                                <b>[5]</b> HE K, SUN J, TANG X.Guided image filtering[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (6) :1397-1409.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An application of Markov random fields to range sensing">

                                <b>[6]</b> DIEBEL J, THRUN S.An application of Markov random fields to range sensing[EB/OL]. (2006-07-11) [2018-02-17].https://arxiv.org/abs/1302.5589.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600233516&amp;v=MjM3MTJaZVp1SHlqbVVMbklKMXNWYVJvPU5pZk9mYks4SHRETXFZOUZadWdNQ1gwL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1udw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> GONG X J, LIU J Y, ZHOU W H, et al.Guided depth enhancement via a fast marching method[J].Image and Vision Computing, 2013, 31 (10) :695-703.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust image filtering using joint static and dynamic guidance">

                                <b>[8]</b> HAM B, CHO M, PONCE J.Robust image filtering using joint static and dynamic guidance[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:4823-4831.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the convergence of nonconvex minimization methods for image recovery">

                                <b>[9]</b> XIAO J, NG M K P, YANG Y F.On the convergence of nonconvex minimization methods for image recovery[J].IEEE Transactions on Image Processing, 2015, 24 (5) :1587-1598.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Structure selective depth superresolution for RGB-D cameras">

                                <b>[10]</b> KIM Y, HAM B, OH C, et al.Structure selective depth superresolution for RGB-D cameras[J].IEEE Transactions on Image Processing, 2016, 25 (11) :5227-5238.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO199905010&amp;v=MTMxMzVnVXJ6QUtDTGZZYkt4RjlqTXFvOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeS8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 丁锋, 杨家本.大系统的递阶辨识[J].自动化学报, 1999, 25 (5) :647-654.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Proximal algorithms">

                                <b>[12]</b> PARIKH N, BOYD S.Proximal algorithms[J].Founda-tions and Trends in Optimization, 2013, 1 (3) :127-239.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Color-guided depth recovery from RGB-D data using an adaptive autoregressive model">

                                <b>[13]</b> YANG J, YE X, LI K, et al.Color-guided depth recovery from RGB-D data using an adaptive autoregressive model[J].IEEE Transactions on Image Processing, 2014, 23 (8) :3443-3458.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image guided depth upsampling using anisotropic total generalized variation">

                                <b>[14]</b> FERSTL D, REINBACHER C, RANFTL R, et al.Image guided depth upsampling using anisotropic total generalized variation[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2013:993-1000.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sun RGB-D:A RGB-D scene understanding benchmark suite">

                                <b>[15]</b> SONG S, LICHTENBERG S P, XIAO J A.RGB-D:a RGB-D scene understanding benchmark suite[C]//Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2015:1-6.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mutual-Structure for Joint Filtering">

                                <b>[16]</b> SHEN X, ZHOU C, XU L, et al.Mutual-structure for joint filtering[C]//Proceedings of IEEE International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2015:3406-3414.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201904038" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201904038&amp;v=MDYxNzBSb0Z5L2dVcnpBTHo3QmJiRzRIOWpNcTQ5R2JJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdWa2FjcW9vRlJTQ2JLUmN2amRwVFpsWThsTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
