<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637130634631993750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJC201903038%26RESULT%3d1%26SIGN%3dU8mPKubW6VWIgR6%252fPyl4VhLhQv4%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903038&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJC201903038&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903038&amp;v=Mjc0NzdydkJMejdCYmJHNEg5ak1ySTlHYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk3bFU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#49" data-title="0 概述 ">0 概述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#52" data-title="1 智能手机硬件结构 ">1 智能手机硬件结构</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#55" data-title="2 单应性矩阵变换 ">2 单应性矩阵变换</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="2.1 SIFT特征点检测与匹配">2.1 SIFT特征点检测与匹配</a></li>
                                                <li><a href="#62" data-title="2.2 基于RANSAC算法的单应性矩阵求解">2.2 基于RANSAC算法的单应性矩阵求解</a></li>
                                                <li><a href="#68" data-title="2.3 图像配准">2.3 图像配准</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#71" data-title="3 未标定光度立体视觉 ">3 未标定光度立体视觉</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#80" data-title="3.1 GBR模糊性问题">3.1 GBR模糊性问题</a></li>
                                                <li><a href="#95" data-title="3.2 总变差正则化估计">3.2 总变差正则化估计</a></li>
                                                <li><a href="#128" data-title="3.3 熵值最小化估计">3.3 熵值最小化估计</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#136" data-title="4 实验结果与分析 ">4 实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#137" data-title="4.1 数据集">4.1 数据集</a></li>
                                                <li><a href="#142" data-title="4.2 真实环境实验结果">4.2 真实环境实验结果</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#149" data-title="5 结束语 ">5 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="&lt;b&gt;图1 智能手机硬件结构&lt;/b&gt;"><b>图1 智能手机硬件结构</b></a></li>
                                                <li><a href="#61" data-title="&lt;b&gt;图2 SIFT特征匹配&lt;/b&gt;"><b>图2 SIFT特征匹配</b></a></li>
                                                <li><a href="#70" data-title="&lt;b&gt;图3 图像配准示意图&lt;/b&gt;"><b>图3 图像配准示意图</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;图4&lt;/b&gt;&lt;i&gt;μ&lt;/i&gt;、&lt;i&gt;ν&lt;/i&gt;&lt;b&gt;对深度场总变差函数值的影响&lt;/b&gt;"><b>图4</b><i>μ</i>、<i>ν</i><b>对深度场总变差函数值的影响</b></a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;图5 GBR变换对重建石膏图像反射率分布直方图的影响&lt;/b&gt;"><b>图5 GBR变换对重建石膏图像反射率分布直方图的影响</b></a></li>
                                                <li><a href="#139" data-title="&lt;b&gt;图6 各方法图像三维重建结果&lt;/b&gt;"><b>图6 各方法图像三维重建结果</b></a></li>
                                                <li><a href="#141" data-title="&lt;b&gt;表1 各重建方法性能比较结果&lt;/b&gt;"><b>表1 各重建方法性能比较结果</b></a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;图7 智能手机图像采集示意图&lt;/b&gt;"><b>图7 智能手机图像采集示意图</b></a></li>
                                                <li><a href="#146" data-title="&lt;b&gt;图8 抱枕图像表面纹理重建结果&lt;/b&gt;"><b>图8 抱枕图像表面纹理重建结果</b></a></li>
                                                <li><a href="#147" data-title="&lt;b&gt;图9 人民币图像表面纹理重建结果&lt;/b&gt;"><b>图9 人民币图像表面纹理重建结果</b></a></li>
                                                <li><a href="#148" data-title="&lt;b&gt;图10 印章图像表面纹理重建结果&lt;/b&gt;"><b>图10 印章图像表面纹理重建结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" PRADOS E, FAUGERAS O.Shape from shading:mathematical models in computer vision the handbook:MR2232543 68U10[R].Berlin, Germany:Springer, 1989:375-388." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Shape from shading:mathematical models in computer vision the handbook:MR2232543 68U10">
                                        <b>[1]</b>
                                         PRADOS E, FAUGERAS O.Shape from shading:mathematical models in computer vision the handbook:MR2232543 68U10[R].Berlin, Germany:Springer, 1989:375-388.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" WOODHAM R J.Photometric method for determining surface orientation from multiple images[J].Optical Engineering, 1980, 19 (1) :1-22." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PHOTOMETRIC METHOD FOR DETERMINING SURFACE ORIENTATION FROM MULTIPLE IMAGES">
                                        <b>[2]</b>
                                         WOODHAM R J.Photometric method for determining surface orientation from multiple images[J].Optical Engineering, 1980, 19 (1) :1-22.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" YUILLE A, SNOW D.Shape and albedo from multiple images using integrability computer vision and pattern recognition[C]//Proceedings of IEEE Conference on Computer Society.Washington D.C., USA:IEEE Press, 1997:158-164." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Shape and albedo from multiple images using integrability">
                                        <b>[3]</b>
                                         YUILLE A, SNOW D.Shape and albedo from multiple images using integrability computer vision and pattern recognition[C]//Proceedings of IEEE Conference on Computer Society.Washington D.C., USA:IEEE Press, 1997:158-164.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" ALLDRIN N G, MALLICK S P, KRIEGMAN D J.Resolving the generalized bas-relief ambiguity by entropy minimization computer vision and pattern recognition[C]//Proceedings of CVPR’07.Washington D.C., USA:IEEE Press, 2007:1-7." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Resolving the generalized bas-relief ambiguity byentropy minimization">
                                        <b>[4]</b>
                                         ALLDRIN N G, MALLICK S P, KRIEGMAN D J.Resolving the generalized bas-relief ambiguity by entropy minimization computer vision and pattern recognition[C]//Proceedings of CVPR’07.Washington D.C., USA:IEEE Press, 2007:1-7.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" FAVARO P.A closed-form solution to uncalibrated photometric stereo via diffuse maxima[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:821-828." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A closed-form solution to uncalibrated photometric stereo via diffuse maxima">
                                        <b>[5]</b>
                                         FAVARO P.A closed-form solution to uncalibrated photometric stereo via diffuse maxima[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:821-828.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" QUEAU Y, LAUZE F, DUROU J D.Solving uncalibrated photometric stereo using total variation[J].Journal of Mathematical Imaging and Vision, 2015, 52 (1) :87-107." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Solving uncalibrated photometric stereo using total variation">
                                        <b>[6]</b>
                                         QUEAU Y, LAUZE F, DUROU J D.Solving uncalibrated photometric stereo using total variation[J].Journal of Mathematical Imaging and Vision, 2015, 52 (1) :87-107.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" BRESSON X, CHAN T.Fast dual minimization of the vectorial total variation norm and applications to color image processing[J].Inverse Problems and Imaging, 2008, 2 (4) :455-484." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast dual minimization of the vectorial total variation norm and applications to color image processing">
                                        <b>[7]</b>
                                         BRESSON X, CHAN T.Fast dual minimization of the vectorial total variation norm and applications to color image processing[J].Inverse Problems and Imaging, 2008, 2 (4) :455-484.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" LUO T, SHEN J, LI X.Accurate normal and reflectance recovery using energy optimization[J].IEEE Transactions on Circuits and Systems for Video Technology, 2015, 25 (2) :212-224." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accurate normal and reflectance recovery using energy optimization">
                                        <b>[8]</b>
                                         LUO T, SHEN J, LI X.Accurate normal and reflectance recovery using energy optimization[J].IEEE Transactions on Circuits and Systems for Video Technology, 2015, 25 (2) :212-224.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" PARK J, SINHA S N, MATSUSHITA Y, et al.Robust multiview photometric stereo using planar mesh parameterization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (8) :1591-1604." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust Multiview Photometric Stereo Using Planar Mesh Parameterization">
                                        <b>[9]</b>
                                         PARK J, SINHA S N, MATSUSHITA Y, et al.Robust multiview photometric stereo using planar mesh parameterization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (8) :1591-1604.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" HIGO T, MATSUSHITA Y, JOSHI N, et al.A hand-held photometric stereo camera for 3-D modeling[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2009:1234-1241." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A hand-held photometric stereo camera for3-D modeling">
                                        <b>[10]</b>
                                         HIGO T, MATSUSHITA Y, JOSHI N, et al.A hand-held photometric stereo camera for 3-D modeling[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2009:1234-1241.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" SHI B, INOSE K, MATSUSHITA Y, et al.Photometric stereo using Internet images[C]//Proceedings of International Conference on 3D Vision.Washington D.C., USA:IEEE Press, 2015:361-368." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Photometric stereo using Internet images">
                                        <b>[11]</b>
                                         SHI B, INOSE K, MATSUSHITA Y, et al.Photometric stereo using Internet images[C]//Proceedings of International Conference on 3D Vision.Washington D.C., USA:IEEE Press, 2015:361-368.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 杨晓波.基于光度立体视觉法的织物三维表面形态研究[J].西安工程大学学报, 2001, 15 (1) :20-25." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XBFZ200101004&amp;v=MDY4OTVsVXJ2QVBTL05kTEc0SHRETXJvOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         杨晓波.基于光度立体视觉法的织物三维表面形态研究[J].西安工程大学学报, 2001, 15 (1) :20-25.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" 杨晓波, 黄秀宝.基于光度立体视觉的起皱织物表面形态重建研究[J].东华大学学报 (自然科学版) , 2002, 28 (2) :48-55." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DHDZ200202010&amp;v=MDE2OTQ5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSb0Z5N2xVcnZBSVNYUGRMRzRIdFBNclk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         杨晓波, 黄秀宝.基于光度立体视觉的起皱织物表面形态重建研究[J].东华大学学报 (自然科学版) , 2002, 28 (2) :48-55.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" 林欣堂, 李艳东, 吴攀超.新的闭式通用浮雕变换解算法在三维表面检测中的应用[J].吉林大学学报 (工学版) , 2015, 45 (6) :1987-1993." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JLGY201506038&amp;v=MTY3NzlHRnJDVVJMT2VaZVJvRnk3bFVydkFMeUhNZDdHNEg5VE1xWTlHYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         林欣堂, 李艳东, 吴攀超.新的闭式通用浮雕变换解算法在三维表面检测中的应用[J].吉林大学学报 (工学版) , 2015, 45 (6) :1987-1993.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 聂颖, 宋展, 焦国华.一种基于近似点光源模型的光度立体视觉系统标定方法[J].集成技术, 2016, 5 (5) :38-48." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JCJI201605004&amp;v=MDM3MTdydkFMeTdCWjdHNEg5Zk1xbzlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk3bFU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         聂颖, 宋展, 焦国华.一种基于近似点光源模型的光度立体视觉系统标定方法[J].集成技术, 2016, 5 (5) :38-48.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MDE4NTlCYXJPNEh0SE9wNHhGYmVzT1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkM3bFZiL0pKRlk9Tmo3&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" FISCHLER M A, BOLLES R C.Random sample consensus:a paradigm for model fitting with applications to image analysis and automated cartography[J].Communications of the ACM, 1981, 24 (6) :726-740." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography">
                                        <b>[17]</b>
                                         FISCHLER M A, BOLLES R C.Random sample consensus:a paradigm for model fitting with applications to image analysis and automated cartography[J].Communications of the ACM, 1981, 24 (6) :726-740.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" DAN K.A singularly valuable decomposition:the SVD of a matrix[J].College Mathematics Journal, 1996, 27 (1) :2-23." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Singularly Valuable Decomposition The SVD of a Matrix 1996">
                                        <b>[18]</b>
                                         DAN K.A singularly valuable decomposition:the SVD of a matrix[J].College Mathematics Journal, 1996, 27 (1) :2-23.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" RUDIN L I, OSHER S.Total variation based image restoration with free local constraints[C]//Proceedings of IEEE International Conference on Image Processing.Washington D.C., USA:IEEE Press, 1994:31-35." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Total variation based image restoration with free local constraints">
                                        <b>[19]</b>
                                         RUDIN L I, OSHER S.Total variation based image restoration with free local constraints[C]//Proceedings of IEEE International Conference on Image Processing.Washington D.C., USA:IEEE Press, 1994:31-35.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" PERRONE D, FAVARO P.A clearer picture of total variation blind deconvolution[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (6) :1041-1055." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A clearer picture of total variation blind deconvolution">
                                        <b>[20]</b>
                                         PERRONE D, FAVARO P.A clearer picture of total variation blind deconvolution[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (6) :1041-1055.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" PALUBINSKAS G.An unsupervised clustering method by entropy minimization pattern recognition[M]//LINDEN W, DOSE V, FISCHER R, et al.Maximum entropy and Bayesian methods garching.Berlin, Germany:Springer, 1998:1816-1818." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An unsupervised clustering method by entropy minimization pattern recognition">
                                        <b>[21]</b>
                                         PALUBINSKAS G.An unsupervised clustering method by entropy minimization pattern recognition[M]//LINDEN W, DOSE V, FISCHER R, et al.Maximum entropy and Bayesian methods garching.Berlin, Germany:Springer, 1998:1816-1818.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" WU L, GANESH A, SHI B, et al.Robust photometric stereo via low-rank matrix completion and recovery[C]//Proceedings of Asian Conference on Computer Vision.Berlin, Germany:Springer, 2010:703-717." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust photometric stereo via low-rank matrix completion and recovery">
                                        <b>[22]</b>
                                         WU L, GANESH A, SHI B, et al.Robust photometric stereo via low-rank matrix completion and recovery[C]//Proceedings of Asian Conference on Computer Vision.Berlin, Germany:Springer, 2010:703-717.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" KAZHDAN M, BOLITHO M, HOPPE H.Poisson surface reconstruction eurographics[C]//Proceedings of Symposium on Geometry Processing.Berlin, Germany:Springer, 2006:61-70." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Poisson surface reconstruction">
                                        <b>[23]</b>
                                         KAZHDAN M, BOLITHO M, HOPPE H.Poisson surface reconstruction eurographics[C]//Proceedings of Symposium on Geometry Processing.Berlin, Germany:Springer, 2006:61-70.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJC" target="_blank">计算机工程</a>
                2019,45(03),225-231+236 DOI:10.19678/j.issn.1000-3428.0050289            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于智能手机的三维重建方法</b></span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%80%9D%E5%9B%AD&amp;code=38857158&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈思园</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AE%8B%E5%B1%95&amp;code=30203116&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">宋展</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B0%B9%E4%B8%9A%E5%AE%89&amp;code=24623912&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">尹业安</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E6%B1%89%E7%BA%BA%E7%BB%87%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0017230&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武汉纺织大学数学与计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E6%B7%B1%E5%9C%B3%E5%85%88%E8%BF%9B%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6%E9%99%A2%E6%B7%B1%E5%9C%B3%E5%B8%82%E8%99%9A%E6%8B%9F%E7%8E%B0%E5%AE%9E%E4%B8%8E%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92%E6%8A%80%E6%9C%AF%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=1516324&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院深圳先进技术研究院深圳市虚拟现实与人机交互技术重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为快速准确估计物体三维表面结构, 提出基于智能手机的三维重建方法。利用SIFT特征检测方法与RANSAC算法求解单应性矩阵, 使用基于单应性矩阵变换的图像配准算法将多幅视角不同的手机图像配准到同一视角, 并采用总变差正则化与能量最小化联合估计方法求解通用浅浮雕参数, 实现物体表面三维重构。实验结果表明, 该方法能恢复物体表面细微纹理, 重建精度较高。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%99%BA%E8%83%BD%E6%89%8B%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">智能手机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维重建;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E9%85%8D%E5%87%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像配准;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%95%E5%BA%94%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">单应性;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%89%E5%BA%A6%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">光度立体视觉;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    陈思园 (1993—) , 男, 硕士, 主研方向为图像处理、计算机视觉;;
                                </span>
                                <span>
                                    *宋展 (通信作者) , 研究员;;
                                </span>
                                <span>
                                    尹业安, 教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划 (2017YFB1103602);</span>
                                <span>国家自然科学基金 (61773363, U1613213, U1713213);</span>
                                <span>中科院人机智能协同系统实验室和深圳市3D内容生成技术工程实验室联合项目 ([2017]476);</span>
                    </p>
            </div>
                    <h1><b>3D Reconstruction Method Based on Smartphone</b></h1>
                    <h2>
                    <span>CHEN Siyuan</span>
                    <span>SONG Zhan</span>
                    <span>YIN Yean</span>
            </h2>
                    <h2>
                    <span>School of Mathematics and Computer, Wuhan Textile University</span>
                    <span>Shenzhen Key Laboratory of Virtual Reality and Human Interaction Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to quickly and accurately estimate the 3D surface structure of objects, this paper proposes a 3D reconstruction method based on smartphone.It uses Scale Invariant Feature Transform (SIFT) feature detection method and RANSAC algorithm to solve homography matrix, realizes multiple smartphone images registration with different view angles to the same perspective, and uses the total variation regularization and Energy Minimization (EM) joint estimation method to solve Generalized Bas-relief (GBR) parameters to realize 3D reconstruction of object surface.Experimental result shows that the method can restore the fine texture of the object surface, and the reconstruction accuracy is high.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=smartphone&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">smartphone;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=3D%20reconstruction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">3D reconstruction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20registration&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image registration;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=homography&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">homography;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Photometric%20Stereo%20(PS)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Photometric Stereo (PS) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-01-25</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="49" name="49" class="anchor-tag">0 概述</h3>
                <div class="p1">
                    <p id="50">智能手机在当今社会十分普遍, 成像器件包括摄像机和闪光灯。对于智能手机的特殊结构, 可以利用光度立体视觉 (Photometric Stereo, PS) 算法对智能手机获取的图像估计物体三维表面结构。PS由SFS<citation id="151" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>发展而来, 根据是否需要标定光源分为标定和未标定光度立体视觉 (Uncalibrated Photometric Stereo, UPS) 。在物体为朗伯表面、光照为平行光的条件下, 图像灰度信息、法向量、反射率和光源向量满足一个线性等式约束<citation id="152" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。UPS根据灰度信息估计物体表面法向、反射率和光源向量, 是一个不适定求解问题, 通常需增加额外的约束进行求解。文献<citation id="153" type="reference">[<a class="sup">3</a>]</citation>利用奇异值分解 (Singular Value Decomposition, SVD) 及假设表面可积使问题的求解缩小为对一个3×3通用浅浮雕 (Generalized Bas-relief, GBR) 变换矩阵的估计, 对GBR模糊性的求解是未标定光度立体视觉的一般方向。文献<citation id="154" type="reference">[<a class="sup">4</a>]</citation>根据朗伯体反射率分布规律, 对反射率概率分布建立能量函数, 再使用由粗到精的迭代方法估计GBR参数。文献<citation id="155" type="reference">[<a class="sup">5</a>]</citation>利用局部表面反射极大值构建估计GBR参数的封闭形式。文献<citation id="156" type="reference">[<a class="sup">6</a>,<a class="sup">7</a>]</citation>将总变差正则化方法应用于GBR的求解, 对深度场建立总变差正则化函数并求解其深度梯度场, 用凸优化的方法优化最佳深度场, 从而得到最小误差下的GBR参数。</p>
                </div>
                <div class="p1">
                    <p id="51">近年来, 研究人员还致力于将PS算法与其他方法相结合。文献<citation id="157" type="reference">[<a class="sup">8</a>]</citation>融合PS与视网膜大脑皮层理论建立能量优化框架, 通过最小化能量恢复法向量场和反射率。文献<citation id="158" type="reference">[<a class="sup">9</a>]</citation>结合多视图方法, 利用多目立体方法获得稀疏的3D点, 再利用PS获得的法向量优化视差图, 得到高精度的三维模型。文献<citation id="159" type="reference">[<a class="sup">10</a>]</citation>结合PS和运动恢复结构 (Struct from Motion, SFM) 的方法, 利用深度信息和PS获得的法向信息建立能量函数, 获得物体稠密且精度较高的3D模型。文献<citation id="160" type="reference">[<a class="sup">11</a>]</citation>使用网络图片结合多视图和UPS技术实现目标三维重建。文献<citation id="163" type="reference">[<a class="sup">12</a>,<a class="sup">13</a>]</citation>将PS算法应用于织物表面重建, 检测织物起皱程度。文献<citation id="161" type="reference">[<a class="sup">14</a>]</citation>提出一种基于局部灰度极大值的GBR参数闭式求解方法。文献<citation id="162" type="reference">[<a class="sup">15</a>]</citation>对近场点光源进行标定, 建立点光源模型, 使PS算法不局限于传统的平行光假设。本文在现有研究的基础上, 提出基于单应性矩阵变换的图像配准算法, 可将多幅图像还原到同一视角, 再使用UPS技术重建物体表面。</p>
                </div>
                <h3 id="52" name="52" class="anchor-tag">1 智能手机硬件结构</h3>
                <div class="p1">
                    <p id="53">智能手机通常有相机和闪光灯组件, 如图1所示, 具备PS所需的硬件条件, 将手机从不同角度拍摄物体的多幅图像模拟PS的不同光照条件, 使用图像配准技术还原图像, 使图像像素对齐, 解决相机视角不固定问题。</p>
                </div>
                <div class="area_img" id="54">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903038_054.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 智能手机硬件结构" src="Detail/GetImg?filename=images/JSJC201903038_054.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 智能手机硬件结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903038_054.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="55" name="55" class="anchor-tag">2 单应性矩阵变换</h3>
                <div class="p1">
                    <p id="56">单应性变换是一种线性变换。二维图像的单应性变换广泛应用于计算机视觉中, 表示2幅图像中坐标点的映射关系。假设给定图像上某点的齐次坐标为<b><i>P</i></b><sub>1</sub> (<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>, 1) , 其对应图像的点为<b><i>P</i></b><sub>2</sub> (<i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>, 1) , 存在如下关系:</p>
                </div>
                <div class="p1">
                    <p id="57"><b><i>P</i></b><sub>1</sub>=<b><i>P</i></b><sub>2</sub><b><i>H</i></b>      (1) </p>
                </div>
                <div class="p1">
                    <p id="58">其中, <b><i>H</i></b>是一个3×3单应性矩阵, 其未知量有8个, 每组对应点可以产生2个等式, 利用已知的4组对应点即可求解出单应性矩阵<b><i>H</i></b>。若要求解2幅图像之间的单应性矩阵, 至少需要知道图像之间4组不共线的匹配点。当匹配点为4组时, 矩阵<b><i>H</i></b>有唯一解;当匹配点大于4组时, 则可以利用最小二乘法或SVD来求解问题, 利用SIFT特征点检测与匹配方法可得到较好的匹配结果。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59">2.1 SIFT特征点检测与匹配</h4>
                <div class="p1">
                    <p id="60"><i>SIFT</i>算法<citation id="164" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>具有旋转、尺度不变性, 对亮度、噪声、阴影有较好的鲁棒性。<i>SIFT</i>算法采用高斯差分算子提取特征点, 每个特征点都会生成一个特征描述子, 特征描述子是一个128维度的向量, 其包括特征点的8个方向向量的幅值和16个方向角度。<i>SIFT</i>算法在匹配过程中选取一幅图像中的某一特征点向量与另一幅图像的特征点向量进行欧式距离测量, 找到距离最近的特征点向量, 若与其距离小于某个阈值, 则接受该对匹配点。图2为<i>SIFT</i>特征匹配结果。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903038_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 SIFT特征匹配" src="Detail/GetImg?filename=images/JSJC201903038_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 SIFT特征匹配</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903038_061.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="62" name="62">2.2 基于RANSAC算法的单应性矩阵求解</h4>
                <div class="p1">
                    <p id="63">若物体表面纹理丰富, 则SIFT算法会匹配出远大于4组的匹配点对, 并且会产生一些误匹配点, 称为外点。RANSAC算法<citation id="165" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>从一组包含外点的数据集中通过迭代方式估计数学模型的参数。由此可知, 通过2幅图像的4组匹配点即可求解线性方程得出单应性矩阵。基于RANSAC的单应性求解算法具体如下:</p>
                </div>
                <div class="p1">
                    <p id="64">1) 假设由SIFT算法检测并筛选出的匹配点对为<i>N</i> (<i>N</i>&gt;4) , 随机选取4组不共线点, 计算单应性矩阵<b><i>H</i></b>。</p>
                </div>
                <div class="p1">
                    <p id="65">2) 计算所有匹配点与模型<i>M</i>的投影误差, 若误差小于阈值, 则加入内点集<i>I</i>。</p>
                </div>
                <div class="p1">
                    <p id="66">3) 若当前内点集<i>I</i>元素个数大于最优内点集<i>I</i><sub>best</sub>, 则更新<i>I</i>=<i>I</i><sub>best</sub>, 同时更新迭代次数<i>k</i>, <i>k</i>=lg (1-0.995) /lg (1-<i>w</i><sup>4</sup>) , <i>w</i>为内点比例。</p>
                </div>
                <div class="p1">
                    <p id="67">4) 若迭代次数大于<i>k</i>, 则退出;否则迭代次数加1, 重复上述步骤。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68">2.3 图像配准</h4>
                <div class="p1">
                    <p id="69">在使用图像配准技术对N幅不同视角的图像进行配准时, 首先选取一幅参考图像作为正视角, 然后求取剩余N-1幅图像到正视角的单应性, 并利用单应性将剩余N-1幅图像映射到正视角, 即可完成图像配准。图3展示了图像配准前和配准后的匹配结果。第1行是配准前的图像姿态, 第2行是配准后的图像姿态。各图像中的框在图像中的位置和大小均相同, 可以看出本文配准方法效果较好, 可以较好地对齐图像像素。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903038_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 图像配准示意图" src="Detail/GetImg?filename=images/JSJC201903038_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 图像配准示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903038_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="71" name="71" class="anchor-tag">3 未标定光度立体视觉</h3>
                <div class="p1">
                    <p id="72">标定光度立体视觉通过手机相机和闪光灯获取不同光源下的多幅图像, 仅由一组光源信息和表面形状未知的物体图像恢复其法向和表面的光度立体视觉问题称为未标定光度立体视觉。当物体表面为朗伯反射时, 光源为平行光, 不考虑镜面反射和阴影的情况, 第<i>i</i>幅图像的第<i>j</i>个像素的强度为:</p>
                </div>
                <div class="p1">
                    <p id="73"><b><i>I</i></b><sub><i>ij</i></sub>=<i>ρ</i><sub><i>j</i></sub><b><i>n</i></b><sup>T</sup><sub><i>j</i></sub><b><i>s</i></b><sub><i>i</i></sub>      (2) </p>
                </div>
                <div class="p1">
                    <p id="74">其中, <i>ρ</i><sub><i>j</i></sub>是反射率, <b><i>n</i></b><sub><i>j</i></sub>是法向量, <b><i>s</i></b><sub><i>i</i></sub>是光源向量, <b><i>I</i></b>∈<image href="images/JSJC201903038_075.jpg" type="" display="inline" placement="inline"><alt></alt></image><sup><i>m</i>×<i>n</i></sup>是图像数据, <i>m</i>是一幅图像的像素点数量, <i>n</i>为图像数量。令<b><i>B</i></b>=<i>ρ</i><b><i>n</i></b><sup>T</sup>, 存在如下等式:</p>
                </div>
                <div class="p1">
                    <p id="76"><b><i>I</i></b>=<b><i>BS</i></b>      (3) </p>
                </div>
                <div class="p1">
                    <p id="77">这是一个线性方程组, 由于法向量为三维, 因此至少需要3幅不同光源下的图像, 存在如下等式:</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">B</mi><mo>⌢</mo></mover><mo>=</mo><mover accent="true"><mi mathvariant="bold-italic">Ι</mi><mo>⌢</mo></mover><mi mathvariant="bold-italic">S</mi><msup><mrow></mrow><mo>+</mo></msup><mo>, </mo><mover accent="true"><mi>ρ</mi><mo>⌢</mo></mover><mo>=</mo><mo stretchy="false">∥</mo><mover accent="true"><mi mathvariant="bold-italic">B</mi><mo>⌢</mo></mover><mo stretchy="false">∥</mo><mo>, </mo><mover accent="true"><mi mathvariant="bold-italic">n</mi><mo>⌢</mo></mover><mo>=</mo><mover accent="true"><mi mathvariant="bold-italic">B</mi><mo>⌢</mo></mover><mo>/</mo><mover accent="true"><mi>ρ</mi><mo>⌢</mo></mover><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">其中, <b><i>S</i></b><sup>+</sup>是<b><i>S</i></b>的伪逆。当光源矩阵已知时, 求解线性方程组即可求得法向量矩阵;当光源未知、图像数量大于3时, 可以用最小二乘或SVD方法求解线性方程。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80">3.1 GBR模糊性问题</h4>
                <div class="p1">
                    <p id="81">当光源矩阵未知时, 利用<i>SVD</i><citation id="166" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>对图像数据矩阵进行分解:</p>
                </div>
                <div class="p1">
                    <p id="82"><b><i>I</i></b>=<b><i>UDV</i></b><sup>T</sup>      (5) </p>
                </div>
                <div class="p1">
                    <p id="83">其中, <b><i>D</i></b>是一个对角线由<b><i>II</i></b><sup>T</sup>的特征值组成的对角矩阵, <b><i>U</i></b>是由<b><i>I</i></b><sup>T</sup><b><i>I</i></b>的奇异值向量归一化后的列向量, <b><i>V</i></b>是由<b><i>II</i></b><sup>T</sup>的奇异值向量归一化后的列向量。假设<i>x</i>代表某一点在图像上的坐标, <i>e</i> (<i>x</i>) 为<b><i>V</i></b>的前3列, <b><i>f</i></b> (<i>y</i>) 为<i>U</i>的前3列, 则:</p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">B</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mn>3</mn></msub><mi mathvariant="bold-italic">e</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">S</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">Q</mi><msub><mrow></mrow><mn>3</mn></msub><mspace width="0.25em" /><mi mathvariant="bold-italic">f</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="85">其中, <b><i>P</i></b><sub>3</sub>和<b><i>Q</i></b><sub>3</sub>是3×3的矩阵, 且满足<b><i>P</i></b><sup>T</sup><sub>3</sub><b><i>Q</i></b><sub>3</sub>=<b><i>D</i></b><sub>3</sub>, <b><i>D</i></b><sub>3</sub>是对角线由<b><i>D</i></b>中最大的3个奇异值组成的对角矩阵。文献<citation id="167" type="reference">[<a class="sup">3</a>]</citation>假设表面连续可积, 利用可积性约束等式求解<b><i>P</i></b><sub>3</sub>, 但是可积性约束等式只能求出<b><i>P</i></b><sub>3</sub>矩阵中的6个值, 还有3个值需要用另外的方法求解, 即GBR模糊性问题。GBR矩阵为:</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">G</mi><mo>=</mo><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mi>μ</mi></mtd><mtd><mi>ν</mi></mtd><mtd><mi>λ</mi></mtd></mtr></mtable></mrow><mo>) </mo></mrow></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">G</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>=</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mi>λ</mi></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mi>λ</mi></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mo>-</mo><mi>μ</mi></mtd><mtd><mo>-</mo><mi>ν</mi></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>) </mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">由文献<citation id="168" type="reference">[<a class="sup">3</a>]</citation>方法得到初始的<b><i>B</i></b><sup>0</sup>和<b><i>S</i></b><sup>0</sup>后, 其与真实的<b><i>B</i></b>和<b><i>S</i></b>之间只差一个GBR变换, 即:</p>
                </div>
                <div class="p1">
                    <p id="88"><b><i>I</i></b>=<b><i>BS</i></b>≈<b><i>B</i></b><sup>0</sup><b><i>G</i></b><sup>-1</sup><b><i>GS</i></b><sup>0</sup>=<b><i>P</i></b><sub>3</sub><b><i>e</i></b> (<i>x</i>) <b><i>GG</i></b><sup>-1</sup><b><i>Q</i></b><sub>3</sub><b><i>f</i></b> (<i>y</i>)      (8) </p>
                </div>
                <div class="p1">
                    <p id="89">可积性约束可以应用于<b><i>B</i></b>, 具体的差分形式为:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mrow><mi>c</mi><mi>u</mi><mi>r</mi><mi>l</mi></mrow><mo stretchy="true">¯</mo></mover><mspace width="0.25em" /><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mn>0</mn></msup><mo>=</mo><mfrac><mo>∂</mo><mrow><mo>∂</mo><mi>y</mi></mrow></mfrac><mo stretchy="false"> (</mo><mfrac><mrow><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>x</mi><mn>0</mn></msubsup></mrow><mrow><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup></mrow></mfrac><mo stretchy="false">) </mo><mo>-</mo><mfrac><mo>∂</mo><mrow><mo>∂</mo><mi>x</mi></mrow></mfrac><mo stretchy="false"> (</mo><mfrac><mrow><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>y</mi><mn>0</mn></msubsup></mrow><mrow><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup></mrow></mfrac><mo stretchy="false">) </mo><mo>=</mo><mn>0</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">在真实图像数据中, <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mrow><mi>c</mi><mi>u</mi><mi>r</mi><mi>l</mi></mrow><mo stretchy="true">¯</mo></mover><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mn>0</mn></msup><mo>=</mo><mn>0</mn></mrow></math></mathml>通常很难满足, 为解决<i>GBR</i>模糊性问题, 研究者们提出多种方法, 在物体为朗伯体反射模型的假设下, 利用物体本身的一些性质来求解问题。例如使用图像中的局部极大值信息恢复光源向量<citation id="169" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>, 采用朗伯体反射率概率分布特性建立能量函数<citation id="170" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 通过最小化能量函数迭代估计出<i>GBR</i>参数, 其假设物体表面反射率趋近于相同。当重建出的表面局部或全局反射率相差越小时, 能量函数值越小, 对于同种材质的物体该假设是合理的, 重写其算法为:</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mn>0</mn></msup><mi mathvariant="bold-italic">S</mi><msup><mrow></mrow><mn>0</mn></msup><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">∥</mo><mo>=</mo><mi>min</mi></mtd></mtr><mtr><mtd><mo stretchy="false">∥</mo><mover accent="true"><mrow><mi>c</mi><mi>u</mi><mi>r</mi><mi>l</mi></mrow><mo stretchy="true">¯</mo></mover><mspace width="0.25em" /><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mn>0</mn></msup><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mi>min</mi></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mover accent="true"><mi>μ</mi><mo>⌢</mo></mover><mo>, </mo><mover accent="true"><mi>ν</mi><mo>⌢</mo></mover><mo>, </mo><mover accent="true"><mi>λ</mi><mo>⌢</mo></mover><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi>μ</mi><mo>, </mo><mi>ν</mi><mo>, </mo><mi>λ</mi></mrow></munder><mspace width="0.25em" /><mi>ε</mi><mo stretchy="false"> (</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">G</mi><mrow><mo stretchy="false"> (</mo><mi>μ</mi><mo>, </mo><mi>ν</mi><mo>, </mo><mi>λ</mi><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mn>0</mn></msup><mo stretchy="false">∥</mo><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">式 (10) 中第1行利用图像灰度值对求解的初始<b><i>B</i></b><sup>0</sup>和<b><i>S</i></b><sup>0</sup>进行最小误差约束, 第2行利用表面可积约束, <i>ε</i> (‖<b><i>G</i></b> (<i>μ</i>, <i>ν</i>, <i>λ</i>) <sup>T</sup><b><i>B</i></b><sup>0</sup>‖) 表示经过GBR转换后的反射率分布能量。</p>
                </div>
                <h4 class="anchor-tag" id="95" name="95">3.2 总变差正则化估计</h4>
                <div class="p1">
                    <p id="96">总变差 (<i>Total Variation</i>, <i>TV</i>) 正则化是一个广泛用于测量正则化的函数。对于一个连续可微的函数f:Ω⊂R<sup>n</sup>→R, 总变差函数为:</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><mi>V</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><mrow><munder><mo>∫</mo><mi>Ω</mi></munder><mo stretchy="false">∥</mo></mrow></mstyle><mo>∇</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><mtext>d</mtext><mi>x</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">TV是对函数变换特性的一个度量, 是一个具体的数值, 函数变化越大, 总变差值也越大。当TV应用于图像时, <i>n</i>=2。文献<citation id="171" type="reference">[<a class="sup">19</a>]</citation>将TV正则化用于图像去噪。文献<citation id="172" type="reference">[<a class="sup">20</a>]</citation>利用TV迭代的方法将低分辨率图像恢复到高分辨率图像, 增加了图像的有效像素。在本文中对深度场<b><i>u</i></b>建立总变差函数。当<i>n</i>&gt;1时, TV有多种形式定义, 其中使用最广泛的一种定义为:</p>
                </div>
                <div class="p1">
                    <p id="99"><i>TV</i> (<i>f</i>) =<mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><mrow><munder><mo>∫</mo><mi>Ω</mi></munder><mrow></mrow></mrow></mstyle></mrow></math></mathml>‖<i>J</i> (<i>f</i> (<i>x</i>) ) ‖<sub>F</sub>d<i>x</i>      (12) </p>
                </div>
                <div class="p1">
                    <p id="101">其中, ‖<i>J</i> (<i>f</i> (<i>x</i>) ) ‖<sub>F</sub>是在<i>x</i>点的雅各比矩阵范数, 另一种定义为:</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula"><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><mi>V</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><mrow><munder><mo>∫</mo><mi>Ω</mi></munder><mrow></mrow></mrow></mstyle></mrow></math></mathml><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">∥</mo><mo>∇</mo><mi>f</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><mtext>d</mtext><mi>x</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>Τ</mi></mstyle><mi>V</mi><mo stretchy="false"> (</mo><mi>f</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="106">本文对深度场<b><i>u</i></b>建立总变差函数, 总变差函数具有较好的微分性质, 能够使用凸优化工具快速得到最优解。GBR参数不仅取决于表面反射率分布, 也取决于物体表面深度场<b><i>u</i></b>, 深度梯度场∇<b><i>u</i></b>= (<b><i>p</i>, <i>q</i></b>) <sup>T</sup>, <b><i>p</i></b>=-<i>n</i><sub><i>x</i></sub>/<i>n</i><sub><i>z</i></sub>, <b><i>q</i></b>=-<i>n</i><sub><i>y</i></sub>/<i>n</i><sub><i>z</i></sub>, 它们均可以由法向量场<b><i>n</i></b>来求解, 与<b><i>B</i></b><sup>0</sup>存在以下关系:</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mn>0</mn></msup><mo>=</mo><mfrac><mi>ρ</mi><mrow><msqrt><mrow><mo stretchy="false">∥</mo><mo>∇</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mn>1</mn></mrow></msqrt></mrow></mfrac><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mo>-</mo><mo>∇</mo><mi mathvariant="bold-italic">u</mi></mtd></mtr><mtr><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>) </mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108">图4给出了<i>μ</i>、<i>ν</i>对深度场总变差函数值的影响, 其中, <i>μ</i>、<i>ν</i>的真实值均为0, <i>λ</i>=1, 为单独观察每个值对总变差函数的影响, 在计算某个值对总变差函数值的影响时, 将另外2个值设置为真实值。图4 (a) 中的直线为<i>y</i>=200。可以看出, 在<i>μ</i>、<i>ν</i>接近真实值时, 深度场的总变差函数值最小。因此可以通过对深度场建立总变差函数, 然后最小化函数求出<i>μ</i>、<i>ν</i>的最优解。在得到<i>μ</i>、<i>ν</i>后即可估计<i>λ</i>, 本文使用能量最小化 (Energy Minimization, EM) 方法估计<i>λ</i>。</p>
                </div>
                <div class="area_img" id="109">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903038_109.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4μ、ν对深度场总变差函数值的影响" src="Detail/GetImg?filename=images/JSJC201903038_109.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4</b><i>μ</i>、<i>ν</i><b>对深度场总变差函数值的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903038_109.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="110">在由文献<citation id="173" type="reference">[<a class="sup">3</a>]</citation>方法得到初始<b><i>B</i></b><sup>0</sup>后, 深度场的求解只与GBR参数有关。假设真实深度场是二次可微的, 则GBR参数的求解问题可以描述为:</p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mover accent="true"><mi>u</mi><mo>⌢</mo></mover><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mi>u</mi></munder><mspace width="0.25em" /><mi>Τ</mi><mi>V</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd columnalign="left"><mo stretchy="false">∥</mo><mi>ρ</mi><mfrac><mrow><mo stretchy="false"> (</mo><mo>-</mo><mo>∂</mo><msub><mrow></mrow><mi>x</mi></msub><mi mathvariant="bold-italic">u</mi><mo>, </mo><mo>-</mo><mo>∂</mo><msub><mrow></mrow><mi>y</mi></msub><mi mathvariant="bold-italic">u</mi><mo>, </mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mrow><msqrt><mrow><mo stretchy="false">∥</mo><mo>∇</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mn>1</mn></mrow></msqrt></mrow></mfrac><mi mathvariant="bold-italic">S</mi><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mi>min</mi></mtd></mtr></mtable></mrow></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="112">假设<i>u</i><sup>0</sup> (<i>x</i>, <i>y</i>) 是由初始<b><i>B</i></b><sup>0</sup>求出的初始法向量场<b><i>N</i></b><sup>0</sup>通过法向积分求解的初始深度场, 且<b><i>U</i></b><sup>0</sup>= (<i>x</i>, <i>y</i>, <b><i>u</i></b><sup>0</sup> (<i>x</i>, <i>y</i>) ) <sup>T</sup>, <i>x</i>和<i>y</i>是图像上的坐标位置, <b><i>g</i></b> (<i>μ</i>, <i>ν</i>, <i>λ</i>) = (-<i>μ</i>, -<i>ν</i>, 1) /<i>λ</i>是由GBR参数组成的向量。式 (15) 可描述如下:</p>
                </div>
                <div class="p1">
                    <p id="113" class="code-formula">
                        <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">u</mi><mo>⌢</mo></mover><mo>=</mo><mi mathvariant="bold-italic">g</mi><mo stretchy="false"> (</mo><mover accent="true"><mi>μ</mi><mo>⌢</mo></mover><mo>, </mo><mover accent="true"><mi>ν</mi><mo>⌢</mo></mover><mo>, </mo><mover accent="true"><mi>λ</mi><mo>⌢</mo></mover><mo stretchy="false">) </mo><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mn>0</mn></msup><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mover accent="true"><mi>μ</mi><mo>⌢</mo></mover><mo>, </mo><mover accent="true"><mi>ν</mi><mo>⌢</mo></mover><mo>, </mo><mover accent="true"><mi>λ</mi><mo>⌢</mo></mover><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi>μ</mi><mo>, </mo><mi>ν</mi><mo>, </mo><mi>λ</mi></mrow></munder><mspace width="0.25em" /><mi>Τ</mi><mi>V</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><mo stretchy="false"> (</mo><mi>μ</mi><mo>, </mo><mi>ν</mi><mo>, </mo><mi>λ</mi><mo stretchy="false">) </mo><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mn>0</mn></msup><mo stretchy="false">) </mo><mo>, </mo><mi>λ</mi><mo>&gt;</mo><mn>0</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="114">在获得初始深度场<b><i>u</i></b><sup>0</sup>之后, 求解真实深度场<b><i>u</i></b>:</p>
                </div>
                <div class="p1">
                    <p id="115" class="code-formula">
                        <mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">u</mi><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mn>0</mn></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>μ</mi><mi>x</mi><mo>-</mo><mi>ν</mi><mi>y</mi></mrow><mi>λ</mi></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="116">变换后的深度梯度函数为:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mo>∇</mo><mi mathvariant="bold-italic">u</mi><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>x</mi><mn>0</mn></msubsup><mo>/</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup><mo>+</mo><mi>μ</mi><mo>, </mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>y</mi><mn>0</mn></msubsup><mo>/</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup><mo>+</mo><mi>ν</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mtext> </mtext><mtext> </mtext></mrow><mo>-</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mrow><mo> (</mo><mtable columnalign="left"><mtr><mtd><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>x</mi><mn>0</mn></msubsup><mo>+</mo><mi>μ</mi><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup><mo stretchy="false">) </mo><mo>/</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>y</mi><mn>0</mn></msubsup><mo>+</mo><mi>ν</mi><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup><mo stretchy="false">) </mo><mo>/</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup></mtd></mtr></mtable><mo>) </mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">式 (19) 表明在估计<i>μ</i>、<i>ν</i>时不依赖于<i>λ</i>, 在估计<i>μ</i>、<i>ν</i>时将<i>λ</i>值设置为1, 即:</p>
                </div>
                <div class="p1">
                    <p id="119" class="code-formula">
                        <mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mover accent="true"><mi>μ</mi><mo>⌢</mo></mover><mo>, </mo><mover accent="true"><mi>ν</mi><mo>⌢</mo></mover><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>i</mtext><mtext>n</mtext></mrow></mstyle><mrow><mi>μ</mi><mo>, </mo><mi>ν</mi></mrow></munder><mspace width="0.25em" /><mi>Τ</mi><mi>V</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><mo stretchy="false"> (</mo><mi>μ</mi><mo>, </mo><mi>ν</mi><mo>, </mo><mn>1</mn><mo stretchy="false">) </mo><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mn>0</mn></msup><mo stretchy="false">) </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="120">式 (20) 可用quasi-Newton方法一次性求解, 展开式为:</p>
                </div>
                <div class="p1">
                    <p id="121"><b><i>E</i></b> (<i>μ</i>, <i>ν</i>) =<i>TV</i> (<i>g</i> (<i>μ</i>, <i>ν</i>, 1) <b><i>U</i></b><sup>0</sup>) =<i>TV</i> (-<i>μx</i>-<i>νy</i>+<b><i>u</i></b><sup>0</sup> (<i>x</i>, <i>y</i>) )      (21) </p>
                </div>
                <div class="p1">
                    <p id="123">其偏微分为:</p>
                </div>
                <div class="p1">
                    <p id="124" class="code-formula">
                        <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mo>∂</mo><msub><mrow></mrow><mi>μ</mi></msub><mi mathvariant="bold-italic">E</mi><mo>=</mo><mstyle displaystyle="true"><mrow><munder><mo>∫</mo><mi>Ω</mi></munder><mrow><mfrac><mrow><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>x</mi><mn>0</mn></msubsup><mo>+</mo><mi>μ</mi><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup></mrow><mrow><msqrt><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>x</mi><mn>0</mn></msubsup><mo>+</mo><mi>μ</mi><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>y</mi><mn>0</mn></msubsup><mo>+</mo><mi>ν</mi><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup><mo stretchy="false">) </mo></mrow></msqrt></mrow></mfrac></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mo>∂</mo><msub><mrow></mrow><mi>ν</mi></msub><mi mathvariant="bold-italic">E</mi><mo>=</mo><mstyle displaystyle="true"><mrow><munder><mo>∫</mo><mi>Ω</mi></munder><mrow><mfrac><mrow><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>y</mi><mn>0</mn></msubsup><mo>+</mo><mi>ν</mi><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup></mrow><mrow><msqrt><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>x</mi><mn>0</mn></msubsup><mo>+</mo><mi>μ</mi><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>y</mi><mn>0</mn></msubsup><mo>+</mo><mi>ν</mi><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup><mo stretchy="false">) </mo></mrow></msqrt></mrow></mfrac></mrow></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="125">为加快估计<i>μ</i>、<i>ν</i>的速度, 利用吉洪诺夫正则化方法将<i>μ</i>、<i>ν</i>的初始值<mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mover accent="true"><mi>μ</mi><mo>⌢</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo><mover accent="true"><mi>ν</mi><mo>⌢</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo></mrow></math></mathml>设置为:</p>
                </div>
                <div class="p1">
                    <p id="127" class="code-formula">
                        <mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mover accent="true"><mi>μ</mi><mo>⌢</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><mover accent="true"><mi mathvariant="bold-italic">p</mi><mo>¯</mo></mover><msup><mrow></mrow><mn>0</mn></msup><mo>=</mo><mo>-</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>x</mi><mn>0</mn></msubsup><mo>/</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup></mtd></mtr><mtr><mtd><mover accent="true"><mi>ν</mi><mo>⌢</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><mover accent="true"><mi mathvariant="bold-italic">q</mi><mo>¯</mo></mover><msup><mrow></mrow><mn>0</mn></msup><mo>=</mo><mo>-</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>y</mi><mn>0</mn></msubsup><mo>/</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>z</mi><mn>0</mn></msubsup></mtd></mtr></mtable></mrow></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="128" name="128">3.3 熵值最小化估计</h4>
                <div class="p1">
                    <p id="129">通过对生活中大量事物的观察发现, 物体表面反射率仅有少数几个值构成, 反射率分布函数接近于脉冲函数, 直方图近似法可以有效近似反射率分布规律。GBR变换对重建石膏图像反射率分布直方图的影响如图5所示。</p>
                </div>
                <div class="area_img" id="130">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903038_130.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 GBR变换对重建石膏图像反射率分布直方图的影响" src="Detail/GetImg?filename=images/JSJC201903038_130.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 GBR变换对重建石膏图像反射率分布直方图的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903038_130.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="131">反射率分布直方图在GBR变换前是平缓的, 变换后变尖锐。根据该规律, 可以为反射率分布函数<i>f</i>建立能量函数:</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><mrow><munder><mo>∫</mo><mi>Ω</mi></munder><mspace width="0.25em" /></mrow></mstyle><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mrow><mi>lg</mi></mrow><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext>d</mtext><mi>x</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">式 (24) 常用于类型数量未知情况下的无监督聚类分析<citation id="174" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>, <i>f</i> (<i>x</i>) 为反射率概率分布函数。</p>
                </div>
                <div class="p1">
                    <p id="134"><i>f</i> (<i>x</i>) =<i>P</i> (<i>ρ</i>) =<i>P</i> (‖<b><i>B</i></b><sup>0</sup><b><i>G</i></b><sup>-1</sup>‖)      (25) </p>
                </div>
                <div class="p1">
                    <p id="135">本文在估计<i>λ</i>时, 将<i>μ</i>、<i>ν</i>设置为0。理论上, <i>λ</i>可以为任意正数, 但根据经验<i>λ</i>值通常小于5, 因此令0&lt;<i>λ</i>≤5, 然后将<i>λ</i>离散化, 使用由粗到精的方法估计<i>λ</i>值。</p>
                </div>
                <h3 id="136" name="136" class="anchor-tag">4 实验结果与分析</h3>
                <h4 class="anchor-tag" id="137" name="137">4.1 数据集</h4>
                <div class="p1">
                    <p id="138">本文利用图卢兹大学信息技术学院的网站数据集进行对比实验, 数据来自于网站 (<i>http</i>://<i>ubee</i>.<i>enseeiht</i>.<i>fr</i>/<i>photometricstereo</i>/) 。数据集共有4组, 依次为<i>Korean</i>_<i>doll</i>、<i>Redfish</i>、<i>Octopus</i>、<i>Beethoven</i>, 每组数据均有5幅图像, 所有实验编码环境为<i>Matlab</i>2017<i>a</i>, 电脑配置为3.04 <i>GHz CPU</i>, <i>Intel CORE i</i>7。将本文方法分别与<i>EM</i>方法和朗伯反射极大值 (<i>LDR</i>) 方法进行比较, 比较方法均是与标定光源的光度立体视觉方法相比, 比较项包括与<i>PS</i>方法相比获得的平均法向角度误差 (<i>Mean Angle Error</i>, <i>MAE</i>) 和<i>CPU</i>运行时间。图6展示了各种方法的重建结果。</p>
                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903038_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 各方法图像三维重建结果" src="Detail/GetImg?filename=images/JSJC201903038_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 各方法图像三维重建结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903038_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="140">表1列出各方法的性能比较结果。可以看出, 本文方法相比EM方法和LDR方法的重建结果更好, EM方法由于使用由粗到精的方法进行迭代, 需要求解3个参数, 因此时间较长。LDR求解速度较快, 但求解精度不太稳定。</p>
                </div>
                <div class="area_img" id="141">
                    <p class="img_tit"><b>表1 各重建方法性能比较结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="141" border="1"><tr><td>数据集</td><td>重建方法</td><td>MAE/ (°) </td><td>CPU运行时间/s</td></tr><tr><td rowspan="3"><br />Korean_doll</td><td><br />EM方法</td><td>12.68</td><td>207.50</td></tr><tr><td><br />LDR方法</td><td>17.49</td><td>2.16</td></tr><tr><td><br />本文方法</td><td>10.90</td><td>5.45</td></tr><tr><td rowspan="3"><br />Redfish</td><td><br />EM方法</td><td>11.28</td><td>33.97</td></tr><tr><td><br />LDR方法</td><td>11.26</td><td>0.47</td></tr><tr><td><br />本文方法</td><td>10.66</td><td>0.82</td></tr><tr><td rowspan="3"><br />Octopus</td><td><br />EM方法</td><td>11.66</td><td>30.99</td></tr><tr><td><br />LDR方法</td><td>12.09</td><td>0.30</td></tr><tr><td><br />本文方法</td><td>10.12</td><td>0.69</td></tr><tr><td rowspan="3"><br />Beethoven</td><td><br />EM方法</td><td>11.07</td><td>16.16</td></tr><tr><td><br />LDR方法</td><td>10.24</td><td>0.28</td></tr><tr><td><br />本文方法</td><td>9.25</td><td>0.44</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="142" name="142">4.2 真实环境实验结果</h4>
                <div class="p1">
                    <p id="143">图7展示了图像采集装置, 采集装置为智能手机, 型号为iphone6。采集时从不同角度对重建物进行拍照, 同时打开闪光灯。在拍摄时处于黑暗环境减少环境光的影响, 在移动手机拍摄视角时, 偏差不宜过大, 使配准阶段每一个像素都能对齐。在采集图像时, 手机离物体约30 cm。</p>
                </div>
                <div class="area_img" id="144">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903038_144.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 智能手机图像采集示意图" src="Detail/GetImg?filename=images/JSJC201903038_144.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 智能手机图像采集示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903038_144.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="145">在实验中假设手机光源为平行光。为便于验证, 本文将采集图像复制到电脑端。在真实环境下, 物体表面通常会存在镜面反射或阴影等干扰点。本文使用文献<citation id="175" type="reference">[<a class="sup">22</a>]</citation>方法对输入图像数据进行低秩处理, 使得图像数据矩阵的秩为3, 去除镜面反射或阴影等噪点。在得到法向图后, 使用泊松解析法<citation id="176" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>, 由法向积分获得物体表面三维结构。图8～图10分别展示了对抱枕、人民币和印章图像表面纹理的重建结果。为加快运算速度, 对每幅图像都进行下采样, 并选取局部区域进行计算。可以看出, 本文方法能恢复物体表面的细微纹理, 重建精度较高。</p>
                </div>
                <div class="area_img" id="146">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903038_146.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 抱枕图像表面纹理重建结果" src="Detail/GetImg?filename=images/JSJC201903038_146.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图8 抱枕图像表面纹理重建结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903038_146.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="147">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903038_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 人民币图像表面纹理重建结果" src="Detail/GetImg?filename=images/JSJC201903038_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图9 人民币图像表面纹理重建结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903038_147.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="148">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJC201903038_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 印章图像表面纹理重建结果" src="Detail/GetImg?filename=images/JSJC201903038_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图10 印章图像表面纹理重建结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJC201903038_148.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="149" name="149" class="anchor-tag">5 结束语</h3>
                <div class="p1">
                    <p id="150">本文提出一种基于智能手机的三维重建方法, 使用手机相机和闪光灯器件从不同视角获得图像数据, 利用图像配准和非标定光度立体视觉技术重建物体表面结构。本文方法重建精度高, 但由于手机闪光灯光源近似为平行光, 因此重建结果存在误差, 并且实验发现对曲率较大的表面进行图像配准时难度较大, 即该方法适用于表面平坦的重建物。下一步将对此进行重点研究, 使本文方法更具普适性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Shape from shading:mathematical models in computer vision the handbook:MR2232543 68U10">

                                <b>[1]</b> PRADOS E, FAUGERAS O.Shape from shading:mathematical models in computer vision the handbook:MR2232543 68U10[R].Berlin, Germany:Springer, 1989:375-388.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PHOTOMETRIC METHOD FOR DETERMINING SURFACE ORIENTATION FROM MULTIPLE IMAGES">

                                <b>[2]</b> WOODHAM R J.Photometric method for determining surface orientation from multiple images[J].Optical Engineering, 1980, 19 (1) :1-22.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Shape and albedo from multiple images using integrability">

                                <b>[3]</b> YUILLE A, SNOW D.Shape and albedo from multiple images using integrability computer vision and pattern recognition[C]//Proceedings of IEEE Conference on Computer Society.Washington D.C., USA:IEEE Press, 1997:158-164.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Resolving the generalized bas-relief ambiguity byentropy minimization">

                                <b>[4]</b> ALLDRIN N G, MALLICK S P, KRIEGMAN D J.Resolving the generalized bas-relief ambiguity by entropy minimization computer vision and pattern recognition[C]//Proceedings of CVPR’07.Washington D.C., USA:IEEE Press, 2007:1-7.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A closed-form solution to uncalibrated photometric stereo via diffuse maxima">

                                <b>[5]</b> FAVARO P.A closed-form solution to uncalibrated photometric stereo via diffuse maxima[C]//Proceedings of IEEE Conference on Computer Vision and Pattern Recognition.Washington D.C., USA:IEEE Press, 2012:821-828.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Solving uncalibrated photometric stereo using total variation">

                                <b>[6]</b> QUEAU Y, LAUZE F, DUROU J D.Solving uncalibrated photometric stereo using total variation[J].Journal of Mathematical Imaging and Vision, 2015, 52 (1) :87-107.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast dual minimization of the vectorial total variation norm and applications to color image processing">

                                <b>[7]</b> BRESSON X, CHAN T.Fast dual minimization of the vectorial total variation norm and applications to color image processing[J].Inverse Problems and Imaging, 2008, 2 (4) :455-484.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accurate normal and reflectance recovery using energy optimization">

                                <b>[8]</b> LUO T, SHEN J, LI X.Accurate normal and reflectance recovery using energy optimization[J].IEEE Transactions on Circuits and Systems for Video Technology, 2015, 25 (2) :212-224.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust Multiview Photometric Stereo Using Planar Mesh Parameterization">

                                <b>[9]</b> PARK J, SINHA S N, MATSUSHITA Y, et al.Robust multiview photometric stereo using planar mesh parameterization[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017, 39 (8) :1591-1604.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A hand-held photometric stereo camera for3-D modeling">

                                <b>[10]</b> HIGO T, MATSUSHITA Y, JOSHI N, et al.A hand-held photometric stereo camera for 3-D modeling[C]//Proceedings of International Conference on Computer Vision.Washington D.C., USA:IEEE Press, 2009:1234-1241.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Photometric stereo using Internet images">

                                <b>[11]</b> SHI B, INOSE K, MATSUSHITA Y, et al.Photometric stereo using Internet images[C]//Proceedings of International Conference on 3D Vision.Washington D.C., USA:IEEE Press, 2015:361-368.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XBFZ200101004&amp;v=MTMxMTE0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdsVXJ2QVBTL05kTEc0SHRETXJvOUZZSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 杨晓波.基于光度立体视觉法的织物三维表面形态研究[J].西安工程大学学报, 2001, 15 (1) :20-25.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DHDZ200202010&amp;v=MDMzOTMzenFxQnRHRnJDVVJMT2VaZVJvRnk3bFVydkFJU1hQZExHNEh0UE1yWTlFWklRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 杨晓波, 黄秀宝.基于光度立体视觉的起皱织物表面形态重建研究[J].东华大学学报 (自然科学版) , 2002, 28 (2) :48-55.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JLGY201506038&amp;v=MTc0MzZxQnRHRnJDVVJMT2VaZVJvRnk3bFVydkFMeUhNZDdHNEg5VE1xWTlHYklRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 林欣堂, 李艳东, 吴攀超.新的闭式通用浮雕变换解算法在三维表面检测中的应用[J].吉林大学学报 (工学版) , 2015, 45 (6) :1987-1993.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JCJI201605004&amp;v=Mjk4NDVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm9GeTdsVXJ2QUx5N0JaN0c0SDlmTXFvOUZZSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 聂颖, 宋展, 焦国华.一种基于近似点光源模型的光度立体视觉系统标定方法[J].集成技术, 2016, 5 (5) :38-48.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MTQ0MDRhck80SHRIT3A0eEZiZXNPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGQzdsVmIvSkpGWT1OajdC&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography">

                                <b>[17]</b> FISCHLER M A, BOLLES R C.Random sample consensus:a paradigm for model fitting with applications to image analysis and automated cartography[J].Communications of the ACM, 1981, 24 (6) :726-740.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Singularly Valuable Decomposition The SVD of a Matrix 1996">

                                <b>[18]</b> DAN K.A singularly valuable decomposition:the SVD of a matrix[J].College Mathematics Journal, 1996, 27 (1) :2-23.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Total variation based image restoration with free local constraints">

                                <b>[19]</b> RUDIN L I, OSHER S.Total variation based image restoration with free local constraints[C]//Proceedings of IEEE International Conference on Image Processing.Washington D.C., USA:IEEE Press, 1994:31-35.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A clearer picture of total variation blind deconvolution">

                                <b>[20]</b> PERRONE D, FAVARO P.A clearer picture of total variation blind deconvolution[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (6) :1041-1055.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An unsupervised clustering method by entropy minimization pattern recognition">

                                <b>[21]</b> PALUBINSKAS G.An unsupervised clustering method by entropy minimization pattern recognition[M]//LINDEN W, DOSE V, FISCHER R, et al.Maximum entropy and Bayesian methods garching.Berlin, Germany:Springer, 1998:1816-1818.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust photometric stereo via low-rank matrix completion and recovery">

                                <b>[22]</b> WU L, GANESH A, SHI B, et al.Robust photometric stereo via low-rank matrix completion and recovery[C]//Proceedings of Asian Conference on Computer Vision.Berlin, Germany:Springer, 2010:703-717.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Poisson surface reconstruction">

                                <b>[23]</b> KAZHDAN M, BOLITHO M, HOPPE H.Poisson surface reconstruction eurographics[C]//Proceedings of Symposium on Geometry Processing.Berlin, Germany:Springer, 2006:61-70.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJC201903038" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201903038&amp;v=Mjc0NzdydkJMejdCYmJHNEg5ak1ySTlHYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJvRnk3bFU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUU45dm52MzRMT3pvcFZMMjlLRVVpST0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
